index,text
25410,sub disciplines of the water sector are fractured into specialty domains so the underlying modeling tools for flow and water quality are designed based on a pre determined set of equations however many problems involve interactions between multiple domains in an integrated one water approach the opportunity to integrate the different sets of equations is fundamental to the shift towards evaluating environmental issues more holistically this paper describes an extensible modeling framework for defining and adding user defined model components using plugins the plugin approach allows the available model components and the processes to adapt to the user s specific needs and objectives the focus of this paper is to describe the philosophy of developing the open extendable framework and to present the data structure used to describe model components their properties and the equations used for computing state and derived variables in the end four examples of the framework s multi domain capability are provided keywords agile software extensible framework plugin add in modeling framework water system model data availability all the data and codes have been made available on github 1 software availability software name openhydroqual year first available 2019 operating system windows mac os or linux operating system availability the installation package for the gui version of openhydroqual is available at https www openhydroqual com free user registration required source openhydroqual code can be accessed through the github repository https github com arashmassoudieh openhydroqual cost free license openhydroqual is released under a gnu general public license version 2 june 1991 https www gnu org licenses oldlicenses gpl 2 0 en html examples the data and model files of all the demonstration examples presented in this paper can be found at https github com arashmassoudieh openhydroqual tree master examples more instructional examples can be found on the youtube channel https www youtube com channel ucj3b55fpmnaam3b5besdhmg or the program website https openhydroqual com knowledge base 2 introduction environmental models play an essential role in predicting and simulating the nature of natural and engineered environmental systems evaluating the impact of various design operation and management decisions and extracting transferable knowledge from site specific data among other functions tools developed for modeling environmental systems in general and water systems in particular often focus on a single domain with a uniform set of governing equations applied to the entire domain examples include modeling frameworks developed to construct models of flow and reactive transport in groundwater systems flow in unsaturated soil pressurized flow in pipe networks hydraulics in open channels water distribution networks water quality in surface water bodies hydrologic modeling of watersheds urban stormwater management and stormwater control measures however many problems related to natural or engineered water systems involving flow mass transfer or aquatic ecology particularly when natural systems are affected by engineering infrastructure require considering interactions between multiple domains each governed by different sets of processes models and governing equations the application of disjoint domain specific models limits our ability to obtain a holistic view of systems by considering the interactions between different domains bulatewicz et al 2013 for example the interactions between overland flow streams soil and groundwater processes in modeling flow and transport in a watershed are likely affected by water divergence for agricultural industrial use or public supply yang et al 2009 ficklin et al 2013 essaid and caldwell 2017 sophocleous and perkins 2000 integrated urban water management consisting of pipe networks storage units pumps and treatment plants mitchell 2006 pikaar et al 2014 and modeling flow and transport processes for stormwater management involving runoff generation conveyance networks various types of stormwater control measures involving soil percolation and groundwater surface water interactions thomas and vogel 2012 naeimi and safavi 2019 kim et al 2019 coupling two or more computational tools each made for a different domain has been widely utilized to solve multi domain environmental problems either manually or through interfaces bailey et al 2016 aliyari et al 2019 zhang and chui 2020 baek et al 2020 de keyser et al 2010 kidmose et al 2015 however coupling multiple model engines developed with different programming languages and different spatial and temporal discretization is not always a straightforward task it does not result in the best computational efficiency especially when two way or multiple way coupling of the processes in different domains is required coupling various models through file exchange or internal computer memory can be highly time consuming and labor intensive kneis 2015 rode et al 2010 bruggeman and bolding 2014 sophocleous and perkins 2000 one typical problem is when models of large scale natural systems for example at the watershed scale are to be coupled with manual or automatic human controlled processes such as water withdrawal water supply wells or best management practices due to the differences between the spatial and temporal scales varga et al 2016 the recent attempts to develop digital twins for water systems involving a diverse array of components increase the need for the existence of agile modeling tools that can accommodate new components and can be extended and added to the model in a plug and play fashion furthermore modeling is sometimes used to study specific aspects of a system or test a hypothesis requiring the inclusion of particular processes or incremental changes of process representation using customized physically based or empirical relationships to address this need modeling frameworks should allow users to alter the governing equations or add their hypothesized processes to their models mendoza et al 2015 clark et al 2011 hamilton et al 2022 fenicia et al 2008 as our understanding of the mechanisms affecting the working of natural and engineered systems advances there is a need to revise modeling frameworks to be able to add new processes seamlessly or alter existing ones mendoza et al 2015 clark et al 2011 david et al 2013 argues that modeling frameworks should promote users creativity to construct new models without them having to get involved in the software engineering aspects of the modeling frameworks this fosters creativity by not constraining the modeler to the developer s view of the processes in other words the underlying conceptual model of the physical system should not be intertwined with the framework and instead it must exist outside the framework to allow continuous development these points highlight the importance of developing modeling frameworks that provide maximum agility flexibility and transparency to adapt to a wide range of target problems one way to achieve this is to avoid hard coding the model governing equations to the greatest extent possible allowing users to effortlessly inspect and alter the governing equations used to describe various components of a model without needing to recompile the code the plugin based or open architecture approach in which a user can develop and add a feature to a software application has been widely adopted in many areas of software engineering dunfey et al 2006 schindelin et al 2015 rueden et al 2017 the key idea behind plugin architecture in software engineering is to isolate the program s core from its features allowing the addition of features with ideally no change to the core plugins provide extensibility flexibility and transparency and also can facilitate collaboration this approach can be adopted in the case of models used for water systems by enabling the definition of various components e g surface water soil pipes water wells plants using plugins the governing equations describing flow and transport in each component will all be included in the plugins trolle et al 2012 pointed out that to achieve flexibility in a modeling framework biogeochemical and ecological modules should not restrict the dimensionality and structure of their modeled environments the block link representation of the modeled environment allows the modeling domain to be configured as an interconnected set of various domains each represented by appropriate governing equations and discretized according to need and with the desired dimensionality the plugin approach has been widely adopted in many areas of software engineering such as in web browsers remote sensing and image processing applications gis applications email clients and text editors e g duarte and teodoro 2021 nielsen et al 2021 the plugin approach minimizes hard coding keeps the computational engine lightweight allows third party expansion and reduces the size of an application by not loading unused features the plugin approach keeps the numerical solution algorithm separate from individual processes allowing standalone testing of individual processes by keeping the computational engine generic debugging and optimizing the program core becomes more manageable and can be done independently of the individual components the plugin approach allows the evolution and expansion of the framework to rely on a community of users ahalt et al 2014 beck et al 2001 and by supporting freedom of choice for a modeler the requirements for the modeling tool need not be fully known at the time of development and can change and expand iteratively and incrementally with a user s community s involvement sydelko et al 2001 proposed an object oriented approach for dynamic ecosystem modeling based on a dynamic information architecture system dias that can use external models to represent various aspects of the system zhang et al 2016 extended a lumped parameter hydrological model to include crop growth soil biochemical processes soil erosion water quality and dam regulations zeng et al 2020 made steps towards achieving an extensible modeling framework for watershed management by developing an interface oriented add in modeling framework that used dynamic link libraries dlls for adding new processors encapsulating modules to their modeling tool for watershed management they used topological sorting of the water system network to determine the information flow from components to others this paper describes a new open source plugin based extensible and flexible modeling framework for modeling automatic parameter estimation and optimizing aquatic systems the modeling framework can be used in developing models of a wide range of water related problems ranging from water supply networks stormwater watershed modeling surface water groundwater stream interactions water quality and many more as well as problems consisting of a combination of two or more of these domains interacting in a coupled way the modeling framework has the following characteristics models are constructed based on the object oriented design as a network of blocks in which the balance of material is done and links through which the exchange of materials occurs all the components and the governing equations defining their processes are introduced as plugins that are completely separate from the computational engine as text files all the plugins are readable and modifiable by users users can also add their own components by developing new plugins all the components of the modeling framework are offered as ascii text files and thus the governing equations are fully transparent the modeling framework can be used either in the graphical user interface gui form or by including the engine as a library into another code a console version of the program is also available the numerical solution algorithm is generic and completely independent of the processes to be considered in the model it can solve balance equations for any state variable as long as the relationships between exchange rates and state variables are provided the program has features for optimization and auto calibration based on measured data auto calibration can be done deterministically based on the maximum likelihood approach using a hybrid genetic algorithm or probabilistically using the markov chain monte carlo mcmc method 3 inner workings water flow energy dynamics and chemical fate and transport in any zero one two or three dimensional model can be modeled effectively by representing the domain as a set of elements blocks exchanging water mass or energy through interfaces links that connect the blocks to each other given that the relationships between the state variables inside the blocks and the rate of exchange between the blocks are known either directly or indirectly through some intermediate derived variables this formulation will result in a system of non linear ordinary differential equations that can be solved for state variables any balance equations for water mass or energy in a water system can be described in the following generic form 1 d w i d t j q i j r i w i θ i r j w j θ j θ i j k u i k r i w i where w i is the total amount of a generic state variable in block i and q i j q j i is the transfer rate from blocks i to block j the exchange rate q i j is a generic function of a set of derived quantities of blocks i and j noted by r i and r j specifically which is ultimately a function of the state variables w i and w j a set of properties or parameters associated with the blocks i and j noted by θ i and θ j respectively and a set of properties of the link indicated by θ i j u i k indicates the external forcing or source sinks affecting state variable w in block i for example when computing the water flux from one unsaturated soil layer to another w is the total amount of water in a block q is the flow rate from one block to another which is a function of the derived quantity hydraulic head r in each of the blocks this in turn depends on the amount of water in the blocks we can similarly use this generic form to represent the balance of the mass of chemicals undergoing reactions energy heat etc the computational engine of openhydroqual can solve equations presented in the form of eq 1 using an implicit newton raphson method with an adaptive time step and partial jacobian updating massoudieh et al 2017 the details of the numerical method are provided in appendix a in openhydroqual the building blocks of a model include blocks links sources chemical constituents reactions parameters objective functions and observed data all of these components inherit from a single class called object each object has a series of properties hereafter referred to as quantities each quantity can have one of the following identities the quantities can be constants strings state variables expressions time series data sources or rules constants represent some physical properties of the objects expressions are quantities that their values are derived based on other properties currently functions including min max exp log abs sign square root heaviside function and two kernel smoothing functions based on gaussian and exponential kernels for time series data can be used in the expressions additional functions can easily be added as the need arises variables that get their values from the outputs of source objects rules are like expressions but they allow if then conditionals all classes defining the components can be introduced by the user in a plugin file written in json format crockford 2012 fig 2 provides a simple example of the textual modeling language for a block object representing a reservoir as a demonstration for more details about the structure of plugin files and the meaning of each keyword please see the user s manual available on the program s website 3 1 building blocks of a model to create a model various elements like blocks links sources parameters observations objective functions chemical constituents reactions and reaction parameters are combined these elements inherit from a class named object fig 1 which mainly consists of multiple quantities that can represent constants strings time series data derived quantities or state variables the values of these quantities are determined by solving balance equations each object type such as soil surface runoff or links representing the interfaces between them has its properties specified in external plugin files written in the json data interchange format these external plugin files also contain equations governing the exchange of water energy and material between blocks through links as well as expressions for all derived variables the model allows different groups of object types which are defined in separate json files i e plugins to be added as needed the main code interprets the plugins to a system of ordinary differential equations representing the conservation of the state variables a block is a control volume for which the balance equations are solved while links represent the interface between blocks through which water and material exchange occurs sources are objects that control the influx or outflux of water or material into a block examples of sources include precipitation evapotranspiration external loading of a chemical into a block mass transfer through processes such as aeration or transfer of energy to a block through radiation or heat conduction parameters are quantitative properties of model components whose values can be estimated through optimization or deterministic or probabilistic parameter estimation observations contain information about a measured quantity that is intended to be used for model calibration an observation object contains properties that specify the corresponding model output to the measured quantity and the time series containing the measured data objective functions are objects that specify the target function to be maximized or minimized in the optimization process an objective function contains an expression that determines the dynamic output items to be used for calculating the objective function and how the dynamic quantity is aggregated to determine the final objective function the options are maximum integral variance and specific quantiles of the quantity s frequency distribution in the output dynamically calculated based on the model s outputs reactions are objects that store reaction rate expressions and stoichiometric constants of a reaction affecting one or more constituents the code was written using the c programming language a gui was developed using the qt library which allows the user to import plugins insert model components utilizing a drag and drop approach assign properties to each component run the model and post process the results fig 3 shows a screenshot of the gui the dynamic library for the computational engine is entirely separate from the gui and can be included in other c programs without the gui the stand alone dynamic library allows future seamless incorporation of the modeling framework into web based tools or gis applications or other programs for example for optimal control choi et al 2021 holzworth et al 2010 the library also allows using parts of the computational engine in conjunction with other models or tools for example one can couple the reaction module of openhydroqual with a distributed hydrodynamic or hydrologic model representing a water body the gui is designed to be intuitive model components can be inserted one by one through drag and drop as one or two dimensional arrays of linked blocks or by directly writing an easy to understand script that is then interpreted by the framework a console version of the tool is also available that can be used for batch processing or as a server side application there are currently 17 plugins included in the repository that have components for modeling groundwater flow and transport flow in unsaturated soil pressurized flow in pipe networks open channel and streamflow evapotranspiration urban water management stormwater conveyance stormwater control measures chemical mass transfer and reactions particle transport fluvial processes and some more these plugins are included in the installation package different components coming from various plugins can be used in conjunction for example one may use some components from the groundwater plugin in conjunction with a pump pipe system or stream components defined in other plugins the computational engine first translates the model schema to a system of ordinary differential equations that are then solved using a global implicit method hoffmann et al 2010 as described in appendix a although the main code performs a validation by ensuring the necessary quantities required in each object to establish connections between them exists it is inevitable that a user may define a plugin that is unsolvable or one that is solvable but does not accurately represent the physical processes being modeled two cases representing the validation of the reactive transport feature of the model through comparison with exact solutions are available at https github com arashmassoudieh openhydroqual tree master validation 4 demonstration examples we present four examples to demonstrate openhydroqual s flexible modeling capability the main goal of the examples is to show the versatile capabilities of openhydroqual and encompass domains that are not typically available together in a single modeling framework the systems considered in the examples are not necessarily based on any particular real case but we have made an effort to use realistic parameter values based on the typical values found in the literature the purpose of the four demonstration cases is to show how the framework can be used to construct models comprising a diverse range of components and not to verify whether the governing equations in the plugins used accurately represent the modeled processes when applied to real modeling problems where observed data is available openhydroqual allows for modifying not only the parameter values but also the governing equations used in the plugins iteratively until a good agreement between modeled and measured data is achieved the first demonstration case represents an aquifer system utilized for water supply and the water distribution network the second example illustrates a system consisting of four bioretention systems receiving water from four impervious catchments we modeled the flow in the sewer network connecting the bioretention systems infiltration through the unsaturated soil and groundwater recharge the third example represents a wet pond that is discretized into six compartments the model includes biogeochemical processes affecting organic matter and nitrogen species in the overlying water and active sediments the model considers evaporation and infiltration into the underlying soil the fourth example shows an urbanized watershed with runoff entering an infiltration basin with a dry well we model runoff generation and conveyance through the sewer network ponding and then exfiltration through the dry well and also the build up wash off and transport of a hypothetical pollutant in the system for the sake of brevity some of the details of the models are provided in the supplementary information due to the large number of components used in the four examples provided it is not possible to present the governing equations controlling each and every component however all the governing equations considered in all the plugins used in the examples as well as other plugins delivered with the installation package by default can be found at https github com arashmassoudieh openhydroqual tree master resources 4 1 demonstration i modeling a coupled water distribution network with an unconfined groundwater system this example consists of an unconfined aquifer system used as the water supply to a small water distribution network a pump withdraws water from a water supply well and sends the water to an elevated water tank the storage tank is connected to a water distribution network the diagram of the system that has been modeled is shown in fig 4 the unconfined groundwater system is modeled as a 1000 m 1000 m square domain which is discretized into a 5 5 grid the water well is in the center point of the domain the bedrock or aquifer base is assumed to be 20 m below the ground surface and the initial groundwater table is 7 m below the ground surface a fixed head boundary condition at an elevation of 7 m below the ground surface is assumed for all four boundaries around the domain the hydraulic conductivity and the specific yield for the aquifer are considered to be 1 8 m day and 0 3 respectively the flow rate from each aquifer block to an adjacent one is calculated based on darcy s law 2 q k b h i j h i 1 j h i j h i 1 j z i j z i 1 j 2 δ x where k is the hydraulic conductivity b is the width of the blocks h i j is the piezometric head at block i j z i j is the elevation of the bedrock at block i j and δ x is the centroid to centroid distance of the two blocks being connected the water supply well is explicitly considered a block the flow rate from the unconfined aquifer cell to the water supply well is computed as follows mays 2010 3 q π h i j z w h i j h w log 2 δ r d w where z w is the bottom elevation of the well h w is the hydraulic head in the well δ r is the average distance from the aquifer cell to the center of the well which is approximated as a i j 4 a i j is the area of the aquifer cell and d w is the diameter of the well the characteristic curve of the pump withdrawing water from the well is expressed as 4 h p m 43 1 0 4 q 2 where q is the flow in m 3 day fig 5b shows the aquifer recharge rate per unit area during the simulation period the storage tank is assumed to be at an elevation of 20 m and has a base area of 100 m 2 note that if the rate of outflow exceeds the inflow rate for a specific node over an extended period the storage in that node can approach zero for example the withdrawal rate from the well can exceed the inflow rate from the aquifer under such circumstances the dry block condition becomes active and the outflow from the node is limited according to the algorithm described in appendix a 1 the water consumption rate by all users is assumed to be the same and has daily and seasonal variations as shown in fig 5a the elevations of the nodes of the water network and the properties of the pipes are provided in table s1 in the supplementary materials we used the hazen williams equation mays 2010 to calculate the head loss flow relationship in the pipes the hazen williams coefficient is assumed to be 100 for all the pipes fig 6 shows the results of the simulation panel a shows the storage volume in the water tower tank please note that at some times during the simulation the tank remains empty because the overall consumption is higher than the rate at which water can be pumped to the tank panel b shows the hydraulic head at node 1 as an example note that the elevation of node 1 is 15 m and when the hydraulic head falls below that value the user will not receive the designated demand as shown in panel f panel c shows the hydraulic head at the central grid cell of the aquifer panel d shows the flow through the pump from the well to the tower tank panel e shows the hydraulic head in the tank note that the water storage in the well becomes zero at some times during the simulation because the maximum pumping rate based on the pump characteristic curve exceeds the flow rate from the aquifer to the well panel f depicts the actual consumption by the user at node 1 the actual consumption is at times less than the designated flow because of the lack of water availability in the storage tank 4 2 demonstration ii bioretention system this example represents four bioretention systems receiving runoff from four impervious surface areas we model the rainfall runoff process over the catchments diverting their runoff to the bioretention cells each bioretention cell comprises a surface ponding component engineered soil and an aggregate storage layer underneath the engineered soil an underdrain pipe collects the water from the aggregate layer and diverts it to a catch basin a riser is considered in the catch basin to increase the internal storage we also model exfiltration into the native soil down to the groundwater the native soil underneath each of the bioretention cells is discretized into four layers van genuchten equations are used to compute the infiltration fluxes between the soil layers van genuchten 1980 fig manning s equation is used to model the flow rate exiting each impervious sub catchment 5 q o u t w s 0 1 2 n d d 0 5 3 where w is the effective width of the impervious catchment s 0 is the mean slope along the flow direction n is manning s roughness coefficient d is the mean water depth over the catchment and d 0 is the depression storage zhang et al 2020 fig 7 shows the configuration of the system and the conceptualization of each bioretention cell the values of all model parameters are provided in table s2 in the supplementary materials a catch basin is considered to receive underdrain and overflow water from each bioretention cell and direct it to another catch basin on the main sewer line for the sake of simplicity all bioretention cells are assumed to be identical except for their elevations the evapotranspiration from the engineered soil is computed using the penman model penman 1948 precipitation relative humidity solar radiation wind speed and temperature data were taken from the baltimore washington airport station https www weather gov lwx for the simulation period 2010 2013 a correction factor of 0 1 is applied to the evaporation rate to account for the shading effect all the weather time series data and the model file are available at https github com arashmassoudieh openhydroqual tree master examples bioretention fig 8a shows the precipitation data used in the model the data represent precipitation during the years 2010 2013 from the baltimore washington airport station fig 8b shows the evapotranspiration rate from an individual bioretention cell throughout the simulation period panel c of fig 8 shows the underdrain flow rate from a single bioretention cell panel d shows the groundwater recharge rate from a single bioretention cell and panel e shows the total outflow into the main sewer system 4 3 demonstration iii biogeochemical processes in the overlying water and sediments in a stormwater wet pond in this example we demonstrate a case in which the reactive transport feature of openhydroqual is used to model the water quality processes in a wet pond the properties of the wet pond system are adopted from comings et al 2000 fig 9 a shows how the wet pond is discretized into six smaller compartments each modeled as a continuously stirred tank reactor each compartment is modeled based on a storage depth relationship of the form s α d 2 0 where α is calculated so that the surface area becomes equal to the values shown in fig 9 a with the depths indicated in the figure the flows between the compartments are calculated using manning s equation assuming a wide channel 6 q 1 n m h i h i 1 δ x b d 5 3 where n m is manning s roughness coefficient h i and h i 1 are the hydraulic heads water level at the two adjacent compartments w is the width of the channel at the contact section and d is the average water depth of the two compartments being connected all the physical parameters used are provided in table s3 in the supplementary materials we are looking to consider the biogeochemical processes in the active bed sediment and the impacts of sediment water exchange therefore active bed sediment compartments with depths of 10 cm are included at the bottom of each pond compartment advective and diffusive processes are considered to exchange dissolved chemicals between the overlying water and the bed sediments 7 j d e c o c s where j d is the diffusive flux between overlying water and the sediments c o is the concentration in the overlying water and c s is the pore water concentration in the sediments the bed sediments are connected to a groundwater compartment with a fixed hydraulic head to model loss due to exfiltration fig 9 b shows the conceptualization of the system fig 10 shows the inflow rate and the loading of dissolved organic matter dom nitrate no 3 1 and ammonia ammonium nh 3 into the pond through the inflow the concentration of dissolved oxygen do in the inflow is assumed to be constant and equal to 8 5 mg l throughout the simulation period the species are assumed to undergo reactions as summarized in table 1 in the overlying water and the bed sediments four chemical species dom no 3 1 nh 3 nh 4 and d o are considered in the model a diffusion coefficient of 0 0017 m 2 s through the sediment water interface is considered for all species it is assumed that the dom is released as a result of the hydrolysis of solid organic matter in the sediments at a constant rate of 16 g m 3 day a rate limited aeration mass exchange rate m o k l o a s d o s d o is considered for modeling the oxygen transfer through the surface of the pond where a s is the surface area of the ponds which is variable with time and k l o l t is the transfer coefficient the values of the reaction parameters are provided in table s4 in the supplementary materials fig 11 shows the temporal variation of the concentrations of all the species in the overlying water and the sediments of the last compartment compartment six of the wet pond system as seen in this case ammonia and nitrate concentrations in the sediments and the overlying water tend to increase during periods with no inflow this indicates that the inflow water acts as a diluting factor compared to the dom release from the underlying sediments additionally the do concentration in the sediments is not low enough compared to the half saturation parameter k n o of 1 4 mg l to result in significant denitrification it is worth noting that the inflow and loading into the system can be obtained from other modeling tools by converting the outputs of those models to the format needed by openhydroqual 4 4 demonstration iv a storm sewershed infiltration basin dry well system this example is based on a dry well installed in fort irvine california in 2016 reference the system to be modeled contains a watershed that is discretized into 13 smaller sub watersheds the sewer network an infiltration pond a dry well and the soil media surrounding the dry well fig 12a because the soil in the area mainly consists of sandy soil we do not expect runoff to be generated on previous areas of the watershed so only the impervious areas are considered in the model three main storm sewer pipes carry the stormwater to the infiltration basin the impervious areas of the sub catchments and lengths of the segments of the storm sewer pipes are provided in table s6 in the supplementary materials the stage volume relationship in the infiltration pond is s 86 061 h 2 766 an overflow weir allows the water in the infiltration basin to overflow into the conventional sewer system the head flow relationship for overflow through the v notch weir to the conventional sewer is q m 3 s 4 5442 h z 0 2 995 where z 0 is the crest elevation of the outflow weir which in this case is 1 60 m above the lowest elevation of the infiltration pond the depth of the dry well is 42 95 m and the depth to the groundwater table is 70 28 m the soil underneath the infiltration basin is modeled as a two dimensional vertical system consisting of 13 layers the unsaturated zone comprises five distinct stratigraphic layers in terms of hydraulic properties fig 12b the van genuchten soil retention parameters considered for each layer are provided in table s5 in the supplementary materials the soil is non uniformly discretized into 10 rings radially so that the radial increments of the rings grow by a factor of 1 2 moving from the center outward this means that the radial increment of the outer most ring is approximately 5 16 times larger than the inner most ring the reason for the non linear discretization is that it was deemed more important to capture the flow dynamics near the well than farther away from it the groundwater table is modeled as a fixed head boundary condition the evapotranspiration from the topsoil layer of the pond was modeled using the penman model penman 1948 the precipitation and the historical weather data needed to compute evaporation during the simulation period january 1 2018 to december 30 2020 were adopted from the los angeles international airport lax weather station because the precipitation at the fort irvine site was sparse all the weather time series data and the model file are available at https github com arashmassoudieh openhydroqual tree master examples drywell the build up wash off and transport of a hypothetical pollutant are also modeled the pollutant is assumed to build up on the surfaces of the catchment at a rate of 0 01 g day m 2 the wash off rate during the rain events is assumed according to the following equation 8 r 1 157 1 0 5 h 2 c s where r g m 2 s is the release rate h is the average sheet flow depth over the catchment and c s g m 2 is the surface deposited contaminant concentration since manning s equation is used to calculate the flow velocity over the catchments this equation implicitly relates the release rate to the overland flow velocity through a power equation massoudieh et al 2008 for the sake of simplicity the pollutant is assumed to be conservative and not to interact with solid surfaces after being mobilized from the surface additionally only advective transport of the pollutant is taken into account and molecular diffusion in surface water and soil is ignored fig 13a shows simulation results for the inflow from the south and north sewer pipes and the overflow through the weir into the conventional sewer system over a one year period from june 2018 to may 2019 fig 13a shows the water depth in the well and the pond during the entire simulation period from 2018 to 2021 fig 14 shows the deposited concentration of the hypothetical pollutant on the sub catchment surfaces the concentration of dissolved pollutants in the well and the cumulative mass loading into the groundwater the impact of the first flush can be seen in the changes in concentration in the well during rain events such a model can be used to evaluate the effectiveness of dry wells as a means for stormwater management and groundwater recharge and the potential contamination risks they may pose to groundwater coupling the rainfall runoff and sewer processes with the soil processes allows dynamic evaluation of the impacts of practices such as dry wells at the watershed scale a more complex version of the model could be used to evaluate pre treatment impacts interactions with solid particles including suspended solids and soil and degradation reactions 5 discussion and conclusions an open source extensible framework for constructing flow and water quality models of natural and engineered water systems is proposed this framework structure is versatile using plugins that are programmed outside of the main code or can be provided through dynamic libraries thus allowing for the implementation of a one water integrated watershed openhydroqual is a good candidate for constructing models of systems for which a single off the shelf application is not adequate or when the user desires to formulate the problem in a different way than those applications are based on since the framework is agnostic and can accommodate external non native software it can be potentially used by owners cities utilities watershed managers and regulators as a veritable operating system for hosting native and external watershed models this framework uses a generic solver to solve the diverse range of governing equations resulting from the diverse components it can accommodate through plugins openhydroqual can be used for building models of water systems involving heterogeneous components in which various domains governed by different equations need to work in a coupled way openhydroqual adapts the agile software programming approach to expand the software through plugins defining new components representing media types interfaces between media blocks chemical constituents mass transfer and reaction processes and external forcing including sources and sinks of water and chemicals the extensibility automatic parameter estimation feature open source and platform independence and the availability of the console version of openhydroqual make it a suitable candidate to be used in cloud based platforms for example for digital twin applications the framework can include behavioral tools to encourage participation and collaboration and evaluate policies effect on the outcomes this framework is a cradle for additional layers of implementation for example the use of live sensors can convert the proposed modeling framework to an active interactive digital twin the next steps are to explore some of these approaches through real world calibration and validation exercises the plugin approach allows third party developers to extend or customize the application to construct models comprised of components that may not be available in most off the shelf software applications such problems are expected to arise as a shift towards a one water paradigm occurs openhydroqual is also a suitable tool for hypothesis testing when the user needs to have the flexibility to implement and test novel governing equations to describe the behavior of a system four demonstration applications are outlined the examples were selected to show how the tool can accommodate various system features governed by different equations and over various scales from the lab or a single unit process scale to the watershed scale it should be noted that openhydroqual is designed to mainly solve equations arising from balance principles applied to scalar quantities so using it to solve equations involving the conservation of vector quantities e g conservation of momentum may be challenging in the plugin approach utilized the main code acts as an interpreter of the governing equations provided in the plugins this might adversely affect the simulation speed the speed of the simulation is particularly important when openhydroqual is implemented to describe distributed system by configuring the blocks as a two or three dimensional grid an alternative approach is to compile the plugins into dynamic link libraries dlls where equations are hard coded the dll approach improves the speed of the simulation at the cost of adding to the steps needed to extend the program by users because they need to perform a compilation step declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the model platform was partly funded by national science foundation sbir seed fund usa grant 2152000 in part for the overall development of a watershed digital twin cloud platform appendix a numerical algorithm a fully implicit newton raphson nr method with adaptive time step is used to solve eq 1 the adaptive time step ensures the stability and performance of the code the discretized form of eq 1 for a generic block i can be written as follows a 1 υ i w t δ t w i t δ t w i t δ t j q i j w i t δ t w j t δ t k u i k w i t δ t 0 where υ i is the residual associated with block i which needs to approach zero through an iterative process and w is the vector of state variables at time t δ t please note that w represents the total amount of our state variable which can be the amount of water the mass of a chemical constituent or any other state variable and q i j represents the total flow mass rate flowing from block i to block j for the sake of simplicity the dependence of q i j on w i and w j through the derived variable r and the dependence on the parameters is not written explicitly in the equation but is implicit using the nr algorithm the new value of w t δ t is found by iterating through the following equation a 2 w t δ t w t δ t j 1 ϒ w t δ t where j is the jacobian matrix of ϒ with respect to w the value of the diagonal elements of the jacobian matrix can be computed on eq a 1 as follows a 3 j i i 1 δ t j q i j w i w i w j u i k w i w i where q i j w i w i w j and u i k w i w i w j are the derivatives of flow rate and source terms with respect to the state variable w i a 4 q i j w i w i w j d d w i q i j w i w j u i k w i w i w j d d w i u i k w i please note that q can depend on w indirectly through a set of derived variables r in openhydroqual the derivatives are evaluated numerically for each link the value of non diagonal elements of the jacobian matrix for the cases where blocks i and j are connected through a link is calculated as follows a 5 j i j j q i j w j w i w j please note that because a jacobian matrix approximated based on the values of the state variables at several time steps before the current time step can still be a good approximation of the jacobian matrix for the current values of the state variables the jacobian matrix does not need to be updated for each iteration or even for every time step this in fact can improve the computational efficiency of the numerical method because the calculation of the jacobian matrix can be costly massoudieh et al 2017 openhydroqual decides on when to update the jacobian matrix based on the number of iterations needed for the nr method to converge a 1 treating dry blocks a challenge in the control volume approach when the equations governing the flow from one block to another are non constrained is that the storage or the amount of the state variable in the blocks can become negative which is not physically possible this occurs when q i j w i w j is non zero at w i 0 to numerically handle the cases when a block becomes dry when the value of a state variable at a cell becomes negative at the end of an nr iteration cycle the numerical algorithm assumes that all the outflows and sinks from the block are reduced by a factor β i then the system is solved by considering β as one of the unknowns to be solved so the balance equation for the block with its state variable becoming negative is modified to the following a 6 υ i w t δ t w i t δ t β i j max q i j w i t δ t w j t δ t 0 j min q i j w i t δ t w j t δ t 0 β i k min u i k w i t δ t 0 max u i k w i t δ t 0 0 the diagonal member of the jacobian matrix will now be a 7 j i i d υ i w t δ t d β i j max q i j w i t δ t w j t δ t 0 k min u i k w i t δ t 0 and the non diagonal elements of the jacobian matrix for blocks connected to block i will be a 8 j i j d υ i w t δ t d w j β i j q i j w j w i w j h q i j w i w j j q i j w j w i w j h q i j w i w j β i k u i k w j w i t δ t h u i k w i t δ t k u i k w j w i t δ t h u i k w i t δ t where h is the heaviside function for a receiving block i e block j the jacobian matrix element j j i needs to be modified accordingly as a 9 j j i min q j i w j t δ t w i t δ t 0 for the block undergoing dryness the state variable w i is replaced by β i as the unknown and the system of non linear equations is solved diagonal element j j of the jacobian matrix for the members connected to dry cells should also be modified by multiplying the term representing the link between j and i by β in eq a 3 the block is kept dry until the computed β i is greater than one which indicates that the block is wet after that point the block is treated as a regular non dry block the computational time step is adjusted based on the number of iterations needed for the solution to converge or whether convergence occurs two parameters n r max and n r min are specified the time step is reduced by a factor when the number of nr iterations needed exceeds n r min and is increased when the number of iterations required falls below n r min the time step value is also reduced by a larger factor when convergence does not occur appendix b supplementary data supplementary material related to this article can be found online at https doi org 10 1016 j envsoft 2023 105707 appendix b supplementary data the following is the supplementary material related to this article mmc s1 the values of parameters used in the four demonstration cases 
25410,sub disciplines of the water sector are fractured into specialty domains so the underlying modeling tools for flow and water quality are designed based on a pre determined set of equations however many problems involve interactions between multiple domains in an integrated one water approach the opportunity to integrate the different sets of equations is fundamental to the shift towards evaluating environmental issues more holistically this paper describes an extensible modeling framework for defining and adding user defined model components using plugins the plugin approach allows the available model components and the processes to adapt to the user s specific needs and objectives the focus of this paper is to describe the philosophy of developing the open extendable framework and to present the data structure used to describe model components their properties and the equations used for computing state and derived variables in the end four examples of the framework s multi domain capability are provided keywords agile software extensible framework plugin add in modeling framework water system model data availability all the data and codes have been made available on github 1 software availability software name openhydroqual year first available 2019 operating system windows mac os or linux operating system availability the installation package for the gui version of openhydroqual is available at https www openhydroqual com free user registration required source openhydroqual code can be accessed through the github repository https github com arashmassoudieh openhydroqual cost free license openhydroqual is released under a gnu general public license version 2 june 1991 https www gnu org licenses oldlicenses gpl 2 0 en html examples the data and model files of all the demonstration examples presented in this paper can be found at https github com arashmassoudieh openhydroqual tree master examples more instructional examples can be found on the youtube channel https www youtube com channel ucj3b55fpmnaam3b5besdhmg or the program website https openhydroqual com knowledge base 2 introduction environmental models play an essential role in predicting and simulating the nature of natural and engineered environmental systems evaluating the impact of various design operation and management decisions and extracting transferable knowledge from site specific data among other functions tools developed for modeling environmental systems in general and water systems in particular often focus on a single domain with a uniform set of governing equations applied to the entire domain examples include modeling frameworks developed to construct models of flow and reactive transport in groundwater systems flow in unsaturated soil pressurized flow in pipe networks hydraulics in open channels water distribution networks water quality in surface water bodies hydrologic modeling of watersheds urban stormwater management and stormwater control measures however many problems related to natural or engineered water systems involving flow mass transfer or aquatic ecology particularly when natural systems are affected by engineering infrastructure require considering interactions between multiple domains each governed by different sets of processes models and governing equations the application of disjoint domain specific models limits our ability to obtain a holistic view of systems by considering the interactions between different domains bulatewicz et al 2013 for example the interactions between overland flow streams soil and groundwater processes in modeling flow and transport in a watershed are likely affected by water divergence for agricultural industrial use or public supply yang et al 2009 ficklin et al 2013 essaid and caldwell 2017 sophocleous and perkins 2000 integrated urban water management consisting of pipe networks storage units pumps and treatment plants mitchell 2006 pikaar et al 2014 and modeling flow and transport processes for stormwater management involving runoff generation conveyance networks various types of stormwater control measures involving soil percolation and groundwater surface water interactions thomas and vogel 2012 naeimi and safavi 2019 kim et al 2019 coupling two or more computational tools each made for a different domain has been widely utilized to solve multi domain environmental problems either manually or through interfaces bailey et al 2016 aliyari et al 2019 zhang and chui 2020 baek et al 2020 de keyser et al 2010 kidmose et al 2015 however coupling multiple model engines developed with different programming languages and different spatial and temporal discretization is not always a straightforward task it does not result in the best computational efficiency especially when two way or multiple way coupling of the processes in different domains is required coupling various models through file exchange or internal computer memory can be highly time consuming and labor intensive kneis 2015 rode et al 2010 bruggeman and bolding 2014 sophocleous and perkins 2000 one typical problem is when models of large scale natural systems for example at the watershed scale are to be coupled with manual or automatic human controlled processes such as water withdrawal water supply wells or best management practices due to the differences between the spatial and temporal scales varga et al 2016 the recent attempts to develop digital twins for water systems involving a diverse array of components increase the need for the existence of agile modeling tools that can accommodate new components and can be extended and added to the model in a plug and play fashion furthermore modeling is sometimes used to study specific aspects of a system or test a hypothesis requiring the inclusion of particular processes or incremental changes of process representation using customized physically based or empirical relationships to address this need modeling frameworks should allow users to alter the governing equations or add their hypothesized processes to their models mendoza et al 2015 clark et al 2011 hamilton et al 2022 fenicia et al 2008 as our understanding of the mechanisms affecting the working of natural and engineered systems advances there is a need to revise modeling frameworks to be able to add new processes seamlessly or alter existing ones mendoza et al 2015 clark et al 2011 david et al 2013 argues that modeling frameworks should promote users creativity to construct new models without them having to get involved in the software engineering aspects of the modeling frameworks this fosters creativity by not constraining the modeler to the developer s view of the processes in other words the underlying conceptual model of the physical system should not be intertwined with the framework and instead it must exist outside the framework to allow continuous development these points highlight the importance of developing modeling frameworks that provide maximum agility flexibility and transparency to adapt to a wide range of target problems one way to achieve this is to avoid hard coding the model governing equations to the greatest extent possible allowing users to effortlessly inspect and alter the governing equations used to describe various components of a model without needing to recompile the code the plugin based or open architecture approach in which a user can develop and add a feature to a software application has been widely adopted in many areas of software engineering dunfey et al 2006 schindelin et al 2015 rueden et al 2017 the key idea behind plugin architecture in software engineering is to isolate the program s core from its features allowing the addition of features with ideally no change to the core plugins provide extensibility flexibility and transparency and also can facilitate collaboration this approach can be adopted in the case of models used for water systems by enabling the definition of various components e g surface water soil pipes water wells plants using plugins the governing equations describing flow and transport in each component will all be included in the plugins trolle et al 2012 pointed out that to achieve flexibility in a modeling framework biogeochemical and ecological modules should not restrict the dimensionality and structure of their modeled environments the block link representation of the modeled environment allows the modeling domain to be configured as an interconnected set of various domains each represented by appropriate governing equations and discretized according to need and with the desired dimensionality the plugin approach has been widely adopted in many areas of software engineering such as in web browsers remote sensing and image processing applications gis applications email clients and text editors e g duarte and teodoro 2021 nielsen et al 2021 the plugin approach minimizes hard coding keeps the computational engine lightweight allows third party expansion and reduces the size of an application by not loading unused features the plugin approach keeps the numerical solution algorithm separate from individual processes allowing standalone testing of individual processes by keeping the computational engine generic debugging and optimizing the program core becomes more manageable and can be done independently of the individual components the plugin approach allows the evolution and expansion of the framework to rely on a community of users ahalt et al 2014 beck et al 2001 and by supporting freedom of choice for a modeler the requirements for the modeling tool need not be fully known at the time of development and can change and expand iteratively and incrementally with a user s community s involvement sydelko et al 2001 proposed an object oriented approach for dynamic ecosystem modeling based on a dynamic information architecture system dias that can use external models to represent various aspects of the system zhang et al 2016 extended a lumped parameter hydrological model to include crop growth soil biochemical processes soil erosion water quality and dam regulations zeng et al 2020 made steps towards achieving an extensible modeling framework for watershed management by developing an interface oriented add in modeling framework that used dynamic link libraries dlls for adding new processors encapsulating modules to their modeling tool for watershed management they used topological sorting of the water system network to determine the information flow from components to others this paper describes a new open source plugin based extensible and flexible modeling framework for modeling automatic parameter estimation and optimizing aquatic systems the modeling framework can be used in developing models of a wide range of water related problems ranging from water supply networks stormwater watershed modeling surface water groundwater stream interactions water quality and many more as well as problems consisting of a combination of two or more of these domains interacting in a coupled way the modeling framework has the following characteristics models are constructed based on the object oriented design as a network of blocks in which the balance of material is done and links through which the exchange of materials occurs all the components and the governing equations defining their processes are introduced as plugins that are completely separate from the computational engine as text files all the plugins are readable and modifiable by users users can also add their own components by developing new plugins all the components of the modeling framework are offered as ascii text files and thus the governing equations are fully transparent the modeling framework can be used either in the graphical user interface gui form or by including the engine as a library into another code a console version of the program is also available the numerical solution algorithm is generic and completely independent of the processes to be considered in the model it can solve balance equations for any state variable as long as the relationships between exchange rates and state variables are provided the program has features for optimization and auto calibration based on measured data auto calibration can be done deterministically based on the maximum likelihood approach using a hybrid genetic algorithm or probabilistically using the markov chain monte carlo mcmc method 3 inner workings water flow energy dynamics and chemical fate and transport in any zero one two or three dimensional model can be modeled effectively by representing the domain as a set of elements blocks exchanging water mass or energy through interfaces links that connect the blocks to each other given that the relationships between the state variables inside the blocks and the rate of exchange between the blocks are known either directly or indirectly through some intermediate derived variables this formulation will result in a system of non linear ordinary differential equations that can be solved for state variables any balance equations for water mass or energy in a water system can be described in the following generic form 1 d w i d t j q i j r i w i θ i r j w j θ j θ i j k u i k r i w i where w i is the total amount of a generic state variable in block i and q i j q j i is the transfer rate from blocks i to block j the exchange rate q i j is a generic function of a set of derived quantities of blocks i and j noted by r i and r j specifically which is ultimately a function of the state variables w i and w j a set of properties or parameters associated with the blocks i and j noted by θ i and θ j respectively and a set of properties of the link indicated by θ i j u i k indicates the external forcing or source sinks affecting state variable w in block i for example when computing the water flux from one unsaturated soil layer to another w is the total amount of water in a block q is the flow rate from one block to another which is a function of the derived quantity hydraulic head r in each of the blocks this in turn depends on the amount of water in the blocks we can similarly use this generic form to represent the balance of the mass of chemicals undergoing reactions energy heat etc the computational engine of openhydroqual can solve equations presented in the form of eq 1 using an implicit newton raphson method with an adaptive time step and partial jacobian updating massoudieh et al 2017 the details of the numerical method are provided in appendix a in openhydroqual the building blocks of a model include blocks links sources chemical constituents reactions parameters objective functions and observed data all of these components inherit from a single class called object each object has a series of properties hereafter referred to as quantities each quantity can have one of the following identities the quantities can be constants strings state variables expressions time series data sources or rules constants represent some physical properties of the objects expressions are quantities that their values are derived based on other properties currently functions including min max exp log abs sign square root heaviside function and two kernel smoothing functions based on gaussian and exponential kernels for time series data can be used in the expressions additional functions can easily be added as the need arises variables that get their values from the outputs of source objects rules are like expressions but they allow if then conditionals all classes defining the components can be introduced by the user in a plugin file written in json format crockford 2012 fig 2 provides a simple example of the textual modeling language for a block object representing a reservoir as a demonstration for more details about the structure of plugin files and the meaning of each keyword please see the user s manual available on the program s website 3 1 building blocks of a model to create a model various elements like blocks links sources parameters observations objective functions chemical constituents reactions and reaction parameters are combined these elements inherit from a class named object fig 1 which mainly consists of multiple quantities that can represent constants strings time series data derived quantities or state variables the values of these quantities are determined by solving balance equations each object type such as soil surface runoff or links representing the interfaces between them has its properties specified in external plugin files written in the json data interchange format these external plugin files also contain equations governing the exchange of water energy and material between blocks through links as well as expressions for all derived variables the model allows different groups of object types which are defined in separate json files i e plugins to be added as needed the main code interprets the plugins to a system of ordinary differential equations representing the conservation of the state variables a block is a control volume for which the balance equations are solved while links represent the interface between blocks through which water and material exchange occurs sources are objects that control the influx or outflux of water or material into a block examples of sources include precipitation evapotranspiration external loading of a chemical into a block mass transfer through processes such as aeration or transfer of energy to a block through radiation or heat conduction parameters are quantitative properties of model components whose values can be estimated through optimization or deterministic or probabilistic parameter estimation observations contain information about a measured quantity that is intended to be used for model calibration an observation object contains properties that specify the corresponding model output to the measured quantity and the time series containing the measured data objective functions are objects that specify the target function to be maximized or minimized in the optimization process an objective function contains an expression that determines the dynamic output items to be used for calculating the objective function and how the dynamic quantity is aggregated to determine the final objective function the options are maximum integral variance and specific quantiles of the quantity s frequency distribution in the output dynamically calculated based on the model s outputs reactions are objects that store reaction rate expressions and stoichiometric constants of a reaction affecting one or more constituents the code was written using the c programming language a gui was developed using the qt library which allows the user to import plugins insert model components utilizing a drag and drop approach assign properties to each component run the model and post process the results fig 3 shows a screenshot of the gui the dynamic library for the computational engine is entirely separate from the gui and can be included in other c programs without the gui the stand alone dynamic library allows future seamless incorporation of the modeling framework into web based tools or gis applications or other programs for example for optimal control choi et al 2021 holzworth et al 2010 the library also allows using parts of the computational engine in conjunction with other models or tools for example one can couple the reaction module of openhydroqual with a distributed hydrodynamic or hydrologic model representing a water body the gui is designed to be intuitive model components can be inserted one by one through drag and drop as one or two dimensional arrays of linked blocks or by directly writing an easy to understand script that is then interpreted by the framework a console version of the tool is also available that can be used for batch processing or as a server side application there are currently 17 plugins included in the repository that have components for modeling groundwater flow and transport flow in unsaturated soil pressurized flow in pipe networks open channel and streamflow evapotranspiration urban water management stormwater conveyance stormwater control measures chemical mass transfer and reactions particle transport fluvial processes and some more these plugins are included in the installation package different components coming from various plugins can be used in conjunction for example one may use some components from the groundwater plugin in conjunction with a pump pipe system or stream components defined in other plugins the computational engine first translates the model schema to a system of ordinary differential equations that are then solved using a global implicit method hoffmann et al 2010 as described in appendix a although the main code performs a validation by ensuring the necessary quantities required in each object to establish connections between them exists it is inevitable that a user may define a plugin that is unsolvable or one that is solvable but does not accurately represent the physical processes being modeled two cases representing the validation of the reactive transport feature of the model through comparison with exact solutions are available at https github com arashmassoudieh openhydroqual tree master validation 4 demonstration examples we present four examples to demonstrate openhydroqual s flexible modeling capability the main goal of the examples is to show the versatile capabilities of openhydroqual and encompass domains that are not typically available together in a single modeling framework the systems considered in the examples are not necessarily based on any particular real case but we have made an effort to use realistic parameter values based on the typical values found in the literature the purpose of the four demonstration cases is to show how the framework can be used to construct models comprising a diverse range of components and not to verify whether the governing equations in the plugins used accurately represent the modeled processes when applied to real modeling problems where observed data is available openhydroqual allows for modifying not only the parameter values but also the governing equations used in the plugins iteratively until a good agreement between modeled and measured data is achieved the first demonstration case represents an aquifer system utilized for water supply and the water distribution network the second example illustrates a system consisting of four bioretention systems receiving water from four impervious catchments we modeled the flow in the sewer network connecting the bioretention systems infiltration through the unsaturated soil and groundwater recharge the third example represents a wet pond that is discretized into six compartments the model includes biogeochemical processes affecting organic matter and nitrogen species in the overlying water and active sediments the model considers evaporation and infiltration into the underlying soil the fourth example shows an urbanized watershed with runoff entering an infiltration basin with a dry well we model runoff generation and conveyance through the sewer network ponding and then exfiltration through the dry well and also the build up wash off and transport of a hypothetical pollutant in the system for the sake of brevity some of the details of the models are provided in the supplementary information due to the large number of components used in the four examples provided it is not possible to present the governing equations controlling each and every component however all the governing equations considered in all the plugins used in the examples as well as other plugins delivered with the installation package by default can be found at https github com arashmassoudieh openhydroqual tree master resources 4 1 demonstration i modeling a coupled water distribution network with an unconfined groundwater system this example consists of an unconfined aquifer system used as the water supply to a small water distribution network a pump withdraws water from a water supply well and sends the water to an elevated water tank the storage tank is connected to a water distribution network the diagram of the system that has been modeled is shown in fig 4 the unconfined groundwater system is modeled as a 1000 m 1000 m square domain which is discretized into a 5 5 grid the water well is in the center point of the domain the bedrock or aquifer base is assumed to be 20 m below the ground surface and the initial groundwater table is 7 m below the ground surface a fixed head boundary condition at an elevation of 7 m below the ground surface is assumed for all four boundaries around the domain the hydraulic conductivity and the specific yield for the aquifer are considered to be 1 8 m day and 0 3 respectively the flow rate from each aquifer block to an adjacent one is calculated based on darcy s law 2 q k b h i j h i 1 j h i j h i 1 j z i j z i 1 j 2 δ x where k is the hydraulic conductivity b is the width of the blocks h i j is the piezometric head at block i j z i j is the elevation of the bedrock at block i j and δ x is the centroid to centroid distance of the two blocks being connected the water supply well is explicitly considered a block the flow rate from the unconfined aquifer cell to the water supply well is computed as follows mays 2010 3 q π h i j z w h i j h w log 2 δ r d w where z w is the bottom elevation of the well h w is the hydraulic head in the well δ r is the average distance from the aquifer cell to the center of the well which is approximated as a i j 4 a i j is the area of the aquifer cell and d w is the diameter of the well the characteristic curve of the pump withdrawing water from the well is expressed as 4 h p m 43 1 0 4 q 2 where q is the flow in m 3 day fig 5b shows the aquifer recharge rate per unit area during the simulation period the storage tank is assumed to be at an elevation of 20 m and has a base area of 100 m 2 note that if the rate of outflow exceeds the inflow rate for a specific node over an extended period the storage in that node can approach zero for example the withdrawal rate from the well can exceed the inflow rate from the aquifer under such circumstances the dry block condition becomes active and the outflow from the node is limited according to the algorithm described in appendix a 1 the water consumption rate by all users is assumed to be the same and has daily and seasonal variations as shown in fig 5a the elevations of the nodes of the water network and the properties of the pipes are provided in table s1 in the supplementary materials we used the hazen williams equation mays 2010 to calculate the head loss flow relationship in the pipes the hazen williams coefficient is assumed to be 100 for all the pipes fig 6 shows the results of the simulation panel a shows the storage volume in the water tower tank please note that at some times during the simulation the tank remains empty because the overall consumption is higher than the rate at which water can be pumped to the tank panel b shows the hydraulic head at node 1 as an example note that the elevation of node 1 is 15 m and when the hydraulic head falls below that value the user will not receive the designated demand as shown in panel f panel c shows the hydraulic head at the central grid cell of the aquifer panel d shows the flow through the pump from the well to the tower tank panel e shows the hydraulic head in the tank note that the water storage in the well becomes zero at some times during the simulation because the maximum pumping rate based on the pump characteristic curve exceeds the flow rate from the aquifer to the well panel f depicts the actual consumption by the user at node 1 the actual consumption is at times less than the designated flow because of the lack of water availability in the storage tank 4 2 demonstration ii bioretention system this example represents four bioretention systems receiving runoff from four impervious surface areas we model the rainfall runoff process over the catchments diverting their runoff to the bioretention cells each bioretention cell comprises a surface ponding component engineered soil and an aggregate storage layer underneath the engineered soil an underdrain pipe collects the water from the aggregate layer and diverts it to a catch basin a riser is considered in the catch basin to increase the internal storage we also model exfiltration into the native soil down to the groundwater the native soil underneath each of the bioretention cells is discretized into four layers van genuchten equations are used to compute the infiltration fluxes between the soil layers van genuchten 1980 fig manning s equation is used to model the flow rate exiting each impervious sub catchment 5 q o u t w s 0 1 2 n d d 0 5 3 where w is the effective width of the impervious catchment s 0 is the mean slope along the flow direction n is manning s roughness coefficient d is the mean water depth over the catchment and d 0 is the depression storage zhang et al 2020 fig 7 shows the configuration of the system and the conceptualization of each bioretention cell the values of all model parameters are provided in table s2 in the supplementary materials a catch basin is considered to receive underdrain and overflow water from each bioretention cell and direct it to another catch basin on the main sewer line for the sake of simplicity all bioretention cells are assumed to be identical except for their elevations the evapotranspiration from the engineered soil is computed using the penman model penman 1948 precipitation relative humidity solar radiation wind speed and temperature data were taken from the baltimore washington airport station https www weather gov lwx for the simulation period 2010 2013 a correction factor of 0 1 is applied to the evaporation rate to account for the shading effect all the weather time series data and the model file are available at https github com arashmassoudieh openhydroqual tree master examples bioretention fig 8a shows the precipitation data used in the model the data represent precipitation during the years 2010 2013 from the baltimore washington airport station fig 8b shows the evapotranspiration rate from an individual bioretention cell throughout the simulation period panel c of fig 8 shows the underdrain flow rate from a single bioretention cell panel d shows the groundwater recharge rate from a single bioretention cell and panel e shows the total outflow into the main sewer system 4 3 demonstration iii biogeochemical processes in the overlying water and sediments in a stormwater wet pond in this example we demonstrate a case in which the reactive transport feature of openhydroqual is used to model the water quality processes in a wet pond the properties of the wet pond system are adopted from comings et al 2000 fig 9 a shows how the wet pond is discretized into six smaller compartments each modeled as a continuously stirred tank reactor each compartment is modeled based on a storage depth relationship of the form s α d 2 0 where α is calculated so that the surface area becomes equal to the values shown in fig 9 a with the depths indicated in the figure the flows between the compartments are calculated using manning s equation assuming a wide channel 6 q 1 n m h i h i 1 δ x b d 5 3 where n m is manning s roughness coefficient h i and h i 1 are the hydraulic heads water level at the two adjacent compartments w is the width of the channel at the contact section and d is the average water depth of the two compartments being connected all the physical parameters used are provided in table s3 in the supplementary materials we are looking to consider the biogeochemical processes in the active bed sediment and the impacts of sediment water exchange therefore active bed sediment compartments with depths of 10 cm are included at the bottom of each pond compartment advective and diffusive processes are considered to exchange dissolved chemicals between the overlying water and the bed sediments 7 j d e c o c s where j d is the diffusive flux between overlying water and the sediments c o is the concentration in the overlying water and c s is the pore water concentration in the sediments the bed sediments are connected to a groundwater compartment with a fixed hydraulic head to model loss due to exfiltration fig 9 b shows the conceptualization of the system fig 10 shows the inflow rate and the loading of dissolved organic matter dom nitrate no 3 1 and ammonia ammonium nh 3 into the pond through the inflow the concentration of dissolved oxygen do in the inflow is assumed to be constant and equal to 8 5 mg l throughout the simulation period the species are assumed to undergo reactions as summarized in table 1 in the overlying water and the bed sediments four chemical species dom no 3 1 nh 3 nh 4 and d o are considered in the model a diffusion coefficient of 0 0017 m 2 s through the sediment water interface is considered for all species it is assumed that the dom is released as a result of the hydrolysis of solid organic matter in the sediments at a constant rate of 16 g m 3 day a rate limited aeration mass exchange rate m o k l o a s d o s d o is considered for modeling the oxygen transfer through the surface of the pond where a s is the surface area of the ponds which is variable with time and k l o l t is the transfer coefficient the values of the reaction parameters are provided in table s4 in the supplementary materials fig 11 shows the temporal variation of the concentrations of all the species in the overlying water and the sediments of the last compartment compartment six of the wet pond system as seen in this case ammonia and nitrate concentrations in the sediments and the overlying water tend to increase during periods with no inflow this indicates that the inflow water acts as a diluting factor compared to the dom release from the underlying sediments additionally the do concentration in the sediments is not low enough compared to the half saturation parameter k n o of 1 4 mg l to result in significant denitrification it is worth noting that the inflow and loading into the system can be obtained from other modeling tools by converting the outputs of those models to the format needed by openhydroqual 4 4 demonstration iv a storm sewershed infiltration basin dry well system this example is based on a dry well installed in fort irvine california in 2016 reference the system to be modeled contains a watershed that is discretized into 13 smaller sub watersheds the sewer network an infiltration pond a dry well and the soil media surrounding the dry well fig 12a because the soil in the area mainly consists of sandy soil we do not expect runoff to be generated on previous areas of the watershed so only the impervious areas are considered in the model three main storm sewer pipes carry the stormwater to the infiltration basin the impervious areas of the sub catchments and lengths of the segments of the storm sewer pipes are provided in table s6 in the supplementary materials the stage volume relationship in the infiltration pond is s 86 061 h 2 766 an overflow weir allows the water in the infiltration basin to overflow into the conventional sewer system the head flow relationship for overflow through the v notch weir to the conventional sewer is q m 3 s 4 5442 h z 0 2 995 where z 0 is the crest elevation of the outflow weir which in this case is 1 60 m above the lowest elevation of the infiltration pond the depth of the dry well is 42 95 m and the depth to the groundwater table is 70 28 m the soil underneath the infiltration basin is modeled as a two dimensional vertical system consisting of 13 layers the unsaturated zone comprises five distinct stratigraphic layers in terms of hydraulic properties fig 12b the van genuchten soil retention parameters considered for each layer are provided in table s5 in the supplementary materials the soil is non uniformly discretized into 10 rings radially so that the radial increments of the rings grow by a factor of 1 2 moving from the center outward this means that the radial increment of the outer most ring is approximately 5 16 times larger than the inner most ring the reason for the non linear discretization is that it was deemed more important to capture the flow dynamics near the well than farther away from it the groundwater table is modeled as a fixed head boundary condition the evapotranspiration from the topsoil layer of the pond was modeled using the penman model penman 1948 the precipitation and the historical weather data needed to compute evaporation during the simulation period january 1 2018 to december 30 2020 were adopted from the los angeles international airport lax weather station because the precipitation at the fort irvine site was sparse all the weather time series data and the model file are available at https github com arashmassoudieh openhydroqual tree master examples drywell the build up wash off and transport of a hypothetical pollutant are also modeled the pollutant is assumed to build up on the surfaces of the catchment at a rate of 0 01 g day m 2 the wash off rate during the rain events is assumed according to the following equation 8 r 1 157 1 0 5 h 2 c s where r g m 2 s is the release rate h is the average sheet flow depth over the catchment and c s g m 2 is the surface deposited contaminant concentration since manning s equation is used to calculate the flow velocity over the catchments this equation implicitly relates the release rate to the overland flow velocity through a power equation massoudieh et al 2008 for the sake of simplicity the pollutant is assumed to be conservative and not to interact with solid surfaces after being mobilized from the surface additionally only advective transport of the pollutant is taken into account and molecular diffusion in surface water and soil is ignored fig 13a shows simulation results for the inflow from the south and north sewer pipes and the overflow through the weir into the conventional sewer system over a one year period from june 2018 to may 2019 fig 13a shows the water depth in the well and the pond during the entire simulation period from 2018 to 2021 fig 14 shows the deposited concentration of the hypothetical pollutant on the sub catchment surfaces the concentration of dissolved pollutants in the well and the cumulative mass loading into the groundwater the impact of the first flush can be seen in the changes in concentration in the well during rain events such a model can be used to evaluate the effectiveness of dry wells as a means for stormwater management and groundwater recharge and the potential contamination risks they may pose to groundwater coupling the rainfall runoff and sewer processes with the soil processes allows dynamic evaluation of the impacts of practices such as dry wells at the watershed scale a more complex version of the model could be used to evaluate pre treatment impacts interactions with solid particles including suspended solids and soil and degradation reactions 5 discussion and conclusions an open source extensible framework for constructing flow and water quality models of natural and engineered water systems is proposed this framework structure is versatile using plugins that are programmed outside of the main code or can be provided through dynamic libraries thus allowing for the implementation of a one water integrated watershed openhydroqual is a good candidate for constructing models of systems for which a single off the shelf application is not adequate or when the user desires to formulate the problem in a different way than those applications are based on since the framework is agnostic and can accommodate external non native software it can be potentially used by owners cities utilities watershed managers and regulators as a veritable operating system for hosting native and external watershed models this framework uses a generic solver to solve the diverse range of governing equations resulting from the diverse components it can accommodate through plugins openhydroqual can be used for building models of water systems involving heterogeneous components in which various domains governed by different equations need to work in a coupled way openhydroqual adapts the agile software programming approach to expand the software through plugins defining new components representing media types interfaces between media blocks chemical constituents mass transfer and reaction processes and external forcing including sources and sinks of water and chemicals the extensibility automatic parameter estimation feature open source and platform independence and the availability of the console version of openhydroqual make it a suitable candidate to be used in cloud based platforms for example for digital twin applications the framework can include behavioral tools to encourage participation and collaboration and evaluate policies effect on the outcomes this framework is a cradle for additional layers of implementation for example the use of live sensors can convert the proposed modeling framework to an active interactive digital twin the next steps are to explore some of these approaches through real world calibration and validation exercises the plugin approach allows third party developers to extend or customize the application to construct models comprised of components that may not be available in most off the shelf software applications such problems are expected to arise as a shift towards a one water paradigm occurs openhydroqual is also a suitable tool for hypothesis testing when the user needs to have the flexibility to implement and test novel governing equations to describe the behavior of a system four demonstration applications are outlined the examples were selected to show how the tool can accommodate various system features governed by different equations and over various scales from the lab or a single unit process scale to the watershed scale it should be noted that openhydroqual is designed to mainly solve equations arising from balance principles applied to scalar quantities so using it to solve equations involving the conservation of vector quantities e g conservation of momentum may be challenging in the plugin approach utilized the main code acts as an interpreter of the governing equations provided in the plugins this might adversely affect the simulation speed the speed of the simulation is particularly important when openhydroqual is implemented to describe distributed system by configuring the blocks as a two or three dimensional grid an alternative approach is to compile the plugins into dynamic link libraries dlls where equations are hard coded the dll approach improves the speed of the simulation at the cost of adding to the steps needed to extend the program by users because they need to perform a compilation step declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the model platform was partly funded by national science foundation sbir seed fund usa grant 2152000 in part for the overall development of a watershed digital twin cloud platform appendix a numerical algorithm a fully implicit newton raphson nr method with adaptive time step is used to solve eq 1 the adaptive time step ensures the stability and performance of the code the discretized form of eq 1 for a generic block i can be written as follows a 1 υ i w t δ t w i t δ t w i t δ t j q i j w i t δ t w j t δ t k u i k w i t δ t 0 where υ i is the residual associated with block i which needs to approach zero through an iterative process and w is the vector of state variables at time t δ t please note that w represents the total amount of our state variable which can be the amount of water the mass of a chemical constituent or any other state variable and q i j represents the total flow mass rate flowing from block i to block j for the sake of simplicity the dependence of q i j on w i and w j through the derived variable r and the dependence on the parameters is not written explicitly in the equation but is implicit using the nr algorithm the new value of w t δ t is found by iterating through the following equation a 2 w t δ t w t δ t j 1 ϒ w t δ t where j is the jacobian matrix of ϒ with respect to w the value of the diagonal elements of the jacobian matrix can be computed on eq a 1 as follows a 3 j i i 1 δ t j q i j w i w i w j u i k w i w i where q i j w i w i w j and u i k w i w i w j are the derivatives of flow rate and source terms with respect to the state variable w i a 4 q i j w i w i w j d d w i q i j w i w j u i k w i w i w j d d w i u i k w i please note that q can depend on w indirectly through a set of derived variables r in openhydroqual the derivatives are evaluated numerically for each link the value of non diagonal elements of the jacobian matrix for the cases where blocks i and j are connected through a link is calculated as follows a 5 j i j j q i j w j w i w j please note that because a jacobian matrix approximated based on the values of the state variables at several time steps before the current time step can still be a good approximation of the jacobian matrix for the current values of the state variables the jacobian matrix does not need to be updated for each iteration or even for every time step this in fact can improve the computational efficiency of the numerical method because the calculation of the jacobian matrix can be costly massoudieh et al 2017 openhydroqual decides on when to update the jacobian matrix based on the number of iterations needed for the nr method to converge a 1 treating dry blocks a challenge in the control volume approach when the equations governing the flow from one block to another are non constrained is that the storage or the amount of the state variable in the blocks can become negative which is not physically possible this occurs when q i j w i w j is non zero at w i 0 to numerically handle the cases when a block becomes dry when the value of a state variable at a cell becomes negative at the end of an nr iteration cycle the numerical algorithm assumes that all the outflows and sinks from the block are reduced by a factor β i then the system is solved by considering β as one of the unknowns to be solved so the balance equation for the block with its state variable becoming negative is modified to the following a 6 υ i w t δ t w i t δ t β i j max q i j w i t δ t w j t δ t 0 j min q i j w i t δ t w j t δ t 0 β i k min u i k w i t δ t 0 max u i k w i t δ t 0 0 the diagonal member of the jacobian matrix will now be a 7 j i i d υ i w t δ t d β i j max q i j w i t δ t w j t δ t 0 k min u i k w i t δ t 0 and the non diagonal elements of the jacobian matrix for blocks connected to block i will be a 8 j i j d υ i w t δ t d w j β i j q i j w j w i w j h q i j w i w j j q i j w j w i w j h q i j w i w j β i k u i k w j w i t δ t h u i k w i t δ t k u i k w j w i t δ t h u i k w i t δ t where h is the heaviside function for a receiving block i e block j the jacobian matrix element j j i needs to be modified accordingly as a 9 j j i min q j i w j t δ t w i t δ t 0 for the block undergoing dryness the state variable w i is replaced by β i as the unknown and the system of non linear equations is solved diagonal element j j of the jacobian matrix for the members connected to dry cells should also be modified by multiplying the term representing the link between j and i by β in eq a 3 the block is kept dry until the computed β i is greater than one which indicates that the block is wet after that point the block is treated as a regular non dry block the computational time step is adjusted based on the number of iterations needed for the solution to converge or whether convergence occurs two parameters n r max and n r min are specified the time step is reduced by a factor when the number of nr iterations needed exceeds n r min and is increased when the number of iterations required falls below n r min the time step value is also reduced by a larger factor when convergence does not occur appendix b supplementary data supplementary material related to this article can be found online at https doi org 10 1016 j envsoft 2023 105707 appendix b supplementary data the following is the supplementary material related to this article mmc s1 the values of parameters used in the four demonstration cases 
25411,fuel moisture content fmc plays a significant role in wildfire behavior and rate of spread ros in addition fmc is a highly dynamic factor and very vulnerable to climate variations understanding the effect of fmc on the behavior of fire spread models is crucial and detailed analysis of specific aspects of complex models is a very effective way to improve them the simplified physical fire spread model phyfire considers the effect of fmc in a novel way involving a multivalued maximal monotone operator several numerical experiments have been carried out to confirm that the behavior of the ros simulated with phyfire involving fmc is as expected in the reviewed literature an exponential decrease in fire ros compared to fmc for different scenarios considering different fuel types terrain slopes and wind speeds phyfire performs very accurately proving that the multivalued operator used is suitable and consistent keywords fuel moisture content rate of spread multivalued operator wildfire spread simulation data availability data will be made available on request 1 introduction fuel moisture content fmc defined as the mass of water contained within vegetation in relation to the dry mass plays a significant role in wildfire behavior and rate of spread ros chuvieco et al 2009 in addition fmc is one of the most dynamic component of wildfire fuels it varies rapidly in time and space and it is very vulnerable to weather changes including air temperature relative humidity and precipitation ellis et al 2022 understanding the effect of fmc on fire occurrence and behavior is critical in future climate change scenarios especially in vulnerable areas as the european mediterranean basin vilar et al 2021 fmc is usually separated into dead dfmc and live lfmc components most studies focus on dfmc to understand the effect of fmc on fire spread behavior as it is easier to reproduce in laboratory experiments lfmc also affects the flammability of plants but it is more complex and difficult to quantify this effect fmc is one of the primary variables in many fire behavior prediction models and fire danger indices the current capacity to measure fmc remotely yebra et al 2013 quan et al 2017 makes it an accessible variable for use in fire behavior models therefore any spread model should suitably capture the effect of fmc on ros this paper sets out to prove that the simplified physical fire spread model phyfire developed by the authors accurately reflects the effect of fmc on the ros of simulated fires both separately and in the presence of wind and a terrain slope for different fuel types accordingly the literature on this effect has been extensively reviewed with a thorough exploration of experimental studies on the subject a brief description of phyfire is accompanied by a particular emphasis on how phyfire considers fmc involving a multivalued maximal monotone operator which is the main novelty of this model compared to others in terms of how to represent the effect of fmc we also briefly present the latest improvements regarding the numerical resolution of the model phyfire is part of a wildfire simulation tool integrated into a geographic information system gis which includes its own wind field simulation model hdwind it is not our intention here to provide a detailed description of the two models or of the simulation tool developed accordingly numerous aspects of the phyfire and hdwind models their numerical implementation and the gis tool are described elsewhere ferragut et al 2015 2011 prieto et al 2017 asensio et al 2021 moreover the phyfire hdwind system is a work in progress we are continuing with the ongoing task of improving the physical models their numerical implementation schemes and their gis integration several numerical experiments have been conducted to confirm that the behavior of the ros simulated with phyfire involving fmc is as expected in the reviewed literature in different scenarios terrain slope wind speed and fuel type in other words it corresponds to an exponential function in decline where there is a coefficient k of decay of the curve that explains the effect of moisture the experiments have been performed using the fire behavior data of forest fuels in the spanish region of galicia shown in the photo guide arellano et al 2016 2 model description understanding the behavior of a system as complex as a wildfire is an undeniably useful tool for wildfire management and the development of simulation models plays a key role in this complex challenge cardil et al 2021 there are a large number of models sullivan 2009a b and operational tools papadopoulos and pavlidou 2011 designed for the prediction of wildfire behavior empirical models group 1992 quasi empirical models rothermel 1972 lopes et al 2002 and physical based models mell et al 2007 the more complex atmosphere wildfire coupled models mandel et al 2011 and the recent data driven or data assimilation models yoo and song 2023 the phyfire hdwind operational tool is a gis integrated wildfire spread simulation tool developed by the research group on numerical simulation and scientific computation at the university of salamanca prieto et al 2017 it is based on the simplified physical fire spread model phyfire and the high definition wind field model hdwind the phyfire hdwind code is implemented in c using the own finite element library neptuno cascón et al 2018 and the api openmp for the multiprocessor platforms to reduce computational time álvarez et al 2017 both models are compatible with any platform and can operate either together or separately the gis integrated phyfire hdwind tool was integrated into a web platform http sinumcc usal es this platform was developed using the latest communication and data processing technologies such as api rest json and arcgis server asensio et al 2021 this open access system enables any internet user to use the phyfire hdwind tools without any prior knowledge of either the models or the gis tools the system carries out all the steps of the simulation process in a holistic manner providing the user with a rapid display of the simulation results the advantages of phyfire s technological improvements do not obviate the key question of model reliability the aim here is to further our understanding of the model s performance regarding fmc and find out if it responds as expected in several scenarios including different fuel types wind speeds and terrain slopes we will therefore restrict ourselves to the phyfire model with particular emphasis on the effect of humidity through a multivalued operator in addition the experiments here use a constant wind speed so the hdwind model is not used except in the real example in section 6 no further details on this model are included here but they can be found in asensio et al 2005 ferragut et al 2011 2013 and more recently in prieto herráez et al 2021 2 1 the fire model phyfire phyfire is a simplified two dimensional one phase physical fire spread model based on energy and mass conservation equations asensio et al 2021 this model considers convection and radiation as dominant thermal transfer mechanisms morvan 2011 and depends mainly on meteorological data wind direction and intensity ambient temperature and humidity topography and fuel type and load to better understand the phyfire model we briefly present and explain the equations of the current version of the model as well as the last numerical scheme used to solve it asensio et al 2023 focusing on the multivalued function representing the effect of the fmc the equations of the phyfire model are as follows 1 t e β v e α u r u c in s 0 t m a x 2 e g u in s 0 t m a x 3 t c g u c in s 0 t m a x where the unknowns are the dimensionless enthalpy e e m c t the dimensionless solid fuel temperature u t t t and the solid fuel mass fraction c m m 0 defined on the surface s where the fire develops the physical quantities e j m 2 t k and m kg m 2 are enthalpy the temperature of the solid fuel and the fuel load respectively and c j k 1 kg 1 is the heat capacity of the solid fuel t k is a reference temperature and m 0 kg m 2 is the initial solid fuel load surface s is defined by the mapping s d r 3 x y x y h x y where h x y is a known function representing the topography of the surface s and d 0 l x 0 l y r 2 is a rectangle representing the projection of the surface s fuel is described by the given initial fuel load m 0 and the moisture content m v kg of water kg of dry fuel as well as the fuel type which are scalar functions defined on d fuel type determines the value of some input variables of the model as shown in table 1 we use homogeneous dirichlet boundary conditions whereby the model is valid as long as the fire does not reach the boundary the initial conditions represent the value of the nondimensional solid fuel load including eventual fire breaks and the source of the fire phyfire allows restarting the simulation using intermediate fire perimeters with updated meteorological information the term r u c on the right hand side of eq 1 represents the energy due to radiation and depends on the radiation absorption coefficient inside the flame a the first of the three model parameters listed in table 1 that should be adjusted thermal radiation has a significant effect on ros drying the fuel at the fire s leading edge and thus accelerating its ignition the radiation term is highly nonlinear and three dimensional so the computational cost of its numerical solution in wildfire spread models makes it a challenging task when the flame is not vertical due to wind or terrain slope the effect of thermal radiation is higher downwind and upslope respectively to deal with this effect radiation is represented by a non local radiation term solving the corresponding radiation intensity equation in a three dimensional domain representing the air layer d over surface s d x y z x y d h x y z h x y δ where δ is the height of the air layer assuming that the height of the flames is always less than δ for more details about how to solve the differential equation representing the radiation intensity and how to compute incident radiation energy at each point on the surface s see ferragut et al 2015 notice note that the flame geometry affects the radiation received at each point so in the computation of the radiation detailed in the previous reference it is distinguished whether the flame is vertical or tilted as mentioned above in this paper we pay particular attention to how the phyfire model addresses the effect of the fmc the influence of fmc and heat absorption by pyrolysis is handled by a multivalued maximal monotone operator representing enthalpy ferragut et al 2007 in eq 2 as far as we know phyfire is the first and only fire spread model that treats the enthalpy equation with a multivalued operator defined as follow 4 g u u if u u v u v u v λ v if u u v u λ v if u v u u p u p λ v if u u p where u v and u p are the non dimensional evaporation temperature of the water and the non dimensional pyrolysis temperature of the solid fuel respectively fmc denoted in the model equations by m v kg of water kg of dry fuel appears in the multivalued operator through λ v which is the non dimensional evaporation heat λ v m v λ v c t where λ v 2 25 1 0 6 j kg 1 is the latent heat of evaporation of water it should be noted that in the burned area λ v 0 the use of a multivalued operator is informed by the classical two phase stefan problem and it has been adapted to model the two well defined phases in a wildfire combustion process cox 1995 the endothermic phase that includes the dehydration of the solid fuel and the exothermic phase in which the flammable mixture from fuel pyrolysis begins to release energy these are the solid and gaseous phase respectively which in phyfire are simplified by the multivalued operator g the correction factor β in the convective term of eq 1 and flame temperature and height in the radiation term flame height depends on wind strength and surface slope asensio sevilla et al 2020 phyfire has been provided with a flame height sub model depending on these two factors based on the observation of the experimental curves for different fuels arellano et al 2016 the flame height sub model is as follows 5 f f h f v v 1 2 1 f s s 2 where f h is an independent flame height parameter f v is a wind correction factor f s is a slope correction factor v is the wind strength in m s and s represents the slope at each point on the surface providing a flame height in meters flame temperature is approximated in terms of solid fuel under some simplifications we assumed that this temperature does not vary inside a stabilized flame that heat losses inside the flame are mainly due to local radiation and that a maximum flame temperature t f m a x is available in asensio et al 2023 can be found the details of how to derive the following expression for flame temperature 6 t f t 4 t t p t f m a x 4 t 4 m 1 4 where the term t t p is zero when the process is endothermic and one when it is exothermic the other major heat transfer mechanism in a wildfire is convection which is represented in phyfire through the convective term β v e in eq 1 this term represents the energy convected by the gas pyrolyzed through the elementary control volume where the non dimensional surface wind speed v can either be a constant value or variable both spatially and temporally for example provided by the high definition hdwind model the correction factor β represents the fraction of transported enthalpy retained by the solid fuel in the aforementioned one phase simplification β is the second of the three model parameters that should be adjusted for further details about parameter β see prieto et al 2015 as regards the other terms α u represents the energy lost by natural vertical convection where α is the non dimensional coefficient that depends on the natural convection coefficient h the third model parameter to be adjusted the right hand side of eq 3 represents the loss of solid fuel due to combustion assuming there is no loss below the pyrolysis temperature and that the loss rate remains constant when this temperature is reached this rate is inversely proportional to the solid half life time t 1 2 of the combustion of each type of fuel eqs 1 2 3 properly reflects the simplified combustion process in the burning area but these equations can be further simplified in the burned area assuming that once the fuel has been burned the enthalpy is not recovered and considering that an area is fully burned when the mass fraction of solid fuel is less than 0 1 then the only equation to be solved in the burned area is 7 t u α u r u c in s 0 t m a x where we are neglecting the heat transported by convection to the burned area 2 2 numerical method the numerical method used to solve this non local radiation model included a p1 finite element method for the spatial discretization on a regular mesh combined with a predictor corrector finite difference scheme for the time discretization the predictor step is a euler semi implicit scheme and the corrector step is a modified crank nicolson scheme after analyzing other numerical schemes throughout the development process of the phyfire model its numerical resolution and its practical implementation see asensio et al 2023 this scheme has provided stable numerical solutions and a good balance between efficiency and computational cost the computational cost has been reduced by defining what we define as active nodes so that the equations are solved only in the neighborhood of the fire front and by adapting the numerical scheme and the corresponding code to parallel computing ferragut et al 2015 the spatial discretization varies depending on the precision level currently varies from precision level 0 corresponding to 50 m cell size to precision level 5 corresponding to 2 5 m cell size for the experiments performed in this work we have used precision level 4 5 m cell size for the study of the behavior of ros versus fmc in section 4 4 and precision level 3 7 5 m cell size for the simulation of the real case in section 6 given the initial values u 0 and c 0 defined by the initial conditions we set the value of the initial enthalpy for each node i of the spatial discretization depending on the initial nondimensional temperature u 0 as follow 8 e i 0 u i 0 if u i 0 u v u i 0 λ v if u i 0 u v given the values of the unknowns u n c n and e n at time step n we compute u n 1 c n 1 and e n 1 by means of the following steps 1 build the set of active nodes 2 compute the radiation heat 3 prediction step semi implicit euler method 4 update the set of active nodes 5 update the radiation heat 6 correction step modified crank nicolson method a node i is considered an active node if u i 0 and c i 0 1 or if it belongs to the radiation molecule associated to a node fulfilling the previous condition the radiation molecule is a set of nodes consisting of the node itself and the neighboring nodes defining the area affected by the radiation emitted by the node in question the numerical computation of the radiation term for each time step r n is fully described in ferragut et al 2015 we focus here on those numerical aspects of the algorithm that are new compared to previous versions specifically the predictor corrector finite difference scheme we must first mention the total discretization of the convective term of eq 1 that is carried out in each step of the predictor corrector scheme t e β v e 1 δ t e n 1 e n where e n e n x n and x n x x x t n 1 t n x β v δ t is the position at time t n of the particle that is at position x at time t n 1 predictor step the discrete equations in the burning area in the predictor step correspond to a semi implicit euler scheme 9 e n 1 2 e n δ t α u n 1 2 r n 10 e n 1 2 g u n 1 2 11 c n 1 2 c n δ t g u n 1 2 c n 1 where e n 1 2 u n 1 2 and c n 1 2 stand for the predicted value of e n 1 u n 1 and c n 1 respectively the basic idea is to handle the linear term implicitly and since the non local radiation term r n depends strongly on the temperature u n and on the solid fuel c n they are evaluated explicitly at time t n but even so eqs 9 11 continue to be non linear due to the multivalued operator g nevertheless the solution of this problem can be reduced to explicit calculations the multivalued operator in eq 10 is maximal monotone and hence its resolvent j μ i d μ g 1 is a well defined univalued operator for any μ 0 moreover the yosida approximation bermúdez and moreno 1981 of g g μ i d j μ μ is a lipschitz operator and the inclusion in eq 10 is equivalent for all μ 0 to the following equation 12 e n 1 2 g μ u n 1 2 μ e n 1 2 or 13 u n 1 2 j μ u n 1 2 μ e n 1 2 now rearranging eq 9 14 u n 1 2 1 α δ t e n 1 2 1 α δ t e n 1 α r n and taking μ 1 α δ τ in eq 13 we obtain 15 u n 1 2 j 1 α δ t 1 α δ t e n 1 α r n which it is equivalent to solve 16 α δ t i d g u n 1 2 e n δ t r n thus denoting æ n e n δ t r n the value of u n 1 2 is given by æ n 1 α δ t if æ n 1 α δ t u v u v if æ n 1 α δ t u v 1 α δ t u v λ v æ n λ v 1 α δ t if æ n 1 α δ t u v λ v 1 α δ t u p λ v 17 u p if æ n 1 α δ t u p λ v once u n 1 2 has been obtained we calculate e n 1 2 and c n 1 2 explicitly from eq 9 and 11 respectively 18 e n 1 2 e n α δ t u n 1 2 δ t r n 19 c n 1 2 c n 1 δ t g u n 1 2 notice that eqs 15 18 and 19 can be solved simultaneously in all active nodes so parallel computation can be used to reduce the computational cost indeed the loop over all actives nodes to compute u n 1 2 e n 1 2 and c n 1 2 has been parallelized using the api openmp chapman et al 2007 in the burned area only eq 7 needs to be solved whose discrete version using a semi implicit euler scheme is 20 u n 1 2 u n δ t α u n 1 2 r n that can be solved explicitly 21 u n 1 2 u n δ t r n 1 α δ t corrector step the discrete equations in the burning area in the corrector step correspond to a crank nicolson scheme 22 e n 1 e n δ t α u n 1 u n 2 r n 1 2 r n 2 23 e n 1 g u n 1 24 c n 1 c n δ τ g u n 1 u n 2 c n 1 c n 2 where we have approximate r n 1 by r n 1 2 computed in terms of u n 1 2 and c n 1 2 the estimations obtained in the prediction steps as at this point u n 1 and c n 1 are not known as in the prediction step rearranging eq 22 we have 25 u n 1 2 α δ t e n 1 2 α δ t e n u n r n 1 2 r n α as in the predictor step taking μ 2 α δ t the multivalued eq 23 can be written as 26 u n 1 j 2 α δ t 2 α δ t e n u n r n 1 2 r n α which it is equivalent to solve 27 2 α δ τ i d g u n 1 2 α δ t e n u n r n 1 2 r n α denoting now æ n 2 α δ t e n u n r n 1 2 r n α the value of u n 1 is given by æ n 1 α δ t 2 if æ n 1 α δ t 2 u v u v if æ n 1 α δ t 2 u v 1 α δ t 2 u v λ v æ n λ v 1 α δ t 2 if æ n 1 α δ t 2 u v λ v 1 α δ t 2 u p λ v 28 u p if æ n 1 α δ t 2 u p λ v again once u n 1 has been obtained we can update the enthalpy e n 1 from eq 22 and the fuel c n 1 from eq 24 29 e n 1 e n α δ t u n 1 u n 2 δ t r n 1 2 r n 2 30 c n 1 1 δ t 2 g u n 1 u n 2 1 δ t 2 g u n 1 u n 2 c n once more eqs 26 29 and 30 can be solved simultaneously in all active nodes so again the parallel calculation allows us to reduce the computational cost in the correction step in the burned area only 22 needs to be considered which can be solved explicitly u n 1 1 α δ t 2 u n δ τ 2 r n 1 2 r n 1 α δ t 2 3 fuel moisture content as a wildfire spread factor fmc has a direct relationship with wildfire ros being one of the variables together with wind that most influences it chuvieco et al 2009 mainly through the process of heating and subsequently evaporating the water in the fuel enabling it to attain combustion conditions this process involves the consumption of the energy released by the adjacent combustion fuel and requires time which reduces ros as moisture increases the laboratory and field fires analyzed in rossa and fernandes 2018b have evidenced that wind explains 61 9 of ros variance while dfmc explains the remaining 38 1 furthermore the damping effect of moisture on ros is not affected by the wind remaining constant rossa and fernandes 2017 there is consensus on the crucial influence that dfmc has on ros but there are discrepancies over the influence of lfmc finney et al 2013 which are manifested in theoretical propagation models rothermel 1972 albini 1976 stocks et al 1989 and are based on experimental trials contradictory results are obtained between field tests involving controlled burning where lfmc barely influences ros and laboratory studies in which there is a clear relationship between lfmc and ros rossa and fernandes 2018b consequently propagation models based on laboratory studies often use a weight of live and dead fuel based on their mass while those informed by field experiments consider only dead fuel rossa and fernandes 2018b this difficulty in detecting the influence of live fuel on ros in field tests is because it can be concealed in two different ways on the one hand live fuel maintains an almost constant moisture content throughout the year e g mature pine needles or other fuels in non mediterranean climates or on the other their variation follows a similar pattern to that of dead fuel measured as a monthly average many models are therefore based solely on dead fuel but it should be noted that this is only true if the moisture implicit in the live fuel albeit not accounted for remains within the same ranges as during the experimentation informing the model if for example fmc is much lower due to drought the model will no longer hold rossa and fernandes 2018a and will even pose a threat if used in prevention extinction operations experiments carried out in the laboratory using a mix of live and dead fuel seem to confirm that lfmc reduces ros in the same proportion as dead fuel without finding any significant differences between the two marino et al 2012 rossa and fernandes 2017 the decisive variable is therefore the moisture content weighted according to mass in dry weight regardless of whether it is alive or dead moreover live and dead fuels influence ros through the same mechanism that is through the absorption of the heat generated by the fire to raise its temperature and subsequently evaporate before the fuel can begin to burn this means the phenological state of the vegetation is not relevant but instead its moisture content rossa and fernandes 2017 there are indications however that the ignition mechanism of live fuel may be different as it may ignite before all the water content has evaporated finney et al 2013 rossa and fernandes 2018a after conducting a series of laboratory experiments with live fuel involving four common mountain species in portugal rossa et al 2016 conclude that there is a threshold for lfmc of between 50 and 70 although in another paper they report 100 rossa and fernandes 2017 whereby the influence the increase has on ros is small although present which is consistent with field observations viegas et al 2013 report a threshold in the proportion of dead fuel to live one below which the fire stops spreading ros 0 this value depends on the moisture content of both types of fuel and environmental conditions to explain the influence of fmc on ros several authors cheney et al 1993 burrows 1999 fernandes et al 2009 marino et al 2012 anderson et al 2015 rossa et al 2016 use an exponential function in decline where there is a coefficient k of decay of the curve that explains the effect of moisture in both laboratory and field experiments the function is as follows 31 r o s c e k f m c this function is usually integrated as a term into a general function of ros including other variables such as wind speed slope depth of the fuel bed or degree of cure of the herbaceous fuel table 2 shows coefficient k values for different studies with k values corresponding mainly to ros measurements in m min 1 part of the literature reviewed reports other versions of this exponential relationship including the effect of wind and terrain slope cheney et al 1993 burrows 1999 fernandes et al 2009 anderson et al 2015 propose the following equation 32 r o s c v b e k f m c where v is surface wind speed marino et al 2012 propose a linear model for wind as their experimental study is limited to two wind figures but they stress that this model has no predictive value for wind effect this study is of particular interest because it compares experimental data and predictions from the physically based model firetec as in this article with phyfire one of the problems mentioned in marino et al 2012 is the difference in scale between experiments and simulations with firetec this is not an issue in our study as phyfire allows computations at different scales by changing the precision level other authors also suggest that the impact of fmc upon the fire behavior was also affected by the wind conditions and substantiate this with numerical experiments morvan 2013 but do not propose a particular expression of this relationship the model suggested in fernandes et al 2009 describes ros in terms of surface wind speed and fmc and also slope terrain s through the following function 33 r o s c v b e p s k f m c 4 methodology 4 1 description of the experiments the spatial domain for the experiments is an even sloping surface with a manageable but realistic scale namely 6000 m 3000 m the fire focus is a line 25 m wide located at a distance of 1000 m from the lower short side wind and slope are taken in the same direction that is the fire front follows both the slope and the wind ros is computed as the slope of the linear regression line used to fit the position of the fire front in real time every five minutes from minute 10 to minute 60 measured lengthwise the ros calculation code provides controls to detect if the fire goes out or if it is approaching the limit of the domain avoiding unnecessary or unrealistic calculations uniform fuel distribution is considered for four types of brush and one type of grass selected from the comprehensive report arellano et al 2016 this is a photo guide that provides valuable information about the main forestry fuels in galicia in northwest spain and specifically the main physical features of fuels related to their fire behavior which are of particular interest to this study this guide provides a system for estimating the probable behavior of a wildfire that involves the fuels analyzed including flame height and ros under a range of scenarios three different slopes 0 20 and 40 and wind speed ranging between 0 and 60 km h 1 there is also information on the fuel load and its weighted height these data have allowed us to adjust the parameters and certain input variables in phyfire table 3 lists some of the properties of the five fuels selected the model corresponding to one of the 13 standard fuels according to the northern forest fire laboratory nffl classification system anderson 1982 the specific fuel from the photo guide arellano et al 2016 and certain characteristics such as fuel load or weighted height 4 2 flame height adjustment the first step involved adjusting the flame height sub model coefficients in eq 5 for each one of the five fuel types selected by a nonlinear least square approximation of flame height data obtained from graphics in the photo guide arellano et al 2016 for different slopes 0 20 and 40 and wind speed at intervals of 5 km h 1 from 0 to 45 km h 1 as regards the four types of brush flame height data for a wind speed of 0 km h 1 was not considered due to its high uncertainty conversely grassland analyzed in arellano et al 2016 report that the fire does not spread in conditions of no wind and no slope and flame height is zero so these flame height data should be included the adjustment has been performed using cftool the matlab curve fitting toolbox selecting a levenberg marquardt algorithm reaching a coefficient of determination r 2 0 95 in all cases table 3 contains the flame height model coefficients computed and the goodness of fit in terms of the coefficients of determination r 2 the goodness of flame height sub model eq 5 has been discussed in detail in asensio sevilla et al 2020 so here we only provide the value of the coefficient of determination r 2 to justify the adjustment without specifying other error metrics as this is not the aim of this study 4 3 parameter adjustment the second step is the adjustment of the three phyfire parameters namely the mean absorption coefficient a the natural convection coefficient h and the correction factor of the convective term β using these five fuel models and ros data from the photo guide arellano et al 2016 for the given ranges of wind speed and terrain slope the initial aim was to follow the same parameter adjustment strategy as in prieto et al 2015 where we first adjusted a and h for no wind and no slope fire data with β then being adjusted with all the other ros data for the given terrain slopes and wind speeds this strategy was shown to be effective in prieto et al 2015 and responded to the conclusions derived from the sensitivity analysis and parameter adjustment reported there where a and h did not vary significantly for different scenarios including slope wind and fuel moisture content always recording the same order of magnitude β became the most relevant input factor for ros strongly dependent on wind magnitude this strategy has proven inadequate here due to the incorporation of the new flame height sub model given by eq 5 an in depth study of the parameter adjustment process revealed an important change in the sensitivity of the model parameters a new global sensitivity analysis gsa of phyfire parameters showed a major change in the importance of both the mean absorption coefficient a and the correction factor of convective term β this new gsa was performed using the safe sensitivity analysis for everybody matlab toolbox pianosi et al 2015 with the elementary effect test saltelli et al 2008 the results of this gsa revealed the greater importance of the mean absorption coefficient a in all scenarios whereby the flame height sub model corrects the undue importance of the correction factor of convective term β although not the subject of this study the results of this gsa have been used here to design a better model parameter adjustment strategy we have fixed h in a previous adjustment using only no wind and no slope ros data obtaining a mean value of 10 605 j s 1 m 2 k 1 β has been selected in the order of hundredths β 0 02 its typical value prieto et al 2015 but with the aim of assuring the existence of an optimum value of the third parameter a in all scenarios the objective here is to verify whether phyfire simulations confirm the exponential function 31 assessing the isolated effect of fmc on ros as well as functions 32 and 33 when wind speed and terrain slope are considered it is therefore important to best fit the model to each scenario and choose the scenarios with the least uncertainty among all those previously analyzed a bisection method has been used to determine the value of the parameter a that equals the value of the computational ros with the experimental ros for each scenario the parameter adjustment has been implemented in c as phyfire in order to optimize the adjustment process as the evaluation of the model is the costliest part the total number of cases analyzed amounts to 74 corresponding to the five fuel types three terrain slopes 0 20 and 40 and five wind speeds 5 10 15 20 and 25 km h 1 except for grass and 0 slope where the wind speed of 5 km h 1 is not considered scenarios with a lower degree of uncertainty have been considered avoiding very low or very high winds in which the data are less reliable the results of this adjustment are shown in table 4 4 4 data analysis ros versus fmc once the model parameters have been adjusted for each scenario each wind speed terrain slope and fuel type phyfire has been evaluated by varying the fmc to test whether the simulated ros record an exponential decay as a function of fmc as in the empirical models reviewed fmc ranges from 3 to 244 using 17 values following an exponential distribution as previous observation of the results showed that high fmc produces few changes in ros this is the first positive observation of the good behavior of the phyfire model in this study the overall trend in the ros fmc relationship suggests an fmc threshold of 50 70 above which its response to increasingly higher fmc is weak rossa et al 2016 nonlinear regression analyses have been performed to summarize the behavior of ros for the simulation data in terms of fmc eq 31 fmc and wind speed eq 32 and fmc wind speed and terrain slope eq 33 for all the fuel types selected a routine has been built in matlab based on the function lsqcurvefit which solves nonlinear curve fitting data fitting problems in the least squares sense selecting the levenberg marquardt algorithm this matlab function returns the adjusted parameters the squared 2 norm of the residual and the residual array itself this allows easy calculation of the coefficient of determination r 2 and an overall indicator of goodness of fit as well as the adjusted coefficient of determination r a d j 2 a modified version of r 2 for the number of independent variables in the model r 2 1 i 1 n y i y ˆ i 2 i 1 n y i y 2 r a d j 2 1 1 r 2 n 1 n d 1 other deviation measures computed to evaluate the model s performances were the root mean square error rmse and the mean absolute error mae as well as their normalized versions the normalized root mean square error nrmse and the normalized mean absolute error nmae in order to relate the corresponding error measures to the observed range of the variable we also provide the mean biased error mbe to discover whether the models tend to overestimate or underestimate ros r m s e 1 n i 1 n y i y ˆ i 2 n r m s e r m s e y m a e 1 n i 1 n y i y ˆ i n m a e 1 n i 1 n y i y ˆ i y i m b e 1 n i 1 n y ˆ i y i the 95 confidence intervals have been calculated for estimating the coefficients of the three models and they are all significant although the cftool used previously for adjusting the flame height eq 5 can be used for eqs 31 and 32 it cannot be used for eq 33 because it depends on three variables fmc wind speed and terrain slope cftool provides a flexible interface for fitting curves and surfaces to data but not for more than two independent variables the use of the lsqcurvefit function is more flexible for computing the error metrics and upholds uniformity in the analysis of the three models phyfire states all data in si units although in the fitting of eqs 31 32 and 33 ros has been measured in m min 1 as in the literature reviewed for obtaining values of the exponential coefficient k comparable to those found in the references fmc is measured in and wind speed in m s 1 5 results and discussion the exponential relationship between ros and fmc described by eq 31 explains on average 80 of the cases in all the scenarios with better results in cases with steeper slopes and higher wind speeds table 5 shows fitted values and all the metrics computed to assess the goodness of fit for each one of the five fuel types and an intermediate scenario of 20 slope and 20 km h 1 wind speed no significant differences are observed between the chosen intermediate scenario and the mean values of all scenarios all the fuels record a similar performance with fuel 5 having a worse r 2 but better mae the negative but small values of the mbe imply that the model slightly underestimates ros values of pre exponential factor c are not shown because they vary considerably depending on wind speed and terrain slope as expected the pre exponential factor of eqs 32 and 33 reflects this behavior fig 1 shows the predicted ros values for all the fuel types and the scenario selected for table 5 namely 20 terrain slope and 20 km h 1 wind speed the behavior of the different types of fuels can be appreciated ros values are in full agreement with the photo guide data arellano et al 2016 eq 32 incorporates the effect of wind speed achieving a better fit explaining on average 90 of cases for all the slopes and fuel types in terms of r 2 and also r a d j 2 so the improvement in fit cannot be attributed to increased degrees of freedom rmse and mae increase with the slope but this is due to higher values of ros however the normalized versions of these error measures nrmse and nmae remain in the same range for all slopes and fuel types table 6 shows fitted values and all the metrics computed finally eq 33 which also incorporates the effect of the slope achieves an optimal fit with r a d j 2 0 95 for almost all the fuel types except grassland fuel type 1 with r a d j 2 0 94 probably due to fewer data and fuel type 5 r a d j 2 0 936 the worst performing brush in all the settings as can be seen in table 6 coefficients p and k reflecting the effect of slope and fmc respectively record similar values for all the fuels as in the experimental cases appearing in the refs fernandes et al 2009 the exponential coefficient of wind term records a similar value for grassland fuel type 1 and brush as well as the pre exponential factor c which is explained by the different fire behavior of grasslands and brushlands the normalized versions of the error measures nrmse and nmae maintain acceptable values as does mbe eq 33 slightly overestimates the ros for grassland fuel type 1 and slightly underestimates the ros for brushlands see table 7 eq 31 is fulfilled for several fuel types wind speeds and terrain slopes and the value of the coefficient k obtained also remains within the same range for eqs 32 and 33 which considers wind and slope and it is within the limits set by the studies that have evaluated it certain discrepancies of a quantitative nature that can be observed in the values obtained for the exponential factor and the ros may be due to the fact that the model parameters have been adjusted based on the data available at arellano et al 2016 constrained to an fmc of 6 the radiation absorption coefficient a can be sensitive to fmc and wider flame length and ros data would provide a more reliable fit of the model parameters and would reduce the observed discrepancies 6 a real example the real example used to illustrate this study occurred in an area of the autonomous region of galicia since the analysis carried out corresponds to fuels typical of this area of north western spain this case has already been used in two previous publications prieto et al 2017 asensio et al 2021 where details of the fire extension the characteristics of the affected area and the meteorological conditions can be found however we summarize here the most relevant data this wildfire occurred in osoño orense at 15 25 local time on august 17 2009 burning 224 ha of pinus pinaster shrubland and grassland ambient temperature was above 30 c and humidity below 30 the wind was increasing from 2 m s to almost 5 m s the fire developed during the afternoon and in the areas most exposed to solar radiation western face the fire spread more rapidly this is precisely the feature that we have sought to capture with this new simulation the fuel in areas more exposed to solar radiation has lower moisture content and this affects the fire behavior in these areas we have simulated four different scenarios taking into account some of the actions of the firefighting teams in particular three large firebreaks on the right flank without these actions with a constant fmc throughout the simulation domain and with a variable fmc depending on the solar radiation received reducing it by 5 in the west facing areas the simulation of each scenario involved about 150 s of computing time on a laptop computer equipped with an intel i7 processor dual core 3 50 ghz and 16 gb of ram for a rectangular simulation area of 3320 m 2745 m and a resolution of 7 5 m for the finite element mesh fig 2 shows the result of the simulation with the phyfire model of the osoño fire during the first four and a quarter hours assuming that the fuel moisture is spatially uniform and without considering the actions of the firefighting teams in fig 3 we have considered the effect of solar radiation on the west facing areas reducing humidity by 5 which shows how the fire advances more rapidly and affects a larger area in these areas fig 4 shows how the fire lines designed by the firefighters were effective in preventing the fire from reaching the nearby population even in the worst case scenario in terms of fmc this scenario is consistent with the report of the firefighting teams which designed three firebreaks to prevent the fire from reaching the nearest population nevertheless the actions of the fire truck water tanks on flanks during the last part of the fire were not considered in the simulation this may explain why our simulation exceeds the perimeter 7 summary and conclusions this study has explored the sensitivity of fire ros and certain environmental conditions mainly fmc but also wind speed and terrain slope in numerical simulations performed by the simplified physical phyfire model the results are qualitatively compared to field and tunnel based experiments and with others numerical experiments found in the literature the conclusion is that the phyfire model is highly consistent with an exponential decay of fire ros compared to fmc alone and also in the presence of wind speed and terrain slope phyfire therefore performs as expected with respect to fmc according to the experimental models reviewed with a high degree of accuracy in all the scenarios analyzed this study therefore proves that the innovative and original way in which phyfire considers the effect of fmc through a multivalued operator is highly significant we have also observed the existence of an fmc threshold above which the response of ros to increasingly higher fmc is weak as in the experimental studies overall this work shows the expediency of studying specific aspects of complex simulation models to improve their understanding with a view to increasing their overall efficiency the development of wildland fire simulation models is a very complex task and their applicability is a matter of discussion alexander and cruz 2013 one way to tackle this challenge is to conduct a detailed analysis of specific aspects that allow for the model s overall improvement updated information on time and space for fmc will provide better simulation results as evidenced by the real fire simulation therefore in order to improve the accuracy of fire spread simulation it would be highly desirable to use all the technology and new methods at our disposal to enhance the fmc information sharples et al 2009 miller et al 2022 quan et al 2017 software availability name of the software phyfire developer luis ferragut m isabel asensio j manuel cascón diego prieto contact information sinumcc usal es program language c neptno openmp software availability http sinumcc usal es declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research has been partially supported by the spanish ministry of economy and competitiveness mineco through project pid2019 107685rb i00 the european regional development fund erdf the department of education of the regional government the junta de castilla y león spain grant contract sa089p20 and the european union s horizon 2020 research and innovation framework programme under grant agreement id 101036926 
25411,fuel moisture content fmc plays a significant role in wildfire behavior and rate of spread ros in addition fmc is a highly dynamic factor and very vulnerable to climate variations understanding the effect of fmc on the behavior of fire spread models is crucial and detailed analysis of specific aspects of complex models is a very effective way to improve them the simplified physical fire spread model phyfire considers the effect of fmc in a novel way involving a multivalued maximal monotone operator several numerical experiments have been carried out to confirm that the behavior of the ros simulated with phyfire involving fmc is as expected in the reviewed literature an exponential decrease in fire ros compared to fmc for different scenarios considering different fuel types terrain slopes and wind speeds phyfire performs very accurately proving that the multivalued operator used is suitable and consistent keywords fuel moisture content rate of spread multivalued operator wildfire spread simulation data availability data will be made available on request 1 introduction fuel moisture content fmc defined as the mass of water contained within vegetation in relation to the dry mass plays a significant role in wildfire behavior and rate of spread ros chuvieco et al 2009 in addition fmc is one of the most dynamic component of wildfire fuels it varies rapidly in time and space and it is very vulnerable to weather changes including air temperature relative humidity and precipitation ellis et al 2022 understanding the effect of fmc on fire occurrence and behavior is critical in future climate change scenarios especially in vulnerable areas as the european mediterranean basin vilar et al 2021 fmc is usually separated into dead dfmc and live lfmc components most studies focus on dfmc to understand the effect of fmc on fire spread behavior as it is easier to reproduce in laboratory experiments lfmc also affects the flammability of plants but it is more complex and difficult to quantify this effect fmc is one of the primary variables in many fire behavior prediction models and fire danger indices the current capacity to measure fmc remotely yebra et al 2013 quan et al 2017 makes it an accessible variable for use in fire behavior models therefore any spread model should suitably capture the effect of fmc on ros this paper sets out to prove that the simplified physical fire spread model phyfire developed by the authors accurately reflects the effect of fmc on the ros of simulated fires both separately and in the presence of wind and a terrain slope for different fuel types accordingly the literature on this effect has been extensively reviewed with a thorough exploration of experimental studies on the subject a brief description of phyfire is accompanied by a particular emphasis on how phyfire considers fmc involving a multivalued maximal monotone operator which is the main novelty of this model compared to others in terms of how to represent the effect of fmc we also briefly present the latest improvements regarding the numerical resolution of the model phyfire is part of a wildfire simulation tool integrated into a geographic information system gis which includes its own wind field simulation model hdwind it is not our intention here to provide a detailed description of the two models or of the simulation tool developed accordingly numerous aspects of the phyfire and hdwind models their numerical implementation and the gis tool are described elsewhere ferragut et al 2015 2011 prieto et al 2017 asensio et al 2021 moreover the phyfire hdwind system is a work in progress we are continuing with the ongoing task of improving the physical models their numerical implementation schemes and their gis integration several numerical experiments have been conducted to confirm that the behavior of the ros simulated with phyfire involving fmc is as expected in the reviewed literature in different scenarios terrain slope wind speed and fuel type in other words it corresponds to an exponential function in decline where there is a coefficient k of decay of the curve that explains the effect of moisture the experiments have been performed using the fire behavior data of forest fuels in the spanish region of galicia shown in the photo guide arellano et al 2016 2 model description understanding the behavior of a system as complex as a wildfire is an undeniably useful tool for wildfire management and the development of simulation models plays a key role in this complex challenge cardil et al 2021 there are a large number of models sullivan 2009a b and operational tools papadopoulos and pavlidou 2011 designed for the prediction of wildfire behavior empirical models group 1992 quasi empirical models rothermel 1972 lopes et al 2002 and physical based models mell et al 2007 the more complex atmosphere wildfire coupled models mandel et al 2011 and the recent data driven or data assimilation models yoo and song 2023 the phyfire hdwind operational tool is a gis integrated wildfire spread simulation tool developed by the research group on numerical simulation and scientific computation at the university of salamanca prieto et al 2017 it is based on the simplified physical fire spread model phyfire and the high definition wind field model hdwind the phyfire hdwind code is implemented in c using the own finite element library neptuno cascón et al 2018 and the api openmp for the multiprocessor platforms to reduce computational time álvarez et al 2017 both models are compatible with any platform and can operate either together or separately the gis integrated phyfire hdwind tool was integrated into a web platform http sinumcc usal es this platform was developed using the latest communication and data processing technologies such as api rest json and arcgis server asensio et al 2021 this open access system enables any internet user to use the phyfire hdwind tools without any prior knowledge of either the models or the gis tools the system carries out all the steps of the simulation process in a holistic manner providing the user with a rapid display of the simulation results the advantages of phyfire s technological improvements do not obviate the key question of model reliability the aim here is to further our understanding of the model s performance regarding fmc and find out if it responds as expected in several scenarios including different fuel types wind speeds and terrain slopes we will therefore restrict ourselves to the phyfire model with particular emphasis on the effect of humidity through a multivalued operator in addition the experiments here use a constant wind speed so the hdwind model is not used except in the real example in section 6 no further details on this model are included here but they can be found in asensio et al 2005 ferragut et al 2011 2013 and more recently in prieto herráez et al 2021 2 1 the fire model phyfire phyfire is a simplified two dimensional one phase physical fire spread model based on energy and mass conservation equations asensio et al 2021 this model considers convection and radiation as dominant thermal transfer mechanisms morvan 2011 and depends mainly on meteorological data wind direction and intensity ambient temperature and humidity topography and fuel type and load to better understand the phyfire model we briefly present and explain the equations of the current version of the model as well as the last numerical scheme used to solve it asensio et al 2023 focusing on the multivalued function representing the effect of the fmc the equations of the phyfire model are as follows 1 t e β v e α u r u c in s 0 t m a x 2 e g u in s 0 t m a x 3 t c g u c in s 0 t m a x where the unknowns are the dimensionless enthalpy e e m c t the dimensionless solid fuel temperature u t t t and the solid fuel mass fraction c m m 0 defined on the surface s where the fire develops the physical quantities e j m 2 t k and m kg m 2 are enthalpy the temperature of the solid fuel and the fuel load respectively and c j k 1 kg 1 is the heat capacity of the solid fuel t k is a reference temperature and m 0 kg m 2 is the initial solid fuel load surface s is defined by the mapping s d r 3 x y x y h x y where h x y is a known function representing the topography of the surface s and d 0 l x 0 l y r 2 is a rectangle representing the projection of the surface s fuel is described by the given initial fuel load m 0 and the moisture content m v kg of water kg of dry fuel as well as the fuel type which are scalar functions defined on d fuel type determines the value of some input variables of the model as shown in table 1 we use homogeneous dirichlet boundary conditions whereby the model is valid as long as the fire does not reach the boundary the initial conditions represent the value of the nondimensional solid fuel load including eventual fire breaks and the source of the fire phyfire allows restarting the simulation using intermediate fire perimeters with updated meteorological information the term r u c on the right hand side of eq 1 represents the energy due to radiation and depends on the radiation absorption coefficient inside the flame a the first of the three model parameters listed in table 1 that should be adjusted thermal radiation has a significant effect on ros drying the fuel at the fire s leading edge and thus accelerating its ignition the radiation term is highly nonlinear and three dimensional so the computational cost of its numerical solution in wildfire spread models makes it a challenging task when the flame is not vertical due to wind or terrain slope the effect of thermal radiation is higher downwind and upslope respectively to deal with this effect radiation is represented by a non local radiation term solving the corresponding radiation intensity equation in a three dimensional domain representing the air layer d over surface s d x y z x y d h x y z h x y δ where δ is the height of the air layer assuming that the height of the flames is always less than δ for more details about how to solve the differential equation representing the radiation intensity and how to compute incident radiation energy at each point on the surface s see ferragut et al 2015 notice note that the flame geometry affects the radiation received at each point so in the computation of the radiation detailed in the previous reference it is distinguished whether the flame is vertical or tilted as mentioned above in this paper we pay particular attention to how the phyfire model addresses the effect of the fmc the influence of fmc and heat absorption by pyrolysis is handled by a multivalued maximal monotone operator representing enthalpy ferragut et al 2007 in eq 2 as far as we know phyfire is the first and only fire spread model that treats the enthalpy equation with a multivalued operator defined as follow 4 g u u if u u v u v u v λ v if u u v u λ v if u v u u p u p λ v if u u p where u v and u p are the non dimensional evaporation temperature of the water and the non dimensional pyrolysis temperature of the solid fuel respectively fmc denoted in the model equations by m v kg of water kg of dry fuel appears in the multivalued operator through λ v which is the non dimensional evaporation heat λ v m v λ v c t where λ v 2 25 1 0 6 j kg 1 is the latent heat of evaporation of water it should be noted that in the burned area λ v 0 the use of a multivalued operator is informed by the classical two phase stefan problem and it has been adapted to model the two well defined phases in a wildfire combustion process cox 1995 the endothermic phase that includes the dehydration of the solid fuel and the exothermic phase in which the flammable mixture from fuel pyrolysis begins to release energy these are the solid and gaseous phase respectively which in phyfire are simplified by the multivalued operator g the correction factor β in the convective term of eq 1 and flame temperature and height in the radiation term flame height depends on wind strength and surface slope asensio sevilla et al 2020 phyfire has been provided with a flame height sub model depending on these two factors based on the observation of the experimental curves for different fuels arellano et al 2016 the flame height sub model is as follows 5 f f h f v v 1 2 1 f s s 2 where f h is an independent flame height parameter f v is a wind correction factor f s is a slope correction factor v is the wind strength in m s and s represents the slope at each point on the surface providing a flame height in meters flame temperature is approximated in terms of solid fuel under some simplifications we assumed that this temperature does not vary inside a stabilized flame that heat losses inside the flame are mainly due to local radiation and that a maximum flame temperature t f m a x is available in asensio et al 2023 can be found the details of how to derive the following expression for flame temperature 6 t f t 4 t t p t f m a x 4 t 4 m 1 4 where the term t t p is zero when the process is endothermic and one when it is exothermic the other major heat transfer mechanism in a wildfire is convection which is represented in phyfire through the convective term β v e in eq 1 this term represents the energy convected by the gas pyrolyzed through the elementary control volume where the non dimensional surface wind speed v can either be a constant value or variable both spatially and temporally for example provided by the high definition hdwind model the correction factor β represents the fraction of transported enthalpy retained by the solid fuel in the aforementioned one phase simplification β is the second of the three model parameters that should be adjusted for further details about parameter β see prieto et al 2015 as regards the other terms α u represents the energy lost by natural vertical convection where α is the non dimensional coefficient that depends on the natural convection coefficient h the third model parameter to be adjusted the right hand side of eq 3 represents the loss of solid fuel due to combustion assuming there is no loss below the pyrolysis temperature and that the loss rate remains constant when this temperature is reached this rate is inversely proportional to the solid half life time t 1 2 of the combustion of each type of fuel eqs 1 2 3 properly reflects the simplified combustion process in the burning area but these equations can be further simplified in the burned area assuming that once the fuel has been burned the enthalpy is not recovered and considering that an area is fully burned when the mass fraction of solid fuel is less than 0 1 then the only equation to be solved in the burned area is 7 t u α u r u c in s 0 t m a x where we are neglecting the heat transported by convection to the burned area 2 2 numerical method the numerical method used to solve this non local radiation model included a p1 finite element method for the spatial discretization on a regular mesh combined with a predictor corrector finite difference scheme for the time discretization the predictor step is a euler semi implicit scheme and the corrector step is a modified crank nicolson scheme after analyzing other numerical schemes throughout the development process of the phyfire model its numerical resolution and its practical implementation see asensio et al 2023 this scheme has provided stable numerical solutions and a good balance between efficiency and computational cost the computational cost has been reduced by defining what we define as active nodes so that the equations are solved only in the neighborhood of the fire front and by adapting the numerical scheme and the corresponding code to parallel computing ferragut et al 2015 the spatial discretization varies depending on the precision level currently varies from precision level 0 corresponding to 50 m cell size to precision level 5 corresponding to 2 5 m cell size for the experiments performed in this work we have used precision level 4 5 m cell size for the study of the behavior of ros versus fmc in section 4 4 and precision level 3 7 5 m cell size for the simulation of the real case in section 6 given the initial values u 0 and c 0 defined by the initial conditions we set the value of the initial enthalpy for each node i of the spatial discretization depending on the initial nondimensional temperature u 0 as follow 8 e i 0 u i 0 if u i 0 u v u i 0 λ v if u i 0 u v given the values of the unknowns u n c n and e n at time step n we compute u n 1 c n 1 and e n 1 by means of the following steps 1 build the set of active nodes 2 compute the radiation heat 3 prediction step semi implicit euler method 4 update the set of active nodes 5 update the radiation heat 6 correction step modified crank nicolson method a node i is considered an active node if u i 0 and c i 0 1 or if it belongs to the radiation molecule associated to a node fulfilling the previous condition the radiation molecule is a set of nodes consisting of the node itself and the neighboring nodes defining the area affected by the radiation emitted by the node in question the numerical computation of the radiation term for each time step r n is fully described in ferragut et al 2015 we focus here on those numerical aspects of the algorithm that are new compared to previous versions specifically the predictor corrector finite difference scheme we must first mention the total discretization of the convective term of eq 1 that is carried out in each step of the predictor corrector scheme t e β v e 1 δ t e n 1 e n where e n e n x n and x n x x x t n 1 t n x β v δ t is the position at time t n of the particle that is at position x at time t n 1 predictor step the discrete equations in the burning area in the predictor step correspond to a semi implicit euler scheme 9 e n 1 2 e n δ t α u n 1 2 r n 10 e n 1 2 g u n 1 2 11 c n 1 2 c n δ t g u n 1 2 c n 1 where e n 1 2 u n 1 2 and c n 1 2 stand for the predicted value of e n 1 u n 1 and c n 1 respectively the basic idea is to handle the linear term implicitly and since the non local radiation term r n depends strongly on the temperature u n and on the solid fuel c n they are evaluated explicitly at time t n but even so eqs 9 11 continue to be non linear due to the multivalued operator g nevertheless the solution of this problem can be reduced to explicit calculations the multivalued operator in eq 10 is maximal monotone and hence its resolvent j μ i d μ g 1 is a well defined univalued operator for any μ 0 moreover the yosida approximation bermúdez and moreno 1981 of g g μ i d j μ μ is a lipschitz operator and the inclusion in eq 10 is equivalent for all μ 0 to the following equation 12 e n 1 2 g μ u n 1 2 μ e n 1 2 or 13 u n 1 2 j μ u n 1 2 μ e n 1 2 now rearranging eq 9 14 u n 1 2 1 α δ t e n 1 2 1 α δ t e n 1 α r n and taking μ 1 α δ τ in eq 13 we obtain 15 u n 1 2 j 1 α δ t 1 α δ t e n 1 α r n which it is equivalent to solve 16 α δ t i d g u n 1 2 e n δ t r n thus denoting æ n e n δ t r n the value of u n 1 2 is given by æ n 1 α δ t if æ n 1 α δ t u v u v if æ n 1 α δ t u v 1 α δ t u v λ v æ n λ v 1 α δ t if æ n 1 α δ t u v λ v 1 α δ t u p λ v 17 u p if æ n 1 α δ t u p λ v once u n 1 2 has been obtained we calculate e n 1 2 and c n 1 2 explicitly from eq 9 and 11 respectively 18 e n 1 2 e n α δ t u n 1 2 δ t r n 19 c n 1 2 c n 1 δ t g u n 1 2 notice that eqs 15 18 and 19 can be solved simultaneously in all active nodes so parallel computation can be used to reduce the computational cost indeed the loop over all actives nodes to compute u n 1 2 e n 1 2 and c n 1 2 has been parallelized using the api openmp chapman et al 2007 in the burned area only eq 7 needs to be solved whose discrete version using a semi implicit euler scheme is 20 u n 1 2 u n δ t α u n 1 2 r n that can be solved explicitly 21 u n 1 2 u n δ t r n 1 α δ t corrector step the discrete equations in the burning area in the corrector step correspond to a crank nicolson scheme 22 e n 1 e n δ t α u n 1 u n 2 r n 1 2 r n 2 23 e n 1 g u n 1 24 c n 1 c n δ τ g u n 1 u n 2 c n 1 c n 2 where we have approximate r n 1 by r n 1 2 computed in terms of u n 1 2 and c n 1 2 the estimations obtained in the prediction steps as at this point u n 1 and c n 1 are not known as in the prediction step rearranging eq 22 we have 25 u n 1 2 α δ t e n 1 2 α δ t e n u n r n 1 2 r n α as in the predictor step taking μ 2 α δ t the multivalued eq 23 can be written as 26 u n 1 j 2 α δ t 2 α δ t e n u n r n 1 2 r n α which it is equivalent to solve 27 2 α δ τ i d g u n 1 2 α δ t e n u n r n 1 2 r n α denoting now æ n 2 α δ t e n u n r n 1 2 r n α the value of u n 1 is given by æ n 1 α δ t 2 if æ n 1 α δ t 2 u v u v if æ n 1 α δ t 2 u v 1 α δ t 2 u v λ v æ n λ v 1 α δ t 2 if æ n 1 α δ t 2 u v λ v 1 α δ t 2 u p λ v 28 u p if æ n 1 α δ t 2 u p λ v again once u n 1 has been obtained we can update the enthalpy e n 1 from eq 22 and the fuel c n 1 from eq 24 29 e n 1 e n α δ t u n 1 u n 2 δ t r n 1 2 r n 2 30 c n 1 1 δ t 2 g u n 1 u n 2 1 δ t 2 g u n 1 u n 2 c n once more eqs 26 29 and 30 can be solved simultaneously in all active nodes so again the parallel calculation allows us to reduce the computational cost in the correction step in the burned area only 22 needs to be considered which can be solved explicitly u n 1 1 α δ t 2 u n δ τ 2 r n 1 2 r n 1 α δ t 2 3 fuel moisture content as a wildfire spread factor fmc has a direct relationship with wildfire ros being one of the variables together with wind that most influences it chuvieco et al 2009 mainly through the process of heating and subsequently evaporating the water in the fuel enabling it to attain combustion conditions this process involves the consumption of the energy released by the adjacent combustion fuel and requires time which reduces ros as moisture increases the laboratory and field fires analyzed in rossa and fernandes 2018b have evidenced that wind explains 61 9 of ros variance while dfmc explains the remaining 38 1 furthermore the damping effect of moisture on ros is not affected by the wind remaining constant rossa and fernandes 2017 there is consensus on the crucial influence that dfmc has on ros but there are discrepancies over the influence of lfmc finney et al 2013 which are manifested in theoretical propagation models rothermel 1972 albini 1976 stocks et al 1989 and are based on experimental trials contradictory results are obtained between field tests involving controlled burning where lfmc barely influences ros and laboratory studies in which there is a clear relationship between lfmc and ros rossa and fernandes 2018b consequently propagation models based on laboratory studies often use a weight of live and dead fuel based on their mass while those informed by field experiments consider only dead fuel rossa and fernandes 2018b this difficulty in detecting the influence of live fuel on ros in field tests is because it can be concealed in two different ways on the one hand live fuel maintains an almost constant moisture content throughout the year e g mature pine needles or other fuels in non mediterranean climates or on the other their variation follows a similar pattern to that of dead fuel measured as a monthly average many models are therefore based solely on dead fuel but it should be noted that this is only true if the moisture implicit in the live fuel albeit not accounted for remains within the same ranges as during the experimentation informing the model if for example fmc is much lower due to drought the model will no longer hold rossa and fernandes 2018a and will even pose a threat if used in prevention extinction operations experiments carried out in the laboratory using a mix of live and dead fuel seem to confirm that lfmc reduces ros in the same proportion as dead fuel without finding any significant differences between the two marino et al 2012 rossa and fernandes 2017 the decisive variable is therefore the moisture content weighted according to mass in dry weight regardless of whether it is alive or dead moreover live and dead fuels influence ros through the same mechanism that is through the absorption of the heat generated by the fire to raise its temperature and subsequently evaporate before the fuel can begin to burn this means the phenological state of the vegetation is not relevant but instead its moisture content rossa and fernandes 2017 there are indications however that the ignition mechanism of live fuel may be different as it may ignite before all the water content has evaporated finney et al 2013 rossa and fernandes 2018a after conducting a series of laboratory experiments with live fuel involving four common mountain species in portugal rossa et al 2016 conclude that there is a threshold for lfmc of between 50 and 70 although in another paper they report 100 rossa and fernandes 2017 whereby the influence the increase has on ros is small although present which is consistent with field observations viegas et al 2013 report a threshold in the proportion of dead fuel to live one below which the fire stops spreading ros 0 this value depends on the moisture content of both types of fuel and environmental conditions to explain the influence of fmc on ros several authors cheney et al 1993 burrows 1999 fernandes et al 2009 marino et al 2012 anderson et al 2015 rossa et al 2016 use an exponential function in decline where there is a coefficient k of decay of the curve that explains the effect of moisture in both laboratory and field experiments the function is as follows 31 r o s c e k f m c this function is usually integrated as a term into a general function of ros including other variables such as wind speed slope depth of the fuel bed or degree of cure of the herbaceous fuel table 2 shows coefficient k values for different studies with k values corresponding mainly to ros measurements in m min 1 part of the literature reviewed reports other versions of this exponential relationship including the effect of wind and terrain slope cheney et al 1993 burrows 1999 fernandes et al 2009 anderson et al 2015 propose the following equation 32 r o s c v b e k f m c where v is surface wind speed marino et al 2012 propose a linear model for wind as their experimental study is limited to two wind figures but they stress that this model has no predictive value for wind effect this study is of particular interest because it compares experimental data and predictions from the physically based model firetec as in this article with phyfire one of the problems mentioned in marino et al 2012 is the difference in scale between experiments and simulations with firetec this is not an issue in our study as phyfire allows computations at different scales by changing the precision level other authors also suggest that the impact of fmc upon the fire behavior was also affected by the wind conditions and substantiate this with numerical experiments morvan 2013 but do not propose a particular expression of this relationship the model suggested in fernandes et al 2009 describes ros in terms of surface wind speed and fmc and also slope terrain s through the following function 33 r o s c v b e p s k f m c 4 methodology 4 1 description of the experiments the spatial domain for the experiments is an even sloping surface with a manageable but realistic scale namely 6000 m 3000 m the fire focus is a line 25 m wide located at a distance of 1000 m from the lower short side wind and slope are taken in the same direction that is the fire front follows both the slope and the wind ros is computed as the slope of the linear regression line used to fit the position of the fire front in real time every five minutes from minute 10 to minute 60 measured lengthwise the ros calculation code provides controls to detect if the fire goes out or if it is approaching the limit of the domain avoiding unnecessary or unrealistic calculations uniform fuel distribution is considered for four types of brush and one type of grass selected from the comprehensive report arellano et al 2016 this is a photo guide that provides valuable information about the main forestry fuels in galicia in northwest spain and specifically the main physical features of fuels related to their fire behavior which are of particular interest to this study this guide provides a system for estimating the probable behavior of a wildfire that involves the fuels analyzed including flame height and ros under a range of scenarios three different slopes 0 20 and 40 and wind speed ranging between 0 and 60 km h 1 there is also information on the fuel load and its weighted height these data have allowed us to adjust the parameters and certain input variables in phyfire table 3 lists some of the properties of the five fuels selected the model corresponding to one of the 13 standard fuels according to the northern forest fire laboratory nffl classification system anderson 1982 the specific fuel from the photo guide arellano et al 2016 and certain characteristics such as fuel load or weighted height 4 2 flame height adjustment the first step involved adjusting the flame height sub model coefficients in eq 5 for each one of the five fuel types selected by a nonlinear least square approximation of flame height data obtained from graphics in the photo guide arellano et al 2016 for different slopes 0 20 and 40 and wind speed at intervals of 5 km h 1 from 0 to 45 km h 1 as regards the four types of brush flame height data for a wind speed of 0 km h 1 was not considered due to its high uncertainty conversely grassland analyzed in arellano et al 2016 report that the fire does not spread in conditions of no wind and no slope and flame height is zero so these flame height data should be included the adjustment has been performed using cftool the matlab curve fitting toolbox selecting a levenberg marquardt algorithm reaching a coefficient of determination r 2 0 95 in all cases table 3 contains the flame height model coefficients computed and the goodness of fit in terms of the coefficients of determination r 2 the goodness of flame height sub model eq 5 has been discussed in detail in asensio sevilla et al 2020 so here we only provide the value of the coefficient of determination r 2 to justify the adjustment without specifying other error metrics as this is not the aim of this study 4 3 parameter adjustment the second step is the adjustment of the three phyfire parameters namely the mean absorption coefficient a the natural convection coefficient h and the correction factor of the convective term β using these five fuel models and ros data from the photo guide arellano et al 2016 for the given ranges of wind speed and terrain slope the initial aim was to follow the same parameter adjustment strategy as in prieto et al 2015 where we first adjusted a and h for no wind and no slope fire data with β then being adjusted with all the other ros data for the given terrain slopes and wind speeds this strategy was shown to be effective in prieto et al 2015 and responded to the conclusions derived from the sensitivity analysis and parameter adjustment reported there where a and h did not vary significantly for different scenarios including slope wind and fuel moisture content always recording the same order of magnitude β became the most relevant input factor for ros strongly dependent on wind magnitude this strategy has proven inadequate here due to the incorporation of the new flame height sub model given by eq 5 an in depth study of the parameter adjustment process revealed an important change in the sensitivity of the model parameters a new global sensitivity analysis gsa of phyfire parameters showed a major change in the importance of both the mean absorption coefficient a and the correction factor of convective term β this new gsa was performed using the safe sensitivity analysis for everybody matlab toolbox pianosi et al 2015 with the elementary effect test saltelli et al 2008 the results of this gsa revealed the greater importance of the mean absorption coefficient a in all scenarios whereby the flame height sub model corrects the undue importance of the correction factor of convective term β although not the subject of this study the results of this gsa have been used here to design a better model parameter adjustment strategy we have fixed h in a previous adjustment using only no wind and no slope ros data obtaining a mean value of 10 605 j s 1 m 2 k 1 β has been selected in the order of hundredths β 0 02 its typical value prieto et al 2015 but with the aim of assuring the existence of an optimum value of the third parameter a in all scenarios the objective here is to verify whether phyfire simulations confirm the exponential function 31 assessing the isolated effect of fmc on ros as well as functions 32 and 33 when wind speed and terrain slope are considered it is therefore important to best fit the model to each scenario and choose the scenarios with the least uncertainty among all those previously analyzed a bisection method has been used to determine the value of the parameter a that equals the value of the computational ros with the experimental ros for each scenario the parameter adjustment has been implemented in c as phyfire in order to optimize the adjustment process as the evaluation of the model is the costliest part the total number of cases analyzed amounts to 74 corresponding to the five fuel types three terrain slopes 0 20 and 40 and five wind speeds 5 10 15 20 and 25 km h 1 except for grass and 0 slope where the wind speed of 5 km h 1 is not considered scenarios with a lower degree of uncertainty have been considered avoiding very low or very high winds in which the data are less reliable the results of this adjustment are shown in table 4 4 4 data analysis ros versus fmc once the model parameters have been adjusted for each scenario each wind speed terrain slope and fuel type phyfire has been evaluated by varying the fmc to test whether the simulated ros record an exponential decay as a function of fmc as in the empirical models reviewed fmc ranges from 3 to 244 using 17 values following an exponential distribution as previous observation of the results showed that high fmc produces few changes in ros this is the first positive observation of the good behavior of the phyfire model in this study the overall trend in the ros fmc relationship suggests an fmc threshold of 50 70 above which its response to increasingly higher fmc is weak rossa et al 2016 nonlinear regression analyses have been performed to summarize the behavior of ros for the simulation data in terms of fmc eq 31 fmc and wind speed eq 32 and fmc wind speed and terrain slope eq 33 for all the fuel types selected a routine has been built in matlab based on the function lsqcurvefit which solves nonlinear curve fitting data fitting problems in the least squares sense selecting the levenberg marquardt algorithm this matlab function returns the adjusted parameters the squared 2 norm of the residual and the residual array itself this allows easy calculation of the coefficient of determination r 2 and an overall indicator of goodness of fit as well as the adjusted coefficient of determination r a d j 2 a modified version of r 2 for the number of independent variables in the model r 2 1 i 1 n y i y ˆ i 2 i 1 n y i y 2 r a d j 2 1 1 r 2 n 1 n d 1 other deviation measures computed to evaluate the model s performances were the root mean square error rmse and the mean absolute error mae as well as their normalized versions the normalized root mean square error nrmse and the normalized mean absolute error nmae in order to relate the corresponding error measures to the observed range of the variable we also provide the mean biased error mbe to discover whether the models tend to overestimate or underestimate ros r m s e 1 n i 1 n y i y ˆ i 2 n r m s e r m s e y m a e 1 n i 1 n y i y ˆ i n m a e 1 n i 1 n y i y ˆ i y i m b e 1 n i 1 n y ˆ i y i the 95 confidence intervals have been calculated for estimating the coefficients of the three models and they are all significant although the cftool used previously for adjusting the flame height eq 5 can be used for eqs 31 and 32 it cannot be used for eq 33 because it depends on three variables fmc wind speed and terrain slope cftool provides a flexible interface for fitting curves and surfaces to data but not for more than two independent variables the use of the lsqcurvefit function is more flexible for computing the error metrics and upholds uniformity in the analysis of the three models phyfire states all data in si units although in the fitting of eqs 31 32 and 33 ros has been measured in m min 1 as in the literature reviewed for obtaining values of the exponential coefficient k comparable to those found in the references fmc is measured in and wind speed in m s 1 5 results and discussion the exponential relationship between ros and fmc described by eq 31 explains on average 80 of the cases in all the scenarios with better results in cases with steeper slopes and higher wind speeds table 5 shows fitted values and all the metrics computed to assess the goodness of fit for each one of the five fuel types and an intermediate scenario of 20 slope and 20 km h 1 wind speed no significant differences are observed between the chosen intermediate scenario and the mean values of all scenarios all the fuels record a similar performance with fuel 5 having a worse r 2 but better mae the negative but small values of the mbe imply that the model slightly underestimates ros values of pre exponential factor c are not shown because they vary considerably depending on wind speed and terrain slope as expected the pre exponential factor of eqs 32 and 33 reflects this behavior fig 1 shows the predicted ros values for all the fuel types and the scenario selected for table 5 namely 20 terrain slope and 20 km h 1 wind speed the behavior of the different types of fuels can be appreciated ros values are in full agreement with the photo guide data arellano et al 2016 eq 32 incorporates the effect of wind speed achieving a better fit explaining on average 90 of cases for all the slopes and fuel types in terms of r 2 and also r a d j 2 so the improvement in fit cannot be attributed to increased degrees of freedom rmse and mae increase with the slope but this is due to higher values of ros however the normalized versions of these error measures nrmse and nmae remain in the same range for all slopes and fuel types table 6 shows fitted values and all the metrics computed finally eq 33 which also incorporates the effect of the slope achieves an optimal fit with r a d j 2 0 95 for almost all the fuel types except grassland fuel type 1 with r a d j 2 0 94 probably due to fewer data and fuel type 5 r a d j 2 0 936 the worst performing brush in all the settings as can be seen in table 6 coefficients p and k reflecting the effect of slope and fmc respectively record similar values for all the fuels as in the experimental cases appearing in the refs fernandes et al 2009 the exponential coefficient of wind term records a similar value for grassland fuel type 1 and brush as well as the pre exponential factor c which is explained by the different fire behavior of grasslands and brushlands the normalized versions of the error measures nrmse and nmae maintain acceptable values as does mbe eq 33 slightly overestimates the ros for grassland fuel type 1 and slightly underestimates the ros for brushlands see table 7 eq 31 is fulfilled for several fuel types wind speeds and terrain slopes and the value of the coefficient k obtained also remains within the same range for eqs 32 and 33 which considers wind and slope and it is within the limits set by the studies that have evaluated it certain discrepancies of a quantitative nature that can be observed in the values obtained for the exponential factor and the ros may be due to the fact that the model parameters have been adjusted based on the data available at arellano et al 2016 constrained to an fmc of 6 the radiation absorption coefficient a can be sensitive to fmc and wider flame length and ros data would provide a more reliable fit of the model parameters and would reduce the observed discrepancies 6 a real example the real example used to illustrate this study occurred in an area of the autonomous region of galicia since the analysis carried out corresponds to fuels typical of this area of north western spain this case has already been used in two previous publications prieto et al 2017 asensio et al 2021 where details of the fire extension the characteristics of the affected area and the meteorological conditions can be found however we summarize here the most relevant data this wildfire occurred in osoño orense at 15 25 local time on august 17 2009 burning 224 ha of pinus pinaster shrubland and grassland ambient temperature was above 30 c and humidity below 30 the wind was increasing from 2 m s to almost 5 m s the fire developed during the afternoon and in the areas most exposed to solar radiation western face the fire spread more rapidly this is precisely the feature that we have sought to capture with this new simulation the fuel in areas more exposed to solar radiation has lower moisture content and this affects the fire behavior in these areas we have simulated four different scenarios taking into account some of the actions of the firefighting teams in particular three large firebreaks on the right flank without these actions with a constant fmc throughout the simulation domain and with a variable fmc depending on the solar radiation received reducing it by 5 in the west facing areas the simulation of each scenario involved about 150 s of computing time on a laptop computer equipped with an intel i7 processor dual core 3 50 ghz and 16 gb of ram for a rectangular simulation area of 3320 m 2745 m and a resolution of 7 5 m for the finite element mesh fig 2 shows the result of the simulation with the phyfire model of the osoño fire during the first four and a quarter hours assuming that the fuel moisture is spatially uniform and without considering the actions of the firefighting teams in fig 3 we have considered the effect of solar radiation on the west facing areas reducing humidity by 5 which shows how the fire advances more rapidly and affects a larger area in these areas fig 4 shows how the fire lines designed by the firefighters were effective in preventing the fire from reaching the nearby population even in the worst case scenario in terms of fmc this scenario is consistent with the report of the firefighting teams which designed three firebreaks to prevent the fire from reaching the nearest population nevertheless the actions of the fire truck water tanks on flanks during the last part of the fire were not considered in the simulation this may explain why our simulation exceeds the perimeter 7 summary and conclusions this study has explored the sensitivity of fire ros and certain environmental conditions mainly fmc but also wind speed and terrain slope in numerical simulations performed by the simplified physical phyfire model the results are qualitatively compared to field and tunnel based experiments and with others numerical experiments found in the literature the conclusion is that the phyfire model is highly consistent with an exponential decay of fire ros compared to fmc alone and also in the presence of wind speed and terrain slope phyfire therefore performs as expected with respect to fmc according to the experimental models reviewed with a high degree of accuracy in all the scenarios analyzed this study therefore proves that the innovative and original way in which phyfire considers the effect of fmc through a multivalued operator is highly significant we have also observed the existence of an fmc threshold above which the response of ros to increasingly higher fmc is weak as in the experimental studies overall this work shows the expediency of studying specific aspects of complex simulation models to improve their understanding with a view to increasing their overall efficiency the development of wildland fire simulation models is a very complex task and their applicability is a matter of discussion alexander and cruz 2013 one way to tackle this challenge is to conduct a detailed analysis of specific aspects that allow for the model s overall improvement updated information on time and space for fmc will provide better simulation results as evidenced by the real fire simulation therefore in order to improve the accuracy of fire spread simulation it would be highly desirable to use all the technology and new methods at our disposal to enhance the fmc information sharples et al 2009 miller et al 2022 quan et al 2017 software availability name of the software phyfire developer luis ferragut m isabel asensio j manuel cascón diego prieto contact information sinumcc usal es program language c neptno openmp software availability http sinumcc usal es declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this research has been partially supported by the spanish ministry of economy and competitiveness mineco through project pid2019 107685rb i00 the european regional development fund erdf the department of education of the regional government the junta de castilla y león spain grant contract sa089p20 and the european union s horizon 2020 research and innovation framework programme under grant agreement id 101036926 
25412,global climate change has led to large fluctuations in lake levels in recent years as meteorological and hydrological parameters have changed and water use has been intense water scientists use various computer models to analyze the hydrological variables recorded in the past and make projections for all future scenarios based on the technological progress six different types of algorithms were studied in this review to predict the water level in lakes the prediction results show that deep learning dl has the highest accuracy in terms of the evaluation metrics since the artificial intelligence ai field is still emerging and continue to improve this study highlights better comprehension of current applications and the problems that need to be investigated more for lwl forecasting techniques it reveals that the studies mainly focused on lakes either in usa or china and there is room for improvement for other locations that are scarcely investigated keywords lake water level reservoir water level prediction forecast time series data availability no data was used for the research described in the article 1 introduction a global warming trend is expected to result in significant changes in main hydrological cycles including changes in amounts and spatial distributions of precipitation evaporation in the water surface transpiration in watersheds as well as domestic water consumption intensity chen et al 2020 zappa et al 2014 ahn et al 2016 lake s water levels lwl are most sensitive to variability and changes in climate because changes in lwls play a key role in affecting the quantity and quality of the lake water resources and the watershed ecological environment it is expected that the frequency and severity of extreme climate events will increase and enhance floods and droughts in many regions deteriorate natural water quality which needs prompt decision action plans both for water budget and quality management valizadeh et al 2014 voulanas et al 2021 the water levels in many natural lakes and reservoirs are progressively decreasing in the last decades most recent studies claimed that climate change and water consumption uptrends nourani et al 2021 would cause water levels to continue to decline this scenario spurred serious concern since freshwater lakes and reservoirs are key features of the water supply infrastructure industrial domestic and agricultural activities within the region depend directly on reliable water delivery in general the quantity and quality of lake water resources are intertwined with the input output balance and climate fluctuations shrestha et al 2012 plisnier et al 2018 temporal and spatial changes in lwls are a particularly reliable indicator of changes in catchment water balances soja 2013 the dynamics of the lake water budget can act as sentinels for regional water cycles by displaying signals that combine climatic and landscape pressures and show significant changes in these variables williamson et al 2009 adams and sada 2014 moreover climate change significantly impacts lakes water levels directly and indirectly through changes in atmospheric drivers such as precipitation and evapotranspiration the impacts of climate change on lakes are likely to increase in the future taner et al 2011 byun and hamlet 2018 therefore the potential influences of climate change on lake hydrology are of paramount importance for managing drinking water systems in terms of enhancing and protecting the resilience of the lakes and supporting interdependent human and ecosystem communities lwl regimes are influenced by climate hydrology and water consumption actually in recent years fluctuations of the lwls are influenced by changes in precipitation and evaporation bartolai et al 2015 and these water bodies have been significantly affected by global warming and climate change finlayson et al 2013 furthermore lakes are under increasing pressure due to accelerating water consumption in the dry season coops et al 2003 haghighi et al 2014 yuan et al 2015 1 1 research significance climate change significantly impacts the natural hydrological cycle and amplifies water scarcity haddeland et al 2014 fernandes et al 2011 santos et al 2014 the effects of meteorological parameters and water consumption on patterns of lwl variations are of fundamental importance to quantifying climate change s ecological and economic risks the responses in lwls can be used as indicators to assess the overall regional hydrological impacts of climate change water consumption trends and land use modifications haghighi and klove 2015 coops et al 2003 yuan et al 2015 the literature background indicates an increasing concern to investigate lwl and reservoir water level rwl prediction especially considering the recent climate change effects this increase can also be observed in the number of publications in the last 15 years see fig 1 the number of publications in fig 1 indicates a drastic increase in studying lwl and rwl prediction especially for the years 2020 and 2021 one of the reasons to study lwl and rwl prediction may be due to climate change effects and water scarcity in recent years however the study area differs in terms of geographic locations where the effect of climate change has the most impact on demographics which can be seen in fig 2 below most studies focused on lakes in either china or usa and usa canada border locations there are also studied lakes in other parts of the world in the literature the 17 other studies focused on europe while 13 investigated asia reservoirs the studied areas in africa are 9 in australia 3 and in south america 2 lake levels were modeled the number of study areas in fig 2 is higher than the number of studies since one study may explore more than one lake or reservoir to compare them in addition although the time span of studies in the literature is 15 years 2006 2021 the period of datasets in studies differs in terms of collection techniques and usually higher than 15 years the scholars publish their articles and conference proceedings in well respected journals and conferences the percentages in fig 3 indicate the rate of articles comparing whole studies in this systematic literature review studies the most popular journal for these types of studies is water in addition journal of hydrology regional studies and plos one also get a high amount of studies other studies are almost equally represented in different journals in mostly water related areas the figure results reveal that listed journals emphasize lwl and rwl prediction related studies and are most likely to embrace related fields in their publications scholars mostly decided to predict future lwl by using artificial neural network ann other most popular algorithms consist of support vector regression svr random forest rf and artificial neuro fuzzy inference system anfis fig 4 shows that there is no dominance or consensus of the algorithm that is used by scholars in the literature in addition the promising results of neural network nn based prediction models attract scholars to build prediction models using these algorithms and deep learning methods yuan et al 2022 almost every one of three studies used root mean squared error rmse as an evaluation metric as it can be seen in fig 5 the second and third most popular evaluation metrics in literature are coefficient of determination r2 and mean absolute error mae although these algorithms are the most popular among scholars not all of them stick to using only one evaluation metric rather they evaluate the results mostly more than one evaluation metric one of the reasons not to stick to one evaluation metric may be to enhance the credibility of evaluation metric results when the evaluation metrics are compared in terms of ai models in literature results it can be seen that rmse and mse take the majority for mathematical and equation based models ann and fuzzy logic r2 is mostly selected in regression and deep learning models and never used in fuzzy logic models another aspect is that less than 10 of researchers used mape mae as an evaluation metric for mathematical and equation based models see fig 6 1 2 research objectives there have been various attempts to prevent any kind of drought or flood risk that may harm society in a potential economic downturn basically previous analysis of long term data on water level fluctuations of a watershed over time can be used to assess the effects of climate variability and anthropogenic activities on water resources liu et al 2021 there are various solutions to prevent these types of risks ehteram et al 2021 ethteram et al 2018 but the solutions are only effective if they are taken at the right time thus the prediction of water levels is important to get efficient and effective counter actions for any kind of drought and flood risks the results of the earlier attempts to anticipate lwl are undoubtedly encouraging especially in light of the fact that in comparison to conventional methods applications of ai models for the forecasting of lwl are still in their infancy yet there are still a lot of uncertainties and difficulties in both the application of the models and the interpretation of the results how for instance may input combinations be chosen to increase model performance which algorithm is more trustworthy how can model performance be assessed this is largely because we currently have very little understanding of statistical and artificial intelligence models as these ideas and techniques are continually being refined these are currently leading to two different perceptions and actions one is that there has been a notable increase in the use of machine learning and deep learning models for water level forecasting in lakes and the other one is that there has been a rise in skepticism regarding studies that have used these models and the results that have been reported in order to better comprehend and communicate the development of the approaches successful applications of them and the problems that still need to be overcome it is necessary to analyze the applications of models for lwl forecasting that are already accessible this is the first attempt at conducting slr for lwl forecasting other review studies focus solely on machine learning models and neglect other statistical models zhu et al 2020 sannasi chakravarthy et al 2022 in addition unlike other review studies this study includes regional input and evaluation metric comparisons in order to analyze algorithms effectively in this slr experimental prediction models have been analyzed based on scientific advancement and this review gives an overview of the models efficiency in order to integrate prevention techniques with prediction models with respect to selected meteorological and hydrological parameters although prediction and prevention techniques are two different methodologies they are interrelated to each other the risk prevention techniques could be handled more efficiently in terms of budget time and other scarcity issues e g water with the help of lwl and rwl prediction techniques 2 related work freshwater lakes are subject to substantial annual variations in storage levels due to seasonality in catchment inflows and lake outflows valizadeh et al 2014 in this context climate change has been a topic of interest for many researchers to predict water level fluctuation and analyze the reasons for water budget and water quality changes for instance mendoza et al 2006 studied the causes of cuitzeo lake s changes in mexico they used statistical models to link water level fluctuations to rainfall and temperature for this purpose the time series was used motiee and mcbean 2009 also found that climate change had been caused a reduction of 50 cm in the water level of superior lake located in north america which is the highest amount between 1928 and 2009 they also found that the lake s water level has decreased by 1 cm every year using these results they found that these changes can indicate signs of climate change phenomena in the studied area zilefac 2010 showed that by reducing rainfall and increasing temperature the average depth of chad lake has fallen from about 7 m to 1 5 m njaya et al 2011 stated that the average depth of chilwa lake decreased from 0 to 12 m between 1960 and 2000 huang et al 2011 considered the temperature and precipitation the most critical factors affecting fluctuations of cottonwood lake in the united states mekonnen et al 2012 pointed out that the depth of naivasha lake decreased by 4 m between 1965 and 2001 using several index analyses palynology sedimentology chemical composition and paleontology and geomorphologic processes of the eastern poland basin zawiska et al 2015 claimed that weather has been the primary motivation for change in aquatic and terrestrial ecosystems salih et al 2019 predicted evaporative losses from reservoirs to contribute to the literature from a different perspective previous studies regarding historical and projected future responses to climate change focus on the lake s catchment and have drawn a number of consistent conclusions historically several hydrological models such as finite volume 3d ocean model fvcom abbaspour et al 2012 finite element subsurface flow feflow taminskas et al 2013 and precipitation runoff evapotranspiration hydrotope prevah zappa et al 2014 have been used to explore historical climate and land use effects on water bodies and reported the role of the climate variability is stronger than the land use changes similarly artificial intelligence ai models liang et al 2018 damova et al 2020 aslan et al 2022 ebtehaj et al 2021 have shown an extensive ability to model the lake river system or streamflow water levels without the need for experimental apparatus and complex hydro physical models based on physical principles and mathematical equations chen et al 2020 mtilatila et al 2020 a good search of existing literature shows that these investigations included the applications of the ann model in spite of their successful applications several research works have shown a wide range of forecasting accuracies that in fact have varied with respect to the geographic features of the tested sites as shown in earlier studies deo and şahin 2016 prasad et al 2017 where models tested at the study sites with different climatic and hydrological patterns were compared moreover the search for a one size fit it all forecast model for solving hydrological modeling problems remains an open contribution to be made to the existing literature since no universal model currently exists for all types of climates and regions mishra and singh 2011 in view of the scientific advancement the present study reviews the historical achievements and applications of the latest learning based models for lwl forecasting all the models are reviewed in the literature and because of their popularity these models are frequently used in the studies 1 ann 2 support vector machine svm 3 anfis 4 hybrid models by integration of wavelet analysis and ann artificial neuro fuzzy inference system and svm models 5 extreme learning machine elm and 6 deep learning dl there are several challenges before developing an lwl or rwl model mostly due to the nature of dataset generation among the challenges how to determine the input combinations to improve model reliability and how to split the available datasets to capture better water level dynamics under the impact of climate change and the influence of extreme events are discussed 3 methodology the present state of knowledge of lwl prediction and forecasting models was assessed using a systematic literature review slr kitchenham et al 2009 by carefully establishing search and inclusion exclusion criteria the slr accurately assesses the existing literature it is also transparent and repeatable the slr begins with the discovery of data sources and the establishment of search criteria after that publications are selected or omitted from the final sample based on criteria relevant to the study s goal finally data of interest is collected from complete text from the sample followed by analysis and a report of the findings even though a considerable sample was retrieved from the slr it may not pick up all important references in other cases specific references were added for debates although not appearing in the slr results 3 1 research questions at the beginning of the review phase there has been three research questions determined in the following order rq1 what are the models that are used for the prediction of water level in a reservoir rq2 what types of machine learning models are utilized to anticipate a reservoir s water level in addition what are the categorization of statistical models that are used in the prediction of water level in a reservoir rq3 what types of deep learning models are utilized to forecast reservoir water levels 3 2 defining the review protocol the research questions are established considering the research scope and the keywords for the systematic search are extracted in the title abstract or keywords at least one occurrence from these keywords was extracted lake and water and level and predict reservoir and water and level and predict lake and water and level and forecast and reservoir and water and level and forecast at initial studies were refined with certain inclusion and exclusion criteria to narrow them down for the first phase only published studies from journals book chapters and conference proceedings that have open access were included in this study on the other hand this study excluded studies that were written other than english for the whole paper regarding the second and third phases a quality assessment checklist qac was prepared to assess eligibility for individual studies the checklist items include a is the study about water level prediction b is there any reservoir in which the water level was predicted c does the research paper reveal the methodology 3 3 inclusion and exclusion criteria there are additional criteria for study selection after defining the review protocol to select relevant topics with the aim of the study the three criteria that are used in the study are as follows i the study must be related to a natural or artificial freshwater lake i e exclusion of seas rivers groundwater or related environments or purely conceptual models ii the research model must be on lwls fluctuations or dynamics e g exclusion of studies that modeled floods risks drought conditions economic impacts human population or other animals and iii the models must be capable of forecasting or predicting lwls and validating and or explaining observed data qualitatively 3 4 conducting the review the systematic search was conducted on october 3 2021 using scopus sciencedirect and web of science databases stage 1 produced 1470 papers when the qac was applied to the results for the second and third phases 269 and 72 articles remained respectively fig 7 4 results and discussion 4 1 statistical models for lwl and rwl prediction the slr process revealed different types of statistical models and techniques used in predicting lwls ranging from hydrodynamic models to regression models this study grouped these techniques under four categories hydrodynamic models water balance models wbm regression models and mathematical and equation based models out of a total of 47 statistical models 34 used only one technique whereas 13 used two or more methods together 4 1 1 regression models 4 1 1 1 conceptual background linear regression lr s and non lrs are the core of many machine learning methods many researchers have used simple regressions to predict lwl across many lakes in a specific region and these studies were classed as regression models in this systematic literature review 4 1 1 2 bibliographic review table statistical models zhu et al 2017 developed an lr model to forecast the lake chad water level prediction located at nigeria cameroon niger and chad border the model forecasts lake water balance lwb by using direct precipitation evaporation the inflow of the lake from the chari logone river system and outflow from the lake which includes both the discharge of the surface water to the northern basin and the seepage of the lake in the form of groundwater discharge as input variables similarly lin et al 2015 explored the combination of the routing application for the parallel computation of discharge rapid model noah multiparameter land surface model noah mp lsm model and multiple linear regression mlr for lake level prediction task by using inflow rate from the main stream and tributaries as simulated by rapid the outflow rate in m3 s p t precipitation and evaporation in addition hu et al 2018b studied the prediction of lwl with the svr model by disregarding the rest and only using three years of daily flow rate and outflow discharge data garcía molinos et al 2015 investigated bayesian harmonic regression models bhrm to predict lwl in natural irish lakes located in ireland the models forecast lwl by using level water level again the same approach is pursued by m dawam and ku mahamud 2019 using rainfall parameters and changes in rwl with the sliding window technique on the other hand mohammadi et al 2020 used svr and support vector regression grey wolf optimization svr gwo prediction models with similar input combinations with historical lwls castillo botón et al 2020 proposed svr and gaussian processes gp for belesar dammed rwl prediction the study set the output parameter as dammed water level which is measured in hm3 and tries to predict this level by using height m and flow m3 s upstream and on the tributaries and also the precipitation amount mm as input parameters kenda et al 2020 also used similar input parameters raw hourly weather forecast data precipitation intensity precipitation type temperature cloud cover dew point humidity pressure and daytime hu et al 2018a s approach is to use an svr model with only precipitation data liu et al 2017 employed a multi objective decision model modm and statistical regression predictive function srpf to predict water levels of the hongjiadu reservoir which is based in china the dataset was accumulated annually and the dataset size is 63 the output of the model is rwl while the inputs are year start water level inflow power output and power generation several evaluation metrics are used in this study degrees of confidence doc amount of forecast factor aoff sum of squares ss residual sum of squares rsos regression square sum rss multiple correlation coefficient mcc residual standard deviation rsd and mean relative errors mre the results indicate that there are two methods to manage water resources out of their unpredictable fluctuations one method is statistical regression which applies when there is a steady inflow another method is the modm which applies when there is a serious contradiction sapitang et al 2020 used boosted decision tree regression bdtr decision forest regression dfr bayesian linear regression blr and neural network regression nnr to predict lwls in malaysia the dataset contains 12 531 data rows which were collected daily the models predict lwl with rainfall and water level in addition rainfall water level and sent out data were selected as another set of inputs the performance of the models was evaluated with mae rmse r2 residual absolute error rae and residual standard error rse as metrics the results highlight that all models can be used to predict lwls however the blr model outperformed other models according to evaluation metrics bonakdari et al 2019 proposed minimax probability machine regression mpmr relevance vector machine rvm gaussian process regression gpr and elm models to use in their lwl prediction study the case study is applied in a lake located on the usa canada border with a surface area of 2402 km2 the dataset contains 1152 data rows estimated from 96 years of monthly accumulated data the models predict lwl by using lwl with lags as the input variable the performance of the models is evaluated by using r2 mae rmse legates and mccabes index lmi and refined willmott s index rwi and nash sutcliffe coefficient nsc as metrics it can be determined from the results that all models can predict lwls significantly among the models used in this study mpmr has the highest prediction performance 4 1 1 3 comparison and combination the first regression model on lwl forecasting goes as early as 2015 in which the study focuses on a mechanistic model for lake level changes llc and combined with a land surface model to improve the accuracy of results lin et al 2015 on the other hand garcía molinos et al 2015 emphasizes the importance of the seasonality effect when predicting water level dynamics zhu et al 2017 attempted to predict a change in water volume in chad lake by using multiple remote sensing observations a remarkable finding of the study indicates that while most of the water losses are directly related to evaporation in the entire lake the southern pool losses are related to the outflow previous regression models never attempted to compare the model with other prediction models liu et al 2017 used two models for lwl prediction modm and the statistical regression function they found statistical regression function model is advantageous when the dataset size is large and inflow to the lake is steady while modm could be best used in cases when there is a serious contradiction in reservoir function hu et al 2018a are the pioneers for lwl prediction with only one external parameter as precipitation the authors found that with only precipitation data the water levels can be predicted as well as prevents overestimation and underestimation in terms of quantity and magnitude in the same year the same authors conducted a second experiment for the same lake with other input parameters they found that the most important input parameter for lwl prediction is historical lwl data similar to the hu et al 2018a s study m dawam and ku mahamud 2019 decided to use precipitation as the only external input variable but they got the best result with the combination of precipitation and historical lwl data they also found that the mlr results highly depended on the dataset s normalization on top of these studies sapitang et al 2020 proposed two scenario based prediction models one includes precipitation and lwl other one includes precipitation lwl and discharge as inputs they also tested the models with different time horizons from one day to seven days the authors found similar results with previous scholars that only precipitation as an external input is a good predictor for lwl castillo botón et al 2020 proposed prediction models for both short term and long term periods in the short term they found that upstream and tributaries flow are highly effective parameters whereas precipitation and dam outputs are less relevant for the prediction for this reason this study contradicts with findings of hu et al 2018a and m dawam and ku mahamud 2019 s studies that got the best prediction result with precipitation lwl and only precipitation data kenda et al 2020 worked on the most comprehensive regression study with 21 models to predict only one lake water surface and water level therefore only this study could give the finding that batch regression algorithms perform better than incremental regression algorithms mohammadi et al 2020 experimented similar to garcía molinos et al 2015 s study by only using lwl as an input parameter however instead of focusing on the seasonality effect they rather focused on the time lag effect on lwl prediction they found that it gives the best performance only by using either 1 2 3 or 4 periods of time lags regression based models are presented in table 1 4 1 2 mathematical and equation based models 4 1 2 1 conceptual background mathematical and equation based models are usually derived by scholars in terms of their experiences with the subject matter and historical data although the researchers developed their own equation in every study some of the studies share the same name such as the wbm however even though the model name is the same the input parameter differs in terms of study 4 1 2 2 bibliographic review table statistical models dinka 2020 used the lake capacity curve equation to predict the lake basaka water level in ethiopia the study predicts lwl using 22 years of monthly lake stage area and volume data the volume of water was used in li et al 2013 s study as water depth with bands to predict adjusted water depth gillies et al 2015 selected input parameters as a change in lake level and tree ring reconstructed change in lake level on the other hand hirsch et al 2014 predicted water level fluctuation using depth volume and slope of the reservoir basin as input parameters paynter and nachabe 2011 investigated on generalized extreme value gev model to predict lwls using maximum and minimum lake levels the flood and drought stages jahani et al 2016 analyzed chance constrained cc optimization model with similar parameters such as index of season random inflow to reservoir release from reservoir and reservoir storage at the beginning of the season myakisheva et al 2021 on the other hand took only historical lwls into account to predict future lwls montroull et al 2013 studied the variable infiltration capacity vic hydrology model to forecast iberá wetlands water levels in argentina by using only 10 years of daily lwl data taminskas et al 2013 used a similar volume based input parameter as a change in water balance due to climate change variables in their study morgan et al 2019 investigated the wbm with their parameters as annual average runoff volume equilibrium pit lake surface area predicted equilibrium water level and wbm equilibrium water level paul et al 2019 developed a two dimensional depth averaged model for lake victoria water level prediction with inputs and outputs based parameters of the lake into account they used 51 years of monthly evaporation precipitation river inflow and outflow data abbaspour et al 2012 also predicted lwls with precipitation evaporation river and runoff discharge as input variables talsma et al 2016 studied on non linear model predictive control model while selecting the inflow of the ijssel river the inflow of the vecht river exchange with the regional water systems rainfall and evaporation forecast as input variables bertone et al 2017 predict the storage volume of the reservoir using rainfall main river inflow and gross volume variation as input variables hussain et al 2021 developed a gravity recovery and climate experiment grace prediction model which is applied in indus basin in pakistan the dataset used in this study has 78 data rows accumulated from 13 years of bimonthly data including evapotranspiration and precipitation as input variables guinaldo et al 2021 used the mass lake model to contribute to the literature on the lwl prediction area with over lake precipitation over lake evaporation runoff drainage over the runoff mask inflow entering the lake from the tributaries lake outflow and the contribution of the lake groundwater fluxes as an input magyar et al 2021 proposed dynamic factor analysis dfa to predict neusiedlersee lwls using evapotranspiration and precipitation data jiang et al 2021 employed discrete wavelet transformation dwt inarx setting discharge and precipitation as input variables haque et al 2021 used the 2d hydrodynamic model to predict the lwl with discharge data li et al 2016b developed a reservoir hydrological model to predict reservoir volume using gauged surface inflow ungauged surface inflow total outflow surface area direct precipitation evaporation net groundwater source and unit conversion factor croley 2006 on the other hand used 37 years of monthly precipitation runoff and evaporation data as input haddout et al 2018 applied the fvcom model for water level prediction in aguelmam sidi ali lake with input parameters such as precipitation evaporation and runoff discharges rodríguez rodríguez et al 2012 explored the prediction model of the water budget conceptual model wbcm with direct precipitation onto the lake s surface groundwater flow base flow in streams and subsurface runoff zappa et al 2014 employed the prevah model to assess surface water level using precipitation evaporation soil moisture litter moisture water temperature groundwater level runoff and snow water equivalent as input parameters person et al 2007 applied a three dimensional surface water groundwater model swgm with 50 years of monthly runoff evapotranspiration infiltration streamflow and groundwater hydrodynamics data voulanas et al 2021 used the feflow model in order to forecast the water level for the kastoria basin located in western macedonia greece the input variables of the dataset include rainfall surface runoff evaporation and discharge or the flow volume at the basin s outlet chen et al 2020 investigated the wbm based on gr4j to forecast water levels in thirlmere lakes national park with precipitation runoff and evapotranspiration data mtilatila et al 2020 predicted water level change using precipitation and evaporation as variables lastly ricko et al 2011 predict lwl by using the freshwater flux variable as the main input with rainfall being the main contributor to observed differences in given model versions in the tropics region lofgren and rouhana 2016 applied the large basin runoff model lbrm in their study to forecast laurentian great lakes water levels located between the usa canada border the dataset in this study contains 684 data rows estimated from 57 years of monthly data the model forecasts lwl with temperature adjustment energy adjustment priestley taylor and clausius clapeyron as input variables the performance of the model was evaluated with statistical significance according to the results based on evaluation metrics the water level can be predicted with a significance level of 99 98 the extreme high value of significance brings extra sensitivity of et to air temperature li et al 2014 employed a spatiotemporal pattern model for the lwl prediction area in their study the study takes place in tibetan lakes located in china the dataset consists of 14 600 data rows estimated from 40 years of daily accumulated data the study forecasts lwl change with mean temperature precipitation solar radiation wind speed and vapor pressure as input variables the model s performance was evaluated with the coefficient of correlation r as a metric in the results permafrost degradation contributes to the available water prediction in the region a lot while glacier melt has minimal effect fry et al 2020 explored the lwl prediction study by focusing on the net basin supply nbs model for laurentian great lakes located between the usa canada border the number of observations is not given for the dataset in this study however the study dataset output is determined as a seasonal water budget and the input is not explicitly given the temporal of the dataset consists of three periods which are 1 3 and 6 months the performance of the model was determined using heidke skill score hss the authors claim from the results that monthly mean water levels can be predicted with a 6 month lead time however the model interpretation requires some skill and related operator selection to improve model forecast results ouni et al 2020 proposed the delft3d flow model in order to predict and simulate lwls in ichkeul lake tunisia the dataset for the model consists of lake bed roughness and lwl data however the size of the dataset is not given it predicts lwl by taking lake bed roughness into account the evaluation metric to measure the performance of the delft3d flow model is rmse according to the results that are generated from the rmse score of 0 027 the delft3d flow model can predict the water level well cai et al 2016 developed a wbm to use on hulun lake in china the surface area of the lake is around 2000 km2 the dataset contains 372 data rows accumulated out of 31 years of monthly data in the model lwl is forecasted by taking into account precipitation mean temperature wind speed relative humidity and sunshine duration from 1960 to 2014 river discharge and evaporation the performance of the model is tested by calibration in the results it can be inferred that the model can forecast fluctuations in lwl ahn et al 2016 proposed a water balance network model wbnm and a watershed scale hydrologic model wshm soil and water assessment tool swat for the lwl prediction subject the study was done in the geum river basin in south korea the basin has a surface area of 9645 5 km2 the dataset size is 2190 estimated from 6 years of daily data the model predicts dam water level dwl by taking air temperature precipitation relative humidity wind speed and sunshine hours as input variables the study used the r2 the nash sutcliffe efficiency nse and the rmse as evaluation metrics the results show that water shortage is expected as 38 2 in the 2040s 38 2 in the 2080s for representative concentration pathway rcp 4 5 scenario and 21 3 in the 2040s and 22 1 in the 2080s for rcp 8 5 scenario 4 1 2 3 comparison and combination out of all mathematical models some scholars favored the wbm model which enhances the model s accuracy performance the first attempt to conduct wbm was done by ricko et al 2011 by using different rainfall data for varying input parameters keeping other model input parameters constant rodríguez rodríguez et al 2012 on the other hand conducted the model by adding groundwater flow baseflow in streams and subsurface runoff in addition to rainfall data as input parameters ahn et al 2016 used a daily dataset for their model consisting of air temperature precipitation relative humidity wind speed and sunshine hours as input parameters cai et al 2016 had a limited dataset with only 372 data rows but were able to predict lwl with precipitation mean temperature wind speed relative humidity and sunshine duration river discharge and evaporation as input parameters morgan et al 2019 s study is the only study that never used rainfall as an input parameter other scholars predicted llc with precipitation runoff and evapotranspiration as input parameters chen et al 2020 mtilatila et al 2020 scholars generated other models as specific equational models although different models have common input parameters some developed specific parameters only for their models gillies et al 2015 used tree ring reconstructed change in lake level as an input variable while li et al 2014 used vapor pressure ouni et al 2020 on the other hand decided to use lake bed roughness as one of their input variables mathematical and equation based models are presented in table 2 4 2 machine learning models for lwl and rwl prediction the slr process also produced machine learning models to predict lwls in a range between ann and elms this study grouped these techniques under four categories ann decision tree fuzzy logic and other models out of a total of 23 machine learning models 12 used only one technique whereas 11 used two or more techniques together 4 2 1 ann 4 2 1 1 conceptual background anns consist of several interconnected neurons and are a combination of weighted non lrs and discriminant models each neuron is a component that performs an lr or non lr neurons are connected and structured in layers with one serving as an input layer one or more serving as hidden layers for performing several measurements in sequence and one serving as an output layer for displaying the results sarle 1994 the key feature of anns is that they can mimic brain activity by learning complicated non linear correlations from the input 4 2 1 2 bibliographic review table statistical models mislan et al 2018 developed adaptive neural network backpropagation annbp in their study to forecast max lwl min lwl and average lwl by using historical max lwl min lwl and average lwl as an input variable similarly wang et al 2018 studied the combination of copula entropy ce with wavelet neural network wnn with 10 years of daily rainfall and lwl data jaafar et al 2010 analyzed non linear ann to study lwl prediction the model forecasts lwl by using lwl with lags as an input variable üneş et al 2015 used ann to predict lwl with lwl with different time lags as an input variable on the other hand piasecki et al 2018 increased the parameter basket with binary variables evaporation and precipitation as input variables in addition to the historical water level piasecki et al 2017 employed ann multilayer perceptron mlp and mlr to predict lwls with maximal and minimal temperature tmax tmin wind speed ws vertical circulation vc and water level from previous periods wl ashaary et al 2015 investigated nns by taking historical rwl as an input variable young et al 2015 investigated three dimensional hydrodynamic models ann auto regressive moving average with exogenous input armax and combined hydrodynamic and ann for the lwl prediction study the study takes place in an alpine lake located in taiwan the number of observations in the dataset is counted as 7296 and the temporal is hourly the model predicts lwl by using inflow discharge outflow discharge and precipitation the model s performance is evaluated using mae rmse and r results indicate that water levels can be predicted with the hydrodynamic model in the calibration stage but not in the validation stage among models the ann and armax models showed superior results compared with the hydrodynamic model mpallas et al 2011 applied ann and anfis for the kerkini lwl prediction study the region of the area resides only in the greek part of the lake which constitutes a 6472 km2 surface area the dataset in this study contains 252 data rows estimated from 12 years of monthly data the models are generated using visual basic programming software and predict lwl and runoff using rainfall lake evaporation strymonas basin evapotranspiration water flow from bulgaria and water consumption that comes from human activities as input variables the performance of the model was tested by using reduced mean squared error mse and r2 it is concluded from the results that the models used in this study are satisfactory predictive tools to forecast lwls the performance results are quite similar between the models páliz larrea et al 2021 explored nn and anfis in their lwl prediction study the study takes place in the salve faccha reservoir in northern ecuador the dataset in this study consists of 2920 data rows estimated from 8 years of daily data in this study the output is determined as lwl for 1 6 days in advance while the input is rainfall the performance of the model was evaluated using r nash index and rmse the results show that rainfall cannot estimate rwl in a good performance according to evaluation metric results the nn with t 4 and anfis with t 6 showed the best performance latif et al 2021 proposed ann models with radial basis function rbf in order to use in lwl prediction study the authors used klang gate reservoir the study area located in malaysia the dataset contains 132 data rows estimated from 11 years of accumulated monthly data the model predicts water losses from the reservoir by using inflow the release of the dam and initial and final storage of the reservoir the performance of the model was tested using rmse as an evaluation metric it is concluded from the results that the ann model can predict water levels with an rmse score of 20 07 the model also provides benefits to reservoir operation with extra information on water losses final storage and variation of water level ishak et al 2011 developed a decision support model based on an nn to work lwl study the dataset consists of 3041 data rows accumulated from daily data the model forecasts rwl by using rainfall as an input variable the evaluation metrics used in this study are training testing and validation error the results reveal that this study s nn model performed well in forecasting and decision models 4 2 1 3 comparison and combination the authors that predicted lwl with ann models mostly selected lwl as their input variable mislan et al 2018 wang et al 2018 jaafar et al 2010 üneş et al 2015 piasecki et al 2018 piasecki et al 2018 2018 ashaary et al 2015 rainfall discharge evaporation temperature and wind speed were other parameters solely used or combined with different parameters wang et al 2018 young et al 2015 mpallas et al 2011 páliz larrea et al 2021 latif et al 2021 piasecki et al 2017 2018 although most of the studies used nn or ann as the only model to predict the output some scholars added different models in their research to compare it with the ann model such as ce armax anfis mlp mlr and hydrodynamic model wang et al 2018 young et al 2015 mpallas et al 2011 páliz larrea et al 2021 ashaary et al 2015 young et al 2015 found that ann and armax models are giving lower mae and rmse results compared with the hydrodynamic model however when mpallas et al 2011 and páliz larrea et al 2021 compare the ann and anfis models they found the results are quite similar which indicates the models can be used interchangeably ann models are presented in table 3 4 2 2 decision tree 4 2 2 1 conceptual background decision trees are inference models that find thresholds and common properties in data they can be either linear or non linear these models categorize the data and extract general rules from specific examples 4 2 2 2 bibliographic review table statistical models guyennon et al 2021 proposed an rf model for their lwl prediction study the study takes place in lake bracciano which is located in central italy the dataset consists of 812 data rows accumulated monthly data the model predicts lwl by using precipitation temperature surface evaporation wind speed relative humidity atmospheric pressure solar radiation and abstraction as input variables the performance evaluation techniques used in this study are rmse and mae according to the results extracted from evaluation metrics even though the data studied is not complete the rf model can still predict lwl well the incomplete parts of the study include air temperature and short term precipitation on the other hand long term precipitation caused the most fluctuation in the water level wang and wang 2020 explored gp mlr mlp m5 pruned m5p model tree rf and k nearest neighbor knn to estimate future lwls they used the lake erie dataset for their experiment located on the usa canada border the dataset contains 4380 data rows estimated from 12 years of daily data the study forecasts lwl by using precipitation air temperature shortwave radiation longwave radiation wind speed and relative humidity as input variables the evaluation metrics used in this study were stated as rmse and mae the results reveal that mlr and m5p have the highest performance scores on evaluation metrics ed to process based models nhu et al 2020 studied m5p rf random tree rt and reduced error pruning tree rept models to experiment on the lwl prediction area the study is held in zrebar lake which has a surface area of 8 9 km2 and is located in iran the dataset size is 2190 estimated from 6 years of daily data the study predicts lwl by using previous day water level t 1 t 1 t 2 t 1 t 2 t 3 t 1 t 2 t 3 t 4 t 1 t 2 t 3 t 4 t 5 as input variable the performance of the study was evaluated by using rmse mae r2 percent bias pbias the ratio of the rmse to the standard deviation sd of measured data rsr and visual frameworks taylor diagram and box plot results indicate that the best performance was taken with the one day lag input in addition the performance of the result decreased when the lag time increased m5p gave the best result among the models while the rept model had the worst performance obringer and nateghi 2018 analyzed generalized linear model glm generalized additive model gam multivariate adaptive regression spline mars classification and regression trees cart bagged cart rf svm bayesian additive regression trees bart and null mean only model to forecast urban rwl located in the usa the dataset consists of 18 615 data rows estimated from 51 years of daily data in this study the output is determined as rwl while the input is streamflow dew point population soil moisture enso discharge humidity water use and precipitation the model was tested by using r2 as an evaluation metric it is concluded from the results that rf is the best predictive model for lwl prediction moreover streamflow city population and el niño southern oscillation enso index are the most important variables affecting the result li et al 2016a a applied rf ann svr and linear model to apply lwl prediction in their study the study takes place in poyang lake which is located in china the lake has a surface area of 1000 km2 dry season and 4000 km2 in the wet season the dataset contains 20 805 data rows estimated from 57 years of daily data the study predicts lwl using water level discharge and time lags as input variables the performance of the model was evaluated using r2 and rmse metrics according to the results extracted from evaluation metrics rf gave the best performance for lwl prediction the variable importance was also analyzed and previous water level and discharge from the yangtze river were the most effective variables for the model koch et al 2021 investigated catboost gradient boosting decision tree using the model in their lwl prediction study the case study is applied in a lake located in denmark with a surface area of 43 000 km2 the dataset size 10 950 is estimated from 30 years of daily accumulated data in this study the output is determined as the depth of the uppermost water table while the input is soil texture geology topography based characteristics water body proximity land cover and outputs from a hydrological simulation with the dk model the performance evaluation metric for the model is mae the results show that the proposed model can forecast water table variability with high accuracy performance decision tree based models are presented in table 4 4 2 3 fuzzy logic 4 2 3 1 conceptual background fuzzy logic is a computing approach based on degrees of truth rather than the traditional true or false boolean logic on which the modern computer is built 4 2 3 2 bibliographic review table statistical models ehteram et al 2021 developed anfis so anfis fa anfis pso mlp so mlp fa and mlp pso models to study on lwl prediction area the study area was determined as a lake located in iran the dataset in this study contains 168 data rows estimated from 14 years of monthly data the study predicts lwl using temperature and rainfall lagged seven input combinations according to pca as input variables the performance evaluation metric in this study is rmse it is concluded from the results that the best performance was attained by the anfis so model together with rainfall and temperature inputs on the other hand the input variable of six months of rainfall lag times performed poorly in the model üneş et al 2019 used anfis svm radial basis neural networks rbnn and generalized regression neural networks grnn to conduct their study on lwl prediction the study takes place in a lake located in the usa with a surface area of 70 km2 the dataset consists of 2272 data rows accumulated from daily data the study estimates future rwl using rwl with lag times as an input variable the model performance was evaluated using mse mae and r it can be inferred from the results that anfis models have the highest performance compared with auto regressive models ar auto regressive moving average arma multi linear regression mlr models and ai models to forecast rwl tsao et al 2021 analyzed fuzzy neural networks fnn with multi stage architecture to study future lwls the study is held in the techi hydropower which has a surface area of 1235 73 km2 and is located in taiwan the data size is 17 520 estimated from 2 years of hourly accumulated data in this study the output is determined as reservoir inflow and water level while input as meteorological rainfall data rainfall observation data water level and power generation the evaluation metrics for the performance of the model are mae rmse and mse the authors claim from the results that the model used in this study could utilize water resources effectively it could also positively impact water plant management since the model s performance is high in heavy precipitation valizadeh et al 2014 employed anfis with membership functions to conduct their study on the lwl prediction area the case study is applied to a lake in malaysia with a surface area of 1290 km2 the dataset consists of 4015 data rows estimated from 11 years of daily data the study forecasts lwl using rainfall and lwl with different time lags for both as input variables the model s performance was evaluated using rmse mean absolute percentage error mape and mae the model performance is high in the results since the predicted and actual data strongly fit each other fuzzy logic based models are presented in table 5 4 3 deep learning models for lwl and rwl prediction the slr process extracted deep learning models to predict lwls although there are different types of deep learning techniques used this study grouped them into one category due to a limited number of studies on these types of models out of a total of 3 deep learning models 2 of them used long short term memory lstm whereas one of them used convolutional neural network cnn 4 3 1 conceptual background deep learning is a machine learning and ai technique that mimics how humans acquire knowledge deep learning algorithms are built in a hierarchy of increasing complexity and abstraction unlike typical machine learning algorithms which are linear 4 3 2 bibliographic review table deep learning models liang et al 2018 analyzed lstm to conduct their experiment on the lwl prediction study the study area was selected as the three gorges dam located in china the dataset consists of 4015 data rows estimated from 10 years of daily data the study predicts lwl by using the daily average tgd discharge daily average discharge at xiangtan station daily average discharge at taojiang station daily average discharge at taoyuan station daily average discharge at jinshi station and daily average precipitation as an input variable the evaluation metrics to test this study s performance were r2 and rmse it is concluded from the results that the lstm model outperforms the svm machine learning model damova et al 2020 investigated cnn to estimate future lwls the study was conducted on 3 three lakes in bulgaria kyrdjali studen kladenec and ivaylovgrad the dataset contains 3650 rows estimated from 10 years of daily accumulated data the study forecasts rwl by using precipitations solid and liquid soil moisture air temperature skin temperature vegetation index and in situ measurements of water balance characteristics as input variables the performance of the study was evaluated by using minmae the results show that the proposed model outperforms non semantic solutions and standalone gis models costa nourani et al 2021 used fully connected neural networks fcnn and long short term memory in their study to forecast lwls located in the usa the data size is not given but the temporal of the accumulated data is daily in this study the output is determined as lwl while the input as temperature density and northward and eastward water velocity the evaluation metric used in this study is an average error it can be determined from the results that both models have satisfactory results that enable predicting lwls accurately between fcnn and lstm models their performance was similar to each other however lstm needs more learning parameters to have equivalent results 5 overview of data driven modeling the reviewed studies used mathematical models in common the studies either derived their formula or generated a combination of different mathematical models to predict lakes or rwls the general direction towards feature selection is to use historical lwls some studies used multivariate attributes to predict future water levels in addition the tendency for evaluation metric selection includes rmse r2 and mae which constitute about 46 of all slr studies although studies give meaningful results to measure water supplies in the drinking water reservoir they lack the integration between water supply prediction and water management system decision processes the majority focus on the study intention is either drought prediction or flood prediction the modeling techniques alter in terms of publication date recent studies usually focus on machine learning guyennon et al 2021 koch et al 2021 and deep learning techniques damova et al 2020 costa nogueira jr et al 2021 while past studies used mathematical person et al 2007 paynter and nachabe 2011 and regression based models lin et al 2015 garcía molinos et al 2015 the drastic change comes from the evolution of machine learning and deep learning techniques in recent years therefore there is still an open research area to focus on machine learning and deep learning techniques to predict lwl and rwl for future periods although some researchers favor some algorithms for their studies these algorithms are chosen in terms of specific needs considering their advantages and disadvantages 6 discussion for survey research to be effective it must review and evaluate the existing literature and present a thorough argument that will be useful to readers who are interested in this section a number of crucial ideas are distilled and explored in light of the reviewed study on ai models for lwl modeling compared to previous conceptual models ann and rnn models can be simply converted from univariate to multivariate instances moreover by modifying the learning algorithms transfer functions and model structure ann and rnn models complexity may be easily adjusted similar to regression models correlation analyses or empirical evidence may be used to assign the input variables according to the reviewed articles the findings show that in comparison to other models like arma and decision trees ann and rnn models can accurately forecast the lwl and capture the non linear behaviors of the lwl in various locations and case studies the input data used is crucial when creating lwl prediction models over a specific time frame several researchers have built their models for predicting lwl solely using the delays of lwl some researchers on the other hand coupled historical lwl data with hydrological factors including precipitation evaporation sunshine length temperature river flow discharge and so on according to this review the majority of researchers have exclusively employed hydrological or meteorological factors for lwl forecasting long term growth of deep learning applications in hydrology is anticipated due to improvements in computing power and internet technologies in fact compared to other hydrological variables like water level and discharge the application of deep learning in lwl and rwl prediction is still very limited it comes as no surprise that there will soon be more deep learning reservoir related articles available if exploited intelligently lake and reservoir which are currently underexplored in many regions of the world can offer an alternate approach to lessen problems with water stress lake resource management requires accurate knowledge and predictions in order for local governments to fully utilize the deep learning extracted lwl information future research collaborations between researchers and local stakeholders must be strengthened for example the creation of tools with user friendly graphical user interfaces may encourage the use of deep learning in lwl simulation and forecasting by local stakeholders and users with little programming experience information about the lake can be obtained and processed more intelligently with larger user groups thanks to the internet of things iot paradigm smart water quantity and quality monitoring systems have been accelerated by improvements in computing power internet speed and coverage as well as the quick development of software technologies like cloud storage systems and service oriented architecture thus it is anticipated that the adoption of iot would make it easier to gather lwl data iot and deep learning integration can deliver more precise real time lwl data collection transport and analysis at a lower cost the choice of input was mostly determined by how those variables affected the chosen result precipitation 17 lwl and evaporation were the most preferred input variables by researchers several factors rely on the location which may have an impact on the lwl directly or indirectly it is also worth to mention that remote sensing data is also a good validation criterion for model performance the final given results for lwl or rwl such as radar altimetry observations are serving as a good current long term independent source for validation when evaluating how good any modeled data could be few researchers focused on this aspect by using remote sensing data chen et al 2020 huang et al 2011 zhu et al 2017 although state of the art algorithms such as lstm and gru models give the best results liang et al 2018 costa nogueira jr et al 2021 thanks to their sequential structure the model could be further developed but some recent efforts to integrate attention based mechanisms didn t outperform zhu et al 2022 other novel perceptions could help to increase the prediction performance in the future 7 conclusion the available potable water is an imminent concern for the human society which is considered to affect the near future the main supply of drinking water comes from lakes which are in danger of drying up if the water is consumed at today s pace therefore various studies focus on water level prediction of lakes and reservoirs especially after 2015 predicting water levels would enable water management systems for lakes to work efficiently this study reviews lwl prediction using five different algorithms equation based ann decision tree fuzzy logic and deep learning models the models were compared with each other in several studies to see the effect of model performance the advantages and disadvantages of the models were evaluated and discussed in detail this study has several limitations that have to be improved in further studies the studies rely on recent ai modeling techniques that still continue to get better at rapid pace in addition this study is limited to the search words that are stated in the methodology section there may be other studies that don t include these generic search words in title abstract keywords but the topic may be about lake water level prediction the study directs the future to study integration with water management systems and decision support suggestions for these systems in addition the findings could direct scholars to study other drinking water supplies to predict to prevent extreme drought conditions author contributions conceptualisation s o m y and s o y methodology s o s o y validation s o formal analysis s o investigation s o s o y and m y data curation s o writing original draft preparation s o writing review and editing s o m y and s o y visualisation s o and m y supervision s o y project administration s o s o y and m y all authors have read and agreed to the version of the manuscript declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests muhammad yaqub reports financial support was provided by national research foundation of korea acknowledgements south korean part of this study was supported by the national research foundation of korea nrf grants nrf 2021r1i1a1a0105783111 from the korean government msit to dr muhammad yaqub abbreviations ai atificial intellience anfis adaptive neuro fuzzy inferren sys ann artificial neural network annbp adapt neural network backprop aoff amount of forecast factor armax auto reg mov avg with exog inp bart bayesian additive regression trees blr bayesian linear regression bdtr boosted decision tree regression bhrm bayesian harmonic regress models cart classification and regression trees cc chance constrained ce copula entropy cnn convolutional neural network dfa dynamic factor analysis dfr decision forest regression dic deviance information criterion doc degrees of confidence dwl dam water level dwt discrete wavelet transformation dtc decision tree classifier dtr decision tree regression ef efficiency index elm extreme learning machine etc extra tree classifier etr extra tree regression fcnn fully connected neural network feflow finite element subsurface flow fnn fuzzy neural networks fvcom finite volume 3d ocean model gam generalized additive model gbr gradient boosting regression gev generalized extreme value glm generalized linear model gnb gaussian naïve bayes gp gaussian process gpr gaussian process regression grace gravity recovery and climate exp grnn generalized regression neural net htc hoeffding tree classifier hat c hat classifier hat r hat regression hss heidke skill score htr hoeffding tree regression iot internet of things kge kling gupta efficiency knc k neighbors classifier knn k nearest neighbor knr k neighbors regression lbrm large basin runoff model llc lake level change lmi legates and mccabes index lor logistic regression lr linear regression lstm long short term memory lwb lake water balance lwl lake water level m5p m5 pruned mae mean absolute error mape mean absolute percentage error mare mean absolute relative error mars multivariate adaptive reg spline mbe mean biased error mcc multiple correlation coefficient mlp multilayer perceptron mlp r multilayer perceptron regression mlr multiple linear regression mpmr minimax probability machine reg mre mean relative error mse mean squared error modm multi objective decision model nbs net basin supply nic normalized information contribut nn neural network nnr neural network regression noah mp lsm noah multiparamet land surf mo nrmse normalized root mean square er nsc nash sutcliffe criterion nse nash sutcliffe efficiency p precipitation p e anomalous net freshwater pbias percent bias plsr partial least squares regression prevah precipit runoff evapo hydrotope qac quality assessment checklist r coefficient of correlation r2 coefficient of determination rae residual absolute error rapid rout app for para comp of disc rbnn radial basis neural networks rcp represent concentration pathway rept reduced error pruning tree rf random forest rfc random forest classifier rfr random forest regression rmse root mean squared error rsd residual standard deviation rse residual standard error rsos residual sum of squares rss regression square sum rvm relevance vector machine rwi refined willmott s index rwl reservoir water level rt random tree sd standard deviation src spearman s rank correlation srpf statistical reg predictive function ss sum of squares svm support vector machine svr support vector regression svr gwo sup vec reg grey wolf optim swgm surface water groundwater model vic variable infiltration capacity wbcm water budget conceptual model wbm water balance model wbnm water balance network model wnn wavelet neural network wshm watershed scale hydrologic model 
25412,global climate change has led to large fluctuations in lake levels in recent years as meteorological and hydrological parameters have changed and water use has been intense water scientists use various computer models to analyze the hydrological variables recorded in the past and make projections for all future scenarios based on the technological progress six different types of algorithms were studied in this review to predict the water level in lakes the prediction results show that deep learning dl has the highest accuracy in terms of the evaluation metrics since the artificial intelligence ai field is still emerging and continue to improve this study highlights better comprehension of current applications and the problems that need to be investigated more for lwl forecasting techniques it reveals that the studies mainly focused on lakes either in usa or china and there is room for improvement for other locations that are scarcely investigated keywords lake water level reservoir water level prediction forecast time series data availability no data was used for the research described in the article 1 introduction a global warming trend is expected to result in significant changes in main hydrological cycles including changes in amounts and spatial distributions of precipitation evaporation in the water surface transpiration in watersheds as well as domestic water consumption intensity chen et al 2020 zappa et al 2014 ahn et al 2016 lake s water levels lwl are most sensitive to variability and changes in climate because changes in lwls play a key role in affecting the quantity and quality of the lake water resources and the watershed ecological environment it is expected that the frequency and severity of extreme climate events will increase and enhance floods and droughts in many regions deteriorate natural water quality which needs prompt decision action plans both for water budget and quality management valizadeh et al 2014 voulanas et al 2021 the water levels in many natural lakes and reservoirs are progressively decreasing in the last decades most recent studies claimed that climate change and water consumption uptrends nourani et al 2021 would cause water levels to continue to decline this scenario spurred serious concern since freshwater lakes and reservoirs are key features of the water supply infrastructure industrial domestic and agricultural activities within the region depend directly on reliable water delivery in general the quantity and quality of lake water resources are intertwined with the input output balance and climate fluctuations shrestha et al 2012 plisnier et al 2018 temporal and spatial changes in lwls are a particularly reliable indicator of changes in catchment water balances soja 2013 the dynamics of the lake water budget can act as sentinels for regional water cycles by displaying signals that combine climatic and landscape pressures and show significant changes in these variables williamson et al 2009 adams and sada 2014 moreover climate change significantly impacts lakes water levels directly and indirectly through changes in atmospheric drivers such as precipitation and evapotranspiration the impacts of climate change on lakes are likely to increase in the future taner et al 2011 byun and hamlet 2018 therefore the potential influences of climate change on lake hydrology are of paramount importance for managing drinking water systems in terms of enhancing and protecting the resilience of the lakes and supporting interdependent human and ecosystem communities lwl regimes are influenced by climate hydrology and water consumption actually in recent years fluctuations of the lwls are influenced by changes in precipitation and evaporation bartolai et al 2015 and these water bodies have been significantly affected by global warming and climate change finlayson et al 2013 furthermore lakes are under increasing pressure due to accelerating water consumption in the dry season coops et al 2003 haghighi et al 2014 yuan et al 2015 1 1 research significance climate change significantly impacts the natural hydrological cycle and amplifies water scarcity haddeland et al 2014 fernandes et al 2011 santos et al 2014 the effects of meteorological parameters and water consumption on patterns of lwl variations are of fundamental importance to quantifying climate change s ecological and economic risks the responses in lwls can be used as indicators to assess the overall regional hydrological impacts of climate change water consumption trends and land use modifications haghighi and klove 2015 coops et al 2003 yuan et al 2015 the literature background indicates an increasing concern to investigate lwl and reservoir water level rwl prediction especially considering the recent climate change effects this increase can also be observed in the number of publications in the last 15 years see fig 1 the number of publications in fig 1 indicates a drastic increase in studying lwl and rwl prediction especially for the years 2020 and 2021 one of the reasons to study lwl and rwl prediction may be due to climate change effects and water scarcity in recent years however the study area differs in terms of geographic locations where the effect of climate change has the most impact on demographics which can be seen in fig 2 below most studies focused on lakes in either china or usa and usa canada border locations there are also studied lakes in other parts of the world in the literature the 17 other studies focused on europe while 13 investigated asia reservoirs the studied areas in africa are 9 in australia 3 and in south america 2 lake levels were modeled the number of study areas in fig 2 is higher than the number of studies since one study may explore more than one lake or reservoir to compare them in addition although the time span of studies in the literature is 15 years 2006 2021 the period of datasets in studies differs in terms of collection techniques and usually higher than 15 years the scholars publish their articles and conference proceedings in well respected journals and conferences the percentages in fig 3 indicate the rate of articles comparing whole studies in this systematic literature review studies the most popular journal for these types of studies is water in addition journal of hydrology regional studies and plos one also get a high amount of studies other studies are almost equally represented in different journals in mostly water related areas the figure results reveal that listed journals emphasize lwl and rwl prediction related studies and are most likely to embrace related fields in their publications scholars mostly decided to predict future lwl by using artificial neural network ann other most popular algorithms consist of support vector regression svr random forest rf and artificial neuro fuzzy inference system anfis fig 4 shows that there is no dominance or consensus of the algorithm that is used by scholars in the literature in addition the promising results of neural network nn based prediction models attract scholars to build prediction models using these algorithms and deep learning methods yuan et al 2022 almost every one of three studies used root mean squared error rmse as an evaluation metric as it can be seen in fig 5 the second and third most popular evaluation metrics in literature are coefficient of determination r2 and mean absolute error mae although these algorithms are the most popular among scholars not all of them stick to using only one evaluation metric rather they evaluate the results mostly more than one evaluation metric one of the reasons not to stick to one evaluation metric may be to enhance the credibility of evaluation metric results when the evaluation metrics are compared in terms of ai models in literature results it can be seen that rmse and mse take the majority for mathematical and equation based models ann and fuzzy logic r2 is mostly selected in regression and deep learning models and never used in fuzzy logic models another aspect is that less than 10 of researchers used mape mae as an evaluation metric for mathematical and equation based models see fig 6 1 2 research objectives there have been various attempts to prevent any kind of drought or flood risk that may harm society in a potential economic downturn basically previous analysis of long term data on water level fluctuations of a watershed over time can be used to assess the effects of climate variability and anthropogenic activities on water resources liu et al 2021 there are various solutions to prevent these types of risks ehteram et al 2021 ethteram et al 2018 but the solutions are only effective if they are taken at the right time thus the prediction of water levels is important to get efficient and effective counter actions for any kind of drought and flood risks the results of the earlier attempts to anticipate lwl are undoubtedly encouraging especially in light of the fact that in comparison to conventional methods applications of ai models for the forecasting of lwl are still in their infancy yet there are still a lot of uncertainties and difficulties in both the application of the models and the interpretation of the results how for instance may input combinations be chosen to increase model performance which algorithm is more trustworthy how can model performance be assessed this is largely because we currently have very little understanding of statistical and artificial intelligence models as these ideas and techniques are continually being refined these are currently leading to two different perceptions and actions one is that there has been a notable increase in the use of machine learning and deep learning models for water level forecasting in lakes and the other one is that there has been a rise in skepticism regarding studies that have used these models and the results that have been reported in order to better comprehend and communicate the development of the approaches successful applications of them and the problems that still need to be overcome it is necessary to analyze the applications of models for lwl forecasting that are already accessible this is the first attempt at conducting slr for lwl forecasting other review studies focus solely on machine learning models and neglect other statistical models zhu et al 2020 sannasi chakravarthy et al 2022 in addition unlike other review studies this study includes regional input and evaluation metric comparisons in order to analyze algorithms effectively in this slr experimental prediction models have been analyzed based on scientific advancement and this review gives an overview of the models efficiency in order to integrate prevention techniques with prediction models with respect to selected meteorological and hydrological parameters although prediction and prevention techniques are two different methodologies they are interrelated to each other the risk prevention techniques could be handled more efficiently in terms of budget time and other scarcity issues e g water with the help of lwl and rwl prediction techniques 2 related work freshwater lakes are subject to substantial annual variations in storage levels due to seasonality in catchment inflows and lake outflows valizadeh et al 2014 in this context climate change has been a topic of interest for many researchers to predict water level fluctuation and analyze the reasons for water budget and water quality changes for instance mendoza et al 2006 studied the causes of cuitzeo lake s changes in mexico they used statistical models to link water level fluctuations to rainfall and temperature for this purpose the time series was used motiee and mcbean 2009 also found that climate change had been caused a reduction of 50 cm in the water level of superior lake located in north america which is the highest amount between 1928 and 2009 they also found that the lake s water level has decreased by 1 cm every year using these results they found that these changes can indicate signs of climate change phenomena in the studied area zilefac 2010 showed that by reducing rainfall and increasing temperature the average depth of chad lake has fallen from about 7 m to 1 5 m njaya et al 2011 stated that the average depth of chilwa lake decreased from 0 to 12 m between 1960 and 2000 huang et al 2011 considered the temperature and precipitation the most critical factors affecting fluctuations of cottonwood lake in the united states mekonnen et al 2012 pointed out that the depth of naivasha lake decreased by 4 m between 1965 and 2001 using several index analyses palynology sedimentology chemical composition and paleontology and geomorphologic processes of the eastern poland basin zawiska et al 2015 claimed that weather has been the primary motivation for change in aquatic and terrestrial ecosystems salih et al 2019 predicted evaporative losses from reservoirs to contribute to the literature from a different perspective previous studies regarding historical and projected future responses to climate change focus on the lake s catchment and have drawn a number of consistent conclusions historically several hydrological models such as finite volume 3d ocean model fvcom abbaspour et al 2012 finite element subsurface flow feflow taminskas et al 2013 and precipitation runoff evapotranspiration hydrotope prevah zappa et al 2014 have been used to explore historical climate and land use effects on water bodies and reported the role of the climate variability is stronger than the land use changes similarly artificial intelligence ai models liang et al 2018 damova et al 2020 aslan et al 2022 ebtehaj et al 2021 have shown an extensive ability to model the lake river system or streamflow water levels without the need for experimental apparatus and complex hydro physical models based on physical principles and mathematical equations chen et al 2020 mtilatila et al 2020 a good search of existing literature shows that these investigations included the applications of the ann model in spite of their successful applications several research works have shown a wide range of forecasting accuracies that in fact have varied with respect to the geographic features of the tested sites as shown in earlier studies deo and şahin 2016 prasad et al 2017 where models tested at the study sites with different climatic and hydrological patterns were compared moreover the search for a one size fit it all forecast model for solving hydrological modeling problems remains an open contribution to be made to the existing literature since no universal model currently exists for all types of climates and regions mishra and singh 2011 in view of the scientific advancement the present study reviews the historical achievements and applications of the latest learning based models for lwl forecasting all the models are reviewed in the literature and because of their popularity these models are frequently used in the studies 1 ann 2 support vector machine svm 3 anfis 4 hybrid models by integration of wavelet analysis and ann artificial neuro fuzzy inference system and svm models 5 extreme learning machine elm and 6 deep learning dl there are several challenges before developing an lwl or rwl model mostly due to the nature of dataset generation among the challenges how to determine the input combinations to improve model reliability and how to split the available datasets to capture better water level dynamics under the impact of climate change and the influence of extreme events are discussed 3 methodology the present state of knowledge of lwl prediction and forecasting models was assessed using a systematic literature review slr kitchenham et al 2009 by carefully establishing search and inclusion exclusion criteria the slr accurately assesses the existing literature it is also transparent and repeatable the slr begins with the discovery of data sources and the establishment of search criteria after that publications are selected or omitted from the final sample based on criteria relevant to the study s goal finally data of interest is collected from complete text from the sample followed by analysis and a report of the findings even though a considerable sample was retrieved from the slr it may not pick up all important references in other cases specific references were added for debates although not appearing in the slr results 3 1 research questions at the beginning of the review phase there has been three research questions determined in the following order rq1 what are the models that are used for the prediction of water level in a reservoir rq2 what types of machine learning models are utilized to anticipate a reservoir s water level in addition what are the categorization of statistical models that are used in the prediction of water level in a reservoir rq3 what types of deep learning models are utilized to forecast reservoir water levels 3 2 defining the review protocol the research questions are established considering the research scope and the keywords for the systematic search are extracted in the title abstract or keywords at least one occurrence from these keywords was extracted lake and water and level and predict reservoir and water and level and predict lake and water and level and forecast and reservoir and water and level and forecast at initial studies were refined with certain inclusion and exclusion criteria to narrow them down for the first phase only published studies from journals book chapters and conference proceedings that have open access were included in this study on the other hand this study excluded studies that were written other than english for the whole paper regarding the second and third phases a quality assessment checklist qac was prepared to assess eligibility for individual studies the checklist items include a is the study about water level prediction b is there any reservoir in which the water level was predicted c does the research paper reveal the methodology 3 3 inclusion and exclusion criteria there are additional criteria for study selection after defining the review protocol to select relevant topics with the aim of the study the three criteria that are used in the study are as follows i the study must be related to a natural or artificial freshwater lake i e exclusion of seas rivers groundwater or related environments or purely conceptual models ii the research model must be on lwls fluctuations or dynamics e g exclusion of studies that modeled floods risks drought conditions economic impacts human population or other animals and iii the models must be capable of forecasting or predicting lwls and validating and or explaining observed data qualitatively 3 4 conducting the review the systematic search was conducted on october 3 2021 using scopus sciencedirect and web of science databases stage 1 produced 1470 papers when the qac was applied to the results for the second and third phases 269 and 72 articles remained respectively fig 7 4 results and discussion 4 1 statistical models for lwl and rwl prediction the slr process revealed different types of statistical models and techniques used in predicting lwls ranging from hydrodynamic models to regression models this study grouped these techniques under four categories hydrodynamic models water balance models wbm regression models and mathematical and equation based models out of a total of 47 statistical models 34 used only one technique whereas 13 used two or more methods together 4 1 1 regression models 4 1 1 1 conceptual background linear regression lr s and non lrs are the core of many machine learning methods many researchers have used simple regressions to predict lwl across many lakes in a specific region and these studies were classed as regression models in this systematic literature review 4 1 1 2 bibliographic review table statistical models zhu et al 2017 developed an lr model to forecast the lake chad water level prediction located at nigeria cameroon niger and chad border the model forecasts lake water balance lwb by using direct precipitation evaporation the inflow of the lake from the chari logone river system and outflow from the lake which includes both the discharge of the surface water to the northern basin and the seepage of the lake in the form of groundwater discharge as input variables similarly lin et al 2015 explored the combination of the routing application for the parallel computation of discharge rapid model noah multiparameter land surface model noah mp lsm model and multiple linear regression mlr for lake level prediction task by using inflow rate from the main stream and tributaries as simulated by rapid the outflow rate in m3 s p t precipitation and evaporation in addition hu et al 2018b studied the prediction of lwl with the svr model by disregarding the rest and only using three years of daily flow rate and outflow discharge data garcía molinos et al 2015 investigated bayesian harmonic regression models bhrm to predict lwl in natural irish lakes located in ireland the models forecast lwl by using level water level again the same approach is pursued by m dawam and ku mahamud 2019 using rainfall parameters and changes in rwl with the sliding window technique on the other hand mohammadi et al 2020 used svr and support vector regression grey wolf optimization svr gwo prediction models with similar input combinations with historical lwls castillo botón et al 2020 proposed svr and gaussian processes gp for belesar dammed rwl prediction the study set the output parameter as dammed water level which is measured in hm3 and tries to predict this level by using height m and flow m3 s upstream and on the tributaries and also the precipitation amount mm as input parameters kenda et al 2020 also used similar input parameters raw hourly weather forecast data precipitation intensity precipitation type temperature cloud cover dew point humidity pressure and daytime hu et al 2018a s approach is to use an svr model with only precipitation data liu et al 2017 employed a multi objective decision model modm and statistical regression predictive function srpf to predict water levels of the hongjiadu reservoir which is based in china the dataset was accumulated annually and the dataset size is 63 the output of the model is rwl while the inputs are year start water level inflow power output and power generation several evaluation metrics are used in this study degrees of confidence doc amount of forecast factor aoff sum of squares ss residual sum of squares rsos regression square sum rss multiple correlation coefficient mcc residual standard deviation rsd and mean relative errors mre the results indicate that there are two methods to manage water resources out of their unpredictable fluctuations one method is statistical regression which applies when there is a steady inflow another method is the modm which applies when there is a serious contradiction sapitang et al 2020 used boosted decision tree regression bdtr decision forest regression dfr bayesian linear regression blr and neural network regression nnr to predict lwls in malaysia the dataset contains 12 531 data rows which were collected daily the models predict lwl with rainfall and water level in addition rainfall water level and sent out data were selected as another set of inputs the performance of the models was evaluated with mae rmse r2 residual absolute error rae and residual standard error rse as metrics the results highlight that all models can be used to predict lwls however the blr model outperformed other models according to evaluation metrics bonakdari et al 2019 proposed minimax probability machine regression mpmr relevance vector machine rvm gaussian process regression gpr and elm models to use in their lwl prediction study the case study is applied in a lake located on the usa canada border with a surface area of 2402 km2 the dataset contains 1152 data rows estimated from 96 years of monthly accumulated data the models predict lwl by using lwl with lags as the input variable the performance of the models is evaluated by using r2 mae rmse legates and mccabes index lmi and refined willmott s index rwi and nash sutcliffe coefficient nsc as metrics it can be determined from the results that all models can predict lwls significantly among the models used in this study mpmr has the highest prediction performance 4 1 1 3 comparison and combination the first regression model on lwl forecasting goes as early as 2015 in which the study focuses on a mechanistic model for lake level changes llc and combined with a land surface model to improve the accuracy of results lin et al 2015 on the other hand garcía molinos et al 2015 emphasizes the importance of the seasonality effect when predicting water level dynamics zhu et al 2017 attempted to predict a change in water volume in chad lake by using multiple remote sensing observations a remarkable finding of the study indicates that while most of the water losses are directly related to evaporation in the entire lake the southern pool losses are related to the outflow previous regression models never attempted to compare the model with other prediction models liu et al 2017 used two models for lwl prediction modm and the statistical regression function they found statistical regression function model is advantageous when the dataset size is large and inflow to the lake is steady while modm could be best used in cases when there is a serious contradiction in reservoir function hu et al 2018a are the pioneers for lwl prediction with only one external parameter as precipitation the authors found that with only precipitation data the water levels can be predicted as well as prevents overestimation and underestimation in terms of quantity and magnitude in the same year the same authors conducted a second experiment for the same lake with other input parameters they found that the most important input parameter for lwl prediction is historical lwl data similar to the hu et al 2018a s study m dawam and ku mahamud 2019 decided to use precipitation as the only external input variable but they got the best result with the combination of precipitation and historical lwl data they also found that the mlr results highly depended on the dataset s normalization on top of these studies sapitang et al 2020 proposed two scenario based prediction models one includes precipitation and lwl other one includes precipitation lwl and discharge as inputs they also tested the models with different time horizons from one day to seven days the authors found similar results with previous scholars that only precipitation as an external input is a good predictor for lwl castillo botón et al 2020 proposed prediction models for both short term and long term periods in the short term they found that upstream and tributaries flow are highly effective parameters whereas precipitation and dam outputs are less relevant for the prediction for this reason this study contradicts with findings of hu et al 2018a and m dawam and ku mahamud 2019 s studies that got the best prediction result with precipitation lwl and only precipitation data kenda et al 2020 worked on the most comprehensive regression study with 21 models to predict only one lake water surface and water level therefore only this study could give the finding that batch regression algorithms perform better than incremental regression algorithms mohammadi et al 2020 experimented similar to garcía molinos et al 2015 s study by only using lwl as an input parameter however instead of focusing on the seasonality effect they rather focused on the time lag effect on lwl prediction they found that it gives the best performance only by using either 1 2 3 or 4 periods of time lags regression based models are presented in table 1 4 1 2 mathematical and equation based models 4 1 2 1 conceptual background mathematical and equation based models are usually derived by scholars in terms of their experiences with the subject matter and historical data although the researchers developed their own equation in every study some of the studies share the same name such as the wbm however even though the model name is the same the input parameter differs in terms of study 4 1 2 2 bibliographic review table statistical models dinka 2020 used the lake capacity curve equation to predict the lake basaka water level in ethiopia the study predicts lwl using 22 years of monthly lake stage area and volume data the volume of water was used in li et al 2013 s study as water depth with bands to predict adjusted water depth gillies et al 2015 selected input parameters as a change in lake level and tree ring reconstructed change in lake level on the other hand hirsch et al 2014 predicted water level fluctuation using depth volume and slope of the reservoir basin as input parameters paynter and nachabe 2011 investigated on generalized extreme value gev model to predict lwls using maximum and minimum lake levels the flood and drought stages jahani et al 2016 analyzed chance constrained cc optimization model with similar parameters such as index of season random inflow to reservoir release from reservoir and reservoir storage at the beginning of the season myakisheva et al 2021 on the other hand took only historical lwls into account to predict future lwls montroull et al 2013 studied the variable infiltration capacity vic hydrology model to forecast iberá wetlands water levels in argentina by using only 10 years of daily lwl data taminskas et al 2013 used a similar volume based input parameter as a change in water balance due to climate change variables in their study morgan et al 2019 investigated the wbm with their parameters as annual average runoff volume equilibrium pit lake surface area predicted equilibrium water level and wbm equilibrium water level paul et al 2019 developed a two dimensional depth averaged model for lake victoria water level prediction with inputs and outputs based parameters of the lake into account they used 51 years of monthly evaporation precipitation river inflow and outflow data abbaspour et al 2012 also predicted lwls with precipitation evaporation river and runoff discharge as input variables talsma et al 2016 studied on non linear model predictive control model while selecting the inflow of the ijssel river the inflow of the vecht river exchange with the regional water systems rainfall and evaporation forecast as input variables bertone et al 2017 predict the storage volume of the reservoir using rainfall main river inflow and gross volume variation as input variables hussain et al 2021 developed a gravity recovery and climate experiment grace prediction model which is applied in indus basin in pakistan the dataset used in this study has 78 data rows accumulated from 13 years of bimonthly data including evapotranspiration and precipitation as input variables guinaldo et al 2021 used the mass lake model to contribute to the literature on the lwl prediction area with over lake precipitation over lake evaporation runoff drainage over the runoff mask inflow entering the lake from the tributaries lake outflow and the contribution of the lake groundwater fluxes as an input magyar et al 2021 proposed dynamic factor analysis dfa to predict neusiedlersee lwls using evapotranspiration and precipitation data jiang et al 2021 employed discrete wavelet transformation dwt inarx setting discharge and precipitation as input variables haque et al 2021 used the 2d hydrodynamic model to predict the lwl with discharge data li et al 2016b developed a reservoir hydrological model to predict reservoir volume using gauged surface inflow ungauged surface inflow total outflow surface area direct precipitation evaporation net groundwater source and unit conversion factor croley 2006 on the other hand used 37 years of monthly precipitation runoff and evaporation data as input haddout et al 2018 applied the fvcom model for water level prediction in aguelmam sidi ali lake with input parameters such as precipitation evaporation and runoff discharges rodríguez rodríguez et al 2012 explored the prediction model of the water budget conceptual model wbcm with direct precipitation onto the lake s surface groundwater flow base flow in streams and subsurface runoff zappa et al 2014 employed the prevah model to assess surface water level using precipitation evaporation soil moisture litter moisture water temperature groundwater level runoff and snow water equivalent as input parameters person et al 2007 applied a three dimensional surface water groundwater model swgm with 50 years of monthly runoff evapotranspiration infiltration streamflow and groundwater hydrodynamics data voulanas et al 2021 used the feflow model in order to forecast the water level for the kastoria basin located in western macedonia greece the input variables of the dataset include rainfall surface runoff evaporation and discharge or the flow volume at the basin s outlet chen et al 2020 investigated the wbm based on gr4j to forecast water levels in thirlmere lakes national park with precipitation runoff and evapotranspiration data mtilatila et al 2020 predicted water level change using precipitation and evaporation as variables lastly ricko et al 2011 predict lwl by using the freshwater flux variable as the main input with rainfall being the main contributor to observed differences in given model versions in the tropics region lofgren and rouhana 2016 applied the large basin runoff model lbrm in their study to forecast laurentian great lakes water levels located between the usa canada border the dataset in this study contains 684 data rows estimated from 57 years of monthly data the model forecasts lwl with temperature adjustment energy adjustment priestley taylor and clausius clapeyron as input variables the performance of the model was evaluated with statistical significance according to the results based on evaluation metrics the water level can be predicted with a significance level of 99 98 the extreme high value of significance brings extra sensitivity of et to air temperature li et al 2014 employed a spatiotemporal pattern model for the lwl prediction area in their study the study takes place in tibetan lakes located in china the dataset consists of 14 600 data rows estimated from 40 years of daily accumulated data the study forecasts lwl change with mean temperature precipitation solar radiation wind speed and vapor pressure as input variables the model s performance was evaluated with the coefficient of correlation r as a metric in the results permafrost degradation contributes to the available water prediction in the region a lot while glacier melt has minimal effect fry et al 2020 explored the lwl prediction study by focusing on the net basin supply nbs model for laurentian great lakes located between the usa canada border the number of observations is not given for the dataset in this study however the study dataset output is determined as a seasonal water budget and the input is not explicitly given the temporal of the dataset consists of three periods which are 1 3 and 6 months the performance of the model was determined using heidke skill score hss the authors claim from the results that monthly mean water levels can be predicted with a 6 month lead time however the model interpretation requires some skill and related operator selection to improve model forecast results ouni et al 2020 proposed the delft3d flow model in order to predict and simulate lwls in ichkeul lake tunisia the dataset for the model consists of lake bed roughness and lwl data however the size of the dataset is not given it predicts lwl by taking lake bed roughness into account the evaluation metric to measure the performance of the delft3d flow model is rmse according to the results that are generated from the rmse score of 0 027 the delft3d flow model can predict the water level well cai et al 2016 developed a wbm to use on hulun lake in china the surface area of the lake is around 2000 km2 the dataset contains 372 data rows accumulated out of 31 years of monthly data in the model lwl is forecasted by taking into account precipitation mean temperature wind speed relative humidity and sunshine duration from 1960 to 2014 river discharge and evaporation the performance of the model is tested by calibration in the results it can be inferred that the model can forecast fluctuations in lwl ahn et al 2016 proposed a water balance network model wbnm and a watershed scale hydrologic model wshm soil and water assessment tool swat for the lwl prediction subject the study was done in the geum river basin in south korea the basin has a surface area of 9645 5 km2 the dataset size is 2190 estimated from 6 years of daily data the model predicts dam water level dwl by taking air temperature precipitation relative humidity wind speed and sunshine hours as input variables the study used the r2 the nash sutcliffe efficiency nse and the rmse as evaluation metrics the results show that water shortage is expected as 38 2 in the 2040s 38 2 in the 2080s for representative concentration pathway rcp 4 5 scenario and 21 3 in the 2040s and 22 1 in the 2080s for rcp 8 5 scenario 4 1 2 3 comparison and combination out of all mathematical models some scholars favored the wbm model which enhances the model s accuracy performance the first attempt to conduct wbm was done by ricko et al 2011 by using different rainfall data for varying input parameters keeping other model input parameters constant rodríguez rodríguez et al 2012 on the other hand conducted the model by adding groundwater flow baseflow in streams and subsurface runoff in addition to rainfall data as input parameters ahn et al 2016 used a daily dataset for their model consisting of air temperature precipitation relative humidity wind speed and sunshine hours as input parameters cai et al 2016 had a limited dataset with only 372 data rows but were able to predict lwl with precipitation mean temperature wind speed relative humidity and sunshine duration river discharge and evaporation as input parameters morgan et al 2019 s study is the only study that never used rainfall as an input parameter other scholars predicted llc with precipitation runoff and evapotranspiration as input parameters chen et al 2020 mtilatila et al 2020 scholars generated other models as specific equational models although different models have common input parameters some developed specific parameters only for their models gillies et al 2015 used tree ring reconstructed change in lake level as an input variable while li et al 2014 used vapor pressure ouni et al 2020 on the other hand decided to use lake bed roughness as one of their input variables mathematical and equation based models are presented in table 2 4 2 machine learning models for lwl and rwl prediction the slr process also produced machine learning models to predict lwls in a range between ann and elms this study grouped these techniques under four categories ann decision tree fuzzy logic and other models out of a total of 23 machine learning models 12 used only one technique whereas 11 used two or more techniques together 4 2 1 ann 4 2 1 1 conceptual background anns consist of several interconnected neurons and are a combination of weighted non lrs and discriminant models each neuron is a component that performs an lr or non lr neurons are connected and structured in layers with one serving as an input layer one or more serving as hidden layers for performing several measurements in sequence and one serving as an output layer for displaying the results sarle 1994 the key feature of anns is that they can mimic brain activity by learning complicated non linear correlations from the input 4 2 1 2 bibliographic review table statistical models mislan et al 2018 developed adaptive neural network backpropagation annbp in their study to forecast max lwl min lwl and average lwl by using historical max lwl min lwl and average lwl as an input variable similarly wang et al 2018 studied the combination of copula entropy ce with wavelet neural network wnn with 10 years of daily rainfall and lwl data jaafar et al 2010 analyzed non linear ann to study lwl prediction the model forecasts lwl by using lwl with lags as an input variable üneş et al 2015 used ann to predict lwl with lwl with different time lags as an input variable on the other hand piasecki et al 2018 increased the parameter basket with binary variables evaporation and precipitation as input variables in addition to the historical water level piasecki et al 2017 employed ann multilayer perceptron mlp and mlr to predict lwls with maximal and minimal temperature tmax tmin wind speed ws vertical circulation vc and water level from previous periods wl ashaary et al 2015 investigated nns by taking historical rwl as an input variable young et al 2015 investigated three dimensional hydrodynamic models ann auto regressive moving average with exogenous input armax and combined hydrodynamic and ann for the lwl prediction study the study takes place in an alpine lake located in taiwan the number of observations in the dataset is counted as 7296 and the temporal is hourly the model predicts lwl by using inflow discharge outflow discharge and precipitation the model s performance is evaluated using mae rmse and r results indicate that water levels can be predicted with the hydrodynamic model in the calibration stage but not in the validation stage among models the ann and armax models showed superior results compared with the hydrodynamic model mpallas et al 2011 applied ann and anfis for the kerkini lwl prediction study the region of the area resides only in the greek part of the lake which constitutes a 6472 km2 surface area the dataset in this study contains 252 data rows estimated from 12 years of monthly data the models are generated using visual basic programming software and predict lwl and runoff using rainfall lake evaporation strymonas basin evapotranspiration water flow from bulgaria and water consumption that comes from human activities as input variables the performance of the model was tested by using reduced mean squared error mse and r2 it is concluded from the results that the models used in this study are satisfactory predictive tools to forecast lwls the performance results are quite similar between the models páliz larrea et al 2021 explored nn and anfis in their lwl prediction study the study takes place in the salve faccha reservoir in northern ecuador the dataset in this study consists of 2920 data rows estimated from 8 years of daily data in this study the output is determined as lwl for 1 6 days in advance while the input is rainfall the performance of the model was evaluated using r nash index and rmse the results show that rainfall cannot estimate rwl in a good performance according to evaluation metric results the nn with t 4 and anfis with t 6 showed the best performance latif et al 2021 proposed ann models with radial basis function rbf in order to use in lwl prediction study the authors used klang gate reservoir the study area located in malaysia the dataset contains 132 data rows estimated from 11 years of accumulated monthly data the model predicts water losses from the reservoir by using inflow the release of the dam and initial and final storage of the reservoir the performance of the model was tested using rmse as an evaluation metric it is concluded from the results that the ann model can predict water levels with an rmse score of 20 07 the model also provides benefits to reservoir operation with extra information on water losses final storage and variation of water level ishak et al 2011 developed a decision support model based on an nn to work lwl study the dataset consists of 3041 data rows accumulated from daily data the model forecasts rwl by using rainfall as an input variable the evaluation metrics used in this study are training testing and validation error the results reveal that this study s nn model performed well in forecasting and decision models 4 2 1 3 comparison and combination the authors that predicted lwl with ann models mostly selected lwl as their input variable mislan et al 2018 wang et al 2018 jaafar et al 2010 üneş et al 2015 piasecki et al 2018 piasecki et al 2018 2018 ashaary et al 2015 rainfall discharge evaporation temperature and wind speed were other parameters solely used or combined with different parameters wang et al 2018 young et al 2015 mpallas et al 2011 páliz larrea et al 2021 latif et al 2021 piasecki et al 2017 2018 although most of the studies used nn or ann as the only model to predict the output some scholars added different models in their research to compare it with the ann model such as ce armax anfis mlp mlr and hydrodynamic model wang et al 2018 young et al 2015 mpallas et al 2011 páliz larrea et al 2021 ashaary et al 2015 young et al 2015 found that ann and armax models are giving lower mae and rmse results compared with the hydrodynamic model however when mpallas et al 2011 and páliz larrea et al 2021 compare the ann and anfis models they found the results are quite similar which indicates the models can be used interchangeably ann models are presented in table 3 4 2 2 decision tree 4 2 2 1 conceptual background decision trees are inference models that find thresholds and common properties in data they can be either linear or non linear these models categorize the data and extract general rules from specific examples 4 2 2 2 bibliographic review table statistical models guyennon et al 2021 proposed an rf model for their lwl prediction study the study takes place in lake bracciano which is located in central italy the dataset consists of 812 data rows accumulated monthly data the model predicts lwl by using precipitation temperature surface evaporation wind speed relative humidity atmospheric pressure solar radiation and abstraction as input variables the performance evaluation techniques used in this study are rmse and mae according to the results extracted from evaluation metrics even though the data studied is not complete the rf model can still predict lwl well the incomplete parts of the study include air temperature and short term precipitation on the other hand long term precipitation caused the most fluctuation in the water level wang and wang 2020 explored gp mlr mlp m5 pruned m5p model tree rf and k nearest neighbor knn to estimate future lwls they used the lake erie dataset for their experiment located on the usa canada border the dataset contains 4380 data rows estimated from 12 years of daily data the study forecasts lwl by using precipitation air temperature shortwave radiation longwave radiation wind speed and relative humidity as input variables the evaluation metrics used in this study were stated as rmse and mae the results reveal that mlr and m5p have the highest performance scores on evaluation metrics ed to process based models nhu et al 2020 studied m5p rf random tree rt and reduced error pruning tree rept models to experiment on the lwl prediction area the study is held in zrebar lake which has a surface area of 8 9 km2 and is located in iran the dataset size is 2190 estimated from 6 years of daily data the study predicts lwl by using previous day water level t 1 t 1 t 2 t 1 t 2 t 3 t 1 t 2 t 3 t 4 t 1 t 2 t 3 t 4 t 5 as input variable the performance of the study was evaluated by using rmse mae r2 percent bias pbias the ratio of the rmse to the standard deviation sd of measured data rsr and visual frameworks taylor diagram and box plot results indicate that the best performance was taken with the one day lag input in addition the performance of the result decreased when the lag time increased m5p gave the best result among the models while the rept model had the worst performance obringer and nateghi 2018 analyzed generalized linear model glm generalized additive model gam multivariate adaptive regression spline mars classification and regression trees cart bagged cart rf svm bayesian additive regression trees bart and null mean only model to forecast urban rwl located in the usa the dataset consists of 18 615 data rows estimated from 51 years of daily data in this study the output is determined as rwl while the input is streamflow dew point population soil moisture enso discharge humidity water use and precipitation the model was tested by using r2 as an evaluation metric it is concluded from the results that rf is the best predictive model for lwl prediction moreover streamflow city population and el niño southern oscillation enso index are the most important variables affecting the result li et al 2016a a applied rf ann svr and linear model to apply lwl prediction in their study the study takes place in poyang lake which is located in china the lake has a surface area of 1000 km2 dry season and 4000 km2 in the wet season the dataset contains 20 805 data rows estimated from 57 years of daily data the study predicts lwl using water level discharge and time lags as input variables the performance of the model was evaluated using r2 and rmse metrics according to the results extracted from evaluation metrics rf gave the best performance for lwl prediction the variable importance was also analyzed and previous water level and discharge from the yangtze river were the most effective variables for the model koch et al 2021 investigated catboost gradient boosting decision tree using the model in their lwl prediction study the case study is applied in a lake located in denmark with a surface area of 43 000 km2 the dataset size 10 950 is estimated from 30 years of daily accumulated data in this study the output is determined as the depth of the uppermost water table while the input is soil texture geology topography based characteristics water body proximity land cover and outputs from a hydrological simulation with the dk model the performance evaluation metric for the model is mae the results show that the proposed model can forecast water table variability with high accuracy performance decision tree based models are presented in table 4 4 2 3 fuzzy logic 4 2 3 1 conceptual background fuzzy logic is a computing approach based on degrees of truth rather than the traditional true or false boolean logic on which the modern computer is built 4 2 3 2 bibliographic review table statistical models ehteram et al 2021 developed anfis so anfis fa anfis pso mlp so mlp fa and mlp pso models to study on lwl prediction area the study area was determined as a lake located in iran the dataset in this study contains 168 data rows estimated from 14 years of monthly data the study predicts lwl using temperature and rainfall lagged seven input combinations according to pca as input variables the performance evaluation metric in this study is rmse it is concluded from the results that the best performance was attained by the anfis so model together with rainfall and temperature inputs on the other hand the input variable of six months of rainfall lag times performed poorly in the model üneş et al 2019 used anfis svm radial basis neural networks rbnn and generalized regression neural networks grnn to conduct their study on lwl prediction the study takes place in a lake located in the usa with a surface area of 70 km2 the dataset consists of 2272 data rows accumulated from daily data the study estimates future rwl using rwl with lag times as an input variable the model performance was evaluated using mse mae and r it can be inferred from the results that anfis models have the highest performance compared with auto regressive models ar auto regressive moving average arma multi linear regression mlr models and ai models to forecast rwl tsao et al 2021 analyzed fuzzy neural networks fnn with multi stage architecture to study future lwls the study is held in the techi hydropower which has a surface area of 1235 73 km2 and is located in taiwan the data size is 17 520 estimated from 2 years of hourly accumulated data in this study the output is determined as reservoir inflow and water level while input as meteorological rainfall data rainfall observation data water level and power generation the evaluation metrics for the performance of the model are mae rmse and mse the authors claim from the results that the model used in this study could utilize water resources effectively it could also positively impact water plant management since the model s performance is high in heavy precipitation valizadeh et al 2014 employed anfis with membership functions to conduct their study on the lwl prediction area the case study is applied to a lake in malaysia with a surface area of 1290 km2 the dataset consists of 4015 data rows estimated from 11 years of daily data the study forecasts lwl using rainfall and lwl with different time lags for both as input variables the model s performance was evaluated using rmse mean absolute percentage error mape and mae the model performance is high in the results since the predicted and actual data strongly fit each other fuzzy logic based models are presented in table 5 4 3 deep learning models for lwl and rwl prediction the slr process extracted deep learning models to predict lwls although there are different types of deep learning techniques used this study grouped them into one category due to a limited number of studies on these types of models out of a total of 3 deep learning models 2 of them used long short term memory lstm whereas one of them used convolutional neural network cnn 4 3 1 conceptual background deep learning is a machine learning and ai technique that mimics how humans acquire knowledge deep learning algorithms are built in a hierarchy of increasing complexity and abstraction unlike typical machine learning algorithms which are linear 4 3 2 bibliographic review table deep learning models liang et al 2018 analyzed lstm to conduct their experiment on the lwl prediction study the study area was selected as the three gorges dam located in china the dataset consists of 4015 data rows estimated from 10 years of daily data the study predicts lwl by using the daily average tgd discharge daily average discharge at xiangtan station daily average discharge at taojiang station daily average discharge at taoyuan station daily average discharge at jinshi station and daily average precipitation as an input variable the evaluation metrics to test this study s performance were r2 and rmse it is concluded from the results that the lstm model outperforms the svm machine learning model damova et al 2020 investigated cnn to estimate future lwls the study was conducted on 3 three lakes in bulgaria kyrdjali studen kladenec and ivaylovgrad the dataset contains 3650 rows estimated from 10 years of daily accumulated data the study forecasts rwl by using precipitations solid and liquid soil moisture air temperature skin temperature vegetation index and in situ measurements of water balance characteristics as input variables the performance of the study was evaluated by using minmae the results show that the proposed model outperforms non semantic solutions and standalone gis models costa nourani et al 2021 used fully connected neural networks fcnn and long short term memory in their study to forecast lwls located in the usa the data size is not given but the temporal of the accumulated data is daily in this study the output is determined as lwl while the input as temperature density and northward and eastward water velocity the evaluation metric used in this study is an average error it can be determined from the results that both models have satisfactory results that enable predicting lwls accurately between fcnn and lstm models their performance was similar to each other however lstm needs more learning parameters to have equivalent results 5 overview of data driven modeling the reviewed studies used mathematical models in common the studies either derived their formula or generated a combination of different mathematical models to predict lakes or rwls the general direction towards feature selection is to use historical lwls some studies used multivariate attributes to predict future water levels in addition the tendency for evaluation metric selection includes rmse r2 and mae which constitute about 46 of all slr studies although studies give meaningful results to measure water supplies in the drinking water reservoir they lack the integration between water supply prediction and water management system decision processes the majority focus on the study intention is either drought prediction or flood prediction the modeling techniques alter in terms of publication date recent studies usually focus on machine learning guyennon et al 2021 koch et al 2021 and deep learning techniques damova et al 2020 costa nogueira jr et al 2021 while past studies used mathematical person et al 2007 paynter and nachabe 2011 and regression based models lin et al 2015 garcía molinos et al 2015 the drastic change comes from the evolution of machine learning and deep learning techniques in recent years therefore there is still an open research area to focus on machine learning and deep learning techniques to predict lwl and rwl for future periods although some researchers favor some algorithms for their studies these algorithms are chosen in terms of specific needs considering their advantages and disadvantages 6 discussion for survey research to be effective it must review and evaluate the existing literature and present a thorough argument that will be useful to readers who are interested in this section a number of crucial ideas are distilled and explored in light of the reviewed study on ai models for lwl modeling compared to previous conceptual models ann and rnn models can be simply converted from univariate to multivariate instances moreover by modifying the learning algorithms transfer functions and model structure ann and rnn models complexity may be easily adjusted similar to regression models correlation analyses or empirical evidence may be used to assign the input variables according to the reviewed articles the findings show that in comparison to other models like arma and decision trees ann and rnn models can accurately forecast the lwl and capture the non linear behaviors of the lwl in various locations and case studies the input data used is crucial when creating lwl prediction models over a specific time frame several researchers have built their models for predicting lwl solely using the delays of lwl some researchers on the other hand coupled historical lwl data with hydrological factors including precipitation evaporation sunshine length temperature river flow discharge and so on according to this review the majority of researchers have exclusively employed hydrological or meteorological factors for lwl forecasting long term growth of deep learning applications in hydrology is anticipated due to improvements in computing power and internet technologies in fact compared to other hydrological variables like water level and discharge the application of deep learning in lwl and rwl prediction is still very limited it comes as no surprise that there will soon be more deep learning reservoir related articles available if exploited intelligently lake and reservoir which are currently underexplored in many regions of the world can offer an alternate approach to lessen problems with water stress lake resource management requires accurate knowledge and predictions in order for local governments to fully utilize the deep learning extracted lwl information future research collaborations between researchers and local stakeholders must be strengthened for example the creation of tools with user friendly graphical user interfaces may encourage the use of deep learning in lwl simulation and forecasting by local stakeholders and users with little programming experience information about the lake can be obtained and processed more intelligently with larger user groups thanks to the internet of things iot paradigm smart water quantity and quality monitoring systems have been accelerated by improvements in computing power internet speed and coverage as well as the quick development of software technologies like cloud storage systems and service oriented architecture thus it is anticipated that the adoption of iot would make it easier to gather lwl data iot and deep learning integration can deliver more precise real time lwl data collection transport and analysis at a lower cost the choice of input was mostly determined by how those variables affected the chosen result precipitation 17 lwl and evaporation were the most preferred input variables by researchers several factors rely on the location which may have an impact on the lwl directly or indirectly it is also worth to mention that remote sensing data is also a good validation criterion for model performance the final given results for lwl or rwl such as radar altimetry observations are serving as a good current long term independent source for validation when evaluating how good any modeled data could be few researchers focused on this aspect by using remote sensing data chen et al 2020 huang et al 2011 zhu et al 2017 although state of the art algorithms such as lstm and gru models give the best results liang et al 2018 costa nogueira jr et al 2021 thanks to their sequential structure the model could be further developed but some recent efforts to integrate attention based mechanisms didn t outperform zhu et al 2022 other novel perceptions could help to increase the prediction performance in the future 7 conclusion the available potable water is an imminent concern for the human society which is considered to affect the near future the main supply of drinking water comes from lakes which are in danger of drying up if the water is consumed at today s pace therefore various studies focus on water level prediction of lakes and reservoirs especially after 2015 predicting water levels would enable water management systems for lakes to work efficiently this study reviews lwl prediction using five different algorithms equation based ann decision tree fuzzy logic and deep learning models the models were compared with each other in several studies to see the effect of model performance the advantages and disadvantages of the models were evaluated and discussed in detail this study has several limitations that have to be improved in further studies the studies rely on recent ai modeling techniques that still continue to get better at rapid pace in addition this study is limited to the search words that are stated in the methodology section there may be other studies that don t include these generic search words in title abstract keywords but the topic may be about lake water level prediction the study directs the future to study integration with water management systems and decision support suggestions for these systems in addition the findings could direct scholars to study other drinking water supplies to predict to prevent extreme drought conditions author contributions conceptualisation s o m y and s o y methodology s o s o y validation s o formal analysis s o investigation s o s o y and m y data curation s o writing original draft preparation s o writing review and editing s o m y and s o y visualisation s o and m y supervision s o y project administration s o s o y and m y all authors have read and agreed to the version of the manuscript declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests muhammad yaqub reports financial support was provided by national research foundation of korea acknowledgements south korean part of this study was supported by the national research foundation of korea nrf grants nrf 2021r1i1a1a0105783111 from the korean government msit to dr muhammad yaqub abbreviations ai atificial intellience anfis adaptive neuro fuzzy inferren sys ann artificial neural network annbp adapt neural network backprop aoff amount of forecast factor armax auto reg mov avg with exog inp bart bayesian additive regression trees blr bayesian linear regression bdtr boosted decision tree regression bhrm bayesian harmonic regress models cart classification and regression trees cc chance constrained ce copula entropy cnn convolutional neural network dfa dynamic factor analysis dfr decision forest regression dic deviance information criterion doc degrees of confidence dwl dam water level dwt discrete wavelet transformation dtc decision tree classifier dtr decision tree regression ef efficiency index elm extreme learning machine etc extra tree classifier etr extra tree regression fcnn fully connected neural network feflow finite element subsurface flow fnn fuzzy neural networks fvcom finite volume 3d ocean model gam generalized additive model gbr gradient boosting regression gev generalized extreme value glm generalized linear model gnb gaussian naïve bayes gp gaussian process gpr gaussian process regression grace gravity recovery and climate exp grnn generalized regression neural net htc hoeffding tree classifier hat c hat classifier hat r hat regression hss heidke skill score htr hoeffding tree regression iot internet of things kge kling gupta efficiency knc k neighbors classifier knn k nearest neighbor knr k neighbors regression lbrm large basin runoff model llc lake level change lmi legates and mccabes index lor logistic regression lr linear regression lstm long short term memory lwb lake water balance lwl lake water level m5p m5 pruned mae mean absolute error mape mean absolute percentage error mare mean absolute relative error mars multivariate adaptive reg spline mbe mean biased error mcc multiple correlation coefficient mlp multilayer perceptron mlp r multilayer perceptron regression mlr multiple linear regression mpmr minimax probability machine reg mre mean relative error mse mean squared error modm multi objective decision model nbs net basin supply nic normalized information contribut nn neural network nnr neural network regression noah mp lsm noah multiparamet land surf mo nrmse normalized root mean square er nsc nash sutcliffe criterion nse nash sutcliffe efficiency p precipitation p e anomalous net freshwater pbias percent bias plsr partial least squares regression prevah precipit runoff evapo hydrotope qac quality assessment checklist r coefficient of correlation r2 coefficient of determination rae residual absolute error rapid rout app for para comp of disc rbnn radial basis neural networks rcp represent concentration pathway rept reduced error pruning tree rf random forest rfc random forest classifier rfr random forest regression rmse root mean squared error rsd residual standard deviation rse residual standard error rsos residual sum of squares rss regression square sum rvm relevance vector machine rwi refined willmott s index rwl reservoir water level rt random tree sd standard deviation src spearman s rank correlation srpf statistical reg predictive function ss sum of squares svm support vector machine svr support vector regression svr gwo sup vec reg grey wolf optim swgm surface water groundwater model vic variable infiltration capacity wbcm water budget conceptual model wbm water balance model wbnm water balance network model wnn wavelet neural network wshm watershed scale hydrologic model 
25413,anthropogenic hydrologic alteration threatens the health of riverine ecosystems machine learning algorithms that employ the use of model trees to predict hydrologic alteration are underrepresented in related literature this study assesses hydrologic alteration in the pearl and pascagoula river basins using modeled daily streamflow hydrologic alteration was determined by hypothesis testing and the computation of the net change across 60 years cubist models were developed for both basins to predict hydrologic alteration and to identify important basin characteristics results from net change and the hypothesis test indicated the basins were essentially identical with respect to the amount of hydrologic alteration cubist models for the basins successfully made accurate predictions of hydrologic alteration and demonstrated that the importance of basin geomorphology and land cover on alteration differed in both basins the results of the study demonstrate the feasibility of model trees in assessing hydrologic alteration keywords cubist machine learning model tree hydrologic alteration data availability data used in this study may be found in a data release at the following url https www sciencebase gov catalog item 615234cbd34e0df5fb9bd87b 1 introduction flow of many streams in the united states and globally has been altered by human activities jackson et al 2001 jackson and marmulla 2001 jowett and biggs 2009 king et al 2000 throughout history humans have been in competition with the natural environment over water which and the relationship has grown complex as people become more aware of the services provided by riverine ecosystems arthington et al 2006 additionally unsustainable water consumption has led to a range of deleterious effects on stream ecosystems and the availability of water to support the global human population dye and bosch 2000 frederick and gleick 2001 schindler 2001 moreover others have noted that failed policies and insufficient regulation of water resources driven by a lack of understanding pose an existential threat for future generations arthington and pusey 2003 serageldin 1995 answering critical questions related to human interactions with the hydrologic environment can improve our understanding of hydrologic alteration and the threat it poses to stream ecosystems how does hydrologic alteration influence riverine ecosystems and to what spatial and temporal extents are these phenomena observable with respect to perturbations of the natural streamflow regime what are the climatic and anthropogenic drivers of these perturbations how do we best quantify hydrologic alteration lastly can we predict factors and the magnitude of hydrologic alteration using data driven methodologies and what approaches are most appropriate we address with this study the last two questions by computing quantitative metrics of hydrologic alteration and then using a collection of models to predict those same metrics riverine ecosystems are dependent on streamflow to regulate water quality energy resources physical habitat and biotic interaction poff et al 1997 over time these ecosystems have evolved to thrive in response to the natural fluctuations of streamflow fluctuations in the magnitude timing duration and overall rate of change of streamflow are key to maintaining healthy riverine ecosystems poff et al 1997 due to the significant role that streamflow plays in the environment it is also important to recognize hydrologic alteration of the natural streamflow regime as a major threat to the health of riverine ecosystems bunn and arthington 2002 carlisle et al 2011 jackson and marmulla 2001 poff et al 2007 pringle et al 2000 yu et al 2016 fundamentally the hydrology of a stream in pristine conditions i e those without substantial human interactions is a function of the climatic conditions watershed geomorphology and the geologic setting bunn and arthington 2002 frissell et al 1986 as water demand has grown with changes in the size and distribution of human populations finding pristine streamflow conditions is difficult due to societies reliance on water resources for drinking irrigation industry and in the production of energy the changing landscape in the united states has greatly disrupted the natural flow regime dahl 1990 graf 1999 poff et al 2006 poff and hart 2002 for the riverine environment land use change can be a greater threat to the health of riverine ecosystems than climate related changes peterson and kwak 1999 for example many studies focusing on urban watersheds have described increasing flows and flashiness of streamflow and changes in baseflow in response to changes in the imperviousness of the watershed bledsoe and watson 2001 konrad et al 2005 hollis 1975 meyer 2005 simmons and reynolds 1982 away from urban areas conversion of land cover for agricultural use is connected to declining baseflow longer low flow events and increasing stream flashiness dow 2007 lenhart et al 2011 sparks 1995 yasarer et al 2020 pressure on riverine ecosystems is projected to increase by 2050 as water scarcity affects an increasing number of countries globally liu et al 2017 palmer et al 2008 petts 2009 rockström et al 2009 zhang et al 2016 dams and reservoirs represent a source of hydrologic alteration because of the role they play in sustaining water supply and controlling floods operating dams and reservoirs cause substantial fluctuations in streamflow from sub daily to seasonal temporal scales resulting in a more homogeneous flow regime that primarily reflects the frequency and timing of reservoir releases and other operational activities botter et al 2010 mcmanamay et al 2012 pérez ciria et al 2019 zhang et al 2016 the effects of dams on streamflow timing and magnitude vary based on the type operation and storage capacity of dams mcmanamay et al 2012 richter et al 1996 in assessing the influence of dams on streamflow comparative analysis of pre and post periods of flow regulation represents one of the most robust and well studied approaches gao et al 2009 pyron and neumann 2008 richter et al 1996 one advantage of this approach is that it controls for physical factors that are unique to the basin of study and allows for more direct analysis of temporal changes in streamflow mcmanamay et al 2012 however a weakness to this approach lies in the ability to distinguish climatic versus anthropogenic factors of hydrologic alteration particularly when strong climatic gradients exist during the period of analysis botter et al 2010 as a result the popularity of statistical model based approaches has grown for estimating natural streamflow conditions in addition to quantifying the amount of hydrologic alteration and the underlying drivers of hydrologic alteration assessments of hydrologic alteration must begin with the characterization of stream attributes in the absence of human activity or where humans have had minimal influence carlisle et al 2010 a variety of methodologies have been developed to estimate natural streamflow conditions using rainfall runoff models bock et al 2016 mccabe and wolock 2011 in recent decades advances in computational abilities and the availability of streamflow climate and geomorphological data have enabled researchers to apply data driven methodologies to estimate streamflow characteristics with the use of machine learning algorithms carlisle et al 2016 miller et al 2018 preis and ostfeld 2008 snelder et al 2009 many studies have demonstrated the usefulness of regression trees schnier and cai 2014 sharma et al 2021 support vector machines asefa et al 2006 maity et al 2010 and artificial neural network approaches adnan et al 2017 isik and ozden 2013 to predictive modeling of complex hydrologic systems and the assessment of hydrologic alteration the indicators of hydrologic alteration iha richter et al 1996 were developed to provide a tool that used streamflow characteristics as indicators of the effects of alterations on the ecological functions of riverine ecosystems from numerous contributing factors mathews and richter 2007 this methodology has been used successfully to assess hydrologic alteration in many studies ali et al 2019 gao et al 2012 koel and sparks 2002 however the iha has drawn scrutiny because of its overall complexity 33 streamflow variables and 34 eco flow variables and statistical redundancy in favor of more simplistic approaches that are equally as capable of accurately determining the impacts of hydrologic alteration gao et al 2009 this study explores using generalized metrics to describe patterns of hydrologic alteration in two major river basins in the southeastern united states we employed two flow duration curve based methodologies to identify streamflow records that have undergone significant hydrologic alteration p value 0 05 and to determine the magnitude and nature of this change based on the results of these two methodologies this study tests the hypothesis that hydrologic alteration in the basins can be attributed to the influence of land cover change flow regulation by dams and the resulting amount of water stored in each basin understanding the importance of this type of information to water resource managers statistical models were developed to predict altered streamflow as a function of watershed attributes a rule based regression tree modeling approach was used to evaluate the importance of individual watershed characteristics e g land use and streamflow regulation to predicting hydrologic alteration predictions in watersheds with similar climate topography and land cover 2 study area our study focuses on the pearl river and pascagoula river basins located in the coastal plain physiographic region of central and southeastern parts of mississippi in the southeastern united states fig 1 the annual average temperature ranges from about 11 c 51 fahrenheit to about 25 c 77 fahrenheit and the average annual precipitation for the area ranges from 1372 mm 54 inches to 1499 mm 59 inches arguez et al 2010 the pearl river basin drains an area of approximately 22 688 km2 the pearl river is approximately 789 km long beginning in neshoba county and drains into the mississippi sound and the gulf of mexico in the head waters of the basin the landscape consists of rolling hills which transition into flat floodplains near mississippi s gulf coast forests are the predominant land cover in the basin 50 percent followed by pasture and rangeland which accounts for approximately 24 percent of the basin s area mississippi department of environmental quality 2008 historically the pearl river has been prone to major flooding most notably in 1979 which damaged residences and businesses costing more than 500 million dollars an equivalent of more than 1 billion dollars today nws jackson ms 1979 pearl river flood weather gov the ross barnett reservoir is the only major impoundment on the pearl river the reservoir was constructed in the 1960s covers an area of 134 km2 and is the primary source of drinking water for the city of jackson the state s capitol and surrounding areas wersal et al 2006 the reservoir also acts as a flood control structure and recreational waterbody the pascagoula river is the largest and only river unaffected by dams that drains into the gulf of mexico dynesius and nilsson 1994 the pascagoula river basin is the second largest river basin in mississippi and drains an area of 24 864 km2 before emptying into the mississippi sound and gulf of mexico 130 km downstream of the confluence of the leaf and chickasawhay rivers the basin s landscape transitions from rolling hills and shallow streams in the north to flat swampy bottomlands in the southern part of the basin forest is the predominant land cover 59 percent in the basin followed by cropland and pastures which account for 21 percent of the basin s area mississippi department of environmental quality 2001 developed land in the basin only accounts for approximately one percent of the basin area in 1999 timber production from the basin accounted for 26 percent of timber production for the state population centers in the basin include hattiesburg and the coastal cities of pascagoula biloxi and gulfport 3 materials and methods 3 1 streamflow data modeled streamflow data used in this study are available for 9201 huc12 pourpoints across states that border the gulf of mexico for the period from 1950 to 2009 from robinson and knight 2020 the streamflow model was constructed using a decade of daily streamflow data from january 2000 through december 2009 at 74 u s geological survey usgs streamgages located within the mobile tombigbee and the galveston trinity river basins spanning parts of alabama mississippi texas and louisiana worland et al 2019 these basins were selected to represent unique climatic and physiographic properties that included sites on regulated and unregulated streams across the region a more detailed discussion of the methodology used to predict the streamflow data used in this study can be found in worland et al 2019 3 2 hydrologic alteration metrics the modeled streamflow data for huc12 units in the pearl river basin 234 and pascagoula river basin 295 were divided into pre and post alteration periods the pre alteration period included streamflow data from january 1 1950 through december 31 1969 and the post alteration period included data from january 1 1990 through december 31 2009 we chose to use the split period approach because it controlled for the physical parameters of the huc12 units over a 20 year interim period in which hydrologic alteration may have been a result of climatic or anthropogenic influences similar to what is described by richter et al 1996 moreover a 20 year transition period was selected because it met the minimum requirements of the statistical analysis discussed later in this section the first indicator of hydrologic alteration computed was the net hydrologic change referred to as net change in this study referred to as ecochange by gao et al 2009 to compute the net change we began by computing the ecosurplus and ecodeficit introduced by vogel et al 2007 as metrics to evaluate changes in streamflow in response to flow regulation or other forms of hydrologic alteration directly impacting the streamflow regime these metrics are computed using flow duration curves fdcs computed over any temporal scale and reflect the overall gain ecosurplus or loss ecodeficit of streamflow resulting from alteration vogel et al 2007 based on the approach used by vogel and fennessey 1994 median annual fdcs for the pre and post alteration periods were estimated for each huc12 the fdcs were then compared across the full range of flows to develop curves and identify exceedance probabilities at which the two curves intersected if during the pre alteration period streamflow was greater than the post alteration period then the ecosurplus was calculated as the ratio of the area between the pre and post alteration fdcs to the area beneath the entire pre alteration fdc conversely if the pre alteration period streamflow was less than the post alteration streamflow then the ecodeficit was calculated in the same manner as the ecosurplus lastly the two terms were combined as described by gao et al 2009 to attain a value of the net change which reflects the net effect of hydrologic alteration on the amount of available streamflow the confidence interval hypothesis test ci test kroll et al 2015 which calculated the significance p value of the departure of the post alteration mean fdc from the pre alteration mean fdc was computed as a second indicator of hydrologic alteration jackknife resampling with 1000 iterations of the pre alteration years was performed with each iteration resulting in 5 random years in the pre alteration period mean fdcs were calculated from each 5 year pre alteration group and the p value was determined for each mean fdc the ci test checks if the resulting distribution of p values for the pre alteration mean fdcs are consistent with the null hypothesis that streamflow is not significantly altered relative to this period next mean fdcs and p values were computed for daily streamflow in the post alteration period the p values computed from this step represents the probability that the quantile of streamflow at any exceedance probability falls outside the confidence interval of the mean fdc for the pre alteration period kroll et al 2015 for this study the departure was considered statistically significant if the p value was less than or equal to 0 05 results of the hydrologic change analysis and the confidence interval hypothesis tests are available from crowley ornelas and roland 2023 3 3 cubist to explore the influence of basin characteristics on the resulting p values from the ci test we constructed m5 cubist models in the r programming language r core team 2022 for each basin using the cubist r package kuhn and ross quinlan 2022 a cubist model is a regression tree that employs the use of rules at terminal nodes of the tree to condition predictions of a given variable loh 2014 worland et al 2018 similar to other regression tree models cubist model predictions are based on the values of predictor variables that fall within the splits that subdivide the prediction space of the model worland et al 2018 the prediction space of the model refers to the portioned set of predictor variables based on their relationship to the target variable of the model the splits are determined based on an algorithm that seeks to minimize model prediction error at each node of the tree by conditioning those predictions based only on nodes belonging to the same branch of the tree at each node of the tree the cubist model produces a linear regression model quinlan 1993 quinlan 1993 describes committees and neighbors as the two hyperparameters of the cubist model cubist uses the number of committees to demarcate a number of ensemble models used in predictions the resulting prediction of the target variable is the mean of the predicted value from all ensemble models the number of neighbors refers to the number of prediction cases with similar values of the target variable to be used to predict the value of a new case when a number of neighbors is specified the predicted value is the mean of predicted values of the nearest neighbors during model development values of the hyperparameters were optimized to mitigate model error and improve model fit a ten fold cross validation procedure was used to find the optimal number of committees and neighbors the final pearl river basin model was constructed with 6 committees and 1 neighbor and had a total of 298 rules with an average of about 50 rules per committee the final pascagoula river basin model consisted of 334 rules with an average of 56 rules for each committee the model had six committees and two neighbors during model development adding more committees provided marginal improvement with respect to model accuracy however increasing the number of committees eventually produced no change in model performance reduced model parsimony and increased redundancy of the rules in the model tree the models were constructed using covariate data published by crowley ornelas et al 2019 for the period from 1950 to 2000 at a decadal time step covariates used in the models fall into five general categories variables related to basin geomorphology basin slope basin area topographic wetness index twi accumulated stream length stream density sinuosity land cover variables wetland developed open water forest cultivated cropland and hay and pasture water storage and infrastructure variables flood storage normal storage and upstream road crossings rdx environmental mean precipitation and mean temperature and other net change a summary of the covariate data used to construct the models along with model results can be found in crowley ornelas and roland 2023 after constructing the database of predictors and the response variable a random sampling of 70 percent of the database was used to train the model and the remaining 30 percent of the data were used as test data to evaluate the performance of each model model performance was evaluated by calculating the nash sutcliffe efficiency nse root mean square error rmse mean absolute error mae and percent bias pbias the nse was computed to assess the overall fit of the model predictions to the observed values the rmse was computed because it is a more conservative measure of model error than the mae the mae was used as an error metric because it is a simple metric to compute and interpret however the mae does not provide a measure of the direction of model prediction errors as a result the pbias was calculated to determine the tendency of the model to overestimate or underestimate predictions as a part of this study we were also interested in the individual importance of covariates used in model predictions the importance of covariates used in the basin models were evaluated by determining the frequency at which variables were used in the model rules and regression equations the caret r package kuhn 2021 was used to determine the importance of each covariate by combining the usage of each covariate in rule conditions and in the model linearly a more detailed discussion of this topic can be found in kuhn 2021 4 results 4 1 net change the results of the net change analysis provided more insights about changes in amount of streamflow in the pearl and pascagoula river basins between 1970 and 1990 the computed values of net change in the pearl and pascagoula river basins demonstrated a high degree of similarity between the two basins with respect to changes in streamflow volume similar to the results of the ci test there was no statistically significant difference p value 0 05 in the variance of the computed net change values fig 2 in the pearl river basin the median net change value was 0 19 and in the pascagoula river basin the median net change value was 0 22 median net change values indicated that most huc12 units in both basins had a net surplus of streamflow in the pearl river basin 97 percent of huc12 units had a net surplus and in the pascagoula river basin 95 percent of huc12 units had a surplus only 22 huc12 units had a net deficit across both basins the implication of this result is that relative to the pre alteration period streamflow volumes typically increased from 1970 to 1990 however this varied spatially fig 3 less water was delivered to downstream huc12 units from huc12 units near the outlets of the pearl and pascagoula river basins in some cases the amount of water delivered to the mississippi sound and gulf of mexico had decreased in the upper part of the pearl river basin five huc12 units had a net deficit which indicated less streamflow was delivered to downstream huc12 units post alteration however in the middle part of the basin streamflow delivery from huc12 units increased particularly near densely populated areas net change values for huc12 units near the outlet of the basin were typically smaller with respect to values computed for huc12 units in the middle part of the basin conversely values of the net change in the pascagoula river basin decreased from the upper part of the basin toward the basin outlet huc12 units with net deficits were also located near the basin outlet along the mississippi sound in the computed net change values a similar pattern of a collection of huc12 units across the boundaries of both watersheds had similar net change values coinciding with the band of altered huc12 units based on the results of the ci test 4 2 confidence interval hypothesis test the results of the ci test indicated that both basins had a similar number of huc12 units that had experienced a statistically significant amount of hydrologic alteration during the period from 1970 to 1990 in the pascagoula river basin 22 percent of huc12 units were altered and in the pearl river basin 26 percent of huc12 units were altered however the slight difference in the percentages of altered huc12 units between the two basins was not statistically significant p value 0 05 the median p value in the pascagoula river basin was 0 27 fig 4 in the pearl river basin the median value was 0 34 and the range of p values calculated had greater variance than the pascagoula river basin based on visual inspection of mapped p values altered huc12 units typically corresponded with locations of impoundments in both river basins in the pearl river basin altered huc12 units were grouped around small dams on tallahaga creek upstream and downstream of the ross barnett reservoir and dam on the mainstem of the pearl river fig 5 in the pascagoula river basin altered huc12 units were more concentrated around the headwater tributaries of the pascagoula river specifically huc12 units with statistically significant hydrologic alteration occurred at locations upstream and downstream of okatibbee dam on okatibbee creek and in huc12 units along the leaf river near the confluence of the leaf river and the chicakasawhay river and along the mainstem of the pascagoula river most huc12 units were not altered although there were some exceptions huc12 units located around the mainstem were typically unaltered and moving east or west away from the main channel the number of altered huc12 units increased toward the east there were clusters of altered huc12 units along the eastern boundary of the basin near mobile alabama west of the main channel a cluster of altered huc12 units extended across the boundaries of the two basins forming a band across the lower part of both basins the locations of these altered huc12 units corresponded with the gulfport biloxi and pascagoula metropolitan area 4 3 cubist models the overall fit of both the pearl and pascagoula cubist models was good based on the computed nse values table 1 according to moriasi et al 2015 a nse greater than 0 8 can be considered very good error evaluation statistics rmse and mae for each model were both satisfactory based on the criteria established by singh et al 2005 which defined a low rmse or mae as less than half of the standard deviation of the observed values which was 0 15 for the pascagoula and 0 16 for the pearl for both models pbias was determined to be acceptable because less than one percent of model predictions were overestimates or underestimates of the observed p values pbias for the pearl and pascagoula models had some underestimates of p values on test and training data however this accounted for less than one percent of model predictions in all cases the only exception was the pearl model predictions on the model training data which tended to overestimate p values predictions made by the pearl model generally showed good agreement with most of the observed p values fig 6 a based on this plot model errors were generally within a consistent range although there were exceptions most notably in p values ranging from 0 4 to 0 8 the pascagoula model tended to overestimate p values in the lower ranges but underestimated larger p values fig 6b the pearl and pascagoula models were similar in that they exhibit more error in predictions across similar ranges of observed p values much of the model error exhibited by both models can be explained in the specification of the two models for some huc12 units the model could be improved by incorporating additional variables to characterize features or activities in the watershed that have not been included in the final model such as changes in population distribution or water use another potential source of error is derived from edge cases in the ensemble of model trees where regression equations were not estimated in these situations the predicted p value represents the median value of the observed p values for cases with conditions covered by that rule analysis of predictor variable usage provided a means of assessing the influence of predictor variables on model predictions as a measure of the usage of predictor variables in rule conditions or in the linear regression equations at each node of the tree we computed the variable importance assuming that the most significant variables in the models have an importance of 50 percent or more the most important variables in the pearl model were basin slope net change and rdx fig 7 a these results indicate that basin slope was used most frequently to partition the observed p values in the conditions of rule cases or to be included in the linear models associated with particular rules it should be noted here that the importance of variables in the models does not have to add to 100 percent because they are a measure of the usage in each model not all variables are used in each linear equation in the model tree nor are they all used in every rule condition in the model tree in the pascagoula model the most important variables were the computed net change rdx basin slope twi percentage of hay and pasture the percentage of wetland and sinuosity fig 7b based on these results we concluded that geomorphology had similar importance in both models but land cover was generally more important in the pascagoula model than in the pearl model analyzing the coefficients of the linear models in the model tree allowed for a general view of the influence of the most important variables on p value predictions for this analysis we used the median values of the coefficients to determine if a particular coefficient had a positive or negative effect on the predicted p values a negative median coefficient value indicated a variable typically decreased p values a positive median coefficient value indicated a variable typically increased p value the results indicate that some variables typically have the same effect on hydrologic alteration for both basins i e the variable is typically associated with an increase for both basins or a decrease for both basins and other variables have an opposite effect for each basin i e the variable is associated with an increase in one basin and decrease in the other or vice versa variables that typically had the same effect for both basins were developed land basin slope and net change for both models basin slope had the largest negative coefficient value fig 8 this result suggested that larger basin slope was associated with more hydrologic alteration in addition to basin slope developed area and net change tended to increase hydrologic alteration in both basins in both basins increasing forest area indicated less hydrologic alteration variables that typically had opposite diverging effect for both basins included all other land cover type variables wetland area and hay pasture all increased hydrologic alteration in the pearl but decreased hydrologic alteration in the pascagoula open water displayed a strong increasing effect on alteration in the pearl river basin but its effect was strongly decreasing in the pascagoula river basin the exception was cultivated cropland which decreased hydrologic alteration in the pearl river basin but increased hydrologic alteration in the pascagoula river basin land cover change between 1950 and 2000 was similar in the pearl and pascagoula river basins crowley ornelas et al 2019 during this period wetland land cover decreased by approximately 16 percent in both basins and cropland land cover decreased by 79 percent in the pearl river basin and 67 percent in the pascagoula river basin fig 9 one of the starkest changes in land cover in the basins came from drastic increases in the amount of developed area 110 and 200 percent in the pearl and pascagoula river basins respectively such drastic increases in the amount of developed area provides an additional explanation of the increasing streamflow during the post alteration period the pattern of net change and p values of huc12 units in both basins demonstrated findings that were consistent with those of khanal 2012 that link downstream effects on streamflow in the pearl river with anthropogenic activities in the upper part of the basin 5 discussion using synthetic daily streamflow data to investigate hydrologic alteration provided a means to quantify alteration in gaged and ungaged stream reaches across the pearl and pascagoula river basins a major consideration when designing the study and interpreting its results was the ability of the modeled streamflow data to broadly represent physical conditions and thereby provide a valid representation of hydrologic alteration in the two basins the results of this study indicated that both basins were nearly identical with respect to the number of altered huc12 units after 1970 similarly watersheds in both basins have generated more streamflow since the 1970s lins and slack 1999 and 2005 reported increasing streamflow trends from the 1940s through the 1990s in the south atlantic gulf water resource region wherein the pearl and pascagoula river basins are located moreover interdecadal variability in streamflow with respect to climatic oscillations such as the atlantic multidecadal oscillation amo and the el nino southern oscillation enso also support the notion of increasing streamflow over the period of study tootle et al 2005 in the southeast warm phases of the amo in the 1950s and 1960s were typically associated with less streamflow in the region the cold phase of the amo which dominated the temporal domain of this study resulted in more streamflow across the region the authors cited extreme flooding events enso and hurricane activity as contributing factors to streamflow during amo cold phases although climate variability provides context for the general patterns of changes in streamflow magnitude confounding factors that influence streamflow need to be considered i e anthropogenic activities which were explored using the basin models cubist models constructed for each basin demonstrated a high level of accuracy and the unique effects of basin characteristics on the hydrology of the two basins anthropogenic activities such as channelization dams and reservoir construction are linked to hydrologic alteration as demonstrated by the basin models this result has been explored in other studies in the pearl river basin whereby geomorphic instability of the river channel from anthropogenic activities has been linked to diminished fish populations piller et al 2004 tipton et al 2004 similarly in the pascagoula river basin geomorphic instability has historically been tied to land cover conversion and various mining activities along major tributaries of the river mossa and coley 2004 the leaf river is an example in the pascagoula basin where the mean elevation of the river channel has decreased over the years from mining activities along the banks of the river mossa 2003 our results indicate that geomorphology is an important driver of hydrologic alteration in the basins however its impact was more pronounced in the pearl river basin than in the pascagoula river basin in the pascagoula river basin and to a lesser extent in the pearl river basin land cover conversion was a significant driver of hydrologic alteration bell waldron et al 2020 reported that between 1950 and 2014 marsh area extents near the mouth of the pascagoula river declined by nearly 18 percent with nearly 10 percent of marsh area converted to open water since 1955 many studies have attributed wetland loss along mississippi s gulf coast to urbanization deposition of dredging material and direct wetland conversion to open water between 1950 and 1992 meyer arendt 1989 oivanki et al 1995 meyer arendt et al 1998 moreover the rate of loss of coastal wetland is anticipated to increase as sea levels rise in response to climate change bell waldron et al 2020 wetland and open water land cover change represent one type of land cover conversion impact on hydrologic alteration but both are linked to urban development in the basin in the southern united states the percent of the population living in urban areas has increased dramatically over the past several decades from 18 percent living in urban areas to 72 percent between 1900 and 2000 o driscoll et al 2010 over several decades the growth of urban areas has had many impacts on hydrology and riverine ecosystems in recent decades in the pascagoula river basin urbanization driven by population and economic growth from fossil fuel production has led to impairment of stream reaches in the basin merem et al 2011 moreover stream impairment and hydrologic alteration are further exacerbated by the urbanization of farmland whereby farmland which once acted as a buffer for runoff entering the stream no longer exists giving way to diminished water quality in addition to geomorphic instability in addition to historical changes in the basin climate change threatens to intensify the negative effects of land cover change in the southeast climate change is expected to increase the magnitude and frequency of extreme precipitation events daily 20 year extreme precipitation is projected to increase by as much as 12 by mid century and 21 by the end of the century easterling et al 2017 the implications of current patterns of development in watersheds in a time of climate change may be varied and water resource managers could be challenged to develop management strategies which effectively weigh the advantages and disadvantages of socio economic changes while considering important ecosystem services and their associations 5 1 model limitations because of the complex nature of hydrologic alteration constructing models that accurately represent conditions in the physical environment is challenging not having access to sufficient quantities of quality data is an important source of model error and overall model uncertainty constructing models with sufficient amounts of quality data better informs models and enables more accurate representations of the processes effecting model predictions as many statistical models are often data intensive the application of cubist explored in this study demonstrates cubist models can be accurate when trained on relatively small amounts of data machine learning models can identify complex relationships that might otherwise be dismissed as model error due to data constraints or as an instance of an incomplete understanding of the physical processes occurring in the model domain the specifics of the mechanics of this process are not obvious therefore a robust analysis of model predictions and agreement with respect to physical conditions is important to interpreting model predictions and describing the physical processes at play in selecting an appropriate modeling algorithm the trade off between model accuracy and model interpretability must be considered interpretation of the cubist decision tree become increasingly complex as the tree grows i e increasing number of rules and committees linear models at the leaves of the tree are optimized to reduce prediction error at that branch which results in less overall model error as the tree grows before reaching a point where model error no longer decreases in applications where model interpretability is prioritized a smaller tree may be preferred for a more general representation of the relationships between model predictions and predictors the linear models in the tree allow for quick interrogation of model predictions that can be helpful in determining an appropriate tree size for maximum accuracy and reasonable interpretability 6 conclusion the results of this study demonstrated the potential of applying machine learning in the context of determining the effects of human interactions with the natural environment the application of a cubist model in this study provided interesting insights about the pearl and pascagoula river basins and factors contributing to hydrologic alteration the models were able to demonstrate with accuracy the most important drivers of hydrologic alteration in the two basins which had similar amounts of altered huc12 units the models identified changing land cover and geomorphic instability related to dam construction and mining activities as important anthropogenic activities in the basins effecting streamflow between 1950 and 2009 the ability of predictive models to identify and characterize processes and sources of hydrologic alteration accurately can support water resource managers in implementing appropriate management actions with respect to resource management and conservation the accuracy of the cubist models developed in this study demonstrate the potential of data driven approaches towards the development of effective management strategies to help target places in need of additional investment towards conservation and remediation the methodologies presented in this study enables resource managers to not only assess the current conditions of hydrologic alteration in basins but also provide a way for managers to assess the impact of future changes on basin hydrology applying cubist models in a decision support framework not only allows resource managers to assess many different scenarios in their watersheds but the models can be implemented as living models where updates may be automated using workflows unique to the needs of users declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests victor roland ii reports financial support was provided by gulf coast ecosystem restoration council acknowledgements funding for this research was provided by the gulf coast ecosystem restoration council we would like to thank all individuals that participated in the planning and execution of this work we would also like to thank all anonymous reviewers for their constructive feedback which served to improve this work any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government 
25413,anthropogenic hydrologic alteration threatens the health of riverine ecosystems machine learning algorithms that employ the use of model trees to predict hydrologic alteration are underrepresented in related literature this study assesses hydrologic alteration in the pearl and pascagoula river basins using modeled daily streamflow hydrologic alteration was determined by hypothesis testing and the computation of the net change across 60 years cubist models were developed for both basins to predict hydrologic alteration and to identify important basin characteristics results from net change and the hypothesis test indicated the basins were essentially identical with respect to the amount of hydrologic alteration cubist models for the basins successfully made accurate predictions of hydrologic alteration and demonstrated that the importance of basin geomorphology and land cover on alteration differed in both basins the results of the study demonstrate the feasibility of model trees in assessing hydrologic alteration keywords cubist machine learning model tree hydrologic alteration data availability data used in this study may be found in a data release at the following url https www sciencebase gov catalog item 615234cbd34e0df5fb9bd87b 1 introduction flow of many streams in the united states and globally has been altered by human activities jackson et al 2001 jackson and marmulla 2001 jowett and biggs 2009 king et al 2000 throughout history humans have been in competition with the natural environment over water which and the relationship has grown complex as people become more aware of the services provided by riverine ecosystems arthington et al 2006 additionally unsustainable water consumption has led to a range of deleterious effects on stream ecosystems and the availability of water to support the global human population dye and bosch 2000 frederick and gleick 2001 schindler 2001 moreover others have noted that failed policies and insufficient regulation of water resources driven by a lack of understanding pose an existential threat for future generations arthington and pusey 2003 serageldin 1995 answering critical questions related to human interactions with the hydrologic environment can improve our understanding of hydrologic alteration and the threat it poses to stream ecosystems how does hydrologic alteration influence riverine ecosystems and to what spatial and temporal extents are these phenomena observable with respect to perturbations of the natural streamflow regime what are the climatic and anthropogenic drivers of these perturbations how do we best quantify hydrologic alteration lastly can we predict factors and the magnitude of hydrologic alteration using data driven methodologies and what approaches are most appropriate we address with this study the last two questions by computing quantitative metrics of hydrologic alteration and then using a collection of models to predict those same metrics riverine ecosystems are dependent on streamflow to regulate water quality energy resources physical habitat and biotic interaction poff et al 1997 over time these ecosystems have evolved to thrive in response to the natural fluctuations of streamflow fluctuations in the magnitude timing duration and overall rate of change of streamflow are key to maintaining healthy riverine ecosystems poff et al 1997 due to the significant role that streamflow plays in the environment it is also important to recognize hydrologic alteration of the natural streamflow regime as a major threat to the health of riverine ecosystems bunn and arthington 2002 carlisle et al 2011 jackson and marmulla 2001 poff et al 2007 pringle et al 2000 yu et al 2016 fundamentally the hydrology of a stream in pristine conditions i e those without substantial human interactions is a function of the climatic conditions watershed geomorphology and the geologic setting bunn and arthington 2002 frissell et al 1986 as water demand has grown with changes in the size and distribution of human populations finding pristine streamflow conditions is difficult due to societies reliance on water resources for drinking irrigation industry and in the production of energy the changing landscape in the united states has greatly disrupted the natural flow regime dahl 1990 graf 1999 poff et al 2006 poff and hart 2002 for the riverine environment land use change can be a greater threat to the health of riverine ecosystems than climate related changes peterson and kwak 1999 for example many studies focusing on urban watersheds have described increasing flows and flashiness of streamflow and changes in baseflow in response to changes in the imperviousness of the watershed bledsoe and watson 2001 konrad et al 2005 hollis 1975 meyer 2005 simmons and reynolds 1982 away from urban areas conversion of land cover for agricultural use is connected to declining baseflow longer low flow events and increasing stream flashiness dow 2007 lenhart et al 2011 sparks 1995 yasarer et al 2020 pressure on riverine ecosystems is projected to increase by 2050 as water scarcity affects an increasing number of countries globally liu et al 2017 palmer et al 2008 petts 2009 rockström et al 2009 zhang et al 2016 dams and reservoirs represent a source of hydrologic alteration because of the role they play in sustaining water supply and controlling floods operating dams and reservoirs cause substantial fluctuations in streamflow from sub daily to seasonal temporal scales resulting in a more homogeneous flow regime that primarily reflects the frequency and timing of reservoir releases and other operational activities botter et al 2010 mcmanamay et al 2012 pérez ciria et al 2019 zhang et al 2016 the effects of dams on streamflow timing and magnitude vary based on the type operation and storage capacity of dams mcmanamay et al 2012 richter et al 1996 in assessing the influence of dams on streamflow comparative analysis of pre and post periods of flow regulation represents one of the most robust and well studied approaches gao et al 2009 pyron and neumann 2008 richter et al 1996 one advantage of this approach is that it controls for physical factors that are unique to the basin of study and allows for more direct analysis of temporal changes in streamflow mcmanamay et al 2012 however a weakness to this approach lies in the ability to distinguish climatic versus anthropogenic factors of hydrologic alteration particularly when strong climatic gradients exist during the period of analysis botter et al 2010 as a result the popularity of statistical model based approaches has grown for estimating natural streamflow conditions in addition to quantifying the amount of hydrologic alteration and the underlying drivers of hydrologic alteration assessments of hydrologic alteration must begin with the characterization of stream attributes in the absence of human activity or where humans have had minimal influence carlisle et al 2010 a variety of methodologies have been developed to estimate natural streamflow conditions using rainfall runoff models bock et al 2016 mccabe and wolock 2011 in recent decades advances in computational abilities and the availability of streamflow climate and geomorphological data have enabled researchers to apply data driven methodologies to estimate streamflow characteristics with the use of machine learning algorithms carlisle et al 2016 miller et al 2018 preis and ostfeld 2008 snelder et al 2009 many studies have demonstrated the usefulness of regression trees schnier and cai 2014 sharma et al 2021 support vector machines asefa et al 2006 maity et al 2010 and artificial neural network approaches adnan et al 2017 isik and ozden 2013 to predictive modeling of complex hydrologic systems and the assessment of hydrologic alteration the indicators of hydrologic alteration iha richter et al 1996 were developed to provide a tool that used streamflow characteristics as indicators of the effects of alterations on the ecological functions of riverine ecosystems from numerous contributing factors mathews and richter 2007 this methodology has been used successfully to assess hydrologic alteration in many studies ali et al 2019 gao et al 2012 koel and sparks 2002 however the iha has drawn scrutiny because of its overall complexity 33 streamflow variables and 34 eco flow variables and statistical redundancy in favor of more simplistic approaches that are equally as capable of accurately determining the impacts of hydrologic alteration gao et al 2009 this study explores using generalized metrics to describe patterns of hydrologic alteration in two major river basins in the southeastern united states we employed two flow duration curve based methodologies to identify streamflow records that have undergone significant hydrologic alteration p value 0 05 and to determine the magnitude and nature of this change based on the results of these two methodologies this study tests the hypothesis that hydrologic alteration in the basins can be attributed to the influence of land cover change flow regulation by dams and the resulting amount of water stored in each basin understanding the importance of this type of information to water resource managers statistical models were developed to predict altered streamflow as a function of watershed attributes a rule based regression tree modeling approach was used to evaluate the importance of individual watershed characteristics e g land use and streamflow regulation to predicting hydrologic alteration predictions in watersheds with similar climate topography and land cover 2 study area our study focuses on the pearl river and pascagoula river basins located in the coastal plain physiographic region of central and southeastern parts of mississippi in the southeastern united states fig 1 the annual average temperature ranges from about 11 c 51 fahrenheit to about 25 c 77 fahrenheit and the average annual precipitation for the area ranges from 1372 mm 54 inches to 1499 mm 59 inches arguez et al 2010 the pearl river basin drains an area of approximately 22 688 km2 the pearl river is approximately 789 km long beginning in neshoba county and drains into the mississippi sound and the gulf of mexico in the head waters of the basin the landscape consists of rolling hills which transition into flat floodplains near mississippi s gulf coast forests are the predominant land cover in the basin 50 percent followed by pasture and rangeland which accounts for approximately 24 percent of the basin s area mississippi department of environmental quality 2008 historically the pearl river has been prone to major flooding most notably in 1979 which damaged residences and businesses costing more than 500 million dollars an equivalent of more than 1 billion dollars today nws jackson ms 1979 pearl river flood weather gov the ross barnett reservoir is the only major impoundment on the pearl river the reservoir was constructed in the 1960s covers an area of 134 km2 and is the primary source of drinking water for the city of jackson the state s capitol and surrounding areas wersal et al 2006 the reservoir also acts as a flood control structure and recreational waterbody the pascagoula river is the largest and only river unaffected by dams that drains into the gulf of mexico dynesius and nilsson 1994 the pascagoula river basin is the second largest river basin in mississippi and drains an area of 24 864 km2 before emptying into the mississippi sound and gulf of mexico 130 km downstream of the confluence of the leaf and chickasawhay rivers the basin s landscape transitions from rolling hills and shallow streams in the north to flat swampy bottomlands in the southern part of the basin forest is the predominant land cover 59 percent in the basin followed by cropland and pastures which account for 21 percent of the basin s area mississippi department of environmental quality 2001 developed land in the basin only accounts for approximately one percent of the basin area in 1999 timber production from the basin accounted for 26 percent of timber production for the state population centers in the basin include hattiesburg and the coastal cities of pascagoula biloxi and gulfport 3 materials and methods 3 1 streamflow data modeled streamflow data used in this study are available for 9201 huc12 pourpoints across states that border the gulf of mexico for the period from 1950 to 2009 from robinson and knight 2020 the streamflow model was constructed using a decade of daily streamflow data from january 2000 through december 2009 at 74 u s geological survey usgs streamgages located within the mobile tombigbee and the galveston trinity river basins spanning parts of alabama mississippi texas and louisiana worland et al 2019 these basins were selected to represent unique climatic and physiographic properties that included sites on regulated and unregulated streams across the region a more detailed discussion of the methodology used to predict the streamflow data used in this study can be found in worland et al 2019 3 2 hydrologic alteration metrics the modeled streamflow data for huc12 units in the pearl river basin 234 and pascagoula river basin 295 were divided into pre and post alteration periods the pre alteration period included streamflow data from january 1 1950 through december 31 1969 and the post alteration period included data from january 1 1990 through december 31 2009 we chose to use the split period approach because it controlled for the physical parameters of the huc12 units over a 20 year interim period in which hydrologic alteration may have been a result of climatic or anthropogenic influences similar to what is described by richter et al 1996 moreover a 20 year transition period was selected because it met the minimum requirements of the statistical analysis discussed later in this section the first indicator of hydrologic alteration computed was the net hydrologic change referred to as net change in this study referred to as ecochange by gao et al 2009 to compute the net change we began by computing the ecosurplus and ecodeficit introduced by vogel et al 2007 as metrics to evaluate changes in streamflow in response to flow regulation or other forms of hydrologic alteration directly impacting the streamflow regime these metrics are computed using flow duration curves fdcs computed over any temporal scale and reflect the overall gain ecosurplus or loss ecodeficit of streamflow resulting from alteration vogel et al 2007 based on the approach used by vogel and fennessey 1994 median annual fdcs for the pre and post alteration periods were estimated for each huc12 the fdcs were then compared across the full range of flows to develop curves and identify exceedance probabilities at which the two curves intersected if during the pre alteration period streamflow was greater than the post alteration period then the ecosurplus was calculated as the ratio of the area between the pre and post alteration fdcs to the area beneath the entire pre alteration fdc conversely if the pre alteration period streamflow was less than the post alteration streamflow then the ecodeficit was calculated in the same manner as the ecosurplus lastly the two terms were combined as described by gao et al 2009 to attain a value of the net change which reflects the net effect of hydrologic alteration on the amount of available streamflow the confidence interval hypothesis test ci test kroll et al 2015 which calculated the significance p value of the departure of the post alteration mean fdc from the pre alteration mean fdc was computed as a second indicator of hydrologic alteration jackknife resampling with 1000 iterations of the pre alteration years was performed with each iteration resulting in 5 random years in the pre alteration period mean fdcs were calculated from each 5 year pre alteration group and the p value was determined for each mean fdc the ci test checks if the resulting distribution of p values for the pre alteration mean fdcs are consistent with the null hypothesis that streamflow is not significantly altered relative to this period next mean fdcs and p values were computed for daily streamflow in the post alteration period the p values computed from this step represents the probability that the quantile of streamflow at any exceedance probability falls outside the confidence interval of the mean fdc for the pre alteration period kroll et al 2015 for this study the departure was considered statistically significant if the p value was less than or equal to 0 05 results of the hydrologic change analysis and the confidence interval hypothesis tests are available from crowley ornelas and roland 2023 3 3 cubist to explore the influence of basin characteristics on the resulting p values from the ci test we constructed m5 cubist models in the r programming language r core team 2022 for each basin using the cubist r package kuhn and ross quinlan 2022 a cubist model is a regression tree that employs the use of rules at terminal nodes of the tree to condition predictions of a given variable loh 2014 worland et al 2018 similar to other regression tree models cubist model predictions are based on the values of predictor variables that fall within the splits that subdivide the prediction space of the model worland et al 2018 the prediction space of the model refers to the portioned set of predictor variables based on their relationship to the target variable of the model the splits are determined based on an algorithm that seeks to minimize model prediction error at each node of the tree by conditioning those predictions based only on nodes belonging to the same branch of the tree at each node of the tree the cubist model produces a linear regression model quinlan 1993 quinlan 1993 describes committees and neighbors as the two hyperparameters of the cubist model cubist uses the number of committees to demarcate a number of ensemble models used in predictions the resulting prediction of the target variable is the mean of the predicted value from all ensemble models the number of neighbors refers to the number of prediction cases with similar values of the target variable to be used to predict the value of a new case when a number of neighbors is specified the predicted value is the mean of predicted values of the nearest neighbors during model development values of the hyperparameters were optimized to mitigate model error and improve model fit a ten fold cross validation procedure was used to find the optimal number of committees and neighbors the final pearl river basin model was constructed with 6 committees and 1 neighbor and had a total of 298 rules with an average of about 50 rules per committee the final pascagoula river basin model consisted of 334 rules with an average of 56 rules for each committee the model had six committees and two neighbors during model development adding more committees provided marginal improvement with respect to model accuracy however increasing the number of committees eventually produced no change in model performance reduced model parsimony and increased redundancy of the rules in the model tree the models were constructed using covariate data published by crowley ornelas et al 2019 for the period from 1950 to 2000 at a decadal time step covariates used in the models fall into five general categories variables related to basin geomorphology basin slope basin area topographic wetness index twi accumulated stream length stream density sinuosity land cover variables wetland developed open water forest cultivated cropland and hay and pasture water storage and infrastructure variables flood storage normal storage and upstream road crossings rdx environmental mean precipitation and mean temperature and other net change a summary of the covariate data used to construct the models along with model results can be found in crowley ornelas and roland 2023 after constructing the database of predictors and the response variable a random sampling of 70 percent of the database was used to train the model and the remaining 30 percent of the data were used as test data to evaluate the performance of each model model performance was evaluated by calculating the nash sutcliffe efficiency nse root mean square error rmse mean absolute error mae and percent bias pbias the nse was computed to assess the overall fit of the model predictions to the observed values the rmse was computed because it is a more conservative measure of model error than the mae the mae was used as an error metric because it is a simple metric to compute and interpret however the mae does not provide a measure of the direction of model prediction errors as a result the pbias was calculated to determine the tendency of the model to overestimate or underestimate predictions as a part of this study we were also interested in the individual importance of covariates used in model predictions the importance of covariates used in the basin models were evaluated by determining the frequency at which variables were used in the model rules and regression equations the caret r package kuhn 2021 was used to determine the importance of each covariate by combining the usage of each covariate in rule conditions and in the model linearly a more detailed discussion of this topic can be found in kuhn 2021 4 results 4 1 net change the results of the net change analysis provided more insights about changes in amount of streamflow in the pearl and pascagoula river basins between 1970 and 1990 the computed values of net change in the pearl and pascagoula river basins demonstrated a high degree of similarity between the two basins with respect to changes in streamflow volume similar to the results of the ci test there was no statistically significant difference p value 0 05 in the variance of the computed net change values fig 2 in the pearl river basin the median net change value was 0 19 and in the pascagoula river basin the median net change value was 0 22 median net change values indicated that most huc12 units in both basins had a net surplus of streamflow in the pearl river basin 97 percent of huc12 units had a net surplus and in the pascagoula river basin 95 percent of huc12 units had a surplus only 22 huc12 units had a net deficit across both basins the implication of this result is that relative to the pre alteration period streamflow volumes typically increased from 1970 to 1990 however this varied spatially fig 3 less water was delivered to downstream huc12 units from huc12 units near the outlets of the pearl and pascagoula river basins in some cases the amount of water delivered to the mississippi sound and gulf of mexico had decreased in the upper part of the pearl river basin five huc12 units had a net deficit which indicated less streamflow was delivered to downstream huc12 units post alteration however in the middle part of the basin streamflow delivery from huc12 units increased particularly near densely populated areas net change values for huc12 units near the outlet of the basin were typically smaller with respect to values computed for huc12 units in the middle part of the basin conversely values of the net change in the pascagoula river basin decreased from the upper part of the basin toward the basin outlet huc12 units with net deficits were also located near the basin outlet along the mississippi sound in the computed net change values a similar pattern of a collection of huc12 units across the boundaries of both watersheds had similar net change values coinciding with the band of altered huc12 units based on the results of the ci test 4 2 confidence interval hypothesis test the results of the ci test indicated that both basins had a similar number of huc12 units that had experienced a statistically significant amount of hydrologic alteration during the period from 1970 to 1990 in the pascagoula river basin 22 percent of huc12 units were altered and in the pearl river basin 26 percent of huc12 units were altered however the slight difference in the percentages of altered huc12 units between the two basins was not statistically significant p value 0 05 the median p value in the pascagoula river basin was 0 27 fig 4 in the pearl river basin the median value was 0 34 and the range of p values calculated had greater variance than the pascagoula river basin based on visual inspection of mapped p values altered huc12 units typically corresponded with locations of impoundments in both river basins in the pearl river basin altered huc12 units were grouped around small dams on tallahaga creek upstream and downstream of the ross barnett reservoir and dam on the mainstem of the pearl river fig 5 in the pascagoula river basin altered huc12 units were more concentrated around the headwater tributaries of the pascagoula river specifically huc12 units with statistically significant hydrologic alteration occurred at locations upstream and downstream of okatibbee dam on okatibbee creek and in huc12 units along the leaf river near the confluence of the leaf river and the chicakasawhay river and along the mainstem of the pascagoula river most huc12 units were not altered although there were some exceptions huc12 units located around the mainstem were typically unaltered and moving east or west away from the main channel the number of altered huc12 units increased toward the east there were clusters of altered huc12 units along the eastern boundary of the basin near mobile alabama west of the main channel a cluster of altered huc12 units extended across the boundaries of the two basins forming a band across the lower part of both basins the locations of these altered huc12 units corresponded with the gulfport biloxi and pascagoula metropolitan area 4 3 cubist models the overall fit of both the pearl and pascagoula cubist models was good based on the computed nse values table 1 according to moriasi et al 2015 a nse greater than 0 8 can be considered very good error evaluation statistics rmse and mae for each model were both satisfactory based on the criteria established by singh et al 2005 which defined a low rmse or mae as less than half of the standard deviation of the observed values which was 0 15 for the pascagoula and 0 16 for the pearl for both models pbias was determined to be acceptable because less than one percent of model predictions were overestimates or underestimates of the observed p values pbias for the pearl and pascagoula models had some underestimates of p values on test and training data however this accounted for less than one percent of model predictions in all cases the only exception was the pearl model predictions on the model training data which tended to overestimate p values predictions made by the pearl model generally showed good agreement with most of the observed p values fig 6 a based on this plot model errors were generally within a consistent range although there were exceptions most notably in p values ranging from 0 4 to 0 8 the pascagoula model tended to overestimate p values in the lower ranges but underestimated larger p values fig 6b the pearl and pascagoula models were similar in that they exhibit more error in predictions across similar ranges of observed p values much of the model error exhibited by both models can be explained in the specification of the two models for some huc12 units the model could be improved by incorporating additional variables to characterize features or activities in the watershed that have not been included in the final model such as changes in population distribution or water use another potential source of error is derived from edge cases in the ensemble of model trees where regression equations were not estimated in these situations the predicted p value represents the median value of the observed p values for cases with conditions covered by that rule analysis of predictor variable usage provided a means of assessing the influence of predictor variables on model predictions as a measure of the usage of predictor variables in rule conditions or in the linear regression equations at each node of the tree we computed the variable importance assuming that the most significant variables in the models have an importance of 50 percent or more the most important variables in the pearl model were basin slope net change and rdx fig 7 a these results indicate that basin slope was used most frequently to partition the observed p values in the conditions of rule cases or to be included in the linear models associated with particular rules it should be noted here that the importance of variables in the models does not have to add to 100 percent because they are a measure of the usage in each model not all variables are used in each linear equation in the model tree nor are they all used in every rule condition in the model tree in the pascagoula model the most important variables were the computed net change rdx basin slope twi percentage of hay and pasture the percentage of wetland and sinuosity fig 7b based on these results we concluded that geomorphology had similar importance in both models but land cover was generally more important in the pascagoula model than in the pearl model analyzing the coefficients of the linear models in the model tree allowed for a general view of the influence of the most important variables on p value predictions for this analysis we used the median values of the coefficients to determine if a particular coefficient had a positive or negative effect on the predicted p values a negative median coefficient value indicated a variable typically decreased p values a positive median coefficient value indicated a variable typically increased p value the results indicate that some variables typically have the same effect on hydrologic alteration for both basins i e the variable is typically associated with an increase for both basins or a decrease for both basins and other variables have an opposite effect for each basin i e the variable is associated with an increase in one basin and decrease in the other or vice versa variables that typically had the same effect for both basins were developed land basin slope and net change for both models basin slope had the largest negative coefficient value fig 8 this result suggested that larger basin slope was associated with more hydrologic alteration in addition to basin slope developed area and net change tended to increase hydrologic alteration in both basins in both basins increasing forest area indicated less hydrologic alteration variables that typically had opposite diverging effect for both basins included all other land cover type variables wetland area and hay pasture all increased hydrologic alteration in the pearl but decreased hydrologic alteration in the pascagoula open water displayed a strong increasing effect on alteration in the pearl river basin but its effect was strongly decreasing in the pascagoula river basin the exception was cultivated cropland which decreased hydrologic alteration in the pearl river basin but increased hydrologic alteration in the pascagoula river basin land cover change between 1950 and 2000 was similar in the pearl and pascagoula river basins crowley ornelas et al 2019 during this period wetland land cover decreased by approximately 16 percent in both basins and cropland land cover decreased by 79 percent in the pearl river basin and 67 percent in the pascagoula river basin fig 9 one of the starkest changes in land cover in the basins came from drastic increases in the amount of developed area 110 and 200 percent in the pearl and pascagoula river basins respectively such drastic increases in the amount of developed area provides an additional explanation of the increasing streamflow during the post alteration period the pattern of net change and p values of huc12 units in both basins demonstrated findings that were consistent with those of khanal 2012 that link downstream effects on streamflow in the pearl river with anthropogenic activities in the upper part of the basin 5 discussion using synthetic daily streamflow data to investigate hydrologic alteration provided a means to quantify alteration in gaged and ungaged stream reaches across the pearl and pascagoula river basins a major consideration when designing the study and interpreting its results was the ability of the modeled streamflow data to broadly represent physical conditions and thereby provide a valid representation of hydrologic alteration in the two basins the results of this study indicated that both basins were nearly identical with respect to the number of altered huc12 units after 1970 similarly watersheds in both basins have generated more streamflow since the 1970s lins and slack 1999 and 2005 reported increasing streamflow trends from the 1940s through the 1990s in the south atlantic gulf water resource region wherein the pearl and pascagoula river basins are located moreover interdecadal variability in streamflow with respect to climatic oscillations such as the atlantic multidecadal oscillation amo and the el nino southern oscillation enso also support the notion of increasing streamflow over the period of study tootle et al 2005 in the southeast warm phases of the amo in the 1950s and 1960s were typically associated with less streamflow in the region the cold phase of the amo which dominated the temporal domain of this study resulted in more streamflow across the region the authors cited extreme flooding events enso and hurricane activity as contributing factors to streamflow during amo cold phases although climate variability provides context for the general patterns of changes in streamflow magnitude confounding factors that influence streamflow need to be considered i e anthropogenic activities which were explored using the basin models cubist models constructed for each basin demonstrated a high level of accuracy and the unique effects of basin characteristics on the hydrology of the two basins anthropogenic activities such as channelization dams and reservoir construction are linked to hydrologic alteration as demonstrated by the basin models this result has been explored in other studies in the pearl river basin whereby geomorphic instability of the river channel from anthropogenic activities has been linked to diminished fish populations piller et al 2004 tipton et al 2004 similarly in the pascagoula river basin geomorphic instability has historically been tied to land cover conversion and various mining activities along major tributaries of the river mossa and coley 2004 the leaf river is an example in the pascagoula basin where the mean elevation of the river channel has decreased over the years from mining activities along the banks of the river mossa 2003 our results indicate that geomorphology is an important driver of hydrologic alteration in the basins however its impact was more pronounced in the pearl river basin than in the pascagoula river basin in the pascagoula river basin and to a lesser extent in the pearl river basin land cover conversion was a significant driver of hydrologic alteration bell waldron et al 2020 reported that between 1950 and 2014 marsh area extents near the mouth of the pascagoula river declined by nearly 18 percent with nearly 10 percent of marsh area converted to open water since 1955 many studies have attributed wetland loss along mississippi s gulf coast to urbanization deposition of dredging material and direct wetland conversion to open water between 1950 and 1992 meyer arendt 1989 oivanki et al 1995 meyer arendt et al 1998 moreover the rate of loss of coastal wetland is anticipated to increase as sea levels rise in response to climate change bell waldron et al 2020 wetland and open water land cover change represent one type of land cover conversion impact on hydrologic alteration but both are linked to urban development in the basin in the southern united states the percent of the population living in urban areas has increased dramatically over the past several decades from 18 percent living in urban areas to 72 percent between 1900 and 2000 o driscoll et al 2010 over several decades the growth of urban areas has had many impacts on hydrology and riverine ecosystems in recent decades in the pascagoula river basin urbanization driven by population and economic growth from fossil fuel production has led to impairment of stream reaches in the basin merem et al 2011 moreover stream impairment and hydrologic alteration are further exacerbated by the urbanization of farmland whereby farmland which once acted as a buffer for runoff entering the stream no longer exists giving way to diminished water quality in addition to geomorphic instability in addition to historical changes in the basin climate change threatens to intensify the negative effects of land cover change in the southeast climate change is expected to increase the magnitude and frequency of extreme precipitation events daily 20 year extreme precipitation is projected to increase by as much as 12 by mid century and 21 by the end of the century easterling et al 2017 the implications of current patterns of development in watersheds in a time of climate change may be varied and water resource managers could be challenged to develop management strategies which effectively weigh the advantages and disadvantages of socio economic changes while considering important ecosystem services and their associations 5 1 model limitations because of the complex nature of hydrologic alteration constructing models that accurately represent conditions in the physical environment is challenging not having access to sufficient quantities of quality data is an important source of model error and overall model uncertainty constructing models with sufficient amounts of quality data better informs models and enables more accurate representations of the processes effecting model predictions as many statistical models are often data intensive the application of cubist explored in this study demonstrates cubist models can be accurate when trained on relatively small amounts of data machine learning models can identify complex relationships that might otherwise be dismissed as model error due to data constraints or as an instance of an incomplete understanding of the physical processes occurring in the model domain the specifics of the mechanics of this process are not obvious therefore a robust analysis of model predictions and agreement with respect to physical conditions is important to interpreting model predictions and describing the physical processes at play in selecting an appropriate modeling algorithm the trade off between model accuracy and model interpretability must be considered interpretation of the cubist decision tree become increasingly complex as the tree grows i e increasing number of rules and committees linear models at the leaves of the tree are optimized to reduce prediction error at that branch which results in less overall model error as the tree grows before reaching a point where model error no longer decreases in applications where model interpretability is prioritized a smaller tree may be preferred for a more general representation of the relationships between model predictions and predictors the linear models in the tree allow for quick interrogation of model predictions that can be helpful in determining an appropriate tree size for maximum accuracy and reasonable interpretability 6 conclusion the results of this study demonstrated the potential of applying machine learning in the context of determining the effects of human interactions with the natural environment the application of a cubist model in this study provided interesting insights about the pearl and pascagoula river basins and factors contributing to hydrologic alteration the models were able to demonstrate with accuracy the most important drivers of hydrologic alteration in the two basins which had similar amounts of altered huc12 units the models identified changing land cover and geomorphic instability related to dam construction and mining activities as important anthropogenic activities in the basins effecting streamflow between 1950 and 2009 the ability of predictive models to identify and characterize processes and sources of hydrologic alteration accurately can support water resource managers in implementing appropriate management actions with respect to resource management and conservation the accuracy of the cubist models developed in this study demonstrate the potential of data driven approaches towards the development of effective management strategies to help target places in need of additional investment towards conservation and remediation the methodologies presented in this study enables resource managers to not only assess the current conditions of hydrologic alteration in basins but also provide a way for managers to assess the impact of future changes on basin hydrology applying cubist models in a decision support framework not only allows resource managers to assess many different scenarios in their watersheds but the models can be implemented as living models where updates may be automated using workflows unique to the needs of users declaration of competing interest the authors declare the following financial interests personal relationships which may be considered as potential competing interests victor roland ii reports financial support was provided by gulf coast ecosystem restoration council acknowledgements funding for this research was provided by the gulf coast ecosystem restoration council we would like to thank all individuals that participated in the planning and execution of this work we would also like to thank all anonymous reviewers for their constructive feedback which served to improve this work any use of trade firm or product names is for descriptive purposes only and does not imply endorsement by the u s government 
25414,a new geothermal reservoir modelling framework is discussed the framework has two main objectives first all the geoscience and reservoir engineering data should be stored in a simple manner not in any way dependent on the model grid to be used and secondly the data storage protocols should be easily transferable from one modelling project to the next in our framework some of the data are stored as part of a digital conceptual model created in leapfrog geothermal while most of the rest including well by well reservoir engineering data are stored in human and machine readable json files finally some of the data related to the specification of production history and future scenario parameters are stored in control spreadsheets the reservoir model files required for running natural state production history and future scenario simulations are set up using leapfrog a suite of python scripts and control spreadsheets the python scripts are set up in a general way so that they require little or no modification for use on a new modelling project the model set up process is mainly automatic with very little manual intervention required due to the generality of the process it is easy to modify the reservoir model input files when new data become available such as updated production data similarly the mesh independent database allows new models to be set up easily and quickly this includes modification to the grid for example by adding local refinement or the use of a new grid also a suite of re useable python scripts has been developed for plotting standard sets of results from reservoir models keywords modelling framework geothermal reservoir simulation waiwera python data availability data will be made available on request software availability name of software geothermal modelling framework lead developer john o sullivan contact address department of engineering science university of auckland auckland new zealand telephone 64 9 3737 599 ext 85 353 email jp osullivan auckland ac nz co developers and designers joris popineau michael gravatt theo renaud jeremy riffault adrian croucher angus yeh and michael o sullivan year first available 2022 hardware required windows pc software required leapfrog geothermal python pytough library autough2 or tough2 or waiwera tim availability and cost some of the key python scripts used in the geothermal modelling framework are not yet available it is expected that they will be added to the pytough library within the next 12 months leapfrog geothermal and tough2 are commercial software and require licences autough2 is made available free to holders of a tough2 licence waiwera tim and the pytough library are free program language python program size leapfrog geothermal and tough2 are large software packages but the controlling python scripts in the geothermal modelling framework are quite small waiwera is available at https waiwera github io tim is available at https tim readthedocs io en latest and the pytough library is available at https github com acroucher pytough 1 introduction setting up and running a geothermal model is a complex process involving the following steps i gather data and set up a conceptual model ii set up a computational grid iii use the computational grid and conceptual model to set up a reservoir model iv calibrate a natural state model v calibrate a production history model vi use the calibrated model to run future scenarios this modelling process is often iterative for example it is usual to iterate through the calibration of the natural state and production history models checking the natural state model after changes are made to the production history model similarly it is common to revisit the conceptual model and even the set up of the computational grid during the model calibration process therefore it is important to have a flexible and easy to use workflow for carrying out the modelling process there are two broad approaches to the modelling process monolithic a single software package perhaps two for the whole process modular multiple software packages integrated into a modelling framework via suitable auxiliary software tools the monolithic approach has the advantage of ease of use and therefore accessibility for new users but tends to be inflexible it is implemented in petrasim alcott et al 2006 yamamoto 2008 and in the recently developed volsung clearwater and franz 2019 franz et al 2019 however the monolithic approach of volsung grew out of a more modular approach discussed by franz 2016 the option of two tightly coupled packages is implemented in the petrel eclipse software marketed by schlumberger mainly used in the oil and gas industry but recently applied to geothermal modelling e g stacey williams 2017 sullera et al 2021 similarly cmg offers a combination of a simulator called stars and a post processor called results which has been used for geothermal modelling e g wisnandary alamsyah 2012 deo et al 2013 beckers et al 2021 the modular approach offers greater flexibility as the component software can be combined in different ways to suit different models and is our preferred approach the idea of an integrated modular geothermal modelling framework was probably first discussed by nakao et al 1998 in the context of a modelling study of okuaizu geothermal field this study was carried out jointly by geothermal energy research development co japan industrial research limited new zealand and okuaizu geothermal co japan some geological modelling and data handling was carried out with geobase sato et al 1995 the simulator tough2 was used and pre and post processing was carried out with geocad burnell et al 2003 the tools used for integrating the software were not discussed tanaka and itoi 2010 created a pre and post processor for tough2 linked to a database their software included some of the elements of an integrated modelling framework as did the workflow discussed by audigane et al 2011 they used the petrel geomodeler for setting up a digital geological model and creating a reservoir model input file the output from petrel is an input file for eclipse the schlumberger reservoir modelling software audigane et al 2011 used a fortran program to convert this to a tough2 input file and they also used several fortran programs for modifying the tough2 input file and for processing the tough2 output for visualization in tecplot and paraview berry et al 2014 created tough2gis as a suite of gui provided bash scripts running in the grass gis environment with tough2gis it is possible to generate and manage the conceptual model and to create the numerical reservoir model tough2viewer bonduá et al 2012 is used for visualization the combination of tough2gis and tough2viewer has most of the elements of an integrated modelling framework but does not appear to have been used for many modeling studies of geothermal fields franz 2016 discusses a modelling package matatauira which includes some of the features of a general modelling framework including a fully coupled reservoir wellbore surface simulator and graphical user interfaces to easily set up models carry out data analysis and provide visualization in 3d this package has been developed further to create the volsung software delsante et al 2018 discuss the adaption of the oil gas pre and post processing package restudio for use with tough2 and using geological models built with petrel the interface was built with a series of modules each of them handling a phase of the usual workflow of a geothermal modelling study 2 components of the framework 2 1 rationale for the framework based on our modelling experience and our review of previous work we consider the following criteria to be essential for a general integrated geothermal modelling framework all data including the digital conceptual model should be mesh independent and in a standard format for all reservoir models easy to use and re useable tools e g scripts should be provided for integrating the steps in the modelling process thus making it easy to set up and run modified or new reservoir models easy to use and re useable visualization tools should be provided to assist with calibration and for producing useful plots for modellers and end users the framework should have flexibility so that extra tools can easily be added e g for generating new types of future scenarios for producing new types of plots or for adding extras such as uncertainty quantification or inverse modelling as none of the previous workflows or tools described above in section 1 fulfilled all these criteria and some did not provide the functionality of a complete framework for the entire modelling process we decided to develop a new geothermal modelling framework gmf the gmf does not change the standard modelling process e g o sullivan et al o sullivan and o sullivan 2016 outlined above but can greatly speed it up allowing more time for calibration and delivering better models the ease of use and re useability of the various integration and visualization tools python scripts have been gradually improved by having students meet and overcome problems in applying the gmf to modelling projects and from the experiences of our modelling team in applying it to several projects see section 10 the main components of the gmf are briefly summarized in the rest of this section and more details are given in later sections 2 2 digital conceptual models the development of our gmf started when the leapfrog software became available and we began using it for setting up digital conceptual models newson et al 2012 leapfrog s integrated environment allows field wide multidisciplinary data to be directly visualized compared and modelled and it is now used widely for geothermal projects alcaraz et al 2010 2011 2015 milicich et al 2010 massiot et al 2011 newson et al 2012 pearson et al 2012 kandie et al 2016 the digital conceptual model is discussed further in section 4 2 3 reservoir simulation after setting up a digital conceptual model in leapfrog the next stage of the development of our gmf was the use of python scripts for setting up an input file for a reservoir simulator o sullivan et al 2019 popineau et al 2018 we use the simulators autough2 yeh et al 2012 and waiwera croucher et al 2016 2017 2018 2020 o sullivan et al 2017 but with some modification of scripts allowing for differences in the format of input and output files the gmf could be applied to any geothermal simulator more details of model set up within the gmf are given in sections 5 and 6 2 4 visualization tools previous visualization tools for geothermal modelling with tough2 there have been many tools developed for setting up reservoir models and visualizing modelling results the commercial software includes geocad burnell et al 2003 wingridder pan 2003 petrasim alcott et al 2006 yamamoto 2008 mview avis et al 2012 leapfrog newson et al 2012 re studio delsante et al 2018 and volsung clearwater and franz 2019 franz et al 2019 a few modellers have used simulators and accompanying visualization tools developed for the oil and gas industry but also applicable to geothermal modelling for example sullera et al 2021 used the petrel platform for pre and post processing of results obtained from using the eclipse simulator to model the leyte geothermal field there have also been many free and open source visualization tools developed for use with tough2 some of the easily accessible software is listed in table 1 visualization tools for the gmf in our gmf we use the open source software tim yeh et al 2013 for simple 2d and 1d plots and the commercial software leapfrog for 3d visualization the simulators autough2 and waiwera are both based on the finite volume method for spatial discretization and the input files do not need to contain complete information about the geometry of the model grid for tim and its predecessor mulgraph we supply the geometric information required for visualization through a geometry file that contains the xy coordinates of the nodes the nodes forming each block the connectivity of blocks and the layer structure tim assumes each layer is horizontal and the block structure within each layer is the same a simplification not required by tough2 there are tools in tim and pytough for setting up the geometry file a key part of our gmf is the pytough library croucher 2011 2015 wellmann et al 2012 which contains many scripts for model management and visualization two other python libraries have been developed for assisting with geothermal modelling namely toughio luu 2020 and t2geores majano 2021 however pytough offers a more comprehensive suite of software tools some that we find very useful are the scripts used to generate suites of plots showing the state of calibration of a model as shown below in figs 6 8 some of the python scripts used in the gmf have not yet been included within pytough but will be after more testing and quality assurance has been carried out 2 4 integration tools in the gmf end to end integration between the different elements of the framework is carried out using python scripts which offer great flexibility without needing to be compiled and interface naturally with the pytough library a list of the scripts used within the gmf is provided in table 2 in section 3 this list of scripts corresponds to the step by step process required for a geothermal modelling study this complex task is currently addressed using a variety of software tools by other geothermal modellers we claim novelty for our gmf in two respects i we have broken down the modelling process into a logical and fine grained sequence of steps ii we have developed python scripts for carrying out each step these scripts have been extensively tested to ensure that they are easy to use easy to modify and can be easily applied to a new project 2 5 data storage and access in our gmf we store data in three ways see table 3 i geoscientific and some reservoir engineering data are stored in leapfrog and are used for creating the digital conceptual model see table 4 ii reservoir engineering data are stored in json files see table 6 iii some data for setting up production histories and future scenarios are stored in spreadsheets a key part of the gmf is that the well by well reservoir data and some other data see table 3 are entered into machine and human readable json files data are used directly from standard json files for model setup model calibration and plotting of results 3 presentation of the framework fig 1 presentation of the framework used to process reservoir model files for the natural state the production history and the future scenario the reservoir model is based on a conceptual model set up in leapfrog from the geoscientific data contained in the digital conceptual model see section 4 once a model grid has been set up a model input file can be generated using leapfrog then python scripts are used to modify the reservoir model for example the leapfrog rock type names are replaced by a naming convention for the formations and faults inside or outside the main reservoir etc see section 6 often the vertical and horizontal face permeabilities for dipping faults and non aligned faults need to be adjusted see section 6 2 python scripts are used to implement boundary conditions and initial conditions in the model input file see section 7 a summary of the python scripts currently used in the gmf and their function is given in table 2 for each well the natural state temperatures and pressures and production data are stored in a json file see section 8 they are called by scripts to set up the production history model input file and to post process the results see table 2 and section 9 similarly the control spreadsheets contain some of the data for the production history and future scenario for the injection and production wells and are used to write the relevant module of the input file for example gener in autough2 the data storage in the gmf is summarized in table 3 this framework can be applied to any digital conceptual model built with leapfrog it allows enough flexibility so that changes to the conceptual model can easily be made and transferred through to the reservoir models 4 conceptual model 4 1 overview developing a conceptual model of a geothermal field requires combining knowledge from a wide range of sources the conceptual model should describe where the upflow and recharge is coming from the size of the resource and the location of fluid controls such as geology structures and alteration zones e g purwandono et al 2015 mroczek et al 2016 mcdowell et al 2020 renaud et al 2022 a key element of our gmf is a digital conceptual model that is built from field data although the digital conceptual model is an essential foundation for our gmf we regard its construction or modification as a separate but challenging task to be carried out before implementing the gmf more discussion of our approach to conceptual modelling is given in section 4 2 and is included in publications on some of our modelling studies e g prastika et al 2016 wardana et al 2016 nugraha et al 2018 o sullivan et al 2018 in the geological model which forms a major part of the conceptual model of a geothermal system three main features are important the geological units structures and mineral alteration see fig 2 these are the ingredients that typically go into the development of the permeability model discussed below that is used for setting up rock types in a reservoir model as well as the geological model the digital conceptual model may contain geophysical data such as magneto telluric mt data geochemical data such as chloride concentrations and reservoir engineering data such as well tracks downhole temperature profiles and feed zone elevations similarly information about geothermal surface features such as hot springs and steaming ground as well as any geo referenced objects roads buildings lake etc can easily be added to the digital conceptual model and visualized alongside the geological model table 4 contains a summary of the data that are usually included in the digital conceptual model 4 2 geology for a developed geothermal field the geological units in a leapfrog model are derived from geological maps and stratigraphy stratigraphy is obtained from wells and from interpreted geological cross sections often the stratigraphy from well data must be grouped simplified and sometimes interpreted in order to generate a set of consistent geological units that realistically reflect the current understanding of the subsurface alcaraz et al 2010 massiot et al 2011a newson et al 2012 alcaraz and barber 2015 alcaraz and milicich et al 2018 however at the early stages of development or before development begins there may be little or no downhole data to apply our modelling framework to a greenfield site we have used a simple approach to setting up a geological model stratigraphy is estimated from geological models of the wider area by analogy with similar systems and from the geological history e g dates of various eruptions prastika et al 2016 wardana et al 2016 nugraha et al 2018 within our gmf the geological model can be easily updated with measured downhole well data when they become available and the corresponding changes are easily transferred through to the reservoir model 4 3 structural model faults and structures can be explicitly defined in the structural model which is integrated into the leapfrog geological model as represented in fig 2 usually the dip of a fault is well constrained near the surface but at depth is more uncertain in the geological model the path of faults or structures may need to be modified to achieve agreement with reservoir engineering data mcnamara et al 2016 one example of this is when feed zone data from a well indicates a location of high permeability corresponding to the intersection of the well with a fault this new information may require the location of a fault to be adjusted in the digital conceptual model 4 4 alteration zone the shape and size of this alteration zone or clay cap is an important part of the conceptual model of a geothermal field as it is an important mechanism for controlling fluid flow however an alteration model should be based on a combination of data sepulveda et al 2012 sewell et al 2012 ardid et al 2021 such as resistivity from magneto telluric or mt data temperature data feed zone elevations and quality as well as mineralogy identified by methylene blue tests gunderson et al 2000 rosenberg 2017 and other methods such as scanning electron microscopy sem x ray diffraction xrd and petrographic microscopy e g lynne et al 2011 2013 in our workflow the alteration model is considered separately from the structures and geology and then superimposed on them in the leapfrog digital conceptual model 4 5 other data including other forms of geothermal data into the 3d leapfrog digital conceptual model helps to visualize and understand the geothermal system for example looking at the locations of surface features and geochemistry data such as chemical composition and geothermometry data can indicate the location of the deep upflow these deductions are based on how much the geothermal fluid has mixed with shallow aquifers on the way to the surface d amore and panichi 1985 joseph et al 2011 if the flow path based on geochemistry lines up with a fault it helps to explain the pathway through the alteration zone and helps to establish the conceptual model these extra data types can be used by geothermal modellers to calibrate reservoir models to qualitative data as well as to the traditional quantitative data such as temperature profiles and transient pressure and enthalpy data all the data discussed above and more can be entered into leapfrog and used as a visual database and for 3d visualization of the digital conceptual model o sullivan et al 2019 popineau et al 2018 5 model grid the size orientation and type of discretization for the model grid is a matter of judgment for the modeller but in general it is chosen to capture the important physical processes in sufficient detail one approach is to start with a coarse model that runs quickly and then refine the grid as necessary the framework presented here is designed to make it easy to modify the reservoir model if the grid is changed to establish the model grid we first set up the geometry file see section 2 2 using tim or pytough in most recent models we have included the shallow unsaturated zone and set the top of the model at ground surface in this case we include a high resolution topographical surface available from google earth for example as part of the digital conceptual model tools available in leapfrog or pytough can be used to fit the topography to the model grid by setting the elevation of the top of each column in the model in the geometry file see fig 3 some modellers prefer to have the top of their model at the water table in this case water table data can be included in leapfrog and then the same approach can be used to fit the top of the model to a smoothed surface fitted to the water table data for autough2 models we avoid very thin blocks at the top of a column that can cause computational problems e g less than 2 m thick by snapping the topography to the nearest top boundary of a layer for waiwera only complete blocks can be used and so for all columns the topography must be snapped to the nearest top boundary of a layer in several of our models part of the grid lies beneath a river a lake or the ocean in this case bathymetry data are added to the topography data however we have found that with typical block sizes the interpolation process may not always be adequate for dealing with rivers and some small amount of manual adjustment is required for setting up a physically reasonable continuous river track 6 permeability model 6 1 rock type mapping the first step in setting up the permeability model based on the leapfrog digital conceptual model is to map the corresponding rock types on to the model grid by using leapfrog basic rock types are assigned for each geological formation and then modified rock types are introduced with script 1 see table 2 where a fault intersects the formation and where the clay cap overlays a formation in some cases to provide a better representation of the heterogeneity in the reservoir and to give extra flexibility during the calibration process a geological formation can be split into sub formations for example to represent the deep and shallow parts of the formation or where a part of the formation is thought to be highly fractured the tools in leapfrog geothermal and our script 1 make the process of assigning rock types to the model blocks simple and efficient as shown in fig 4 the same process can also be used to transfer any updates in the geological model to the reservoir model leapfrog geothermal allows dipping faults to be represented and has options that can be used to ensure that the fault is represented continuously along the strike and up the dip of the fault the user can also specify the width of the damage zone which controls how far on each side of the fault it is assumed that permeability has been affected by the fault 6 2 rock type properties next script 2 see table 2 assigns each rock type the physical properties needed for the reservoir simulation porosity permeabilities rock conductivity etc these can be assigned either from an existing reservoir model or from initial estimates for the properties of different rock formations and structures a clear and logical naming convention for rock types is set up this convention respects the geology structures and alteration zone and typically defines a large number of rock types table 5 shows the 5 character convention for naming rock types using four rock types within the ignimbrite formation as examples as shown the first character identifies the formation the second character identifies the first fault the third character identifies the second fault the fourth character identifies whether or not the clay cap is present and the fifth character is the version number script 10 is used to convert the single porosity natural state model into a dual porosity production history model all or part of the model can be treated as dual porosity similarly script 11 is used to convert the final results from the natural state simulation into initial conditions for the dual porosity production history model with the same pressure and temperature or vapour saturation assigned to the fracture block and matrix blocks replacing each single block in the natural state model another important feature of the gmf is the mapping of a permeability structure from an older model if there is an older well calibrated version of the model with a different grid coarser or finer it can be used by script 2 for mapping over the old rock type parameters on to the rock types of the new model this process provides a good starting point for calibration of the new model 7 boundary conditions all boundary conditions are assigned by using mesh independent parameters defined at the model set up stage some parameters such as depth and location of a lake river etc are included in the digital conceptual model while others such as rainfall background deep heat flow and hot upflow of mass are included in a boundary condition json file 7 1 top boundary at the top boundary we set up either dry atmosphere blocks containing air and water vapour or wet atmosphere blocks containing water in the dry atmosphere blocks above land the pressure is set as atmospheric pressure 1 bara and the temperature is set at an average annual value for the area of interest average monthly or weekly temperatures are sometimes used in production history models in the wet atmosphere blocks the temperature and pressures are set to correspond to values at a lake a river or ocean bed varying with the bathymetry the pressure is calculated as the hydrostatic pressure based on the depth of the body of water also at the top of the dry land part of the model infiltration of rain into the soil is represented by the injection of water usually an annual average rainfall is used and a suitable infiltration rate assumed but in some cases e g our model of the rotorua geothermal field febrianto et al 2013 ratouis et al 2014 setiadi et al 2014 ratouis et al 2015abc ratouis et al 2016abc ratouis et al 2017 the precipitation is allowed to vary throughout the year by applying the historical monthly or weekly rainfall also in this case and in some other models a spatially variable infiltration rate is used for the rotorua model a customized version of script 3 is used to restrict infiltration in the urban area and allow more infiltration outside the city where there is less impermeable cover we do not add rainfall to wet atmosphere blocks e g under the lake the infiltration rate can be made to depend on features such as ground cover slope of the ground or surface geology this infiltration rate is then calculated from the specified rainfall in kg s m2 which can be mapped on to the surface of any grid system and made to depend on block areas for models with the top of the model at the water table wet atmosphere blocks are used and no rainfall is included in this case the resulting inflow through the top of the model has the potential to be used for calibration against infiltration data in terms of our gmf the only requirement is the specification of the topography bathymetry in the leapfrog model and infiltration rates in terms of mesh independent global coordinates in the boundary condition json data file 7 2 side boundary typically reservoir models are made large enough in area so that most of the convective system can be included within the model and closed or no flow side boundary conditions are used this assumes that flows from the geothermal system either in the natural state or during the production history do not cause significant pressure changes at the edge of the model in some cases this assumption is not appropriate for the production history simulation or future scenarios and recharge is allowed through the sides of the model this is implemented in autough2 through pressure dependent generators with the identifier rech so that water flows in if the pressure at a boundary block drops as a result of nearby production or water flows out if the pressure near the boundary increases as a result of injection the details of the side recharge are set up in a mesh independent manner in a json file and implemented in the model with a python script script 9 in table 2 7 3 bottom boundary the depth of a reservoir model is usually set such that the bottom boundary is well below the bottom of any wells say approximately 1 km at that depth for most reservoirs the use of a supercritical equation of state eos is unnecessary but in some cases a supercritical eos needs to be considered montegrossi et al 2015 o sullivan et al 2020 typically the base of a model is located at between 2500 masl and 3500 masl but some are deeper such as the current wairakei tauhara model 4500 masl and some are shallower such as for rotorua 1500 masl where there are no deep wells and the focus is on capturing surface changes ratouis et al 2016a at the bottom boundary a background flow of heat is specified this can be constant across the whole model or made to be spatially dependent for our gmf the heat flux is specified in a json file in terms of the mesh independent coordinate system e g a constant heat flux over the whole area or a piecewise constant heat source or something more complicated for inverse modelling purposes we have sometimes represented heat flow by simple functions e g radial basis functions that can be expressed in terms of a few parameters script 3 is then used to assign the appropriate heat flow rate for the bottom cells depending on column areas also at some locations usually along deep faults an upflow of very hot water is specified in the boundary condition json file this is usually one of the key quantities to be adjusted during model calibration the upflow can be assigned different values at many blocks in the basement layer or it can be expressed in terms of simple functions controlled by a few parameters e g using pilot points omagbon et al 2016 again script 3 is used to assign injection of very hot water at the relevant blocks in the bottom layer of the model in some production history and future scenario models we have added an extra pressure dependent deep inflow of very hot water so that the deep hot recharge increases as the very deep reservoir pressures decline due to production again the parameters for the deep recharge are given in mesh independent form in a json file and a script script 9 in table 2 is used to implement the deep recharge wells in the production history and future scenario model files 7 4 surface features in some cases surface features are represented by local high vertical permeability pathways allowing enhanced outflow at the top of the appropriate column in the model the trouble with this approach is that it averages fluid properties such as temperature over the area of the model column which may be large compared to the size of the surface feature it also allows water feeding the hot spring to mix with cold water in shallow aquifers before reaching the surface in some cases this may not be appropriate as there is an isolated pathway from a hot region in the reservoir to the surface an alternative approach is to represent the surface feature e g hot springs hot pools or steaming ground by a spring generator feeding from a suitable depth a mass well in autough2 with a constant production rate set for the natural state model and a pressure dependent deliverability option see below used for production history and future scenarios for our modelling framework the location feed depth and area of each surface feature must be specified in a separate json file and then a script is used to set up wells representing the surface features in the chosen model grid system script 4 in table 2 8 wells and feedzones 8 1 feed zone allocation well tracks and their feedzones must be defined in geothermal reservoir models so that source or sink terms can be created to represent fluid flowing into or out of the feedzones in the past the low resolution of the reservoir models meant that often a feedzone was contained entirely within a single model block this makes the process of assigning and handling the wells simple however in multi million block models each feedzone of a well may span multiple model blocks to deal with this situation we use a system where well information such as the well track feedzones and other well data are stored in json format data files see table 6 when setting up a production history or future scenario model python scripts read these data files and then sample down the well track in the specified model grid this identifies the blocks associated with each feedzone and the proportion that each block contributes to the feedzone script 7 in table 2 for example a feedzone can span two blocks but 60 may be in the first block and 40 may be in the second block depending on the proportion of the feed in each block for wells that have multiple feedzones the proportion that each feedzone contributes to the total mass produced or reinjected is usually supplied by reservoir engineers guided by surveys such as pressure temperature spinner pts runs or output tests grant and bixley 2011 for multi feedzone wells a control spreadsheet contains the feedzone fraction as one of the parameters and it can be made time dependent to allow the modeller to change the feedzone proportions with time this is desirable as well feedzone proportions change over time due to a range of factors such as scaling and work overs mclean et al 2021 in some cases the feedzone fraction is adjusted as part of the calibration process for the production history model within our framework we use the scripts to set up a new gener when adjustments are made to the feedzone proportions the total that a well produces or reinjects is imposed on the model through the recorded history these data are included in the well by well json files and script 8 is used to set up the data in the production history model input file in some cases these flows may need to be inferred because the mass flow is only measured at a separator which is fed by multiple wells for example with our ohaaki model o sullivan et al 2012 clearwater and franz 2019 ratouis et al 2017a mcdowell et al 2018a 2018b we use annual output tests to set the contribution from each well that feeds a particular separator and assume that fraction remains constant over the year obtaining accurate production and injection data for a modelling study is often a time consuming task a common problem we have encountered is inconsistency between the production data and the injection data e g with the total injection rate incorrectly exceeding the total production rate our framework does not solve this problem but it does help to quickly rewrite a modified production history model file when the clean production and injection data are added to the well by well json files 8 2 deliverability for future scenario simulations rather than imposing a mass flow on a well we allow the mass flow to depend on the reservoir pressure this is done with the deliverability option for production wells and an injectivity option for injection wells the deliverability mode calculates flow rate as a function of pressure at the feed zone this means that if the feed zone pressure declines so will the mass flow in the formulation of the deliverability option available with tough2 pruess et al 1999 the mass flow q mβ of each phase β w for water and β s for steam is given by 1 q m β k r β ν β pi p β p w b here for each phase k rβ is the relative permeability p β is the pressure and ν β is the kinematic viscosity pi is the productivity index and p wb is the flowing bottom hole pressure the key parameter in the deliverability formula is the flowing bottom hole pressure p wb if the reservoir pressure in both phases falls below p wb then the well will not produce in the framework presented here script 13 is used to automatically assign a deliverability generator to each feed block in each feed zone in the well usually it is expected that the performance of the wells will not change from the end of the production history simulation to the start of the future scenario and for each generator a productivity index pi is calculated with a script based on 1 to ensure a smooth transition of the mass flow between the production history and future scenario 8 3 production and injection flow rate production or injection data through time is stored for each well in their json file they are used as input for the production history model with the quantity split across feed blocks these data are also reproduced in plots see fig 8 to enable checking that the model is correctly producing or injecting the specified amounts 8 4 production enthalpies variation of enthalpy of the produced fluid for a given well over time is another key data type used to calibrate the production history model the enthalpy data are included in the json file for each producing well the bottom right plot of fig 8 shows an example of this kind of comparison the match to production enthalpy for so called excess enthalpy wells i e wells producing fluid with an enthalpy above that of water is important as a good match indicates that the right amount of boiling is occurring in the model usually matching the behaviour of excess enthalpy wells quite tightly constrains the nearby permeability and porosity as mentioned above the proportion of the total production assigned to each feed zone can be considered as a calibration parameter and enthalpy data from the well can guide the choice of these proportions in control spreadsheet for the well 8 5 well groups information about well groups is useful for reporting results and for model set up for example calculating an average production enthalpy or steam flow for each separator can help with understanding the characteristics of the reservoir well groupings are commonly used in setting up future scenario models this is done in the case of larger fields with multiple separators e g ohaaki see mcdowell et al 2018a b separate steam targets can be set for these areas since wells generally can only service the separators to which they are connected the most common groupings we use are by location in different areas zones reservoirs etc by depth like shallow intermediate or deep wells and by affiliations to a separator or a power plant there may be several power plants in one system such as at wairakei 8 6 future scenarios set up future scenarios are usually specified by the reservoir engineers who want to investigate different management strategies for the field for example these might involve varying the level of production to investigate sustainability or testing reinjection in different locations to investigate thermal breakthrough typically many trials are required to arrive at a satisfactory set of future scenarios and the process of manually setting up the corresponding model files is very tedious and these files are not transparent to overcome these two issues as part of our gmf we have developed a system of setting up future scenarios using spreadsheets with which reservoir engineers can easily interact these are project specific as the scenarios tend to be project specific however we have a standardized but flexible format that allows fast development and implementation of future scenarios future production and reinjection rates for existing wells and make up wells are set up within control spreadsheets using different parameters like operation dates rates or deliverability parameters wellbore pressure and pi as discussed above for as many scenarios as needed then script 13 is used to generate the gener module within the autough2 model file or the equivalent module in a waiwera model file no direct editing of the model files is required as all changes in the specification of the future scenario are made in the spreadsheet for each new make up well a new json file is written containing information such as well track and feedzones in the same format as for the existing wells this means that the standardized scripts can treat a make up well in the same way as an existing well the productivity indices of feedzones for the make up wells are estimated based on data from the existing wells 9 plotting results good visualization tools are essential for model calibration and for reporting model results to the decision makers o sullivan et al 2019 popineau et al 2018 our standard visualization tool tim can be used for developing modifying and running reservoir models and for displaying results yeh et al 2013 tim is an open source visualization tool developed at the university of auckland https tim readthedocs io en latest fig 5 shows a cross section of the temperature distribution in a model from tim many model inputs and outputs can be easily visualized in tim alongside tim we use python scripts to produce standard sets of plots scripts 6 and 12 in table 2 in the plotting script there are a range of options the user can specify such as plotting results for a selection of wells we have attempted to make the plotting scripts general so that they can be used on any geothermal field with one or more model grids with little or no adjustment we have also made the python script easy to read so that they are easy to modify the ease of use and re useability has been improved over time by having many modellers including students apply them to modelling projects for natural state models we primarily plot downhole temperature profiles for all wells a typical page of this type of report including the location of the wells is shown in fig 6 it shows the locations of five wells the resistivity boundaries and track of the waikato river are shown for orienting the model other identifiable features of the geothermal system such as easting and northing or faults and caldera boundaries can be used the figures show model temperatures plotted together with the observed temperatures from the standardized json files to better describe the quality of the match the root mean square deviation rmsd is calculated using model temperatures interpolated to the elevations of the observed temperatures the rmsd error for each well and for different elevation bands can be plotted on a map as shown in fig 7 this figure helps to identify the areas and depths of the model that need improvement by further calibration as it shows areas where the model is too cold and other areas where the model is too hot the decision based on fig 7 could be that the upflow or vertical permeability in the western and south eastern parts of the field needs to be decreased to give a better match to the temperature data figs 6 and 7 are plots generated for the ohaaki geothermal field several models of this field were set up before the gmf was available but its application to ohaaki particularly using plots such as fig 7 has improved model calibration the matches of model results to data shown in figs 6 and 8 were improved by using the gmf for production history simulations a similar but more extensive set of plots is produced it can incorporate many different plots for each well for example well location temperature vs time downhole temperature profile with model results plotted for the date when the data were collected pressure vs time at the model feed blocks mass steam brine flow rate vs time production enthalpy vs time a typical example is shown in fig 8 the suite of plots for the production history model contains one or two pages per well like fig 8 and includes all relevant data and model results for that well plots of field wide totals are also produced e g for total production flow rates of mass steam brine and average enthalpy standardized plotting for future scenarios is more difficult to arrange as there are variations between fields with respect to what issues are important these suites of plots are made as standard as possible but typically vary from one project to the next having a standard set of plots to start from makes plotting results for future scenarios for a new project or an existing project with new requirements relatively easy comparison between scenarios is also important typically scenarios are run to study the effect of varying production levels or to test different reinjection strategies plotting results from two or more models on one set of figures allows assessment of these differences in addition to standardized reports 3d visualization of results is used to integrate results from the modelling process with data from the digital conceptual model we use leapfrog geothermal for this purpose this software is licensed but viewer files can be created that allows stakeholders to view prepared model results licence free in a web based browser as an example fig 9 shows the steam zone near the top of the hot upflow the integrated database for the geothermal field wells parameters geological settings can be shown together with reservoir modelling results to aid decision makers who are managing the field 10 applications 10 1 previous projects the gmf has been in development for the last 10 years during that time the fundamental ideas of integrating a digital conceptual model and a numerical reservoir model have remained the same and most of the effort has gone into standardizing the suite of python scripts used to implement the gmf see tables 2 and 7 and for standardizing data storage see table 3 various versions of the gmf have been used on commercial modelling projects on ohaaki new zealand namora i langit kamojang lahendong indonesia lihir papua new guinea san jacinto nicaragua and the paris basin france the only open source reports on these studies are o sullivan et al 2021 and popineau et al 2022 also several student modelling projects have used the gmf e g on arjuno welirang darajat dieng hululais jaboi kerinci lahendong lumut balai muara laboh patuha telaga ngebel waesano and ulubelu all in indonesia a few of these studies have been published in conference proceedings e g prastika et al 2016 wardana et al 2016 nugraha et al 2018 o sullivan et al 2018 10 2 summary for kamojang in order to provide more insight into the details of the gmf a summary of its recent application to a modelling study of the kamojang geothermal field indonesia is provided here in table 7 as the table shows the software packages used are leapfrog geothermal for setting up the digital conceptual model and for setting up most of the data file for autough2 autough2 for running the natural state production history and future scenario simulation tim for visualization to assist with calibration of the natural state and production history models the key components of the gmf are the python scripts listed in table 2 these scripts are used for model set up and for generating suites of plots for each stage of modelling see figs 6 8 for plots for the ohaaki geothermal field these scripts are used for all our modelling studies but required some customization for the kamojang project but as emphasized throughout this paper these scripts have been standardized as much as possible to minimise the amount of modification required for each new project as discussed in note 1 below table 7 the script that is used to set up the boundary conditions had to be extensively modified for the kamojang project because kamojang is a vapour dominated system 10 3 greenfield systems our approach is to begin computer modelling as early as possible even for greenfield systems where little or no well data are available see section 4 2 recently we have suggested modelling with uncertainty quantification as a resource estimation methodology currently the procedure has only been demonstrated on synthetic models dekkers et al 2022a 2022b but we expect to use it on real fields in the future as explained in the next section tools from the gmf are used to generate the many sample models used for resource estimation methodology also the gmf can be used to quickly update the model as more data become available 10 4 uncertainty quantification in several of our recent modelling studies e g doherty et al 2017 maclaren et al 2020 omagbon et al 2016 we have used uncertainty quantification uq to provide p10 and p90 estimates of key parameters such as total steam flow rather than just a single value we have also used similar methodology to carry out data worth analysis to identify which new monitoring data is likely to be most effective in reducing uncertainty in model predictions e g dekkers et al 2021 the gmf assist these studies in two ways first it greatly accelerates the model set up and calibration process leaving more time for uq and data worth analysis secondly the model set up scripts from the gmf can be used with a small amount of modification for generating the large number of models required for uq with parameters sampled from statistical distributions 10 5 ease of use we have recently used the gmf in short courses on geothermal modelling and found that it greatly improves the student experience pre prepared digital conceptual models json files and python scripts were provided and the students were able to quickly set up run and calibrate a computer model they learnt about the modelling process rather than being overwhelmed by the complexity of the software for more advanced users of our gmf familiarity with using leapfrog to set up a digital conceptual model is required and competency with python is necessary to be able to modify the model set up and plotting scripts thus the learning curve with our gmf is steeper than with monolithic software such as petrasim or volsung however we think the extra flexibility of our gmf makes the effort worthwhile 11 conclusion in the past maintaining a robust connection between reservoir models and conceptual models especially as the conceptual model evolves over time has been a challenge the tools used to model geothermal systems have typically been bespoke which presents a challenge when taking on new projects in this paper we presented a modelling framework which addresses both challenges by using standardized tools to store data set up models and plot results a key part of our modelling framework is a digital conceptual model implemented in leapfrog geothermal which allows the link between reservoir models and conceptual understanding to be maintained this is important because the conceptual understanding of the field may change when new data are collected for example geological formations structures and the alteration zone may change our gmf is designed to make the changes in the conceptual model easily transferable to the reservoir model likewise if the model grid has evolved with refinement added in areas of interest the reservoir model can be updated easily the gmf includes a system for standardizing field data such as feed zone locations downhole data and various transient data types as well as model inputs e g heat flows mass up flows etc using a global coordinate system and keywords standardized scripts can then be used to set up models and create reports for any geothermal field using any model grid this also means that we can use all the existing tools on a new project which allows geothermal reservoir modelling to happen on a short time frame of all the previous modelling frameworks discussed in section 1 only the two monolithic variants petrasim and volsung are widely used none of the modular variants appear to have gained much acceptance outside their home institutions it remains to be seen if our modular gmf can do better declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the university of auckland 
25414,a new geothermal reservoir modelling framework is discussed the framework has two main objectives first all the geoscience and reservoir engineering data should be stored in a simple manner not in any way dependent on the model grid to be used and secondly the data storage protocols should be easily transferable from one modelling project to the next in our framework some of the data are stored as part of a digital conceptual model created in leapfrog geothermal while most of the rest including well by well reservoir engineering data are stored in human and machine readable json files finally some of the data related to the specification of production history and future scenario parameters are stored in control spreadsheets the reservoir model files required for running natural state production history and future scenario simulations are set up using leapfrog a suite of python scripts and control spreadsheets the python scripts are set up in a general way so that they require little or no modification for use on a new modelling project the model set up process is mainly automatic with very little manual intervention required due to the generality of the process it is easy to modify the reservoir model input files when new data become available such as updated production data similarly the mesh independent database allows new models to be set up easily and quickly this includes modification to the grid for example by adding local refinement or the use of a new grid also a suite of re useable python scripts has been developed for plotting standard sets of results from reservoir models keywords modelling framework geothermal reservoir simulation waiwera python data availability data will be made available on request software availability name of software geothermal modelling framework lead developer john o sullivan contact address department of engineering science university of auckland auckland new zealand telephone 64 9 3737 599 ext 85 353 email jp osullivan auckland ac nz co developers and designers joris popineau michael gravatt theo renaud jeremy riffault adrian croucher angus yeh and michael o sullivan year first available 2022 hardware required windows pc software required leapfrog geothermal python pytough library autough2 or tough2 or waiwera tim availability and cost some of the key python scripts used in the geothermal modelling framework are not yet available it is expected that they will be added to the pytough library within the next 12 months leapfrog geothermal and tough2 are commercial software and require licences autough2 is made available free to holders of a tough2 licence waiwera tim and the pytough library are free program language python program size leapfrog geothermal and tough2 are large software packages but the controlling python scripts in the geothermal modelling framework are quite small waiwera is available at https waiwera github io tim is available at https tim readthedocs io en latest and the pytough library is available at https github com acroucher pytough 1 introduction setting up and running a geothermal model is a complex process involving the following steps i gather data and set up a conceptual model ii set up a computational grid iii use the computational grid and conceptual model to set up a reservoir model iv calibrate a natural state model v calibrate a production history model vi use the calibrated model to run future scenarios this modelling process is often iterative for example it is usual to iterate through the calibration of the natural state and production history models checking the natural state model after changes are made to the production history model similarly it is common to revisit the conceptual model and even the set up of the computational grid during the model calibration process therefore it is important to have a flexible and easy to use workflow for carrying out the modelling process there are two broad approaches to the modelling process monolithic a single software package perhaps two for the whole process modular multiple software packages integrated into a modelling framework via suitable auxiliary software tools the monolithic approach has the advantage of ease of use and therefore accessibility for new users but tends to be inflexible it is implemented in petrasim alcott et al 2006 yamamoto 2008 and in the recently developed volsung clearwater and franz 2019 franz et al 2019 however the monolithic approach of volsung grew out of a more modular approach discussed by franz 2016 the option of two tightly coupled packages is implemented in the petrel eclipse software marketed by schlumberger mainly used in the oil and gas industry but recently applied to geothermal modelling e g stacey williams 2017 sullera et al 2021 similarly cmg offers a combination of a simulator called stars and a post processor called results which has been used for geothermal modelling e g wisnandary alamsyah 2012 deo et al 2013 beckers et al 2021 the modular approach offers greater flexibility as the component software can be combined in different ways to suit different models and is our preferred approach the idea of an integrated modular geothermal modelling framework was probably first discussed by nakao et al 1998 in the context of a modelling study of okuaizu geothermal field this study was carried out jointly by geothermal energy research development co japan industrial research limited new zealand and okuaizu geothermal co japan some geological modelling and data handling was carried out with geobase sato et al 1995 the simulator tough2 was used and pre and post processing was carried out with geocad burnell et al 2003 the tools used for integrating the software were not discussed tanaka and itoi 2010 created a pre and post processor for tough2 linked to a database their software included some of the elements of an integrated modelling framework as did the workflow discussed by audigane et al 2011 they used the petrel geomodeler for setting up a digital geological model and creating a reservoir model input file the output from petrel is an input file for eclipse the schlumberger reservoir modelling software audigane et al 2011 used a fortran program to convert this to a tough2 input file and they also used several fortran programs for modifying the tough2 input file and for processing the tough2 output for visualization in tecplot and paraview berry et al 2014 created tough2gis as a suite of gui provided bash scripts running in the grass gis environment with tough2gis it is possible to generate and manage the conceptual model and to create the numerical reservoir model tough2viewer bonduá et al 2012 is used for visualization the combination of tough2gis and tough2viewer has most of the elements of an integrated modelling framework but does not appear to have been used for many modeling studies of geothermal fields franz 2016 discusses a modelling package matatauira which includes some of the features of a general modelling framework including a fully coupled reservoir wellbore surface simulator and graphical user interfaces to easily set up models carry out data analysis and provide visualization in 3d this package has been developed further to create the volsung software delsante et al 2018 discuss the adaption of the oil gas pre and post processing package restudio for use with tough2 and using geological models built with petrel the interface was built with a series of modules each of them handling a phase of the usual workflow of a geothermal modelling study 2 components of the framework 2 1 rationale for the framework based on our modelling experience and our review of previous work we consider the following criteria to be essential for a general integrated geothermal modelling framework all data including the digital conceptual model should be mesh independent and in a standard format for all reservoir models easy to use and re useable tools e g scripts should be provided for integrating the steps in the modelling process thus making it easy to set up and run modified or new reservoir models easy to use and re useable visualization tools should be provided to assist with calibration and for producing useful plots for modellers and end users the framework should have flexibility so that extra tools can easily be added e g for generating new types of future scenarios for producing new types of plots or for adding extras such as uncertainty quantification or inverse modelling as none of the previous workflows or tools described above in section 1 fulfilled all these criteria and some did not provide the functionality of a complete framework for the entire modelling process we decided to develop a new geothermal modelling framework gmf the gmf does not change the standard modelling process e g o sullivan et al o sullivan and o sullivan 2016 outlined above but can greatly speed it up allowing more time for calibration and delivering better models the ease of use and re useability of the various integration and visualization tools python scripts have been gradually improved by having students meet and overcome problems in applying the gmf to modelling projects and from the experiences of our modelling team in applying it to several projects see section 10 the main components of the gmf are briefly summarized in the rest of this section and more details are given in later sections 2 2 digital conceptual models the development of our gmf started when the leapfrog software became available and we began using it for setting up digital conceptual models newson et al 2012 leapfrog s integrated environment allows field wide multidisciplinary data to be directly visualized compared and modelled and it is now used widely for geothermal projects alcaraz et al 2010 2011 2015 milicich et al 2010 massiot et al 2011 newson et al 2012 pearson et al 2012 kandie et al 2016 the digital conceptual model is discussed further in section 4 2 3 reservoir simulation after setting up a digital conceptual model in leapfrog the next stage of the development of our gmf was the use of python scripts for setting up an input file for a reservoir simulator o sullivan et al 2019 popineau et al 2018 we use the simulators autough2 yeh et al 2012 and waiwera croucher et al 2016 2017 2018 2020 o sullivan et al 2017 but with some modification of scripts allowing for differences in the format of input and output files the gmf could be applied to any geothermal simulator more details of model set up within the gmf are given in sections 5 and 6 2 4 visualization tools previous visualization tools for geothermal modelling with tough2 there have been many tools developed for setting up reservoir models and visualizing modelling results the commercial software includes geocad burnell et al 2003 wingridder pan 2003 petrasim alcott et al 2006 yamamoto 2008 mview avis et al 2012 leapfrog newson et al 2012 re studio delsante et al 2018 and volsung clearwater and franz 2019 franz et al 2019 a few modellers have used simulators and accompanying visualization tools developed for the oil and gas industry but also applicable to geothermal modelling for example sullera et al 2021 used the petrel platform for pre and post processing of results obtained from using the eclipse simulator to model the leyte geothermal field there have also been many free and open source visualization tools developed for use with tough2 some of the easily accessible software is listed in table 1 visualization tools for the gmf in our gmf we use the open source software tim yeh et al 2013 for simple 2d and 1d plots and the commercial software leapfrog for 3d visualization the simulators autough2 and waiwera are both based on the finite volume method for spatial discretization and the input files do not need to contain complete information about the geometry of the model grid for tim and its predecessor mulgraph we supply the geometric information required for visualization through a geometry file that contains the xy coordinates of the nodes the nodes forming each block the connectivity of blocks and the layer structure tim assumes each layer is horizontal and the block structure within each layer is the same a simplification not required by tough2 there are tools in tim and pytough for setting up the geometry file a key part of our gmf is the pytough library croucher 2011 2015 wellmann et al 2012 which contains many scripts for model management and visualization two other python libraries have been developed for assisting with geothermal modelling namely toughio luu 2020 and t2geores majano 2021 however pytough offers a more comprehensive suite of software tools some that we find very useful are the scripts used to generate suites of plots showing the state of calibration of a model as shown below in figs 6 8 some of the python scripts used in the gmf have not yet been included within pytough but will be after more testing and quality assurance has been carried out 2 4 integration tools in the gmf end to end integration between the different elements of the framework is carried out using python scripts which offer great flexibility without needing to be compiled and interface naturally with the pytough library a list of the scripts used within the gmf is provided in table 2 in section 3 this list of scripts corresponds to the step by step process required for a geothermal modelling study this complex task is currently addressed using a variety of software tools by other geothermal modellers we claim novelty for our gmf in two respects i we have broken down the modelling process into a logical and fine grained sequence of steps ii we have developed python scripts for carrying out each step these scripts have been extensively tested to ensure that they are easy to use easy to modify and can be easily applied to a new project 2 5 data storage and access in our gmf we store data in three ways see table 3 i geoscientific and some reservoir engineering data are stored in leapfrog and are used for creating the digital conceptual model see table 4 ii reservoir engineering data are stored in json files see table 6 iii some data for setting up production histories and future scenarios are stored in spreadsheets a key part of the gmf is that the well by well reservoir data and some other data see table 3 are entered into machine and human readable json files data are used directly from standard json files for model setup model calibration and plotting of results 3 presentation of the framework fig 1 presentation of the framework used to process reservoir model files for the natural state the production history and the future scenario the reservoir model is based on a conceptual model set up in leapfrog from the geoscientific data contained in the digital conceptual model see section 4 once a model grid has been set up a model input file can be generated using leapfrog then python scripts are used to modify the reservoir model for example the leapfrog rock type names are replaced by a naming convention for the formations and faults inside or outside the main reservoir etc see section 6 often the vertical and horizontal face permeabilities for dipping faults and non aligned faults need to be adjusted see section 6 2 python scripts are used to implement boundary conditions and initial conditions in the model input file see section 7 a summary of the python scripts currently used in the gmf and their function is given in table 2 for each well the natural state temperatures and pressures and production data are stored in a json file see section 8 they are called by scripts to set up the production history model input file and to post process the results see table 2 and section 9 similarly the control spreadsheets contain some of the data for the production history and future scenario for the injection and production wells and are used to write the relevant module of the input file for example gener in autough2 the data storage in the gmf is summarized in table 3 this framework can be applied to any digital conceptual model built with leapfrog it allows enough flexibility so that changes to the conceptual model can easily be made and transferred through to the reservoir models 4 conceptual model 4 1 overview developing a conceptual model of a geothermal field requires combining knowledge from a wide range of sources the conceptual model should describe where the upflow and recharge is coming from the size of the resource and the location of fluid controls such as geology structures and alteration zones e g purwandono et al 2015 mroczek et al 2016 mcdowell et al 2020 renaud et al 2022 a key element of our gmf is a digital conceptual model that is built from field data although the digital conceptual model is an essential foundation for our gmf we regard its construction or modification as a separate but challenging task to be carried out before implementing the gmf more discussion of our approach to conceptual modelling is given in section 4 2 and is included in publications on some of our modelling studies e g prastika et al 2016 wardana et al 2016 nugraha et al 2018 o sullivan et al 2018 in the geological model which forms a major part of the conceptual model of a geothermal system three main features are important the geological units structures and mineral alteration see fig 2 these are the ingredients that typically go into the development of the permeability model discussed below that is used for setting up rock types in a reservoir model as well as the geological model the digital conceptual model may contain geophysical data such as magneto telluric mt data geochemical data such as chloride concentrations and reservoir engineering data such as well tracks downhole temperature profiles and feed zone elevations similarly information about geothermal surface features such as hot springs and steaming ground as well as any geo referenced objects roads buildings lake etc can easily be added to the digital conceptual model and visualized alongside the geological model table 4 contains a summary of the data that are usually included in the digital conceptual model 4 2 geology for a developed geothermal field the geological units in a leapfrog model are derived from geological maps and stratigraphy stratigraphy is obtained from wells and from interpreted geological cross sections often the stratigraphy from well data must be grouped simplified and sometimes interpreted in order to generate a set of consistent geological units that realistically reflect the current understanding of the subsurface alcaraz et al 2010 massiot et al 2011a newson et al 2012 alcaraz and barber 2015 alcaraz and milicich et al 2018 however at the early stages of development or before development begins there may be little or no downhole data to apply our modelling framework to a greenfield site we have used a simple approach to setting up a geological model stratigraphy is estimated from geological models of the wider area by analogy with similar systems and from the geological history e g dates of various eruptions prastika et al 2016 wardana et al 2016 nugraha et al 2018 within our gmf the geological model can be easily updated with measured downhole well data when they become available and the corresponding changes are easily transferred through to the reservoir model 4 3 structural model faults and structures can be explicitly defined in the structural model which is integrated into the leapfrog geological model as represented in fig 2 usually the dip of a fault is well constrained near the surface but at depth is more uncertain in the geological model the path of faults or structures may need to be modified to achieve agreement with reservoir engineering data mcnamara et al 2016 one example of this is when feed zone data from a well indicates a location of high permeability corresponding to the intersection of the well with a fault this new information may require the location of a fault to be adjusted in the digital conceptual model 4 4 alteration zone the shape and size of this alteration zone or clay cap is an important part of the conceptual model of a geothermal field as it is an important mechanism for controlling fluid flow however an alteration model should be based on a combination of data sepulveda et al 2012 sewell et al 2012 ardid et al 2021 such as resistivity from magneto telluric or mt data temperature data feed zone elevations and quality as well as mineralogy identified by methylene blue tests gunderson et al 2000 rosenberg 2017 and other methods such as scanning electron microscopy sem x ray diffraction xrd and petrographic microscopy e g lynne et al 2011 2013 in our workflow the alteration model is considered separately from the structures and geology and then superimposed on them in the leapfrog digital conceptual model 4 5 other data including other forms of geothermal data into the 3d leapfrog digital conceptual model helps to visualize and understand the geothermal system for example looking at the locations of surface features and geochemistry data such as chemical composition and geothermometry data can indicate the location of the deep upflow these deductions are based on how much the geothermal fluid has mixed with shallow aquifers on the way to the surface d amore and panichi 1985 joseph et al 2011 if the flow path based on geochemistry lines up with a fault it helps to explain the pathway through the alteration zone and helps to establish the conceptual model these extra data types can be used by geothermal modellers to calibrate reservoir models to qualitative data as well as to the traditional quantitative data such as temperature profiles and transient pressure and enthalpy data all the data discussed above and more can be entered into leapfrog and used as a visual database and for 3d visualization of the digital conceptual model o sullivan et al 2019 popineau et al 2018 5 model grid the size orientation and type of discretization for the model grid is a matter of judgment for the modeller but in general it is chosen to capture the important physical processes in sufficient detail one approach is to start with a coarse model that runs quickly and then refine the grid as necessary the framework presented here is designed to make it easy to modify the reservoir model if the grid is changed to establish the model grid we first set up the geometry file see section 2 2 using tim or pytough in most recent models we have included the shallow unsaturated zone and set the top of the model at ground surface in this case we include a high resolution topographical surface available from google earth for example as part of the digital conceptual model tools available in leapfrog or pytough can be used to fit the topography to the model grid by setting the elevation of the top of each column in the model in the geometry file see fig 3 some modellers prefer to have the top of their model at the water table in this case water table data can be included in leapfrog and then the same approach can be used to fit the top of the model to a smoothed surface fitted to the water table data for autough2 models we avoid very thin blocks at the top of a column that can cause computational problems e g less than 2 m thick by snapping the topography to the nearest top boundary of a layer for waiwera only complete blocks can be used and so for all columns the topography must be snapped to the nearest top boundary of a layer in several of our models part of the grid lies beneath a river a lake or the ocean in this case bathymetry data are added to the topography data however we have found that with typical block sizes the interpolation process may not always be adequate for dealing with rivers and some small amount of manual adjustment is required for setting up a physically reasonable continuous river track 6 permeability model 6 1 rock type mapping the first step in setting up the permeability model based on the leapfrog digital conceptual model is to map the corresponding rock types on to the model grid by using leapfrog basic rock types are assigned for each geological formation and then modified rock types are introduced with script 1 see table 2 where a fault intersects the formation and where the clay cap overlays a formation in some cases to provide a better representation of the heterogeneity in the reservoir and to give extra flexibility during the calibration process a geological formation can be split into sub formations for example to represent the deep and shallow parts of the formation or where a part of the formation is thought to be highly fractured the tools in leapfrog geothermal and our script 1 make the process of assigning rock types to the model blocks simple and efficient as shown in fig 4 the same process can also be used to transfer any updates in the geological model to the reservoir model leapfrog geothermal allows dipping faults to be represented and has options that can be used to ensure that the fault is represented continuously along the strike and up the dip of the fault the user can also specify the width of the damage zone which controls how far on each side of the fault it is assumed that permeability has been affected by the fault 6 2 rock type properties next script 2 see table 2 assigns each rock type the physical properties needed for the reservoir simulation porosity permeabilities rock conductivity etc these can be assigned either from an existing reservoir model or from initial estimates for the properties of different rock formations and structures a clear and logical naming convention for rock types is set up this convention respects the geology structures and alteration zone and typically defines a large number of rock types table 5 shows the 5 character convention for naming rock types using four rock types within the ignimbrite formation as examples as shown the first character identifies the formation the second character identifies the first fault the third character identifies the second fault the fourth character identifies whether or not the clay cap is present and the fifth character is the version number script 10 is used to convert the single porosity natural state model into a dual porosity production history model all or part of the model can be treated as dual porosity similarly script 11 is used to convert the final results from the natural state simulation into initial conditions for the dual porosity production history model with the same pressure and temperature or vapour saturation assigned to the fracture block and matrix blocks replacing each single block in the natural state model another important feature of the gmf is the mapping of a permeability structure from an older model if there is an older well calibrated version of the model with a different grid coarser or finer it can be used by script 2 for mapping over the old rock type parameters on to the rock types of the new model this process provides a good starting point for calibration of the new model 7 boundary conditions all boundary conditions are assigned by using mesh independent parameters defined at the model set up stage some parameters such as depth and location of a lake river etc are included in the digital conceptual model while others such as rainfall background deep heat flow and hot upflow of mass are included in a boundary condition json file 7 1 top boundary at the top boundary we set up either dry atmosphere blocks containing air and water vapour or wet atmosphere blocks containing water in the dry atmosphere blocks above land the pressure is set as atmospheric pressure 1 bara and the temperature is set at an average annual value for the area of interest average monthly or weekly temperatures are sometimes used in production history models in the wet atmosphere blocks the temperature and pressures are set to correspond to values at a lake a river or ocean bed varying with the bathymetry the pressure is calculated as the hydrostatic pressure based on the depth of the body of water also at the top of the dry land part of the model infiltration of rain into the soil is represented by the injection of water usually an annual average rainfall is used and a suitable infiltration rate assumed but in some cases e g our model of the rotorua geothermal field febrianto et al 2013 ratouis et al 2014 setiadi et al 2014 ratouis et al 2015abc ratouis et al 2016abc ratouis et al 2017 the precipitation is allowed to vary throughout the year by applying the historical monthly or weekly rainfall also in this case and in some other models a spatially variable infiltration rate is used for the rotorua model a customized version of script 3 is used to restrict infiltration in the urban area and allow more infiltration outside the city where there is less impermeable cover we do not add rainfall to wet atmosphere blocks e g under the lake the infiltration rate can be made to depend on features such as ground cover slope of the ground or surface geology this infiltration rate is then calculated from the specified rainfall in kg s m2 which can be mapped on to the surface of any grid system and made to depend on block areas for models with the top of the model at the water table wet atmosphere blocks are used and no rainfall is included in this case the resulting inflow through the top of the model has the potential to be used for calibration against infiltration data in terms of our gmf the only requirement is the specification of the topography bathymetry in the leapfrog model and infiltration rates in terms of mesh independent global coordinates in the boundary condition json data file 7 2 side boundary typically reservoir models are made large enough in area so that most of the convective system can be included within the model and closed or no flow side boundary conditions are used this assumes that flows from the geothermal system either in the natural state or during the production history do not cause significant pressure changes at the edge of the model in some cases this assumption is not appropriate for the production history simulation or future scenarios and recharge is allowed through the sides of the model this is implemented in autough2 through pressure dependent generators with the identifier rech so that water flows in if the pressure at a boundary block drops as a result of nearby production or water flows out if the pressure near the boundary increases as a result of injection the details of the side recharge are set up in a mesh independent manner in a json file and implemented in the model with a python script script 9 in table 2 7 3 bottom boundary the depth of a reservoir model is usually set such that the bottom boundary is well below the bottom of any wells say approximately 1 km at that depth for most reservoirs the use of a supercritical equation of state eos is unnecessary but in some cases a supercritical eos needs to be considered montegrossi et al 2015 o sullivan et al 2020 typically the base of a model is located at between 2500 masl and 3500 masl but some are deeper such as the current wairakei tauhara model 4500 masl and some are shallower such as for rotorua 1500 masl where there are no deep wells and the focus is on capturing surface changes ratouis et al 2016a at the bottom boundary a background flow of heat is specified this can be constant across the whole model or made to be spatially dependent for our gmf the heat flux is specified in a json file in terms of the mesh independent coordinate system e g a constant heat flux over the whole area or a piecewise constant heat source or something more complicated for inverse modelling purposes we have sometimes represented heat flow by simple functions e g radial basis functions that can be expressed in terms of a few parameters script 3 is then used to assign the appropriate heat flow rate for the bottom cells depending on column areas also at some locations usually along deep faults an upflow of very hot water is specified in the boundary condition json file this is usually one of the key quantities to be adjusted during model calibration the upflow can be assigned different values at many blocks in the basement layer or it can be expressed in terms of simple functions controlled by a few parameters e g using pilot points omagbon et al 2016 again script 3 is used to assign injection of very hot water at the relevant blocks in the bottom layer of the model in some production history and future scenario models we have added an extra pressure dependent deep inflow of very hot water so that the deep hot recharge increases as the very deep reservoir pressures decline due to production again the parameters for the deep recharge are given in mesh independent form in a json file and a script script 9 in table 2 is used to implement the deep recharge wells in the production history and future scenario model files 7 4 surface features in some cases surface features are represented by local high vertical permeability pathways allowing enhanced outflow at the top of the appropriate column in the model the trouble with this approach is that it averages fluid properties such as temperature over the area of the model column which may be large compared to the size of the surface feature it also allows water feeding the hot spring to mix with cold water in shallow aquifers before reaching the surface in some cases this may not be appropriate as there is an isolated pathway from a hot region in the reservoir to the surface an alternative approach is to represent the surface feature e g hot springs hot pools or steaming ground by a spring generator feeding from a suitable depth a mass well in autough2 with a constant production rate set for the natural state model and a pressure dependent deliverability option see below used for production history and future scenarios for our modelling framework the location feed depth and area of each surface feature must be specified in a separate json file and then a script is used to set up wells representing the surface features in the chosen model grid system script 4 in table 2 8 wells and feedzones 8 1 feed zone allocation well tracks and their feedzones must be defined in geothermal reservoir models so that source or sink terms can be created to represent fluid flowing into or out of the feedzones in the past the low resolution of the reservoir models meant that often a feedzone was contained entirely within a single model block this makes the process of assigning and handling the wells simple however in multi million block models each feedzone of a well may span multiple model blocks to deal with this situation we use a system where well information such as the well track feedzones and other well data are stored in json format data files see table 6 when setting up a production history or future scenario model python scripts read these data files and then sample down the well track in the specified model grid this identifies the blocks associated with each feedzone and the proportion that each block contributes to the feedzone script 7 in table 2 for example a feedzone can span two blocks but 60 may be in the first block and 40 may be in the second block depending on the proportion of the feed in each block for wells that have multiple feedzones the proportion that each feedzone contributes to the total mass produced or reinjected is usually supplied by reservoir engineers guided by surveys such as pressure temperature spinner pts runs or output tests grant and bixley 2011 for multi feedzone wells a control spreadsheet contains the feedzone fraction as one of the parameters and it can be made time dependent to allow the modeller to change the feedzone proportions with time this is desirable as well feedzone proportions change over time due to a range of factors such as scaling and work overs mclean et al 2021 in some cases the feedzone fraction is adjusted as part of the calibration process for the production history model within our framework we use the scripts to set up a new gener when adjustments are made to the feedzone proportions the total that a well produces or reinjects is imposed on the model through the recorded history these data are included in the well by well json files and script 8 is used to set up the data in the production history model input file in some cases these flows may need to be inferred because the mass flow is only measured at a separator which is fed by multiple wells for example with our ohaaki model o sullivan et al 2012 clearwater and franz 2019 ratouis et al 2017a mcdowell et al 2018a 2018b we use annual output tests to set the contribution from each well that feeds a particular separator and assume that fraction remains constant over the year obtaining accurate production and injection data for a modelling study is often a time consuming task a common problem we have encountered is inconsistency between the production data and the injection data e g with the total injection rate incorrectly exceeding the total production rate our framework does not solve this problem but it does help to quickly rewrite a modified production history model file when the clean production and injection data are added to the well by well json files 8 2 deliverability for future scenario simulations rather than imposing a mass flow on a well we allow the mass flow to depend on the reservoir pressure this is done with the deliverability option for production wells and an injectivity option for injection wells the deliverability mode calculates flow rate as a function of pressure at the feed zone this means that if the feed zone pressure declines so will the mass flow in the formulation of the deliverability option available with tough2 pruess et al 1999 the mass flow q mβ of each phase β w for water and β s for steam is given by 1 q m β k r β ν β pi p β p w b here for each phase k rβ is the relative permeability p β is the pressure and ν β is the kinematic viscosity pi is the productivity index and p wb is the flowing bottom hole pressure the key parameter in the deliverability formula is the flowing bottom hole pressure p wb if the reservoir pressure in both phases falls below p wb then the well will not produce in the framework presented here script 13 is used to automatically assign a deliverability generator to each feed block in each feed zone in the well usually it is expected that the performance of the wells will not change from the end of the production history simulation to the start of the future scenario and for each generator a productivity index pi is calculated with a script based on 1 to ensure a smooth transition of the mass flow between the production history and future scenario 8 3 production and injection flow rate production or injection data through time is stored for each well in their json file they are used as input for the production history model with the quantity split across feed blocks these data are also reproduced in plots see fig 8 to enable checking that the model is correctly producing or injecting the specified amounts 8 4 production enthalpies variation of enthalpy of the produced fluid for a given well over time is another key data type used to calibrate the production history model the enthalpy data are included in the json file for each producing well the bottom right plot of fig 8 shows an example of this kind of comparison the match to production enthalpy for so called excess enthalpy wells i e wells producing fluid with an enthalpy above that of water is important as a good match indicates that the right amount of boiling is occurring in the model usually matching the behaviour of excess enthalpy wells quite tightly constrains the nearby permeability and porosity as mentioned above the proportion of the total production assigned to each feed zone can be considered as a calibration parameter and enthalpy data from the well can guide the choice of these proportions in control spreadsheet for the well 8 5 well groups information about well groups is useful for reporting results and for model set up for example calculating an average production enthalpy or steam flow for each separator can help with understanding the characteristics of the reservoir well groupings are commonly used in setting up future scenario models this is done in the case of larger fields with multiple separators e g ohaaki see mcdowell et al 2018a b separate steam targets can be set for these areas since wells generally can only service the separators to which they are connected the most common groupings we use are by location in different areas zones reservoirs etc by depth like shallow intermediate or deep wells and by affiliations to a separator or a power plant there may be several power plants in one system such as at wairakei 8 6 future scenarios set up future scenarios are usually specified by the reservoir engineers who want to investigate different management strategies for the field for example these might involve varying the level of production to investigate sustainability or testing reinjection in different locations to investigate thermal breakthrough typically many trials are required to arrive at a satisfactory set of future scenarios and the process of manually setting up the corresponding model files is very tedious and these files are not transparent to overcome these two issues as part of our gmf we have developed a system of setting up future scenarios using spreadsheets with which reservoir engineers can easily interact these are project specific as the scenarios tend to be project specific however we have a standardized but flexible format that allows fast development and implementation of future scenarios future production and reinjection rates for existing wells and make up wells are set up within control spreadsheets using different parameters like operation dates rates or deliverability parameters wellbore pressure and pi as discussed above for as many scenarios as needed then script 13 is used to generate the gener module within the autough2 model file or the equivalent module in a waiwera model file no direct editing of the model files is required as all changes in the specification of the future scenario are made in the spreadsheet for each new make up well a new json file is written containing information such as well track and feedzones in the same format as for the existing wells this means that the standardized scripts can treat a make up well in the same way as an existing well the productivity indices of feedzones for the make up wells are estimated based on data from the existing wells 9 plotting results good visualization tools are essential for model calibration and for reporting model results to the decision makers o sullivan et al 2019 popineau et al 2018 our standard visualization tool tim can be used for developing modifying and running reservoir models and for displaying results yeh et al 2013 tim is an open source visualization tool developed at the university of auckland https tim readthedocs io en latest fig 5 shows a cross section of the temperature distribution in a model from tim many model inputs and outputs can be easily visualized in tim alongside tim we use python scripts to produce standard sets of plots scripts 6 and 12 in table 2 in the plotting script there are a range of options the user can specify such as plotting results for a selection of wells we have attempted to make the plotting scripts general so that they can be used on any geothermal field with one or more model grids with little or no adjustment we have also made the python script easy to read so that they are easy to modify the ease of use and re useability has been improved over time by having many modellers including students apply them to modelling projects for natural state models we primarily plot downhole temperature profiles for all wells a typical page of this type of report including the location of the wells is shown in fig 6 it shows the locations of five wells the resistivity boundaries and track of the waikato river are shown for orienting the model other identifiable features of the geothermal system such as easting and northing or faults and caldera boundaries can be used the figures show model temperatures plotted together with the observed temperatures from the standardized json files to better describe the quality of the match the root mean square deviation rmsd is calculated using model temperatures interpolated to the elevations of the observed temperatures the rmsd error for each well and for different elevation bands can be plotted on a map as shown in fig 7 this figure helps to identify the areas and depths of the model that need improvement by further calibration as it shows areas where the model is too cold and other areas where the model is too hot the decision based on fig 7 could be that the upflow or vertical permeability in the western and south eastern parts of the field needs to be decreased to give a better match to the temperature data figs 6 and 7 are plots generated for the ohaaki geothermal field several models of this field were set up before the gmf was available but its application to ohaaki particularly using plots such as fig 7 has improved model calibration the matches of model results to data shown in figs 6 and 8 were improved by using the gmf for production history simulations a similar but more extensive set of plots is produced it can incorporate many different plots for each well for example well location temperature vs time downhole temperature profile with model results plotted for the date when the data were collected pressure vs time at the model feed blocks mass steam brine flow rate vs time production enthalpy vs time a typical example is shown in fig 8 the suite of plots for the production history model contains one or two pages per well like fig 8 and includes all relevant data and model results for that well plots of field wide totals are also produced e g for total production flow rates of mass steam brine and average enthalpy standardized plotting for future scenarios is more difficult to arrange as there are variations between fields with respect to what issues are important these suites of plots are made as standard as possible but typically vary from one project to the next having a standard set of plots to start from makes plotting results for future scenarios for a new project or an existing project with new requirements relatively easy comparison between scenarios is also important typically scenarios are run to study the effect of varying production levels or to test different reinjection strategies plotting results from two or more models on one set of figures allows assessment of these differences in addition to standardized reports 3d visualization of results is used to integrate results from the modelling process with data from the digital conceptual model we use leapfrog geothermal for this purpose this software is licensed but viewer files can be created that allows stakeholders to view prepared model results licence free in a web based browser as an example fig 9 shows the steam zone near the top of the hot upflow the integrated database for the geothermal field wells parameters geological settings can be shown together with reservoir modelling results to aid decision makers who are managing the field 10 applications 10 1 previous projects the gmf has been in development for the last 10 years during that time the fundamental ideas of integrating a digital conceptual model and a numerical reservoir model have remained the same and most of the effort has gone into standardizing the suite of python scripts used to implement the gmf see tables 2 and 7 and for standardizing data storage see table 3 various versions of the gmf have been used on commercial modelling projects on ohaaki new zealand namora i langit kamojang lahendong indonesia lihir papua new guinea san jacinto nicaragua and the paris basin france the only open source reports on these studies are o sullivan et al 2021 and popineau et al 2022 also several student modelling projects have used the gmf e g on arjuno welirang darajat dieng hululais jaboi kerinci lahendong lumut balai muara laboh patuha telaga ngebel waesano and ulubelu all in indonesia a few of these studies have been published in conference proceedings e g prastika et al 2016 wardana et al 2016 nugraha et al 2018 o sullivan et al 2018 10 2 summary for kamojang in order to provide more insight into the details of the gmf a summary of its recent application to a modelling study of the kamojang geothermal field indonesia is provided here in table 7 as the table shows the software packages used are leapfrog geothermal for setting up the digital conceptual model and for setting up most of the data file for autough2 autough2 for running the natural state production history and future scenario simulation tim for visualization to assist with calibration of the natural state and production history models the key components of the gmf are the python scripts listed in table 2 these scripts are used for model set up and for generating suites of plots for each stage of modelling see figs 6 8 for plots for the ohaaki geothermal field these scripts are used for all our modelling studies but required some customization for the kamojang project but as emphasized throughout this paper these scripts have been standardized as much as possible to minimise the amount of modification required for each new project as discussed in note 1 below table 7 the script that is used to set up the boundary conditions had to be extensively modified for the kamojang project because kamojang is a vapour dominated system 10 3 greenfield systems our approach is to begin computer modelling as early as possible even for greenfield systems where little or no well data are available see section 4 2 recently we have suggested modelling with uncertainty quantification as a resource estimation methodology currently the procedure has only been demonstrated on synthetic models dekkers et al 2022a 2022b but we expect to use it on real fields in the future as explained in the next section tools from the gmf are used to generate the many sample models used for resource estimation methodology also the gmf can be used to quickly update the model as more data become available 10 4 uncertainty quantification in several of our recent modelling studies e g doherty et al 2017 maclaren et al 2020 omagbon et al 2016 we have used uncertainty quantification uq to provide p10 and p90 estimates of key parameters such as total steam flow rather than just a single value we have also used similar methodology to carry out data worth analysis to identify which new monitoring data is likely to be most effective in reducing uncertainty in model predictions e g dekkers et al 2021 the gmf assist these studies in two ways first it greatly accelerates the model set up and calibration process leaving more time for uq and data worth analysis secondly the model set up scripts from the gmf can be used with a small amount of modification for generating the large number of models required for uq with parameters sampled from statistical distributions 10 5 ease of use we have recently used the gmf in short courses on geothermal modelling and found that it greatly improves the student experience pre prepared digital conceptual models json files and python scripts were provided and the students were able to quickly set up run and calibrate a computer model they learnt about the modelling process rather than being overwhelmed by the complexity of the software for more advanced users of our gmf familiarity with using leapfrog to set up a digital conceptual model is required and competency with python is necessary to be able to modify the model set up and plotting scripts thus the learning curve with our gmf is steeper than with monolithic software such as petrasim or volsung however we think the extra flexibility of our gmf makes the effort worthwhile 11 conclusion in the past maintaining a robust connection between reservoir models and conceptual models especially as the conceptual model evolves over time has been a challenge the tools used to model geothermal systems have typically been bespoke which presents a challenge when taking on new projects in this paper we presented a modelling framework which addresses both challenges by using standardized tools to store data set up models and plot results a key part of our modelling framework is a digital conceptual model implemented in leapfrog geothermal which allows the link between reservoir models and conceptual understanding to be maintained this is important because the conceptual understanding of the field may change when new data are collected for example geological formations structures and the alteration zone may change our gmf is designed to make the changes in the conceptual model easily transferable to the reservoir model likewise if the model grid has evolved with refinement added in areas of interest the reservoir model can be updated easily the gmf includes a system for standardizing field data such as feed zone locations downhole data and various transient data types as well as model inputs e g heat flows mass up flows etc using a global coordinate system and keywords standardized scripts can then be used to set up models and create reports for any geothermal field using any model grid this also means that we can use all the existing tools on a new project which allows geothermal reservoir modelling to happen on a short time frame of all the previous modelling frameworks discussed in section 1 only the two monolithic variants petrasim and volsung are widely used none of the modular variants appear to have gained much acceptance outside their home institutions it remains to be seen if our modular gmf can do better declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was supported by the university of auckland 
