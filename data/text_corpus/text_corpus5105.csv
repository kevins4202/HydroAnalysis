index,text
25525,this paper describes a simplified flood model based on cellular automata in order to be implemented in applications which require the simulation of a great number of flood scenarios at regional scale the model is based on a top down evaluation of the flow process through the cells of the dem according to the conditions in a moore neighbourhood the cells are classified in a dynamic process in four possible states with its own rules to verify the quality of the results an evaluation is carried out using the benchmarking tests and results shown in neelz and pender 2013 besides the 2d models hec ras and iber were used to evaluate quantitatively the efficiency of the model in terms of water depth and flood extent from this it is observed that the model produces very acceptable results especially where dynamic effects are less significant keywords conceptual flood model cellular automata flood hazard flood risk data availability the authors do not have permission to share data 1 introduction floods are recurrent events in many countries with social and economic consequences and even catastrophic potential when produced in extreme scenarios they have an important impact on public finances forcing governments to use funds that originally were established for other purposes to deal with the emergency and restore the status quo ante for years the global strategies against floods were oriented to protection and mitigation however experience has proved that floods are almost impossible to eradicate so strategies have been re oriented to flood risk management where negative consequences must be considered mostert and junier 2009 as flooding might continue to affect communities despite the best flood risk engineering practices it is important to plan for an adequate management of the emergency and a quick recovery this includes planning for the right human and financial resources to be available the main aim of risk assessment is to estimate the probability of adverse consequences for established time intervals due to the occurrence of natural hazards integrating in a rational way the uncertainties related to each part of the process plate 2002 merz and thieken 2004 council of european union 2007 unisdr 2009 world bank et al 2012a torres et al 2014 the availability of historical information on catastrophic flood events is very limited and data on the economic consequences is still scarcer considering the possibility of highly destructive events in the future risk assessment has to focus on probabilistic models that use available information to best predict future scenarios and consider the spatial and temporal uncertainties involved in the analysis process melchers 1999 merz et al 2004 lane et al 2011 torres et al 2014 1 1 probabilistic flood risk assessment the probabilistic risk assessment consists of evaluating the consequences i e economic losses in the exposed group of assets due to the occurrence of each flood scenario which collectively describe the flood hazard and then integrating the results in risk indexes for a realistic and structured flood risk analysis it is necessary to estimate the relationship between the amount of foreseen damage vulnerability in an inventory of assets exposure and the occurrence probability of the flood hazard the risk due to natural hazards is commonly expressed in terms of the expected loss e β and the loss exceedance rate ν β which specifies the frequency usually annual of the occurrence of the losses esteva 1967 1 e β i 1 e v e n t e β h i f a event i 2 ν β i 1 e v e n t pr b β event i f a event i 3 pr b β event i h pr b β h f h event i d h where pr b β event i is the probability that the loss be larger than β since the i t h event occurred and f a event i is the annual frequency of occurrence of the i t h event pr b β h is the exceedance probability of the loss value β since the local intensity is h and f h event i is the probability density of the intensity conditioned to the occurrence of the i t h event this term takes into account the fact that once an event has occurred the intensity at the site of interest is uncertain e g water depth flow velocity energy head among others for these purposes it is necessary to compile data from two different aspects the flood hazard at the site intensity and frequency and the vulnerability of the exposed asset it is standard international practice to estimate the vulnerability through vulnerability damage functions which represent the relationship between the expected damage loss and the intensity of the flood according to the main characteristics of the evaluated asset i e cost material use number of levels type of contents among others these vulnerability damage functions have commonly considered that direct losses are mainly related to the flood depth e g smith 1994 merz and thieken 2004 green et al 2011 jongman et al 2012 torres et al 2014 hammond et al 2015 velasco et al 2016 frongia et al 2017 nguyen et al 2017 komolafe et al 2019 martínez gomariz et al 2020 romali and yusop 2021 this assumption might be due to limited information about other parameters characterising the flood however kreibich et al 2009 investigated the influence of other flood parameters as flow velocity and head energy on the structural damage and monetary flood loss of buildings and road infrastructure concluding that the influence of velocity was only significant on structural damage to road infrastructure even it has been recognized that vulnerability damage functions have several sources of uncertainty in the flood parameters and in the potential damage in assets and should be treated as random variables torres et al 2014 hammond et al 2015 in this study the principal flood characteristics of interest for risk assessment purposes are the flood depth and extent the probabilistic risk assessment requires a great amount of flood scenarios and or simulations to reach a high level of robustness in the hazard assessment these flood scenarios are generally obtained from two main sources to allow the estimation of the consequences a historic flood events by means of historic records in situ or more recently analysis of remote sense data e g gómez palacios et al 2016 and b numerical flood models which use engineering basis in their development since the availability of historical records that describe adequately the spatial extent and distribution of the flood intensity i e water depth and velocity is still not enough to fulfil the requirements of risk assessment the feasibility of the process depends enormously on numerical flood models which must be efficient and with a reasonable cost of time and resources the hydrodynamic models are a good alternative to generate flood scenarios at high spatial and temporal resolution considering different levels of complexity due to its ability to solve the equations that define the flow physical properties and behaviour however the computational costs especially of 2 d and 3d models for large floodplains are extremely high besides the requirements of detailed data about spatial distribution of the input parameter and for model calibration which are usually not available for large floodplains and regional studies teng et al 2015 scorzini et al 2018 these aspects limit the application of hydrodynamic models to studies where the availability of input data the level of complexity and the computational costs allow their implementation 1 2 conceptual flood models in the last years it has become more acceptable the use of simplified conceptual models with a lower level of detail as a reasonable alternative to generate rapidly flood scenarios in large scale this type of model does not solve the physically based flow equations and are based on simplified hydraulic assumptions and considerations on the characteristics of the terrain teng et al 2015 2017 scorzini et al 2018 conceptual flood models can be used predictively but does not fit the full description of a hydrodynamic model these type of models are sometimes classified as 0d models in a wrong way since most of them show the 2d representation of the flood pender 2006 they are also considered as 0 term models in contrast to full term models that solve shallow water equations in 2d by omitting one or two acceleration terms neelz and pender 2013 these models require a lower computational cost compared to hydrodynamic models they are fast and robust more desirable for applications that do not require velocity outputs and have low demands on the representation and accuracy of flow dynamics teng et al 2017 the execution time savings of this type of model is suitable for large floodplains and for probabilistic risk assessment which requires a large number of simulations when there are clear flow paths through the floodplain these models produce predictions of flood extent volume and water depth that are well comparable to 2d shallow water equation models however comparisons differ for topographies of high complexity especially in areas where the conservation of moment is important such as predictions of water levels and velocities in a complex floodplain near a dam failure and when the spreading flood encounters an adverse slope in the floodplain these limitations restrict the application of simplified conceptual models to applications where dynamic effects are less significant in the estimation of the water flow teng et al 2017 a first classification of conceptual models was proposed by teng et al 2017 into the following three main groups a rfsm models the rfsm rapid flood spreading method lhomme et al 2008 which pre process the topography classifying ground depressions into flood areas and then distribute the flood volume to fill those areas in general the rfsm models perform the following pre process to estimate the flood propagation through the impact zones delimitation of impact zones relationships area volume for each impact zone list of adjacent impact zones and identification of points of communication between impact zones location and elevation this type of model can produce approximate predictions of the final distribution of the flood with a clear benefit in the computation time compared to hydrodynamic models b planar models these methods obtain the extent of the flood from the intersection of a series of horizontal planes at fine intervals with a high resolution dem and instantly relate the volume of the water to the extent of the flood teng et al 2015 the most used model of this family is the height above the nearest drainage hand proposed by nobre et al 2011 which in recent years has achieved a good level of acceptance i e li et al 2020 santos et al 2021 tewari et al 2021 c cellular automata based models ca the cellular automata techniques correspond to mathematical and computational models for a dynamic system that evolves in discrete steps characterized by local interaction between their elements it is suitable for modelling natural systems that can be described as a massive collection of simple functions that interact locally in this case simple rules are used to promote the transport of water from one cell to another it also allows the application of parallelization for a further reduction in computing time a standard cellular automaton consists of a regular mesh of cells each of which is in a finite number of states at each step of modelling the states of the cells are updated using an identical set of transition rules for each cell the update only implies the previous state of the cell and its neighbours it is common the assumption of the von neumann neighbourhood where the water can flow from the central cell to the four cardinal directions liu and pender 2013 liu et al 2015 the wca2d model proposed by guidolin et al 2016 employed simple transition rules and a weight based system instead of complex shallow water equations the ca ffé model developed by jamali et al 2019 combines the most attractive attributes of ca based flood models and rfms to predict urban flood inundations eliminating all the pre processing and post processing related to the impact zones although the existence of several conceptual models which have already been tested their diffusion commercialization and support is very limited this type of models has not yet achieved a high level of acceptance around the world due to the lack of confidence in them restricting their application in tools of flood risk assessment and management which are very useful to decision makers this is why it is necessary to continue contributing from the developing of new models to be adapted to different needs in risk management up to the application and divulgation of their use the main objective of this work is to develop a new own flood model allowing the adaptation of inputs outputs and processes to different types of requirements in risk applications which is very difficult to do with most of the existing flood models some of this existing probabilistic risk systems used by the insurance sector in mexico e g r plus rs mex rhmex sern the r fonden used by mexican government world bank 2012 and the capra platform ern 2010 cardona et al 2012 used by the initiative of world bank in latin america and some regions in asia this paper describes the development of a simplified conceptual flood model in order to be implemented as base of probabilistic flood risk applications where a great number of flood scenarios over large areas regional scale are needed in the computation of losses focusing on the estimation of flood depth and flood extent to verify the quality and level of approximation of the results obtained for different conditions an evaluation is carried out comparing them with other existing models besides the 2d software hec ras and iber were used to evaluate quantitatively the efficiency of the model 2 proposed model the proposed model is based on the main concepts of ca approaches applied to the cells from a regular grid firstly an initial state is assigned to each cell then an update process of the state of each cell is computed according to simple rules that determines the new state in terms of its current state and the states of the cells in its neighbourhood dottori and todini 2011 ghimire et al 2013 2 1 states the approach is based on a top down evaluation of the water flow through the cells in a step by step process using a set of states according to the conditions with their neighbours and the water flow according to the conditions in a moore neighbourhood c e n t r a l e i g h t n e i g h b o u r s the cells are classified in one of the following four possible states 1 inactive a cell is considered in this state when it does not contain a volume of water to be transferred this state changes if the cell receives volume from any of its neighbouring cells 2 transport this state is defined when the flow cannot be accumulated in the cell having the conditions e g water height slope roughness etc to move downstream to any of the eight neighbouring cells 3 flood area a cell or group of cells without the capacity of transporting water to the neighbouring cells the cells identified as flood area have the capacity to accumulate a certain volume of water according with the conditions of their neighbours 4 edge the edge cells are those surrounding the flood area the edge cells are used to estimate the storage capacity of the flood area to determine the extent of the flood and to locate the exit where the surplus volume can flow through the state classification is a dynamic process cell by cell and considers the condition of the accumulated flow at the analysed position a cell initially considered in a transport state could change posteriorly to a flood area for example if the process of flood accumulation reached again from downstream these states are conceptually very similar to some of the criteria commonly used in rfsm models to classify for example the impact areas and the communication points between them however in rfsm models these classifications and their main characteristics are pre processed independently of the flow scenario differing from the cell by cell analysis used in ca approaches and in this study 2 2 rules according to the state defined for a cell in the step by step process it will be subject to the following rules 1 rule 1 do nothing the inactive cells will not be included in the top down analysis therefore when the process detects an inactive cell this one will be ignored and the analysis will pass to the next one in the sorted array 2 rule 2 transference of volume a transport cell will transfer downstream the volume of water contained in it among the cells in a moore neighbourhood according to the process of transport volume the neighbouring cells which receives water from the centre will be classified automatically as transport cells a transport cell will change its state to flood area when it does not have the capacity to transfer water due to the elevation of its neighbours upslope or flat neighbours 3 rule 3 filling floodplains the flood area cells will store the input volume of water following the process of fill floodplain the maximum storage capacity will be a function of the lowest elevation of edge cells and the surface of the flood area once the flood area is filled up all the cells from within will be considered with the same elevation of the water surface plane surface every time some amount of water is accumulated in the flood area this volume is subtracted from the objective input volume and the general process continues with the remnant if the storage capacity of the flood area is equal or higher than the objective volume then the elevation of the water surface will be computed and the process of fill floodplain will end otherwise the elevation of the water surface will be fill up to the minimum elevation of the surrounding edge cells the surplus volume is considered as the new objective volume the lowest edge cells are classified as new transport cells and the initial sorted array is updated posteriorly the analysis will pass to the next cell in the updated sorted array 4 rule 4 union of waterbodies two or more flood areas connected will be considered as one flood area and their surface will be summed to estimate the new storage capacity once the joint is performed the identification of the new edge cells must be done 2 3 general process the main steps of the proposed model are shown in fig 1 the model requires as input data regular grids with the spatial distribution over the study area of the following three parameters 1 digital elevation model dem 2 manning s roughness coefficient and 3 input volume of water the first step of the algorithm consists in ordering the cells from highest to lowest elevation and including them in an initial array to facilitate the top down analysis following the direction of the water flow from upstream this allows the accumulation of the water volume reaches the lower areas adequately the sorting process is computed considering the elevation of the water surface obtained as the sum of the terrain elevation from the dem plus the water height in the cell from the input grid of volumes of water h e i g h t v o l u m e a r e a after sorting the cells the process of analysis cell by cell begins identifying the cells with and without an input volume all the cells without any volume of water are classified as inactive which allows starting the top down process exclusively from the cells with input flow 2 3 1 process of transport volume the cells with input volume of water are classified initially in transport state in the process of transport volume rule 2 the water in a cell is distributed to a moore neighbourhood according to their characteristics of roughness slope and equivalent water height for this a transport factor f t i is proposed see fig 2 considering that the amount of volume transported outside the cell be proportional to the downstream flow q i calculated with the manning equation in each i direction considering the main hydraulic characteristics of the nearby environment as it can be seen in equations of fig 2 being f t i a normalization in terms of the total downstream flow ensures that no more water be distributed than the existing one mass conservation the transference downstream of the volume is illustrated in fig 3 the process of transport volume rule 2 ends when it reaches a cell without the capacity of transporting water to the neighbouring cells in other words when the estimation of the volume propagated in all directions through the equations in fig 2 is equal to zero in this case the cell is identified as a flood area and the process of fill floodplain rule 3 is initialized 2 3 2 process of fill floodplain the process of fill floodplain rule 3 begins to estimate the extent and the elevation of the water surface that the transferred volume of water will generate this process see fig 4 distributes the objective volume and expands the area of the floodplain according to the runoff volume available in the zone as a first step the process of fill floodplain determines the boundaries of the flood area identifying the edge cells fig 5 the total storage capacity of water in the flood area will be computed as the product of the minimum elevation of the surrounding edge cells and the surface extent of the flood area the edge cells with a total elevation equal to the flood area i e flat areas will be classified as flood area and the new edge cells will be identified fig 5 when multiple neighbouring cells are classified as flood areas all of them are considered as a consolidated floodplain especially in terms of area and storage capacity fig 6 if the storage capacity of the flood area is equal or higher than the objective volume then the elevation of the water surface will be computed and the process of fill floodplain will end posteriorly the analysis will pass to the next cell in the initial sorted array the computation of the elevation of the water surface is estimated directly using the surface of the flood area cells the elevation of the lowest edge cell and the elevation of the bottom i e elevation of water surface previously computed or elevation of terrain in dry cells as it is shown in fig 7 as it is a non iterative numerical process volume losses due to instability or other numerical factors are not relevant following the principle of conservation of mass if the objective volume is greater than the storage capacity of the flood area then the flood area cells will be fill up to the minimum elevation of the surrounding edge cells the surplus volume is considered as the new objective volume the lower edge cells are classified as new transport cells the initial sorted array is updated and the process of fill floodplain ends posteriorly the analysis will pass to the next cell in the updated sorted array fig 8 every time some amount of water is accumulated in the flood area this volume is subtracted from the objective volume in the area and the general process continues with the remnant if during the process encounters other waterbodies then it proceeds to join rule 4 the corresponding cells and integrate them into a single floodplain to continue with the steps fig 9 2 4 estimation of flood depth the process of calculating the flood depth is carried out at the end of each runoff scenario when the last floodplain is filled and it is determined that there is no more volume of water to transport for this a distinction is made between cells classified as flood areas that are part of waterbodies and those outside these areas without storage capacity where runoff occurred transport cells the process for estimating flood depths in both situations is described below a flood areas waterbodies in flooded areas the depth of each cell is simply computed as the difference between the elevations of the water surface and the terrain as is shown illustratively in fig 10 b cells without storage capacity transport cells due to the way the flood volume is transferred from upstream to downstream it is necessary to determine a way to obtain depths close to those obtained by step by step hydrodynamic models in areas outside the flooded areas for this it is considered that the greatest depth that can occur under runoff conditions is the critical depth y c similar to that applied in guidolin et al 2016 the critical depth is estimated from equating manning s and froude s equations see eq 4 from this the value of f r 1 froude s number is considered which determines the conditions of the critical depth from there the solution of the critical depth is shown in eq 5 4 g y c 1 2 1 n y c 2 3 s 5 y c g 3 n 6 s 3 where y c is the critical depth in meters s is the slope between cells g is the gravitational acceleration and n is the manning s roughness coefficient the computation of critical depths is carried out in those neighbouring directions with slope prone to the outflow from the cell finally the flood depth used is obtained from the average of the critical depths estimated in all directions 3 validation tests and results to verify the quality and level of approximation of the results computed through the proposed approach in different flow conditions an evaluation is carried out using the benchmark study shown in neelz and pender 2013 they carried out a compendium of tests and results from different flood models in common use 2d 3d and other simplified models table 1 each of the different tests used have particular objectives of evaluation considering different conditions that affect the behavior of the flow in the models in this sense the results obtained from the proposed model are compared with the benchmark obtained by neelz and pender 2013 in each test some locations are chosen in order to evaluate the performance of the model in specific conditions these conditions include points near to the volume inputs where accumulation and velocity of the flow can be important in areas with shallow flow where inertial effects can become very relevant in areas with abrupt changes of terrain that can cause important variations in velocity in zones of final flow accumulation originally the variables to verify include water depth flow velocity extension of the flood area and arrival times however because of the characteristics of the proposed model in this paper only the flood depth and the extension of the flood area are compared the access to all the software used in the original benchmark study was not available to reproduce their results and compare more metrics with all the models therefore in a first stage the results of water depth of the proposed model were compared directly to the charts published as a reference of the behaviour of the model in a second stage the tests were modelled in 2d following the same conditions described by neelz and pender using two free access softwares hec ras usace 2021 and iber bladé et al 2014 both models are commonly used and are well known by the global community the use of this results allowed a more rigorous evaluation of the reliability and predictability of the proposed model the statistics used to evaluate the performance of the proposed model are described in table 2 where h i t s is the number of pixels flooded by the proposed model and the comparison model f a l s e a l a r m is the number of pixels flooded by the proposed model and not by the comparison model m i s s e s is the number of pixels not flooded by the proposed model and not by the comparison model n o e v e n t s is the number of pixels not flooded by the proposed model and by the comparison model y p is the depth of the proposed model in meters y c is the depth of the comparison model in meters in the following it is a brief description of two of the tests carried out and their respective results 3 1 test 1 this test corresponding to test 5 in neelz and pender 2013 is designed to simulate the downstream propagation through a river after a dam failure see fig 11 the input volume is 9 450 000 m3 introduced by the southwestern part of the dem see fig 12 the objective of this test is to evaluate the capacity of this model to simulate floods from the introduction of a high volume of water due to a dam failure it is expected to observe the upstream behavior near the dam failure where the flow velocity can be significant in the middle of the channel where the inertial behavior of the water is no longer relevant and downstream of the channel where the largest amount of volume will accumulate at the end in fig 13 the water levels in some of the reference points considered are shown as it is a simplified model that does not evaluate the flow through time it loses the capacity to represent the maximum results product of the wave propagation in addition for points 6 and 7 located on the banks of the river the water does not arrive due to the simplification of the dynamic behaviour of the passage of water over these areas this is coherent with the limitation of the conceptual models of not being reliable in analyses where the inertial components play an important role in the calculations although the model reaches the final water levels it does not have the ability to reproduce the effect of the wave propagation of the flow which could be very important in a dam rupture the results of the statistics to evaluate the predictability and reliability of the proposed model versus the hec ras and iber are shown in table 3 in this analysis the flooded cells are defined considering two limit depths of the water 0 1 m and 0 05 m which are commonly used for the definition of flooded areas that can cause damage in flood risk assessment the cells with depth of water lesser than the limits are considered as dry cells the comparison between the model and hec ras shows a very high agreement in detection and volumetric results see table 3 of the final flood print for both of the limit depths taking into account flood depths greater than 0 1 m the results are r h values of 94 7 f a r of 1 38 and p e c of 98 49 the r m s e is 0 085 m and the n s e coefficient is 0 994 in general the i f s and the b i a s indicate that both in area and volume the model underestimates very low the obtained flood print about 3 975 in area and 7 1 in volume the results of the comparison with iber could be appreciated as less convincing than those with hec ras however they can be considered as very acceptable in terms of detection and volumetric results for flood depths greater than 0 1 m r h values of 86 81 f a r of 0 and p e c of 96 65 the r m s e is 0 13 m and the n s e coefficient is 0 987 in this case the moderate low value in r h represents the number of cells flooded by iber that the model fails to flood in the contour lines of the flood prints from the three models shown in fig 14 differences can be noted for example at point 7 where the model does not register the accumulation of water 3 2 test 2 this test corresponds to test 8 a in neelz and pender 2013 and consists of an urban layout of 400 m by 960 m as it is shown in fig 15 a homogeneous rain is introduced over the entire system equivalent to a volume of 7800 m3 in addition an input of water is considered through a sewer that generates an inlet of 4300 m3 located in the upper right corner a total volume of 12 100 m3 is introduced to the system the main objective of the test is to check the capacity of the model on a high resolution dem 5 m 5 m the points to highlight in this test are points of downstream accumulation where the inertial component of the water does not take great relevance and where an important part of the water volume is going to accumulate point 1 and point 3 in fig 15 the flood depth at the end of computation is shown in fig 16 fig 17 shows the water levels obtained on some of the points compared to the models in the benchmarking study the results obtained are very close in the reference points the comparison between the proposed model and hec ras table 4 very acceptable results were obtained for depths greater than 0 1 m r h values of 95 18 f a r of 11 463 and p e c of 98 685 the r m s e is 0 012 m and the n s e coefficient is 0 988 the i f s shows that the model overestimates the flooded area in 7 5 the b i a s indicates a volumetric underestimation of 2 2 in the case of the comparison with iber table 4 also very acceptable results were obtained for depths greater than 0 1 m h r values of 94 75 f a r of 7 32 and p e c of 98 97 the r m s e is 0 018 m and the n s e coefficient is 0 973 the model overestimates the flooded area by 2 and 0 01 in volume however these values are into an optimal range in fig 18 the contours of the flood prints obtained with the proposed model hec ras and iber are shown considering a minimum flood depth of 0 1 m as it can be seen the flood prints are very similar in the three models as it was mentioned the main objective of the development of the conceptual model is to solve flood scenarios on a regional scale as quickly as possible as shown in table 5 which shows the efficiency of the model at the time of resolution in comparison with two dimensional models where the proposed model solves both tests in the order of 1 s the tests were performed on a computer with the following characteristics windows 8 1 pro operating system core i7 4 1 ghz 8 core processor ram 16 gb 4 conclusions in probabilistic risk assessment the computation of flood scenarios using common hydrodynamic models usually requires a large amount of time and computational resources to estimate the adverse consequences of the floods especially when dealing with analysis of large areas or simulation of a great number of scenarios the model proposed in this paper is developed in order to have a tool that provides flood scenarios with a low computational cost that allows to work with large regions and the simulation of a great number of scenarios these results can be incorporated in risk assessment tools and applications for government officials in economic and financial planning institutions civil protection and other authorities to improve the decision making process and contribute to the effectiveness of risk management due to flood hazard this model shows acceptable results both in high and low complexity areas subject to the own limitations of the model considering the flood depth and extent as the main parameters of interest with much shorter computational times practically instantly compared with more complex models which run in order of many minutes per scenario on the other hand the results obtained in the efficiency tests from the measurement of performance indices showed that the proposed model obtains approximate results in magnitude water depth and spatial extent flooded area in both tests for water levels above 0 05 m and 0 1 m the model showed good performance index values which allows us to increase confidence that the conceptual model established has sufficient capabilities for the simulation of scenarios where the dynamic component may not be as relevant since the model is not solved dynamically it is not possible to know the time in which the runoff reaches a location or the intermediate values of the process as observed in the benchmarking however the flood depths computed are very close to those obtained through other simplified models and the final level obtained by means of hydrodynamic models this type of model do not substitute other more complex models which solve the physically based flow equations in 1d 2d or 3d in applications where the hydrodynamic behaviour of the flow should be represented in detail in future research it will be desired to improve the model to increase the approximation in cases where the dynamic component be important and implement the flow velocity calculation so the results can better represent the flood declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the second author s work was carried out during his internship as undergraduate student at the engineering institute of unam the authors acknowledge the kind help of dr josé antonio gonzález vázquez of the universidad autónoma metropolitana in providing the data to perform the tests 
25525,this paper describes a simplified flood model based on cellular automata in order to be implemented in applications which require the simulation of a great number of flood scenarios at regional scale the model is based on a top down evaluation of the flow process through the cells of the dem according to the conditions in a moore neighbourhood the cells are classified in a dynamic process in four possible states with its own rules to verify the quality of the results an evaluation is carried out using the benchmarking tests and results shown in neelz and pender 2013 besides the 2d models hec ras and iber were used to evaluate quantitatively the efficiency of the model in terms of water depth and flood extent from this it is observed that the model produces very acceptable results especially where dynamic effects are less significant keywords conceptual flood model cellular automata flood hazard flood risk data availability the authors do not have permission to share data 1 introduction floods are recurrent events in many countries with social and economic consequences and even catastrophic potential when produced in extreme scenarios they have an important impact on public finances forcing governments to use funds that originally were established for other purposes to deal with the emergency and restore the status quo ante for years the global strategies against floods were oriented to protection and mitigation however experience has proved that floods are almost impossible to eradicate so strategies have been re oriented to flood risk management where negative consequences must be considered mostert and junier 2009 as flooding might continue to affect communities despite the best flood risk engineering practices it is important to plan for an adequate management of the emergency and a quick recovery this includes planning for the right human and financial resources to be available the main aim of risk assessment is to estimate the probability of adverse consequences for established time intervals due to the occurrence of natural hazards integrating in a rational way the uncertainties related to each part of the process plate 2002 merz and thieken 2004 council of european union 2007 unisdr 2009 world bank et al 2012a torres et al 2014 the availability of historical information on catastrophic flood events is very limited and data on the economic consequences is still scarcer considering the possibility of highly destructive events in the future risk assessment has to focus on probabilistic models that use available information to best predict future scenarios and consider the spatial and temporal uncertainties involved in the analysis process melchers 1999 merz et al 2004 lane et al 2011 torres et al 2014 1 1 probabilistic flood risk assessment the probabilistic risk assessment consists of evaluating the consequences i e economic losses in the exposed group of assets due to the occurrence of each flood scenario which collectively describe the flood hazard and then integrating the results in risk indexes for a realistic and structured flood risk analysis it is necessary to estimate the relationship between the amount of foreseen damage vulnerability in an inventory of assets exposure and the occurrence probability of the flood hazard the risk due to natural hazards is commonly expressed in terms of the expected loss e β and the loss exceedance rate ν β which specifies the frequency usually annual of the occurrence of the losses esteva 1967 1 e β i 1 e v e n t e β h i f a event i 2 ν β i 1 e v e n t pr b β event i f a event i 3 pr b β event i h pr b β h f h event i d h where pr b β event i is the probability that the loss be larger than β since the i t h event occurred and f a event i is the annual frequency of occurrence of the i t h event pr b β h is the exceedance probability of the loss value β since the local intensity is h and f h event i is the probability density of the intensity conditioned to the occurrence of the i t h event this term takes into account the fact that once an event has occurred the intensity at the site of interest is uncertain e g water depth flow velocity energy head among others for these purposes it is necessary to compile data from two different aspects the flood hazard at the site intensity and frequency and the vulnerability of the exposed asset it is standard international practice to estimate the vulnerability through vulnerability damage functions which represent the relationship between the expected damage loss and the intensity of the flood according to the main characteristics of the evaluated asset i e cost material use number of levels type of contents among others these vulnerability damage functions have commonly considered that direct losses are mainly related to the flood depth e g smith 1994 merz and thieken 2004 green et al 2011 jongman et al 2012 torres et al 2014 hammond et al 2015 velasco et al 2016 frongia et al 2017 nguyen et al 2017 komolafe et al 2019 martínez gomariz et al 2020 romali and yusop 2021 this assumption might be due to limited information about other parameters characterising the flood however kreibich et al 2009 investigated the influence of other flood parameters as flow velocity and head energy on the structural damage and monetary flood loss of buildings and road infrastructure concluding that the influence of velocity was only significant on structural damage to road infrastructure even it has been recognized that vulnerability damage functions have several sources of uncertainty in the flood parameters and in the potential damage in assets and should be treated as random variables torres et al 2014 hammond et al 2015 in this study the principal flood characteristics of interest for risk assessment purposes are the flood depth and extent the probabilistic risk assessment requires a great amount of flood scenarios and or simulations to reach a high level of robustness in the hazard assessment these flood scenarios are generally obtained from two main sources to allow the estimation of the consequences a historic flood events by means of historic records in situ or more recently analysis of remote sense data e g gómez palacios et al 2016 and b numerical flood models which use engineering basis in their development since the availability of historical records that describe adequately the spatial extent and distribution of the flood intensity i e water depth and velocity is still not enough to fulfil the requirements of risk assessment the feasibility of the process depends enormously on numerical flood models which must be efficient and with a reasonable cost of time and resources the hydrodynamic models are a good alternative to generate flood scenarios at high spatial and temporal resolution considering different levels of complexity due to its ability to solve the equations that define the flow physical properties and behaviour however the computational costs especially of 2 d and 3d models for large floodplains are extremely high besides the requirements of detailed data about spatial distribution of the input parameter and for model calibration which are usually not available for large floodplains and regional studies teng et al 2015 scorzini et al 2018 these aspects limit the application of hydrodynamic models to studies where the availability of input data the level of complexity and the computational costs allow their implementation 1 2 conceptual flood models in the last years it has become more acceptable the use of simplified conceptual models with a lower level of detail as a reasonable alternative to generate rapidly flood scenarios in large scale this type of model does not solve the physically based flow equations and are based on simplified hydraulic assumptions and considerations on the characteristics of the terrain teng et al 2015 2017 scorzini et al 2018 conceptual flood models can be used predictively but does not fit the full description of a hydrodynamic model these type of models are sometimes classified as 0d models in a wrong way since most of them show the 2d representation of the flood pender 2006 they are also considered as 0 term models in contrast to full term models that solve shallow water equations in 2d by omitting one or two acceleration terms neelz and pender 2013 these models require a lower computational cost compared to hydrodynamic models they are fast and robust more desirable for applications that do not require velocity outputs and have low demands on the representation and accuracy of flow dynamics teng et al 2017 the execution time savings of this type of model is suitable for large floodplains and for probabilistic risk assessment which requires a large number of simulations when there are clear flow paths through the floodplain these models produce predictions of flood extent volume and water depth that are well comparable to 2d shallow water equation models however comparisons differ for topographies of high complexity especially in areas where the conservation of moment is important such as predictions of water levels and velocities in a complex floodplain near a dam failure and when the spreading flood encounters an adverse slope in the floodplain these limitations restrict the application of simplified conceptual models to applications where dynamic effects are less significant in the estimation of the water flow teng et al 2017 a first classification of conceptual models was proposed by teng et al 2017 into the following three main groups a rfsm models the rfsm rapid flood spreading method lhomme et al 2008 which pre process the topography classifying ground depressions into flood areas and then distribute the flood volume to fill those areas in general the rfsm models perform the following pre process to estimate the flood propagation through the impact zones delimitation of impact zones relationships area volume for each impact zone list of adjacent impact zones and identification of points of communication between impact zones location and elevation this type of model can produce approximate predictions of the final distribution of the flood with a clear benefit in the computation time compared to hydrodynamic models b planar models these methods obtain the extent of the flood from the intersection of a series of horizontal planes at fine intervals with a high resolution dem and instantly relate the volume of the water to the extent of the flood teng et al 2015 the most used model of this family is the height above the nearest drainage hand proposed by nobre et al 2011 which in recent years has achieved a good level of acceptance i e li et al 2020 santos et al 2021 tewari et al 2021 c cellular automata based models ca the cellular automata techniques correspond to mathematical and computational models for a dynamic system that evolves in discrete steps characterized by local interaction between their elements it is suitable for modelling natural systems that can be described as a massive collection of simple functions that interact locally in this case simple rules are used to promote the transport of water from one cell to another it also allows the application of parallelization for a further reduction in computing time a standard cellular automaton consists of a regular mesh of cells each of which is in a finite number of states at each step of modelling the states of the cells are updated using an identical set of transition rules for each cell the update only implies the previous state of the cell and its neighbours it is common the assumption of the von neumann neighbourhood where the water can flow from the central cell to the four cardinal directions liu and pender 2013 liu et al 2015 the wca2d model proposed by guidolin et al 2016 employed simple transition rules and a weight based system instead of complex shallow water equations the ca ffé model developed by jamali et al 2019 combines the most attractive attributes of ca based flood models and rfms to predict urban flood inundations eliminating all the pre processing and post processing related to the impact zones although the existence of several conceptual models which have already been tested their diffusion commercialization and support is very limited this type of models has not yet achieved a high level of acceptance around the world due to the lack of confidence in them restricting their application in tools of flood risk assessment and management which are very useful to decision makers this is why it is necessary to continue contributing from the developing of new models to be adapted to different needs in risk management up to the application and divulgation of their use the main objective of this work is to develop a new own flood model allowing the adaptation of inputs outputs and processes to different types of requirements in risk applications which is very difficult to do with most of the existing flood models some of this existing probabilistic risk systems used by the insurance sector in mexico e g r plus rs mex rhmex sern the r fonden used by mexican government world bank 2012 and the capra platform ern 2010 cardona et al 2012 used by the initiative of world bank in latin america and some regions in asia this paper describes the development of a simplified conceptual flood model in order to be implemented as base of probabilistic flood risk applications where a great number of flood scenarios over large areas regional scale are needed in the computation of losses focusing on the estimation of flood depth and flood extent to verify the quality and level of approximation of the results obtained for different conditions an evaluation is carried out comparing them with other existing models besides the 2d software hec ras and iber were used to evaluate quantitatively the efficiency of the model 2 proposed model the proposed model is based on the main concepts of ca approaches applied to the cells from a regular grid firstly an initial state is assigned to each cell then an update process of the state of each cell is computed according to simple rules that determines the new state in terms of its current state and the states of the cells in its neighbourhood dottori and todini 2011 ghimire et al 2013 2 1 states the approach is based on a top down evaluation of the water flow through the cells in a step by step process using a set of states according to the conditions with their neighbours and the water flow according to the conditions in a moore neighbourhood c e n t r a l e i g h t n e i g h b o u r s the cells are classified in one of the following four possible states 1 inactive a cell is considered in this state when it does not contain a volume of water to be transferred this state changes if the cell receives volume from any of its neighbouring cells 2 transport this state is defined when the flow cannot be accumulated in the cell having the conditions e g water height slope roughness etc to move downstream to any of the eight neighbouring cells 3 flood area a cell or group of cells without the capacity of transporting water to the neighbouring cells the cells identified as flood area have the capacity to accumulate a certain volume of water according with the conditions of their neighbours 4 edge the edge cells are those surrounding the flood area the edge cells are used to estimate the storage capacity of the flood area to determine the extent of the flood and to locate the exit where the surplus volume can flow through the state classification is a dynamic process cell by cell and considers the condition of the accumulated flow at the analysed position a cell initially considered in a transport state could change posteriorly to a flood area for example if the process of flood accumulation reached again from downstream these states are conceptually very similar to some of the criteria commonly used in rfsm models to classify for example the impact areas and the communication points between them however in rfsm models these classifications and their main characteristics are pre processed independently of the flow scenario differing from the cell by cell analysis used in ca approaches and in this study 2 2 rules according to the state defined for a cell in the step by step process it will be subject to the following rules 1 rule 1 do nothing the inactive cells will not be included in the top down analysis therefore when the process detects an inactive cell this one will be ignored and the analysis will pass to the next one in the sorted array 2 rule 2 transference of volume a transport cell will transfer downstream the volume of water contained in it among the cells in a moore neighbourhood according to the process of transport volume the neighbouring cells which receives water from the centre will be classified automatically as transport cells a transport cell will change its state to flood area when it does not have the capacity to transfer water due to the elevation of its neighbours upslope or flat neighbours 3 rule 3 filling floodplains the flood area cells will store the input volume of water following the process of fill floodplain the maximum storage capacity will be a function of the lowest elevation of edge cells and the surface of the flood area once the flood area is filled up all the cells from within will be considered with the same elevation of the water surface plane surface every time some amount of water is accumulated in the flood area this volume is subtracted from the objective input volume and the general process continues with the remnant if the storage capacity of the flood area is equal or higher than the objective volume then the elevation of the water surface will be computed and the process of fill floodplain will end otherwise the elevation of the water surface will be fill up to the minimum elevation of the surrounding edge cells the surplus volume is considered as the new objective volume the lowest edge cells are classified as new transport cells and the initial sorted array is updated posteriorly the analysis will pass to the next cell in the updated sorted array 4 rule 4 union of waterbodies two or more flood areas connected will be considered as one flood area and their surface will be summed to estimate the new storage capacity once the joint is performed the identification of the new edge cells must be done 2 3 general process the main steps of the proposed model are shown in fig 1 the model requires as input data regular grids with the spatial distribution over the study area of the following three parameters 1 digital elevation model dem 2 manning s roughness coefficient and 3 input volume of water the first step of the algorithm consists in ordering the cells from highest to lowest elevation and including them in an initial array to facilitate the top down analysis following the direction of the water flow from upstream this allows the accumulation of the water volume reaches the lower areas adequately the sorting process is computed considering the elevation of the water surface obtained as the sum of the terrain elevation from the dem plus the water height in the cell from the input grid of volumes of water h e i g h t v o l u m e a r e a after sorting the cells the process of analysis cell by cell begins identifying the cells with and without an input volume all the cells without any volume of water are classified as inactive which allows starting the top down process exclusively from the cells with input flow 2 3 1 process of transport volume the cells with input volume of water are classified initially in transport state in the process of transport volume rule 2 the water in a cell is distributed to a moore neighbourhood according to their characteristics of roughness slope and equivalent water height for this a transport factor f t i is proposed see fig 2 considering that the amount of volume transported outside the cell be proportional to the downstream flow q i calculated with the manning equation in each i direction considering the main hydraulic characteristics of the nearby environment as it can be seen in equations of fig 2 being f t i a normalization in terms of the total downstream flow ensures that no more water be distributed than the existing one mass conservation the transference downstream of the volume is illustrated in fig 3 the process of transport volume rule 2 ends when it reaches a cell without the capacity of transporting water to the neighbouring cells in other words when the estimation of the volume propagated in all directions through the equations in fig 2 is equal to zero in this case the cell is identified as a flood area and the process of fill floodplain rule 3 is initialized 2 3 2 process of fill floodplain the process of fill floodplain rule 3 begins to estimate the extent and the elevation of the water surface that the transferred volume of water will generate this process see fig 4 distributes the objective volume and expands the area of the floodplain according to the runoff volume available in the zone as a first step the process of fill floodplain determines the boundaries of the flood area identifying the edge cells fig 5 the total storage capacity of water in the flood area will be computed as the product of the minimum elevation of the surrounding edge cells and the surface extent of the flood area the edge cells with a total elevation equal to the flood area i e flat areas will be classified as flood area and the new edge cells will be identified fig 5 when multiple neighbouring cells are classified as flood areas all of them are considered as a consolidated floodplain especially in terms of area and storage capacity fig 6 if the storage capacity of the flood area is equal or higher than the objective volume then the elevation of the water surface will be computed and the process of fill floodplain will end posteriorly the analysis will pass to the next cell in the initial sorted array the computation of the elevation of the water surface is estimated directly using the surface of the flood area cells the elevation of the lowest edge cell and the elevation of the bottom i e elevation of water surface previously computed or elevation of terrain in dry cells as it is shown in fig 7 as it is a non iterative numerical process volume losses due to instability or other numerical factors are not relevant following the principle of conservation of mass if the objective volume is greater than the storage capacity of the flood area then the flood area cells will be fill up to the minimum elevation of the surrounding edge cells the surplus volume is considered as the new objective volume the lower edge cells are classified as new transport cells the initial sorted array is updated and the process of fill floodplain ends posteriorly the analysis will pass to the next cell in the updated sorted array fig 8 every time some amount of water is accumulated in the flood area this volume is subtracted from the objective volume in the area and the general process continues with the remnant if during the process encounters other waterbodies then it proceeds to join rule 4 the corresponding cells and integrate them into a single floodplain to continue with the steps fig 9 2 4 estimation of flood depth the process of calculating the flood depth is carried out at the end of each runoff scenario when the last floodplain is filled and it is determined that there is no more volume of water to transport for this a distinction is made between cells classified as flood areas that are part of waterbodies and those outside these areas without storage capacity where runoff occurred transport cells the process for estimating flood depths in both situations is described below a flood areas waterbodies in flooded areas the depth of each cell is simply computed as the difference between the elevations of the water surface and the terrain as is shown illustratively in fig 10 b cells without storage capacity transport cells due to the way the flood volume is transferred from upstream to downstream it is necessary to determine a way to obtain depths close to those obtained by step by step hydrodynamic models in areas outside the flooded areas for this it is considered that the greatest depth that can occur under runoff conditions is the critical depth y c similar to that applied in guidolin et al 2016 the critical depth is estimated from equating manning s and froude s equations see eq 4 from this the value of f r 1 froude s number is considered which determines the conditions of the critical depth from there the solution of the critical depth is shown in eq 5 4 g y c 1 2 1 n y c 2 3 s 5 y c g 3 n 6 s 3 where y c is the critical depth in meters s is the slope between cells g is the gravitational acceleration and n is the manning s roughness coefficient the computation of critical depths is carried out in those neighbouring directions with slope prone to the outflow from the cell finally the flood depth used is obtained from the average of the critical depths estimated in all directions 3 validation tests and results to verify the quality and level of approximation of the results computed through the proposed approach in different flow conditions an evaluation is carried out using the benchmark study shown in neelz and pender 2013 they carried out a compendium of tests and results from different flood models in common use 2d 3d and other simplified models table 1 each of the different tests used have particular objectives of evaluation considering different conditions that affect the behavior of the flow in the models in this sense the results obtained from the proposed model are compared with the benchmark obtained by neelz and pender 2013 in each test some locations are chosen in order to evaluate the performance of the model in specific conditions these conditions include points near to the volume inputs where accumulation and velocity of the flow can be important in areas with shallow flow where inertial effects can become very relevant in areas with abrupt changes of terrain that can cause important variations in velocity in zones of final flow accumulation originally the variables to verify include water depth flow velocity extension of the flood area and arrival times however because of the characteristics of the proposed model in this paper only the flood depth and the extension of the flood area are compared the access to all the software used in the original benchmark study was not available to reproduce their results and compare more metrics with all the models therefore in a first stage the results of water depth of the proposed model were compared directly to the charts published as a reference of the behaviour of the model in a second stage the tests were modelled in 2d following the same conditions described by neelz and pender using two free access softwares hec ras usace 2021 and iber bladé et al 2014 both models are commonly used and are well known by the global community the use of this results allowed a more rigorous evaluation of the reliability and predictability of the proposed model the statistics used to evaluate the performance of the proposed model are described in table 2 where h i t s is the number of pixels flooded by the proposed model and the comparison model f a l s e a l a r m is the number of pixels flooded by the proposed model and not by the comparison model m i s s e s is the number of pixels not flooded by the proposed model and not by the comparison model n o e v e n t s is the number of pixels not flooded by the proposed model and by the comparison model y p is the depth of the proposed model in meters y c is the depth of the comparison model in meters in the following it is a brief description of two of the tests carried out and their respective results 3 1 test 1 this test corresponding to test 5 in neelz and pender 2013 is designed to simulate the downstream propagation through a river after a dam failure see fig 11 the input volume is 9 450 000 m3 introduced by the southwestern part of the dem see fig 12 the objective of this test is to evaluate the capacity of this model to simulate floods from the introduction of a high volume of water due to a dam failure it is expected to observe the upstream behavior near the dam failure where the flow velocity can be significant in the middle of the channel where the inertial behavior of the water is no longer relevant and downstream of the channel where the largest amount of volume will accumulate at the end in fig 13 the water levels in some of the reference points considered are shown as it is a simplified model that does not evaluate the flow through time it loses the capacity to represent the maximum results product of the wave propagation in addition for points 6 and 7 located on the banks of the river the water does not arrive due to the simplification of the dynamic behaviour of the passage of water over these areas this is coherent with the limitation of the conceptual models of not being reliable in analyses where the inertial components play an important role in the calculations although the model reaches the final water levels it does not have the ability to reproduce the effect of the wave propagation of the flow which could be very important in a dam rupture the results of the statistics to evaluate the predictability and reliability of the proposed model versus the hec ras and iber are shown in table 3 in this analysis the flooded cells are defined considering two limit depths of the water 0 1 m and 0 05 m which are commonly used for the definition of flooded areas that can cause damage in flood risk assessment the cells with depth of water lesser than the limits are considered as dry cells the comparison between the model and hec ras shows a very high agreement in detection and volumetric results see table 3 of the final flood print for both of the limit depths taking into account flood depths greater than 0 1 m the results are r h values of 94 7 f a r of 1 38 and p e c of 98 49 the r m s e is 0 085 m and the n s e coefficient is 0 994 in general the i f s and the b i a s indicate that both in area and volume the model underestimates very low the obtained flood print about 3 975 in area and 7 1 in volume the results of the comparison with iber could be appreciated as less convincing than those with hec ras however they can be considered as very acceptable in terms of detection and volumetric results for flood depths greater than 0 1 m r h values of 86 81 f a r of 0 and p e c of 96 65 the r m s e is 0 13 m and the n s e coefficient is 0 987 in this case the moderate low value in r h represents the number of cells flooded by iber that the model fails to flood in the contour lines of the flood prints from the three models shown in fig 14 differences can be noted for example at point 7 where the model does not register the accumulation of water 3 2 test 2 this test corresponds to test 8 a in neelz and pender 2013 and consists of an urban layout of 400 m by 960 m as it is shown in fig 15 a homogeneous rain is introduced over the entire system equivalent to a volume of 7800 m3 in addition an input of water is considered through a sewer that generates an inlet of 4300 m3 located in the upper right corner a total volume of 12 100 m3 is introduced to the system the main objective of the test is to check the capacity of the model on a high resolution dem 5 m 5 m the points to highlight in this test are points of downstream accumulation where the inertial component of the water does not take great relevance and where an important part of the water volume is going to accumulate point 1 and point 3 in fig 15 the flood depth at the end of computation is shown in fig 16 fig 17 shows the water levels obtained on some of the points compared to the models in the benchmarking study the results obtained are very close in the reference points the comparison between the proposed model and hec ras table 4 very acceptable results were obtained for depths greater than 0 1 m r h values of 95 18 f a r of 11 463 and p e c of 98 685 the r m s e is 0 012 m and the n s e coefficient is 0 988 the i f s shows that the model overestimates the flooded area in 7 5 the b i a s indicates a volumetric underestimation of 2 2 in the case of the comparison with iber table 4 also very acceptable results were obtained for depths greater than 0 1 m h r values of 94 75 f a r of 7 32 and p e c of 98 97 the r m s e is 0 018 m and the n s e coefficient is 0 973 the model overestimates the flooded area by 2 and 0 01 in volume however these values are into an optimal range in fig 18 the contours of the flood prints obtained with the proposed model hec ras and iber are shown considering a minimum flood depth of 0 1 m as it can be seen the flood prints are very similar in the three models as it was mentioned the main objective of the development of the conceptual model is to solve flood scenarios on a regional scale as quickly as possible as shown in table 5 which shows the efficiency of the model at the time of resolution in comparison with two dimensional models where the proposed model solves both tests in the order of 1 s the tests were performed on a computer with the following characteristics windows 8 1 pro operating system core i7 4 1 ghz 8 core processor ram 16 gb 4 conclusions in probabilistic risk assessment the computation of flood scenarios using common hydrodynamic models usually requires a large amount of time and computational resources to estimate the adverse consequences of the floods especially when dealing with analysis of large areas or simulation of a great number of scenarios the model proposed in this paper is developed in order to have a tool that provides flood scenarios with a low computational cost that allows to work with large regions and the simulation of a great number of scenarios these results can be incorporated in risk assessment tools and applications for government officials in economic and financial planning institutions civil protection and other authorities to improve the decision making process and contribute to the effectiveness of risk management due to flood hazard this model shows acceptable results both in high and low complexity areas subject to the own limitations of the model considering the flood depth and extent as the main parameters of interest with much shorter computational times practically instantly compared with more complex models which run in order of many minutes per scenario on the other hand the results obtained in the efficiency tests from the measurement of performance indices showed that the proposed model obtains approximate results in magnitude water depth and spatial extent flooded area in both tests for water levels above 0 05 m and 0 1 m the model showed good performance index values which allows us to increase confidence that the conceptual model established has sufficient capabilities for the simulation of scenarios where the dynamic component may not be as relevant since the model is not solved dynamically it is not possible to know the time in which the runoff reaches a location or the intermediate values of the process as observed in the benchmarking however the flood depths computed are very close to those obtained through other simplified models and the final level obtained by means of hydrodynamic models this type of model do not substitute other more complex models which solve the physically based flow equations in 1d 2d or 3d in applications where the hydrodynamic behaviour of the flow should be represented in detail in future research it will be desired to improve the model to increase the approximation in cases where the dynamic component be important and implement the flow velocity calculation so the results can better represent the flood declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the second author s work was carried out during his internship as undergraduate student at the engineering institute of unam the authors acknowledge the kind help of dr josé antonio gonzález vázquez of the universidad autónoma metropolitana in providing the data to perform the tests 
25526,we develop a regional hydrological model that applies to arid and semi arid regions by explicitly considering the effect of irrigation on the hydrological processes a new irrigation module is here integrated into the recently introduced atmospheric and hydrological modelling system ahms for the quantitative assessment of basin scale hydrological response to climate change and the impact of anthropogenic activities on water resources the land surface channel routing and groundwater modules of the ahms are extended here to incorporate the new module we then apply the model to simulating the hydrological processes in the yellow river basin an arid and semi arid region where irrigation constitutes the most important source of water use the model is calibrated and validated using in situ and remote sensing observations this study demonstrates the capability of the ahms for regional hydrological modelling in arid and semi arid basins where irrigation profoundly influences the water balance keywords hydrological modelling yellow river basin arid and semi arid areas irrigation model calibration validation data availability data will be made available on request 1 introduction atmospheric and hydrological models have been under intensive development in recent years as they provide a powerful tool for the assessment and prediction of regional hydrological processes and the investigation of the dynamic feedbacks between the atmosphere and continental hydrosphere gochis et al 2013 maxwell et al 2011 shrestha et al 2014 wagner et al 2016a such models have found diverse applications in studies on basin scale hydrological responses to climate change and anthropogenic activities maxwell et al 2007 wilby et al 1994 however hydrological simulation in arid and semi arid regions remains a formidable task because the reliable representations of the often low and heterogeneous rainfall intermittent river flow and impacts of human activities are particularly challenging pilgrim et al 1988 rafiei sardooi et al 2022 thus we focus here on the development of a hydrological model for arid and semi arid regions specifically the yellow river basin is selected as the research area owing to its unique hydrological characteristics and important position in china the yellow river is the second longest river in china 5464 km and the yellow river basin 795 000 km2 is the largest basin in north china the average water resources in the yellow river basin account for only 2 of the total water resources in china but the water from this basin feeds 12 of the chinese population however water shortage constitutes a serious problem given the increasing water demand in the area with continuing population growth and urban development in 1997 the downstream 704 km from the estuary dried up for more than 226 days cong et al 2009 the large irrigation districts in the yellow river basin are mainly located in arid and semi arid areas and irrigation has accounted for instance for more than 80 60 of the gross human water use in the period from 1956 to 2010 2001 2019 and rapidly increasing with time fig 1 for instance hetao region takes about 5 billion m3 water every year from the yellow river although industrial water use has been increasing since the early 2000s due to economic development irrigation still constitutes the most important source of water use in this area jia et al 2006 most previous studies about hydrological processes in the yellow river basin neglected explicit consideration of river water use in large scale irrigation districts e g cong et al 2009 yuan et al 2016 a water use module was introduced in the wep l distributed hydrological model by jia et al 2006 by taking the census irrigation data as input assess the water resources in the yellow river basin in the latter study irrigation water requirements in the model were estimated using statistical methods and data not physically based modelling yin et al 2021 extended the global land surface model orchidee organizing carbon and hydrology in dynamic ecosystems by including a model for irrigation crop and offline dam operation their model assumes that streams supply water to the crops within the grid cells they flow across only neglecting water transfer over long distances given the commonly used channels in the irrigation districts of arid and semi arid regions this neglect may lead to an underestimation of actual river irrigation volumes and affect the accuracy of hydrological simulations over large irrigated districts yin et al 2021 the main purpose of this article is to develop a hydrological model for long term large scale hydrological processes in arid and semi arid basins focusing on the yellow river basin our model development builds on the offline mode of the coupled atmospheric and hydrological modelling system ahms developed at the university of cologne jiang et al 2020 xia 2019 an example of the ahms applications to wet hydrological basins can be found in xia et al 2022 the use of river water and groundwater for irrigation in the yellow river basin is expected to profoundly impact the regional hydrological processes we thus extend the ahms to include river water and groundwater use processes to better simulate the streamflow and assess the water resources in the yellow river basin to this end the land surface channel routing and groundwater models of ahms are extended to account for river water and groundwater use in irrigation and to include a scheme for estimating irrigated water requirement as proposed by xu et al 2019 these new developments lead to improved ahms simulations by reducing the errors associated with the underestimation of evaporation and the overestimation of runoff in the yellow river basin we also show that the modelling of streamflow in the arid and semi arid regions of the yellow river basin also improves upon consideration of irrigation 2 method 2 1 introduction of the offline atmospheric and hydrological modelling system ahms the atmospheric and hydrological modelling system ahms is a fully coupled atmospheric and hydrological modelling system jiang et al 2020 xia 2019 xia et al 2022 specifically ahms couples the weather research and forecasting wrf modelling system skamarock and klemp 2008 with the physically based distributed regional hydrological model system hms yu et al 2006 through the noah multiparameterziation land surface model noah mp chen and dudhia 2001 niu et al 2011 furthermore the module in wrf hydro gochis et al 2013 is employed for downscaling and upscaling of variables between the grids of land surface model and hydrological model ahms can either be run online i e coupled with the full wrf model for atmospheric dynamics or offline which is the situation adopted in the present study by using prescribed near surface atmospheric forcing variables a schematic diagram identifying the main components of the online and offline ahms simulations is displayed in fig 2 as shown in this figure while the online ahms can be employed to study the dynamic feedback between the atmosphere surface and subsurface the offline ahms can be used to effectively calibrate and validate hydrological models different from the previous work of xia et al 2022 combined the land surface hydrological model with the global crop water model gcwm to study hydrological processes in the water rich areas of china this study aims to develop an irrigation model that applies to arid and semi arid regions to this end we extend ahms to incorporate and modify a dynamic irrigation scheme xu et al 2019 in noah mp allowing us to quantify the dynamic irrigation water requirements of dryland crops based on the soil moisture deficit method furthermore we incorporate the water uptake applicable to irrigation districts located in arid and semi arid regions into the channel routing model and groundwater model of hms specifically we develop a channel routing model that considers long distance water supply processes in irrigation areas characteristic of arid and semi arid regions such as those in the yellow river basin a summary of the main components of the offline ahms simulations applied in the present work is provided in the subsequent sections section 2 2 describes the hydrological models involved in the noah mp and hms section 2 3 presents the irrigation scheme in ahms fig 3 displays a schematic diagram of the hydrological cycle represented in ahms and discussed in the following sections 2 2 hydrological modelling in noah mp and hms the land surface model noah mp is a single column model that simulates the exchange of heat moisture and momentum between the land surface and the atmosphere the model provides a multi parameterization framework for application in various land surface schemes chen and dudhia 2001 niu et al 2011 furthermore noah mp has been modified to be consistent with the hms model and darcy s law boundary condition has been applied to simulate the moisture interactions between the unsaturated and saturated zones xia 2019 moreover the hydrological model system hms developed for mesoscale and large scale hydrological simulations by yu et al 2006 has been substantially improved in the framework of hydrological modelling xia 2019 hms is now applicable to simulate all main components involved in hydrological processes including surface water flow groundwater flow and the interaction flux between them specifically the hms model consists of three sub models a two dimensional channel routing model rt2d a two dimensional groundwater hydrological model gw2d and a groundwater and channel interaction model gci these modules compute streamflow groundwater flows from cell to cell and exchange with the stream respectively noah mp and hms consider four surface soil layers with a total depth of 2 m and a single groundwater layer the vertical movement of water in the surface soil is simulated by the richard equation see section 2 2 1 while the horizontal movement of groundwater is modelled using the boussinesq equation for unconfined conditions see section 2 2 2 the runoff rate is predicted based on the theory of infiltration excess runoff horton runoff see section s1 in the supplementary material and saturation excess runoff exchange water between surface soil and groundwater drainage river groundwater and river vadose zone subsurface flow are calculated according to darcy s law see section s2 in the supplementary material the flow routing is simulated by a diffusive wave model with the manning equation see section 2 2 3 which can be used in low relief areas and account for backwater effects additional details about surface energy balances and vegetation dynamics of noah mp are described in chen and dudhia 2001 and niu et al 2011 2 2 1 vertical movement of soil water the movement of soil water in the vertical direction is described by the richards equation pachepsky et al 2003 richards 1931 1 θ t z k ψ z z s z t where θ is the volumetric soil water content t is time s z is the height above the data in the soil column positive upward m k is the hydraulic conductivity m s 1 ψ is the soil matric potential m and s z t is the soil moisture sink term e g transpiration losses in the root zone to solve eq 1 the following top boundary condition is considered 2 q wat p t m e g r sf q irr where q wat denotes the water input on the soil surface p t is the throughfall precipitation m is the snow melt e g is the ground evaporation r sf is the surface runoff and q irr is the actual irrigated water including river irrigation and groundwater irrigation which in the present study is added to the soil surface furthermore we assume that the irrigation water is spread evenly and horizontally over the ground while the actual irrigation input value on the soil surface is calculated from eq 8 see section 2 3 2 2 2 2d single layer distributed groundwater model the dynamics of the horizontal movement of groundwater are described by the following partial differential boussinesq equation for unconfined conditions 3 s p h g t x t g h g x y t g h g y q net x y t where t g is the aquifer transmissivity m 2 s 1 s p is the storage coefficient porosity m 3 m 3 q net m s 1 denotes the net contribution of sink and source terms including the interaction flux between groundwater and unsaturated soil the exchange of water between rivers and groundwater and the extraction of groundwater from wells q irr gw 2 2 3 channel routing model river and lake levels are represented by the prognostic variable h r which represents the thickness of surface water averaged over the grid cell by combining the continuity of mass in the cell with the momentum equation for transport between cells the rate of change of h r can be written as a h r t x a c 1 n r h 2 3 h r x h r x 1 2 y a c 1 n r h 2 3 h r y h r y 1 2 4 r sf f w c g c u c l q irr sf x y t where a is the river bed area of water in the river or lake m2 a c is the cross sectional area of water in the river or lake at cell boundaries m2 n is manning s roughness coefficient s m 1 3 and r sf is the hydraulic radius m which is equivalent to w d 2 d w for an open channel flow through a rectangular cross section with w and d denoting the width and depth of the river m furthermore x and y denote the horizontal directions and the water flow term between neighbouring grid cells is computed by considering all eight directions on the plane including the diagonals specifically for every grid cell in the square lattice constituting the simulation domain eq 4 is solved by considering both nearest neighbouring cells in x and y directions as well as in the diagonals omitted from eq 4 for clarity in addition r sf is the surface runoff m 3 s 1 which encodes the infiltration excess runoff r ins and the saturation excess runoff r sat while f w is the wetted surface fraction which is set to 1 for lakes and to f b for running rivers with f b denoting the fractional area of the river bed computed according to the eq s9 in the supplementary material moreover c g c u and c l denote the values of water flux exchanged by the river with saturated soil unsaturated soil and lake respectively m 3 s 1 while q irr sf is equal to the irrigated water from surface water which has been added to the model in this study m 3 s 1 water supply from the streams to the crops is modelled based on irrigation water demand predicted by the dynamic irrigation scheme in noah mp and constrained by the amount of available water in the stream see section 2 3 eq 9 more precisely water is supplied to the crops located within the grid cells the streams flow across as well as to the crops located in adjacent off stream grid cells the flow process is modelled here by means of the proximity grid search method which considers the nearest neighbouring cells in x and y directions as well as in the diagonals the manning equation is used to estimate the average velocity v x y m s 1 of the river flow cross section 5 v x y n 1 r h 2 3 s f 1 2 where s f is the friction slope to model v x y we apply the diffusive wave equation by neglecting the local and convective acceleration terms and assuming that s f s ws where s ws is the water surface slope here we follow chow 2010 de paiva et al 2013 and yamazaki et al 2011 and assume that the manning roughness coefficient is constant throughout the yellow river basin the sensitivity of the ahms to the manning roughness coefficient n is discussed in section s7 of the supplementary material 2 3 irrigation scheme in ahms the soil moisture deficit method in noah mp is employed to calculate the irrigation water requirements i e when where and how much to irrigate ozdogan et al 2010 xu et al 2019 the equations for the integrated soil moisture availability sma in root zones and irrigation water requirements iwr read 6 sma sm sm wlt sm ref sm wlt 7 iwr sm ref sm f veg f crop 1 0 f iloss where sm is the integrated soil moisture m and sm ref and sm wlt denote the integrated field capacity and wilting point in the root zones m respectively f veg is the vegetation fraction taken from the modis based climatological dataset for the period from 2001 to 2012 broxton et al 2014 and f crop denotes the associated 500 m modis based irrigation fraction ozdogan and gutman 2008 f iloss is the fraction of flood irrigation loss which is set as 0 1 in this study the following irrigation conditions based on irrigation fraction rainfall leaf area index and soil water availability are considered xu et al 2019 reviewed the progress made in the control and optimization of various irrigation models and found that the following irrigation conditions apply to a broad range of scales from the field scale to the continental scale the calibration and sensitivity of the ahms to these irrigation parameters in the yellow river basin are described in section s9 of the supplementary material 1 cropland fraction irrigation fraction is larger than the irrigation fraction threshold irr frac which is set to 0 25 2 dry soil soil moisture availability is less than the irrigation trigger criterion irr mad which is set to 0 5 3 weather rainfall is less than the threshold rainfall rate ir rain which is set to 1 mm hr 4 crop growing season leaf area index is larger than the threshold leaf area index irr lai which is set to 0 6 the actual total irrigation water amount q irr is associated with both surface water and groundwater however this actual amount is limited by the availability of surface water in rivers and lakes the following model applies 8 q irr q irr sf q irr gw 9 q irr sf min i m a x a g f irr sw w sf avail 10 q irr gw i m a x a g f irr gw where q irr sf and q irr gw denote the actual amounts of irrigation water from surface water see section 2 2 3 eq 4 in and groundwater see section 2 2 2 eq 3 m 3 s 1 respectively while f irr sw and f irr gw are the corresponding area fractions of surface water river and groundwater irrigation based on the global map of irrigation areas siebert et al 2005 imax is the infiltration capacity m s 1 which is considered in the irrigation scheme in the present study see section s1 of the supplementary material while ag refers to the grid area m2 moreover w sf avail denotes the available surface water in the river or lake according to the channel routing model m 3 s 1 furthermore we assume that groundwater is sufficient to meet irrigation demand 3 application to the yellow river basin 3 1 study area the yellow river flows across qinghai tibet plateau inner mongolia plateau chinese loess plateau and huanghuaihai plain the yellow river basin fig 4 has an average temperature of 4 and annual precipitation of about 450 mm references from the yellow river bulletin of water resources which is unevenly distributed the basin includes the chinese loess plateau where most areas are arid or semi arid regions moreover the basin is characterized by a plateau and temperate climate and is strongly affected by the east asian monsoon the area of the upper and middle reaches above the huayuankou station amounts to 730 036 km2 thereby accounting for 91 82 of the total basin area furthermore the mean annual runoff at the huayuankou station is 56 7 billion m3 which corresponds to 96 42 of the total runoff of the yellow river the yellow river located downstream of the huayuankou station is an above ground hanging river with a small catchment area which covers about 3 of the yellow river basin excluding the internal flow area of 42 000 km2 therefore this study focuses on the upper reaches of the huayuankou station and the part of the yellow river basin referred to in this study corresponds to the upper reaches of the huayuankou furthermore these upper reaches of huayuankou station are divided into four subbasins namely tnh tnh lz lz tdg and tdg hyk which are associated with the four key hydrological stations in the region including tangnaihe lanzhou toudaoguai and huayuankou 3 2 model input data a lambert conformal projection with standard parallel 38 3 n centred at 109 0 e is used to process input data at a resolution of 20 km for the yellow river basin 3 2 1 topography data the high resolution geographic digital elevation data set multi error removed improved terrain dem merit with a 3sec resolution yamazaki et al 2019 is used and upscaled to 20 km resolution by using an ahms pre processing program yu et al 2006 in the upscaling process the lower values are weighted more strongly to derive a consistent river network the ahms pre processing program is combined with arcswat to obtain the related hydrological data i e river depth and width water surface elevation upstream area and sub basin area furthermore the depth and width of the river channel are estimated from the empirical channel discharge depth width relationship see section s3 in the supplementary material based on the theory of hydraulic geometry leopold and maddock 1953 3 2 2 subsurface data the initial groundwater head is derived from the simulations using the global groundwater model de graaf et al 2015 by using the china 1 4 000 000 geology dataset the hydrogeologic parameters including aquifer thickness porosity and hydraulic conductivity of the aquifer are obtained correspondingly for each lithologic type with a lookup method yang et al 2010 3 2 3 meteorological data the forcing data applied in our simulations are obtained from the china meteorological forcing dataset cmfd he et al 2020 these data include precipitation near surface air temperature near surface specific humidity surface pressure near surface wind surface downwelling shortwave and longwave radiation cmfd is a high spatial temporal resolution gridded near surface meteorological dataset which is specially designed for studies of land surface processes in china this dataset was generated by combining remote sensing products reanalysis datasets and in situ observations from weather stations precipitation fields in cmfd were produced based on the assimilation of 753 weather stations from the china meteorological administration cma and gridded background data including trmm and gldas noah 3 2 4 validation data to calibrate and validate ahms and the new irrigation model introduced here we consider the observed daily water discharge dataset publicly available from the national earth system science data center of china http loess geodata cn and the estimated annual averages of surface water withdrawals for the period 1979 1987 the area associated with the referred dataset comprises the four main gauging stations tn a lz b tdg c and hyk d of yellow river basin specifically due to the lack of data on direct statistical surface withdrawals from 1979 to 1987 we have estimated the corresponding annual averages of surface water withdrawals at the four gauging stations mentioned above based on information available for five years from the yellow river bulletin of water resources 1999 2003 and jia et al 2006 according to the yellow river bulletin of water resources in the period from 1999 to 2003 the percentage of whole basin average surface water withdrawals have been 0 6 9 12 45 38 and 17 18 at the four main gauging stations respectively moreover jia et al 2006 reported a value of approximately 24 km3 yr for the average annual surface water withdrawals from 1980 to 1989 therefore the surface water use in the upper reaches of the tnh is negligible the corresponding values are 2 34 10 91 and 4 13 km3 yr from 1979 to 1987 for the remaining three subbasins respectively similarly we have estimated the corresponding annual averages of surface water and groundwater withdrawals for irrigation from 1979 to 1987 in the area upstream of the hyk station mentioned above are 14 93 and 6 05 km3 yr respectively for the period 1979 to 1987 to validate our model prediction for evapotranspiration we employ the global land evaporation amsterdam model gleam v3 5 dataset martens et al 2017 which has been acquired from satellite observations moreover here we consider gravity recovery and climate experiment grace terrestrial water storage tws data to evaluate modelled tws on a regional scale to this end we have downloaded the latest grace products from the jpl rl06m mascon solutions thereafter jpl mascon wiese et al 2018 provided by the jet propulsion laboratory jpl at the 0 5 degree resolution and the native resolution of jpl rl06m of 3 jpl mascon has been pre processed as follows it is firstly masked by the land grid and subsequently rescaled by using the scaling factors obtained by comparing the tws of jpl mascon with the clm4 based tws provided by the grace website thereafter the dataset is interpolated to a 0 25 degree grid approximately 30 km on the equator fig 5 shows that the tws in the yellow river basin upstream of hyk is declining with a linear trend of approximately 0 5 cm yr from 2002 to 2021 previous studies e g feng et al 2013 have attributed this phenomenon to groundwater over exploitation in north china however our current model does not account for the processes of land use change e g afforestation or reforestation and improvement of groundwater irrigation systems on farmland that led to the groundwater over exploitation in the yellow river basin therefore to apply the tws dataset for the validation of our model here we perform a detrend analysis to remove the associated multi year trend from the jpl mascon thereby obtaining the orange curve in fig 5 3 3 model setup and spin up human interventions in the yellow river basin including irrigation and dam construction experienced substantial intensification during the last decades with uncertain impacts on the evolution of the natural streamflow in the basin here we focus on streamflow simulations from 1979 to 1987 for which both observed streamflow and meteorological data are available to this end model spin up was conducted firstly over several decades to reach dynamic equilibrium while the vegetation type and soil texture were assumed unchanged for the entire simulation period the spatial and temporal resolutions of the land surface and hydrological models are 20 km and 60 min respectively moreover a summary of the physical and control parameterization schemes used in noah mp is listed in table s2 in section s6 of the supplementary material 3 3 model performance evaluation indices the agreement between the predicted and observed values of a given variable can be quantified using the percentage error pe and the square of the correlation coefficient according to bravais pearson r 2 11 pe p o o 100 12 r 2 i 1 n o i o p i p i 1 n o i o 2 i 1 n p i p 2 2 where o and p denote observed and predicted values n is the total number of observations which are identified by the index i in the summation operator and the upper horizontal bar indicates averaging over all data points in the time series furthermore to quantify the agreement between predicted and observed streamflow we employ the nash sutcliffe model efficiency coefficient nse defined through 13 nse 1 i 1 n q s i q 0 i 2 i 1 n q 0 i q 0 2 where q s and q 0 are the predicted and observed values of the streamflow respectively and q 0 denotes the average of the observed values nse ranges from minus infinity poor fit to 1 0 perfect fit in general model prediction is considered to be satisfactory if nse 0 5 moriasi et al 2007 3 4 parameter calibration of hydrological model the calibration of the hydrological model parameters often constitutes a laborious task due to a large number of parameters and a range of uncertainties the sensitivity analysis presented in section s7 in the supplementary material and cuntz et al 2016 indicates that the output fluxes evapotranspiration and runoff predicted from noah mp are sensitive to parameters related to both soil and vegetation characteristics however to calibrate average runoff in the land surface model for further studies here we select the soil parameters saturated hydraulic conductivity that directly affect runoff generation and soil water budget moreover the saturated hydraulic conductance of the riverbed c s is calibrated against the observed baseflow however according to fig 1 the amount of artificial water withdrawals including irrigation and domestic water is very large and cannot be neglected in the computation of the regional water budget therefore to calibrate the hydrological parameters here we consider surface withdrawals see section 3 2 4 by comparing simulated total runoff with the sum of surface withdrawals and observed runoff four subbasins were selected to calibrate soil saturated hydraulic conductivity according to the climate landscape conditions and human activity impact the selected subbasins are the upstream areas of the tangnaihai tnh lanzhou lz toudaoguai tdg and huayuankou hyk gauges see fig 4 the calibrated hydrographs and the corresponding statistics are presented in fig 6 in this figure the monthly streamflow series predicted with our simulations are compared with the observations at the four gauging stations from 1979 to 1987 the hydrograph is greatly improved by the calibration procedure and a reasonable agreement is found between these observations and the simulation results for upper stream stations tangnaihe and lanzhou notably the agreement is better at the upstream stations than at other stations in the midstream arid region we thus conclude that the model must be improved to incorporate human activities in the midstream region including the effect of river irrigation which is the subject of section 5 4 evaluation and discussion the performance of the offline ahms is evaluated in this section by means of terrestrial water budget analysis and by comparing the predicted and observed mean annual runoff and monthly streamflow evapotranspiration and terrestrial water storage anomaly in the yellow river basin moreover section s8 in the supplementary material further describes the spatial distribution of eight hydrological variables including precipitation evapotranspiration runoff streamflow soil moisture groundwater depth surface runoff and subsurface runoff averaged annually from 1979 to 1987 4 1 terrestrial water budget water budget analysis offers a means to verify and evaluate hydrological models de paiva et al 2013 maurer et al 2001 the corresponding mean annual terrestrial water budget for the yellow river basin is presented in fig 7 a as we can see from this figure predicted and observed averaged annual precipitation values agree upon a percentage error pe of 2 which gives us confidence that the input precipitation data from cmfd reanalysis products are reliable for the purpose of the present study the deviation of the model water budget amounts to about 3 for precipitation while the changes in total terrestrial water storage are about 3 of the precipitation furthermore from the results obtained for the average annual evapotranspiration pe is 5 and runoff pe is 35 we conclude that the ahms underestimates the evapotranspiration and overestimates the runoff if river irrigation is neglected based on these findings we further conclude that irrigation constitutes an essential component of the water balance in the yellow river basin and must be incorporated into the ahms model to improve the hydrological simulations in fig 7b the mean annual runoff over 1979 1987 as predicted from our simulations is compared with the corresponding observation at four gauging stations over the same period from 1979 to 1987 the pe values of runoff in the subbasins of tnh tnh lz lz tdg and tdg hyk are 3 4 124 and 23 respectively therefore fig 7b shows that the pe of the mean annual runoff is significant at the lz tdg subbasin as mentioned before the main source of this bias can be attributed to the river water used for irrigation in this region therefore river water used for irrigation is an important component of the water balance particularly in the semi arid areas of the yellow river basin section 5 discusses the incorporation of river water taken for irrigation into ahms simulations 4 2 evapotranspiration fig 8 displays monthly evapotranspiration at the yellow river basin estimated from the gleam along with the corresponding prediction from the ahms for the period from 1980 to 1987 as shown in fig 8 the ahms prediction agrees well with the gleam estimate with the square of the correlation coefficient r 2 0 98 thus further corroborating the capability of our ahms simulations to quantitatively describe long term hydrological processes at the yellow river basin however the ahms slightly underestimates evapotranspiration especially in the winter notwithstanding the good agreement between the ahms and gleam estimates with regard to the evaporation peaks in particular the evapotranspiration in january predicted using ahms is clearly lower than the corresponding gleam estimate two factors could explain this underestimation first since groundwater provides the main source of water for evaporation during dry seasons this underestimation of evapotranspiration could be associated with underestimated groundwater recharge in winter second it has been noted in previous studies groisman and legates 1994 yeh and famiglietti 2008 that measured precipitation from rain gauges have a systematic negative bias because of the local wind effect around rain gauges this negative bias is greater in winter since snowflakes are more prone to wind deflections than raindrops this underestimation of evapotranspiration may be thus caused by negative bias in the precipitation dataset especially in winter 4 3 terrestrial water storage in fig 9 terrestrial water storage change twsc predicted in numerical simulations using ahms and gldas is compared with the corresponding grace based observation results as can be now seen from fig 9 we find a good quantitative agreement r 2 0 55 between the corresponding ahms simulation predictions and their observation counterparts from the grace datasets moreover the agreement of our ahms simulation predictions compares reasonably well with corresponding predictions from the global land data assimilation system gldas results r 2 0 56 too as can be seen from fig 9 therefore ahms represents the long term large scale water cycle in the yellow river basin with a good quantitative agreement with observations furthermore as shown in fig 9 our results indicate that terrestrial water storage changes twsc in 2003 2004 have been much larger than in other years this finding is consistent with the flooding that occurred in the middle and lower reaches of the yellow river basin weihe river sub basin in august 2003 according to the 2003 yellow river water resources bulletin the areal precipitation 555 6 mm of 2003 in the yellow river basin was 28 6 higher than the average areal precipitation 432 mm over the years 1956 2000 we thus attribute the higher tws in the period from 2003 to 2004 see fig 9 to the 2003 floods and the concatenated increase in infiltration and groundwater recharge our interpretation is in line with the association between precipitation and terrestrial water storage chen et al 2010 it should be noted that while the twsc in ahms simulations is obtained by explicitly considering soil moisture groundwater and surface water of rivers and lakes gldas lsm noah makes no explicit consideration of rivers and lakes in the simulations this difference could explain the larger amplitude of the twsc predicted using ahms compared to the corresponding gldas prediction therefore we compare in fig 9 the grace based monthly twsc with the ahms prediction twsc of the surface water δ w sf soil moisture water δ w us and groundwater δ w gw fig 10 indicates that changes in surface water soil moisture and groundwater are associated with twsc fluctuations of nearly the same magnitude it is interesting to note that surface water storage change including in rivers and lakes has been largely ignored in previous studies for example cai et al 2014 found by applying the noah mp model for the mississippi basin that soil moisture dominates the tws anomalies while groundwater constitutes the second component for this basin however consideration of surface water storage is indispensable for hydrological simulations of arid and semi arid regions such as the yellow river basin since the average annual precipitation in the yellow river basin is only about 450 mm the upper reaches provide the main water resources for the arid and semi arid middle and lower reaches i e terrestrial water storage in rivers plays a fundamental role in the yellow river basin and must be considered in the simulations we note that the twsc should further depend on river width and depth and on the area of the floodplains so the caveat must be added that some uncertainty exists about the values of these parameters as discussed in the previous sections furthermore the original ahms models natural terrestrial water cycles i e it does not consider the interference of human activities such as reservoir storage and agricultural irrigation the present work applies a coupled hydrological model of groundwater soil moisture and channel routing model thus making it possible to explicitly describe the contribution of each component to hydrological processes in the yellow river basin 5 irrigation impact on the runoff evapotranspiration terrestrial water storage and streamflow in the yellow river basin irrigation water is an important component of the water balance in the arid and semi arid areas and strongly affects streamflow in the yellow river basin as can be seen from fig 7b the lanzhou tangnaihe lz tdg subbasin is a net water consumption region however the current operational version of the ahms does not account for the effect of water taken from the yellow river for irrigation we thus attribute the discrepancy between predicted and observed average annual runoff at the lz tdg station see fig 7b the predicted average annual runoff is positive while the observed one is negative to the lack of a representation of irrigation water in the model here we extend the land surface channel routing and groundwater models of ahms to include the effect of water taken from the yellow river for irrigation q irr in eq 2 q irr gw in eq 3 and q irr sf in eq 4 to this end we combine the land surface model noah mp in the ahms with a dynamic irrigation scheme xu et al 2019 to quantify the dynamic water requirements for irrigation which is based on soil moisture deficit furthermore the actual river irrigation is further constrained by the amount of available water as well as by the fraction of river water within the total irrigation based on the statistics of irrigation facilities see section 2 3 as described in section 2 3 five parameters related to the irrigation model are considered the calibration and sensitivity analysis of these parameters are shown in section s9 of the supplementary material in the following paragraphs we discuss the results obtained from ahms using the calibrated parameter values in our irrigation model to validate and evaluate the irrigation model we compare the simulated areal average annual irrigation amount with regional statistics see section 3 2 4 from 1979 to 1987 as shown in table 1 the model simulates the total areal average annual irrigation well but the model underestimates river irrigation and overestimates groundwater irrigation moreover we perform the sensitivity analysis of the irrigation amount including river irrigation and groundwater irrigation and the average monthly streamflow at the outlet of the yellow river basin hyk to the irrigation parameters see table s4 in section s9 of the supplementary material we find that the model greatly underestimates the amount of river irrigation in the yellow river basin if the long distance transfer of water from the river to the irrigation area is not considered see table s5 in section s9 of the supplementary material furthermore fig 11 represents the monthly and annual averaged cycles of actual irrigation amount including river irrigation and groundwater irrigation in the yellow river basin the temporal distribution of irrigation water consumption indicates that the maximum water consumption rate occurs in june while during the winter the basin relies heavily on groundwater irrigation fig 12 a displays the annual averaged precipitation evapotranspiration and runoff for the period 1979 1987 obtained from the simulation under consideration of irrigation in the yellow river basin along with the corresponding observations compared to the results displayed in fig 7 no irrigation the percentage error pe of evapotranspiration and runoff changed from 5 to 2 and from 35 to 9 respectively moreover the annual average runoff obtained from the model with irrigation is compared against the observed value in fig 12b as can be seen by comparing fig 12b with fig 7b no irrigation the incorporation of irrigation substantially improved the model predictions in particular in fig 12b the negative average annual runoff at the lz tdg subbasin is accurately reproduced by the model as a result of considering irrigation furthermore we compare the gleam estimate for the evapotranspiration in the yellow river basin in the period of 1980 1987 with the corresponding predictions from the ahms simulation obtained under consideration of taking water from the river for irrigation the results for the yellow river basin are shown in fig 13 since microwave observations of surface soil moisture are assimilated into the gleam soil profile to correct for forcing errors in gleam martens et al 2016 the evapotranspiration estimated by gleam should be able to reflect the effects of irrigation however the incorporation of irrigation into the model does not improve the agreement between gleam estimates and ahms predictions of evapotranspiration the coefficient of determination r 2 decreased slightly from 0 98 to 0 97 upon including irrigation this behaviour can be understood by noting that the original ahms simulation without irrigation already overestimates evapotranspiration in the summer see section 4 2 we find that this overestimation is slightly enhanced by considering irrigation as indicated by the respective square of the correlation coefficient our findings clearly show thus that evapotranspiration is overestimated by ahms in the summer and underestimated in the winter and that this behaviour is not caused by our irrigation model therefore future research should focus on elucidating this behaviour to improve the overall accuracy of ahms and its applicability to the arid and semi arid regions of the yellow river basin next we investigate the effect of irrigation on the changes in terrestrial water storage change twsc fig 14 a and fig 14b compare twsc computed from the grace based monthly observations with the prediction from the ahms simulation considering the different model components affected by water taken from rivers and groundwater for irrigation we find that the agreement of twsc between ahms simulations and grace observations improved when irrigation was taken into account with the respective r 2 values changing from 0 55 without irrigation to 0 57 with irrigation in particular the consistency between the grace based twsc and the surface water changes δ w sf improved significantly due to the inclusion of irrigation with the associated r 2 increasing from 0 23 to 0 39 moreover the difference between the grace based twsc and the soil moisture water changes δ w us was reduced moderately with the associated r 2 increasing from 0 30 to 0 36 however there are no significant improvements in the comparison between the grace based twsc and groundwater changes δ w gw fig 15 compares our model predictions with observations of the monthly fig 15a and averaged monthly fig 15b streamflow at the outlet of the middle reaches of the yellow river basin huayuankou station for 1979 1987 in fig 15a and b the comparison is made both with and without water taken from the river for irrigation in the large irrigation districts including the hetao plateau and ningxia agriculture area the results displayed in fig 15a and b shows that ahms predictions of streamflow agree more closely with observation data when irrigation is considered in the simulation consideration of irrigation has led to a reduction in the systematic errors associated with the streamflow simulations as can be seen in fig 15b the integration error has been reduced from zone to zone in the yellow river basin more precisely the nash sutcliffe model efficiency nse changed from 0 26 without irrigation to 0 55 with irrigation for the monthly streamflow changes and from 0 27 without irrigation to 0 82 with irrigation for the mean monthly streamflow changes model performance improves significantly see area a in fig 15b with consideration of irrigation however various sources for the remaining error associated with the area in fig 15 should be elucidated in future work to address the remaining error in streamflow see area b in fig 15b the influence of industrial and domestic water use as well as dam regulations should be also included in future modelling to improve the model of water use in ahms our model has provided insights into the relevance of irrigation for hydrological processes throughout the yellow river basin as can be seen from figs 6 and 7a a good agreement between predicted and observed runoff and streamflow in the basin s upstream region tangnaihe and lanzhou stations could be obtained in simulations without irrigation after calibration of the soil hydraulic conductivity however the mere calibration of this parameter could not yield a satisfactory comparison between corresponding observations and model results in the midstream area huayuankou station good quantitative agreement including the midstream area could be only found after the incorporation of our irrigation module see figs 12b and 15 therefore our model results clearly show that irrigation plays a major role in hydrological processes in the midstream area of the yellow river basin huayuankou station which is characterized by an arid and semi arid climate our irrigation module should be thus considered in future regional hydrological modelling of arid and semi arid hydrological basins 6 conclusion and outlook in the present work a regional model for long term large scale hydrological processes under consideration of irrigation in the arid and semi arid regions ahms irrig has been presented the model ahms irrig combines the land surface model the flow routing model and the groundwater model of the atmospheric and hydrological modelling system ahms with a modified irrigation scheme xu et al 2019 to quantify the dynamic irrigation amount in arid and semi arid basins specifically this study developed a dynamic irrigation model based on the soil moisture deficit method and constrained by water availability for the arid and semi arid regions moreover the channel routing model and groundwater model of the ahms has been modified here to incorporate the water uptake applicable to the long distance water supply to irrigation districts in an arid and semi arid basin furthermore the actual amount of irrigation is therefore constrained by the water availability estimated with the flow routing as well as the irrigation fractions of surface water and groundwater based on the global map of irrigation areas ahms irrig has been then applied to hydrological simulations of the yellow river basin for the period 1979 2010 to assess the impact of irrigation on the land surface processes in the basin s arid and semi arid areas to this end ahms has been first calibrated and evaluated for the yellow river basin by means of a parameter sensitivity analysis and a terrestrial water budget analysis and through a comparison of model predictions for the mean annual runoff monthly streamflow evapotranspiration and terrestrial water storage change with corresponding observation data both from in situ and remote sensing datasets furthermore to account for water consumption in the yellow river the land surface channel routing and groundwater models have been extended to account for water taken from the river for irrigation the irrigation water demand calculated by the dynamic irrigation scheme in noah mp was added to the sink term and further constrained by water availability in the flow routing and groundwater model and then actual irrigation water is distributed evenly and horizontally over the ground in the land surface model by incorporating the irrigation module into the simulation a more realistic hydrologic response near the outlet of the yellow river basin could be obtained moreover a quantitative agreement was found between the predicted discharge at the upstream gauging stations namely tangnaihe and lanzhou and the corresponding observation data a reasonable agreement of twsc between ahms simulations and observations from grace was also found monthly evapotranspiration estimated by gleam and the one modelled by ahms were found to agree well with each other with the square of correlation coefficient r 2 of about 0 98 our results thus demonstrate the capability of ahms of reproducing long term hydrological processes in the yellow river basin provided water taken from irrigation is considered in the simulation therefore the main novelties of our model development and application can be summarized as follows 1 the development of an irrigation model that considers the long distance water transfer off stream from the river to irrigation districts is fully neglected by previous irrigation models with our model the actual irrigation amount is explicitly computed using the soil moisture deficit method and constrained by the water availability estimated with the flow routing as well as the irrigation fractions of surface water and groundwater based on the global map of irrigation areas 2 the development of a regional hydrological model that is applicable to arid and semi arid regions through the incorporation of irrigation sink and source terms into the channel routing and groundwater models 3 the incorporation of the advanced earth gravity satellite grace dataset for the verification of our hydrological model and the assessment of irrigation impacts on hydrological processes in the arid and semi arid environments of the yellow river basin therefore the future application of our model has the potential to substantially improve the quantitative assessment of the irrigation impacts on hydrological processes in arid and semi arid areas by incorporating our irrigation module into the regional ahms simulation furthermore our model shall provide a helpful tool in the study of feedback effects between irrigation rainfall and temperature in arid and semi arid regions by means of online numerical simulations coupled with the weather research forecasting wrf modelling system moreover the hydrological model extended here to incorporate our irrigation module shall also find application in the study of irrigation effects on local environmental processes under consideration of changes in climate and land use type however the current version of ahms needs to be improved in different ways to more accurately represent hydrological processes in the semi arid and arid areas of the yellow river basin in the present study only soil parameters were calibrated from the land surface model the incorporation of vegetation parameters into the calibration of the numerical simulations would constitute one important model extension in future work additional measurement data of river and floodplain geometry for the channel routing model of the ahms would also improve the prediction of flood timing and peak furthermore the incorporation of various anthropogenic influences such as damming or land use change and the inclusion of the dynamic land use change e g reforestation or afforestation and damming model into ahms constitutes an open modelling task which will be important to improve the quantitative assessment of the hydrological processes in future work overall the extension of ahms presented here led to a more reliable model for predicting runoff and streamflow in arid and semi arid regions such as the yellow river basin the progress achieved in the present work shall pave the way toward a wider model application of ahms at the regional scale over the yellow river basin and other hydrological systems in future work including a broader range of climatic and environmental conditions and anthropogenic influences software availability software name ahms irrig developer cong jiang qian xia hardware requirements pc hpc system requirements linux program language fortran availability https github com jiangcong1990 ahms irrig license free and open source documentation readme and guided example in github repository credit authorship contribution statement cong jiang formal analysis methodology software validation writing original draft writing review editing eric j r parteli conceptualization supervision funding acquisition writing review editing qian xia software xin yin investigation visualization yaping shao conceptualization supervision funding acquisition writing review editing resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research was supported by the german research foundation dfg through the heisenberg programme multiscale simulation of earth surface processes project number 434377576 the china meteorological forcing dataset cmfd is provided by national tibetan plateau data center http data tpdc ac cn daily yellow river discharge data is supported by loess plateau subcenter national earth system science data center national science technology infrastructure of china http loess geodata cn appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105531 
25526,we develop a regional hydrological model that applies to arid and semi arid regions by explicitly considering the effect of irrigation on the hydrological processes a new irrigation module is here integrated into the recently introduced atmospheric and hydrological modelling system ahms for the quantitative assessment of basin scale hydrological response to climate change and the impact of anthropogenic activities on water resources the land surface channel routing and groundwater modules of the ahms are extended here to incorporate the new module we then apply the model to simulating the hydrological processes in the yellow river basin an arid and semi arid region where irrigation constitutes the most important source of water use the model is calibrated and validated using in situ and remote sensing observations this study demonstrates the capability of the ahms for regional hydrological modelling in arid and semi arid basins where irrigation profoundly influences the water balance keywords hydrological modelling yellow river basin arid and semi arid areas irrigation model calibration validation data availability data will be made available on request 1 introduction atmospheric and hydrological models have been under intensive development in recent years as they provide a powerful tool for the assessment and prediction of regional hydrological processes and the investigation of the dynamic feedbacks between the atmosphere and continental hydrosphere gochis et al 2013 maxwell et al 2011 shrestha et al 2014 wagner et al 2016a such models have found diverse applications in studies on basin scale hydrological responses to climate change and anthropogenic activities maxwell et al 2007 wilby et al 1994 however hydrological simulation in arid and semi arid regions remains a formidable task because the reliable representations of the often low and heterogeneous rainfall intermittent river flow and impacts of human activities are particularly challenging pilgrim et al 1988 rafiei sardooi et al 2022 thus we focus here on the development of a hydrological model for arid and semi arid regions specifically the yellow river basin is selected as the research area owing to its unique hydrological characteristics and important position in china the yellow river is the second longest river in china 5464 km and the yellow river basin 795 000 km2 is the largest basin in north china the average water resources in the yellow river basin account for only 2 of the total water resources in china but the water from this basin feeds 12 of the chinese population however water shortage constitutes a serious problem given the increasing water demand in the area with continuing population growth and urban development in 1997 the downstream 704 km from the estuary dried up for more than 226 days cong et al 2009 the large irrigation districts in the yellow river basin are mainly located in arid and semi arid areas and irrigation has accounted for instance for more than 80 60 of the gross human water use in the period from 1956 to 2010 2001 2019 and rapidly increasing with time fig 1 for instance hetao region takes about 5 billion m3 water every year from the yellow river although industrial water use has been increasing since the early 2000s due to economic development irrigation still constitutes the most important source of water use in this area jia et al 2006 most previous studies about hydrological processes in the yellow river basin neglected explicit consideration of river water use in large scale irrigation districts e g cong et al 2009 yuan et al 2016 a water use module was introduced in the wep l distributed hydrological model by jia et al 2006 by taking the census irrigation data as input assess the water resources in the yellow river basin in the latter study irrigation water requirements in the model were estimated using statistical methods and data not physically based modelling yin et al 2021 extended the global land surface model orchidee organizing carbon and hydrology in dynamic ecosystems by including a model for irrigation crop and offline dam operation their model assumes that streams supply water to the crops within the grid cells they flow across only neglecting water transfer over long distances given the commonly used channels in the irrigation districts of arid and semi arid regions this neglect may lead to an underestimation of actual river irrigation volumes and affect the accuracy of hydrological simulations over large irrigated districts yin et al 2021 the main purpose of this article is to develop a hydrological model for long term large scale hydrological processes in arid and semi arid basins focusing on the yellow river basin our model development builds on the offline mode of the coupled atmospheric and hydrological modelling system ahms developed at the university of cologne jiang et al 2020 xia 2019 an example of the ahms applications to wet hydrological basins can be found in xia et al 2022 the use of river water and groundwater for irrigation in the yellow river basin is expected to profoundly impact the regional hydrological processes we thus extend the ahms to include river water and groundwater use processes to better simulate the streamflow and assess the water resources in the yellow river basin to this end the land surface channel routing and groundwater models of ahms are extended to account for river water and groundwater use in irrigation and to include a scheme for estimating irrigated water requirement as proposed by xu et al 2019 these new developments lead to improved ahms simulations by reducing the errors associated with the underestimation of evaporation and the overestimation of runoff in the yellow river basin we also show that the modelling of streamflow in the arid and semi arid regions of the yellow river basin also improves upon consideration of irrigation 2 method 2 1 introduction of the offline atmospheric and hydrological modelling system ahms the atmospheric and hydrological modelling system ahms is a fully coupled atmospheric and hydrological modelling system jiang et al 2020 xia 2019 xia et al 2022 specifically ahms couples the weather research and forecasting wrf modelling system skamarock and klemp 2008 with the physically based distributed regional hydrological model system hms yu et al 2006 through the noah multiparameterziation land surface model noah mp chen and dudhia 2001 niu et al 2011 furthermore the module in wrf hydro gochis et al 2013 is employed for downscaling and upscaling of variables between the grids of land surface model and hydrological model ahms can either be run online i e coupled with the full wrf model for atmospheric dynamics or offline which is the situation adopted in the present study by using prescribed near surface atmospheric forcing variables a schematic diagram identifying the main components of the online and offline ahms simulations is displayed in fig 2 as shown in this figure while the online ahms can be employed to study the dynamic feedback between the atmosphere surface and subsurface the offline ahms can be used to effectively calibrate and validate hydrological models different from the previous work of xia et al 2022 combined the land surface hydrological model with the global crop water model gcwm to study hydrological processes in the water rich areas of china this study aims to develop an irrigation model that applies to arid and semi arid regions to this end we extend ahms to incorporate and modify a dynamic irrigation scheme xu et al 2019 in noah mp allowing us to quantify the dynamic irrigation water requirements of dryland crops based on the soil moisture deficit method furthermore we incorporate the water uptake applicable to irrigation districts located in arid and semi arid regions into the channel routing model and groundwater model of hms specifically we develop a channel routing model that considers long distance water supply processes in irrigation areas characteristic of arid and semi arid regions such as those in the yellow river basin a summary of the main components of the offline ahms simulations applied in the present work is provided in the subsequent sections section 2 2 describes the hydrological models involved in the noah mp and hms section 2 3 presents the irrigation scheme in ahms fig 3 displays a schematic diagram of the hydrological cycle represented in ahms and discussed in the following sections 2 2 hydrological modelling in noah mp and hms the land surface model noah mp is a single column model that simulates the exchange of heat moisture and momentum between the land surface and the atmosphere the model provides a multi parameterization framework for application in various land surface schemes chen and dudhia 2001 niu et al 2011 furthermore noah mp has been modified to be consistent with the hms model and darcy s law boundary condition has been applied to simulate the moisture interactions between the unsaturated and saturated zones xia 2019 moreover the hydrological model system hms developed for mesoscale and large scale hydrological simulations by yu et al 2006 has been substantially improved in the framework of hydrological modelling xia 2019 hms is now applicable to simulate all main components involved in hydrological processes including surface water flow groundwater flow and the interaction flux between them specifically the hms model consists of three sub models a two dimensional channel routing model rt2d a two dimensional groundwater hydrological model gw2d and a groundwater and channel interaction model gci these modules compute streamflow groundwater flows from cell to cell and exchange with the stream respectively noah mp and hms consider four surface soil layers with a total depth of 2 m and a single groundwater layer the vertical movement of water in the surface soil is simulated by the richard equation see section 2 2 1 while the horizontal movement of groundwater is modelled using the boussinesq equation for unconfined conditions see section 2 2 2 the runoff rate is predicted based on the theory of infiltration excess runoff horton runoff see section s1 in the supplementary material and saturation excess runoff exchange water between surface soil and groundwater drainage river groundwater and river vadose zone subsurface flow are calculated according to darcy s law see section s2 in the supplementary material the flow routing is simulated by a diffusive wave model with the manning equation see section 2 2 3 which can be used in low relief areas and account for backwater effects additional details about surface energy balances and vegetation dynamics of noah mp are described in chen and dudhia 2001 and niu et al 2011 2 2 1 vertical movement of soil water the movement of soil water in the vertical direction is described by the richards equation pachepsky et al 2003 richards 1931 1 θ t z k ψ z z s z t where θ is the volumetric soil water content t is time s z is the height above the data in the soil column positive upward m k is the hydraulic conductivity m s 1 ψ is the soil matric potential m and s z t is the soil moisture sink term e g transpiration losses in the root zone to solve eq 1 the following top boundary condition is considered 2 q wat p t m e g r sf q irr where q wat denotes the water input on the soil surface p t is the throughfall precipitation m is the snow melt e g is the ground evaporation r sf is the surface runoff and q irr is the actual irrigated water including river irrigation and groundwater irrigation which in the present study is added to the soil surface furthermore we assume that the irrigation water is spread evenly and horizontally over the ground while the actual irrigation input value on the soil surface is calculated from eq 8 see section 2 3 2 2 2 2d single layer distributed groundwater model the dynamics of the horizontal movement of groundwater are described by the following partial differential boussinesq equation for unconfined conditions 3 s p h g t x t g h g x y t g h g y q net x y t where t g is the aquifer transmissivity m 2 s 1 s p is the storage coefficient porosity m 3 m 3 q net m s 1 denotes the net contribution of sink and source terms including the interaction flux between groundwater and unsaturated soil the exchange of water between rivers and groundwater and the extraction of groundwater from wells q irr gw 2 2 3 channel routing model river and lake levels are represented by the prognostic variable h r which represents the thickness of surface water averaged over the grid cell by combining the continuity of mass in the cell with the momentum equation for transport between cells the rate of change of h r can be written as a h r t x a c 1 n r h 2 3 h r x h r x 1 2 y a c 1 n r h 2 3 h r y h r y 1 2 4 r sf f w c g c u c l q irr sf x y t where a is the river bed area of water in the river or lake m2 a c is the cross sectional area of water in the river or lake at cell boundaries m2 n is manning s roughness coefficient s m 1 3 and r sf is the hydraulic radius m which is equivalent to w d 2 d w for an open channel flow through a rectangular cross section with w and d denoting the width and depth of the river m furthermore x and y denote the horizontal directions and the water flow term between neighbouring grid cells is computed by considering all eight directions on the plane including the diagonals specifically for every grid cell in the square lattice constituting the simulation domain eq 4 is solved by considering both nearest neighbouring cells in x and y directions as well as in the diagonals omitted from eq 4 for clarity in addition r sf is the surface runoff m 3 s 1 which encodes the infiltration excess runoff r ins and the saturation excess runoff r sat while f w is the wetted surface fraction which is set to 1 for lakes and to f b for running rivers with f b denoting the fractional area of the river bed computed according to the eq s9 in the supplementary material moreover c g c u and c l denote the values of water flux exchanged by the river with saturated soil unsaturated soil and lake respectively m 3 s 1 while q irr sf is equal to the irrigated water from surface water which has been added to the model in this study m 3 s 1 water supply from the streams to the crops is modelled based on irrigation water demand predicted by the dynamic irrigation scheme in noah mp and constrained by the amount of available water in the stream see section 2 3 eq 9 more precisely water is supplied to the crops located within the grid cells the streams flow across as well as to the crops located in adjacent off stream grid cells the flow process is modelled here by means of the proximity grid search method which considers the nearest neighbouring cells in x and y directions as well as in the diagonals the manning equation is used to estimate the average velocity v x y m s 1 of the river flow cross section 5 v x y n 1 r h 2 3 s f 1 2 where s f is the friction slope to model v x y we apply the diffusive wave equation by neglecting the local and convective acceleration terms and assuming that s f s ws where s ws is the water surface slope here we follow chow 2010 de paiva et al 2013 and yamazaki et al 2011 and assume that the manning roughness coefficient is constant throughout the yellow river basin the sensitivity of the ahms to the manning roughness coefficient n is discussed in section s7 of the supplementary material 2 3 irrigation scheme in ahms the soil moisture deficit method in noah mp is employed to calculate the irrigation water requirements i e when where and how much to irrigate ozdogan et al 2010 xu et al 2019 the equations for the integrated soil moisture availability sma in root zones and irrigation water requirements iwr read 6 sma sm sm wlt sm ref sm wlt 7 iwr sm ref sm f veg f crop 1 0 f iloss where sm is the integrated soil moisture m and sm ref and sm wlt denote the integrated field capacity and wilting point in the root zones m respectively f veg is the vegetation fraction taken from the modis based climatological dataset for the period from 2001 to 2012 broxton et al 2014 and f crop denotes the associated 500 m modis based irrigation fraction ozdogan and gutman 2008 f iloss is the fraction of flood irrigation loss which is set as 0 1 in this study the following irrigation conditions based on irrigation fraction rainfall leaf area index and soil water availability are considered xu et al 2019 reviewed the progress made in the control and optimization of various irrigation models and found that the following irrigation conditions apply to a broad range of scales from the field scale to the continental scale the calibration and sensitivity of the ahms to these irrigation parameters in the yellow river basin are described in section s9 of the supplementary material 1 cropland fraction irrigation fraction is larger than the irrigation fraction threshold irr frac which is set to 0 25 2 dry soil soil moisture availability is less than the irrigation trigger criterion irr mad which is set to 0 5 3 weather rainfall is less than the threshold rainfall rate ir rain which is set to 1 mm hr 4 crop growing season leaf area index is larger than the threshold leaf area index irr lai which is set to 0 6 the actual total irrigation water amount q irr is associated with both surface water and groundwater however this actual amount is limited by the availability of surface water in rivers and lakes the following model applies 8 q irr q irr sf q irr gw 9 q irr sf min i m a x a g f irr sw w sf avail 10 q irr gw i m a x a g f irr gw where q irr sf and q irr gw denote the actual amounts of irrigation water from surface water see section 2 2 3 eq 4 in and groundwater see section 2 2 2 eq 3 m 3 s 1 respectively while f irr sw and f irr gw are the corresponding area fractions of surface water river and groundwater irrigation based on the global map of irrigation areas siebert et al 2005 imax is the infiltration capacity m s 1 which is considered in the irrigation scheme in the present study see section s1 of the supplementary material while ag refers to the grid area m2 moreover w sf avail denotes the available surface water in the river or lake according to the channel routing model m 3 s 1 furthermore we assume that groundwater is sufficient to meet irrigation demand 3 application to the yellow river basin 3 1 study area the yellow river flows across qinghai tibet plateau inner mongolia plateau chinese loess plateau and huanghuaihai plain the yellow river basin fig 4 has an average temperature of 4 and annual precipitation of about 450 mm references from the yellow river bulletin of water resources which is unevenly distributed the basin includes the chinese loess plateau where most areas are arid or semi arid regions moreover the basin is characterized by a plateau and temperate climate and is strongly affected by the east asian monsoon the area of the upper and middle reaches above the huayuankou station amounts to 730 036 km2 thereby accounting for 91 82 of the total basin area furthermore the mean annual runoff at the huayuankou station is 56 7 billion m3 which corresponds to 96 42 of the total runoff of the yellow river the yellow river located downstream of the huayuankou station is an above ground hanging river with a small catchment area which covers about 3 of the yellow river basin excluding the internal flow area of 42 000 km2 therefore this study focuses on the upper reaches of the huayuankou station and the part of the yellow river basin referred to in this study corresponds to the upper reaches of the huayuankou furthermore these upper reaches of huayuankou station are divided into four subbasins namely tnh tnh lz lz tdg and tdg hyk which are associated with the four key hydrological stations in the region including tangnaihe lanzhou toudaoguai and huayuankou 3 2 model input data a lambert conformal projection with standard parallel 38 3 n centred at 109 0 e is used to process input data at a resolution of 20 km for the yellow river basin 3 2 1 topography data the high resolution geographic digital elevation data set multi error removed improved terrain dem merit with a 3sec resolution yamazaki et al 2019 is used and upscaled to 20 km resolution by using an ahms pre processing program yu et al 2006 in the upscaling process the lower values are weighted more strongly to derive a consistent river network the ahms pre processing program is combined with arcswat to obtain the related hydrological data i e river depth and width water surface elevation upstream area and sub basin area furthermore the depth and width of the river channel are estimated from the empirical channel discharge depth width relationship see section s3 in the supplementary material based on the theory of hydraulic geometry leopold and maddock 1953 3 2 2 subsurface data the initial groundwater head is derived from the simulations using the global groundwater model de graaf et al 2015 by using the china 1 4 000 000 geology dataset the hydrogeologic parameters including aquifer thickness porosity and hydraulic conductivity of the aquifer are obtained correspondingly for each lithologic type with a lookup method yang et al 2010 3 2 3 meteorological data the forcing data applied in our simulations are obtained from the china meteorological forcing dataset cmfd he et al 2020 these data include precipitation near surface air temperature near surface specific humidity surface pressure near surface wind surface downwelling shortwave and longwave radiation cmfd is a high spatial temporal resolution gridded near surface meteorological dataset which is specially designed for studies of land surface processes in china this dataset was generated by combining remote sensing products reanalysis datasets and in situ observations from weather stations precipitation fields in cmfd were produced based on the assimilation of 753 weather stations from the china meteorological administration cma and gridded background data including trmm and gldas noah 3 2 4 validation data to calibrate and validate ahms and the new irrigation model introduced here we consider the observed daily water discharge dataset publicly available from the national earth system science data center of china http loess geodata cn and the estimated annual averages of surface water withdrawals for the period 1979 1987 the area associated with the referred dataset comprises the four main gauging stations tn a lz b tdg c and hyk d of yellow river basin specifically due to the lack of data on direct statistical surface withdrawals from 1979 to 1987 we have estimated the corresponding annual averages of surface water withdrawals at the four gauging stations mentioned above based on information available for five years from the yellow river bulletin of water resources 1999 2003 and jia et al 2006 according to the yellow river bulletin of water resources in the period from 1999 to 2003 the percentage of whole basin average surface water withdrawals have been 0 6 9 12 45 38 and 17 18 at the four main gauging stations respectively moreover jia et al 2006 reported a value of approximately 24 km3 yr for the average annual surface water withdrawals from 1980 to 1989 therefore the surface water use in the upper reaches of the tnh is negligible the corresponding values are 2 34 10 91 and 4 13 km3 yr from 1979 to 1987 for the remaining three subbasins respectively similarly we have estimated the corresponding annual averages of surface water and groundwater withdrawals for irrigation from 1979 to 1987 in the area upstream of the hyk station mentioned above are 14 93 and 6 05 km3 yr respectively for the period 1979 to 1987 to validate our model prediction for evapotranspiration we employ the global land evaporation amsterdam model gleam v3 5 dataset martens et al 2017 which has been acquired from satellite observations moreover here we consider gravity recovery and climate experiment grace terrestrial water storage tws data to evaluate modelled tws on a regional scale to this end we have downloaded the latest grace products from the jpl rl06m mascon solutions thereafter jpl mascon wiese et al 2018 provided by the jet propulsion laboratory jpl at the 0 5 degree resolution and the native resolution of jpl rl06m of 3 jpl mascon has been pre processed as follows it is firstly masked by the land grid and subsequently rescaled by using the scaling factors obtained by comparing the tws of jpl mascon with the clm4 based tws provided by the grace website thereafter the dataset is interpolated to a 0 25 degree grid approximately 30 km on the equator fig 5 shows that the tws in the yellow river basin upstream of hyk is declining with a linear trend of approximately 0 5 cm yr from 2002 to 2021 previous studies e g feng et al 2013 have attributed this phenomenon to groundwater over exploitation in north china however our current model does not account for the processes of land use change e g afforestation or reforestation and improvement of groundwater irrigation systems on farmland that led to the groundwater over exploitation in the yellow river basin therefore to apply the tws dataset for the validation of our model here we perform a detrend analysis to remove the associated multi year trend from the jpl mascon thereby obtaining the orange curve in fig 5 3 3 model setup and spin up human interventions in the yellow river basin including irrigation and dam construction experienced substantial intensification during the last decades with uncertain impacts on the evolution of the natural streamflow in the basin here we focus on streamflow simulations from 1979 to 1987 for which both observed streamflow and meteorological data are available to this end model spin up was conducted firstly over several decades to reach dynamic equilibrium while the vegetation type and soil texture were assumed unchanged for the entire simulation period the spatial and temporal resolutions of the land surface and hydrological models are 20 km and 60 min respectively moreover a summary of the physical and control parameterization schemes used in noah mp is listed in table s2 in section s6 of the supplementary material 3 3 model performance evaluation indices the agreement between the predicted and observed values of a given variable can be quantified using the percentage error pe and the square of the correlation coefficient according to bravais pearson r 2 11 pe p o o 100 12 r 2 i 1 n o i o p i p i 1 n o i o 2 i 1 n p i p 2 2 where o and p denote observed and predicted values n is the total number of observations which are identified by the index i in the summation operator and the upper horizontal bar indicates averaging over all data points in the time series furthermore to quantify the agreement between predicted and observed streamflow we employ the nash sutcliffe model efficiency coefficient nse defined through 13 nse 1 i 1 n q s i q 0 i 2 i 1 n q 0 i q 0 2 where q s and q 0 are the predicted and observed values of the streamflow respectively and q 0 denotes the average of the observed values nse ranges from minus infinity poor fit to 1 0 perfect fit in general model prediction is considered to be satisfactory if nse 0 5 moriasi et al 2007 3 4 parameter calibration of hydrological model the calibration of the hydrological model parameters often constitutes a laborious task due to a large number of parameters and a range of uncertainties the sensitivity analysis presented in section s7 in the supplementary material and cuntz et al 2016 indicates that the output fluxes evapotranspiration and runoff predicted from noah mp are sensitive to parameters related to both soil and vegetation characteristics however to calibrate average runoff in the land surface model for further studies here we select the soil parameters saturated hydraulic conductivity that directly affect runoff generation and soil water budget moreover the saturated hydraulic conductance of the riverbed c s is calibrated against the observed baseflow however according to fig 1 the amount of artificial water withdrawals including irrigation and domestic water is very large and cannot be neglected in the computation of the regional water budget therefore to calibrate the hydrological parameters here we consider surface withdrawals see section 3 2 4 by comparing simulated total runoff with the sum of surface withdrawals and observed runoff four subbasins were selected to calibrate soil saturated hydraulic conductivity according to the climate landscape conditions and human activity impact the selected subbasins are the upstream areas of the tangnaihai tnh lanzhou lz toudaoguai tdg and huayuankou hyk gauges see fig 4 the calibrated hydrographs and the corresponding statistics are presented in fig 6 in this figure the monthly streamflow series predicted with our simulations are compared with the observations at the four gauging stations from 1979 to 1987 the hydrograph is greatly improved by the calibration procedure and a reasonable agreement is found between these observations and the simulation results for upper stream stations tangnaihe and lanzhou notably the agreement is better at the upstream stations than at other stations in the midstream arid region we thus conclude that the model must be improved to incorporate human activities in the midstream region including the effect of river irrigation which is the subject of section 5 4 evaluation and discussion the performance of the offline ahms is evaluated in this section by means of terrestrial water budget analysis and by comparing the predicted and observed mean annual runoff and monthly streamflow evapotranspiration and terrestrial water storage anomaly in the yellow river basin moreover section s8 in the supplementary material further describes the spatial distribution of eight hydrological variables including precipitation evapotranspiration runoff streamflow soil moisture groundwater depth surface runoff and subsurface runoff averaged annually from 1979 to 1987 4 1 terrestrial water budget water budget analysis offers a means to verify and evaluate hydrological models de paiva et al 2013 maurer et al 2001 the corresponding mean annual terrestrial water budget for the yellow river basin is presented in fig 7 a as we can see from this figure predicted and observed averaged annual precipitation values agree upon a percentage error pe of 2 which gives us confidence that the input precipitation data from cmfd reanalysis products are reliable for the purpose of the present study the deviation of the model water budget amounts to about 3 for precipitation while the changes in total terrestrial water storage are about 3 of the precipitation furthermore from the results obtained for the average annual evapotranspiration pe is 5 and runoff pe is 35 we conclude that the ahms underestimates the evapotranspiration and overestimates the runoff if river irrigation is neglected based on these findings we further conclude that irrigation constitutes an essential component of the water balance in the yellow river basin and must be incorporated into the ahms model to improve the hydrological simulations in fig 7b the mean annual runoff over 1979 1987 as predicted from our simulations is compared with the corresponding observation at four gauging stations over the same period from 1979 to 1987 the pe values of runoff in the subbasins of tnh tnh lz lz tdg and tdg hyk are 3 4 124 and 23 respectively therefore fig 7b shows that the pe of the mean annual runoff is significant at the lz tdg subbasin as mentioned before the main source of this bias can be attributed to the river water used for irrigation in this region therefore river water used for irrigation is an important component of the water balance particularly in the semi arid areas of the yellow river basin section 5 discusses the incorporation of river water taken for irrigation into ahms simulations 4 2 evapotranspiration fig 8 displays monthly evapotranspiration at the yellow river basin estimated from the gleam along with the corresponding prediction from the ahms for the period from 1980 to 1987 as shown in fig 8 the ahms prediction agrees well with the gleam estimate with the square of the correlation coefficient r 2 0 98 thus further corroborating the capability of our ahms simulations to quantitatively describe long term hydrological processes at the yellow river basin however the ahms slightly underestimates evapotranspiration especially in the winter notwithstanding the good agreement between the ahms and gleam estimates with regard to the evaporation peaks in particular the evapotranspiration in january predicted using ahms is clearly lower than the corresponding gleam estimate two factors could explain this underestimation first since groundwater provides the main source of water for evaporation during dry seasons this underestimation of evapotranspiration could be associated with underestimated groundwater recharge in winter second it has been noted in previous studies groisman and legates 1994 yeh and famiglietti 2008 that measured precipitation from rain gauges have a systematic negative bias because of the local wind effect around rain gauges this negative bias is greater in winter since snowflakes are more prone to wind deflections than raindrops this underestimation of evapotranspiration may be thus caused by negative bias in the precipitation dataset especially in winter 4 3 terrestrial water storage in fig 9 terrestrial water storage change twsc predicted in numerical simulations using ahms and gldas is compared with the corresponding grace based observation results as can be now seen from fig 9 we find a good quantitative agreement r 2 0 55 between the corresponding ahms simulation predictions and their observation counterparts from the grace datasets moreover the agreement of our ahms simulation predictions compares reasonably well with corresponding predictions from the global land data assimilation system gldas results r 2 0 56 too as can be seen from fig 9 therefore ahms represents the long term large scale water cycle in the yellow river basin with a good quantitative agreement with observations furthermore as shown in fig 9 our results indicate that terrestrial water storage changes twsc in 2003 2004 have been much larger than in other years this finding is consistent with the flooding that occurred in the middle and lower reaches of the yellow river basin weihe river sub basin in august 2003 according to the 2003 yellow river water resources bulletin the areal precipitation 555 6 mm of 2003 in the yellow river basin was 28 6 higher than the average areal precipitation 432 mm over the years 1956 2000 we thus attribute the higher tws in the period from 2003 to 2004 see fig 9 to the 2003 floods and the concatenated increase in infiltration and groundwater recharge our interpretation is in line with the association between precipitation and terrestrial water storage chen et al 2010 it should be noted that while the twsc in ahms simulations is obtained by explicitly considering soil moisture groundwater and surface water of rivers and lakes gldas lsm noah makes no explicit consideration of rivers and lakes in the simulations this difference could explain the larger amplitude of the twsc predicted using ahms compared to the corresponding gldas prediction therefore we compare in fig 9 the grace based monthly twsc with the ahms prediction twsc of the surface water δ w sf soil moisture water δ w us and groundwater δ w gw fig 10 indicates that changes in surface water soil moisture and groundwater are associated with twsc fluctuations of nearly the same magnitude it is interesting to note that surface water storage change including in rivers and lakes has been largely ignored in previous studies for example cai et al 2014 found by applying the noah mp model for the mississippi basin that soil moisture dominates the tws anomalies while groundwater constitutes the second component for this basin however consideration of surface water storage is indispensable for hydrological simulations of arid and semi arid regions such as the yellow river basin since the average annual precipitation in the yellow river basin is only about 450 mm the upper reaches provide the main water resources for the arid and semi arid middle and lower reaches i e terrestrial water storage in rivers plays a fundamental role in the yellow river basin and must be considered in the simulations we note that the twsc should further depend on river width and depth and on the area of the floodplains so the caveat must be added that some uncertainty exists about the values of these parameters as discussed in the previous sections furthermore the original ahms models natural terrestrial water cycles i e it does not consider the interference of human activities such as reservoir storage and agricultural irrigation the present work applies a coupled hydrological model of groundwater soil moisture and channel routing model thus making it possible to explicitly describe the contribution of each component to hydrological processes in the yellow river basin 5 irrigation impact on the runoff evapotranspiration terrestrial water storage and streamflow in the yellow river basin irrigation water is an important component of the water balance in the arid and semi arid areas and strongly affects streamflow in the yellow river basin as can be seen from fig 7b the lanzhou tangnaihe lz tdg subbasin is a net water consumption region however the current operational version of the ahms does not account for the effect of water taken from the yellow river for irrigation we thus attribute the discrepancy between predicted and observed average annual runoff at the lz tdg station see fig 7b the predicted average annual runoff is positive while the observed one is negative to the lack of a representation of irrigation water in the model here we extend the land surface channel routing and groundwater models of ahms to include the effect of water taken from the yellow river for irrigation q irr in eq 2 q irr gw in eq 3 and q irr sf in eq 4 to this end we combine the land surface model noah mp in the ahms with a dynamic irrigation scheme xu et al 2019 to quantify the dynamic water requirements for irrigation which is based on soil moisture deficit furthermore the actual river irrigation is further constrained by the amount of available water as well as by the fraction of river water within the total irrigation based on the statistics of irrigation facilities see section 2 3 as described in section 2 3 five parameters related to the irrigation model are considered the calibration and sensitivity analysis of these parameters are shown in section s9 of the supplementary material in the following paragraphs we discuss the results obtained from ahms using the calibrated parameter values in our irrigation model to validate and evaluate the irrigation model we compare the simulated areal average annual irrigation amount with regional statistics see section 3 2 4 from 1979 to 1987 as shown in table 1 the model simulates the total areal average annual irrigation well but the model underestimates river irrigation and overestimates groundwater irrigation moreover we perform the sensitivity analysis of the irrigation amount including river irrigation and groundwater irrigation and the average monthly streamflow at the outlet of the yellow river basin hyk to the irrigation parameters see table s4 in section s9 of the supplementary material we find that the model greatly underestimates the amount of river irrigation in the yellow river basin if the long distance transfer of water from the river to the irrigation area is not considered see table s5 in section s9 of the supplementary material furthermore fig 11 represents the monthly and annual averaged cycles of actual irrigation amount including river irrigation and groundwater irrigation in the yellow river basin the temporal distribution of irrigation water consumption indicates that the maximum water consumption rate occurs in june while during the winter the basin relies heavily on groundwater irrigation fig 12 a displays the annual averaged precipitation evapotranspiration and runoff for the period 1979 1987 obtained from the simulation under consideration of irrigation in the yellow river basin along with the corresponding observations compared to the results displayed in fig 7 no irrigation the percentage error pe of evapotranspiration and runoff changed from 5 to 2 and from 35 to 9 respectively moreover the annual average runoff obtained from the model with irrigation is compared against the observed value in fig 12b as can be seen by comparing fig 12b with fig 7b no irrigation the incorporation of irrigation substantially improved the model predictions in particular in fig 12b the negative average annual runoff at the lz tdg subbasin is accurately reproduced by the model as a result of considering irrigation furthermore we compare the gleam estimate for the evapotranspiration in the yellow river basin in the period of 1980 1987 with the corresponding predictions from the ahms simulation obtained under consideration of taking water from the river for irrigation the results for the yellow river basin are shown in fig 13 since microwave observations of surface soil moisture are assimilated into the gleam soil profile to correct for forcing errors in gleam martens et al 2016 the evapotranspiration estimated by gleam should be able to reflect the effects of irrigation however the incorporation of irrigation into the model does not improve the agreement between gleam estimates and ahms predictions of evapotranspiration the coefficient of determination r 2 decreased slightly from 0 98 to 0 97 upon including irrigation this behaviour can be understood by noting that the original ahms simulation without irrigation already overestimates evapotranspiration in the summer see section 4 2 we find that this overestimation is slightly enhanced by considering irrigation as indicated by the respective square of the correlation coefficient our findings clearly show thus that evapotranspiration is overestimated by ahms in the summer and underestimated in the winter and that this behaviour is not caused by our irrigation model therefore future research should focus on elucidating this behaviour to improve the overall accuracy of ahms and its applicability to the arid and semi arid regions of the yellow river basin next we investigate the effect of irrigation on the changes in terrestrial water storage change twsc fig 14 a and fig 14b compare twsc computed from the grace based monthly observations with the prediction from the ahms simulation considering the different model components affected by water taken from rivers and groundwater for irrigation we find that the agreement of twsc between ahms simulations and grace observations improved when irrigation was taken into account with the respective r 2 values changing from 0 55 without irrigation to 0 57 with irrigation in particular the consistency between the grace based twsc and the surface water changes δ w sf improved significantly due to the inclusion of irrigation with the associated r 2 increasing from 0 23 to 0 39 moreover the difference between the grace based twsc and the soil moisture water changes δ w us was reduced moderately with the associated r 2 increasing from 0 30 to 0 36 however there are no significant improvements in the comparison between the grace based twsc and groundwater changes δ w gw fig 15 compares our model predictions with observations of the monthly fig 15a and averaged monthly fig 15b streamflow at the outlet of the middle reaches of the yellow river basin huayuankou station for 1979 1987 in fig 15a and b the comparison is made both with and without water taken from the river for irrigation in the large irrigation districts including the hetao plateau and ningxia agriculture area the results displayed in fig 15a and b shows that ahms predictions of streamflow agree more closely with observation data when irrigation is considered in the simulation consideration of irrigation has led to a reduction in the systematic errors associated with the streamflow simulations as can be seen in fig 15b the integration error has been reduced from zone to zone in the yellow river basin more precisely the nash sutcliffe model efficiency nse changed from 0 26 without irrigation to 0 55 with irrigation for the monthly streamflow changes and from 0 27 without irrigation to 0 82 with irrigation for the mean monthly streamflow changes model performance improves significantly see area a in fig 15b with consideration of irrigation however various sources for the remaining error associated with the area in fig 15 should be elucidated in future work to address the remaining error in streamflow see area b in fig 15b the influence of industrial and domestic water use as well as dam regulations should be also included in future modelling to improve the model of water use in ahms our model has provided insights into the relevance of irrigation for hydrological processes throughout the yellow river basin as can be seen from figs 6 and 7a a good agreement between predicted and observed runoff and streamflow in the basin s upstream region tangnaihe and lanzhou stations could be obtained in simulations without irrigation after calibration of the soil hydraulic conductivity however the mere calibration of this parameter could not yield a satisfactory comparison between corresponding observations and model results in the midstream area huayuankou station good quantitative agreement including the midstream area could be only found after the incorporation of our irrigation module see figs 12b and 15 therefore our model results clearly show that irrigation plays a major role in hydrological processes in the midstream area of the yellow river basin huayuankou station which is characterized by an arid and semi arid climate our irrigation module should be thus considered in future regional hydrological modelling of arid and semi arid hydrological basins 6 conclusion and outlook in the present work a regional model for long term large scale hydrological processes under consideration of irrigation in the arid and semi arid regions ahms irrig has been presented the model ahms irrig combines the land surface model the flow routing model and the groundwater model of the atmospheric and hydrological modelling system ahms with a modified irrigation scheme xu et al 2019 to quantify the dynamic irrigation amount in arid and semi arid basins specifically this study developed a dynamic irrigation model based on the soil moisture deficit method and constrained by water availability for the arid and semi arid regions moreover the channel routing model and groundwater model of the ahms has been modified here to incorporate the water uptake applicable to the long distance water supply to irrigation districts in an arid and semi arid basin furthermore the actual amount of irrigation is therefore constrained by the water availability estimated with the flow routing as well as the irrigation fractions of surface water and groundwater based on the global map of irrigation areas ahms irrig has been then applied to hydrological simulations of the yellow river basin for the period 1979 2010 to assess the impact of irrigation on the land surface processes in the basin s arid and semi arid areas to this end ahms has been first calibrated and evaluated for the yellow river basin by means of a parameter sensitivity analysis and a terrestrial water budget analysis and through a comparison of model predictions for the mean annual runoff monthly streamflow evapotranspiration and terrestrial water storage change with corresponding observation data both from in situ and remote sensing datasets furthermore to account for water consumption in the yellow river the land surface channel routing and groundwater models have been extended to account for water taken from the river for irrigation the irrigation water demand calculated by the dynamic irrigation scheme in noah mp was added to the sink term and further constrained by water availability in the flow routing and groundwater model and then actual irrigation water is distributed evenly and horizontally over the ground in the land surface model by incorporating the irrigation module into the simulation a more realistic hydrologic response near the outlet of the yellow river basin could be obtained moreover a quantitative agreement was found between the predicted discharge at the upstream gauging stations namely tangnaihe and lanzhou and the corresponding observation data a reasonable agreement of twsc between ahms simulations and observations from grace was also found monthly evapotranspiration estimated by gleam and the one modelled by ahms were found to agree well with each other with the square of correlation coefficient r 2 of about 0 98 our results thus demonstrate the capability of ahms of reproducing long term hydrological processes in the yellow river basin provided water taken from irrigation is considered in the simulation therefore the main novelties of our model development and application can be summarized as follows 1 the development of an irrigation model that considers the long distance water transfer off stream from the river to irrigation districts is fully neglected by previous irrigation models with our model the actual irrigation amount is explicitly computed using the soil moisture deficit method and constrained by the water availability estimated with the flow routing as well as the irrigation fractions of surface water and groundwater based on the global map of irrigation areas 2 the development of a regional hydrological model that is applicable to arid and semi arid regions through the incorporation of irrigation sink and source terms into the channel routing and groundwater models 3 the incorporation of the advanced earth gravity satellite grace dataset for the verification of our hydrological model and the assessment of irrigation impacts on hydrological processes in the arid and semi arid environments of the yellow river basin therefore the future application of our model has the potential to substantially improve the quantitative assessment of the irrigation impacts on hydrological processes in arid and semi arid areas by incorporating our irrigation module into the regional ahms simulation furthermore our model shall provide a helpful tool in the study of feedback effects between irrigation rainfall and temperature in arid and semi arid regions by means of online numerical simulations coupled with the weather research forecasting wrf modelling system moreover the hydrological model extended here to incorporate our irrigation module shall also find application in the study of irrigation effects on local environmental processes under consideration of changes in climate and land use type however the current version of ahms needs to be improved in different ways to more accurately represent hydrological processes in the semi arid and arid areas of the yellow river basin in the present study only soil parameters were calibrated from the land surface model the incorporation of vegetation parameters into the calibration of the numerical simulations would constitute one important model extension in future work additional measurement data of river and floodplain geometry for the channel routing model of the ahms would also improve the prediction of flood timing and peak furthermore the incorporation of various anthropogenic influences such as damming or land use change and the inclusion of the dynamic land use change e g reforestation or afforestation and damming model into ahms constitutes an open modelling task which will be important to improve the quantitative assessment of the hydrological processes in future work overall the extension of ahms presented here led to a more reliable model for predicting runoff and streamflow in arid and semi arid regions such as the yellow river basin the progress achieved in the present work shall pave the way toward a wider model application of ahms at the regional scale over the yellow river basin and other hydrological systems in future work including a broader range of climatic and environmental conditions and anthropogenic influences software availability software name ahms irrig developer cong jiang qian xia hardware requirements pc hpc system requirements linux program language fortran availability https github com jiangcong1990 ahms irrig license free and open source documentation readme and guided example in github repository credit authorship contribution statement cong jiang formal analysis methodology software validation writing original draft writing review editing eric j r parteli conceptualization supervision funding acquisition writing review editing qian xia software xin yin investigation visualization yaping shao conceptualization supervision funding acquisition writing review editing resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this research was supported by the german research foundation dfg through the heisenberg programme multiscale simulation of earth surface processes project number 434377576 the china meteorological forcing dataset cmfd is provided by national tibetan plateau data center http data tpdc ac cn daily yellow river discharge data is supported by loess plateau subcenter national earth system science data center national science technology infrastructure of china http loess geodata cn appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105531 
25527,numerical prediction of coastal inundation can be complex due to the multiple physical processes involved and typically requires two dimensional numerical model extents particularly in areas with complex along shore morphology such model domains often incur relatively high computational expense recent extreme inundation studies for wellington new zealand were executed using the numerical tool xbeach here the two dimensional physical dynamics associated with multiple small embayments and both reef and sandy beach substrates require large high spatial resolution numerical model extents informed by a multi source elevation surface xbgpu is a translation of key xbeach features into code that permits gpu based acceleration the present study presents a comparison between xbeach and xbgpu for the same numerical model configuration and extents three model resolutions were employed ranging from a typical desktop cpu based xbeach model resolution to the highest resolution model that will require high performance computing hpc scale resources two cpu hpc facilities were used and five gpus to investigate the scalability of both xbeach and xbgpu the latter ranged from desktop grade units to gpus associated with professional computing facilities xbeach scalability is investigated by mean of the speed up ratio the time saving ratio and the computational efficiency these are in reference to the computational speed of a model running on one cpu core the xbgpu speed up ratio is presented as a function of the slowest gpu direct comparisons between xbeach and xbgpu were achieved by using computational capacity as a metric the results indicate that even a desktop grade gpu can compete with the computational efficiency of hpc scale cpu facilities small model resolutions presented inefficient scaling on both high performance cpus and gpus while the high resolution model presented near linear scalability for the high performance gpus nevertheless hpcs can be efficient to solve large computational problems if enough cpus are employed keywords xbeach gpu cpu parallel computing scalability computational efficiency speedup coastal modelling data availability data will be made available on request 1 introduction coastal inundation is a complicated and multifaceted topic there are numerous physical processes contributing to this complexity including storm surge tides wave set up and infragravity waves leijnse et al 2021 the mitigation and adaptation aspect of coastal inundation is also contentious due to the wide variety of private and public property and interests harman et al 2013 gibbs 2016 buchori et al 2018 therefore this topic requires a truly transdisciplinary research approach climate change contributes to the uncertainties associated with the location and extents of coastal flooding events lin et al 2014 wang et al 2020 and thus governing authorities must be able to mitigate adapt and plan for future inundation extents frequencies and depths condon and peter sheng 2012 coastlines around the world contain various coastal and estuarine processes that could make predicting and or understanding inundation events non trivial complex coastline with a heterogeneous progression or strong alongshore variability bays reefs estuary and river mouths gullies and canyons etc makes the use of single dimensional models difficult harley et al 2011 these models are not capable of capturing two dimensional 2d processes e g 2d dependant long or infragravity wave resonance bertin et al 2018 and are thus more prone to misleading predictions more complex models including space varying phenomena are computationally intensive and have typical run times of hours to days depending on the temporal and spatial extent of the investigation and tools employed these tools could be either numerical e g xbeach roelvink et al 2009 delft3d deltares 2021 schism zhang and baptista 2008 zhang 2021 mike21 dhi group 2021 or statistical e g machine learning sonnewald et al 2021 nearshore coastal numerical models typically incorporate two or more models waves hydrodynamics sedimentology etc all interacting at each time step in addition coastal processes occur on a relatively small spatial and temporal scale e g wave breaking which require small computational grid resolutions and short time steps resulting in large computational needs and typically long simulation completion times in areas where the variation in alongshore bathymetry is small satisfactory results can be obtained from a 1d cross shore simulation this can be achieved without significant computational effort for creating probabilistic analyses e g callaghan et al 2013 but this is not an option in reef dominated environments where 2d effects are important computational times can be significantly reduced if the numerical model has been designed to run on a high performance computer hpc colloquially supercomputer typically scientists are careful to not add too many unnecessary physical processes to the computation these choices are based on the domain knowledge of the researcher and are also critical for designing an efficient numerical model access to hpc facilities can be limited e g users may need to belong to an academic institution high demand on shared resources and or the high cost of installation and maintenance most coastal engineering consultancies that offer numerical modelling services are predominantly still using desktop computing or cloud computing facilities due to these constraints many coastal numerical modelling packages are thus still developing aspects of their hpc compatibility and efficiency another positive prospect for gpu based computations is that they are increasingly readily available on cloud computing facilities as well graphics processing units gpus are an alternative computing architecture that has become increasingly popular for data intensive computations matthews 2018 from a computational point of view gpus are highly efficient at handling large data due to their multi threading capability crespo et al 2011 the inexorable development of video games and multimedia has led to gpu computing power with streaming multi processor technology increasing much faster than central processing units cpus in 2007 nvidia released compute unified device architecture cuda which makes the gpu accessible for computation like the cpu rustico et al 2014 this allowed researchers and programmers with prior experience in cpu programming to develop a multitude of applications in computational fluid dynamics computationally too expensive for desktop scale cpus to use gpus instead the fluid dynamic computational use of gpu technology was pioneered with smoothed particle hydrodynamics sph models harada et al 2007 hérault et al 2010 crespo et al 2011 indicating significant reductions in computational times compared to the cpu architecture gpu computing thus also has the potential to significantly improve the running time for more traditional hydrodynamic models used in coastal engineering and hazard modelling the present study investigates a widely used coastal inundation and morphology software called xbeach roelvink et al 2009 xbeach sandy beaches and reefs and xbeach g gravel beaches masselink et al 2014 mccall et al 2014 mccall et al 2015 have been successfully utilised in numerous studies annelies et al 2011 vousdoukas et al 2012 roelvink et al 2018 lashley et al 2020 in both one and two dimensions annelies et al 2011 the physical validation of the xbeach model used in the present study falls outside the present scope and has been performed elsewhere annelies et al 2011 instead the present study has focused on investigating and presenting the computational scalability of a complex xbeach model setup refer to section 3 these scalability tests were performed on both gpu and cpu architectures with the details regarding the execution described in section 4 for gpu architectures scalability tests are performed on xbgpu bosserelle 2022 which contains a subset of features from xbeach that have been ported to the gpu bosserelle 2014 the physical dynamics included in xbpgu are listed in section 3 1 these dynamics are relevant to coastal inundation studies and to bound infragravity wave dynamics also known as long waves roelvink et al 2018 a full description of the selection and implementation of key equations is beyond the scope of this study but an overview of the xbgpu model and computational configurations are given in section 3 2 the selective nature of xbgpu contributed to the computational speed increases presented in sections 5 and 6 1 1 aim the aim of the present study is encapsulated in two overarching research questions while also investigating the role of computational domain resolution 1 do the results of xbeach computed on cpus and xbgpu computed on gpus produce similar results e g do the resulting waves and water levels compare well given the exact same boundary conditions thus directly comparing the resulting numerical solutions and floating point errors of the physical dynamics 2 what is the scalability of xbeach computations on cpus and xbgpu computation on gpus and how do they compare with each other e g xbeach versus xbgpu 2 topography and bathymetry the open coast of the capital of aotearoa new zealand wellington was used as the example model configuration for the present study fig 1 illustrates the model domain extent and location known as the wellington south coast wellington is situated on the southern tip of the aotearoa new zealand s north island on the eastern side of cook strait and the wellington south coasts presents strong alongshore variability here numerous bays sandy pocket beaches and reefs are present the predominant wave approach direction is from the near south 190 tn but each storm has a unique wave characteristic here typical storm conditions were used as an example for the scalability and benchmarking test these conditions are presented in section 4 the model used in the present study was originally used to investigate and understand coastal inundation related to infra gravity waves historic events were simulated and the resulting coastal inundation depths were validated against photographic and video evidence of those events numerous numerical parameter settings were varied in a sensitivity analysis and the subsequently validated numerical model settings were then employed to provide wellington city council guidance with regards to their district planning the historical event validation results are currently in preparation and will be published separately the bathymetry topography utilised in the present study has been noteworthy numerous high resolution numerical studies do not have accurate bathymetry information in the intertidal and surf breaker zones the present study used remotely sensed techniques to infer the bathymetry in these zones satellite derived bathymetry sbd obtained from earth observation environmental services eomap 2022 was merged with a lidar derived digital elevation model dem and multibeam bathymetry the remaining gaps were interpolated the bathymetry topography dem was then resampled to 5 10 and 20m grid resolutions for use in the numerical simulations in fig 1 the combined topography and bathymetry are given up to the 5m land contour for the wellington south coast all the elevation data used in the numerical model and results are relative to the new zealand vertical datum 2016 hereafter nzvd 3 model description 3 1 numerical configuration xbeach has been successfully used for numerous studies around the world e g annelies et al 2011 roelvink et al 2018 the description of the underpinning governing equations is beyond the scope of the present study further details regarding the model physics may be found in roelvink et al 2009 and the xbeach manual deltares 2022 xbeach has been in development for several years and includes many coastal physical phenomena here only the surf beat mode is considered e g not the non hydrostatic wave resolving mode xbgpu on the other hand has been used in only a few studies bosserelle 2014 bosserelle et al 2021 and is a separate project and software from xbeach but uses a subset of xbeach s core features translated so that calculations are performed on gpus xbgpu is only a lightweight port of xbeach and does not contain all the diversity of solvers available for wave flow and sediment transport that xbeach offers for hydrodynamics xbgpu only solves the 2nd order wave action balance for waves and the second order st venant equation for flow similar to that available from the kingday release of xbeach but does not offer for example any of the lower order or single direction solvers made available in xbeach below is a list of the features of xbeach available for gpu computations in xbgpu the 2nd order flow solver the 2nd order wave solver for groups wave breaking wave current interactions space varying bottom friction for both waves and currents only regular rectangular grids are currently supported morphological updating and sediment transport and a single sediment class and layer the model configurations developed in the present study consisted of various sensitivity analyses these were performed on the major model parameter settings including specifically bottom roughness and wave breaking parameters as an example the reef areas are rougher than the sandy areas thus these will present more friction to water and wave movement for accurate wave run up modelling these must be considered through a series of simulations the most stable and accurate simulations were achieved with a spatially varying roughness the distinction was between reef and sandy areas all the settings employed were well within international widely accepted parameter settings for these two substrate descriptions deltares 2022 the main parameters are presented in table 1 the roelvink et al 2009 wave dissipation model was employed together with the smagorinsky formulation for calculating viscosity with a smagorinsky coefficient equal to 0 3 in both models a courant number cfl vousdoukas et al 2012 was employed that ensured model stability together with reasonable computational times in the present study a value of 0 3 was chosen as the maximum cfl number all simulations were executed for a real world simulation period of 3 h hydrodynamic spin up was achieved in approximately 320 350s for all resolutions this allowed for the realistic determination of wave run up inundation extents typical inundation simulation periods will be closer to 9 h typical storm duration but 3 h of model time was more feasible due to the large amounts of simulation that had to be completed for the purposes of this study water levels were kept at the maximum water level for the duration of the simulations thus storm tide levels were employed as 1m relative to nzvd the offshore wave parameters used for creating the stochastic wave time series and thus the bound infragravity waves had a significant wave height of 6m a peak period of 15 5s and a peak direction of 190 tn the wave timeseries length was assumed to be 1 h in other words the time range with which the bound infragravity waves were calculated these conditions are based on typical offshore wave conditions during a storm at the wellington south coast godoi et al 2017 stevens o callaghan et al 2021 often xbeach models are executed with around 12 000 computational grid cells e g roelvink et al 2018 presented tests with a xbeach model with a domain size of 1 2 km longshore and 1 km cross shore at a 10m resolution the high resolution domain utilised for tests in the present study was approximately 8 5 km which at the highest model resolution is a significant computational challenge to be able to get an understanding of the computational occupancy of both the cpus and gpus three model resolutions are implemented these range from arguably low resolution models to high resolution models table 2 shows the rectangular model resolutions and dimensions used the same model extent was used to ensure the same substrate complexities are covered and thus avoid run time biases due to a faster or slower converging numerical configuration 3 2 computational configuration 3 2 1 xbgpu while a full description of xbgpu implementation is beyond the scope of the present study it is described in bosserelle 2014 a brief description of the gpu parallelisation is presented here the xbgpu code is written in cuda c nvidia 2022 and therefore is based on a complete rewriting and redesign from the original xbeach fortran code although alternatives to cuda exist e g opencl openacc and openmp 4 using cuda allowed for the model to be redesigned for gpu use using cuda programming for a gpu is similar to programming for cpu executions in cuda the programmer can create functions hereafter kernels that are called from the cpu but executed on the gpu each kernel reads data from the gpu memory performs the parallel calculation and stores the result back in the gpu memory arrays in the gpu memory are only transferred back to the cpu memory for writing output thus reducing memory transfer overheads xbgpu performs the computations using single precision arithmetic which offers increased performance on gpus while leading to relatively small errors of o 10 3 m for rms wave height and o 10 2 m in water level and o 10 2 m s for current velocity morphodynamics is not used in the simulations in this study so the implication of the impact of single precision computation is not discussed here however it is worth noting that morphodynamics can behave in a chaotic way and may lead to diverging results from small initial difference on the same order as machine precision stecca and hicks 2022 fig 2 presents schematic illustration where the communication between the cpu and gpu architectures using cuda is explained between each kernel and through the time loop of the model the data remains on the gpu unless it is not needed anymore in which case the memory is freed transfers between the gpu and the cpu are relatively slow and therefore only used when initializing the model for boundary conditions transfer and occasionally to save the model results refer to the black arrows in fig 2 while description of gpu computing is beyond the scope of this study a short description of the gpu kernel scheduling follows during the execution of each kernel the computational grid is automatically divided into blocks of predefined number of threads workers in the gpu context the gpu then queues these blocks and performs the calculation for as many blocks as it can hold at once and each gpu thread performs calculations on one computational cell with a unique index calculated from the block thread index a commonly used parallelisation strategy for gridded models on multi core node architectures is to break up the model into sub domains and perform the calculation independently on each sub domain on multi cpus the performance of such a strategy is bound by the speed of memory transfer between cores the speed ups observed on cpus are usually up to the point where inter core node communication becomes more time consuming rautenbach et al 2021 however gpus are designed to overcome this latency by using fast memory transfer this major difference leads to a different approach for choosing the size of the sub domain with the cuda architecture the size of each sub domain is chosen so that it occupies as many cores as possible on the gpu while remaining small enough so that the memory transfers are short in xbgpu the size of the sub domain was chosen as 16 16 cells running with 256 threads for each block leads to a good occupancy of the model for most of the kernels depending on the model resolution it also makes it easy to design a bathymetry grid with a number of rows and columns proportional to 16 and thus makes optimum use of the gpu an optimization concern was to split the model equations into coherent kernels in cuda each kernel can perform a limited amount of instructions each time they are called to address this limitation the original xbeach code is partitioned into many functions each equivalent to a computation grid iteration each performing a small part of the model calculation on the gpu at a time although modern gpus are capable of double precision calculation the performance for single precision calculation is significantly higher thus xbgpu presented here uses exclusively single precision floating point 3 2 2 xbeach xbgpu is used only on gpu enabled systems for comparison with traditional hpc and to investigate scalability the cpu xbeach model was run on two commonwealth scientific and industrial research organisation csiro operated hpc systems in australia see section 4 2 for further system details xbeach was compiled with message passing interface mpi communications enabled permitting the model to be run across numerous cores and multiple hardware nodes in this mode of xbeach a serial job is not possible xbeach mpi uses one core as a model control and decomposes the grid onto the remaining n 1 cores as such the benchmarking comparison when running xbeach in mpi mode is run with 2 cores this is equivalent to a non mpi serial xbeach run because all computations are carried out on a single compute core in order to investigate the scalability an increasing number of compute cores n are requested for the model execution for each core count the model domain is decomposed into n 1 sub grids if n 1 is a prime number the decomposed domain will be computationally inefficient and a lot of communications will be wasted in halo passing thus there might be suboptimal scaling curves compared to a configuration of the model that used all n cores for grid decomposition nevertheless in the present study a typical approach is followed by scaling up by powers of two and integer node counts 3 2 3 xbeach versus xbgpu xbeach is widely used and validated these validations include both reef pearson et al 2017 and beach elsayed and oumeraci 2017 coastal environments xbgpu has previously been tested against direct xbeach solutions and in reef environments bosserelle et al 2021 the south coast of wellington represents a mixture of these substrates together with embayments that might be prone to long wave resonance bellotti 2007 in order to verify that xbeach and xbgpu are essentially doing the same operation a comparison is performed as presented in figs 3 and 4 fig 3 focuses on the root mean square rms wave heights h rms while fig 4 provides insight into the water level z s comparisons here h rms refers to the square root of the average of the squares of all the wave heights at that particular grid cell these values are approximately related to significant wave height values h m0 divided by 1 4 both models were forced with the same boundary conditions to ensure that statistical differences associated with generating the boundary conditions do not influence the comparison in both cases an accompanying instantaneous output from xbgpu provides context to the error margins presented for example in fig 3 b the differences are below 0 02m while the h rms wave crests approached 10m refer to fig 3 a the differences presented in fig 3 b are for a single timestep only after spinning up fig 4 b represents the mean difference over an output timestep thus over a 20 min simulation time fig 4 a sill represent an instantaneous view to illustrate the size of the bound long infragravity wave represented by water levels to understand the differences between xbgpu and xbeach in a more holistic manner the average difference over an output time step 20 min of the whole output domain was calculated the domain and time step averaged values were h rms 1 2448 10 4 m and zs 0 0013m respectively these values are based on the 20m resolution model and illustrates that both xbgpu and xbeach produce similar results the slight differences that are observed are potentially due to floating point errors in the precision assumptions xbgpu is currently only uses single precision calculations while xbeach was run with double precision the single precision execution of xbeach could not be amended by just using the master definition file flag it should also be noted that differences in floating point units fpus could also contribute to slight computational differences 4 methodology the present study was performed on two cpu clusters namely pearcey and petrichor the specifications of these clusters may be found here csiro 2022 the pearcey cpu cluster consists of 360 intel xeon e5 2660v3 nodes with 20 cores per node the new petrichor system consists of amd epyc 7543 nodes with 64 cores per node petrichor was previously called ppts pre production test system at the time this benchmarking was performed but has subsequently been upgraded with more nodes and better network accessibility and thus launched to the full hpc environment as petrichor both these machines are operated by csiro s scientific computing group as moderate scale hpcs two cpu clusters were used in the present study to better represent the generalisation of the benchmarking experiments presented here five different gpu cards were implemented in the present study they represent a range of consumer grade to hpc grade gpus that are generally easily accessible affordable to cards that are generally more expensive and associated with academia or data science and data mining driven supercomputing the new zealand based hpc gpus used in the present study are housed in the new zealand escience infrastructure nesi nesi 2022 while the australian based gpu was housed in the bracewell supercomputer csiro 2022 only gpu computations were performed on nesi the gpus and the associated computing performance and where they were executed used in the present study are the nvidia 1 a100 tensor core 19 5 teraflops nesi 2 tesla p100 9 2 teraflops bracewell nesi 3 geforce rtx 6 45 teraflops desktop 4 t500 3 03 teraflops laptop and the 5 quadro p620 1 39 teraflops desktop where 1 teraflops floating point operations per second 1012 flops most research studies refer to the benchmarking and scalability of numerical models as a function of computational cores rautenbach et al 2021 this is feasible for cpu clusters but ill defined for gpus here two metrics will be elucidated first only the scalability metrics for the two cpu clusters and then the joint performance summary as a function of flops the latter will change as the number of cores are increased all the scalability parameters are calculated in comparison with a series computation on a single cpu core the metrics used in the present study are the speed up time saving efficiency ratios and scalability as a function of the other three parameters rautenbach et al 2021 the speed up ratio is given as 1 s p t 1 t p where t 1 is the time in seconds it takes for a sequential computation on one thread and t p is the time a simulation takes with p computational cores rautenbach et al 2021 zhang et al 2014 the time saving ratio is given by 2 t s p t 1 t p t 1 and the efficiency ratio is defined as 3 e p s p p which may be multiplied by 100 to give an efficiency percentage in order to effectively test the scalability on the cpu clusters the following sequence of cores were tested 2 3 4 8 10 16 20 32 40 48 60 64 80 100 125 and 256 these thread core counts were implemented for both cpu clusters the 2 thread core experiment was considered the series computation as one thread core fulfils a supervising role and thus do not directly add to the computation power because the gpu architecture does not scale with regards to number of cores and nodes floating point operations per second flops are used as scaling metric in equation 4 a similar metric to the speed up ratio given in equation 1 is given thus the speed up ratio is calculated with regards to the slowest gpu the p620 in order to elucidate some aspects of the increasing gpu power related to computational time and thus scalability the relative gpu speed up is therefore given as 4 s g p u t p 620 t g p u where t p620 is the time the computation took on the p620 gpu and t gpu are all the other gpus computational times where the denotes gpu number or name 5 results the computational scalability metric described in section 4 was employed to elucidate the performance of both the cpu clusters and gpus in fig 5 the results are presented fig 5 a c show only the cpu scalability results as the x axes are the threads cores count fig 5 d describes the relative gpu scalability as no thread count is available for the gpu architecture the speed up ratio relative to the slowest gpu is presented refer to equation 4 in fig 5 a and d the 1 1 line is also plotted this was done to simplify the interpretation of the results as ideal scalability will be achieved if the computational time scales with the resource allocation in other words the closer the results are to the 1 1 line the more scalable the problem is fig 5 d also represents all five gpu cards employed in the present study and for all three model resolutions each marker corresponds to a different gpu as labelled on the plot in all the other plots the model resolutions are grouped by colour while the particular cpu cluster pearcey or petrichor is identified via the separate markers refer to the plot legend note that the axis of fig 5 b are on a log10 scale in order to visualise the results better in fig 6 a direct comparison between the cpu clusters and the gpu cards is provided via a log10 scale due to the different architectures the theoretical accessible hardware floating point operations per second flops were used as scaling metric this enabled the direct comparison of the wall clock total simulation run times scalability the flops of the cpus were calculated by taking the flops per cores and multiplying it by the number of cores the gpu flops were used as described by the manufacturer all the pearcey results are indicated via the black lines while all the petrichor results are given in grey like fig 5 d the gpu results are given via the coloured markers each colour denoting a separate model resolution here the direct flops are given together with the total wall clock time 6 discussion in fig 5 a the most significant speed ups are obtained in the medium and high resolution models with cpu clusters the inter core and inter nodal communication is not negligible a balance must be struck between the time saved by deploying more resources versus the increasing communication time associated with the message passing interface mpi strategy in the case of the low resolution model refer to table 2 the optimization point was reached and thus the speed up ratio started to plateau or even slightly decrease for both pearcey and petrichor the medium and high resolution models revealed similar speed up ratio trends with a greater deviation from the 1 1 line with more cores used for most of the models and cpu clusters the speed up ratio was approximately 1 1 for core counts below approximately 20 except for pearcey with the low resolution model in fig 5 b the time saving ratio is given most of the experiments plateaued by using approximately 30 cores interestingly the medium resolution model had a steeper increase in time saving for lower core counts albeit it being marginal due to the log10 scale minor differences are visible the time saving ration presents an asymptotic behaviour as t p tends to zero if a deviation from the asymptotic behaviour is observed at higher core counts it would be an indication that t p is increasing again and thus that the inter core communication time becomes more expensive than the additional computational power in fig 5 c the computational efficiency shows a similar result as the speed up ratio given in fig 5 a the low resolution models lose efficiency the fastest both the medium and high resolution models produced similar efficiency results xbeach is not typically regarded as a well scaling model however the medium and high resolution results presented here indicate it is as good as can be expected for this type of hydrodynamic model in this case the plots indicate the higher resolutions are sufficiently large to justify the additional resourcing of more cores all these results considered using approximately 50 cores would be a good compromise between cpu resourcing efficiency and time saving ratios on a machine like petrichor with 64 core nodes using one whole node is reasonable in general these results refute the misconception that xbeach models does not scale well on cpu clusters but also reveal similar scalability trends observed in other software packages e g rautenbach et al 2021 in fig 5 d the gpu card performance is summarised due to the physical architecture differences the relative speed up is given thus both the flops and the speed up are relative to the p620 gpu hence why the first data point is on the 1 1 line as a further example the a100 is almost 15 times more powerful than the p620 from these results the p100 and the a100 perform better with the higher resolution models for the p100 the high resolution model almost produced an ideal scalability the t500 produced similar results for all the model resolutions the p100 also performed poorly with the low resolution model this may be because the domain size and resolution are in fact too small to optimally make use of the p100 architecture fig 6 best summarises the results it compares the actual wall clock times of the total simulations directly to flops the three model resolutions are clear and both the cpu clusters and gpu group nicely per resolution level l m and h described in table 2 this also makes logical sense as a similar resource in flops thus produce a similar simulation time petrichor produced faster simulation times than pearcey due to the better intra and inter node communication the limitation with the low resolution models are again clear here the increase in simulation time for the cpus are attributed to halo passing communication times becoming more expensive than the additional flops add to solving the problem the p100 and a100 are research quality gpus even 256 cpus could not compete with the a100 for all model resolutions the p620 t500 and the rtx are desktop and laptop grade gpus this implies that they are affordable and easily accessible in numerous developing countries hpc computing resources are still not readily available not even to research institutes even the weakest p620 gpu has the equivalent performance of a 32 core cpu computer while the rtx was approximately equal to a 125 thread cpu cluster over and above the relative computational power this resource is available on a desktop or laptop machine that is easily portable and manageable for countries and institutes who do not already have cpu clusters gpus are a great alternative to professional computing abilities the total cost however including electrical power consumption and capital cost was not fully explored in the present study these lightweight gpus are even attractive to engineering and defence applications where operations are proprietary time sensitive or performed on mobile units for example where hpc access is impractical such as on sea going vessel in real world practical applications hundreds of simulations are often required to truly explore and understand various climate change scenarios and the associated mitigation options even detailed engineering design model calibration or ensemble forecasting might require large numbers of scenarios modelled for these reasons the computational efficiency of numerical models is paramount even slight increases in computational efficiency could result in substantial savings in real world applications over and above this computational efficiency thus also allows scientists and engineers to simulate larger regions at higher resolutions given that high quality topography and bathymetry data is available 6 1 summary and conclusion coastal inundation studies are becoming increasing more important given the infrastructure and environmental threats projected from climate change to be able to inform coastal adaptation strategies accurate and high resolution estimates of potential coastal inundation patterns are required one method of achieving this is by making use of numerical models these models can be computationally very intensive and thus restrict the domain size resolution and temporal scales simulated the present study aims to present the scalability of a well known coastal numerical modelling tool named xbeach roelvink et al 2018 a few key functionalities of xbeach have recently been translated into a version that can be executed on gpu infrastructure called xbgpu bosserelle 2014 bosserelle et al 2021 the present study showed that the h rms and water levels produced by both implementations of xbeach yield very similar results thus allowing the accuracy assumption of previous validation work done for xbeach executed on cpus to be translated to simulation executed with xbgpu on gpus xbeach scalability experiments were done on two cpu clusters pearcey and petrichor csiro 2022 previously published metrics were used to elucidate the scalability via the speed up ratio time saving ratio and efficiency a range of computational cores were used and compared with a single core computation all these experiments were done for three model resolutions the highest resolution of these presenting a serious challenge for typical desktop computational studies only hydro and wave dynamics were investigated in the present study and further investigation into sediment and morphodynamics including single vs double precision accuracies are required bosserelle et al 2021 alongside the two cpu clusters five gpus were used to investigate the computational scalability of xbgpu the exact same model resolutions and physical parameter setting were used in order to compare the results from xbeach and xbgpu more directly floating point operations per second flops were used as scaling metric as opposed to the typical cpu core count the result was that even a desktop grade gpu could compete with a hpc scale cpu cluster having said that existing cpu clusters still prove to be powerful and able to solve large computationally demanding problems the present study may encourage xbeach developers to incorporate the kernel developed for xbgpu and thus enable researchers to make a better informed decision with regards to the investment of new computational facilities and might motivate more numerical codes to be translated into gpu compatible code author statement cr wrote manuscript conceptualised research questions data processing ran scaling tests on nesi gpus compiled results developed original wellington based xbeach and xbgpu surf beat model ct ran cpu scaling tests on hpcs assisted in manuscript preparation db ran gpu tests on bracewell and kubernetes cluster assisted in manuscript preparation rh manuscript review and domain expertise contribution cb assisted in writing the manuscript lead the xbgpu development translation technical supervisor for both xbeach and xbgpu surf beat models domain expertise contribution funding this research was funded by the national institute of water and atmospheric research niwa taihoro nukurangi strategic scientific investment fund work program on hazards exposure and vulnerability carh2202 the authors wish to acknowledge the use of new zealand escience infrastructure nesi high performance computing facilities as part of this research new zealand s national facilities are provided by nesi and funded jointly by nesi s collaborator institutions and through the ministry of business innovation employment s research infrastructure programme https www nesi org nz this project was also supported by resources and expertise provided by csiro imt scientific computing https ror org 02cgy3m12 finally this work was also supported in part by the national research foundation of south africa grant no 116359 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
25527,numerical prediction of coastal inundation can be complex due to the multiple physical processes involved and typically requires two dimensional numerical model extents particularly in areas with complex along shore morphology such model domains often incur relatively high computational expense recent extreme inundation studies for wellington new zealand were executed using the numerical tool xbeach here the two dimensional physical dynamics associated with multiple small embayments and both reef and sandy beach substrates require large high spatial resolution numerical model extents informed by a multi source elevation surface xbgpu is a translation of key xbeach features into code that permits gpu based acceleration the present study presents a comparison between xbeach and xbgpu for the same numerical model configuration and extents three model resolutions were employed ranging from a typical desktop cpu based xbeach model resolution to the highest resolution model that will require high performance computing hpc scale resources two cpu hpc facilities were used and five gpus to investigate the scalability of both xbeach and xbgpu the latter ranged from desktop grade units to gpus associated with professional computing facilities xbeach scalability is investigated by mean of the speed up ratio the time saving ratio and the computational efficiency these are in reference to the computational speed of a model running on one cpu core the xbgpu speed up ratio is presented as a function of the slowest gpu direct comparisons between xbeach and xbgpu were achieved by using computational capacity as a metric the results indicate that even a desktop grade gpu can compete with the computational efficiency of hpc scale cpu facilities small model resolutions presented inefficient scaling on both high performance cpus and gpus while the high resolution model presented near linear scalability for the high performance gpus nevertheless hpcs can be efficient to solve large computational problems if enough cpus are employed keywords xbeach gpu cpu parallel computing scalability computational efficiency speedup coastal modelling data availability data will be made available on request 1 introduction coastal inundation is a complicated and multifaceted topic there are numerous physical processes contributing to this complexity including storm surge tides wave set up and infragravity waves leijnse et al 2021 the mitigation and adaptation aspect of coastal inundation is also contentious due to the wide variety of private and public property and interests harman et al 2013 gibbs 2016 buchori et al 2018 therefore this topic requires a truly transdisciplinary research approach climate change contributes to the uncertainties associated with the location and extents of coastal flooding events lin et al 2014 wang et al 2020 and thus governing authorities must be able to mitigate adapt and plan for future inundation extents frequencies and depths condon and peter sheng 2012 coastlines around the world contain various coastal and estuarine processes that could make predicting and or understanding inundation events non trivial complex coastline with a heterogeneous progression or strong alongshore variability bays reefs estuary and river mouths gullies and canyons etc makes the use of single dimensional models difficult harley et al 2011 these models are not capable of capturing two dimensional 2d processes e g 2d dependant long or infragravity wave resonance bertin et al 2018 and are thus more prone to misleading predictions more complex models including space varying phenomena are computationally intensive and have typical run times of hours to days depending on the temporal and spatial extent of the investigation and tools employed these tools could be either numerical e g xbeach roelvink et al 2009 delft3d deltares 2021 schism zhang and baptista 2008 zhang 2021 mike21 dhi group 2021 or statistical e g machine learning sonnewald et al 2021 nearshore coastal numerical models typically incorporate two or more models waves hydrodynamics sedimentology etc all interacting at each time step in addition coastal processes occur on a relatively small spatial and temporal scale e g wave breaking which require small computational grid resolutions and short time steps resulting in large computational needs and typically long simulation completion times in areas where the variation in alongshore bathymetry is small satisfactory results can be obtained from a 1d cross shore simulation this can be achieved without significant computational effort for creating probabilistic analyses e g callaghan et al 2013 but this is not an option in reef dominated environments where 2d effects are important computational times can be significantly reduced if the numerical model has been designed to run on a high performance computer hpc colloquially supercomputer typically scientists are careful to not add too many unnecessary physical processes to the computation these choices are based on the domain knowledge of the researcher and are also critical for designing an efficient numerical model access to hpc facilities can be limited e g users may need to belong to an academic institution high demand on shared resources and or the high cost of installation and maintenance most coastal engineering consultancies that offer numerical modelling services are predominantly still using desktop computing or cloud computing facilities due to these constraints many coastal numerical modelling packages are thus still developing aspects of their hpc compatibility and efficiency another positive prospect for gpu based computations is that they are increasingly readily available on cloud computing facilities as well graphics processing units gpus are an alternative computing architecture that has become increasingly popular for data intensive computations matthews 2018 from a computational point of view gpus are highly efficient at handling large data due to their multi threading capability crespo et al 2011 the inexorable development of video games and multimedia has led to gpu computing power with streaming multi processor technology increasing much faster than central processing units cpus in 2007 nvidia released compute unified device architecture cuda which makes the gpu accessible for computation like the cpu rustico et al 2014 this allowed researchers and programmers with prior experience in cpu programming to develop a multitude of applications in computational fluid dynamics computationally too expensive for desktop scale cpus to use gpus instead the fluid dynamic computational use of gpu technology was pioneered with smoothed particle hydrodynamics sph models harada et al 2007 hérault et al 2010 crespo et al 2011 indicating significant reductions in computational times compared to the cpu architecture gpu computing thus also has the potential to significantly improve the running time for more traditional hydrodynamic models used in coastal engineering and hazard modelling the present study investigates a widely used coastal inundation and morphology software called xbeach roelvink et al 2009 xbeach sandy beaches and reefs and xbeach g gravel beaches masselink et al 2014 mccall et al 2014 mccall et al 2015 have been successfully utilised in numerous studies annelies et al 2011 vousdoukas et al 2012 roelvink et al 2018 lashley et al 2020 in both one and two dimensions annelies et al 2011 the physical validation of the xbeach model used in the present study falls outside the present scope and has been performed elsewhere annelies et al 2011 instead the present study has focused on investigating and presenting the computational scalability of a complex xbeach model setup refer to section 3 these scalability tests were performed on both gpu and cpu architectures with the details regarding the execution described in section 4 for gpu architectures scalability tests are performed on xbgpu bosserelle 2022 which contains a subset of features from xbeach that have been ported to the gpu bosserelle 2014 the physical dynamics included in xbpgu are listed in section 3 1 these dynamics are relevant to coastal inundation studies and to bound infragravity wave dynamics also known as long waves roelvink et al 2018 a full description of the selection and implementation of key equations is beyond the scope of this study but an overview of the xbgpu model and computational configurations are given in section 3 2 the selective nature of xbgpu contributed to the computational speed increases presented in sections 5 and 6 1 1 aim the aim of the present study is encapsulated in two overarching research questions while also investigating the role of computational domain resolution 1 do the results of xbeach computed on cpus and xbgpu computed on gpus produce similar results e g do the resulting waves and water levels compare well given the exact same boundary conditions thus directly comparing the resulting numerical solutions and floating point errors of the physical dynamics 2 what is the scalability of xbeach computations on cpus and xbgpu computation on gpus and how do they compare with each other e g xbeach versus xbgpu 2 topography and bathymetry the open coast of the capital of aotearoa new zealand wellington was used as the example model configuration for the present study fig 1 illustrates the model domain extent and location known as the wellington south coast wellington is situated on the southern tip of the aotearoa new zealand s north island on the eastern side of cook strait and the wellington south coasts presents strong alongshore variability here numerous bays sandy pocket beaches and reefs are present the predominant wave approach direction is from the near south 190 tn but each storm has a unique wave characteristic here typical storm conditions were used as an example for the scalability and benchmarking test these conditions are presented in section 4 the model used in the present study was originally used to investigate and understand coastal inundation related to infra gravity waves historic events were simulated and the resulting coastal inundation depths were validated against photographic and video evidence of those events numerous numerical parameter settings were varied in a sensitivity analysis and the subsequently validated numerical model settings were then employed to provide wellington city council guidance with regards to their district planning the historical event validation results are currently in preparation and will be published separately the bathymetry topography utilised in the present study has been noteworthy numerous high resolution numerical studies do not have accurate bathymetry information in the intertidal and surf breaker zones the present study used remotely sensed techniques to infer the bathymetry in these zones satellite derived bathymetry sbd obtained from earth observation environmental services eomap 2022 was merged with a lidar derived digital elevation model dem and multibeam bathymetry the remaining gaps were interpolated the bathymetry topography dem was then resampled to 5 10 and 20m grid resolutions for use in the numerical simulations in fig 1 the combined topography and bathymetry are given up to the 5m land contour for the wellington south coast all the elevation data used in the numerical model and results are relative to the new zealand vertical datum 2016 hereafter nzvd 3 model description 3 1 numerical configuration xbeach has been successfully used for numerous studies around the world e g annelies et al 2011 roelvink et al 2018 the description of the underpinning governing equations is beyond the scope of the present study further details regarding the model physics may be found in roelvink et al 2009 and the xbeach manual deltares 2022 xbeach has been in development for several years and includes many coastal physical phenomena here only the surf beat mode is considered e g not the non hydrostatic wave resolving mode xbgpu on the other hand has been used in only a few studies bosserelle 2014 bosserelle et al 2021 and is a separate project and software from xbeach but uses a subset of xbeach s core features translated so that calculations are performed on gpus xbgpu is only a lightweight port of xbeach and does not contain all the diversity of solvers available for wave flow and sediment transport that xbeach offers for hydrodynamics xbgpu only solves the 2nd order wave action balance for waves and the second order st venant equation for flow similar to that available from the kingday release of xbeach but does not offer for example any of the lower order or single direction solvers made available in xbeach below is a list of the features of xbeach available for gpu computations in xbgpu the 2nd order flow solver the 2nd order wave solver for groups wave breaking wave current interactions space varying bottom friction for both waves and currents only regular rectangular grids are currently supported morphological updating and sediment transport and a single sediment class and layer the model configurations developed in the present study consisted of various sensitivity analyses these were performed on the major model parameter settings including specifically bottom roughness and wave breaking parameters as an example the reef areas are rougher than the sandy areas thus these will present more friction to water and wave movement for accurate wave run up modelling these must be considered through a series of simulations the most stable and accurate simulations were achieved with a spatially varying roughness the distinction was between reef and sandy areas all the settings employed were well within international widely accepted parameter settings for these two substrate descriptions deltares 2022 the main parameters are presented in table 1 the roelvink et al 2009 wave dissipation model was employed together with the smagorinsky formulation for calculating viscosity with a smagorinsky coefficient equal to 0 3 in both models a courant number cfl vousdoukas et al 2012 was employed that ensured model stability together with reasonable computational times in the present study a value of 0 3 was chosen as the maximum cfl number all simulations were executed for a real world simulation period of 3 h hydrodynamic spin up was achieved in approximately 320 350s for all resolutions this allowed for the realistic determination of wave run up inundation extents typical inundation simulation periods will be closer to 9 h typical storm duration but 3 h of model time was more feasible due to the large amounts of simulation that had to be completed for the purposes of this study water levels were kept at the maximum water level for the duration of the simulations thus storm tide levels were employed as 1m relative to nzvd the offshore wave parameters used for creating the stochastic wave time series and thus the bound infragravity waves had a significant wave height of 6m a peak period of 15 5s and a peak direction of 190 tn the wave timeseries length was assumed to be 1 h in other words the time range with which the bound infragravity waves were calculated these conditions are based on typical offshore wave conditions during a storm at the wellington south coast godoi et al 2017 stevens o callaghan et al 2021 often xbeach models are executed with around 12 000 computational grid cells e g roelvink et al 2018 presented tests with a xbeach model with a domain size of 1 2 km longshore and 1 km cross shore at a 10m resolution the high resolution domain utilised for tests in the present study was approximately 8 5 km which at the highest model resolution is a significant computational challenge to be able to get an understanding of the computational occupancy of both the cpus and gpus three model resolutions are implemented these range from arguably low resolution models to high resolution models table 2 shows the rectangular model resolutions and dimensions used the same model extent was used to ensure the same substrate complexities are covered and thus avoid run time biases due to a faster or slower converging numerical configuration 3 2 computational configuration 3 2 1 xbgpu while a full description of xbgpu implementation is beyond the scope of the present study it is described in bosserelle 2014 a brief description of the gpu parallelisation is presented here the xbgpu code is written in cuda c nvidia 2022 and therefore is based on a complete rewriting and redesign from the original xbeach fortran code although alternatives to cuda exist e g opencl openacc and openmp 4 using cuda allowed for the model to be redesigned for gpu use using cuda programming for a gpu is similar to programming for cpu executions in cuda the programmer can create functions hereafter kernels that are called from the cpu but executed on the gpu each kernel reads data from the gpu memory performs the parallel calculation and stores the result back in the gpu memory arrays in the gpu memory are only transferred back to the cpu memory for writing output thus reducing memory transfer overheads xbgpu performs the computations using single precision arithmetic which offers increased performance on gpus while leading to relatively small errors of o 10 3 m for rms wave height and o 10 2 m in water level and o 10 2 m s for current velocity morphodynamics is not used in the simulations in this study so the implication of the impact of single precision computation is not discussed here however it is worth noting that morphodynamics can behave in a chaotic way and may lead to diverging results from small initial difference on the same order as machine precision stecca and hicks 2022 fig 2 presents schematic illustration where the communication between the cpu and gpu architectures using cuda is explained between each kernel and through the time loop of the model the data remains on the gpu unless it is not needed anymore in which case the memory is freed transfers between the gpu and the cpu are relatively slow and therefore only used when initializing the model for boundary conditions transfer and occasionally to save the model results refer to the black arrows in fig 2 while description of gpu computing is beyond the scope of this study a short description of the gpu kernel scheduling follows during the execution of each kernel the computational grid is automatically divided into blocks of predefined number of threads workers in the gpu context the gpu then queues these blocks and performs the calculation for as many blocks as it can hold at once and each gpu thread performs calculations on one computational cell with a unique index calculated from the block thread index a commonly used parallelisation strategy for gridded models on multi core node architectures is to break up the model into sub domains and perform the calculation independently on each sub domain on multi cpus the performance of such a strategy is bound by the speed of memory transfer between cores the speed ups observed on cpus are usually up to the point where inter core node communication becomes more time consuming rautenbach et al 2021 however gpus are designed to overcome this latency by using fast memory transfer this major difference leads to a different approach for choosing the size of the sub domain with the cuda architecture the size of each sub domain is chosen so that it occupies as many cores as possible on the gpu while remaining small enough so that the memory transfers are short in xbgpu the size of the sub domain was chosen as 16 16 cells running with 256 threads for each block leads to a good occupancy of the model for most of the kernels depending on the model resolution it also makes it easy to design a bathymetry grid with a number of rows and columns proportional to 16 and thus makes optimum use of the gpu an optimization concern was to split the model equations into coherent kernels in cuda each kernel can perform a limited amount of instructions each time they are called to address this limitation the original xbeach code is partitioned into many functions each equivalent to a computation grid iteration each performing a small part of the model calculation on the gpu at a time although modern gpus are capable of double precision calculation the performance for single precision calculation is significantly higher thus xbgpu presented here uses exclusively single precision floating point 3 2 2 xbeach xbgpu is used only on gpu enabled systems for comparison with traditional hpc and to investigate scalability the cpu xbeach model was run on two commonwealth scientific and industrial research organisation csiro operated hpc systems in australia see section 4 2 for further system details xbeach was compiled with message passing interface mpi communications enabled permitting the model to be run across numerous cores and multiple hardware nodes in this mode of xbeach a serial job is not possible xbeach mpi uses one core as a model control and decomposes the grid onto the remaining n 1 cores as such the benchmarking comparison when running xbeach in mpi mode is run with 2 cores this is equivalent to a non mpi serial xbeach run because all computations are carried out on a single compute core in order to investigate the scalability an increasing number of compute cores n are requested for the model execution for each core count the model domain is decomposed into n 1 sub grids if n 1 is a prime number the decomposed domain will be computationally inefficient and a lot of communications will be wasted in halo passing thus there might be suboptimal scaling curves compared to a configuration of the model that used all n cores for grid decomposition nevertheless in the present study a typical approach is followed by scaling up by powers of two and integer node counts 3 2 3 xbeach versus xbgpu xbeach is widely used and validated these validations include both reef pearson et al 2017 and beach elsayed and oumeraci 2017 coastal environments xbgpu has previously been tested against direct xbeach solutions and in reef environments bosserelle et al 2021 the south coast of wellington represents a mixture of these substrates together with embayments that might be prone to long wave resonance bellotti 2007 in order to verify that xbeach and xbgpu are essentially doing the same operation a comparison is performed as presented in figs 3 and 4 fig 3 focuses on the root mean square rms wave heights h rms while fig 4 provides insight into the water level z s comparisons here h rms refers to the square root of the average of the squares of all the wave heights at that particular grid cell these values are approximately related to significant wave height values h m0 divided by 1 4 both models were forced with the same boundary conditions to ensure that statistical differences associated with generating the boundary conditions do not influence the comparison in both cases an accompanying instantaneous output from xbgpu provides context to the error margins presented for example in fig 3 b the differences are below 0 02m while the h rms wave crests approached 10m refer to fig 3 a the differences presented in fig 3 b are for a single timestep only after spinning up fig 4 b represents the mean difference over an output timestep thus over a 20 min simulation time fig 4 a sill represent an instantaneous view to illustrate the size of the bound long infragravity wave represented by water levels to understand the differences between xbgpu and xbeach in a more holistic manner the average difference over an output time step 20 min of the whole output domain was calculated the domain and time step averaged values were h rms 1 2448 10 4 m and zs 0 0013m respectively these values are based on the 20m resolution model and illustrates that both xbgpu and xbeach produce similar results the slight differences that are observed are potentially due to floating point errors in the precision assumptions xbgpu is currently only uses single precision calculations while xbeach was run with double precision the single precision execution of xbeach could not be amended by just using the master definition file flag it should also be noted that differences in floating point units fpus could also contribute to slight computational differences 4 methodology the present study was performed on two cpu clusters namely pearcey and petrichor the specifications of these clusters may be found here csiro 2022 the pearcey cpu cluster consists of 360 intel xeon e5 2660v3 nodes with 20 cores per node the new petrichor system consists of amd epyc 7543 nodes with 64 cores per node petrichor was previously called ppts pre production test system at the time this benchmarking was performed but has subsequently been upgraded with more nodes and better network accessibility and thus launched to the full hpc environment as petrichor both these machines are operated by csiro s scientific computing group as moderate scale hpcs two cpu clusters were used in the present study to better represent the generalisation of the benchmarking experiments presented here five different gpu cards were implemented in the present study they represent a range of consumer grade to hpc grade gpus that are generally easily accessible affordable to cards that are generally more expensive and associated with academia or data science and data mining driven supercomputing the new zealand based hpc gpus used in the present study are housed in the new zealand escience infrastructure nesi nesi 2022 while the australian based gpu was housed in the bracewell supercomputer csiro 2022 only gpu computations were performed on nesi the gpus and the associated computing performance and where they were executed used in the present study are the nvidia 1 a100 tensor core 19 5 teraflops nesi 2 tesla p100 9 2 teraflops bracewell nesi 3 geforce rtx 6 45 teraflops desktop 4 t500 3 03 teraflops laptop and the 5 quadro p620 1 39 teraflops desktop where 1 teraflops floating point operations per second 1012 flops most research studies refer to the benchmarking and scalability of numerical models as a function of computational cores rautenbach et al 2021 this is feasible for cpu clusters but ill defined for gpus here two metrics will be elucidated first only the scalability metrics for the two cpu clusters and then the joint performance summary as a function of flops the latter will change as the number of cores are increased all the scalability parameters are calculated in comparison with a series computation on a single cpu core the metrics used in the present study are the speed up time saving efficiency ratios and scalability as a function of the other three parameters rautenbach et al 2021 the speed up ratio is given as 1 s p t 1 t p where t 1 is the time in seconds it takes for a sequential computation on one thread and t p is the time a simulation takes with p computational cores rautenbach et al 2021 zhang et al 2014 the time saving ratio is given by 2 t s p t 1 t p t 1 and the efficiency ratio is defined as 3 e p s p p which may be multiplied by 100 to give an efficiency percentage in order to effectively test the scalability on the cpu clusters the following sequence of cores were tested 2 3 4 8 10 16 20 32 40 48 60 64 80 100 125 and 256 these thread core counts were implemented for both cpu clusters the 2 thread core experiment was considered the series computation as one thread core fulfils a supervising role and thus do not directly add to the computation power because the gpu architecture does not scale with regards to number of cores and nodes floating point operations per second flops are used as scaling metric in equation 4 a similar metric to the speed up ratio given in equation 1 is given thus the speed up ratio is calculated with regards to the slowest gpu the p620 in order to elucidate some aspects of the increasing gpu power related to computational time and thus scalability the relative gpu speed up is therefore given as 4 s g p u t p 620 t g p u where t p620 is the time the computation took on the p620 gpu and t gpu are all the other gpus computational times where the denotes gpu number or name 5 results the computational scalability metric described in section 4 was employed to elucidate the performance of both the cpu clusters and gpus in fig 5 the results are presented fig 5 a c show only the cpu scalability results as the x axes are the threads cores count fig 5 d describes the relative gpu scalability as no thread count is available for the gpu architecture the speed up ratio relative to the slowest gpu is presented refer to equation 4 in fig 5 a and d the 1 1 line is also plotted this was done to simplify the interpretation of the results as ideal scalability will be achieved if the computational time scales with the resource allocation in other words the closer the results are to the 1 1 line the more scalable the problem is fig 5 d also represents all five gpu cards employed in the present study and for all three model resolutions each marker corresponds to a different gpu as labelled on the plot in all the other plots the model resolutions are grouped by colour while the particular cpu cluster pearcey or petrichor is identified via the separate markers refer to the plot legend note that the axis of fig 5 b are on a log10 scale in order to visualise the results better in fig 6 a direct comparison between the cpu clusters and the gpu cards is provided via a log10 scale due to the different architectures the theoretical accessible hardware floating point operations per second flops were used as scaling metric this enabled the direct comparison of the wall clock total simulation run times scalability the flops of the cpus were calculated by taking the flops per cores and multiplying it by the number of cores the gpu flops were used as described by the manufacturer all the pearcey results are indicated via the black lines while all the petrichor results are given in grey like fig 5 d the gpu results are given via the coloured markers each colour denoting a separate model resolution here the direct flops are given together with the total wall clock time 6 discussion in fig 5 a the most significant speed ups are obtained in the medium and high resolution models with cpu clusters the inter core and inter nodal communication is not negligible a balance must be struck between the time saved by deploying more resources versus the increasing communication time associated with the message passing interface mpi strategy in the case of the low resolution model refer to table 2 the optimization point was reached and thus the speed up ratio started to plateau or even slightly decrease for both pearcey and petrichor the medium and high resolution models revealed similar speed up ratio trends with a greater deviation from the 1 1 line with more cores used for most of the models and cpu clusters the speed up ratio was approximately 1 1 for core counts below approximately 20 except for pearcey with the low resolution model in fig 5 b the time saving ratio is given most of the experiments plateaued by using approximately 30 cores interestingly the medium resolution model had a steeper increase in time saving for lower core counts albeit it being marginal due to the log10 scale minor differences are visible the time saving ration presents an asymptotic behaviour as t p tends to zero if a deviation from the asymptotic behaviour is observed at higher core counts it would be an indication that t p is increasing again and thus that the inter core communication time becomes more expensive than the additional computational power in fig 5 c the computational efficiency shows a similar result as the speed up ratio given in fig 5 a the low resolution models lose efficiency the fastest both the medium and high resolution models produced similar efficiency results xbeach is not typically regarded as a well scaling model however the medium and high resolution results presented here indicate it is as good as can be expected for this type of hydrodynamic model in this case the plots indicate the higher resolutions are sufficiently large to justify the additional resourcing of more cores all these results considered using approximately 50 cores would be a good compromise between cpu resourcing efficiency and time saving ratios on a machine like petrichor with 64 core nodes using one whole node is reasonable in general these results refute the misconception that xbeach models does not scale well on cpu clusters but also reveal similar scalability trends observed in other software packages e g rautenbach et al 2021 in fig 5 d the gpu card performance is summarised due to the physical architecture differences the relative speed up is given thus both the flops and the speed up are relative to the p620 gpu hence why the first data point is on the 1 1 line as a further example the a100 is almost 15 times more powerful than the p620 from these results the p100 and the a100 perform better with the higher resolution models for the p100 the high resolution model almost produced an ideal scalability the t500 produced similar results for all the model resolutions the p100 also performed poorly with the low resolution model this may be because the domain size and resolution are in fact too small to optimally make use of the p100 architecture fig 6 best summarises the results it compares the actual wall clock times of the total simulations directly to flops the three model resolutions are clear and both the cpu clusters and gpu group nicely per resolution level l m and h described in table 2 this also makes logical sense as a similar resource in flops thus produce a similar simulation time petrichor produced faster simulation times than pearcey due to the better intra and inter node communication the limitation with the low resolution models are again clear here the increase in simulation time for the cpus are attributed to halo passing communication times becoming more expensive than the additional flops add to solving the problem the p100 and a100 are research quality gpus even 256 cpus could not compete with the a100 for all model resolutions the p620 t500 and the rtx are desktop and laptop grade gpus this implies that they are affordable and easily accessible in numerous developing countries hpc computing resources are still not readily available not even to research institutes even the weakest p620 gpu has the equivalent performance of a 32 core cpu computer while the rtx was approximately equal to a 125 thread cpu cluster over and above the relative computational power this resource is available on a desktop or laptop machine that is easily portable and manageable for countries and institutes who do not already have cpu clusters gpus are a great alternative to professional computing abilities the total cost however including electrical power consumption and capital cost was not fully explored in the present study these lightweight gpus are even attractive to engineering and defence applications where operations are proprietary time sensitive or performed on mobile units for example where hpc access is impractical such as on sea going vessel in real world practical applications hundreds of simulations are often required to truly explore and understand various climate change scenarios and the associated mitigation options even detailed engineering design model calibration or ensemble forecasting might require large numbers of scenarios modelled for these reasons the computational efficiency of numerical models is paramount even slight increases in computational efficiency could result in substantial savings in real world applications over and above this computational efficiency thus also allows scientists and engineers to simulate larger regions at higher resolutions given that high quality topography and bathymetry data is available 6 1 summary and conclusion coastal inundation studies are becoming increasing more important given the infrastructure and environmental threats projected from climate change to be able to inform coastal adaptation strategies accurate and high resolution estimates of potential coastal inundation patterns are required one method of achieving this is by making use of numerical models these models can be computationally very intensive and thus restrict the domain size resolution and temporal scales simulated the present study aims to present the scalability of a well known coastal numerical modelling tool named xbeach roelvink et al 2018 a few key functionalities of xbeach have recently been translated into a version that can be executed on gpu infrastructure called xbgpu bosserelle 2014 bosserelle et al 2021 the present study showed that the h rms and water levels produced by both implementations of xbeach yield very similar results thus allowing the accuracy assumption of previous validation work done for xbeach executed on cpus to be translated to simulation executed with xbgpu on gpus xbeach scalability experiments were done on two cpu clusters pearcey and petrichor csiro 2022 previously published metrics were used to elucidate the scalability via the speed up ratio time saving ratio and efficiency a range of computational cores were used and compared with a single core computation all these experiments were done for three model resolutions the highest resolution of these presenting a serious challenge for typical desktop computational studies only hydro and wave dynamics were investigated in the present study and further investigation into sediment and morphodynamics including single vs double precision accuracies are required bosserelle et al 2021 alongside the two cpu clusters five gpus were used to investigate the computational scalability of xbgpu the exact same model resolutions and physical parameter setting were used in order to compare the results from xbeach and xbgpu more directly floating point operations per second flops were used as scaling metric as opposed to the typical cpu core count the result was that even a desktop grade gpu could compete with a hpc scale cpu cluster having said that existing cpu clusters still prove to be powerful and able to solve large computationally demanding problems the present study may encourage xbeach developers to incorporate the kernel developed for xbgpu and thus enable researchers to make a better informed decision with regards to the investment of new computational facilities and might motivate more numerical codes to be translated into gpu compatible code author statement cr wrote manuscript conceptualised research questions data processing ran scaling tests on nesi gpus compiled results developed original wellington based xbeach and xbgpu surf beat model ct ran cpu scaling tests on hpcs assisted in manuscript preparation db ran gpu tests on bracewell and kubernetes cluster assisted in manuscript preparation rh manuscript review and domain expertise contribution cb assisted in writing the manuscript lead the xbgpu development translation technical supervisor for both xbeach and xbgpu surf beat models domain expertise contribution funding this research was funded by the national institute of water and atmospheric research niwa taihoro nukurangi strategic scientific investment fund work program on hazards exposure and vulnerability carh2202 the authors wish to acknowledge the use of new zealand escience infrastructure nesi high performance computing facilities as part of this research new zealand s national facilities are provided by nesi and funded jointly by nesi s collaborator institutions and through the ministry of business innovation employment s research infrastructure programme https www nesi org nz this project was also supported by resources and expertise provided by csiro imt scientific computing https ror org 02cgy3m12 finally this work was also supported in part by the national research foundation of south africa grant no 116359 declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
25528,in this contribution two heuristic search algorithms 1 particle swarm optimization pso and 2 genetic algorithm ga are used to calibrate the iric a two dimensional hydraulic model for a test case on the green river in utah the goal of the search algorithms was to find the combination of roughness values that minimized model error compared to the measured water surface elevation an artificial neural network ann which was trained based on the simulated water surface profiles obtained from iric was used to measure the fitness of each solution implementation of pso and ga both improved the accuracy of the calibration by 34 and 30 percent respectively relative to the trial and error this research demonstrates that the implementation of heuristic search models provides an objective methodology for the calibration of hydraulic models with improved performance when compared to models calibrated via trial and error keywords particle swarm optimization genetic algorithm 2 dimensional flood hydraulic model data availability data will be made available on request 1 introduction modeling hydraulics of rivers is a common essential tool for a variety of water resources engineering problems including flood risk management ballesteros et al 2011 and uncertainty analysis zarzar et al 2018 river rehabilitation and eco habitat evaluation camporeale et al 2013 however the generation of a reliable accurate hydraulic model is a formidable task wang 1997 as it usually requires extensive measured data along with proper input data comprehensive knowledge on the hydraulics and the structure of the model and accurate calibration of the model model calibration is a process in which the input to the model is set in a way that will result in the output of the model matching known measured data baracchini et al 2020 goeury et al 2022 this preliminary step ensures that the model is capable of capturing the physics behind the problem for a known condition in addition it makes the results of the model for future scenarios more reliable although not all calibrated models perform well with future scenarios there is a general understanding that uncalibrated models are not reliable as a result calibration of a hydraulic model is a crucial step in developing a model that can accurately predict river characteristics bessar et al 2020 yang et al 2014 the calibration of a model for river hydraulics usually involves comparing measured and simulated water surface profiles along the river by changing the flow resistant roughness coefficients within the river bed or banks bessar et al 2020 hosseiny et al 2020 zarzar et al 2016 2018 the flow resistant coefficient is the most important influential and widely used parameter for calibrating a river flow model but it is difficult to determine ballesteros et al 2011 bessar et al 2020 wang 1997 traditionally the flow resistant coefficients that minimize the difference between measured and simulated water surface profiles bandini et al 2020 jiang et al 2020 schneider et al 2018 are considered as the optimum results appropriate to use for future simulations model calibration is usually categorized as a nonlinear problem bessar et al 2020 cheng et al 2002 2006 deslauriers and mahdi 2018 since the output of the model does not usually change with the input proportionally this implies that the solution to such a problem might not be unique and multiple solutions might lead to multiple optimums bessar et al 2020 consequently being trapped in such local optimums is a common problem in the calibration of hydraulic and hydrologic models gill et al 2006 and this can increase the errors in the simulations substantially ballesteros et al 2011 this makes the process of calibration of a hydraulic model a complex problem with no simple way to find the global optimum solution developing model calibrations involves finding the best optimum solution related to input data this is considered an optimization problem because it seeks to minimize a function of the input and output data gill et al 2006 xia et al 2021 this optimization has been traditionally carried out using three major categories 1 deterministic approaches which are based on mathematical search algorithms gill et al 2006 2 probabilistic search algorithms gill et al 2006 such as the genetic algorithm ga holland 1975 and particle swarm optimization pso eberhart and kennedy 1995 and 3 trial and error methods the most commonly used model calibration by trial and error is a tedious and time consuming task athira 2021 ma et al 2022 in which the quality of the outcome depends highly on the number of parameters used in calibration as well as the users expertise and knowledge deslauriers and mahdi 2018 gill et al 2006 wang 1997 yang et al 2014 currently there is an increasing interest in developing hydraulic and hydrologic models chai et al 2022 this coupled with advancements in data driven approaches results in a demand for more robust methodologies for model calibration wang 1997 furthermore as the physical models get more sophisticated their calibrations become more complex to a manifold degree gill et al 2006 and this demands hiring new sets of tools and interdisciplinary approaches for model calibrations presently there is a substantial need for improving the accuracy and efficiency in calibration processes of hydraulic and hydrologic models which are calibrated mostly by trial and error wang 1997 yang et al 2014 pso and ga are two advanced evolutionary search algorithms tran ngoc et al 2018 capable of addressing nonlinear optimization problems these methods have been widely used in modeling different water resources engineering problems including but not limited to water quality afshar et al 2011 yandamuri et al 2006 rainfall runoff cheng et al 2002 reshma et al 2015 reservoir operations chang et al 2010 wardlaw and sharif 1999 flood routing chu and chang 2009 river stage predictions chau 2006 and sediment yield yadav et al 2018 more than 33 variants of the pso algorithm have been successfully applied to different water resources problems jahandideh tehrani et al 2020 that indicates that pso is one of the most versatile and powerful optimization algorithms and an excellent candidate for calibrating hydraulic models however the application of pso in the calibration of a river flow hydraulic model has never been investigated this research presents a novel approach for estimating the spatial variations in the flow resistance coefficient along the river in a hydraulic model using pso the goal of these evolutionary algorithm was to find the optimum values of the roughness coefficients that minimized the objective function which was defined as the difference between measured and simulated water surface profiles the performances of the pso algorithm then were compared with the one obtained from both the ga and trial and error methods to estimate the objective function within the evolutionary algorithms pso and ga an artificial neural network ann with a multilayer perceptron was developed to determine the water surface profile along the river the model was trained based on the output of iric a two dimensional hydraulic model further the water surface profiles obtained from pso and ga were compared with the traditional trial and error method the outcome of this paper can be used in any hydraulic model to minimize the error associated with model calibration and to make the calibration process more objective further the methodology presented can be developed to include different calibration parameters and can be adopted for other hydraulic models 2 methodology this section presents the study area along with the methodology used in this research to calibrate the hydraulic model using pso and ga algorithms 2 1 study area the study area for this research is located on the northeast side of the state of utah on a segment of the green river with a length of 3 5 km fig 1 shows the location of the study area along with an aerial view of the selected segment of the river the segment of the green river shown in fig 1 b has been studied by the united states geological survey usgs as such water surface elevations in 38 points for a discharge of 247 m3 s are measured measured data including water surface elevations river bathymetry and topography collected by the usgs along with the procedure for calibrating the hydraulic model for the selected segment of the river is publicly available nelson 2019 obtained topography point cloud has on average a density of 1 point on the banks and 17 points on the bed per 25 m2 the river width in this segment of the river varies from 100 m to 150 m with an average bed slope of 0 0006 m m that coupled with the presence of sediment island and a sharp river bend cause variation in water surface profiles along and across the river this makes the selected segment of the river a good fit for this study 2 2 roughness segmentation in the study area to find the spatial variations in roughness values eight polygons were imposed on the river in the study area fig 1 c the segments were defined in a way that would reflect variations in the roughness coefficient at the start and the end of the modeled area at the river bend and in areas around the sediment island the goal of the evolutionary algorithms was to find the best combinations of the roughness values for the eight segmented areas that would minimize the calibration error the river banks in the study area are not active even during high flow events with a percentile exceedance of 98 hosseiny et al 2020 therefore further roughness segmentations between the bed and the banks were not considered 2 3 hydraulic model the international river interface cooperative iric with the fastmech solver was selected for this study the governing equations for the fastmech solver are presented in the supporting document 2 3 1 roughness in fastmech the input roughness value to the fastmech represents a variety of roughness values in the river including the roughness of the bed and the sediment grain the input roughness to the model can take the form of the drag coefficient change in the drag coefficient impacts the simulated water surface profile directly as such measured water surface elevation can be used to calibrate the model with the drag coefficient the relation between the drag coefficient and the commonly used flow resistance term in rivers known as the manning coefficient n can be approximated as 1 c d n 2 g h 1 3 where c d is the drag coefficient and h is the mean flow depth and g is the gravity acceleration nelson 2019 the drag coefficient considered for this research varied from 0 001 to 0 03 m 1 3s table s 4 as such considering an average depth of 1 4 m for the study area hosseiny et al 2020 and applying equation 1 leads to a range of n values varying from 0 01 to 0 04 which is within the typical range of n for the bed and the banks of natural streams di baldassarre et al 2009 the sensitivity of the fastmech to changes in roughness values is presented in the supporting document 2 4 objective function the pso and ga search algorithms are nonlinear functions that do not rely on the mathematical properties of data this makes the pso and ga versatile and powerful approaches for optimization zucco et al 2015 there are three circular steps associated with the pso and ga evolutionary algorithms 1 production of the initial population 2 evaluation of the population and 3 production of new generations based on the evaluation of the population in step 2 chang et al 2010 the evaluation of the population is the most important part of the algorithm this evaluation usually is carried out by defining an objective function where the population fitness with respect to the desired values is measured the fittest candidates have a higher chance to contribute to the finding of optimum values in the next steps the objective function for this research was defined as the root mean squared error rmse as 2 r m s e i 1 j w s m e a s i w s s i m i 2 j where w s m e a s and w s s i m are measured and simulated water surface profiles respectively and j is the total population count chau et al 2005 the heuristic searching algorithms tend to shift the search of optimum points from discrete to semi continuous space rashidi et al 2011 which needs semi continuous runs of the model in this study to close the loop for the three steps mentioned above there was a need to generate the water surface profiles for different resistant coefficients this requires time consuming tedious and repetitive runs of the hydraulic model as such depending upon the initial population of the searching algorithm and the number of iterations there might be a need to run the hydraulic model multiple thousand times to avoid this time consuming and prohibitively expensive task an artificial neural network ann was developed using the programming language of python as a surrogate model to mimic the hydraulic model efficiently the ann model was trained based on the simulation results of the fastmech this made it feasible for the pso and ga to access and use a trained ann model for estimating the objective function of each new generation 2 5 using ann to generate water surface profile artificial neural networks ann with multilayer perceptron hereafter called ann for simplicity are the most common data driven approaches for modeling non linear problems bhattacharya et al 2007 the structure of an ann model is composed of the input hidden layers and output the hidden layers are assigned some arbitrary number of neurons a non linear function is applied to the input data of each neuron before it is passed to the next neuron the interconnections of the networks between the input and the output data and the neurons make the ann a powerful tool for modeling non linear problems haykin 2008 such as flood modeling the ann model developed for this research received eight input parameters of drag coefficients and generated a 1d water surface profile along the river as the output the input to the ann model took the dimensions of 8 rows by 1 column 8 1 the output of the iric with the fastmech solver was used to generate training datasets the water surface profile generated by the iric included 38 points along the river therefore the output of the ann model took the dimensions of 38 rows by 1 column 38 1 with the known input and output dimensions the hyperparameters for the ann model were investigated including the number of neurons the number of hidden layers activation functions and optimization functions as such 10 hidden layers with 300 neurons in each layer reflected the complexity of the water surface profile adequately more information about the structure of the ann along with the hyperparameters is presented in the supporting document 2 6 particle swarm optimization the concept of particle swarm optimization was initially introduced by eberhart and kennedy 1995 and was based on the social interaction of birds with one another in a flock gill et al 2006 as such a number of particles birds are defined and distributed in the computational domain the particles share the knowledge about their own best position with the other particles once the global optimum position is identified in each iteration the searching direction of all the particles in a hyperspace changes toward the global optimum position brunetti et al 2022 gholami et al 2018 gill et al 2006 hejazi et al 2008 in this study the initial population of the pso number of particles was set to 100 and each particle was composed of eight drag coefficients shown in fig 1 c each of the eight drag coefficients was randomly selected between the numbers of 0 001 and 0 03 this resulted in an initial population with a dimension of 100 rows by 8 columns further both acceleration coefficients were set to 2 the damping coefficient was set to 0 99 and the total number of iterations was set to 100 2 7 genetic algorithm the basic concept of the genetic algorithm ga was initially introduced by holland 1975 and was based on the concept of the survival of the fittest in natural evolutionary theory the candidates solutions in a ga algorithm known as the chromosomes with greater fitness values have better chances of survival and reproduction of new generations in the ga algorithm developed in this research the parent with the highest fitness score in each generation was directly moved to the next generation this step improved the convergence of the ga algorithm and it ensured that the algorithm would not lose the possible best parent due to cross over and mutation in succeeding iterations 3 results this section presents the results obtained from the iric model calibrated with the methods of 1 pso 2 ga and 3 trial and error further the water surface profiles obtained from calibration methods are compared 3 1 pso the pso algorithm for this research was initiated with 100 particles randomly selected from numbers between 0 001 and 0 03 this resulted in the best cost lowest rmse of 0 026 m after 100 iterations further the analysis showed that increasing the number of iterations would not improve the best cost the computational time for the pso algorithm for 100 iterations was 0 6 min fig 2 a shows the performance of the pso search for the optimum solution the horizontal lines in fig 2 a indicate when the particles were focusing on a local optimum rather than the global optimum however due to the structure of the search algorithm other particles found better solutions which helped the model to skip the local minimums the pso algorithm was capable of finding the global optimum with a precision of more than three decimal digits with 100 iterations with a computational time of 0 6 min finding the optimum solution with such precision using the trial and error method is near to impossible 3 2 ga similar to the pso algorithm developed in this study the ga was initiated with 100 chromosomes with the genes varying from 0 001 to 0 03 this resulted in a final rmse of 0 028 m the computational time for the ga algorithm was 16 9 min for 100 iterations fig 2 b shows the performance of the ga during the search for the optimum solution the flat lines in fig 2 b show the situations where a better solution is not found however the cross over and mutation contributed to the production of new generations with better fitness values and helped the ga algorithm skip the local minimum the fittest generation of the ga algorithm table s3 in the supporting document indicates the best combination of drag coefficients along the river for model calibration 3 3 trial and error the measured data for the study area and the procedures for calibrating the iric model with the fastmech solver are documented by the usgs the suggested calibration includes the traditional trial and error method and the estimation of the rmse for different drag coefficients fig 2 c shows that the drag coefficient of 0 008 resulted in a minimum rmse of 0 057 m and therefore it was selected for the whole domain in addition further tuning of the drag coefficient was suggested by the usgs the tuning included an increase in the drag coefficient around the area upstream of the sediment island segment 6 in fig 1 c from 0 008 to 0 013 hosseiny et al 2020 nelson 2019 which reduced the rmse for the model set up in this research to 0 054 m table s4 in the supporting document such tuning is solely based on the user s modeling experience and knowledge about the hydraulics of the river 4 discussion the pso and ga algorithms developed in this research resulted in rmse of 0 036 m and 0 038 m respectively as opposed to an rmse of 0 054 m in the trial and error method this shows that the pso and ga were capable of improving the calibration accuracy by 34 and 30 percent respectively fig 3 a shows a comparison between the best roughness values for model calibration obtained by different methods fig 3 b shows a comparison between measured water surface data and water surface profiles obtained from the hydraulic model that was calibrated by the pso algorithm by the ga algorithm and by the trial and error method fig 3 shows that the coefficients obtained by the trial and error method overpredicted the water surface elevations relative to the measurements however such overprediction varied spatially along the river suggesting a need for more variations in drag coefficients along the river for this method the results showed that the pso method resulted in more variations in estimated drag coefficients specifically in upstream however such variations did not correspond with significant changes in water surface elevation fig 3 the results also showed that in regard to the enhancement of the calibration of the hydraulic model the pso outperformed the ga algorithm by four percent further the pso was 28 folds faster than the ga this suggests that the pso method would be a more efficient more accurate and quicker method for calibrating a hydraulic model for large rivers with more variables than the eight drag coefficients used in this study to show the effects of the calibration method used in the analysis the 2d flood inundation maps were simulated for the best drag coefficients obtained by 1 the pso algorithm 2 the ga algorithm and 3 the trial and error method table 1 shows how changes in the calibration method changed the flood inundation areas and the estimated maximum velocity in the study area table 1 shows that the inundated wet area predicted by the iric model calibrated by the trial and error method was 0 1 percent larger than the one obtained from the model calibrated by the pso this difference is expected to be larger for rivers in lowlands where there is a higher chance that the water would flow onto the floodplain further the maximum velocity obtained from the iric which was calibrated by trial and error was 5 5 percent smaller than the one obtained from the pso this shows the importance of accurate hydraulic calibrations for geomorphologic simulations where the erosion and deposition of sediments vary nonlinearly with the velocity magnitude both evolutionary algorithms minimized the need for the user s prior knowledge about the roughness coefficients for the study area as they automatically searched and found optimum solutions as a result both the pso and ga methods made the calibration process of a hydraulic model more objective regardless of the user s hydraulic knowledge 5 limitations and future work while the heuristic searching algorithms provide the user with the ability to search for the optimum solution in a semi continuous domain they lack carrying information about the fundamental of physics behind the problem this issue is specifically important when overfitting is a point of attention in this paper these algorithms can be looked upon as advanced searching tools that provide the user with a range of possible roughness values for model calibration the issue of overfitting the roughness values can be further investigated in future once more measured data become available in addition the hydraulic model used in this study does not include manning coefficient in the calculations directly as such further investigation can be carried out to analyze the uncertainties associated with including manning coefficient in the analysis 6 conclusion river hydraulic modeling is an essential tool in the river engineering field the calibration of hydraulic models has been traditionally executed by trial and error which requires the user s prior knowledge of hydraulics in addition the traditional calibration method by the trial and error method is a tedious and time consuming task in which finding the global optimum is near to impossible this paper presented an innovative framework for calibrating a hydraulic model with two evolutionary algorithms the particle swarm optimization algorithm pso and the genetic algorithm ga the performances of these two algorithms then were compared with the one obtained from the traditional trial and error method the framework was tested on a segment of the green river in the state of utah a two dimensional hydraulic model iric with a quasi steady solver known as the fastmech was used for flow simulations in the river to account for roughness variations in the model eight regions with possible variable roughness values were defined along the river the goal of the evolutionary algorithms then was to find the best combination of roughness coefficients which would minimize the root mean squared error rmse of the estimated water surface profile and measured water surface elevation data to provide both the ga and the pso with an objective function to estimate the fitness of the candidates within the algorithms an artificial neural network ann with a multilayer perceptron model was developed and was trained based on the outputs from the iric to mimic the hydraulic model the search for the global optimum in both the pso and the ga started from the initial populations and evolved through iterations the initial population count and maximum iterations for the pso and the ga algorithms were both set to 100 the pso and ga both outperformed the traditional trial and error calibration method the pso and ga reduced the rmse of the estimated water surface profile obtained from iric by 34 and 30 percent respectively the wetted area obtained from the calibrated model using the pso algorithm was 0 1 percent smaller than the one obtained from trial and error this difference would be more substantial in lowland rivers where minor changes in water surface elevation would alter the area of inundation significantly further the maximum velocity obtained by the pso in the computational domain was 5 5 percent more than the one obtained by trial and error the pso algorithm was more accurate than the ga algorithm by 4 percent based on the estimated rmse and it performed 28 folds faster while both pso and ga resulted in relatively similar water surface profiles the pso is a preferred choice for calibration of larger rivers because of its accuracy and its efficiency in handling more calibration variables the suggested framework can be extended to include more segmented areas along and across the river representing more variations of the roughness in the bed and the banks of a river to do that it is required that both cost function and the ann model change accordingly to include the bank segmentations in calculations further this suggested framework can be utilized for other hydraulic models where more variables than just the drag coefficient are necessary for calibration the outcome of this paper can be used to automate the calibration process of hydraulic models with minimum interference of the user an important step toward more objective results declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the author would like to sincerely thank dr claire masteller dr foad nazari dr nima ekhtari and dr kamran makarian for sharing their insight with the author during the creation of this manuscript the author would also like to thank mr ward barnes for his editorial assistance appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105537 
25528,in this contribution two heuristic search algorithms 1 particle swarm optimization pso and 2 genetic algorithm ga are used to calibrate the iric a two dimensional hydraulic model for a test case on the green river in utah the goal of the search algorithms was to find the combination of roughness values that minimized model error compared to the measured water surface elevation an artificial neural network ann which was trained based on the simulated water surface profiles obtained from iric was used to measure the fitness of each solution implementation of pso and ga both improved the accuracy of the calibration by 34 and 30 percent respectively relative to the trial and error this research demonstrates that the implementation of heuristic search models provides an objective methodology for the calibration of hydraulic models with improved performance when compared to models calibrated via trial and error keywords particle swarm optimization genetic algorithm 2 dimensional flood hydraulic model data availability data will be made available on request 1 introduction modeling hydraulics of rivers is a common essential tool for a variety of water resources engineering problems including flood risk management ballesteros et al 2011 and uncertainty analysis zarzar et al 2018 river rehabilitation and eco habitat evaluation camporeale et al 2013 however the generation of a reliable accurate hydraulic model is a formidable task wang 1997 as it usually requires extensive measured data along with proper input data comprehensive knowledge on the hydraulics and the structure of the model and accurate calibration of the model model calibration is a process in which the input to the model is set in a way that will result in the output of the model matching known measured data baracchini et al 2020 goeury et al 2022 this preliminary step ensures that the model is capable of capturing the physics behind the problem for a known condition in addition it makes the results of the model for future scenarios more reliable although not all calibrated models perform well with future scenarios there is a general understanding that uncalibrated models are not reliable as a result calibration of a hydraulic model is a crucial step in developing a model that can accurately predict river characteristics bessar et al 2020 yang et al 2014 the calibration of a model for river hydraulics usually involves comparing measured and simulated water surface profiles along the river by changing the flow resistant roughness coefficients within the river bed or banks bessar et al 2020 hosseiny et al 2020 zarzar et al 2016 2018 the flow resistant coefficient is the most important influential and widely used parameter for calibrating a river flow model but it is difficult to determine ballesteros et al 2011 bessar et al 2020 wang 1997 traditionally the flow resistant coefficients that minimize the difference between measured and simulated water surface profiles bandini et al 2020 jiang et al 2020 schneider et al 2018 are considered as the optimum results appropriate to use for future simulations model calibration is usually categorized as a nonlinear problem bessar et al 2020 cheng et al 2002 2006 deslauriers and mahdi 2018 since the output of the model does not usually change with the input proportionally this implies that the solution to such a problem might not be unique and multiple solutions might lead to multiple optimums bessar et al 2020 consequently being trapped in such local optimums is a common problem in the calibration of hydraulic and hydrologic models gill et al 2006 and this can increase the errors in the simulations substantially ballesteros et al 2011 this makes the process of calibration of a hydraulic model a complex problem with no simple way to find the global optimum solution developing model calibrations involves finding the best optimum solution related to input data this is considered an optimization problem because it seeks to minimize a function of the input and output data gill et al 2006 xia et al 2021 this optimization has been traditionally carried out using three major categories 1 deterministic approaches which are based on mathematical search algorithms gill et al 2006 2 probabilistic search algorithms gill et al 2006 such as the genetic algorithm ga holland 1975 and particle swarm optimization pso eberhart and kennedy 1995 and 3 trial and error methods the most commonly used model calibration by trial and error is a tedious and time consuming task athira 2021 ma et al 2022 in which the quality of the outcome depends highly on the number of parameters used in calibration as well as the users expertise and knowledge deslauriers and mahdi 2018 gill et al 2006 wang 1997 yang et al 2014 currently there is an increasing interest in developing hydraulic and hydrologic models chai et al 2022 this coupled with advancements in data driven approaches results in a demand for more robust methodologies for model calibration wang 1997 furthermore as the physical models get more sophisticated their calibrations become more complex to a manifold degree gill et al 2006 and this demands hiring new sets of tools and interdisciplinary approaches for model calibrations presently there is a substantial need for improving the accuracy and efficiency in calibration processes of hydraulic and hydrologic models which are calibrated mostly by trial and error wang 1997 yang et al 2014 pso and ga are two advanced evolutionary search algorithms tran ngoc et al 2018 capable of addressing nonlinear optimization problems these methods have been widely used in modeling different water resources engineering problems including but not limited to water quality afshar et al 2011 yandamuri et al 2006 rainfall runoff cheng et al 2002 reshma et al 2015 reservoir operations chang et al 2010 wardlaw and sharif 1999 flood routing chu and chang 2009 river stage predictions chau 2006 and sediment yield yadav et al 2018 more than 33 variants of the pso algorithm have been successfully applied to different water resources problems jahandideh tehrani et al 2020 that indicates that pso is one of the most versatile and powerful optimization algorithms and an excellent candidate for calibrating hydraulic models however the application of pso in the calibration of a river flow hydraulic model has never been investigated this research presents a novel approach for estimating the spatial variations in the flow resistance coefficient along the river in a hydraulic model using pso the goal of these evolutionary algorithm was to find the optimum values of the roughness coefficients that minimized the objective function which was defined as the difference between measured and simulated water surface profiles the performances of the pso algorithm then were compared with the one obtained from both the ga and trial and error methods to estimate the objective function within the evolutionary algorithms pso and ga an artificial neural network ann with a multilayer perceptron was developed to determine the water surface profile along the river the model was trained based on the output of iric a two dimensional hydraulic model further the water surface profiles obtained from pso and ga were compared with the traditional trial and error method the outcome of this paper can be used in any hydraulic model to minimize the error associated with model calibration and to make the calibration process more objective further the methodology presented can be developed to include different calibration parameters and can be adopted for other hydraulic models 2 methodology this section presents the study area along with the methodology used in this research to calibrate the hydraulic model using pso and ga algorithms 2 1 study area the study area for this research is located on the northeast side of the state of utah on a segment of the green river with a length of 3 5 km fig 1 shows the location of the study area along with an aerial view of the selected segment of the river the segment of the green river shown in fig 1 b has been studied by the united states geological survey usgs as such water surface elevations in 38 points for a discharge of 247 m3 s are measured measured data including water surface elevations river bathymetry and topography collected by the usgs along with the procedure for calibrating the hydraulic model for the selected segment of the river is publicly available nelson 2019 obtained topography point cloud has on average a density of 1 point on the banks and 17 points on the bed per 25 m2 the river width in this segment of the river varies from 100 m to 150 m with an average bed slope of 0 0006 m m that coupled with the presence of sediment island and a sharp river bend cause variation in water surface profiles along and across the river this makes the selected segment of the river a good fit for this study 2 2 roughness segmentation in the study area to find the spatial variations in roughness values eight polygons were imposed on the river in the study area fig 1 c the segments were defined in a way that would reflect variations in the roughness coefficient at the start and the end of the modeled area at the river bend and in areas around the sediment island the goal of the evolutionary algorithms was to find the best combinations of the roughness values for the eight segmented areas that would minimize the calibration error the river banks in the study area are not active even during high flow events with a percentile exceedance of 98 hosseiny et al 2020 therefore further roughness segmentations between the bed and the banks were not considered 2 3 hydraulic model the international river interface cooperative iric with the fastmech solver was selected for this study the governing equations for the fastmech solver are presented in the supporting document 2 3 1 roughness in fastmech the input roughness value to the fastmech represents a variety of roughness values in the river including the roughness of the bed and the sediment grain the input roughness to the model can take the form of the drag coefficient change in the drag coefficient impacts the simulated water surface profile directly as such measured water surface elevation can be used to calibrate the model with the drag coefficient the relation between the drag coefficient and the commonly used flow resistance term in rivers known as the manning coefficient n can be approximated as 1 c d n 2 g h 1 3 where c d is the drag coefficient and h is the mean flow depth and g is the gravity acceleration nelson 2019 the drag coefficient considered for this research varied from 0 001 to 0 03 m 1 3s table s 4 as such considering an average depth of 1 4 m for the study area hosseiny et al 2020 and applying equation 1 leads to a range of n values varying from 0 01 to 0 04 which is within the typical range of n for the bed and the banks of natural streams di baldassarre et al 2009 the sensitivity of the fastmech to changes in roughness values is presented in the supporting document 2 4 objective function the pso and ga search algorithms are nonlinear functions that do not rely on the mathematical properties of data this makes the pso and ga versatile and powerful approaches for optimization zucco et al 2015 there are three circular steps associated with the pso and ga evolutionary algorithms 1 production of the initial population 2 evaluation of the population and 3 production of new generations based on the evaluation of the population in step 2 chang et al 2010 the evaluation of the population is the most important part of the algorithm this evaluation usually is carried out by defining an objective function where the population fitness with respect to the desired values is measured the fittest candidates have a higher chance to contribute to the finding of optimum values in the next steps the objective function for this research was defined as the root mean squared error rmse as 2 r m s e i 1 j w s m e a s i w s s i m i 2 j where w s m e a s and w s s i m are measured and simulated water surface profiles respectively and j is the total population count chau et al 2005 the heuristic searching algorithms tend to shift the search of optimum points from discrete to semi continuous space rashidi et al 2011 which needs semi continuous runs of the model in this study to close the loop for the three steps mentioned above there was a need to generate the water surface profiles for different resistant coefficients this requires time consuming tedious and repetitive runs of the hydraulic model as such depending upon the initial population of the searching algorithm and the number of iterations there might be a need to run the hydraulic model multiple thousand times to avoid this time consuming and prohibitively expensive task an artificial neural network ann was developed using the programming language of python as a surrogate model to mimic the hydraulic model efficiently the ann model was trained based on the simulation results of the fastmech this made it feasible for the pso and ga to access and use a trained ann model for estimating the objective function of each new generation 2 5 using ann to generate water surface profile artificial neural networks ann with multilayer perceptron hereafter called ann for simplicity are the most common data driven approaches for modeling non linear problems bhattacharya et al 2007 the structure of an ann model is composed of the input hidden layers and output the hidden layers are assigned some arbitrary number of neurons a non linear function is applied to the input data of each neuron before it is passed to the next neuron the interconnections of the networks between the input and the output data and the neurons make the ann a powerful tool for modeling non linear problems haykin 2008 such as flood modeling the ann model developed for this research received eight input parameters of drag coefficients and generated a 1d water surface profile along the river as the output the input to the ann model took the dimensions of 8 rows by 1 column 8 1 the output of the iric with the fastmech solver was used to generate training datasets the water surface profile generated by the iric included 38 points along the river therefore the output of the ann model took the dimensions of 38 rows by 1 column 38 1 with the known input and output dimensions the hyperparameters for the ann model were investigated including the number of neurons the number of hidden layers activation functions and optimization functions as such 10 hidden layers with 300 neurons in each layer reflected the complexity of the water surface profile adequately more information about the structure of the ann along with the hyperparameters is presented in the supporting document 2 6 particle swarm optimization the concept of particle swarm optimization was initially introduced by eberhart and kennedy 1995 and was based on the social interaction of birds with one another in a flock gill et al 2006 as such a number of particles birds are defined and distributed in the computational domain the particles share the knowledge about their own best position with the other particles once the global optimum position is identified in each iteration the searching direction of all the particles in a hyperspace changes toward the global optimum position brunetti et al 2022 gholami et al 2018 gill et al 2006 hejazi et al 2008 in this study the initial population of the pso number of particles was set to 100 and each particle was composed of eight drag coefficients shown in fig 1 c each of the eight drag coefficients was randomly selected between the numbers of 0 001 and 0 03 this resulted in an initial population with a dimension of 100 rows by 8 columns further both acceleration coefficients were set to 2 the damping coefficient was set to 0 99 and the total number of iterations was set to 100 2 7 genetic algorithm the basic concept of the genetic algorithm ga was initially introduced by holland 1975 and was based on the concept of the survival of the fittest in natural evolutionary theory the candidates solutions in a ga algorithm known as the chromosomes with greater fitness values have better chances of survival and reproduction of new generations in the ga algorithm developed in this research the parent with the highest fitness score in each generation was directly moved to the next generation this step improved the convergence of the ga algorithm and it ensured that the algorithm would not lose the possible best parent due to cross over and mutation in succeeding iterations 3 results this section presents the results obtained from the iric model calibrated with the methods of 1 pso 2 ga and 3 trial and error further the water surface profiles obtained from calibration methods are compared 3 1 pso the pso algorithm for this research was initiated with 100 particles randomly selected from numbers between 0 001 and 0 03 this resulted in the best cost lowest rmse of 0 026 m after 100 iterations further the analysis showed that increasing the number of iterations would not improve the best cost the computational time for the pso algorithm for 100 iterations was 0 6 min fig 2 a shows the performance of the pso search for the optimum solution the horizontal lines in fig 2 a indicate when the particles were focusing on a local optimum rather than the global optimum however due to the structure of the search algorithm other particles found better solutions which helped the model to skip the local minimums the pso algorithm was capable of finding the global optimum with a precision of more than three decimal digits with 100 iterations with a computational time of 0 6 min finding the optimum solution with such precision using the trial and error method is near to impossible 3 2 ga similar to the pso algorithm developed in this study the ga was initiated with 100 chromosomes with the genes varying from 0 001 to 0 03 this resulted in a final rmse of 0 028 m the computational time for the ga algorithm was 16 9 min for 100 iterations fig 2 b shows the performance of the ga during the search for the optimum solution the flat lines in fig 2 b show the situations where a better solution is not found however the cross over and mutation contributed to the production of new generations with better fitness values and helped the ga algorithm skip the local minimum the fittest generation of the ga algorithm table s3 in the supporting document indicates the best combination of drag coefficients along the river for model calibration 3 3 trial and error the measured data for the study area and the procedures for calibrating the iric model with the fastmech solver are documented by the usgs the suggested calibration includes the traditional trial and error method and the estimation of the rmse for different drag coefficients fig 2 c shows that the drag coefficient of 0 008 resulted in a minimum rmse of 0 057 m and therefore it was selected for the whole domain in addition further tuning of the drag coefficient was suggested by the usgs the tuning included an increase in the drag coefficient around the area upstream of the sediment island segment 6 in fig 1 c from 0 008 to 0 013 hosseiny et al 2020 nelson 2019 which reduced the rmse for the model set up in this research to 0 054 m table s4 in the supporting document such tuning is solely based on the user s modeling experience and knowledge about the hydraulics of the river 4 discussion the pso and ga algorithms developed in this research resulted in rmse of 0 036 m and 0 038 m respectively as opposed to an rmse of 0 054 m in the trial and error method this shows that the pso and ga were capable of improving the calibration accuracy by 34 and 30 percent respectively fig 3 a shows a comparison between the best roughness values for model calibration obtained by different methods fig 3 b shows a comparison between measured water surface data and water surface profiles obtained from the hydraulic model that was calibrated by the pso algorithm by the ga algorithm and by the trial and error method fig 3 shows that the coefficients obtained by the trial and error method overpredicted the water surface elevations relative to the measurements however such overprediction varied spatially along the river suggesting a need for more variations in drag coefficients along the river for this method the results showed that the pso method resulted in more variations in estimated drag coefficients specifically in upstream however such variations did not correspond with significant changes in water surface elevation fig 3 the results also showed that in regard to the enhancement of the calibration of the hydraulic model the pso outperformed the ga algorithm by four percent further the pso was 28 folds faster than the ga this suggests that the pso method would be a more efficient more accurate and quicker method for calibrating a hydraulic model for large rivers with more variables than the eight drag coefficients used in this study to show the effects of the calibration method used in the analysis the 2d flood inundation maps were simulated for the best drag coefficients obtained by 1 the pso algorithm 2 the ga algorithm and 3 the trial and error method table 1 shows how changes in the calibration method changed the flood inundation areas and the estimated maximum velocity in the study area table 1 shows that the inundated wet area predicted by the iric model calibrated by the trial and error method was 0 1 percent larger than the one obtained from the model calibrated by the pso this difference is expected to be larger for rivers in lowlands where there is a higher chance that the water would flow onto the floodplain further the maximum velocity obtained from the iric which was calibrated by trial and error was 5 5 percent smaller than the one obtained from the pso this shows the importance of accurate hydraulic calibrations for geomorphologic simulations where the erosion and deposition of sediments vary nonlinearly with the velocity magnitude both evolutionary algorithms minimized the need for the user s prior knowledge about the roughness coefficients for the study area as they automatically searched and found optimum solutions as a result both the pso and ga methods made the calibration process of a hydraulic model more objective regardless of the user s hydraulic knowledge 5 limitations and future work while the heuristic searching algorithms provide the user with the ability to search for the optimum solution in a semi continuous domain they lack carrying information about the fundamental of physics behind the problem this issue is specifically important when overfitting is a point of attention in this paper these algorithms can be looked upon as advanced searching tools that provide the user with a range of possible roughness values for model calibration the issue of overfitting the roughness values can be further investigated in future once more measured data become available in addition the hydraulic model used in this study does not include manning coefficient in the calculations directly as such further investigation can be carried out to analyze the uncertainties associated with including manning coefficient in the analysis 6 conclusion river hydraulic modeling is an essential tool in the river engineering field the calibration of hydraulic models has been traditionally executed by trial and error which requires the user s prior knowledge of hydraulics in addition the traditional calibration method by the trial and error method is a tedious and time consuming task in which finding the global optimum is near to impossible this paper presented an innovative framework for calibrating a hydraulic model with two evolutionary algorithms the particle swarm optimization algorithm pso and the genetic algorithm ga the performances of these two algorithms then were compared with the one obtained from the traditional trial and error method the framework was tested on a segment of the green river in the state of utah a two dimensional hydraulic model iric with a quasi steady solver known as the fastmech was used for flow simulations in the river to account for roughness variations in the model eight regions with possible variable roughness values were defined along the river the goal of the evolutionary algorithms then was to find the best combination of roughness coefficients which would minimize the root mean squared error rmse of the estimated water surface profile and measured water surface elevation data to provide both the ga and the pso with an objective function to estimate the fitness of the candidates within the algorithms an artificial neural network ann with a multilayer perceptron model was developed and was trained based on the outputs from the iric to mimic the hydraulic model the search for the global optimum in both the pso and the ga started from the initial populations and evolved through iterations the initial population count and maximum iterations for the pso and the ga algorithms were both set to 100 the pso and ga both outperformed the traditional trial and error calibration method the pso and ga reduced the rmse of the estimated water surface profile obtained from iric by 34 and 30 percent respectively the wetted area obtained from the calibrated model using the pso algorithm was 0 1 percent smaller than the one obtained from trial and error this difference would be more substantial in lowland rivers where minor changes in water surface elevation would alter the area of inundation significantly further the maximum velocity obtained by the pso in the computational domain was 5 5 percent more than the one obtained by trial and error the pso algorithm was more accurate than the ga algorithm by 4 percent based on the estimated rmse and it performed 28 folds faster while both pso and ga resulted in relatively similar water surface profiles the pso is a preferred choice for calibration of larger rivers because of its accuracy and its efficiency in handling more calibration variables the suggested framework can be extended to include more segmented areas along and across the river representing more variations of the roughness in the bed and the banks of a river to do that it is required that both cost function and the ann model change accordingly to include the bank segmentations in calculations further this suggested framework can be utilized for other hydraulic models where more variables than just the drag coefficient are necessary for calibration the outcome of this paper can be used to automate the calibration process of hydraulic models with minimum interference of the user an important step toward more objective results declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the author would like to sincerely thank dr claire masteller dr foad nazari dr nima ekhtari and dr kamran makarian for sharing their insight with the author during the creation of this manuscript the author would also like to thank mr ward barnes for his editorial assistance appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105537 
25529,the soil water assessment tool swat is a useful model for evaluating socio ecological tradeoffs and analyzing coupled natural human system dynamics in agricultural watersheds however reservoir operating options in swat are limited this study advances the representation of reservoir operations in swat by adding an option for closed loop multi reservoir operating policies that can be optimized using evolutionary multi objective direct policy search this enables water managers to evaluate the tradeoffs across more coordinated reservoir operations in swat while capitalizing on the model s ability to physically simulate hydrological processes better than traditional reservoir simulation models comparing our advanced reservoir operations with swat s existing operating options in the omo river basin of ethiopia we find a wider range of policies for managing conflicting stakeholder objectives that better compromise across them and are more robust to climate change these advances to swat s reservoir module show promise for informing integrated water resources management keywords swat reservoir operations multi objective optimization climate change impacts data availability i have shared a link to data code in the manuscript software source code updates https github com sjordan29 swat source code updates climate scenarios https github com sjordan29 omo cmip downscaling debias optimization and figures https github com sjordan29 advancing swat reservoir ops developer sarah jordan smjordan329 gmail com source language python r fortran license gnu lesser general public license version 3 1 introduction socio ecological systems models are powerful tools for simulating interactions between human and natural systems to understand their vulnerabilities to different natural resources management policies and climatic stressors reed et al 2022 within the water resources literature the soil water assessment tool swat is a prominent tool for simulating these interactions in agricultural systems gassman et al 2014 wu et al 2020 swat is a semi distributed physically based watershed model capable of modeling surface and subsurface hydrology sediment transport plant growth and nutrient dynamics fig 1 the model was designed to enable users to evaluate the effects of alternative management decisions on water resources in large river basins arnold et al 2012 users can simulate crop planting harvesting irrigation and pesticide applications tillage operations and reservoir management to observe the impact that these human actions have on the natural system neitsch et al 2011 these include water quality impacts of erosion sedimentation and polluted runoff such as loads of nutrients pesticides bacteria and biochemical oxygen demand bod as well as water quantity impacts of changing hydrologic variability and seasonality neitsch et al 2011 not only can swat model one way impacts of human decisions on the environment but its open source code allows for integration with agent based models abms and other decision support tools that enable two way feedbacks between human decisions and environmental outcomes khan 2018 this allows modelers to simulate how humans may change their future management decisions in response to past decisions environmental impacts investigating how those two way interactions propagate to socio environmental outcomes a major water management strategy humans might change in response to observed environmental outcomes and in particular under climate change is reservoir operations however the representation of reservoir operations in swat2012 is simplistic and limited wu et al 2020 in the existing reservoir module users can input measured daily or monthly releases if historical information is available but this does not allow users to model how reservoirs might operate in the future for small uncontrolled reservoirs users can simply define an average annual release rate however many agricultural systems around the world are fed by large surface reservoirs with more variable operations these include mega dams in the american west as well as recent hydropower development in asia latin america and africa aimed at increasing electrification through hydropower production while also providing access to irrigation in areas with developing economies zhang et al 2018 to model large reservoirs like these users can define monthly reservoir target storages in swat neitsch et al 2011 yet this does not allow users to coordinate releases across reservoirs a common shortcoming of hydrological models for example rougé et al 2021 show that calculating releases for each reservoir independently i e without considering the storage in the other reservoirs in the system results in unrealistic outcomes and can have unintended consequences on flood and drought assessments this study seeks to fill this gap by incorporating an additional reservoir module in swat that implements more advanced reservoir control methods that allow for coordinated multi objective management reservoir managers are recognizing the value of such complex adaptive and coordinated rules and are becoming more open to integrating them into operations jasperse et al 2017 talbot et al 2017 recent advancements in multi objective optimal control methods have enabled the discovery of reservoir operating rules that can better balance conflicting socio ecological outcomes adapt to system variability or mitigate the impact of climate change all of which are essential for integrated reservoir management giuliani et al 2016b 2021 zaniolo et al 2021c however most applications of these advanced methods have been limited to reservoir systems models that do not physically model the rainfall runoff process or the ecological impacts of alternative operations this requires coupling multiple models to understand how changing climate conditions propagate through to water supply impacts see e g giuliani et al 2016a zaniolo et al 2021c steinschneider and brown 2012 or how water supply impacts propagate to agricultural or ecological impacts see e g georgiou and papamichail 2008 castelletti et al 2014 alternatively the reservoir simulation models rely on empirical representations of processes like erosion and sedimentation schmitt et al 2018 or proxy measures of agro ecological impacts like water supply deficits loucks and van beek 2017 there has been growing research on embedding reservoir operations in large scale hydrologic models but much of this work has been focused on calibrating the models while considering the impacts of human behavior rather than optimizing control rules for socioecological outcomes see e g dang et al 2020 nazemi and wheater 2015 wada et al 2014 2017 the limited work that has been done on designing multi purpose reservoir operations in swat has only optimized monthly releases and failed to coordinate releases across multiple reservoirs zhang et al 2011 anand et al 2018 this study combines the benefits of modeling flexible coordinated reservoir operations and physically modeling interactions between human and natural systems by advancing the representation of reservoir operations in swat we update the swat source code to enable the simulation and optimization of closed loop nonlinear and state aware reservoir operating policies designed with evolutionary multiobjective direct policy search giuliani et al 2016b we apply these updated policies to a multi objective multi reservoir control problem in the omo river basin ethiopia where a series of reservoirs must balance the irrigation needs of large scale agriculture with the downstream flow requirements of local communities and aquatic wildlife while still generating enough electricity output to justify the cost of hydropower development we compare the performance of existing reservoir operations in swat with the updated coordinated operations under historical and possible future climate conditions to see if we can define more resilient and robust management strategies that reduce socio ecological tradeoffs under a range of conditions while the present study only illustrates this reservoir module within the omo river basin the approach is generalizable and could be adapted to work in any context or in future iterations of the swat model e g swat 2 methods in this study we develop a new reservoir operating option for the swat model in which reservoir releases are coordinated following optimized nonlinear release rules we evaluate the performance of our release rules against policies optimized within an existing reservoir operating option in the swat model consisting of independent monthly storage targets for each reservoir this allows us to see if our operations option can discover policies that better meet the needs of conflicting stakeholders which we explore using a case study in the omo river basin see section 3 for this comparison we optimize both sets of policies using multi objective optimization here we describe how both sets of policies are formulated and optimized within swat 2 1 multi objective optimization of reservoir operations for both the existing and updated reservoir operating module we optimize release policies using evolutionary multi objective direct policy search emodps the emodps framework couples the direct policy search dps approach with multi objective evolutionary algorithms moeas giuliani et al 2016b emodps is a parameterization simulation optimization approach koutsoyiannis and economou 2003 that has been used to solve high dimensional water resources and control problems specifically emodps has been successfully used to define closed loop flexible reservoir operating policies that best balance multiple conflicting objectives giuliani et al 2016b the emodps framework defines a reservoir operating policy within a family of functions p θ in the current swat reservoir module these functions are piecewise linear storage targets described in section 2 2 1 for our new swat reservoir module these functions are gaussian radial basis functions rbfs described in section 2 2 2 the parameters of these functions θ are optimized with respect to operating objectives j using simulation optimization after an initial parameter set is defined the system is simulated and performance is evaluated based on the operating objectives the iterative search process of moeas is then able to create and evolve a pareto approximate set of solutions over the problem s conflicting objectives using randomized mating selection and mutation operations to modify the policy parameters the policy parameterization for each type of reservoir rules is described below 2 2 formulation of operating policies 2 2 1 existing swat reservoir operations swat s existing operating policies are based on monthly storage targets the storage target operations are piecewise linear functions for each reservoir in the system each reservoir s policy is defined by 13 parameters a target storage value for each month starg and the number of days it takes to reach the target storage ndtargr which is constant across all months daily reservoir releases v flowout are calculated as follows 1 v flowout v v targ n d targ where v is the volume of water stored in the reservoir v targ is the reservoir storage target and nd targ is the number of days for the reservoir to reach the target storage arnold et al 2012 once the outflow is determined with this method the model then adjusts the outflow to ensure that minimum and maximum discharge criteria are met existing target storage operations are not fully state aware each reservoir s release decision is based only on its own storage level and the month but does not consider any additional system state information such as the storage at other reservoirs in the system 2 2 2 updates to the swat reservoir module to enable more complex reservoir operating rules in swat we modify the source code of the reservoir module to provide an additional reservoir outflow simulation option that is capable of simulating non linear operating policies and coordinating releases across multiple reservoirs in a river system the modified source code reads non linear function parameters from user defined text files in the modparm and readres modules which are then passed to the reservoir module res and used to calculate daily releases using gaussian radial basis functions rbfs the rbfs determine release decisions as a function of multiple variables the reservoir storage volumes across all reservoirs in the system at the beginning of the day and the day of the year represented by sine and cosine functions with an annual period the source code is modified in order to pass this information to the rbfs these updates to the source code allow the model to calculate daily releases using information about the system state of all reservoirs all updates in this study were specific to the context of the omo river basin but could be generalized following the guidance outlined in the instructions manual of the source code updates github repository see link at top of paper we use gaussian rbfs for the non linear operating rules because giuliani et al 2016b show them to be more effective in solving multi objective policy design problems than other universal approximators like artificial neural networks anns operating policies defined by rbfs prescribe daily releases u t k normalized on 0 1 from the k th reservoir at time t as a function of b time varying inputs v t normalized on 0 1 and an optimized base release for the reservoir normalized on 0 1 a k 2 u t k a k i 1 n w i k exp j i b v t j c i j 2 b i j 2 here n is the total number of rbfs w i k is the weight of the i th rbf and v t is a vector of inputs normalized over 0 1 which here are the reservoir volumes at time t sin 2πt 365 and cos 2πt 365 b is the number of policy inputs and c i b i are the b dimensional center and radius vectors of the i th rbf respectively the weights are not constrained to sum to 1 and therefore do not represent a convex combination fig 2 reproduced from doering et al 2021 is an illustrative example of a reservoir operation policy defined by three rbfs which demonstrates the flexibility that rbf based operating policies can provide the weights centers and radii of these policies are optimized using multi objective optimization the number of these decision variables will depend on the number of rbfs n based on the authors experience an effective rule of thumb for n is b k 1 where b is the number of inputs and k is the number of outputs giuliani et al 2016a quinn et al 2018 future work could explore defining policies using neuro evolutionary multi objective direct policy search nemodps which optimizes not only the policy parameters but their structure requiring less trial and error from the modeler zaniolo et al 2021b when implementing these policies in swat the prescribed release u t k may not always be physically possible the true release realized by the end of day t r t 1 k is determined by subjecting the prescribed release to physical and minimum environmental flow mef constraints these ensure the releases meet mef requirements when feasible power outflows do not exceed the maximum capacity of the turbines and that the spillways are activated when necessary so the reservoir does not exceed its capacity 3 case study 3 1 omo river basin we evaluate the performance of our new reservoir operating option in swat using a case study in the omo river basin the omo river basin is a 79 000 km2 watershed in southwestern ethiopia that drains from the humid and mountainous shewan highlands to the hot and arid plain of the lower omo valley where the river spreads into a biodiverse delta at the ethiopia kenya border the river terminates at lake turkana in kenya which is the world s largest desert lake spanning over 130 000 km2 fig 3 avery 2012 this endoheric system was formed within the kenya rift avery 2010 historically the omo river basin has been a pastoral region where nomadic indigenous tribes migrate seasonally based on water and food availability which are controlled by the river s monsoonal flows as the inter tropical convergence zone itcz shifts northward from september to november and southward from march to may it brings with it rains that result in alternating wet and dry seasons sogreah 2010 rainfall in the northern omo basin peaks in august with a long dry season from november to march rainfall in the central omo basin exhibits a longer and less intense wet season from april to september and rainfall in the southern omo features two mildly rainy periods one in march and april and another in september and october total annual precipitation is highly variable throughout the watershed ranging from about 1 900 mm year in the northernmost parts of the basin to just 300 mm year in the southern omo near lake turkana however the historical flow pattern induced by these monsoonal rains is being altered by dam construction for hydropower production and the expansion of irrigable agriculture in the basin woodroofe 1996 the omo river basin has been a major target for hydropower projects because of its high hydropower potential large amounts of concentrated rainfall in the basin s highlands creates the second largest annual runoff of any river system in the country avery 2012 furthermore the omo river is steep flowing from an elevation of about 3 000 m in the highlands to 400 m at lake turkana over its 760 km length three power plants have been constructed in the omo river basin over the past 20 years gilgel gibe i ii and iii with another hydropower plant koysha under construction table 1 gibe i is a small dam with a powerplant gibe ii is just a powerplant and gibe iii and koysha are very large dams and powerplants the development of gibe iii and koysha megadams has been extremely controversial in the omo river basin since they promote economic development at the expense of indigenous people and ecological resources the gibe iii dam has been particularly controversial as questions surround the legitimacy of its environmental and social impact assessment esia and downstream flows significantly reduced during its filling phase and first few years in operation resulting in steep social impacts carr 2017 avery 2012 2014 continued hydropower development is planned in the omo river basin with the koysha dam ethiopia is working towards reaching self sufficiency in electricity production and 100 electricity access by 2025 with an end goal of becoming an energy exporter iea 2016 asress et al 2013 woodroofe 1996 as of 2016 the national electrification rate in ethiopia was just 25 leaving 75 of the population mainly those in rural areas like the omo river basin without access to electricity iea 2016 zaniolo et al 2021a expanding hydropower plants in the omo helps the country work towards its ambitious goals and the large storage reservoirs behind the dams enable more reliable electricity output in this arid region where 90 of the annual runoff is concentrated to just four months of the year sundin 2017 the storage reservoirs have also allowed for cultivation of large areas devoted to irrigable agriculture avery 2012 the state owned ethiopian sugar corporation esc is developing the kuraz sugar plantation downstream of the koysha dam which is currently projected to span 175 000 ha the esc aims to transform ethiopia from a sugar importer to a top ten global exporter davidson 2015 the ethiopian ministry of agriculture and natural resources has also leased approximately 85 000 ha of land south of the kuraz sugar development project to foreign and private investors oakland institute 2011 this land will primarily be used for cotton plantations carr 2017 hodbod et al 2019 these projects divert water from the main channel through irrigation canals enabling crop growth in an area that is too dry to support rain fed agriculture human rights watch 2017 while water infrastructure development has promoted economic growth through hydropower production and the expansion of irrigable agriculture it has negatively affected indigenous people and the ecological resources in the lower omo valley hathaway 2009 abbink 2012 fratkin 2014 the lower omo basin has historically been home to over 500 000 indigenous people and the development of large scale agriculture has resulted in the displacement and abuse of many indigenous communities oakland institute 2019 the indigenous groups that remain downstream of these developments are agropastoralists that rely on the omo river as their primary source of water and food however altered hydrology from the dams and irrigation diversions have adversely impacted these resources carr 2017 approximately 200 000 indigenous people in the lower omo valley practice flood recession agriculture as a primary source of food for their cattle this practice uses the annual inundations caused by the omo river s late summer flood pulse as a form of irrigation since the dry conditions in the lower omo cannot support rain fed agriculture carr 2017 at the start of the wet season in july the omo river starts to rise in the omo valley until it floods in august and september depositing silt on the floodplain once the flood recedes the shores of the river can be cultivated to produce maize and sorghum that serve as the primary food source for the tribes carr 2017 sogreah 2010 johnston 2009 water infrastructure development has dampened this flood pulse increasing the likelihood that there will be inadequate area to cultivate crops in any given year resulting in food shortages among indigenous populations the dams have also altered the natural annual hydrologic cycle in the omo river delta which feeds into lake turkana an endorheic lake that serves as a food and water source for another 300 000 indigenous people in ethiopia and kenya the omo river accounts for 90 of total inflows so flow patterns in the omo river and water levels in lake turkana are directly correlated sogreah 2010 the historical flood pulse supports the biodiversity in the delta and ensures fluctuations in lake turkana s levels which enable nutrient circulation support the spawning cycles of fish and replenish grazing land for livestock along the shores of the lake gownaris et al 2015 carr 2014 2017 avery 2012 continued disruption to lake turkana s natural oscillations could result in widespread food and water shortages and exacerbate conflicts between tribes over limited resources carr 2017 in this study we seek to find reservoir operating policies that balance all these conflicting demands on the omo river basin s water resources using the soil water assessment tool 3 2 swat model the soil water assessment tool is a semi distributed physically based river basin model arnold et al 1998 swat is one of the most widely used watershed scale models because it can simulate a range of hydrologic and environmental processes it can model hydrological processes sediment transport and routing nutrient and pesticide transport plant growth climate change and anthroprogenic features and activities gassman et al 2014 because it can model the interactions between natural and human processes it is an excellent tool for assessing the impact of alternative water management strategies on a variety of stakeholders we simulate the four dams described in section 3 by building a swat model of the omo river basin the model includes both constructed and planned hydropower plants and planned irrigable agricultural developments in the region unfortunately precipitation and streamflow data in the basin are limited and not open access we seek to create as accurate a model as possible given these data limitations but caution that the model should be further validated and refined as more data become available before any concrete recommendations are made to decision makers in the omo river basin the current formulation still represents a realistic system that serves as a useful test case for demonstrating the capabilities of updated swat reservoir operations in managing socio ecological tradeoffs details regarding the model setup including input data parameter sensitivity analysis and calibration are provided in the supporting information 3 3 formulation of multi objective optimization problem for our five objective problem for reservoir optimization in the omo river basin the emodps framework is mathematically defined as 3 p θ a r g m i n p θ j where 4 j j hyd j env j rec j sug j cot each element of j is defined in section 3 3 1 while the form of the operating policies p θ is defined in section 2 2 the outcome of the optimization is a set of non dominated solutions called the pareto approximate set in which no solution outperforms another on all objectives in this study we solve two separate optimizations to produce two distinct optimal vectors θ for each problem formulation described in section 2 2 3 3 1 formulation of objectives and constraints in order to evaluate system performance of our updated reservoir operations we define five operating objectives and a constraint to capture the multiple and conflicting needs of different stakeholders in the basin hydropower production environmental protection preservation of recession agriculture sugarcane yield cotton yield and flood protection hydropower the hydropower objective to be maximized is calculated as the average annual hydropower production across the four power plants in the omo river basin over the simulation horizon 5 j hyd 1 a h 0 h 1 i 1 n y g h 1 i where g h is the daily hydroelectric power production in gwh h is the number of time steps in the operating horizon here 13 879 days n y is the number of hydropower producing dams here 4 dams and a is the number of years here 30 years hydropower is calculated as 6 g h i η ρ g h h i m i n q h i q m a x i where ρ is the density of water g is the gravitational constant h h i is the hydraulic head of reservoir i on day h q h i is the total release from reservoir i on day h and q m a x h i is the maximum turbine capacity of reservoir i in the omo river basin the efficiency is 0 8 for all power plants the hydropower objective captures the interest of the ethiopian government environment this objective seeks to preserve natural flow conditions in the omo river delta the natural flow regime is defined by flow magnitude frequency duration timing and rate of change poff et al 1997 one common environmental flow objective is to minimize the difference between natural and regulated flow duration curves vogel et al 2007 capturing both the magnitude and frequency characteristics in the omo river basin the timing and magnitude of the seasonal cycle is important to fish spawning in lake turkana avery 2012 to capture this feature the environmental flows objective is computed as the daily average squared distance between the flow in the omo river delta q h delta and the natural pattern q h natomo to be minimized 7 j env 1 h h 0 h 1 q h 1 natomo q h 1 delta 2 the historical pattern is calculated as a 30 day rolling average of the cyclostationary daily mean flows in the delta from an uncontrolled model run using weather inputs from 1989 to 2018 with an 8 year spin up period from 1981 to 1988 this objective assumes that historical conditions are optimal for aquatic wildlife grazing patterns and overall environmental health in the omo river delta recession agriculture the recession agriculture objective is meant to preserve the annual flood pulse that indigenous tribes in the lower omo valley rely on for their main source of food and that the dams have historically dampened it is calculated as the daily average squared distance between flow in the lower omo q h 1 l o and a target artificial flood q h a f to be minimized 8 j rec 1 h h 0 h 1 m a x q h a f q h 1 l o 0 2 the target flood q h a f is zero for most of the year the recession pattern starts on august 29 and linearly increases from 240 cms to a peak of 1 200 cms on september 2 this target plateaus at 1 200 cms until september 11 and then decreases linearly until september 16 when it reaches 0 cms again fig 6a and b sugarcane yield the sugarcane objective is designed to capture the interests of the kuraz sugar development project whose goal is to maximize sugarcane yields swat simulates crop growth according to heat unity theory neitsch et al 2011 each plant has a minimum temperature above which it grows until reaching maturity determined by a plant specific number of potential heat units measured in growing degree days the potential amount of biomass that can accumulate over this time is controlled primarily by radiation which is positively correlated with temperature however actual crop yield is less than potential yield if the crop is under temperature or water stress swat allows users to implement irrigation triggered by a water stress threshold or soil water deficit threshold we implement the water stress threshold trigger as a decision variable in our optimization and seek to maximize simulated sugar and cotton yields this objective is calculated as the average annual sugarcane yield over the simulation horizon to be maximized 9 j sug 1 a a 0 a 1 s 1 s y a s where s is the number of sugarcane hrus representing the kuraz sugar development project a is the number of simulated years here 30 and y a s is the annual yield in a given sugarcane hru cotton yield the cotton objective is designed to capture the interests of private agricultural holdings which will likely primarily grow cotton carr 2017 hodbod et al 2019 this objective is calculated as the average annual cotton yield over the simulation horizon as calculated by swat to be maximized 10 j cot 1 a a 0 a 1 c 1 c y a c where c is the number of cotton hrus representing private agricultural holdings in the lower omo valley and y a c is the annual cotton yield in a given hru minimum environmental flow we ensure the reservoir releases meet mef requirements when feasible the mefs are 1 3 cms for gibe i 70 cms for gibe iii and 25 cms for koysha badagliacca and spinelli 2018 mdi consulting engineers 2016 flood constraint this optimization is subject to a constraint that specifies flows in the lower omo valley should not exceed their historical uncontrolled maximum 11 max q max l o 3290 0 0 where q max l o is the maximum flow in the lower omo valley over the simulation horizon and 3 290 cms is the maximum historical flow simulated in an uncontrolled model run this objective aims to mitigate flood concerns in the basin while indigenous tribes rely on a moderate flood pulse large floods have damaged their crops and dwellings and even resulted in loss of life eepco 2008 this was documented in august 2006 when a flood flows that peaked somewhere between 3 500 and 4 000 cms caused the death of hundreds of people and displaced thousands more we include this constraint so that we do not design policies that could cause such destructive flood pulses downstream 3 3 2 formulation of operating policies in the omo river basin for the existing monthly target operations in the swat model each of the reservoirs has thirteen parameters the target storage level for each month and the number of days it should take to reach the target storage in the context of the omo river basin there are three reservoirs gibe i gibe iii and koysha which means that there are a total of 39 parameters used to define reservoir releases the existing target storage operations are not fully state aware each reservoir s release decision is based only on its own storage level and the month but does not consider any additional system state information such as the storage at the other two reservoirs following the new policy formulation outlined in section 2 2 2 the parameter vector θ c i j b i j w i k with i 1 n j 1 b and k 1 k for the omo system we use n 9 rbfs k 3 reservoirs and b 5 inputs the storage at each of the three reservoirs and a cyclic representation of time captured by sin 2 π t 365 and cos 2 π t 365 all of which are normalized on 0 1 the total number of optimized parameters in each of the operating policies is k n 2b k 120 in addition to the 39 reservoir operating parameters that define monthly storage target operations and 120 reservoir operating parameters for coordinated release policies we also optimize 5 irrigation parameters the water stress threshold that triggers irrigation auto wstrs and the amount of irrigation water applied each time the auto irrigation is triggered irr mx for sugarcane and cotton as well as a single value of the water stress identifier wstrs id which decides whether irrigation is triggered by plant water demand or soil water content which we hold constant for both cotton and sugarcane this brings the total number of decision variables to 44 for the target storage operations and 125 for the coordinated release policies 3 3 3 multiobjective optimization algorithm in this study we use the borg multi objective evolutionary algorithm with the emodps framework to find the optimal parameter vector θ for both existing monthly storage target operations and updated release policies hadka and reed 2013 the borg moea which includes epsilon dominance archiving operators that can flag search stagnation randomized restarts to escape local optima and adaptive selection of search operators is highly robust in solving multi objective optimization problems and has been shown to perform as well or better than other moeas across a wide range of problem formulations hadka and reed 2013 we use a multimaster parallelization of the borg moea hadka and reed 2015 with two masters to optimize operating policies on rivanna the university of virginia s high performance hpc computing cluster a scaling analysis indicated that 240 cores yielded optimal performance rather than rivanna s maximum of 1 000 cores per job while the borg algorithm scales well hadka and reed 2015 the large number of input files required by the swat model degrades system performance and slows optimization as more copies of the model are required a single run of the swat model takes approximately 3 5 min we compare the performance of target storage operations and our coordinated release policies after 190 000 function evaluations which is the maximum number of function evaluations nfe that both problem formulations could achieve in 72 h the computation time limit on rivanna visual inspection of hypervolume a measure of the n dimensional volume of space dominated by a pareto approximation set indicates that the search was adequate for both problem formulations as hypervolume had leveled out indicating that we had reached a point of diminishing returns after 190 000 nfe see fig 2 in the supporting information we thin the pareto approximation sets by re sorting them with larger epsilon values table 5 of the supporting information to yield a reduced but representative set of operating policies for both existing and updated policy formulations 3 4 performance evaluation we first compare the performance of existing and updated reservoir operating policies on each objective under historical climate conditions to which they were optimized to assess the adaptivity of these respective policy designs we then compare their performance under alternative climate scenarios for each policy we calculate the five objective values over a 30 year horizon at mid century 2040 2069 and at the end of the century 2070 2099 in different climate projections we use daily projections from 17 general circulation models gcms in the coupled model intercomparison project 5 cmip5 multimodel ensemble with a single set of initial conditions across four representative concentration pathways rcps for a total of 48 different climate scenarios daily cmip5 estimates of precipitation minimum temperature and maximum temperature were bias corrected and spatially downscaled as described in section 1 3 of the supporting information a list of all climate projections used in the study is also provided in the supporting information table 4 4 results and discussion 4 1 performance evaluation across objectives we first compare the individual policies from the final thinned pareto approximation sets obtained using existing and updated reservoir operating rules the performance of the pareto approximate policies across our five operating objectives is visualized for both formulations in a parallel axis plot fig 4 a each vertical axis in these plots represents policy performance on each objective of interest while each line represents a single reservoir operating policy crossing the axes at its objective values which have been normalized over 0 1 where 0 is the best and 1 the worst here each axis is oriented such that favorable performance is down when lines intersect between the vertical axes this indicates trade offs between the corresponding objectives of those policies as can be seen in fig 4a strong policy performance on one objective often comes at the expense of one or more other objectives for example policies that perform best on the environmental flows objective tend to suffer on hydropower performance and vice versa fig 4a shows the performance of all optimized policies in their individual pareto sets we find that optimizing release policies results in more pareto optimal policies than optimizing existing target storage operations in swat there are 98 release policy pareto optimal solutions compared to 59 target storage solutions we then combine these individual pareto sets into a single set of pareto optimal reservoir operating policies shown in fig 4c we find that the updated swat policies tend to dominate policies designed with swat s existing reservoir operations meaning that the release policies tend to perform as well or better across all objectives compared to the monthly target storage policy formulation since 77 of the release policies make it into the combined pareto set 75 policies while only 41 of the storage target policies do 24 policies this suggests that the release policies dominate a larger space which is confirmed by examining their hypervolume the n dimensional volume of objective space that each pareto approximate set dominates see fig 2 of the supporting information in fact the release policies have a higher hypervolume for all nfe meaning they outperform the target storage policies throughout the optimization process despite having a higher number of decision variables that need to be optimized fig 4a and 4c shows that the release policies particularly outperform storage target operations on hydropower production and environmental flows objectives while still maintaining strong performance on the recession sugar and cotton objectives the target storage policies on the other hand struggle to balance these five objectives the target storage policies have particularly poor performance compared to the coordinated release policies on the environmental flows objective failing to produce operations that can mimic the pre dam flow regime that supports ecological health in the omo delta fig 4b and d shows histograms of euclidean distances of the policies in b the individual pareto sets and d combined pareto set from an ideal policy that attains optimal performance across all 5 objectives equivalent to a vector of zeros in the normalized objective space in both instances the release policy formulation has a greater number of policies with lower distances to the ideal policy than the target storage policy formulation indicating that coordinated release policies can better reduce socio ecological tradeoffs particularly after removing dominated policies however the release policy formulation also has a greater number of policies with higher distances to the ideal policy than the target storage policy formulation suggesting coordinated release policies can also perform better for individual objectives the greater range of distances for the release policy formulation demonstrates that coordinated release policies can produce a wider range of solutions for stakeholders to choose from than target storage operations yielding both stronger outcomes on most individual objectives and better compromise solutions that balance conflicting objectives 4 2 performance evaluation on individual objectives from each formulation s individual pareto set we select the five policies that perform best on each objective to analyze more deeply the performance of these policies is plotted in a parallel axis plot in fig 5 a and listed in tables 6 and 7 of the supporting information examining average daily reservoir storage levels allows us to see how different reservoir operations enable the solutions to attain near optimal performance on particular objectives average daily reservoir storage levels over the simulation horizon for monthly target storage policies are shown in fig 5b for gibe iii and 5d for koysha the two largest reservoirs storage levels at gibe iii tend to stay slightly higher for the best hydropower target storage policy but otherwise there are no clear trends across policies similarly storage levels are nearly the same across policies for koysha with only the best sugar policy distinguishing itself with a dip in reservoir levels in april to provide water for irrigation however this results in a spike in streamflow downstream at the same time since not all of this water was abstracted for irrigation fig 6a c a longer search time during optimization could likely find a policy that can provide adequate downstream flows for irrigation with a less dramatic release pattern for example the best policy for sugarcane with the coordinated release policy design has the highest average downstream flows during the dry season so that water is available for irrigation as needed without a dramatic pulse and while maintaining fairly high reservoir levels at koysha and achieving similar performance on sugarcane yields as the optimal target storage policy figs 5 and 6 b d differences across policies are much more significant for the new coordinated release policies fig 5c for gibe iii and fig 5e for koysha this demonstrates the ability of the updated reservoir operations to coordinate release behavior between reservoirs figs 3 and 4 of the supporting information further illustrate this coordination by plotting the rbf policies i e each major reservoir s prescribed release as a function its own storage the storage in the other major reservoir and the day of the year jointly operating the reservoirs in this way allows the release policies to exploit more reservoir storage than the existing target storage operations in swat which control each reservoir independently and therefore have less flexibility fig 5c and e the best policy for hydropower maintains notably higher reservoir levels at both gibe iii and koysha to create a high head differential for more power production the best policies for other objectives favor releasing more water downstream so reservoir levels are much lower the best policy for environmental flows has low levels at koysha on average likely because it needs to release a lot of water from this reservoir to achieve daily downstream flow targets however this same policy maintains the second highest reservoir levels on average at gibe iii the reservoir directly upstream from koysha showing how it coordinates operations between the two to balance conflicting objectives the best policies for recession agriculture sugarcane and cotton coordinate operations in the opposite manner maintaining fairly low levels at gibe iii and fairly high levels at koysha these policies generally need more water on demand either to meet the flood recession target or to supply water to crops during dry periods so keeping reservoir levels high at koysha ensures water is available to deliver downstream as needed the best policy for cotton rises around june in preparation for when cotton starts to grow in july while the levels at koysha stay high for the recession sugarcane and cotton objectives reservoir levels at gibe iii tend to stay fairly low this could be a mechanism to protect against unnecessarily high releases if the reservoir levels at gibe iii are low this reservoir can capture extra inflow so that koysha levels can stay high without risk of inundating downstream areas it is also informative to visualize how alternative reservoir release policy designs impact downstream flows fig 6 a b shows flows in the omo river valley where we aim to replicate a flood pulse from late august to mid september fig 6c d shows flows in the omo delta from different policy designs compared to the average historical pattern once again it is difficult to parse out trends in the target storage policies other than a spike in the releases for sugar in april additionally while the flows generally follow the natural hydrograph they are far more erratic due to the monthly storage targeting for the release policy formulation the best policies for environmental flows recession agriculture and sugar are able to mimic this behavior much more smoothly the best policy for hydropower dampens peak flows in the omo river valley and delta since it keeps the reservoir levels so high failing to meet historical targets this reduces intra annual variability with higher flows in may and lower flows in september the best policy for recession agriculture reaches a peak slightly after the environmental flows target in order to meet the timing of an ideal flood pulse the best policy for cotton dampens flows during the dry season and shifts the seasonality of flows so that the peak arrives in october to november 4 3 performance evaluation under climate change as a final comparison between the existing swat reservoir operations and the updated policy design we track how policies from the two operating strategies perform in swat simulations using weather inputs from 48 downscaled climate projections this assesses how robust the policies are to conditions outside of those to which they were optimized but under which they may need to operate in the future we plot the performance of each policy in mid and late century for each objective and climate scenario in fig 7 to illustrate if water infrastructure development is exacerbating or mitigating the impact of climate change on different stakeholders in the omo river basin we also plot the performance of an uncontrolled scenario i e no reservoirs and no irrigation under each climate scenario in black as a reference for how the system would perform without the reservoirs similar to fig 4 each line in fig 7 represents a different operating policy but the x axis here corresponds to different climate projections the climate projections are sorted from lowest to highest mean inflow for the hydropower environmental flows and recession agriculture objectives and from lowest to highest mean temperature for sugarcane and cotton yields as these climate characteristics are most predictive of their performance each objective is oriented such that the favorable direction is down as such we see that hydropower and recession agriculture performance improve with higher inflows while environmental flows degrade and sugarcane yields decrease with higher temperature while cotton yields increase to compare the robustness of different operating strategies we define policies as robust if they perform better than the uncontrolled scenarios across all objectives and all projections in both mid and late century 20 coordinated release policies from the combined pareto set meet these criteria while just 3 of the monthly target storage policies do policies that do not meet these criteria have been grayed out we see the best coordinated release policies for hydropower and environmental flows tend to outperform the target storage policies across all climate projections on these objectives it may be counterintutive that dam construction helps regulate environmental flows in this study the environmental flows objective is formulated to assess how well the reservoirs allow us to follow a smoothed cyclo stationary pattern of average historical daily flows in the omo river delta climate change may alter the timing and amount of precipitation and the optimized reservoir operating policies often outperform the projected uncontrolled scenario because the dams are able to shift flows back toward the historical hydrograph it is important to note that this may not mean that the dams are improving environmental outcomes across the board but rather that climate change is altering the historical flow pattern and the reservoir operations are helping preserve a historical flow pattern in the delta and helping prevent deviations from that flow pattern caused by climate change the target storage policies tend to outperform the coordinated release policies across all projections on recession agriculture and perform comparably on sugar cane and cotton yields this is because the only target storage policies that perform robustly across projections favor those objectives fig 8 a to understand why so few target storage policies are able to balance the five conflicting system objectives in possible climate futures compared to the coordinated release policies we investigate how the different operating rules adapt in response to alternative climate conditions for this comparison we choose an interesting compromise solution among the robust policies the historical performance of these compromise policies is shown in fig 8a along with the other policies that meet our robustness metric the non robust operating policies are grayed out fig 8b e illustrate the operating behavior of the two selected compromise policies under each climate projection each line represents the average daily reservoir storage in each climate projection the lines are colored by the average flow in the omo delta in that projection s uncontrolled scenario as a proxy for how wet or dry that climate projection is the average daily level of the operating policies during the historical record is shown with a thick black line we see reservoir levels at gibe iii drop in dry projections or rise slightly in wet projections compared to the historical average level for the coordinated release policy so that koysha levels can stay consistently high this ensures enough water is released from gibe iii and available in koysha to release downstream for environmental flows and recession agriculture in contrast the target storage policy tends to mirror levels at both reservoirs dropping or rising slightly depending on the projection there is no adaptive coordination just failure to meet target storage levels when supply is higher or lower this highlights the benefits of the coordinated release policies fully state aware control rule which allows it to adapt how it coordinates synergistic releases across reservoirs these features likely help release policies better balance downstream flow objectives across a wider range of future scenarios compared to target storage policies explaining why more release policies meet our robustness definition 4 4 spatial visualization figs 4 8 show how coordinated release policies advance the reservoir module within swat but most of these findings could have been discovered with traditional spatially lumped conceptual reservoir systems models as well where swat proves valuable is in it ability to 1 model the impact of climate change impacts without coupling an additional rainfall runoff model yielding the findings shown in figs 7 8 and in 2 allowing for a spatially explicit impact quantification we showcase these spatial capabilities in fig 9 which displays the flow in each reach of the omo river first row and soil moisture in each sub basin second row on the driest day during the historical simulation horizon in an uncontrolled scenario and for each of the coordinated release policies that performs best on each objective we also show each policy s storage trajectories at gibe iii and koysha during this year third row we can see that the reservoir operating policies that perform best on the sugarcane and cotton objectives increase soil moisture in the sub basins where these crops are produced labeled s and c respectively fig 9k l however we also see that these policies exacerbate low flows in the lower omo on this dry day as water is extracted from the river and used to irrigate crops fig 9e and f insufficient water remains because koysha is empty and has no water to supply while gibe iii is not emptying enough in advance of the drought to replenish it figures 9p q we see a similar tradeoff in reverse for the best environmental flows policy reservoir levels at both gibe iii and koysha are low since they are releasing as much water as possible to supply environmental flows in times of drought figure 9n resulting in increased flows in the lower omo compared to an uncontrolled scenario fig 9c but since little water is extracted from the river there is no change in soil moisture to help cultivate cotton and sugarcane in the sub basins of the lower omo fig 9i the ability to spatially visualize swat output allows users to explore policy impacts throughout the basin and find unintended benefits or consequences associated with alternative management strategies which could not be done with a traditional reservoir systems model this work demonstrates the value of allowing users to model flexible and coordinated reservoir releases in a hydrologic model 5 conclusions this study uses the multi reservoir omo river system in ethiopia to demonstrate the power of modeling closed loop nonlinear and state aware reservoir operating policies in a swat model the benefits of these release policies include producing non dominated policies that can perform as well or better than target storage operations across all economic agricultural social and ecological objectives as well as better compromise solutions controlling releases instead of storage levels which more directly impact objectives of hydropower production environmental targets and irrigation allowing for coordinated operations of the reservoir cascade and state adaptivity which is especially valuable for maintaining strong performance on out of sample climate change scenarios and greater flexibility through universal approximation instead of piecewise linear functions using emodps to optimize nonlinear operating policies in swat also allows us to capitalize on swat s ability to model both natural and human components of river systems better than traditional reservoir models such as hec ressim usace 2007 and riverware zagona et al 2001 for example we take advantage of swat s ability to simulate crop growth in order to directly optimize crop yields rather than relying on indirect objectives like minimizing water supply deficit furthermore simulating these policies in swat allows for a more accurate climate impact assessment than traditional reservoir simulation models that take streamflows as input as the rainfall runoff relationship is modeled explicitly in swat while not explored here swat can also facilitate more integrated assessments of how changes in multiple drivers beyond climate including changes in land use and land management influence vulnerabilities furthermore future work can explore how additional management decisions such as fertilizer application can be optimized in conjunction with alternative reservoir operating strategies as the climate changes the government private agricultural stakeholders and subsistence farmers will all need to make adaptation decisions in how they manage land and water resources and more sophisticated reservoir operations could ease that adaptation for example private agricultural stakeholders will need to decide when and how to apply fertilizer and irrigation or if they want to invest in soil conservation projects and subsistence farmers will need to decide which crops to plant in what quantities and whether or not they should migrate these decisions will all depend on how the government chooses to operate dams and whether or not they purchase more land for irrigable agriculture development the advanced reservoir operations in swat allow us to model a suite of optimized release rules in tandem with these possible changes in system dynamics to understand how changing climate and human decisions impact economic and socio ecological outcomes and to inform favorable adaptation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by funding from the university of virginia school of engineering and applied science the authors acknowledge research computing at the university of virginia for providing computational resources and technical support that have contributed to the results reported within this publication https rc virginia edu any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not necessarily reflect the views of the funding entities we also acknowledge and thank jared oyler for his public debiasing and downscaling code which made much of this work possible https github com scrim network red river and liang jun zhu whose github allowed us to update swat source code and create a linux compatible executable so we could run this model on rivanna the university of virginia s high performance computing system https github com watershedmodels swat we acknowledge eth for the omo river flow simulations used to calibrate our swat model and dafne for funding that effort under h2020 framework program of the european union grant number 690268 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105527 
25529,the soil water assessment tool swat is a useful model for evaluating socio ecological tradeoffs and analyzing coupled natural human system dynamics in agricultural watersheds however reservoir operating options in swat are limited this study advances the representation of reservoir operations in swat by adding an option for closed loop multi reservoir operating policies that can be optimized using evolutionary multi objective direct policy search this enables water managers to evaluate the tradeoffs across more coordinated reservoir operations in swat while capitalizing on the model s ability to physically simulate hydrological processes better than traditional reservoir simulation models comparing our advanced reservoir operations with swat s existing operating options in the omo river basin of ethiopia we find a wider range of policies for managing conflicting stakeholder objectives that better compromise across them and are more robust to climate change these advances to swat s reservoir module show promise for informing integrated water resources management keywords swat reservoir operations multi objective optimization climate change impacts data availability i have shared a link to data code in the manuscript software source code updates https github com sjordan29 swat source code updates climate scenarios https github com sjordan29 omo cmip downscaling debias optimization and figures https github com sjordan29 advancing swat reservoir ops developer sarah jordan smjordan329 gmail com source language python r fortran license gnu lesser general public license version 3 1 introduction socio ecological systems models are powerful tools for simulating interactions between human and natural systems to understand their vulnerabilities to different natural resources management policies and climatic stressors reed et al 2022 within the water resources literature the soil water assessment tool swat is a prominent tool for simulating these interactions in agricultural systems gassman et al 2014 wu et al 2020 swat is a semi distributed physically based watershed model capable of modeling surface and subsurface hydrology sediment transport plant growth and nutrient dynamics fig 1 the model was designed to enable users to evaluate the effects of alternative management decisions on water resources in large river basins arnold et al 2012 users can simulate crop planting harvesting irrigation and pesticide applications tillage operations and reservoir management to observe the impact that these human actions have on the natural system neitsch et al 2011 these include water quality impacts of erosion sedimentation and polluted runoff such as loads of nutrients pesticides bacteria and biochemical oxygen demand bod as well as water quantity impacts of changing hydrologic variability and seasonality neitsch et al 2011 not only can swat model one way impacts of human decisions on the environment but its open source code allows for integration with agent based models abms and other decision support tools that enable two way feedbacks between human decisions and environmental outcomes khan 2018 this allows modelers to simulate how humans may change their future management decisions in response to past decisions environmental impacts investigating how those two way interactions propagate to socio environmental outcomes a major water management strategy humans might change in response to observed environmental outcomes and in particular under climate change is reservoir operations however the representation of reservoir operations in swat2012 is simplistic and limited wu et al 2020 in the existing reservoir module users can input measured daily or monthly releases if historical information is available but this does not allow users to model how reservoirs might operate in the future for small uncontrolled reservoirs users can simply define an average annual release rate however many agricultural systems around the world are fed by large surface reservoirs with more variable operations these include mega dams in the american west as well as recent hydropower development in asia latin america and africa aimed at increasing electrification through hydropower production while also providing access to irrigation in areas with developing economies zhang et al 2018 to model large reservoirs like these users can define monthly reservoir target storages in swat neitsch et al 2011 yet this does not allow users to coordinate releases across reservoirs a common shortcoming of hydrological models for example rougé et al 2021 show that calculating releases for each reservoir independently i e without considering the storage in the other reservoirs in the system results in unrealistic outcomes and can have unintended consequences on flood and drought assessments this study seeks to fill this gap by incorporating an additional reservoir module in swat that implements more advanced reservoir control methods that allow for coordinated multi objective management reservoir managers are recognizing the value of such complex adaptive and coordinated rules and are becoming more open to integrating them into operations jasperse et al 2017 talbot et al 2017 recent advancements in multi objective optimal control methods have enabled the discovery of reservoir operating rules that can better balance conflicting socio ecological outcomes adapt to system variability or mitigate the impact of climate change all of which are essential for integrated reservoir management giuliani et al 2016b 2021 zaniolo et al 2021c however most applications of these advanced methods have been limited to reservoir systems models that do not physically model the rainfall runoff process or the ecological impacts of alternative operations this requires coupling multiple models to understand how changing climate conditions propagate through to water supply impacts see e g giuliani et al 2016a zaniolo et al 2021c steinschneider and brown 2012 or how water supply impacts propagate to agricultural or ecological impacts see e g georgiou and papamichail 2008 castelletti et al 2014 alternatively the reservoir simulation models rely on empirical representations of processes like erosion and sedimentation schmitt et al 2018 or proxy measures of agro ecological impacts like water supply deficits loucks and van beek 2017 there has been growing research on embedding reservoir operations in large scale hydrologic models but much of this work has been focused on calibrating the models while considering the impacts of human behavior rather than optimizing control rules for socioecological outcomes see e g dang et al 2020 nazemi and wheater 2015 wada et al 2014 2017 the limited work that has been done on designing multi purpose reservoir operations in swat has only optimized monthly releases and failed to coordinate releases across multiple reservoirs zhang et al 2011 anand et al 2018 this study combines the benefits of modeling flexible coordinated reservoir operations and physically modeling interactions between human and natural systems by advancing the representation of reservoir operations in swat we update the swat source code to enable the simulation and optimization of closed loop nonlinear and state aware reservoir operating policies designed with evolutionary multiobjective direct policy search giuliani et al 2016b we apply these updated policies to a multi objective multi reservoir control problem in the omo river basin ethiopia where a series of reservoirs must balance the irrigation needs of large scale agriculture with the downstream flow requirements of local communities and aquatic wildlife while still generating enough electricity output to justify the cost of hydropower development we compare the performance of existing reservoir operations in swat with the updated coordinated operations under historical and possible future climate conditions to see if we can define more resilient and robust management strategies that reduce socio ecological tradeoffs under a range of conditions while the present study only illustrates this reservoir module within the omo river basin the approach is generalizable and could be adapted to work in any context or in future iterations of the swat model e g swat 2 methods in this study we develop a new reservoir operating option for the swat model in which reservoir releases are coordinated following optimized nonlinear release rules we evaluate the performance of our release rules against policies optimized within an existing reservoir operating option in the swat model consisting of independent monthly storage targets for each reservoir this allows us to see if our operations option can discover policies that better meet the needs of conflicting stakeholders which we explore using a case study in the omo river basin see section 3 for this comparison we optimize both sets of policies using multi objective optimization here we describe how both sets of policies are formulated and optimized within swat 2 1 multi objective optimization of reservoir operations for both the existing and updated reservoir operating module we optimize release policies using evolutionary multi objective direct policy search emodps the emodps framework couples the direct policy search dps approach with multi objective evolutionary algorithms moeas giuliani et al 2016b emodps is a parameterization simulation optimization approach koutsoyiannis and economou 2003 that has been used to solve high dimensional water resources and control problems specifically emodps has been successfully used to define closed loop flexible reservoir operating policies that best balance multiple conflicting objectives giuliani et al 2016b the emodps framework defines a reservoir operating policy within a family of functions p θ in the current swat reservoir module these functions are piecewise linear storage targets described in section 2 2 1 for our new swat reservoir module these functions are gaussian radial basis functions rbfs described in section 2 2 2 the parameters of these functions θ are optimized with respect to operating objectives j using simulation optimization after an initial parameter set is defined the system is simulated and performance is evaluated based on the operating objectives the iterative search process of moeas is then able to create and evolve a pareto approximate set of solutions over the problem s conflicting objectives using randomized mating selection and mutation operations to modify the policy parameters the policy parameterization for each type of reservoir rules is described below 2 2 formulation of operating policies 2 2 1 existing swat reservoir operations swat s existing operating policies are based on monthly storage targets the storage target operations are piecewise linear functions for each reservoir in the system each reservoir s policy is defined by 13 parameters a target storage value for each month starg and the number of days it takes to reach the target storage ndtargr which is constant across all months daily reservoir releases v flowout are calculated as follows 1 v flowout v v targ n d targ where v is the volume of water stored in the reservoir v targ is the reservoir storage target and nd targ is the number of days for the reservoir to reach the target storage arnold et al 2012 once the outflow is determined with this method the model then adjusts the outflow to ensure that minimum and maximum discharge criteria are met existing target storage operations are not fully state aware each reservoir s release decision is based only on its own storage level and the month but does not consider any additional system state information such as the storage at other reservoirs in the system 2 2 2 updates to the swat reservoir module to enable more complex reservoir operating rules in swat we modify the source code of the reservoir module to provide an additional reservoir outflow simulation option that is capable of simulating non linear operating policies and coordinating releases across multiple reservoirs in a river system the modified source code reads non linear function parameters from user defined text files in the modparm and readres modules which are then passed to the reservoir module res and used to calculate daily releases using gaussian radial basis functions rbfs the rbfs determine release decisions as a function of multiple variables the reservoir storage volumes across all reservoirs in the system at the beginning of the day and the day of the year represented by sine and cosine functions with an annual period the source code is modified in order to pass this information to the rbfs these updates to the source code allow the model to calculate daily releases using information about the system state of all reservoirs all updates in this study were specific to the context of the omo river basin but could be generalized following the guidance outlined in the instructions manual of the source code updates github repository see link at top of paper we use gaussian rbfs for the non linear operating rules because giuliani et al 2016b show them to be more effective in solving multi objective policy design problems than other universal approximators like artificial neural networks anns operating policies defined by rbfs prescribe daily releases u t k normalized on 0 1 from the k th reservoir at time t as a function of b time varying inputs v t normalized on 0 1 and an optimized base release for the reservoir normalized on 0 1 a k 2 u t k a k i 1 n w i k exp j i b v t j c i j 2 b i j 2 here n is the total number of rbfs w i k is the weight of the i th rbf and v t is a vector of inputs normalized over 0 1 which here are the reservoir volumes at time t sin 2πt 365 and cos 2πt 365 b is the number of policy inputs and c i b i are the b dimensional center and radius vectors of the i th rbf respectively the weights are not constrained to sum to 1 and therefore do not represent a convex combination fig 2 reproduced from doering et al 2021 is an illustrative example of a reservoir operation policy defined by three rbfs which demonstrates the flexibility that rbf based operating policies can provide the weights centers and radii of these policies are optimized using multi objective optimization the number of these decision variables will depend on the number of rbfs n based on the authors experience an effective rule of thumb for n is b k 1 where b is the number of inputs and k is the number of outputs giuliani et al 2016a quinn et al 2018 future work could explore defining policies using neuro evolutionary multi objective direct policy search nemodps which optimizes not only the policy parameters but their structure requiring less trial and error from the modeler zaniolo et al 2021b when implementing these policies in swat the prescribed release u t k may not always be physically possible the true release realized by the end of day t r t 1 k is determined by subjecting the prescribed release to physical and minimum environmental flow mef constraints these ensure the releases meet mef requirements when feasible power outflows do not exceed the maximum capacity of the turbines and that the spillways are activated when necessary so the reservoir does not exceed its capacity 3 case study 3 1 omo river basin we evaluate the performance of our new reservoir operating option in swat using a case study in the omo river basin the omo river basin is a 79 000 km2 watershed in southwestern ethiopia that drains from the humid and mountainous shewan highlands to the hot and arid plain of the lower omo valley where the river spreads into a biodiverse delta at the ethiopia kenya border the river terminates at lake turkana in kenya which is the world s largest desert lake spanning over 130 000 km2 fig 3 avery 2012 this endoheric system was formed within the kenya rift avery 2010 historically the omo river basin has been a pastoral region where nomadic indigenous tribes migrate seasonally based on water and food availability which are controlled by the river s monsoonal flows as the inter tropical convergence zone itcz shifts northward from september to november and southward from march to may it brings with it rains that result in alternating wet and dry seasons sogreah 2010 rainfall in the northern omo basin peaks in august with a long dry season from november to march rainfall in the central omo basin exhibits a longer and less intense wet season from april to september and rainfall in the southern omo features two mildly rainy periods one in march and april and another in september and october total annual precipitation is highly variable throughout the watershed ranging from about 1 900 mm year in the northernmost parts of the basin to just 300 mm year in the southern omo near lake turkana however the historical flow pattern induced by these monsoonal rains is being altered by dam construction for hydropower production and the expansion of irrigable agriculture in the basin woodroofe 1996 the omo river basin has been a major target for hydropower projects because of its high hydropower potential large amounts of concentrated rainfall in the basin s highlands creates the second largest annual runoff of any river system in the country avery 2012 furthermore the omo river is steep flowing from an elevation of about 3 000 m in the highlands to 400 m at lake turkana over its 760 km length three power plants have been constructed in the omo river basin over the past 20 years gilgel gibe i ii and iii with another hydropower plant koysha under construction table 1 gibe i is a small dam with a powerplant gibe ii is just a powerplant and gibe iii and koysha are very large dams and powerplants the development of gibe iii and koysha megadams has been extremely controversial in the omo river basin since they promote economic development at the expense of indigenous people and ecological resources the gibe iii dam has been particularly controversial as questions surround the legitimacy of its environmental and social impact assessment esia and downstream flows significantly reduced during its filling phase and first few years in operation resulting in steep social impacts carr 2017 avery 2012 2014 continued hydropower development is planned in the omo river basin with the koysha dam ethiopia is working towards reaching self sufficiency in electricity production and 100 electricity access by 2025 with an end goal of becoming an energy exporter iea 2016 asress et al 2013 woodroofe 1996 as of 2016 the national electrification rate in ethiopia was just 25 leaving 75 of the population mainly those in rural areas like the omo river basin without access to electricity iea 2016 zaniolo et al 2021a expanding hydropower plants in the omo helps the country work towards its ambitious goals and the large storage reservoirs behind the dams enable more reliable electricity output in this arid region where 90 of the annual runoff is concentrated to just four months of the year sundin 2017 the storage reservoirs have also allowed for cultivation of large areas devoted to irrigable agriculture avery 2012 the state owned ethiopian sugar corporation esc is developing the kuraz sugar plantation downstream of the koysha dam which is currently projected to span 175 000 ha the esc aims to transform ethiopia from a sugar importer to a top ten global exporter davidson 2015 the ethiopian ministry of agriculture and natural resources has also leased approximately 85 000 ha of land south of the kuraz sugar development project to foreign and private investors oakland institute 2011 this land will primarily be used for cotton plantations carr 2017 hodbod et al 2019 these projects divert water from the main channel through irrigation canals enabling crop growth in an area that is too dry to support rain fed agriculture human rights watch 2017 while water infrastructure development has promoted economic growth through hydropower production and the expansion of irrigable agriculture it has negatively affected indigenous people and the ecological resources in the lower omo valley hathaway 2009 abbink 2012 fratkin 2014 the lower omo basin has historically been home to over 500 000 indigenous people and the development of large scale agriculture has resulted in the displacement and abuse of many indigenous communities oakland institute 2019 the indigenous groups that remain downstream of these developments are agropastoralists that rely on the omo river as their primary source of water and food however altered hydrology from the dams and irrigation diversions have adversely impacted these resources carr 2017 approximately 200 000 indigenous people in the lower omo valley practice flood recession agriculture as a primary source of food for their cattle this practice uses the annual inundations caused by the omo river s late summer flood pulse as a form of irrigation since the dry conditions in the lower omo cannot support rain fed agriculture carr 2017 at the start of the wet season in july the omo river starts to rise in the omo valley until it floods in august and september depositing silt on the floodplain once the flood recedes the shores of the river can be cultivated to produce maize and sorghum that serve as the primary food source for the tribes carr 2017 sogreah 2010 johnston 2009 water infrastructure development has dampened this flood pulse increasing the likelihood that there will be inadequate area to cultivate crops in any given year resulting in food shortages among indigenous populations the dams have also altered the natural annual hydrologic cycle in the omo river delta which feeds into lake turkana an endorheic lake that serves as a food and water source for another 300 000 indigenous people in ethiopia and kenya the omo river accounts for 90 of total inflows so flow patterns in the omo river and water levels in lake turkana are directly correlated sogreah 2010 the historical flood pulse supports the biodiversity in the delta and ensures fluctuations in lake turkana s levels which enable nutrient circulation support the spawning cycles of fish and replenish grazing land for livestock along the shores of the lake gownaris et al 2015 carr 2014 2017 avery 2012 continued disruption to lake turkana s natural oscillations could result in widespread food and water shortages and exacerbate conflicts between tribes over limited resources carr 2017 in this study we seek to find reservoir operating policies that balance all these conflicting demands on the omo river basin s water resources using the soil water assessment tool 3 2 swat model the soil water assessment tool is a semi distributed physically based river basin model arnold et al 1998 swat is one of the most widely used watershed scale models because it can simulate a range of hydrologic and environmental processes it can model hydrological processes sediment transport and routing nutrient and pesticide transport plant growth climate change and anthroprogenic features and activities gassman et al 2014 because it can model the interactions between natural and human processes it is an excellent tool for assessing the impact of alternative water management strategies on a variety of stakeholders we simulate the four dams described in section 3 by building a swat model of the omo river basin the model includes both constructed and planned hydropower plants and planned irrigable agricultural developments in the region unfortunately precipitation and streamflow data in the basin are limited and not open access we seek to create as accurate a model as possible given these data limitations but caution that the model should be further validated and refined as more data become available before any concrete recommendations are made to decision makers in the omo river basin the current formulation still represents a realistic system that serves as a useful test case for demonstrating the capabilities of updated swat reservoir operations in managing socio ecological tradeoffs details regarding the model setup including input data parameter sensitivity analysis and calibration are provided in the supporting information 3 3 formulation of multi objective optimization problem for our five objective problem for reservoir optimization in the omo river basin the emodps framework is mathematically defined as 3 p θ a r g m i n p θ j where 4 j j hyd j env j rec j sug j cot each element of j is defined in section 3 3 1 while the form of the operating policies p θ is defined in section 2 2 the outcome of the optimization is a set of non dominated solutions called the pareto approximate set in which no solution outperforms another on all objectives in this study we solve two separate optimizations to produce two distinct optimal vectors θ for each problem formulation described in section 2 2 3 3 1 formulation of objectives and constraints in order to evaluate system performance of our updated reservoir operations we define five operating objectives and a constraint to capture the multiple and conflicting needs of different stakeholders in the basin hydropower production environmental protection preservation of recession agriculture sugarcane yield cotton yield and flood protection hydropower the hydropower objective to be maximized is calculated as the average annual hydropower production across the four power plants in the omo river basin over the simulation horizon 5 j hyd 1 a h 0 h 1 i 1 n y g h 1 i where g h is the daily hydroelectric power production in gwh h is the number of time steps in the operating horizon here 13 879 days n y is the number of hydropower producing dams here 4 dams and a is the number of years here 30 years hydropower is calculated as 6 g h i η ρ g h h i m i n q h i q m a x i where ρ is the density of water g is the gravitational constant h h i is the hydraulic head of reservoir i on day h q h i is the total release from reservoir i on day h and q m a x h i is the maximum turbine capacity of reservoir i in the omo river basin the efficiency is 0 8 for all power plants the hydropower objective captures the interest of the ethiopian government environment this objective seeks to preserve natural flow conditions in the omo river delta the natural flow regime is defined by flow magnitude frequency duration timing and rate of change poff et al 1997 one common environmental flow objective is to minimize the difference between natural and regulated flow duration curves vogel et al 2007 capturing both the magnitude and frequency characteristics in the omo river basin the timing and magnitude of the seasonal cycle is important to fish spawning in lake turkana avery 2012 to capture this feature the environmental flows objective is computed as the daily average squared distance between the flow in the omo river delta q h delta and the natural pattern q h natomo to be minimized 7 j env 1 h h 0 h 1 q h 1 natomo q h 1 delta 2 the historical pattern is calculated as a 30 day rolling average of the cyclostationary daily mean flows in the delta from an uncontrolled model run using weather inputs from 1989 to 2018 with an 8 year spin up period from 1981 to 1988 this objective assumes that historical conditions are optimal for aquatic wildlife grazing patterns and overall environmental health in the omo river delta recession agriculture the recession agriculture objective is meant to preserve the annual flood pulse that indigenous tribes in the lower omo valley rely on for their main source of food and that the dams have historically dampened it is calculated as the daily average squared distance between flow in the lower omo q h 1 l o and a target artificial flood q h a f to be minimized 8 j rec 1 h h 0 h 1 m a x q h a f q h 1 l o 0 2 the target flood q h a f is zero for most of the year the recession pattern starts on august 29 and linearly increases from 240 cms to a peak of 1 200 cms on september 2 this target plateaus at 1 200 cms until september 11 and then decreases linearly until september 16 when it reaches 0 cms again fig 6a and b sugarcane yield the sugarcane objective is designed to capture the interests of the kuraz sugar development project whose goal is to maximize sugarcane yields swat simulates crop growth according to heat unity theory neitsch et al 2011 each plant has a minimum temperature above which it grows until reaching maturity determined by a plant specific number of potential heat units measured in growing degree days the potential amount of biomass that can accumulate over this time is controlled primarily by radiation which is positively correlated with temperature however actual crop yield is less than potential yield if the crop is under temperature or water stress swat allows users to implement irrigation triggered by a water stress threshold or soil water deficit threshold we implement the water stress threshold trigger as a decision variable in our optimization and seek to maximize simulated sugar and cotton yields this objective is calculated as the average annual sugarcane yield over the simulation horizon to be maximized 9 j sug 1 a a 0 a 1 s 1 s y a s where s is the number of sugarcane hrus representing the kuraz sugar development project a is the number of simulated years here 30 and y a s is the annual yield in a given sugarcane hru cotton yield the cotton objective is designed to capture the interests of private agricultural holdings which will likely primarily grow cotton carr 2017 hodbod et al 2019 this objective is calculated as the average annual cotton yield over the simulation horizon as calculated by swat to be maximized 10 j cot 1 a a 0 a 1 c 1 c y a c where c is the number of cotton hrus representing private agricultural holdings in the lower omo valley and y a c is the annual cotton yield in a given hru minimum environmental flow we ensure the reservoir releases meet mef requirements when feasible the mefs are 1 3 cms for gibe i 70 cms for gibe iii and 25 cms for koysha badagliacca and spinelli 2018 mdi consulting engineers 2016 flood constraint this optimization is subject to a constraint that specifies flows in the lower omo valley should not exceed their historical uncontrolled maximum 11 max q max l o 3290 0 0 where q max l o is the maximum flow in the lower omo valley over the simulation horizon and 3 290 cms is the maximum historical flow simulated in an uncontrolled model run this objective aims to mitigate flood concerns in the basin while indigenous tribes rely on a moderate flood pulse large floods have damaged their crops and dwellings and even resulted in loss of life eepco 2008 this was documented in august 2006 when a flood flows that peaked somewhere between 3 500 and 4 000 cms caused the death of hundreds of people and displaced thousands more we include this constraint so that we do not design policies that could cause such destructive flood pulses downstream 3 3 2 formulation of operating policies in the omo river basin for the existing monthly target operations in the swat model each of the reservoirs has thirteen parameters the target storage level for each month and the number of days it should take to reach the target storage in the context of the omo river basin there are three reservoirs gibe i gibe iii and koysha which means that there are a total of 39 parameters used to define reservoir releases the existing target storage operations are not fully state aware each reservoir s release decision is based only on its own storage level and the month but does not consider any additional system state information such as the storage at the other two reservoirs following the new policy formulation outlined in section 2 2 2 the parameter vector θ c i j b i j w i k with i 1 n j 1 b and k 1 k for the omo system we use n 9 rbfs k 3 reservoirs and b 5 inputs the storage at each of the three reservoirs and a cyclic representation of time captured by sin 2 π t 365 and cos 2 π t 365 all of which are normalized on 0 1 the total number of optimized parameters in each of the operating policies is k n 2b k 120 in addition to the 39 reservoir operating parameters that define monthly storage target operations and 120 reservoir operating parameters for coordinated release policies we also optimize 5 irrigation parameters the water stress threshold that triggers irrigation auto wstrs and the amount of irrigation water applied each time the auto irrigation is triggered irr mx for sugarcane and cotton as well as a single value of the water stress identifier wstrs id which decides whether irrigation is triggered by plant water demand or soil water content which we hold constant for both cotton and sugarcane this brings the total number of decision variables to 44 for the target storage operations and 125 for the coordinated release policies 3 3 3 multiobjective optimization algorithm in this study we use the borg multi objective evolutionary algorithm with the emodps framework to find the optimal parameter vector θ for both existing monthly storage target operations and updated release policies hadka and reed 2013 the borg moea which includes epsilon dominance archiving operators that can flag search stagnation randomized restarts to escape local optima and adaptive selection of search operators is highly robust in solving multi objective optimization problems and has been shown to perform as well or better than other moeas across a wide range of problem formulations hadka and reed 2013 we use a multimaster parallelization of the borg moea hadka and reed 2015 with two masters to optimize operating policies on rivanna the university of virginia s high performance hpc computing cluster a scaling analysis indicated that 240 cores yielded optimal performance rather than rivanna s maximum of 1 000 cores per job while the borg algorithm scales well hadka and reed 2015 the large number of input files required by the swat model degrades system performance and slows optimization as more copies of the model are required a single run of the swat model takes approximately 3 5 min we compare the performance of target storage operations and our coordinated release policies after 190 000 function evaluations which is the maximum number of function evaluations nfe that both problem formulations could achieve in 72 h the computation time limit on rivanna visual inspection of hypervolume a measure of the n dimensional volume of space dominated by a pareto approximation set indicates that the search was adequate for both problem formulations as hypervolume had leveled out indicating that we had reached a point of diminishing returns after 190 000 nfe see fig 2 in the supporting information we thin the pareto approximation sets by re sorting them with larger epsilon values table 5 of the supporting information to yield a reduced but representative set of operating policies for both existing and updated policy formulations 3 4 performance evaluation we first compare the performance of existing and updated reservoir operating policies on each objective under historical climate conditions to which they were optimized to assess the adaptivity of these respective policy designs we then compare their performance under alternative climate scenarios for each policy we calculate the five objective values over a 30 year horizon at mid century 2040 2069 and at the end of the century 2070 2099 in different climate projections we use daily projections from 17 general circulation models gcms in the coupled model intercomparison project 5 cmip5 multimodel ensemble with a single set of initial conditions across four representative concentration pathways rcps for a total of 48 different climate scenarios daily cmip5 estimates of precipitation minimum temperature and maximum temperature were bias corrected and spatially downscaled as described in section 1 3 of the supporting information a list of all climate projections used in the study is also provided in the supporting information table 4 4 results and discussion 4 1 performance evaluation across objectives we first compare the individual policies from the final thinned pareto approximation sets obtained using existing and updated reservoir operating rules the performance of the pareto approximate policies across our five operating objectives is visualized for both formulations in a parallel axis plot fig 4 a each vertical axis in these plots represents policy performance on each objective of interest while each line represents a single reservoir operating policy crossing the axes at its objective values which have been normalized over 0 1 where 0 is the best and 1 the worst here each axis is oriented such that favorable performance is down when lines intersect between the vertical axes this indicates trade offs between the corresponding objectives of those policies as can be seen in fig 4a strong policy performance on one objective often comes at the expense of one or more other objectives for example policies that perform best on the environmental flows objective tend to suffer on hydropower performance and vice versa fig 4a shows the performance of all optimized policies in their individual pareto sets we find that optimizing release policies results in more pareto optimal policies than optimizing existing target storage operations in swat there are 98 release policy pareto optimal solutions compared to 59 target storage solutions we then combine these individual pareto sets into a single set of pareto optimal reservoir operating policies shown in fig 4c we find that the updated swat policies tend to dominate policies designed with swat s existing reservoir operations meaning that the release policies tend to perform as well or better across all objectives compared to the monthly target storage policy formulation since 77 of the release policies make it into the combined pareto set 75 policies while only 41 of the storage target policies do 24 policies this suggests that the release policies dominate a larger space which is confirmed by examining their hypervolume the n dimensional volume of objective space that each pareto approximate set dominates see fig 2 of the supporting information in fact the release policies have a higher hypervolume for all nfe meaning they outperform the target storage policies throughout the optimization process despite having a higher number of decision variables that need to be optimized fig 4a and 4c shows that the release policies particularly outperform storage target operations on hydropower production and environmental flows objectives while still maintaining strong performance on the recession sugar and cotton objectives the target storage policies on the other hand struggle to balance these five objectives the target storage policies have particularly poor performance compared to the coordinated release policies on the environmental flows objective failing to produce operations that can mimic the pre dam flow regime that supports ecological health in the omo delta fig 4b and d shows histograms of euclidean distances of the policies in b the individual pareto sets and d combined pareto set from an ideal policy that attains optimal performance across all 5 objectives equivalent to a vector of zeros in the normalized objective space in both instances the release policy formulation has a greater number of policies with lower distances to the ideal policy than the target storage policy formulation indicating that coordinated release policies can better reduce socio ecological tradeoffs particularly after removing dominated policies however the release policy formulation also has a greater number of policies with higher distances to the ideal policy than the target storage policy formulation suggesting coordinated release policies can also perform better for individual objectives the greater range of distances for the release policy formulation demonstrates that coordinated release policies can produce a wider range of solutions for stakeholders to choose from than target storage operations yielding both stronger outcomes on most individual objectives and better compromise solutions that balance conflicting objectives 4 2 performance evaluation on individual objectives from each formulation s individual pareto set we select the five policies that perform best on each objective to analyze more deeply the performance of these policies is plotted in a parallel axis plot in fig 5 a and listed in tables 6 and 7 of the supporting information examining average daily reservoir storage levels allows us to see how different reservoir operations enable the solutions to attain near optimal performance on particular objectives average daily reservoir storage levels over the simulation horizon for monthly target storage policies are shown in fig 5b for gibe iii and 5d for koysha the two largest reservoirs storage levels at gibe iii tend to stay slightly higher for the best hydropower target storage policy but otherwise there are no clear trends across policies similarly storage levels are nearly the same across policies for koysha with only the best sugar policy distinguishing itself with a dip in reservoir levels in april to provide water for irrigation however this results in a spike in streamflow downstream at the same time since not all of this water was abstracted for irrigation fig 6a c a longer search time during optimization could likely find a policy that can provide adequate downstream flows for irrigation with a less dramatic release pattern for example the best policy for sugarcane with the coordinated release policy design has the highest average downstream flows during the dry season so that water is available for irrigation as needed without a dramatic pulse and while maintaining fairly high reservoir levels at koysha and achieving similar performance on sugarcane yields as the optimal target storage policy figs 5 and 6 b d differences across policies are much more significant for the new coordinated release policies fig 5c for gibe iii and fig 5e for koysha this demonstrates the ability of the updated reservoir operations to coordinate release behavior between reservoirs figs 3 and 4 of the supporting information further illustrate this coordination by plotting the rbf policies i e each major reservoir s prescribed release as a function its own storage the storage in the other major reservoir and the day of the year jointly operating the reservoirs in this way allows the release policies to exploit more reservoir storage than the existing target storage operations in swat which control each reservoir independently and therefore have less flexibility fig 5c and e the best policy for hydropower maintains notably higher reservoir levels at both gibe iii and koysha to create a high head differential for more power production the best policies for other objectives favor releasing more water downstream so reservoir levels are much lower the best policy for environmental flows has low levels at koysha on average likely because it needs to release a lot of water from this reservoir to achieve daily downstream flow targets however this same policy maintains the second highest reservoir levels on average at gibe iii the reservoir directly upstream from koysha showing how it coordinates operations between the two to balance conflicting objectives the best policies for recession agriculture sugarcane and cotton coordinate operations in the opposite manner maintaining fairly low levels at gibe iii and fairly high levels at koysha these policies generally need more water on demand either to meet the flood recession target or to supply water to crops during dry periods so keeping reservoir levels high at koysha ensures water is available to deliver downstream as needed the best policy for cotton rises around june in preparation for when cotton starts to grow in july while the levels at koysha stay high for the recession sugarcane and cotton objectives reservoir levels at gibe iii tend to stay fairly low this could be a mechanism to protect against unnecessarily high releases if the reservoir levels at gibe iii are low this reservoir can capture extra inflow so that koysha levels can stay high without risk of inundating downstream areas it is also informative to visualize how alternative reservoir release policy designs impact downstream flows fig 6 a b shows flows in the omo river valley where we aim to replicate a flood pulse from late august to mid september fig 6c d shows flows in the omo delta from different policy designs compared to the average historical pattern once again it is difficult to parse out trends in the target storage policies other than a spike in the releases for sugar in april additionally while the flows generally follow the natural hydrograph they are far more erratic due to the monthly storage targeting for the release policy formulation the best policies for environmental flows recession agriculture and sugar are able to mimic this behavior much more smoothly the best policy for hydropower dampens peak flows in the omo river valley and delta since it keeps the reservoir levels so high failing to meet historical targets this reduces intra annual variability with higher flows in may and lower flows in september the best policy for recession agriculture reaches a peak slightly after the environmental flows target in order to meet the timing of an ideal flood pulse the best policy for cotton dampens flows during the dry season and shifts the seasonality of flows so that the peak arrives in october to november 4 3 performance evaluation under climate change as a final comparison between the existing swat reservoir operations and the updated policy design we track how policies from the two operating strategies perform in swat simulations using weather inputs from 48 downscaled climate projections this assesses how robust the policies are to conditions outside of those to which they were optimized but under which they may need to operate in the future we plot the performance of each policy in mid and late century for each objective and climate scenario in fig 7 to illustrate if water infrastructure development is exacerbating or mitigating the impact of climate change on different stakeholders in the omo river basin we also plot the performance of an uncontrolled scenario i e no reservoirs and no irrigation under each climate scenario in black as a reference for how the system would perform without the reservoirs similar to fig 4 each line in fig 7 represents a different operating policy but the x axis here corresponds to different climate projections the climate projections are sorted from lowest to highest mean inflow for the hydropower environmental flows and recession agriculture objectives and from lowest to highest mean temperature for sugarcane and cotton yields as these climate characteristics are most predictive of their performance each objective is oriented such that the favorable direction is down as such we see that hydropower and recession agriculture performance improve with higher inflows while environmental flows degrade and sugarcane yields decrease with higher temperature while cotton yields increase to compare the robustness of different operating strategies we define policies as robust if they perform better than the uncontrolled scenarios across all objectives and all projections in both mid and late century 20 coordinated release policies from the combined pareto set meet these criteria while just 3 of the monthly target storage policies do policies that do not meet these criteria have been grayed out we see the best coordinated release policies for hydropower and environmental flows tend to outperform the target storage policies across all climate projections on these objectives it may be counterintutive that dam construction helps regulate environmental flows in this study the environmental flows objective is formulated to assess how well the reservoirs allow us to follow a smoothed cyclo stationary pattern of average historical daily flows in the omo river delta climate change may alter the timing and amount of precipitation and the optimized reservoir operating policies often outperform the projected uncontrolled scenario because the dams are able to shift flows back toward the historical hydrograph it is important to note that this may not mean that the dams are improving environmental outcomes across the board but rather that climate change is altering the historical flow pattern and the reservoir operations are helping preserve a historical flow pattern in the delta and helping prevent deviations from that flow pattern caused by climate change the target storage policies tend to outperform the coordinated release policies across all projections on recession agriculture and perform comparably on sugar cane and cotton yields this is because the only target storage policies that perform robustly across projections favor those objectives fig 8 a to understand why so few target storage policies are able to balance the five conflicting system objectives in possible climate futures compared to the coordinated release policies we investigate how the different operating rules adapt in response to alternative climate conditions for this comparison we choose an interesting compromise solution among the robust policies the historical performance of these compromise policies is shown in fig 8a along with the other policies that meet our robustness metric the non robust operating policies are grayed out fig 8b e illustrate the operating behavior of the two selected compromise policies under each climate projection each line represents the average daily reservoir storage in each climate projection the lines are colored by the average flow in the omo delta in that projection s uncontrolled scenario as a proxy for how wet or dry that climate projection is the average daily level of the operating policies during the historical record is shown with a thick black line we see reservoir levels at gibe iii drop in dry projections or rise slightly in wet projections compared to the historical average level for the coordinated release policy so that koysha levels can stay consistently high this ensures enough water is released from gibe iii and available in koysha to release downstream for environmental flows and recession agriculture in contrast the target storage policy tends to mirror levels at both reservoirs dropping or rising slightly depending on the projection there is no adaptive coordination just failure to meet target storage levels when supply is higher or lower this highlights the benefits of the coordinated release policies fully state aware control rule which allows it to adapt how it coordinates synergistic releases across reservoirs these features likely help release policies better balance downstream flow objectives across a wider range of future scenarios compared to target storage policies explaining why more release policies meet our robustness definition 4 4 spatial visualization figs 4 8 show how coordinated release policies advance the reservoir module within swat but most of these findings could have been discovered with traditional spatially lumped conceptual reservoir systems models as well where swat proves valuable is in it ability to 1 model the impact of climate change impacts without coupling an additional rainfall runoff model yielding the findings shown in figs 7 8 and in 2 allowing for a spatially explicit impact quantification we showcase these spatial capabilities in fig 9 which displays the flow in each reach of the omo river first row and soil moisture in each sub basin second row on the driest day during the historical simulation horizon in an uncontrolled scenario and for each of the coordinated release policies that performs best on each objective we also show each policy s storage trajectories at gibe iii and koysha during this year third row we can see that the reservoir operating policies that perform best on the sugarcane and cotton objectives increase soil moisture in the sub basins where these crops are produced labeled s and c respectively fig 9k l however we also see that these policies exacerbate low flows in the lower omo on this dry day as water is extracted from the river and used to irrigate crops fig 9e and f insufficient water remains because koysha is empty and has no water to supply while gibe iii is not emptying enough in advance of the drought to replenish it figures 9p q we see a similar tradeoff in reverse for the best environmental flows policy reservoir levels at both gibe iii and koysha are low since they are releasing as much water as possible to supply environmental flows in times of drought figure 9n resulting in increased flows in the lower omo compared to an uncontrolled scenario fig 9c but since little water is extracted from the river there is no change in soil moisture to help cultivate cotton and sugarcane in the sub basins of the lower omo fig 9i the ability to spatially visualize swat output allows users to explore policy impacts throughout the basin and find unintended benefits or consequences associated with alternative management strategies which could not be done with a traditional reservoir systems model this work demonstrates the value of allowing users to model flexible and coordinated reservoir releases in a hydrologic model 5 conclusions this study uses the multi reservoir omo river system in ethiopia to demonstrate the power of modeling closed loop nonlinear and state aware reservoir operating policies in a swat model the benefits of these release policies include producing non dominated policies that can perform as well or better than target storage operations across all economic agricultural social and ecological objectives as well as better compromise solutions controlling releases instead of storage levels which more directly impact objectives of hydropower production environmental targets and irrigation allowing for coordinated operations of the reservoir cascade and state adaptivity which is especially valuable for maintaining strong performance on out of sample climate change scenarios and greater flexibility through universal approximation instead of piecewise linear functions using emodps to optimize nonlinear operating policies in swat also allows us to capitalize on swat s ability to model both natural and human components of river systems better than traditional reservoir models such as hec ressim usace 2007 and riverware zagona et al 2001 for example we take advantage of swat s ability to simulate crop growth in order to directly optimize crop yields rather than relying on indirect objectives like minimizing water supply deficit furthermore simulating these policies in swat allows for a more accurate climate impact assessment than traditional reservoir simulation models that take streamflows as input as the rainfall runoff relationship is modeled explicitly in swat while not explored here swat can also facilitate more integrated assessments of how changes in multiple drivers beyond climate including changes in land use and land management influence vulnerabilities furthermore future work can explore how additional management decisions such as fertilizer application can be optimized in conjunction with alternative reservoir operating strategies as the climate changes the government private agricultural stakeholders and subsistence farmers will all need to make adaptation decisions in how they manage land and water resources and more sophisticated reservoir operations could ease that adaptation for example private agricultural stakeholders will need to decide when and how to apply fertilizer and irrigation or if they want to invest in soil conservation projects and subsistence farmers will need to decide which crops to plant in what quantities and whether or not they should migrate these decisions will all depend on how the government chooses to operate dams and whether or not they purchase more land for irrigable agriculture development the advanced reservoir operations in swat allow us to model a suite of optimized release rules in tandem with these possible changes in system dynamics to understand how changing climate and human decisions impact economic and socio ecological outcomes and to inform favorable adaptation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by funding from the university of virginia school of engineering and applied science the authors acknowledge research computing at the university of virginia for providing computational resources and technical support that have contributed to the results reported within this publication https rc virginia edu any opinions findings and conclusions or recommendations expressed in this material are those of the author s and do not necessarily reflect the views of the funding entities we also acknowledge and thank jared oyler for his public debiasing and downscaling code which made much of this work possible https github com scrim network red river and liang jun zhu whose github allowed us to update swat source code and create a linux compatible executable so we could run this model on rivanna the university of virginia s high performance computing system https github com watershedmodels swat we acknowledge eth for the omo river flow simulations used to calibrate our swat model and dafne for funding that effort under h2020 framework program of the european union grant number 690268 appendix a supplementary data the following is the supplementary data to this article multimedia component 1 multimedia component 1 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j envsoft 2022 105527 
