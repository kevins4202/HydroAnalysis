index,text
24495,forests are important for the global carbon cycle hydrothermal balance and climate change human activities can exert a significant impact on forest ecosystems thereby having the potential to alter their physical and chemical properties and thus affecting carbon water and heat budgets and climate change the historical reconstruction of the disturbance of global forests can help us understand the processes and patterns of human activities and global change in this paper we construct a deforestation prediction model using a spearman correlation coefficient and implement the xgboost method using python 3 6 for the reconstruction of deforestation intensity data from 2000 to 2019 secondly the selection of the driver indicators is done by using extreme difference regularization to unify the magnitude and the potential deforestation area risk index is calculated in the form of equal weights finally the actual deforestation data were used for optimization and validation the model shows that the deforestation hotspots are mainly concentrated in the southern and southeastern regions of china and that there are large differences in deforestation in different provinces in the future the fine spatial and temporal patterns of deforestation in china during the historical period can be quantitatively reconstructed which can provide some reference information for forest disaster prevention and forest management in china keywords china deforestation modeling reconstruction 1 introduction forest ecosystems are an important component of terrestrial ecosystems accounting for 86 of the global vegetation carbon stock and 73 of the global soil carbon pool woodwell et al 1978 post et al 1982 as such they play an important role in mitigating the greenhouse effect and maintaining the global climate system and energy cycle additionally forest cover change affects the provision of ecosystem services including biodiversity richness climate regulation kareiva et al 2007 although the importance of forest ecosystems has been recognized by the general public there is a lack of overall quantification and assessment of its components and resources he et al 2020 at present there have been some studies on the quantification and evaluation of ecosystems such as the assessment of changes in the composition and structure of the nitrogen and phosphorus cycles aks et al 2021 ga et al 2015 there are also studies classify and quantify the resources of the ecosystem such as constructing an ecosystem classification system and evaluating ecological assets ecological carrying capacity etc liu et al 2021 byron et al 2011 but in general there is still a lack of necessary ecological monitoring data to support the overall quantification and evaluation of ecosystem components and resources human factors have a non negligible impact on the evolution of forests and other ecosystems such as logging fires etc heinrich et al 2021 stenzel et al 2021 currently the main global forest disturbance datasets include the global forest overall disturbance change curtis et al 2018 constructed by the university of arkansas the global forest watch hansen et al 2013 developed by the university of maryland and the european forest disturbance schelhaas et al 2003 dataset developed by wageningen university the construction of deforestation datasets has been delayed for various reasons global forest watch uses global forest cover change gfc product to study the spatial distribution of deforestation this study analyzed 654178 growing season landsat 7 etm images from 1 3 million images and processed a total of 20 trillion pixels on 10 000 computers using 1 million cpu core hours over 1288mkm2 143 billion 30 m landsat pixels spatial extent has been extended to 2000 2019 according to hansen et al 2013 tropical forest loss and gain represents the largest of the four climatic regions and is the only region with a significant trend in forest loss with losses estimated to increase by 2101 km2 per year for example the deforestation rate in the amazon region dropped from 2 7 million hectares in 2004 to 500 000 hectares in 2012 inpe 2018 tropical deforestation is the largest contributor to carbon fluxes over the last decade when it accounted for 9 of the global carbon budget dez√©cache et al 2018 the increase in the range of livestock activities and the massive expansion of soybeans are the main causes of deforestation in this region arvor et al 2012 macedo et al 2012 in china the available forest history information is more abundant and there is even more recorded supplementary information in the form of maps statistics and surveys noting that the reconstruction accuracy with direct information such as forest statistics combined with proxy information such as population and arable land is more reliable than the reconstruction accuracy with proxy information alone at present two institutions in china have made china forest history datasets namely the 10 km resolution dataset of china from 1700 to 2000 constructed by the institute of geographic resources chinese academy of sciences in 2008 he et al 2015 and the 1 km resolution dataset of china from 1700 to 2000 constructed by nanjing university in 2018 yang et al 2018 hua et al 2021 monitored the spatial and temporal patterns of loss and recovery of subtropical forests in china from 1986 2019 however the studies were mostly focused on the period before 2000 and there is still a knowledge gap regarding the changes in deforestation after 2000 the long term goal of the paris agreement is to limit the increase in global average temperature to less than two degrees celsius compared to the pre industrial period and to strive to limit temperature increases to less than 1 5 degrees celsius to achieve this temperature control goal several countries around the world have announced their intention to become carbon neutral china has set a goal of achieving peak carbon by 2030 and carbon neutrality by 2060 sweden has announced its intention to achieve carbon neutrality by 2045 and several countries including japan south korea canada the uk and the company euromonitor have announced their goal to achieve carbon neutrality by 2050 zhang et al 2021 enhancing the carbon sink capacity of ecosystems plays an important role in mitigating global climate change fang et al 2018 li et al 2017 piao et al 2009 forests are the most important carbon reservoir in terrestrial ecosystems and enhancing the carbon sequestration capacity of forest ecosystems is an important way to potentially mitigate the carbon dioxide problem further noting that deforestation data reconstruction is important for china to cope with global climate change ni j 2013 zhang et al 2015 xu et al 2018 the analysis of deforestation data helps to develop carbon sequestration management measures as well as to enhance china s dominant position in the field of global climate change and it also helps government policy making departments to develop better forest management strategies the construction of a forest disturbance dataset is needed in china to reveal the spatial and temporal changes of anthropogenic disturbances that have occurred in recent years this needs to be done systematically and as finely as possible with the intent of establishing a foundation that will provide physical insight and even predict future outcomes on decadal timescales in the context of a background literary search we selected those publications that use the terms deforestation model or construction in title abstract and or keywords to visualize deforestation research trends in the china national knowledge infrastructure cnki journal database and web of science core collection database we obtained a total of 170 references the bibliometrics revealed that there were 123 documents with exact time records of these the largest amount of literature was in the 1990 2020 logging period 71 such as barona et al 2010 hosonuma et al 2012 wijaya et al 2015 dlamini 2016 sales et al 2017 qin et al 2019 rijal et al 2019 silva et al 2020 wang et al 2020 followed by the 1980 1990 range 33 there were 126 papers with exact logging locations documented south america has the highest number of studies with a total of 68 papers followed by asia and africa with relatively few studies in oceania and europe the main study areas are the tropics lorenz and pitman 2014 amin et al 2019 indonesia gaveau et al 2016 austin et al 2017 pujiono et al 2019 mexico mas et al 2004 vaca et al 2019 brazil and the amazon forest de souza and de marco 2014 godar et al 2014 braganca 2018 globally 43 papers deal with specific deforestation areas mainly at medium and small scales grau et al 2005 gasparri et al 2013 esmaeili and nasrnia 2014 gaveau et al 2016 reddy et al 2016 armenteras et al 2017 gollnow et al 2018 mataveli et al 2021 furthermore 69 articles deal with reconstruction methods with more models artificial intelligence and regression methods used newman et al 2014 subedi et al 2014 rodrigues filho et al 2015 jusys 2016 wang and qiu 2017 de souza and de marco 2018 khuc et al 2018 saha et al 2021 and fewer that used empirical methods mathematical analysis and calculation godar et al 2014 there are also 70 valid papers dealing with natural drivers of deforestation mechanisms and 106 valid papers on social drivers among the natural drivers elevation and slope are the most studied sales et al 2017 grinand et al 2020 saha et al 2021 about 53 followed by precipitation and distance factors aleman et al 2018 jusys 2018 vaca et al 2019 around 36 others such as soil slope direction average daily temperature forest fragmentation vegetation cover and latitude and longitude are mentioned less among the social drivers population density and distance factors are the most studied e g fuchs et al 2013 shehzad et al 2014 wijaya et al 2015 59 followed by gdp e g rosa et al 2013 sales et al 2017 policy factors e g wang and qiu 2017 about 16 and others e g household income road network density livestock population education and employment are relatively less involved the above bibliometric results show that relevant studies on deforestation present a small research scale and time from which a small amount of information such as the amount of deforestation can be directly mined for application therefore this paper first screens the main influencing factors of deforestation through a comprehensive search of the literature and meta analysis secondly the literature related to deforestation was carefully organized and the seven variables most frequently used as independent variables were extracted different regions research periods deforestation areas deforestation reconstruction methods main policy drivers and sources of error were considered in model development finally the constructed deforestation model will fully consider the spatial and temporal differences and accessibility of the main control factors construct the relationship between timber consumption and population timber stock in historical periods and its relationship with timber commerce in the associated periods and use it to estimate historical deforestation and calibrate the model with specific deforestation events in china to enhance the accuracy of the model 2 models and methods 2 1 map of deforestation intensity 2 1 1 construction of a deforestation prediction model the spearman correlation coefficient also known as the spearman rank correlation coefficient was used to correlate the indicators in the database and to screen the indicators for the construction of deforestation prediction models the spearman correlation coefficient is a non parametric rank statistic gauthier 2001 commonly used to measure the strength of association between variables that has the advantage of being independent of the distribution of the original data and is suitable for small sample size analysis zar 2004 in the absence of repeated data the spearman correlation coefficient is 1 or 1 if one variable is a strictly monotonic function of the other and the variables are said to be perfectly spearman correlated with the following formula figs 1 and 2 1 œÅ s 1 6 i 1 n r i j r i j 2 n n 2 1 where r i j and r i j is the rank of observations at different times at the same location i and n is the total number of observations 2 1 2 reconstruction of deforestation intensity data using the xgboost method xgboost which stands for extreme gradient boosting is an optimized distributed gradient boosting library designed to be efficient flexible and portable fig 3 it is an integrated learning algorithm based on gradient boosting trees where weak classifier iterative computation makes the algorithm loss function decrease along the gradient to achieve accurate classification chen and guestrin 2016 overall the algorithm has the advantages of being flexible fast in computation less susceptible to outliers and robust with features such as multi threaded computation use of regularization boosting techniques to reduce overfitting and to ensure the robustness of the model as well as customizable loss functions handling of sparse features and allowing for missing values huang and xie 2018 predictions of missing deforestation were made based on the constructed model the dataset was divided into a hierarchical training set 80 and a validation set 20 the construction of the xgboost model was implemented via python 3 6 in order to prove the reliability of the model this research also ran the ordinary multiple linear regression model linear regression bayesian linear regression model bayesian linear regression and support vector machine model support vector machine svm for model performance comparison linear regression is a regression analysis that uses the least square function called linear regression equation to model the relationship between one or more independent variables and dependent variables cohen et al 2003 and its data uses a linear predictive function to modeling and unknown model parameters are also estimated through data bayesian linear regression is a linear regression model solved by the bayesian inference method in statistics which regards the parameters of the linear model as random variables and calculates the posterior through the prior of model parameters weight coefficients rasmussen et al 2006 support vector machine is a kind of generalized linear classifier that classifies data binary in a supervised learning manner its decision boundary is the maximum margin hyperplane that is solved for the learning sample it uses the hinge loss function hinge loss to calculate empirical risk and adds a regularization term to the solution system to optimize structural risk it is a sparse and robust classification li hang 2012 non linear classification can be performed by the kernel method which is one of the common kernel learning methods hsieh et al 2009 2 2 deforestation risk map 2 2 1 source and processing of data for the assessment of potential deforestation area risk indices the national 1 km2 land use raster data meteorological raster data annual vegetation index ndvi raster data and dem digital elevation model data used to assess the potential deforestation area risk index were obtained from the resource and environment science and data center of the chinese academy of sciences http www resdc cn default aspx and the road traffic data originated from baidu maps http lbsyun baidu com 2 2 2 potential deforestation area risk index assessment methodology based on the selection of indicators research results in the literature on deforestation and the data availability of its drivers rudel et al 2009 houghton 2012 schultz et al 2016 dez√©cache et al 2017 curtis et al 2018 felipe lucia et al 2018 janssen et al 2018 twongyirwe et al 2018 amaral e silva et al 2020 bos et al 2020 hamunyela et al 2020 nansikombi et al 2020 rhyme et al 2020 trigueiro et al 2020 khalatbari et al 2021 a total of seven indicators of potential drivers were selected to construct a potential deforestation area risk index table 1 the sign of the correlations can be summarized as follows the lower the elevation the lower the slope the higher the temperature the higher the precipitation the higher the vegetation cover and the closer to the main road the higher the risk of potential deforestation area the indicator layers are shown in figure 4 after unifying the magnitudes of the different driver indicators using extreme difference regularization according to the overall relationship between different driving factors and deforestation in the existing literature 5 time periods are calculated in the form of equal weight the regional risk index of potential deforestation 1997 2000 2001 2005 2006 2010 2010 2015 and 2016 2020 figure 5 2 3 validation of deforestation simulation results the comparison data used for the validation of the simulation results were from hansen et al 2013 which helped to produce the chinese deforestation map generated in this study first the chinese region was extracted from the hansen deforestation database and the deforestation values for the whole country and each province were extracted through a series of arcgis operations such as merging cropping and extracting with a time scale of five years for one period second the deforestation values extracted from the hansen deforestation database are compared with the deforestation volume obtained from the xgboost machine learning simulations in this study to verify the accuracy of xgboost machine learning simulations the specific calculation method is shown in 2 2 validation results m a c h i n e l e a r n i n g r e s u l t s h a n s e n d a t a s e t m a c h i n e l e a r n i n g r e s u l t s 100 3 results and discussion 3 1 map of deforestation intensity the results of the analysis as shown in figure 6 show that deforestation has a high correlation with crop yield urban development and construction and forest scale related indicators at the same time the interaction between crop yield category indicators and crop yield related indicators with forest scale category indicators and urban development category indicators also have a high correlation based on the above correlation analysis results and review of existing literature the xgboost model was constructed as a timber yield prediction model by selecting the total output value of agriculture forestry animal husbandry and fishery total afforestation area number of forest fires area of nature reserves and gdp per capita as the independent variables and used timber yield indicators as the dependent variables and the r2 of the model reached 0 75 with good generalization performance as shown in figure 7 the two regions with higher deforestation intensity are the northeast and southeast and the overall trend is gradually decreasing from east to west among them 16 provinces and autonomous regions including qinghai sichuan shanghai gansu and the tibet autonomous region have reduced deforestation intensity during this period by 128 69 49 69 98 69 94 01 and 69 67 respectively between 2000 and 2019 fifteen provinces and autonomous regions including shanxi province guangxi zhuang autonomous region hainan province and guangdong province saw a total increase in deforestation intensity 1408 28 998 76 277 26 and 255 73 respectively from 2000 2019 the main reason for this discrepancy is the shift in china s forestry policy from timber production oriented to ecological construction oriented in 1998 followed by the implementation of a complete halt to commercial logging of natural forests nationwide and the introduction of logging quotas in 2017 the southeastern part of the country has a more favorable geographical location and hydrothermal condition higher forest density less frequent forest fires and pests as well as an extensive distribution of fast growing and productive forests the functional demands of society on forests are closely linked to socioeconomic development and the more developed processing and manufacturing industries associated with the dense population in the southeast provide a strong driver for further deforestation to demonstrate the reliability of the models this study ran the ordinary multiple linear regression model the bayesian linear regression model and the support vector machine model simultaneously for model performance comparison table 2 shows the results of the multi metric evaluation of each model and it can be seen that the xgboost model demonstrated superior skill in predicting this dataset over the other three comparison models cross validation is also used to establish independent channels to evaluate the generalization ability of each machine learning algorithm on the test and training sets to prevent overfitting caused by overly complex models the results of the five fold cross validation are shown in table 3 and it can be seen that the five fold cross validation of xgboost is also the best among the other three models 3 2 deforestation risk and intensity map integration process after obtaining the national deforestation risk raster it needs to be combined with the sub provincial deforestation intensity predicted by the machine learning model in this study r version 4 0 3 is used and r language packages are used for raster operations rgdal raster and the process is integrated as shown in figure 8 below first a sub provincial ranking of the combined felling risk was performed to obtain the potential risk ranking of felled rasters within each provincial administrative area second the logging image elements were assigned by combining the logging intensity data predicted by the machine learning model by province the deforestation image allocation process was performed on raster data with a spatial resolution of 1 km and stopped when the area of each province allocated image reached the predicted area the final deforestation pattern data was obtained nationwide and subsequently the collection of chinese deforestation events a total of 34 valid events covering 1980 2020 was added as a variable to the risk map for local correction the resultant totals for the years 2000 2005 2010 2015 and 2020 were obtained for this study and the final results are shown in figure 9 3 3 comparison of deforestation simulation results in research method johon et al 2021 uses landsat 8 images establishes a baseline and defines the scope of the national forest based on xgboost machine learning successfully identifying annual trends in khalatbari et al 2021 the authors use 10 bioclimatic variables as the most important factors to study the environmental variables that affect the distribution of oriental beech in this paper the spearman correlation coefficient of bioclimatic variables is used to construct a deforestation prediction model and python 3 6 is used to implement the xgboost method which is used to reconstruct the deforestation intensity data from 2000 to 2019 in the comparison of the model results through comparison with the deforestation dataset assembled by hansen et al 2013 and published in science this is the world s first high resolution map showing deforestation on earth over the last 20 years their work is ultimately the result of a collaboration between google and the university of maryland nasa and the u s geological survey as a global and freely available dataset it offers extensive forest change information therefore this data set is used to verify the error of our model and to evaluate the accuracy of the model in china as shown in table 4 the results of this study were first compared numerically with the hansen et al 2013 dataset with the intent of providing a detailed understanding of the magnitude of differences in logging results over time for specific provinces and municipalities expressed as a percentage the numerical comparisons are generally manageable but exhibit large variability in some of the results there are two main reasons for this 1 hansen et al 2013 deforestation dataset is a global map of forest loss and gain at a spatial resolution of 30 m and due to the large global scale of the study there is a large potential for specific regional errors 2 the amount of deforestation obtained from the xgboost machine learning simulations in this study was verified by real deforestation events and model calibration therefore the simulation results of this study are more accurate and credible within the chinese region and there is a reasonable degree of variation between the two results as shown in figure 10 the results are presented in map form and compared with the hansen et al 2013 dataset in terms of distribution extent and intensity the results show that the spatial distribution of both is essentially the same mainly distributed in the eastern coastal areas of china showing more in the south and less in the north and a decreasing trend from southeast to northwest this is consistent with the actual distribution of forests in china as well as with the distribution pattern of socioeconomic conditions driving deforestation however the results of this dataset are mainly concentrated in the southern part of china while the results of the hansen et al 2013 dataset have higher concentrations in comparison that are distributed in the eastern coastal region since this study uses actual deforestation events as model validation and calibration the deforestation results from this study are more credible and more consistent with the current deforestation situation in china than the hansen et al 2013 dataset 4 conclusion this paper constructs a prediction model of deforestation volume and uses the xgboost method to reconstruct deforestation intensity data and finally verifies the optimization by actual deforestation data the model shows that the deforestation hotspots are mainly concentrated in the southern and southeastern regions of china and that there are large differences in deforestation in different provinces which is consistent with the spatial pattern of the hansen et al 2013 dataset in addition the model has a high degree of confidence due to the inclusion of specific deforestation events in china that were used for model calibration and validation the deforestation model is based on highly detailed natural disturbance data of chinese forests which can provide some reference information for forest disaster prevention and forest management in china and can also quantitatively reconstruct the fine spatial and temporal patterns of deforestation in china during the historical period which is important for the in depth understanding of the historical changes and internal mechanisms of chinese terrestrial forests in addition it can provide a database and a theoretical guarantee for future historical changes in china s forest carbon pool and eventually provide scientific data support for china s climate negotiations and the development of domestic and international carbon trading markets in the future we can further study the dynamic changes of forest disturbance and its driving mechanisms which can provide experience and inspiration for solving forest related ecological problems and developing management methods this method combined with government action will allow china to take the lead in mitigating climate change funding this work was supported by the national key research and development program of china no 2019yfa0606602 credit author statement we wish to confirm that there are no known conflicts of interest associated with this publication and this manuscript has not been submitted to nor is under review at another journal or other publishing venue we confirm that the manuscript has been read and approved by all named authors and that there are no other persons who satisfied the criteria for authorship but are not listed we further confirm that the order of authors listed in the manuscript has been approved by all of us we confirm that we have given due consideration to the protection of intellectual property associated with this work and that there are no impediments to publication including the timing of publication with respect to intellectual property in so doing we confirm that we have followed the regulations of our institutions concerning intellectual property we understand that the corresponding author is the sole contact for the editorial process including editorial manager and direct communications with the office he she is responsible for communicating with the other authors about progress submissions of revisions and final approval of proofs we confirm that we have provided a current correct email address which is accessible by the corresponding author and which has been configured to accept email from scli urban pku edu cn yajuan zhang writing reviewing and editing data curation lijin zhang visualization investigation huan wang conceptualization data curation yueyao wang methodology software jiaqi ding software validationjiashu shen methodology zheng wang methodology yinglu liu data curation chenyu liang data curation shuangcheng li supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
24495,forests are important for the global carbon cycle hydrothermal balance and climate change human activities can exert a significant impact on forest ecosystems thereby having the potential to alter their physical and chemical properties and thus affecting carbon water and heat budgets and climate change the historical reconstruction of the disturbance of global forests can help us understand the processes and patterns of human activities and global change in this paper we construct a deforestation prediction model using a spearman correlation coefficient and implement the xgboost method using python 3 6 for the reconstruction of deforestation intensity data from 2000 to 2019 secondly the selection of the driver indicators is done by using extreme difference regularization to unify the magnitude and the potential deforestation area risk index is calculated in the form of equal weights finally the actual deforestation data were used for optimization and validation the model shows that the deforestation hotspots are mainly concentrated in the southern and southeastern regions of china and that there are large differences in deforestation in different provinces in the future the fine spatial and temporal patterns of deforestation in china during the historical period can be quantitatively reconstructed which can provide some reference information for forest disaster prevention and forest management in china keywords china deforestation modeling reconstruction 1 introduction forest ecosystems are an important component of terrestrial ecosystems accounting for 86 of the global vegetation carbon stock and 73 of the global soil carbon pool woodwell et al 1978 post et al 1982 as such they play an important role in mitigating the greenhouse effect and maintaining the global climate system and energy cycle additionally forest cover change affects the provision of ecosystem services including biodiversity richness climate regulation kareiva et al 2007 although the importance of forest ecosystems has been recognized by the general public there is a lack of overall quantification and assessment of its components and resources he et al 2020 at present there have been some studies on the quantification and evaluation of ecosystems such as the assessment of changes in the composition and structure of the nitrogen and phosphorus cycles aks et al 2021 ga et al 2015 there are also studies classify and quantify the resources of the ecosystem such as constructing an ecosystem classification system and evaluating ecological assets ecological carrying capacity etc liu et al 2021 byron et al 2011 but in general there is still a lack of necessary ecological monitoring data to support the overall quantification and evaluation of ecosystem components and resources human factors have a non negligible impact on the evolution of forests and other ecosystems such as logging fires etc heinrich et al 2021 stenzel et al 2021 currently the main global forest disturbance datasets include the global forest overall disturbance change curtis et al 2018 constructed by the university of arkansas the global forest watch hansen et al 2013 developed by the university of maryland and the european forest disturbance schelhaas et al 2003 dataset developed by wageningen university the construction of deforestation datasets has been delayed for various reasons global forest watch uses global forest cover change gfc product to study the spatial distribution of deforestation this study analyzed 654178 growing season landsat 7 etm images from 1 3 million images and processed a total of 20 trillion pixels on 10 000 computers using 1 million cpu core hours over 1288mkm2 143 billion 30 m landsat pixels spatial extent has been extended to 2000 2019 according to hansen et al 2013 tropical forest loss and gain represents the largest of the four climatic regions and is the only region with a significant trend in forest loss with losses estimated to increase by 2101 km2 per year for example the deforestation rate in the amazon region dropped from 2 7 million hectares in 2004 to 500 000 hectares in 2012 inpe 2018 tropical deforestation is the largest contributor to carbon fluxes over the last decade when it accounted for 9 of the global carbon budget dez√©cache et al 2018 the increase in the range of livestock activities and the massive expansion of soybeans are the main causes of deforestation in this region arvor et al 2012 macedo et al 2012 in china the available forest history information is more abundant and there is even more recorded supplementary information in the form of maps statistics and surveys noting that the reconstruction accuracy with direct information such as forest statistics combined with proxy information such as population and arable land is more reliable than the reconstruction accuracy with proxy information alone at present two institutions in china have made china forest history datasets namely the 10 km resolution dataset of china from 1700 to 2000 constructed by the institute of geographic resources chinese academy of sciences in 2008 he et al 2015 and the 1 km resolution dataset of china from 1700 to 2000 constructed by nanjing university in 2018 yang et al 2018 hua et al 2021 monitored the spatial and temporal patterns of loss and recovery of subtropical forests in china from 1986 2019 however the studies were mostly focused on the period before 2000 and there is still a knowledge gap regarding the changes in deforestation after 2000 the long term goal of the paris agreement is to limit the increase in global average temperature to less than two degrees celsius compared to the pre industrial period and to strive to limit temperature increases to less than 1 5 degrees celsius to achieve this temperature control goal several countries around the world have announced their intention to become carbon neutral china has set a goal of achieving peak carbon by 2030 and carbon neutrality by 2060 sweden has announced its intention to achieve carbon neutrality by 2045 and several countries including japan south korea canada the uk and the company euromonitor have announced their goal to achieve carbon neutrality by 2050 zhang et al 2021 enhancing the carbon sink capacity of ecosystems plays an important role in mitigating global climate change fang et al 2018 li et al 2017 piao et al 2009 forests are the most important carbon reservoir in terrestrial ecosystems and enhancing the carbon sequestration capacity of forest ecosystems is an important way to potentially mitigate the carbon dioxide problem further noting that deforestation data reconstruction is important for china to cope with global climate change ni j 2013 zhang et al 2015 xu et al 2018 the analysis of deforestation data helps to develop carbon sequestration management measures as well as to enhance china s dominant position in the field of global climate change and it also helps government policy making departments to develop better forest management strategies the construction of a forest disturbance dataset is needed in china to reveal the spatial and temporal changes of anthropogenic disturbances that have occurred in recent years this needs to be done systematically and as finely as possible with the intent of establishing a foundation that will provide physical insight and even predict future outcomes on decadal timescales in the context of a background literary search we selected those publications that use the terms deforestation model or construction in title abstract and or keywords to visualize deforestation research trends in the china national knowledge infrastructure cnki journal database and web of science core collection database we obtained a total of 170 references the bibliometrics revealed that there were 123 documents with exact time records of these the largest amount of literature was in the 1990 2020 logging period 71 such as barona et al 2010 hosonuma et al 2012 wijaya et al 2015 dlamini 2016 sales et al 2017 qin et al 2019 rijal et al 2019 silva et al 2020 wang et al 2020 followed by the 1980 1990 range 33 there were 126 papers with exact logging locations documented south america has the highest number of studies with a total of 68 papers followed by asia and africa with relatively few studies in oceania and europe the main study areas are the tropics lorenz and pitman 2014 amin et al 2019 indonesia gaveau et al 2016 austin et al 2017 pujiono et al 2019 mexico mas et al 2004 vaca et al 2019 brazil and the amazon forest de souza and de marco 2014 godar et al 2014 braganca 2018 globally 43 papers deal with specific deforestation areas mainly at medium and small scales grau et al 2005 gasparri et al 2013 esmaeili and nasrnia 2014 gaveau et al 2016 reddy et al 2016 armenteras et al 2017 gollnow et al 2018 mataveli et al 2021 furthermore 69 articles deal with reconstruction methods with more models artificial intelligence and regression methods used newman et al 2014 subedi et al 2014 rodrigues filho et al 2015 jusys 2016 wang and qiu 2017 de souza and de marco 2018 khuc et al 2018 saha et al 2021 and fewer that used empirical methods mathematical analysis and calculation godar et al 2014 there are also 70 valid papers dealing with natural drivers of deforestation mechanisms and 106 valid papers on social drivers among the natural drivers elevation and slope are the most studied sales et al 2017 grinand et al 2020 saha et al 2021 about 53 followed by precipitation and distance factors aleman et al 2018 jusys 2018 vaca et al 2019 around 36 others such as soil slope direction average daily temperature forest fragmentation vegetation cover and latitude and longitude are mentioned less among the social drivers population density and distance factors are the most studied e g fuchs et al 2013 shehzad et al 2014 wijaya et al 2015 59 followed by gdp e g rosa et al 2013 sales et al 2017 policy factors e g wang and qiu 2017 about 16 and others e g household income road network density livestock population education and employment are relatively less involved the above bibliometric results show that relevant studies on deforestation present a small research scale and time from which a small amount of information such as the amount of deforestation can be directly mined for application therefore this paper first screens the main influencing factors of deforestation through a comprehensive search of the literature and meta analysis secondly the literature related to deforestation was carefully organized and the seven variables most frequently used as independent variables were extracted different regions research periods deforestation areas deforestation reconstruction methods main policy drivers and sources of error were considered in model development finally the constructed deforestation model will fully consider the spatial and temporal differences and accessibility of the main control factors construct the relationship between timber consumption and population timber stock in historical periods and its relationship with timber commerce in the associated periods and use it to estimate historical deforestation and calibrate the model with specific deforestation events in china to enhance the accuracy of the model 2 models and methods 2 1 map of deforestation intensity 2 1 1 construction of a deforestation prediction model the spearman correlation coefficient also known as the spearman rank correlation coefficient was used to correlate the indicators in the database and to screen the indicators for the construction of deforestation prediction models the spearman correlation coefficient is a non parametric rank statistic gauthier 2001 commonly used to measure the strength of association between variables that has the advantage of being independent of the distribution of the original data and is suitable for small sample size analysis zar 2004 in the absence of repeated data the spearman correlation coefficient is 1 or 1 if one variable is a strictly monotonic function of the other and the variables are said to be perfectly spearman correlated with the following formula figs 1 and 2 1 œÅ s 1 6 i 1 n r i j r i j 2 n n 2 1 where r i j and r i j is the rank of observations at different times at the same location i and n is the total number of observations 2 1 2 reconstruction of deforestation intensity data using the xgboost method xgboost which stands for extreme gradient boosting is an optimized distributed gradient boosting library designed to be efficient flexible and portable fig 3 it is an integrated learning algorithm based on gradient boosting trees where weak classifier iterative computation makes the algorithm loss function decrease along the gradient to achieve accurate classification chen and guestrin 2016 overall the algorithm has the advantages of being flexible fast in computation less susceptible to outliers and robust with features such as multi threaded computation use of regularization boosting techniques to reduce overfitting and to ensure the robustness of the model as well as customizable loss functions handling of sparse features and allowing for missing values huang and xie 2018 predictions of missing deforestation were made based on the constructed model the dataset was divided into a hierarchical training set 80 and a validation set 20 the construction of the xgboost model was implemented via python 3 6 in order to prove the reliability of the model this research also ran the ordinary multiple linear regression model linear regression bayesian linear regression model bayesian linear regression and support vector machine model support vector machine svm for model performance comparison linear regression is a regression analysis that uses the least square function called linear regression equation to model the relationship between one or more independent variables and dependent variables cohen et al 2003 and its data uses a linear predictive function to modeling and unknown model parameters are also estimated through data bayesian linear regression is a linear regression model solved by the bayesian inference method in statistics which regards the parameters of the linear model as random variables and calculates the posterior through the prior of model parameters weight coefficients rasmussen et al 2006 support vector machine is a kind of generalized linear classifier that classifies data binary in a supervised learning manner its decision boundary is the maximum margin hyperplane that is solved for the learning sample it uses the hinge loss function hinge loss to calculate empirical risk and adds a regularization term to the solution system to optimize structural risk it is a sparse and robust classification li hang 2012 non linear classification can be performed by the kernel method which is one of the common kernel learning methods hsieh et al 2009 2 2 deforestation risk map 2 2 1 source and processing of data for the assessment of potential deforestation area risk indices the national 1 km2 land use raster data meteorological raster data annual vegetation index ndvi raster data and dem digital elevation model data used to assess the potential deforestation area risk index were obtained from the resource and environment science and data center of the chinese academy of sciences http www resdc cn default aspx and the road traffic data originated from baidu maps http lbsyun baidu com 2 2 2 potential deforestation area risk index assessment methodology based on the selection of indicators research results in the literature on deforestation and the data availability of its drivers rudel et al 2009 houghton 2012 schultz et al 2016 dez√©cache et al 2017 curtis et al 2018 felipe lucia et al 2018 janssen et al 2018 twongyirwe et al 2018 amaral e silva et al 2020 bos et al 2020 hamunyela et al 2020 nansikombi et al 2020 rhyme et al 2020 trigueiro et al 2020 khalatbari et al 2021 a total of seven indicators of potential drivers were selected to construct a potential deforestation area risk index table 1 the sign of the correlations can be summarized as follows the lower the elevation the lower the slope the higher the temperature the higher the precipitation the higher the vegetation cover and the closer to the main road the higher the risk of potential deforestation area the indicator layers are shown in figure 4 after unifying the magnitudes of the different driver indicators using extreme difference regularization according to the overall relationship between different driving factors and deforestation in the existing literature 5 time periods are calculated in the form of equal weight the regional risk index of potential deforestation 1997 2000 2001 2005 2006 2010 2010 2015 and 2016 2020 figure 5 2 3 validation of deforestation simulation results the comparison data used for the validation of the simulation results were from hansen et al 2013 which helped to produce the chinese deforestation map generated in this study first the chinese region was extracted from the hansen deforestation database and the deforestation values for the whole country and each province were extracted through a series of arcgis operations such as merging cropping and extracting with a time scale of five years for one period second the deforestation values extracted from the hansen deforestation database are compared with the deforestation volume obtained from the xgboost machine learning simulations in this study to verify the accuracy of xgboost machine learning simulations the specific calculation method is shown in 2 2 validation results m a c h i n e l e a r n i n g r e s u l t s h a n s e n d a t a s e t m a c h i n e l e a r n i n g r e s u l t s 100 3 results and discussion 3 1 map of deforestation intensity the results of the analysis as shown in figure 6 show that deforestation has a high correlation with crop yield urban development and construction and forest scale related indicators at the same time the interaction between crop yield category indicators and crop yield related indicators with forest scale category indicators and urban development category indicators also have a high correlation based on the above correlation analysis results and review of existing literature the xgboost model was constructed as a timber yield prediction model by selecting the total output value of agriculture forestry animal husbandry and fishery total afforestation area number of forest fires area of nature reserves and gdp per capita as the independent variables and used timber yield indicators as the dependent variables and the r2 of the model reached 0 75 with good generalization performance as shown in figure 7 the two regions with higher deforestation intensity are the northeast and southeast and the overall trend is gradually decreasing from east to west among them 16 provinces and autonomous regions including qinghai sichuan shanghai gansu and the tibet autonomous region have reduced deforestation intensity during this period by 128 69 49 69 98 69 94 01 and 69 67 respectively between 2000 and 2019 fifteen provinces and autonomous regions including shanxi province guangxi zhuang autonomous region hainan province and guangdong province saw a total increase in deforestation intensity 1408 28 998 76 277 26 and 255 73 respectively from 2000 2019 the main reason for this discrepancy is the shift in china s forestry policy from timber production oriented to ecological construction oriented in 1998 followed by the implementation of a complete halt to commercial logging of natural forests nationwide and the introduction of logging quotas in 2017 the southeastern part of the country has a more favorable geographical location and hydrothermal condition higher forest density less frequent forest fires and pests as well as an extensive distribution of fast growing and productive forests the functional demands of society on forests are closely linked to socioeconomic development and the more developed processing and manufacturing industries associated with the dense population in the southeast provide a strong driver for further deforestation to demonstrate the reliability of the models this study ran the ordinary multiple linear regression model the bayesian linear regression model and the support vector machine model simultaneously for model performance comparison table 2 shows the results of the multi metric evaluation of each model and it can be seen that the xgboost model demonstrated superior skill in predicting this dataset over the other three comparison models cross validation is also used to establish independent channels to evaluate the generalization ability of each machine learning algorithm on the test and training sets to prevent overfitting caused by overly complex models the results of the five fold cross validation are shown in table 3 and it can be seen that the five fold cross validation of xgboost is also the best among the other three models 3 2 deforestation risk and intensity map integration process after obtaining the national deforestation risk raster it needs to be combined with the sub provincial deforestation intensity predicted by the machine learning model in this study r version 4 0 3 is used and r language packages are used for raster operations rgdal raster and the process is integrated as shown in figure 8 below first a sub provincial ranking of the combined felling risk was performed to obtain the potential risk ranking of felled rasters within each provincial administrative area second the logging image elements were assigned by combining the logging intensity data predicted by the machine learning model by province the deforestation image allocation process was performed on raster data with a spatial resolution of 1 km and stopped when the area of each province allocated image reached the predicted area the final deforestation pattern data was obtained nationwide and subsequently the collection of chinese deforestation events a total of 34 valid events covering 1980 2020 was added as a variable to the risk map for local correction the resultant totals for the years 2000 2005 2010 2015 and 2020 were obtained for this study and the final results are shown in figure 9 3 3 comparison of deforestation simulation results in research method johon et al 2021 uses landsat 8 images establishes a baseline and defines the scope of the national forest based on xgboost machine learning successfully identifying annual trends in khalatbari et al 2021 the authors use 10 bioclimatic variables as the most important factors to study the environmental variables that affect the distribution of oriental beech in this paper the spearman correlation coefficient of bioclimatic variables is used to construct a deforestation prediction model and python 3 6 is used to implement the xgboost method which is used to reconstruct the deforestation intensity data from 2000 to 2019 in the comparison of the model results through comparison with the deforestation dataset assembled by hansen et al 2013 and published in science this is the world s first high resolution map showing deforestation on earth over the last 20 years their work is ultimately the result of a collaboration between google and the university of maryland nasa and the u s geological survey as a global and freely available dataset it offers extensive forest change information therefore this data set is used to verify the error of our model and to evaluate the accuracy of the model in china as shown in table 4 the results of this study were first compared numerically with the hansen et al 2013 dataset with the intent of providing a detailed understanding of the magnitude of differences in logging results over time for specific provinces and municipalities expressed as a percentage the numerical comparisons are generally manageable but exhibit large variability in some of the results there are two main reasons for this 1 hansen et al 2013 deforestation dataset is a global map of forest loss and gain at a spatial resolution of 30 m and due to the large global scale of the study there is a large potential for specific regional errors 2 the amount of deforestation obtained from the xgboost machine learning simulations in this study was verified by real deforestation events and model calibration therefore the simulation results of this study are more accurate and credible within the chinese region and there is a reasonable degree of variation between the two results as shown in figure 10 the results are presented in map form and compared with the hansen et al 2013 dataset in terms of distribution extent and intensity the results show that the spatial distribution of both is essentially the same mainly distributed in the eastern coastal areas of china showing more in the south and less in the north and a decreasing trend from southeast to northwest this is consistent with the actual distribution of forests in china as well as with the distribution pattern of socioeconomic conditions driving deforestation however the results of this dataset are mainly concentrated in the southern part of china while the results of the hansen et al 2013 dataset have higher concentrations in comparison that are distributed in the eastern coastal region since this study uses actual deforestation events as model validation and calibration the deforestation results from this study are more credible and more consistent with the current deforestation situation in china than the hansen et al 2013 dataset 4 conclusion this paper constructs a prediction model of deforestation volume and uses the xgboost method to reconstruct deforestation intensity data and finally verifies the optimization by actual deforestation data the model shows that the deforestation hotspots are mainly concentrated in the southern and southeastern regions of china and that there are large differences in deforestation in different provinces which is consistent with the spatial pattern of the hansen et al 2013 dataset in addition the model has a high degree of confidence due to the inclusion of specific deforestation events in china that were used for model calibration and validation the deforestation model is based on highly detailed natural disturbance data of chinese forests which can provide some reference information for forest disaster prevention and forest management in china and can also quantitatively reconstruct the fine spatial and temporal patterns of deforestation in china during the historical period which is important for the in depth understanding of the historical changes and internal mechanisms of chinese terrestrial forests in addition it can provide a database and a theoretical guarantee for future historical changes in china s forest carbon pool and eventually provide scientific data support for china s climate negotiations and the development of domestic and international carbon trading markets in the future we can further study the dynamic changes of forest disturbance and its driving mechanisms which can provide experience and inspiration for solving forest related ecological problems and developing management methods this method combined with government action will allow china to take the lead in mitigating climate change funding this work was supported by the national key research and development program of china no 2019yfa0606602 credit author statement we wish to confirm that there are no known conflicts of interest associated with this publication and this manuscript has not been submitted to nor is under review at another journal or other publishing venue we confirm that the manuscript has been read and approved by all named authors and that there are no other persons who satisfied the criteria for authorship but are not listed we further confirm that the order of authors listed in the manuscript has been approved by all of us we confirm that we have given due consideration to the protection of intellectual property associated with this work and that there are no impediments to publication including the timing of publication with respect to intellectual property in so doing we confirm that we have followed the regulations of our institutions concerning intellectual property we understand that the corresponding author is the sole contact for the editorial process including editorial manager and direct communications with the office he she is responsible for communicating with the other authors about progress submissions of revisions and final approval of proofs we confirm that we have provided a current correct email address which is accessible by the corresponding author and which has been configured to accept email from scli urban pku edu cn yajuan zhang writing reviewing and editing data curation lijin zhang visualization investigation huan wang conceptualization data curation yueyao wang methodology software jiaqi ding software validationjiashu shen methodology zheng wang methodology yinglu liu data curation chenyu liang data curation shuangcheng li supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
24496,biodiversity loss is a result of interacting ecological and economic factors and it must be addressed through an analysis of biodiversity conservation policies ecological economic modelling is a helpful approach to this analysis but it is also challenging since modellers often have a specific disciplinary background and tend to misrepresent either the ecological or economic aspects here we introduce some of the most important concepts from both disciplines and since the two modelling cultures also differ between the two disciplines we present an integrated consistent guide through all the steps of generic ecological economic modelling such as formulation of the research question development of the conceptual model model parametrisation and analysis and interpretation of model results although we focus on generic models aimed at a general understanding of causes and remedies for biodiversity loss the concepts and guidance provided here may also help in the modelling of more specific conservation problems this guide is aimed at the intersection of three disciplines ecology economics and mathematical modelling and addresses readers who have some knowledge in at least one of these disciplines and want to learn about the others to build and analyse generic ecological economic models compared to textbooks the guide focuses on the practice of modelling rather than lengthy explanations of theoretical concepts we attempt to demonstrate that generic ecological economic modelling does not require magical powers and instead is a manageable exercise keywords biodiversity conservation policy ecological economic modelling generic modelling land use 1 introduction the world s biodiversity is declining steadily attempts to halt this decline have largely failed thus far a major reason for biodiversity loss is anthropogenic land use change which is primarily driven by economic motives millenium ecosystem assessment 2005 this indicates that to design strategies and policy instruments for halting the loss of biodiversity it is indispensable to address not only the ecological dimension of land use change but also its economic dimension which may include social and behavioural aspects in comparison to purely disciplinary economic and ecological approaches an integrated consideration of economic and ecological aspects and drivers is advantageous because it captures the intertwinedness of ecological and economic factors this approach allows for the development of conservation solutions that are superior to disciplinary ones ando et al 1998 armsworth et al 2006 w√§tzold et al 2006 many land use systems are complex have a large spatial extent and develop over long time frames so empirical research alone may be costly and is often insufficient for understanding the spatiotemporal dynamics of these systems and developing policies for conserving their biodiversity hence modelling has been widely used for more than two decades to address questions of land use change lambin et al 2003 lambin and meyfroid 2011 parker et al 2003 verburg et al 2004 often with a focus on biodiversity e g tudge et al 2021 an important class of land use change models are those that integrate ecological and economic aspects henceforth referred to as ecological economic modelling cf w√§tzold et al 2006 and drechsler 2020 such models aim at representing ecological and economic factors at the same level of resolution and in an integrated manner while in other land use models either the economic or the ecological factor often is considered as an external driver only when it comes to planning and assessing biodiversity conservation strategies and policy instruments in terms of the cost effectiveness both ecological and economic processes need to be taken into account well designed models can help to explore the consequences of policies before their implementation grimm et al 2020 or provide advice on how to improve existing policies will et al 2021 an important distinction between models is their overall purpose grimm et al 2020 distinguish three primary purposes demonstration understanding and prediction while models for prediction tend to be complex and case specific models aimed at demonstrating important concepts or creating a general understanding of the dynamics of the considered systems tend to be simpler and more generalised here we refer to these models as generic models as defined by their claim to cover a broad range of situations and cases drechsler et al 2007 this primer focuses on generic ecological economic models generic models go beyond the peculiarities of specific systems but use general ecological and economic concepts to describe ecological and economic processes such as population dynamics and land use decisions these theoretical concepts are implemented via equations e g for species population growth or rules such as if the economic profit of a land use measure exceeds a certain threshold the measure will be implemented the formulation of these equations and rules usually requires the specification of certain model parameters such as the population growth rate or the profit threshold in the examples above in contrast to specific models these parameters are not estimated empirically but are usually assigned plausible ranges within which the parameters are varied to explore the behaviour of the model generic ecological economic modelling has been applied in many different contexts the first models probably also historically consider the optimal e g cost effective spatial or temporal allocation of conservation budgets to maximise some ecological benefit wu and boggess 1999 drechsler and w√§tzold 2001 costello and polasky 2004 a popular application of these approaches although usually employing specific models is conservation planning in which mathematical algorithms are used to select reserve sites to achieve certain conservation targets such as a particular number of conserved species ando et al 1998 margules and pressey 2000 moilanen et al 2008 strange et al 2011 another application is the identification of trade offs between the ecological benefits and economic costs of conservation measures polasky et al 2008 schr√∂der et al 2008 another major application of generic ecological economic models is the design and assessment of economic instruments such as conservation payments engel 2016 and conservation offsets vaissi√®re et al 2017 which are applied in many parts of the world salzman et al 2018 bull et al 2018 for instance w√§tzold and drechsler 2005 developed a model to understand the importance of the spatial differentiation of conservation payments ando and chen 2011 analysed the optimal length of conservation contracts and drechsler et al 2010 explored the efficiency gains that can be generated by applying the agglomeration bonus concept parkhurst et al 2002 to species conservation further research analysed the application of tradable permits to biodiversity conservation drechsler and w√§tzold 2009 kangas and ollikainen 2019 the cost effectiveness of different governance modes for conservation sch√∂ttker et al 2016 farm scale versus landscape scale management cong et al 2016 and the joint consideration of biodiversity and ecosystem services in policy design ekroos et al 2014 despite the importance of biodiversity conservation and the relevance of generic ecological economic models for our understanding of conservation policies and strategies these models are developed infrequently in our opinion one key reason is that building and analysing generic ecological economic models requires at least some skills in different scientific disciplines including ecology economics and mathematical modelling moreover unlike other methods in ecology and economics there is little guidance on generic ecological economic modelling this lack of information may deter researchers especially those at young ages from delving into this relevant and interesting field a synthesis of important ecological and economic concepts relevant to the field of biodiversity conservation as well as their mathematical formulation can be found in drechsler 2020 however while providing broad coverage of issues drechsler 2020 does not give specific guidance on how to build and analyse ecological economic models the present article attempts to fill this gap by providing a primer for generic ecological economic modelling while limited in the number of considered ecological and economic concepts it is focused on the primary commonalities of ecological economic models and the basic steps that must be taken to develop a generic ecological economic model fortunately many generic ecological economic models with a focus on land use based biodiversity conservation share a common structure despite differences reflecting different research questions we concentrate on generic models that include i spatial structure since landscapes are usually spatially heterogeneous and ecological and economic processes are distance dependant ii dynamics since environmental and economic systems usually change over time and iii land use which provides the interface between the ecological and the economic realms by being an economic activity that affects the ecological system nevertheless while we focus on models for addressing biodiversity conservation and land use the modelling steps and principles presented in the following text largely apply to ecological economic modelling in general most of the approaches and concepts we present are quite well known within their discipline ecology or economics but not across these disciplines and not in terms of how to use them for integrated modelling our primer goes through each of the primary steps for constructing a generic ecological economic model by describing commonly used methods and approaches and explaining necessary considerations each construction of a model starts with the identification of its general purpose and a specific research question section 2 the research question to be addressed implies decisions about which features of the focal system to represent in the model and the establishment of a conceptual model and its formal structure section 3 during the next step this formal structure is implemented via equations and or computer algorithms this implementation must be based on relevant ecological and economic concepts further considerations include how to model the landscape implement stochasticity and boundary conditions and code and parametrise the model section 4 the model results now must be generated and analysed this analysis involves amongst other things the simulation of the model dynamics a statistical analysis of the model output and systematic sensitivity analyses to explore and understand the behaviour of the system section 5 last the primary answers provided by the model to the original research question must be presented and discussed in a way that they can support the decisions of policy makers and stakeholders chapter 6 here it should be noted that for modelling questions related to land use change in general which is much larger and more diverse field than ecological economic modelling for biodiversity conservation primers or textbooks similar to ours exist for example jakeman et al 2006 and national research council and geographical sciences committee 2014 before we start some cautionary notes the amount of information and hints given in the following text may look daunting to neophytes to ecological economic modelling however if readers have some modelling experience or training in theoretical ecology or economics they will find many familiar elements additionally our overview of approaches to model analysis and good modelling practice does not imply that all these approaches are needed in every case in fact in many of the generic ecological economic models that we have co developed we have not used every approach it is important however to know the different concepts and approaches and use them wisely whenever it makes sense and there is enough time in addition modelling as in many other scientific approaches is not a linear process as one might assume from reading this primer it is better to think of it as an iterative endeavour in which at some point in the modelling process one needs to go back to an earlier stage and redo some of the model construction steps last we would like to stress that except for very experienced researchers ecological economic modelling is likely to be more successful if performed by a team because it requires knowledge from different disciplines amongst other things this property implies that if phd students delve into the world of ecological economic modelling they need appropriate support and supervision they should never forget douglas adam s advice in his hitchhiker s guide to the galaxy don t panic 2 identification of the conservation problem decisions on the model purpose formulation of research questions and relevant patterns any modelling project should start with the clarification of the basic issues of the conservation problem to be addressed this could 1 be the conservation of important species or the management of invasive species that could be affected by agricultural or other land use as well as other drivers such as climate change and 2 the land use measures that affect the species may be induced by a policy instrument such as conservation payments after these basic considerations one should define the overall purpose of the modelling exercise as noted in the introduction the primary purpose of generic models is usually to understand the modelled system better however beyond this goal one must specify what exactly should be understood is the purpose to understand the dynamics of the system and how do they depend on drivers or policies is it about managing the system in some optimal manner here optimal may mean that a particular ecological objective such as the survival of a target species is maximised ecological effectiveness alternatively optimal may mean that an ecological objective is maximised for given economic costs or an ecological target is achieved for the lowest economic costs both approaches are typically denoted by the term cost effectiveness box 1 once the conservation problem has been defined and the general purpose of the model has been identified specific research questions should be formulated if the conservation problem is about the management of an invasive species one may analyse whether it is more cost effective to invest financial resources into the prevention of the invasion or the control of the invasion after it has occurred finnoff et al 2007 likewise if the conservation problem is targeting the coexistence of two competing species one may explore whether a conservation offset scheme is ecologically effective in terms of facilitating coexistence surun and drechsler 2018 alternatively one may explore under which circumstances the expansion of conservation reserves may due to adverse feedbacks on the land use outside the reserves create a net reduction in the overall amount of protected biodiversity armsworth et al 2006 these preparatory steps are illustrated in the following text using the example of an agricultural landscape with privately owned land parcels the landscape is inhabited by a species of conservation concern with a limited dispersal range such as a flightless insect for its reproduction the species requires 1 extensive land use that is less profitable to landowners than their preferred intensive land use and 2 that these extensively used land parcels are located as close to each other as possible due to the species limited dispersal range a conservation payment may therefore be introduced that induces landowners to engage in extensive land use by compensating them for the associated profit losses the payment is spatially homogenous and the same for all landowners for an analysis of heterogeneous payments see w√§tzold and drechsler 2005 and participation in the payment scheme is voluntary for these reasons the conservation agency has no control over the spatial locations and arrangement of the land parcels that the landowners manage extensively in response to the payment to induce a spatial agglomeration of the landowners conservation efforts the conservation agency considers the introduction of an agglomeration bonus that is paid on top of the homogenous payment parkhurst et al 2002 if adjacent land parcels including those owned by other landowners are extensively managed as well the response of landowners to the agglomeration bonus may depend on their behavioural traits typically it is assumed that they maximise their economic profits but other motives do exist and could be considered section 4 1 1 the policy maker may then be confronted with the task of designing the agglomeration bonus scheme in the described setting to conserve the focal species in a cost effective manner having defined the conservation problem a model purpose may be to understand the functioning of the agglomeration bonus in the described setting better raising two general research questions how does an agglomeration bonus affect the survival of species in agricultural landscapes and how can it be made cost effective from these general research questions more specific ones may be derived that refer to the peculiarities of the considered system for instance one might ask how the cost effective level of the agglomeration bonus depends on the spatial variation in the conservation costs profit losses and the dispersal range of the species the analysis of these questions section 5 may be simplified considerably if the questions are formulated in a dichotomic manner and can have only two possible answers yes and no for instance one may ask whether the cost effective level of the agglomeration bonus depends on the dispersal range or not and whether there is a positive or negative relation between dispersal and cost effectiveness although new or refined research questions may also come up over the course of model building and analysis cf the modelling cycle of grimm and railsback 2005 see section 6 below it is important to formulate them as early in the modelling process as possible since they are most likely to influence the model structure and the outputs the model should deliver the questions need to focus on the aspects of the modelled systems that are considered essential for answering the research question while other aspects may be ignored or represented in a more aggregated simplified way of course whether a certain aspect is essential must be explored when analysing the model behaviour certain aspects may turn out to not affect the model behaviour or the model may not lead to dynamics and structures that are compatible with observations or general principles cf section 4 3 which indicates that at least one key factor has not yet been considered last one needs to consider the realism of the model to be developed models are simplified representations of real systems so even for generic models we need some indicators that the model makes sense in terms of representing features of the real systems it is important to discuss which features will be used to claim that the model is realistic enough for its purpose from the start of a modelling project because this issue will affect the model design both in terms of its entities variables and scales and its acceptance by stakeholders and policy makers instead of features it helps to think about the patterns that characterise the real system or the class of real systems we are representing with patterns we refer to anything that is beyond random variation and therefore must have some underlying mechanism for generic models usually only broad patterns are of interest for example that an equilibrium e g between the reproduction and mortality of individuals in a population or the demand and supply of a good in a market exists or that high payments for extensive land use will strongly affect land use patterns often however models are in fact designed to reproduce specific patterns of interest to explore their underlying mechanism cyclic dynamics such as the famous pork cycle hanau 1928 or the hare lynx cycle stenseth et al 1998 striking spatial zinck and grimm 2009 p√©rez and janssen 2015 or spatiotemporal patterns thulke et al 1999 van de leemput et al 2015 or patterns in distributions of species richness m begon et al 1990 ch 22 2 or land use type iwamura et al 2016 taubert et al 2018 are examples if more than one observed broad pattern is reproduced by a model it is more likely that it captures the real mechanisms rather than being tweaked by some artificial model mechanisms this strategy of pattern orientated modelling grimm et al 2005 grimm and railsback 2012 railsback and grimm 2019 is widely used for complex specific models but can also help to parameterise generic models efficiently jakoby et al 2014 see section 4 3 gallagher et al 2021 review the kind of patterns that have been used so far for pattern orientated modelling in ecology in economics patterns are often referred to as stylised facts meyer 2019 introduces to the use of stylised facts in economics and other fields 3 specification of the relevant system entities and processes and conceptual construction of the model having identified the conservation problem including the major issues that should be considered and the associated model purpose patterns and research questions we now develop the model in more detail at this stage the development is of a conceptual nature involving verbal and graphical representations of the system the translation into formal or mathematical language as well as the implementation in computer code will be addressed in section 4 the conceptual development of the model consists of a few elements grimm et al 2020 i a description of the entities and ii processes in the model system including interactions between entities iii specification of boundary conditions and iv the introduction of model parameters and model variables 3 1 model entities in the description of the system entities and processes we consider that an ecological economic land model typically consists of three primary components an ecological component an economic component and the model landscape in which the entities are located and the processes operate ecological entities may include m begon et al 1990 individuals populations which are sets of individuals of the same species that interact particularly through mating and reproduction and communities which are sets of populations that interact with each other e g through competition or predation ecosystem models also include abiotic factors with a strong focus on stocks and flows of nutrients and energy instead of organisms and biodiversity and therefore will not be considered here cf grimm et al 2017 the most important entities of the economic model component are usually the individual landowners when derived from these components an entity of a higher organisational order may be split by groups of e g neighbouring landowners or the entirety of all landowners which operates in a market section 4 1 the conservation agency can in principle also be regarded as an economic entity but this categorisation is meaningful only if it is affected by other model entities if the policy maker adapts a policy in response to changes in the system cf polasky and segerson 2009 if such feedback does not exist it is more practical to consider the policy maker as an external driver last the landscape entities must be defined in disciplinary research both within ecology and economics one may distinguish between patch based and grid based approaches to consider the spatial structure in the patch based approach the landscape consists of polygons patches within a matrix of voids such as islands in a sea and the model considers only the patches largely disregarding the matrix examples include simple models consisting of two regions with different ecological and economic characteristics in which a policy maker allocates a conservation budget over both regions to maximise some aggregate ecological benefit e g wu and boggess 1999 w√§tzold and drechsler 2005 here only the size of the regions matters but not their locations in ecology the metapopulation concept which allows the description of population dynamics in spatially structured landscapes see section 4 2 assumes at least in its basic formulation a patch based landscape the ecological processes take place only within the habitat patches while the matrix between the patches is considered only in that individuals may disperse between habitat patches and the probability of an emigrant from one habitat patch reaching another habitat patch may depend on the distance between the two patches for problems and questions that also include land use it is often more appropriate to consider the entire landscape explicitly which can usually be better achieved with a grid based approach here the landscape is structured as a grid of cells usually of quadratic shape although hexagonal grid cells have also been considered by liu 1993 and leonard et al 2017 each grid cell can have properties e g soil quality and be in a particular state e g managed in a particular manner occupied by an individual or a population of a particular species etc spatial heterogeneity within the grid cells is however ignored 3 2 model processes the defined ecological economic and landscape entities interact and change their states locations behaviour etc through processes for instance the land use change on a particular grid cell may change the suitability of the cell as habitat for a species or a group of individuals of the species may through dispersal from a neighbouring cell immigrate and establish a population in this cell through these processes the model becomes dynamic interactions between model entities may be global in that each entity can interact with each other entity or local in that an entity interacts only with some entities such as neighbouring entities global interactions are often assumed for mathematical convenience and make sense if 1 the interactions are very long ranged or 2 the populations are well mixed so that during their lifetime everyone will have contact with many or all other individuals in landscapes however interactions are usually local for example the change in species occupancy of a particular grid cell usually does not depend on the occupancies in all the other grid cells in the model region but due to limited dispersal only on the occupancies in neighbouring cells or in the presence of dispersal corridors on the occupancies in connected grid cells similarly the land use in a grid cell may change via communication between neighbouring landowners depending on the land use in neighbouring grid cells interactions can thus be described by networks that specify for each grid cell with which of the other grid cells it interacts e g minor and urban 2008 or by distance dependant interactions examples of these distance dependant interactions are the probability of a dispersing individual reaching a habitat patch which declines with increasing distance section 4 1 2 or when assuming that the choice of trading partners in a water quality trading market depends on the distance between possible partners nguyen et al 2013 processes may be deterministic or stochastic the outcome of a deterministic process is fully determined by the model parameters and variables while a stochastic process contains random elements so that the outcome of the process may be predictable on average but may vary around its mean in an unpredictable manner stochasticity sections 4 1 3 and 4 1 4 is included whenever it is assumed that observed variation and heterogeneity matter for the question addressed with a model but that the mechanisms causing this variation are unknown or not of interest examples of processes that may be represented stochastically are the reproduction and mortality of individuals burgman et al 1993 or a land use change in response to the changing profitability of land use measures appendix a processes may operate not only between different entities within the modelled system but also from the outside these processes are called exogenous or external and may relate to a changing crop price polhill et al 2013 or rainfall bell et al 2016 that affect the land use profitability as a particular type of external driver one may also regard environmental policies such as a conservation payment scheme in which a particular conservation measure is rewarded via a payment similar to crop price or rainfall the magnitude of such a payment is usually determined exogenously by a conservation agency and is not affected by the state of the system to designate an entity as exogenous or external we assume that there is no feedback from the modelled system on those exogenous processes or drivers of course policies can also be influenced by endogenous processes within the modelled system but studies involving such considerations are rare groeneveld et al 2017 3 3 boundary conditions a final choice regarding the overall model structure concerns the boundary conditions that specify what happens at the physical boundary of the system this question turns up if e g an animal at the northern boundary of the model region wants to move north or if a landowner with the decision rule to adopt neighbouring land use that is observed in at least four of the eight adjacent grid cells has a parcel in the north western corner of the model region that has only three neighbours altogether in specific models one may consider so called open boundaries in which an entity on the system boundary interacts with entities outside the system e g a species population may be affected by the immigration of individuals from the outside but this consideration is less relevant in generic models here boundaries are usually considered either closed or periodic a closed boundary may be imagined as an impermeable wall around the model region the behaviour and decision rules of ecological and economic entities must be formulated accordingly such that an animal moves north only if it is not at the northern boundary and otherwise takes another direction or rests however this assumption implies that the spatiotemporal model dynamics at the boundary differ from those in the interior of the model region if these differences between the interior and the boundary are considered inadequate for the description of the system one may introduce periodic boundaries so that the grid cells at the western border of the model landscape are neighboured or wrapped to the eastern grid cells and or the most northern grid cells are neighboured to the most southern ones depending on whether periodic boundaries are considered in one or two geometric dimensions the model landscape has the shape of a cylinder or a torus wikipedia contributors 2021a the latter is a model world without boundaries and the underlying assumption is that the corresponding real system is much larger than the model system so we can assume that for example as many entities that leave to the east will enter in the same time step from the west or that the grid cells bordering the northern edge will have a similar distribution of properties as those bordering the southern edge the choice of the boundary conditions completes the conceptual description of the generic ecological economic model 3 4 model variables and parameters as a preliminary step towards the formal description of the model we now define mathematical quantities that characterise the entities and processes here we distinguish between variables that we understand as quantities that change over time or that characterise and distinguish the entities while the parameters are constants examples of variables are behavioural traits such as the level of risk aversion see section 4 1 1 the size of a species population in a grid cell or the economic profit gained in a land parcel in a given year in addition to such endogenous variables that change due to processes within the system variables can also characterise external drivers such as a changing crop price or rainfall model parameters are constants that quantify changes mediated by the model s processes for example the per capita population growth rate in eq 8 if they are the same for all processes and entities they are just parameters but if they differ between entities for example the soil type in grid cells they are also variables grimm et al 2020b in this case variation refers to features or attributes of entities not to variation in time all the variables of a model taken together characterise at a given point in time the state of the model system and are therefore referred to as state variables grimm et al 2020b some of these variables plus the possible variables characterising the state in a more aggregated way form the output of a model analysis section 5 3 these output variables may be the total cost of a conservation scheme the mean size of a species population in the model region etc parameters are usually inputs to the model such as the spatial variation in soil quality or the dispersal range of a species which affect the dynamics of the model system and eventually the state variables and model output in the modelling literature the initial values of state variables are also referred to as inputs lorscheid et al 2012 relating model output to model input is a central task in the causal analysis of a model section 5 3 the result of the considerations in this section the conceptual model can be represented verbally or graphically or both a useful and popular tool here is the odd protocol grimm et al 2006 2020 which has been developed for describing so called agent based models but can be used for simulation models in general here o stands for overview including the primary purpose of the model and the model s entities and processes d stands for design concepts such as interactions or stochasticity and d stands for details such as how a stochastic movement behaviour of an individual is modelled or how a landowner predicts future profits of a land use measure the odd protocol is like a checklist in that it guides the modeller through the structured description of all the model elements including the entities processes drivers and boundary conditions for habitat suitability models fig 1 often also referred to as species distribution models a similar protocol exists odmap zurell et al 2020 an example of a graphical representation of a model is shown in fig 1 which takes up the conservation problem outlined in section 2 this representation comprises a landscape component an economic component an ecological component and an external driver the landscape component contains the geographic data of the model region such as the coordinates sizes and soil productivities of the land parcels from the soil productivity Œ∑i determined amongst others by the soil type an economic model calculates the agricultural profitability œÄi xi of each land use measure xi for each grid cell land parcel subtracting the profitability associated with a conservation measure from the profitability associated with the most profitable land use measure yields the opportunity cost of the conservation measure together with the conservation payment which consists of a base component pa and an agglomeration bonus component pb this calculation is the input into a landowner decision model for which the output is the land use xi a habitat suitability model as part of the ecological model component translates land use xi into habitat suitability si which is the basis of the landscape as perceived by the species of concern in applying the metapopulation concept section 4 the dynamics of the species in this landscape are governed by the extinction of local populations in the individual habitat patches land parcels and the colonisation of empty habitat patches the key model variable affected by these processes is the occupancy qi for each habitat patch i e the information on whether the species is present in the patch this text completes the conceptual description of the model system as outlined the aim of the model is to understand how the cost effective design of the payment scheme in particular base payment and bonus pb and pa depend on ecological and economic conditions such as the spatial distribution of the land parcel profitability and the species dispersal range cost effectiveness involves optimisation in which control variables pb and pa are varied to maximise an objective the survival of the species under constraints e g a conservation budget the model in fig 1 is embedded in this optimisation scheme by delivering the associated budget the sum of the payments over all conserving landowners for a given choice of pb and pa and the resulting viability of the species e g its survival probability see section 5 2 2 in obeying the scope of the present paper we will not address optimisation issues any further but will instead focus on the construction and analysis of ecological economic models 4 formal construction implementation and parameterisation of the model 4 1 mathematical formulation once the model is conceptually established it must be translated into formal language here we distinguish between two primary approaches equation based models in which the model processes are formulated through mathematical equations and rule based or algorithmic models that are driven by processes formulated in the form if condition u applies event v happens the rules themselves can include equations so that condition u may be formulated by an equation an advantage of fully equation based models is that they provide a compact and rather transparent mathematical representation of the model and can sometimes be solved analytically so that essential features of the model behaviour are immediately visible the downside is that these advantages are quite rapidly lost when the model system becomes complex due to the large number of factors that are considered important such as spatial dependencies behaviour and variability of agents in these situations rule based models may be required for example they may be grid based jeltsch et al 2008 seltzer 2019 or agent based barfuss et al 2017 muneepeerakul et al 2017 seltzer 2019 grimm and railsback 2005 railsback and grimm 2019 models most generic models employ a mixture of rules and equations for instance the decisions of landowners are often modelled so that some utility function section 4 1 1 is maximised most simply one may assume that utility is proportional to economic profit with an example given by eq 1 and the dynamics of a population are in generic models often described through a differential equation such as eq 8 rules may enter here if landowners observe the behaviour of other landowners and adapt their land use appendix a or if the population growth rate depends on the applied land use measure in a specific model the modelling of the processes is strongly based on the specific knowledge of the focal system but in a generic model we refer to established concepts such as density dependant growth in ecology or market equilibrium in economics reviewing all potentially relevant ecological and economic concepts would be far beyond the present article these concepts can be found in the various disciplinary textbooks in the fields of environmental economics and theoretical ecology e g hanley et al 2016 may and mclean 2007 an extensive overview of concepts relevant for ecological economic modelling is provided by drechsler 2020 but even this publication still covers only a subset of all the concepts that may be of interest in fact the choice of concepts largely depends on the considered system the conservation problem the model s purpose section 2 and in the practice of research of course on the knowledge background of the individual researcher below we present a few general concepts that may be useful 4 1 1 economic concepts 4 1 1 1 modelling the economic profit of land use measures in ecological economic systems socioeconomic processes often affect land use which in turn affects the dynamics of populations and ecosystems fig 1 we therefore first consider the economic component of ecological economic modelling in fig 1 the economic component contains the economic model and the landowner decision making model the economic model determines profitability as a function of land productivity and land use the simplest approach is to assume that the landowner can choose between two land use measures intensive use xi 0 which maximises profit œÄi xi 0 but is not beneficial for biodiversity see section 4 1 2 and an alternative biodiversity friendly or extensive land use measure xi 1 with lower profit œÄi xi 1 in case the conserved area is taken completely out of production one may think of a strictly protected nature reserve and economic activity is not feasible the profit is obviously zero profit is typically defined as the difference between revenue and production cost c in which the revenue is the product of the agricultural yield yi and the market price p for the produced crop e g polhill et al 2013 1 œÄ i p y i c to model the yield one may assume that it is proportional to the local land productivity Œ∑i 2 y i g Œ∑ i with g being some constant additionally one may assume that eq 1 applies only to the intensive profit maximising land use measure xi 0 while for the extensive biodiversity friendly land use measure the profit may be constant and identical for all land parcels œÄi xi 1 œÄ below we model the landowner decisions as functions of the difference between œÄi xi 0 and œÄi xi 1 in this case the profit œÄ can without loss of generality be set to zero which simplifies the calculations in addition yields may be influenced not only by land productivity but also by climatic factors such as rainfall bell et al 2016 furthermore eq 1 motivates another extension profit may depend on the travel distance of land users to a land parcel groeneveld et al 2005 because more distant land parcels incur higher transport costs c distance dependence may also be relevant under other circumstances for example armsworth 2018 considered that the risk of deforestation declines with the distance from settlements last one may consider more than two land use measures and more than a single product from land use polhill et al 2013 4 1 1 2 landowner decision model ecological economic models which address specific challenges of conservation planning see the references in the introduction often apply a top down approach explicitly or implicitly the perspective of a welfare maximising planning agency is adopted that optimises a spatio temporal land use pattern to achieve a conservation goal under a budget or cost constraint armsworth 2018 in this context the decision of the landowners does not need to be explicitly modelled however this is different for incentive based conservation policies such as conservation payments and conservation offsets in this context the decision of the landowner or often equivalently the land user which includes farmers forest owners etc needs to be explicitly addressed landowners are at the intersection between the ecological and the economic subsystem because they respond to economic influences and may interact with other landowners while their actions affect the ecological subsystem and might in turn be influenced by it the simplest concept for modelling human behaviour and often a useful starting point for the development of a generic ecological economic model is the model of homo economicus the homo economicus is a perfectly informed rational and self interested decision maker who strives for the maximisation of his her utility the way to proceed from the heuristic homo economicus model is described below in a very narrow sense utility may be a function of monetary profit but in general it can also include non monetary aspects that determine human well being utility functions are usually assumed to have a concave shape e g u x x 1 2 for x 0 fig 2 to consider that the marginal i e added utility of an additional unit of a good generally declines with increasing possession of the good in addition concave utility functions allow for considering risk aversion as is typically assumed in human decision makers if the outcomes of an action are uncertain for a detailed explanation see pindyck and rubinfeld 2014 or drechsler 2020 assume that a decision maker can choose between some actions ai i 1 m the monetary profit of each action ai is uncertain and can assume one out of n possible values œÄij j 1 n each occurring with probability pj consider further a utility function u œÄ that maps profit onto utility the decision maker will choose the action ai that maximises the expected utility eu 3 e u a i 1 n j 1 n p j u œÄ i j as noted a risk averse decision maker is modelled by a concave utility function such as the von neumann morgenstern utility function 4 u œÄ œÄ 1 œÅ 1 1 œÅ where œÅ is the coefficient of constant relative risk aversion eeckhoudt et al 2005 quaas et al 2007 at œÅ 0 the utility function u œÄ 1 is linear in œÄ and the decision maker effectively maximises their expected profit 5 e œÄ a i 1 n j 1 n p j œÄ i j representing risk neutral decision behaviour with an increasing œÅ the utility function becomes increasingly concave which implies that the expected utility eu of an alternative in which profits œÄj vary over j declines relative to that of an alternative in which profits are certain modelling the behaviour of an individual who is averse to risk for further details see appendix a and drechsler 2020 in addition to the described uncertain variation profits may also change over time œÄ œÄ t so the expected utility in eq 5 is time dependant eu ai eu ai t or equivalently eœÄ ai eœÄ ai t in eq 5 decision makers are generally assumed to have a time preference in the sense that they place a higher value on current benefits and costs compared with future ones several reasons may explain this time preference they include an empirically observed pure time preference impatience of human beings uncertainty about the occurrence of future costs and benefits and the foregone opportunity to invest financial resources today to have a higher amount of financial resources in the future boardman et al 2017 in models with continuous or discrete time this preference is modelled by maximising the present value pv of the expected utility or profit taking into account that future costs and benefits are discounted 6 p v e u a i t 0 e u a i t exp Œ¥ t p v e u a i t 0 e u a i t 1 Œ¥ t respectively where Œ¥ is the discount rate an increasing Œ¥ models an increasing time preference i e future costs and benefits are given increasingly less weight than present costs and benefits a generic modelling example in which the size of the discount rates plays an important role in where and when to conserve an area is armsworth 2018 the model of homo economicus as represented by eqs 3 6 is the classical model of human decisions and the simplest one however clearly this model does not fully capture the complexity of human behaviour for example the behaviour of landowners can be influenced by other factors such as farmer characteristics e g age education or personality social influences e g the attitudes of trusted friends and the availability of information edwards jones 2006 frondel et al 2012 recently dessart et al 2019 reviewed the findings of the past 20 years on the behavioural factors that influence farmers decisions to adopt environmentally sustainable practices the factors were sorted into three classes i dispositional factors including resistance to change risk tolerance which is to a large extent covered by eq 3 and moral or environmental concerns ii social factors including social norms such that a landowner adopts a particular land use if the number or proportion of landowners who employ that land use exceeds a particular threshold and iii cognitive factors including the perceived costs and benefits of land use measures and perceived risks which may differ from the true risks that are considered in the risk utility function associated with the costs and benefits of land use measures the literature provides a number of modelling approaches that address at least some of these factors an 2012 groeneveld et al 2017 schl√ºter et al 2017 huber et al 2018 schwarz et al 2020 in appendix a some useful examples are provided that focus on resistance to change the presence of conflicting objectives social norms perceived costs and benefits and perceived risks all these factors consider the land use decision of each individual landowner they partly include stochastic elements and or consider not only the state of their own land parcel s but also the states e g land use of the land parcels belonging to other landowners taking such complex decision making into account requires agent based modelling approaches tesfatsion 2005 railsback and grimm 2019 whether it is sufficient to assume homo economicus as a decision maker or to assume more complex human behaviour depends amongst other issues on the research question and the model purpose drechsler 2021 ideally the patterns the model is supposed to reproduce may help to identify the most suitable behavioural model the pattern orientated selection of a specific submodel is increasingly used in ecology railsback and grimm 2019 but requires a minimum level of model complexity which can make the model less generic 4 1 1 3 modelling economic incentives for extensive biodiversity friendly land use an important application of ecological economic models is the analysis of economic or market based instruments for the conservation of biodiversity basically these instruments provide a financial incentive to landowners who implement biodiversity friendly land use measures or avoid biodiversity harmful measures employing these measures usually reduces the profit from intensive land use and an economic instrument is aimed at establishing a payment to offset this foregone profit below we briefly outline major types of these instruments in a conservation payment scheme the policy maker offers a payment usually the same payment per measure and area of land for all landowners to those landowners in a region who implement a biodiversity friendly land use measure a key reason for the use of spatially homogeneous payments is that differentiation according to landowners costs is generally not feasible because this information is private and landowners have no incentive to share it with the regulator ferraro 2008 each landowner i then determines whether it is more profitable to perform the intensive land use measure xi 0 which maximises profit œÄi xi 0 or the extensive biodiversity friendly measure xi 1 with lower profit œÄi xi 1 œÄi xi 0 but with the award of the conservation payment p 7 x i 1 œÄ i x i 1 p œÄ i x i 0 0 œÄ i x i 1 p œÄ i x i 0 assuming the homo economicus model landowners for which conservation is too costly so that payment p cannot offset profit loss œÄi 0 œÄi 1 will prefer intensive land use while those for whom the profit loss is smaller than the payment will implement the extensive land use measure as one can observe landowner i responds only to payment p but assuming this consideration is the same for all landowners the payment is not affected by the land use decisions of other landowners in appendix b we will present an example of a payment scheme the agglomeration bonus by parkhurst et al 2002 in which landowners interact with one another examples of generic models that consider the agglomeration bonus concept include albers et al 2008 drechsler et al 2010 bell et al 2016 parkhurst et al 2016 and drechsler 2021 another strain of research on conservation payments addresses the question of whether payments should reward conservation efforts such as a biodiversity friendly land use measure or conservation results such as the presence of a target species on the land parcel examples of generic modelling studies in this context include zabel 2009 derissen and quaas 2013 and drechsler 2017 alternative economic instruments to conservation payments include conservation auctions and offsets box 2 4 1 2 ecological concepts the dynamics of species populations on land parcels with spatially varying habitat suitability are described by population models fig 1 after the following section on habitat suitability we outline four standard modelling approaches which are distinguished by i whether a single habitat patch suitable land parcel or multiple patches the whole landscape are considered and ii whether a single or multiple interacting species are considered 4 1 2 1 habitat suitability model in fig 1 the ecological module contains a habitat suitability model and a population dynamics model habitat suitability models often referred to as species distribution model guisan et al 2017 are based on identifying statistical correlations between habitat features and the observed presence and absence of a species since this approach ties models to specific regions and data sets in a generic model one has to work with informed simplifying assumptions for instance one can assume that the carrying capacity for the species of concern on a land parcel is proportional to the area managed in a species friendly manner alternatively if a land parcel can be managed with different levels of intensity each intensity may be represented by a particular magnitude of the land parcel s carrying capacity another option is if an intensively used land parcel is turned to extensive use one can specify the gradual increase in habitat suitability by using a linear or other mathematical function drechsler and hartig 2011 4 1 2 2 single patch single species population model for the population dynamics of a single species in a single spatially homogenous habitat patch the simplest model reaching back to the economist thomas malthus in the 18th century is the unlimited growth equation 8 d n d t r n which considers that the rate of population change as expressed by the time derivative dn dt is proportional to the current population size with proportionality factor r being the intrinsic per capita population growth rate the model assumes that the growth rate r is constant consequently there is no limit to growth so the population size increases exponentially over time to consider limits to population growth the logistic growth function also more than 100 years old adds a carrying capacity k to eq 8 so that the growth rate dn dt declines with increasing n 9 d n d t r 1 n k this model demonstrates the concept of density dependence and regulation the growth of the population size n depends on the current value of n as n grows the growth dn dt rate declines and this negative feedback leads to the regulation of the population because at n k we have zero growth regulation refers to the fact that after disturbances or events that lead to values of n below or above that of k the population regulates itself back to a value at or close to n k density dependence is a logical postulate because resources e g food are limited so that population growth must stop somewhere however the model does not say anything about the specific mechanisms which might be complex and vary over time and space and not about the role of environmental limitations of growth nevertheless for generic models it is often sufficient to represent density dependence phenomenologically as in eq 9 more details about the models in eqs 8 and 9 in particular their variants for the case of discrete e g annual time steps can be found in textbooks such as wissel 1989 otto and day 2011 or drechsler 2020 the logistic model is deterministic but for small populations random influences can lead to low densities and therefore possibly to extinction this can occur even if the population growth rate is positive when e g a sequence of unfavourable weather conditions reduced the population to low densities so that the random factors that act on the level of the individuals become affective and cause extinction random temporal variations in the population growth rate are called environmental noise whereas the effect of variations at the level of individual life histories is called demographic noise the simulation of a population under demographic noise is demonstrated in detail in burgman et al 1993 and drechsler 2020 hence for small populations under random influences the probability p t of the population surviving for some time t declines exponentially at a local extinction rate if we denote this rate by e quantity e eŒ¥t is the probability of the population going extinct during time interval Œ¥t grimm and wissel 2004 4 1 2 3 multiple patches single species population model if the landscape consists of several habitat patches and individuals can move between habitat patches empty habitat patches are colonised at some colonisation rate c so the probability of a habitat patch becoming colonised during some time interval Œ¥t is c cŒ¥t the colonisation rate c can be modelled as the rate of individuals immigrating into the focal patch multiplied by their probability of establishing a local population the rate of immigration im s into patch s can be modelled as 10 i m s s 1 s e m s Œ≥ d s s where em s is the rate of individuals emigrating from patch s and the so called dispersal kernel Œ≥ dss 1 is a function that models the distance dss dependant probability of an emigrant from patch s reaching patch s often the exponential function Œ≥ dss exp dss Œ¥ is used where Œ¥ is the species dispersal range the model described above forms the essence of hanski s 1999 famous metapopulation model box 3 which is based on the model by levins 1969 this model is probably the most widely used in the field of landscape ecology and the basis of numerous empirical and theoretical studies it is admittedly simplistic but can easily be extended to consider not only whether a local population is present on a habitat patch or not so called patch occupancy models but also the internal dynamics of the population size including life stages random influences and more hanski 1999 in addition the dispersal function in eq 10 can be extended to consider the directed intentional movement of individuals as well as heterogeneous conditions such as land cover for their movements with individual based models even more complicated dispersal models are possible that consider the adaptive movement behaviour of individuals but this approach requires more effort in model development parameterisation and analysis and usually ties the model to specific systems which limits the general insights that can be gained for the complex relation between model simplicity and generality see evans et al 2013 4 1 2 4 single patch multi species population model the above described population dynamic models go quite far in their ability to describe the dynamics of populations however a missing key feature for the modelling of biodiversity or even entire ecosystems is the interaction between different species classical examples of models on the interaction of species are those by lotka 1920 and volterra 1931 for competing species and predator prey systems here when considering a non spatial setting the dynamics of two competing species 1 and 2 with abundances n 1 and n 2 competing for two resources as represented by the carrying capacities k 1 and k 2 are given by 11 d n 1 d t r 1 1 n 1 Œ≤ n 2 k 1 d n 2 d t r 2 1 n 2 Œ≥ n 1 k 2 the competitive influence of species 2 on species 1 is considered by increasing the number of individuals n 1 in the first equation by the term Œ≤n 2 where Œ≤ 1 measures how strongly an individual from species 2 competes compared with an individual from species 1 the competitive influence of species 1 on species 2 is modelled analogously in the second equation the two species can coexist if the strength of the interspecific competition between the two species is smaller than the intraspecific competition amongst individuals of the same species conspecifics Œ≥ k 2 1 k 1 and Œ≤ k 1 1 k 2 the biological interpretation of these conditions is that resource requirements within a species are identical while they should differ to some degree from those of the competing species in this case competition with conspecifics is thus higher so that a species growth is more limited by competition with its conspecifics which is known as negative conspecific density dependence may et al 2020 than by the presence of the other species notably each species at a low density is largely released from intraspecific competition and therefore uses this advantage of being rare to grow faster than the competitor this combination of assumptions about ecological niches and the advantage of rarity plays a key role in the so called modern coexistence theory chesson 2000 which is intended to explain why species rich communities and hence high species diversity can exist for a spatial version of eq 11 one could consider n 1 and n 2 as functions of spatial location and in the intra and interspecific competition one could consider only the number of individuals within a specific radius in a grid based model one could consider n 1 and n 2 as local variables for each grid cell with the grid cells possibly connected with each of their eight adjacent neighbours through dispersal and simulate the dynamics of n 1 and n 2 in each grid cell using eq 11 in addition to competition species may interact as predators and prey via parasitism mutualism or other mechanisms m begon et al 1990 in the context of ecological economic modelling baumg√§rtner 2004 developed a generic model to analyse the efficient conservation of two species as a function of their interaction type the author showed that the interaction between the species can completely reverse the efficient rank order of conservation investments so that e g a species of low priority may due to its influence on another species gain a high priority 4 1 2 5 multiple patches multi species population model last we consider multiple interacting species in a spatially structured landscape a central issue here is the competition for empty habitat patches if the seeds of several plant species are dispersed into empty habitat patches the question is which species will prevail and establish a local population in the patch a simple and intuitive approach here is to assign each species i a competitive strength compi and relate the probability p est i of species i establishing a local population at that strength 12 p est i c o m p i j c o m p j an alternative to eq 12 is to rank all the considered species by their competitive strength compi and assume that in the presence of several species the most competitive one with the highest compi establishes a population with probability one and the others fail with probability one if compi is modelled as the number of seeds in the habitat patch eq 12 describes the so called lottery competition in which the species with the highest number of seeds has the highest chance of establishment banitz et al 2008 usinovicz et al 2012 to facilitate coexistence the more competitive species should have a lower ability to colonise empty habitat patches e g through a smaller dispersal distance in eq 10 since otherwise all other factors being equal it will eventually replace the less competitive species from the region this correlation between species traits is called the competition colonisation trade off which may be modelled at the level of individuals banitz et al 2008 or at the population level tilman 1994 all the presented concepts consider the levels of meta populations and meta communities roughly speaking a community is an ensemble of interacting populations of different species and a metacommunity is an ensemble of interacting metapopulations of different species alternatively one can consider the level of individuals which involves individual based models we refer to the vast literature on the application of individual based models in the field of biodiversity conservation e g grimm and railsback 2005 grimm et al 2017 next to the scale of individuals populations and communities much of ecological research focuses on the ecosystem scale e g m begon et al 1990 historically however ecosystems were conceptualized as compartments characterized by stocks of nutrients and energy and dynamics was assumed to be driven by flows of nutrient and energy between departments there is accordingly still a divide between ecosystem and landscape ecology so that land use models often focus on single species or at specific ecosystem functions such as carbon sequestration but not necessarily at mechanism underlying these functions verburg et al 2009 likewise biodiversity research and ecosystem ecology are still more or less disjunct but would need to be integrated grimm et al 2017 the rationale of focusing on single species in conservation biology is their potential role as umbrella or indicator species if they thrive chance should be high that other species with similar or less complex habitat requirements can persist as well roberge and angelstamm 2004 an increasing number of ecological economic models considers even complex food webs see papers in the research topic policies and strategies for the conservation of metacommunities in frontiers in ecology and evolution more aggregate models employ species area curves that relate the number of species to the size of the conserved area e g w√§tzold and drechsler 2005 for simplicity in this primer we do not consider multiple species nor address the ecosystem scale but it should be kept in mind as the ultimate target scale 4 1 3 modelling the landscape many factors that drive ecological and economic processes are spatially heterogeneous such as soil productivity land cover or the distribution of human settlements within a specific study these features can usually be obtained from real world data but in a generic model these features must be made up by defining stylised landscapes that include aspects of spatial heterogeneity and relationships considered essential for the problem and question addressed by the model the simplest approach to obtaining spatial heterogeneity is to sample the features randomly in a grid based model one can draw the level of an environmental parameter such as soil productivity from a probability distribution for each grid cell the most useful approaches for this purpose are the uniform normal and log normal distributions appendix c a challenge here is to include spatial auto correlation between those random environmental variables a straightforward approach for a single variables like conservation cost is presented in appendix c an algorithm for the creation of landscapes with several features can be found in saura and martin√©z mill√°n 2000 while many research questions can be addressed with these generic random landscapes it can also be useful to model landscapes more realistically and or in more detail bami√®re et al 2013 salecker et al 2019 bartkowski et al 2020 landscape generators can construct complex landscapes consisting of features such as agricultural fields of different shapes and sizes roads hedgerows and more langhammer et al 2019 similar to analyses on the influences of model parameters the systematic evaluation of the effects of the landscape structure becomes increasingly difficult as the complexity of the landscape increases 4 1 4 implementing stochasticity and boundary conditions ecological and economic dynamics usually involve some stochastic elements often an event occurs with some probability p to decide in a simulation whether the event occurs a random number is drawn from the uniform distribution with the bounds of zero and one and if the number happens to be smaller than p the event occurs otherwise the event does not occur if a random number should be drawn from a probability distribution with more than just two possible outcomes in which each possible outcome k 1 k has a probability pk œÉ kpk 1 the cumulative distribution i e the probability qk of observing some k below or equal to k has to be calculated according to 13 q k k 1 k p k then analogous to the case with only two possible outcomes a random number r is drawn from the interval 0 1 outcome 1 is chosen if and only if r q 1 and outcome k is chosen if and only if pk 1 r pk see e g drechsler 2020 as a final issue in this section we consider the geographical boundary conditions closed boundaries are implemented in a straightforward manner by defining maximum and minimum x and y coordinates for the model landscape x min x max y min and y max and if a coordinate occurs within the model process that exceeds the maximum possible value or undercuts the minimum possible value it is set at that maximum or minimum respectively to consider periodic boundaries coordinates x y outside the ranges x min x max and y min y max must be transformed using the modulo or mod command which is available in all programming environments and delivers the remainder of the division of two integer numbers we transform x into x or y into y via 14 x x x min x x min mod x max x min 1 y y y min y y min mod y max y min 1 for instance in the case of x min 1 and x max 10 a value of x 13 three units above x max is transformed to x 1 12 mod 10 1 2 3 or a value of x 2 three units below x min is transformed to x 1 3 mod 10 1 7 8 4 2 implementation of the model the mathematical formulation of the model developed in the previous section must be implemented as a simulation programme on a computer here we briefly introduce a few popular software tools for this task non spatial models that are mathematically represented by a system of coupled differential or difference equations such as eq 8 can be implemented using the software tools stella wikipedia contributors 2021b https www iseesystems com or vensim wikipedia contributors 2021c https vensim com spatially structured models can be conveniently implemented in netlogo https ccl northwestern edu netlogo which is most suitable not only for the implementation of agent based models but also for grid based models compared with programming languages such as c see below in this section software tools such as the three tools mentioned here usually offer an easier and faster way to implement simulation models this is because various components of computer code are already provided that otherwise would have to be written in house netlogo can support the straightforward construction of graphical user interfaces that include buttons and elements for the specification of parameter values up to a graphical representation of the model world which is presented as an array of grid cells it also provides tools for sensitivity analyses section 5 3 in addition various commands in netlogo are effectively small procedures subprograms called primitives that are composed of several lower level commands for example for making an agent move to the neighbouring grid cell with the highest value of a certain feature the primitive uphill is used this action simplifies the programming work and allows for the implementation of many processes by using tested standardised subprograms netlogo is particularly suited for programming beginners while more experienced programmers will favour their known languages for example c or java being based on a code interpreter instead of a compiler netlogo tends to be slower by nature than compiled languages however important algorithms for example for identifying all other landowners or grid cells with specific attributes within a certain radius are highly optimised so that using c for example does not guarantee by itself that the programme will run faster railsback et al 2017 netlogo still has the disadvantage that it does not provide a convenient debugging capacity in which the programmer can trace through the code step by step and observe the changing quantities of the model variables furthermore it has limitations when simulating large systems with millions of grid cells or hundreds of thousands of agents generic model landscapes are however usually not that large another modelling platform is the r software wikipedia contributors 2021d https www r project org originally developed for statistical analysis it also supports the implementation of causal relationships algorithms like loops and more it is less powerful than c and probably less convenient than netlogo but has the advantage that model results can be analysed in the same programming environment and a vast library of free packages exists for this task while netlogo and r are ideally suited for generic models which are usually not very complex for more realistic and thus complex specific software tools exist for example clue s verburg et al 2002 terrame de senna carneiro et al 2013 or pluc verstegen et al 2012 4 3 plausible ranges for the model parameters the central approach to analysing and understanding the dynamics of a generic model is through a sensitivity analysis in which the model parameters are varied and their effects on the model dynamics and model output are explored section 5 3 the present section addresses the choice of plausible ranges for the model parameters although generic models abstract from the specifics of real systems their structure and parameterisation should reflect to the extent possible what is regarded as typical or possible in these real systems in contrast to specific models generic models are made to generate knowledge about relationships rather than to provide absolute predictions of model variables to provide a trivial example for a specific model of a region in germany land prices would be measured in euros and so would reflect the overall expenses of a conservation payment scheme while in the us they would be measured in us dollars however both systems would behave identically all other factors being equal what would probably influence the dynamics of the systems are qualitative relationships such as the coefficient of spatial variation in the land prices which is the ratio of the standard deviation in land prices and the mean and thus independent of the magnitude of the mean or the rate by which the land prices change over time which again would sensibly be measured in percentages of the current land price rather than the absolute value of the land price again if these relationships are equal or unequal between the two systems the two systems will all other things equal behave equally or unequally the following provides examples of this relative scaling of model parameters as a first example soil productivity generally varies amongst land parcels in a region but usually not by orders of magnitude spatial variation in the soil productivity would be measured relative to some mean which for convenience could be set to one another example is a bounded rational landowner who may fail to identify the profit maximising land use measure every time but the probability of such a failure should generally be much smaller than one some other relationships represent specific assumptions of the conservation problem for instance if the assumed size of a grid cell is on the order of one hectare see below within this section a ground beetle with a movement range of approximately ten metres will not be able to disperse over many grid cells but only to the cell s direct neighbours if the assumed time scale of the model is one year see below within this section for species that have at maximum one generation per year it makes no biological sense to assume that a local population survives only for one year so the extinction probability per model time step would be much smaller than one altogether the chosen spatial and temporal scales i e resolution and extent often provide a good starting point for delineating meaningful parameter ranges in selecting a small conservation budget one would need to consider that a conservation payment must be small compared with the median conservation opportunity cost because a payment equal to the median or larger would imply that provided voluntary participation of landowners half or more of the land parcels grid cells will be conserved contrasting what one would generally associate with a small budget this argument relates to what was indicated at the end of section 2 about pattern orientated modelling one such pattern could be the assumption that the proportion of conserved land parcels is on the order of ten percent since there are usually monotonic relationships between conservation payments and the proportion of conserved land parcels one could choose the payment so that the proportion of conserved land parcels is of the desired order of magnitude in an analysis of cost effectiveness or budget efficiency it is usually practical to choose the conservation budget rather than the payment but since these two are also generally monotonically related the above argument also applies for the appropriate choice of budget similar considerations can be made on the ecological side the conservation status of a species structured as a metapopulation box 3 can be measured quite well by using the proportion of occupied habitat patches conserved land parcels if the focus is on endangered species it is sensible to choose the colonisation and extinction rates so that the resulting proportion of occupied habitat patches is rather small in a static landscape this proportion is quite uniquely determined by the ratio of colonisation and extinction rates box 3 which thus can be chosen so that the proportion of occupied land parcels is rather small together with the above consideration of the local population extinction rates this item determined plausible values for the colonisation and extinction rates in drechsler 2021 of course the mentioned relationships between the budget conservation payment and proportion of conserved land parcels as well as the relationship between colonisation and extinction rates and the proportion of occupied land parcels are not fixed but depend amongst others on the design of the modelled payment scheme and the analysis of different designs was introduced as one of the tasks of many ecological economic model analyses therefore the model parameter values cannot and should not be tied to the patterns with high numerical precision which may be sensible in specific models but ranges in the patterns should be allowed so that the proportion of conserved land parcels or the proportion of occupied habitat patches might range between five and twenty percent for small budgets of course even these bounds should not be understood as crisp but as rough guardrails for the analysis having discussed the specification of ranges for the model parameters we now turn to the spatial and temporal dimensions and resolutions of the model even in a generic model these parameters are not entirely arbitrary for instance one should be clear about whether a grid cell is meant to represent the area occupied by a forest stand zinck and grimm 2009 or a local population of an insect species or even a large mammal on the economic side a grid cell would typically represent a land parcel or agricultural field if the field sizes are assumed to differ one may consider the smallest field although it is not necessary to specify the size of the grid cell in square metres or hectares the cell size should be chosen to be appropriate in both ecological and economic dimensions therefore while it may be sensible to assume that an agricultural field harbours a local insect population it is usually not sensible to assume that it contains a single tree from a forest instead it should represent a forest patch whose ecological dynamics would be simulated by differential equations such as eq 8 or in an individual based manner however even though a close match between ecological and economic scales is desirable one should keep in mind that a generic model is designed to create general knowledge rather than precise numerical predictions the same holds for the temporal resolution of the model in many real systems land use changes in annual steps and at least in regions with seasonality population dynamics follow annual life cycles of species and are often modelled on annual time steps therefore in general it is sensible to assume a match between the clock of land use decisions and changes in population sizes or species occupancies of habitat patches one should note here that generic models have rarely considered individuals e g trees or life stages of species but in case this consideration is advised by the research question there is no reason not to do so next for resolution a decision has to be made about the extent of the model landscape i e the number of grid cells for example if one assumes that a grid cell represents an agricultural field the number of grid cells may simply reflect the typical number of agricultural fields in the considered type of region however for testing purposes especially when developing the model it can be useful to work with smaller systems additionally for the final model checking for possible effects of the system size should be a routine part of a model analysis the appropriate time horizon number of simulation steps largely depends on the research question if one is interested in the steady state behaviour of the model the number of time steps should be chosen so that this steady state is reached cf section 5 2 however if the model should describe the dynamics of a policy with a limited duration such as agri environmental schemes with a duration of five years or if a transient ecological process such as the restoration of degraded habitat is considered one may decide to cover a shorter time horizon of only ten time steps years to simplify and if one is interested only in the difference between system behaviours before and after some intervention the consideration of only two time steps can be sufficient e g pindyck 2002 langpap 2006 drechsler and w√§tzold 2020 in addition to those arguments of plausibility or realism another argument for choosing the size and time horizon of a model is to allow for the detection of interesting patterns such as feedback loops e g between land use and species abundance or spatial aggregations e g of conservation efforts as induced by the agglomeration bonus mentioned in section 2 it makes no sense e g to analyse the spatial aggregation of conservation efforts in a landscape with two by two grid cells detecting these patterns generally requires at least and possibly only as a starting point approximately 10 by 10 or 20 by 20 grid cells but some effects become visible only in large landscapes with 100 by 100 grid cells or more e g drechsler and w√§tzold 2009 bell et al 2016 regarding the term scales in the context of ecological economic modelling it should be noted that it is not necessarily understood in the same way in ecology and economics drechsler et al 2007 the same applies in the context of modelling environmental systems in general while for example in ecology scales refers to temporal and spatial scales in environmental modelling in general in particular for integrated modelling linking different environmental compartments scales also refers to different levels of organization and sometimes even different disciplines iwanaga et al 2021 a concluding note may be added in the context of very large numbers of grid cells computation times may become unacceptably large especially given that for a thorough analysis the model must be simulated many times section 5 therefore in the end the optimal choice of the size of the model region and the number of simulation steps is a compromise between the chance of detecting all relevant patterns in a single model run and the comprehensiveness of the model analysis however run time issues have become less important over approximately the last 10 years because high performance computing clusters are increasingly available and convenient to use 5 model analysis 5 1 simulation experiments 5 1 1 choice of initial conditions to analyse the model its dynamics must be simulated these simulations follow the same rationale as experiments in real systems they start from a specific question the settings are controlled accordingly and only certain inputs are varied and the model output of interest is analysed systematically inputs in model analysis comprise all the model parameters and the initial settings of model entities and their variables a first decision often must be made on the initial conditions i e the initial values of the model variables in a model of a forest ecosystem the development of forest cover depends on the initial level so that high forest cover leads to a fast decline bauch et al 2016 in the analysis of a reef ecosystem thampi et al 2018 whether the model system runs into a state with high or with zero macroalgal cover depends amongst others on the initial amount of macroalgae and corals and grimm and wissel 2004 demonstrated that the initial number of individuals in a population substantially affects the survival probability of the population similar to the values of the model parameters the initial values of the model variables should be plausible and reflect the research question if the question concerns the effect of a biodiversity restoration project one may assume that initially there are only a few conservation efforts being performed in the model region population sizes may not be chosen at mathematically possible maxima but at typical values relative to the carrying capacity however similar to the choice of the model parameter values it is sensible to consider a range of initial conditions and explore their influence on the model behaviour through sensitivity analysis section 5 3 the choice of the initial conditions may not only affect the model dynamics quantitatively e g that a higher initial number of individuals increases the population s survival probability but it can also affect the qualitative behaviour of the model in bulte and horan 2003 the model system has two different steady states and the steady state that is eventually assumed depends on the initial conditions moreover systems may include feedback loops that give rise to oscillations and the occurrence and nature of these oscillations can depend on the initial conditions henderson et al 2016 multiple states or domains with different dynamics model behaviour e g oscillations versus steady state are typical features of complex systems thurner et al 2018 that are characterised by entities interacting with each other in a non linear manner complex systems show behaviour that cannot be predicted from the properties of their components in isolation emergence if the assumed state of a system depends on the initial condition disturbances are able tip the system from one state to another scheffer et al 2001 lenton et al 2008 which raises the issue of the system s resilience holling 1973 walker et al 2004 5 1 2 updating of model variables an often ignored but critical issue is the updating of model variables within processes and between consecutive simulation time steps a central challenge here are the interactions between entities in an agglomeration bonus scheme the payment for a particular land parcel depends on the land use in the neighbouring land parcels thus changing the state land use of a land parcel will affect the way in which the states of the neighbouring land parcels will change simulations use discrete time steps within each time step basically two options for updating the variables exist synchronously and asynchronously for the synchronous type of updating all the new values of the variables that were calculated are stored in auxiliary temporary variables therefore the current state of the system and the new state are clearly separated in the above example the current and new states are not mixed so that the sequence by which the landowners in the example are processed in the simulation does not matter only after the values of all the variables have been calculated are they updated synchronously by contrast with asynchronous updating every variable is updated immediately after it has been calculated landowners might thus have a mix of neighbours in both their current and their new state this updating scheme can lead to priority effects for example if individual based model calculations are sorted by a certain identity number of agents or by any of their variables such as age or wealth they might have initial advantages or disadvantages compared with other agents alternatively if computationally convenient grid cells are always processed row by row priority effects may occur to prevent priority effects the sequence by which entities such as agents or grid cells are simulated can be randomised for each time step 5 1 3 replicating simulations stochastic elements such as randomly changing crop prices or conservation costs or randomly changing weather conditions lead to spatial and temporal variability in model variables a population that is affected by random weather events may go extinct within a few time steps or survive for a long time thus a single model run does not reflect the behaviour of a stochastic model to account for this stochasticity the model must be simulated for a sufficiently large number of times and the model outputs of the various replicates are then evaluated statistically there is no general rule for the choice of an appropriate number of replicates instead it must be identified experimentally for instance one can generate a small number of sets of model replicates if the statistics of the model output cf section 5 2 does not change between these sets then the chosen number of replicates is clearly sufficient to encompass the stochasticity in the model when analysing model output statistically however one should be aware of the risk of p hacking by increasing the number of replicates virtually any result can be made significant significance tests should be avoided when analysing stochastic simulation models white et al 2014 rather one should compare confidence intervals or consider effect sizes eq 17 5 2 recording state variables and calculating quantities for model output 5 2 1 what type of output should we take from the model to answer the research questions formulated prior to the model development section 2 the relevant state variables of the model system must be recorded these variables may include the economic profits of landowners the sizes of local species populations etc in the next step these temporally and spatially varying variables must be aggregated into a few meaningful quantities this aggregation is important because to understand the behaviour of the model we must be able to plot and analyse the relationship between model inputs and model output if the model output has too many dimensions it is difficult to systematically explore model behaviour to give an extreme example it is generally infeasible to create overview plots of a model landscape explicitly depicting the state of each grid cell for several time steps and for many model parameter combinations rather we require metrics ideally single numbers that characterise the system state these numbers are usually summary statistics of the model variables such as the means variations and correlations such aggregate outputs can be thought of as currencies railsback and grimm 2019 because we are using them to evaluate the model behaviour in general finding meaningful output variables is an important element of any type of modelling even for generic models which tend to be of lower complexity a single output variable may not be sufficient to understand how the dynamics and structure of the model systems are emerging moreover when trying to make a model match several patterns observed see sections 2 and 6 we will need a set of output variables to characterise those patterns nevertheless in most cases a small number of output variables say two or three is sufficient next the simulation time steps over which the output variables should be recorded must be decided upon only at the final time step or for a number of final time steps furthermore if a model creates complex dynamics such as multiple steady states or oscillations it can take from a given initial condition a considerable number of simulation time steps until these dynamics can be observed and fully captured in the recording of the evaluation quantities the duration of this type of burn in phase depends on the structure of the model in particular its level of stochasticity and the initial conditions in the analysis of a model this phase can only be determined experimentally by simulating the model and identifying the time from which the model variables or the pattern of their dynamics change only marginally or not at all below we present several examples for aggregate quantities or currencies to characterise the state of the model system 5 2 2 temporal statistics if the variables of interest change over time due to stochasticity in the model feedback loops or other factor they should be summarised into statistics such as temporal averages and standard deviations if the focus is on the system dynamics the variables of interest include i the mean time to change from one system state to another and ii the probability of the system remaining in a particular state goel and richter dyn 1974 in the field of conservation biology the most popular representative of type i is the mean time to population extinction while the most popular representative of type ii is the probability of surviving with a non zero population size a particular time frame grimm and wissel 2004 show that there is a close relationship between the mean time to extinction and the probability of extinction a variant in the probability of survival or its complement the probability of extinction i e zero population size is the quasi extinction risk which measures the risk of falling below a particular threshold within a particular time frame ferson and burgman 1995 by this measure the quasi extinction risk depends on the considered extinction threshold and the time over which population sizes are recorded ferson and burgman 1995 the preferred statistics depend largely on the model dynamics if the population never reaches a size of zero a mean time to extinction or probability of extinction does not make much sense instead one should focus on the quasi extinction risk or the mean time until the population falls below a non zero threshold for the first time alternatively one could choose simpler statistics such as the mean and standard deviation of the population size these measures provide an easy and intuitive representation of an ecological benefit however they are of course not meaningful if the population has a high risk of extinction so the population size will be zero for most of the time over which the model dynamics are simulated in ecological economic models which often have two or more relevant ecological and economic state variables a useful extension of the concept of quasi extinction risk is coviability mouysset et al 2014 based on baumg√§rtner and quaas 2009 coviability is the probability of the system staying in a particular state which may be characterised not only by a single state variable e g the species population size but also by other variables such as economic costs 5 2 3 spatial statistics we have focused on temporal statistics so far however spatial statistics can be of equal importance since the spatial structure of the system as represented by the spatial distribution of model variables usually characterises and affects the dynamics of a system similar to the temporal dimension basic spatial statistics include the mean and the standard deviation of a variable over all the land parcels grid cells in the model region the state of a metapopulation section 4 1 2 may be characterised by the mean size of its local populations alternatively if the model distinguishes only between occupied and empty land parcels it may be measured using the proportion of occupied land parcels in addition to its mean and variation the spatial distribution of a model variable may be of interest particularly the degree of the variable s autocorrelation or spatial clustering consider as an example the case of a binary model variable which can take only the values of one or zero y 0 1 here the degree of spatial clustering on a square grid of n grid cells can be measured quite simply by determining the proportion of grid cells pi within the moore neighbourhood mi of the eight adjacent grid cells which have yj 1 j mi for each grid cell i and taking the average of these pi over all grid cells i with yi 1 drechsler 2021 15 c l u s t y i 1 n y i p i i 1 n y i w i t h p i 1 8 j m i y i in eq 15 clusty can range between p and 1 where p œÉyi n is the proportion of grid cells with y 1 a value of clusty p indicates a random distribution of the grid cells with y 1 so each grid cell has on average of 8p neighbours with x 1 while clusty 1 indicates perfect clustering in which all grid cells with y 1 except for those on the cluster boundary have only neighbours with y 1 note that for eq 15 there are numerous alternative measures to quantify the spatial correlation of variables ripley 2005 wiegand and moloney 2013 5 2 4 quantities for characterising complex dynamics if a model creates complex dynamics such as multiple steady states oscillations or spatial patterns measures are needed to characterise this complex model behaviour while steady states can be characterised by the corresponding levels of the model state variables oscillations can be characterised by their mean level amplitude and frequency the spatial analogue for these quantities would be the lengths of the spatial correlations wiegand and moloney 2013 in addition to the characterisation of complex dynamics one may be interested in the set of conditions ranges of model parameters and initial conditions that lead to a particular type of dynamics e g steady state versus oscillations henderson et al 2016 the delineation between different sets of conditions that lead to different dynamics are often called tipping points because they indicate when the system tips from one type of behaviour to another see the references at the end of section 5 1 1 as well as gerling et al 2019 in addition to the identification of these thresholds one may ask how long it takes until the system returns to a stable state after it has been disturbed which is related to the mean transition times introduced above for the lotka volterra model eq 11 fig 3 shows the times to reach the equilibrium state for an exemplary model parameter combination in which n 1 and n 2 are constant in time as a function of the initial state n 1 t 0 n 2 t 0 these two issues tipping points and return times are central to the concept of resilience folke et al 2004 egli et al 2019 a related concept is emergence which refers to the establishment of complex spatial and temporal patterns for example the spatial distributions of trees in savannas jeltsch et al 1996 the mosaic of forest stands in different successional stages as observed in natural beech forests rademacher et al 2004 the spatial distributions of biomass in a disturbed ecological system van de leemput et al 2015 or the level of cooperation in the management of a common pool resource nhim et al 2019 and the level of cooperation in the management of a common pool resource sometimes complex model dynamics can be analysed by scaling them up wu and david 2002 to a markov process a markov process e g goel and richter dyn 1974 grimm and wissel 2004 is a process without memory so the change in the system is determined by its current state only memory effects can however be represented in the state variables used to characterise the model s entities markov processes are represented by a set of equations or rules that give the probabilities pr s s of transitioning into another state s for each system state s the states are characterised by the values of a few aggregate state variables such as those introduced in the previous sections during the simulation of the model the frequency at which this characteristic is assumed is recorded for each state and from a given state how often the system transitions into any of the other states the full model dynamics can then be summarised into a matrix of transition probabilities called the markov matrix while the provision of further details would be beyond the scope of this primer two applications of the described upscaling may be mentioned touza et al 2013 used the approach to detect different modes of cooperative behaviour in forest owners in which cooperation was defined by the benefit accruing from one s own actions to the neighbouring forest owners only two modes of behaviour exist the level of cooperation is either proportional or inversely proportional to the level of culling intensity and determining which mode dominates depends on the preferences trophy hunting vs biodiversity conservation of the forest owners drechsler 2020 ch 17 used the approach to detect a spatiotemporal feedback loop in the land use dynamics induced by an output based payment which rewards the presence of a species on the land rather than a conservation measure the aggregate state variables comprised the proportion and spatial clustering eq 15 of the conserved land parcels and the land parcels occupied by the species 5 2 5 policy performance criteria and optimisation as noted above an important application of ecological economic modelling is the design and assessment of biodiversity conservation instruments a central matter of interest here are policy performance criteria one of these criteria is effectiveness i e the ability of a policy to achieve a given ecological objective this type of objective may be the survival of one or several interacting species see the research topic policies and strategies for the conservation of metacommunities in frontiers in ecology and evolution or a given level of resilience of the system to disturbances bauch et al 2016 bieg et al 2017 dressler et al 2019 if financial resources are limited cost effectiveness is of equal importance i e the ability of a policy instrument to achieve given ecological objectives at the lowest costs or equivalently to maximise ecological objectives for given costs w√§tzold and schwerdtner 2005 last the model output and the conclusions that are drawn are likely to depend on the values of the model parameters see section 5 3 another performance criterion of a policy is its robustness regarding uncertainty in these model parameters see section 5 3 5 here the way in which a policy performs if parameter values deviate from best guessed values is analysed and the most robust policy is the one whose worst performance over all the alternative parameter values is best amongst all the compared policies ben haim 2001 often the task is to maximise a policy performance criterion which requires numerical optimisation the simplest method for this purpose is to vary the policy parameters such as the level of the agglomeration bonus in drechsler 2021 or the level of decentralisation in bareille and zavalloni 2020 within their plausible ranges simulate the model dynamics and identify the values that maximise the policy criterion cost effectiveness in drechsler 2021 and economic welfare in bareille and zavalloni 2020 however this method is rather slow and may lead to unacceptable computation times in these cases more efficient optimisation routines must be used many textbooks on numerical optimisation are available such as nocedal and wright 2006 and talbi 2009 and the libraries of some software packages such as gams wikipedia contributors 2021e https www gams com or r see reference in section 4 2 include optimisation routines the netlogo installation see reference in section 4 2 includes the programme behaviorsearch stonedahl and wilensky 2010 which provides a collection of optimisation algorithms for netlogo programmes covering the issue of optimisation in more detail would clearly be beyond the scope of this article 5 3 sensitivity and statistical analyses to explore model behaviour 5 3 1 sensitivity experiments and local sensitivity analysis to explore and understand the behaviour of the model and the modelled system the assumptions behind the model and the values of the model parameters are varied and the response of the model output section 5 2 is recorded and related to the variations in the model parameters this type of model exploration is known as a sensitivity analysis saltelli et al 2009 the simplest and most popular type of sensitivity analysis are sensitivity experiments railsback and grimm 2019 in which each model parameter a is varied in turn from some baseline value a base within its plausible range and changes in the model output variable y are recorded all the other parameters are fixed at their baseline values the results of these experiments are usually depicted in plots of one or more output variables versus the varied parameter a special case of an entire set of sensitivity experiments is a local sensitivity analysis in which the model parameters are varied only by very small magnitudes such as ten percent from the baseline value again only one parameter is varied at a time therefore these analyses are also referred to as one at a time analyses oat dividing the change in the output variable by the change in the model parameter yields a sensitivity coefficient here one can consider the deviations in absolute or relative fashions relative to the baseline values a baseline and y a baseline 16a s abs y varied y baseline a varied a baseline 16b s rel y varied y baseline y baseline a varied a baseline a baseline 1 mathematically this analysis resembles the derivative dy da of y with respect to a at point a a baseline eq 16a and the derivative of the logarithms dlny dlna at point a a baseline eq 16b these sensitivity coefficients show the main effects of the model parameters their rank order indicates which parameter and hence the process it controls has the strongest effect on the output variable while straightforward to perform and easy to interpret oat analyses have three limitations the results might differ when starting from different base parameter values interactions between parameters such that the sensitivity of one parameter depends on the level of another parameter are not captured and non linear effects are not captured to detect nonlinearities the sensitivity coefficient must be calculated for several values of a to capture the interactions between parameters and their processes two parameters can be varied systematically at the same time i e both vary over their ranges with a sufficiently high resolution for example over ten values plotting the output variable as a function of the two model parameters with the two parameters measured on the two axes yields a contour plot or heat map which helps us to understand the interaction between these two parameters an example of this type of plot is shown in fig 3 it is important to consider these analyses or even more complex analyses as described in the following section not just as technical exercises but as the means for 1 gaining an understanding of the sensitivity of parameters and their processes and 2 developing possible explanations for these sensitivities subsequently these explanations can often be tested using additional simulation experiments that are targeted at dominant processes in a complex model with many parameters identifying all these two way interactions or three way or higher order interactions may be infeasible instead one would usually analyse only the interactions of the parameters with the largest primary effects as determined above 5 3 2 global sensitivity analysis in global sensitivity analyses all the model parameters can take any value within their respective ranges so that the entire parameter space is covered saltelli et al 2009 thiele et al 2014 several approaches are available to choose parameter values during a global sensitivity analysis a basic approach is to cover the parameter space completely either i by defining for each parameter i i 1 i a number ni of possible equidistant values and building all œÄ ini ni if n 1 n 2 ni n parameter combinations or ii by forming a desired number of parameter combinations by randomly drawing each model parameter from its range an advantage of variant i is that some software tools for drawing multidimensional plots of model output as a function of model parameters require systematic coverage of the parameter space as inputs an advantage of variant ii is that the model output can be related to the model parameters through statistical methods see section 5 3 3 a more efficient systematic coverage of the parameter space can be achieved through subsampling the most common approach here is latin hypercube sampling e g thiele et al 2014 in which the ranges of all the model parameters are split into small intervals and the parameter combinations are sampled so that each of these intervals is occupied only once for a two dimensional parameter space equivalent to the task of positioning several rooks on a chess board so that they cannot threaten each other now the challenge is to analyse the data jumble that comes out of these procedures a simple first step can be to calculate the correlations between a model output variable and each model parameter a large positive negative correlation indicates that an increase in the model parameter significantly increases decreases the model output variable similar to a simulation experiment this action identifies the main effects more demanding are the variance partitioning methods such as the sobol method in saltelli et al 2009 which explores how much the variation in parameters both by themselves and in interaction with others explains the variation in the model output for complex models the resulting statistical model is often used as a meta or surrogate model that is used for further model analysis and application pietzsch et al 2020 a simpler alternative to the mentioned variance partitioning methods which only consider the primary effects is the analysis of variance anova anova is available through practically any statistics package and spreadsheet software and rather easy to apply drechsler 2021 used it to determine how much of the variance in the model output is due to a set of parameters describing the decision making of landowners relative to the variance that is caused by other model parameters such as the spatial variation in conservation costs usually generic models have a relatively small number of parameters for models with many parameters these global analyses cannot be performed for all the model parameters because the results would be virtually impossible to interpret therefore first so called morris screening can be performed which ranks all the parameters by their global importance global methods such as the sobol are then performed only for the about five most important parameters see for example ayll√≥n et al 2016 software platforms devoted to data science and statistical analyses such as r see reference in section 4 2 or python wikipedia contributors 2021f https www python org provide packages for running and analysing all the common methods of sensitivity analysis global sensitivity analysis is increasingly used because of these packages and the increasing popularity of r and other statistical software however it is important like with any method provided by some packages to ensure that these packages are driven by questions and that their output is interpreted in terms of these questions simply presenting the plots produced by the sobol method is not sufficient the relevant result is the interpretation of these plots sometimes a simple interpretation is possible but very often this is not the case because the model shows different behaviours in different parts of its parameter space this is however not necessarily a bad thing because not all the parts of the parameter space are always relevant to the research question thus a global sensitivity analysis should be performed with a sense of proportion 5 3 3 statistical methods for model output analyses as mentioned in section 5 1 3 for stochastic models it can be adequate to support observations of parameter influences on model output through statistical analyses a typical question here is whether a change in a model parameter from some value a baseline to another value a varied has a relevant effect on some model output y for this determination the model is analysed many times to obtain replicates of the model variable y for both parameter values a baseline and a varied an effect size t is calculated as 17 t e y a varied y a baseline s d y a varied s d y a baseline where e y a varied y a baseline is the expected value of the difference in y caused by varying a over the replicates and sd y a varied and sd y a baseline are the standard deviations of y for the two levels of a cohen 1988 here t relates the difference between the means to the variation standard deviations in the model output the effect size is independent of the number of replicates to obtain the t statistic for a t test one would divide the t in eq 17 by the square root of the number of replicates which avoids the risk of p hacking mentioned in section 5 1 3 statistical methods also support the investigation of dichotomic research questions such as is conservation scheme a more cost effective than another conservation scheme b or does the increase in parameter x increase or decrease the cost effectiveness of scheme a compared with scheme b related to this are questions such as which model parameter combinations are associated with a particular type of model outputs as examples p√©rez and janssen 2015 determined via a t test whether the level of cooperation amongst resource users differed between different assumptions regarding the amount and spatial distribution of the resource and drechsler and w√§tzold 2020 identified model parameter combinations in which the lock in and path dependence of biodiversity conservation measures are particularly relevant while drechsler 2021 analysed many random model parameter combinations and identified those in which bounded rational landowner behaviour has a large effect on the performance of a conservation scheme to analyse the output of a global sensitivity analysis multivariate analyses such as ordination and classification have proven useful these methods basically sort objects such as model parameter combinations into groups that are similar with respect to some characteristic such as a model output describing these methods in detail would be far beyond the scope of this article so we refer to textbooks such as pielou 1984 and johnson and wichern 2013 two examples may demonstrate the potential of such methods the ordination by drechsler 1998 arranged nine parameters of a population dynamical model into three groups so that the parameters in each group had a qualitatively very similar influence on the rank order of four conservation measures surun and drechsler 2018 arranged 10 000 model parameter combinations each representing the combination of two species traits of two competing species into five groups so that the species trait combinations in each group responded similarly to the choice of two conservation scheme design parameters this reduction in the model parameter space substantially simplified the analysis of how the coexistence of the two competing species depends on the scheme design similar tasks can be performed using regression trees breiman et al 2017 which split the parameter space by identifying bounds on specific model parameters that lead to similar levels of a model output variable polhill et al 2013 used the method to explore the effects of model parameters including policy design parameters on the species richness in a fictitious model region 5 3 4 robustness analysis to address uncertainty in the model structure while sensitivity analyses focus on parameters a robustness analysis ra also includes the model structure and the choice of submodels describing specific processes the primary motivation for performing an ra is that model development is path dependant depending on the specific formulation of the research question the data and expert knowledge used and the output metrics applied model development can take different paths because each step on this path constrains the available design choices for the next step as a result models of even the same system and similar questions often differ greatly the aim of an ra is thus weisberg 2012 after wimsatt 1981 to separate the scientifically important parts and predictions of our models from the illusory ones which are accidents of representations the basic idea of the ra is to try to break a model i e to see when the model ceases to explain certain phenomena grimm and berger 2016 suggested augmenting the current culture of communicating models as working just fine with a culture of presenting analyses in which we try to break models i e model mechanisms explaining certain observations break down they defined ra as the systematic deconstruction of a model by forcefully changing the model parameters structure and representation of processes ra thus helps to tell the features of a model that are essential for the answers provided by the model from the path dependant accidents of representation in practice an ra comprises heuristics such as turning certain processes off how much do they matter or making the model world simpler or more complex for example by contrasting simple and complex process representations or by contrasting homogeneous and heterogeneous environments an ra and its elements are helpful for understanding how model results are emerging this understanding is essential for a model to be useful because blind trust in model output is unacceptable grimm and berger 2016 provide an overall scheme and examples of ra ra is particularly important for complex models but even in the usually simpler generic models assuming different functional relationships in the submodels can have strong effects 6 good modelling practice the ecological economic models considered in this primer are about instruments and policies that affect the real world ultimately the hope is that lessons learned from the model will support the development and implementation of the best e g in terms of cost effectiveness biodiversity conservation instruments this approach requires that both the model and its analysis are transparent and replicable so that the model and its results are credible since the iterative process of model development comprises several steps question formulation conceptual model development implementation testing analysis and application good modelling practice must cover all of these steps one way to document that good practice was followed throughout and that all aspects are transparent and replicable is by using the trace transparent and comprehensive ecological modelling documentation framework schmolke et al 2010 grimm et al 2014 trace documents trace all relevant aspects of model development they provide a standard template with sections corresponding to all steps of model development ideally modellers keep a notebook during model development in which they concisely document their activities daily by using the terminology of trace to tag their notebook entries these modelling notebooks ayll√≥n et al 2021 can then be used to compile trace documents that are attached as supplements to articles or reports by using trace to document the iterative development testing and application of a model modellers know where to put what type of information including the model description data and output files etc and when model users have specific questions they know exactly where in the trace document to look for this information keeping modelling notebooks based on trace terminology considerably adds transparency and credibility to models and their results but also has direct benefits to modellers because these notebooks force us to explicitly reflect upon what we planned and have achieved and trace provides a checklist of all the important aspects of model development analysis and use the credibility of models is important given their aim of supporting the development of conservation policies one key aspect of credibility is how well the model represents the real system potential model users often require that a model is making correct predictions before they are willing to consider its results however testing model predictions is usually not possible with social ecological systems because we cannot perform controlled experiments moreover models cannot in principle predict the future because there are always drivers for example climate politics or epidemics that cannot be predicted it is therefore important to distinguish three primary purposes of models grimm et al 2020 demonstrating a specific concept understanding the mechanisms underlying a certain phenomenon and prediction the prediction function usually must be confined to specific situations short time horizons and different scenarios regarding the drivers the generic models described here are meant for demonstration and understanding and therefore not for making specific predictions nevertheless there must be some generic features reproduced by generic models that still allow us to use the lessons learned in the real world the most widely used feature is that the modelled system exists often in some sort of equilibrium possibly including some variation or oscillations around some mean in addition the behaviour of the model especially for extreme values of the model parameters should at least to some extent and with respect to the important features be explicable by arguments of plausibility and logic for example an increase in the conservation payment or budget should unless there are good counterarguments such as threshold effects increase the number of conserved land parcels in a region or an increase in the number of habitats should again unless there are good counterarguments such as threshold effects increase the viability of the species in the region an agglomeration bonus should generally lead to more spatial aggregation of conservation efforts which according to the metapopulation theory outlined in box 3 should generally increase the viability of the species in that way a generic model may generate a set of trivial predictions or weak patterns that are straightforward to reproduce however reproducing a set of largely independent patterns is non trivial because it requires a specific level of complexity and realism which is the primary idea of pattern orientated modelling see section 2 notably the trivial predictions from plausibility tests often consider extreme or simplified scenarios there can always be factors that were not considered within the generic model that would lead to different results for example while it is plausible to observe a beneficial effect of the agglomeration bonus on a single dispersal limited species the presence of a predator that also benefits from habitat agglomeration and places predation pressure on the species may of course reverse the original outcome thus if predation is a concern within the scope of the research question the predator and its population dynamics should be explicitly included in the model unfortunately generic models and their results are often presented without referring to their primary purpose and their level or realism which has led to cases in which their results were viewed as predictions and used for making decisions affecting the real world for instance the famous hare lynx cycle in canada has long been regarded as a prime application of the generic 2 species models of lotka 1920 and volterra 1931 similar to the model of eq 11 above until recently empirical research and improved specific models have shown that other factors such as climatic factors and self regulation in the populations are of the same or probably even of much higher importance zhang et al 2007 yan et al 2013 7 interpretation and discussion of model results to answer the research questions having descended in section 3 from the real world into the world of mathematics or depending on one s personal taste ascended into it we must now return by interpreting and translating the results of the model analysis particularly the sensitivity analyses into a narrative by using ordinary language of course the details of this process depend on the research question s in a first step one could consider the primary effects identified in the sensitivity analysis which in the example of drechsler 2021 revealed that the influence of two out of four parameters of landowner behaviour were rather small compared with that of other ecological and economic model parameters while the influence of the other two behavioural parameters was moderate similarly or next one could present interaction effects as in w√§tzold and drechsler 2005 in which spatially differentiated conservation payments turned out to be more cost effective than homogeneous payments especially if conservation efforts in the subregion with the higher marginal conservation cost also generated a higher marginal ecological benefit in this manner the most important results of the sensitivity analyses are presented in which it is advisable to start with the simple results such as the primary effects and end with the more complex results after or depending on personal taste parallel to the presentation of these results plausible explanations of the results should ideally follow recalling that the purpose of generic modelling is understanding making explanations and arguments of plausibility form a central part in the discussion of the results of generic model analyses these explanations have their roots in the results of the sensitivity analyses described in section 5 3 underlining the value of this sometimes tedious but important part of modelling often our explanations are hypotheses that can be tested by performing additional simulation experiments more generally a model can often not be fully understood in a single viewing instead with rather little preliminary understanding of the model one usually starts with a rather broad and shallow sensitivity analysis that focuses on the primary effects the understanding gained by this viewing as well as any remaining gaps stimulates a more informed analysis which continues until a satisfactory understanding of the model is achieved this approach somewhat relates to the modelling cycle described by grimm and railsback 2005 of course one should be aware that complete understanding is only an ideal that can be achieved if at all only at high costs in terms of work time so it is up to the researcher to find a reasonable compromise in any case at least the primary effects regarding the original research question should be understood and their reasons explained because otherwise the model would not be very useful given that for policy support it is usually not the model itself but the drawn narratives that are decisive this characterisation replicates the conclusion of section 6 in which modelling requires not only computational but also intellectual efforts next it is important to highlight the limitations of the analysis this consideration is particularly relevant regarding the basic assumptions underlying the model one reason for assumptions that purposely ignore aspects of the analysed system may be that their inclusion would produce foreseeable straightforward results and thus would complicate the model without any major gains in terms of understanding an example is the neglect of transaction costs here the costs of setting up and running a policy in the study by w√§tzold and drechsler 2005 these costs were ignored or assumed to be zero since they are always higher in spatially differentiated than in homogenous conservation payments armsworth et al 2012 including them would have led to the straightforward result that an increase decrease in transaction costs makes spatially differentiated payments less more cost effective in comparison to spatially homogeneous payments hence including transaction costs would have made the model more complex and the modelling more tedious without generating any insights however when drawing policy relevant conclusions from the model it is useful to remind the reader and oneself about this limiting assumption because the resulting policy recommendations may otherwise be biased another reason for simplifying assumptions may be that their inclusion would make the model overly complex or they are simply not deemed relevant at the time of modelling unlike in the abovementioned case of transaction costs it may not be straightforward to understand how the inclusion of these aspects may change the model results this aspect should be acknowledged in the discussion of the model limitations and one may suggest further research to investigate this previously ignored consideration an example of such a case in which a previously ignored aspect was later included in a model is vortkamp et al 2020 who extended a model by barraquand and martinet 2011 to include allee effects i e the increase in the population growth rate with an increasing population size which can be observed at low densities and is often due to the effects of the mating behaviour which requires specific minimum densities the authors found that including allee effects substantially alters the performance ranking of conservation policies last one should bear in mind that the results of the model are only valid within the considered parameter range although parameter values should have been selected in a way that they represent rather general situations it cannot be excluded that parameter values outside the considered ranges but still relevant for real conservation problems may lead to qualitatively different results an appropriate way of addressing these unavoidable limitations of generic models is to formulate policy recommendations with caution bearing in mind that the model may miss aspects that may change the conclusions drawn from its analysis thus if policy recommendations are derived from a model analysis it is advisable to formulate these recommendations in a careful manner using wordings such as the model results indicate the model results suggest or within the considered parameter range we find that or similar this advice however should in no way diminish the power of generic models which lies in the generation of understanding and the factors that are likely to be important in the design of biodiversity conservation policies 8 conclusion ecological economic modelling is a very useful approach for the integration of ecological and economic knowledge we focus on generic ecological economic models that are rather abstract and aim at the general understanding of mechanisms that drive the interaction of ecological and economic factors as compared to specific models that are usually more detailed and focus on real systems we limit ourselves here to generic models because on the one hand these are associated with particular challenges such as the abstract and generic formulation of processes and their interaction as well as systematic model analysis to develop general understanding and on the other hand a primer for generic ecological economic modelling does not yet exist like textbooks this guide is unlikely to be read from cover to cover rather beginners in ecological economic modelling will benefit from the introductory sections in particular the parts on concepts and formulating the research question then while iteratively going through the different steps of model development implementation testing analysis and use readers will find guidance for the corresponding steps the culture of modelling differs widely between disciplines and between ecological and economic modelling drechsler et al 2007 mathematical models based on calculus which have been so successful in physics have been and are still used in ecology and economics but in ecology these models now more or less peacefully coexist with simulation approaches such as agent based or grid based models economic theory is still dominated by mathematical formulations but simulations also seem to be gaining ground we therefore presented guidance for the entire modelling cycle to help establish a consistent and coherent culture for ecological economic modelling while the cultures may differ the basic challenges and steps of modelling are independent of specific disciplines for beginners in ecological economic modelling it can be helpful not to necessarily start developing a model from scratch but to re implement and then develop an existing model this approach can be used to practice the various steps of modelling but it can also help the novice to enter a productive modelling cycle faster and more efficiently and it can improve theory development in general thiele and grimm 2015 our guide will also facilitate understanding of the existing models which is a prerequisite for advancing the field only if we fully understand a model and its rationale will we able to critically evaluate both and where appropriate improve and extend them the existing disciplinary guides and textbooks are still needed and useful for ecological economic modellers but they do not prepare users well for interdisciplinary modelling we hope that our guide helps to close this gap declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank two reviewers for their insightful comments and suggestions supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2021 109861 appendix supplementary materials image application 1 
24496,biodiversity loss is a result of interacting ecological and economic factors and it must be addressed through an analysis of biodiversity conservation policies ecological economic modelling is a helpful approach to this analysis but it is also challenging since modellers often have a specific disciplinary background and tend to misrepresent either the ecological or economic aspects here we introduce some of the most important concepts from both disciplines and since the two modelling cultures also differ between the two disciplines we present an integrated consistent guide through all the steps of generic ecological economic modelling such as formulation of the research question development of the conceptual model model parametrisation and analysis and interpretation of model results although we focus on generic models aimed at a general understanding of causes and remedies for biodiversity loss the concepts and guidance provided here may also help in the modelling of more specific conservation problems this guide is aimed at the intersection of three disciplines ecology economics and mathematical modelling and addresses readers who have some knowledge in at least one of these disciplines and want to learn about the others to build and analyse generic ecological economic models compared to textbooks the guide focuses on the practice of modelling rather than lengthy explanations of theoretical concepts we attempt to demonstrate that generic ecological economic modelling does not require magical powers and instead is a manageable exercise keywords biodiversity conservation policy ecological economic modelling generic modelling land use 1 introduction the world s biodiversity is declining steadily attempts to halt this decline have largely failed thus far a major reason for biodiversity loss is anthropogenic land use change which is primarily driven by economic motives millenium ecosystem assessment 2005 this indicates that to design strategies and policy instruments for halting the loss of biodiversity it is indispensable to address not only the ecological dimension of land use change but also its economic dimension which may include social and behavioural aspects in comparison to purely disciplinary economic and ecological approaches an integrated consideration of economic and ecological aspects and drivers is advantageous because it captures the intertwinedness of ecological and economic factors this approach allows for the development of conservation solutions that are superior to disciplinary ones ando et al 1998 armsworth et al 2006 w√§tzold et al 2006 many land use systems are complex have a large spatial extent and develop over long time frames so empirical research alone may be costly and is often insufficient for understanding the spatiotemporal dynamics of these systems and developing policies for conserving their biodiversity hence modelling has been widely used for more than two decades to address questions of land use change lambin et al 2003 lambin and meyfroid 2011 parker et al 2003 verburg et al 2004 often with a focus on biodiversity e g tudge et al 2021 an important class of land use change models are those that integrate ecological and economic aspects henceforth referred to as ecological economic modelling cf w√§tzold et al 2006 and drechsler 2020 such models aim at representing ecological and economic factors at the same level of resolution and in an integrated manner while in other land use models either the economic or the ecological factor often is considered as an external driver only when it comes to planning and assessing biodiversity conservation strategies and policy instruments in terms of the cost effectiveness both ecological and economic processes need to be taken into account well designed models can help to explore the consequences of policies before their implementation grimm et al 2020 or provide advice on how to improve existing policies will et al 2021 an important distinction between models is their overall purpose grimm et al 2020 distinguish three primary purposes demonstration understanding and prediction while models for prediction tend to be complex and case specific models aimed at demonstrating important concepts or creating a general understanding of the dynamics of the considered systems tend to be simpler and more generalised here we refer to these models as generic models as defined by their claim to cover a broad range of situations and cases drechsler et al 2007 this primer focuses on generic ecological economic models generic models go beyond the peculiarities of specific systems but use general ecological and economic concepts to describe ecological and economic processes such as population dynamics and land use decisions these theoretical concepts are implemented via equations e g for species population growth or rules such as if the economic profit of a land use measure exceeds a certain threshold the measure will be implemented the formulation of these equations and rules usually requires the specification of certain model parameters such as the population growth rate or the profit threshold in the examples above in contrast to specific models these parameters are not estimated empirically but are usually assigned plausible ranges within which the parameters are varied to explore the behaviour of the model generic ecological economic modelling has been applied in many different contexts the first models probably also historically consider the optimal e g cost effective spatial or temporal allocation of conservation budgets to maximise some ecological benefit wu and boggess 1999 drechsler and w√§tzold 2001 costello and polasky 2004 a popular application of these approaches although usually employing specific models is conservation planning in which mathematical algorithms are used to select reserve sites to achieve certain conservation targets such as a particular number of conserved species ando et al 1998 margules and pressey 2000 moilanen et al 2008 strange et al 2011 another application is the identification of trade offs between the ecological benefits and economic costs of conservation measures polasky et al 2008 schr√∂der et al 2008 another major application of generic ecological economic models is the design and assessment of economic instruments such as conservation payments engel 2016 and conservation offsets vaissi√®re et al 2017 which are applied in many parts of the world salzman et al 2018 bull et al 2018 for instance w√§tzold and drechsler 2005 developed a model to understand the importance of the spatial differentiation of conservation payments ando and chen 2011 analysed the optimal length of conservation contracts and drechsler et al 2010 explored the efficiency gains that can be generated by applying the agglomeration bonus concept parkhurst et al 2002 to species conservation further research analysed the application of tradable permits to biodiversity conservation drechsler and w√§tzold 2009 kangas and ollikainen 2019 the cost effectiveness of different governance modes for conservation sch√∂ttker et al 2016 farm scale versus landscape scale management cong et al 2016 and the joint consideration of biodiversity and ecosystem services in policy design ekroos et al 2014 despite the importance of biodiversity conservation and the relevance of generic ecological economic models for our understanding of conservation policies and strategies these models are developed infrequently in our opinion one key reason is that building and analysing generic ecological economic models requires at least some skills in different scientific disciplines including ecology economics and mathematical modelling moreover unlike other methods in ecology and economics there is little guidance on generic ecological economic modelling this lack of information may deter researchers especially those at young ages from delving into this relevant and interesting field a synthesis of important ecological and economic concepts relevant to the field of biodiversity conservation as well as their mathematical formulation can be found in drechsler 2020 however while providing broad coverage of issues drechsler 2020 does not give specific guidance on how to build and analyse ecological economic models the present article attempts to fill this gap by providing a primer for generic ecological economic modelling while limited in the number of considered ecological and economic concepts it is focused on the primary commonalities of ecological economic models and the basic steps that must be taken to develop a generic ecological economic model fortunately many generic ecological economic models with a focus on land use based biodiversity conservation share a common structure despite differences reflecting different research questions we concentrate on generic models that include i spatial structure since landscapes are usually spatially heterogeneous and ecological and economic processes are distance dependant ii dynamics since environmental and economic systems usually change over time and iii land use which provides the interface between the ecological and the economic realms by being an economic activity that affects the ecological system nevertheless while we focus on models for addressing biodiversity conservation and land use the modelling steps and principles presented in the following text largely apply to ecological economic modelling in general most of the approaches and concepts we present are quite well known within their discipline ecology or economics but not across these disciplines and not in terms of how to use them for integrated modelling our primer goes through each of the primary steps for constructing a generic ecological economic model by describing commonly used methods and approaches and explaining necessary considerations each construction of a model starts with the identification of its general purpose and a specific research question section 2 the research question to be addressed implies decisions about which features of the focal system to represent in the model and the establishment of a conceptual model and its formal structure section 3 during the next step this formal structure is implemented via equations and or computer algorithms this implementation must be based on relevant ecological and economic concepts further considerations include how to model the landscape implement stochasticity and boundary conditions and code and parametrise the model section 4 the model results now must be generated and analysed this analysis involves amongst other things the simulation of the model dynamics a statistical analysis of the model output and systematic sensitivity analyses to explore and understand the behaviour of the system section 5 last the primary answers provided by the model to the original research question must be presented and discussed in a way that they can support the decisions of policy makers and stakeholders chapter 6 here it should be noted that for modelling questions related to land use change in general which is much larger and more diverse field than ecological economic modelling for biodiversity conservation primers or textbooks similar to ours exist for example jakeman et al 2006 and national research council and geographical sciences committee 2014 before we start some cautionary notes the amount of information and hints given in the following text may look daunting to neophytes to ecological economic modelling however if readers have some modelling experience or training in theoretical ecology or economics they will find many familiar elements additionally our overview of approaches to model analysis and good modelling practice does not imply that all these approaches are needed in every case in fact in many of the generic ecological economic models that we have co developed we have not used every approach it is important however to know the different concepts and approaches and use them wisely whenever it makes sense and there is enough time in addition modelling as in many other scientific approaches is not a linear process as one might assume from reading this primer it is better to think of it as an iterative endeavour in which at some point in the modelling process one needs to go back to an earlier stage and redo some of the model construction steps last we would like to stress that except for very experienced researchers ecological economic modelling is likely to be more successful if performed by a team because it requires knowledge from different disciplines amongst other things this property implies that if phd students delve into the world of ecological economic modelling they need appropriate support and supervision they should never forget douglas adam s advice in his hitchhiker s guide to the galaxy don t panic 2 identification of the conservation problem decisions on the model purpose formulation of research questions and relevant patterns any modelling project should start with the clarification of the basic issues of the conservation problem to be addressed this could 1 be the conservation of important species or the management of invasive species that could be affected by agricultural or other land use as well as other drivers such as climate change and 2 the land use measures that affect the species may be induced by a policy instrument such as conservation payments after these basic considerations one should define the overall purpose of the modelling exercise as noted in the introduction the primary purpose of generic models is usually to understand the modelled system better however beyond this goal one must specify what exactly should be understood is the purpose to understand the dynamics of the system and how do they depend on drivers or policies is it about managing the system in some optimal manner here optimal may mean that a particular ecological objective such as the survival of a target species is maximised ecological effectiveness alternatively optimal may mean that an ecological objective is maximised for given economic costs or an ecological target is achieved for the lowest economic costs both approaches are typically denoted by the term cost effectiveness box 1 once the conservation problem has been defined and the general purpose of the model has been identified specific research questions should be formulated if the conservation problem is about the management of an invasive species one may analyse whether it is more cost effective to invest financial resources into the prevention of the invasion or the control of the invasion after it has occurred finnoff et al 2007 likewise if the conservation problem is targeting the coexistence of two competing species one may explore whether a conservation offset scheme is ecologically effective in terms of facilitating coexistence surun and drechsler 2018 alternatively one may explore under which circumstances the expansion of conservation reserves may due to adverse feedbacks on the land use outside the reserves create a net reduction in the overall amount of protected biodiversity armsworth et al 2006 these preparatory steps are illustrated in the following text using the example of an agricultural landscape with privately owned land parcels the landscape is inhabited by a species of conservation concern with a limited dispersal range such as a flightless insect for its reproduction the species requires 1 extensive land use that is less profitable to landowners than their preferred intensive land use and 2 that these extensively used land parcels are located as close to each other as possible due to the species limited dispersal range a conservation payment may therefore be introduced that induces landowners to engage in extensive land use by compensating them for the associated profit losses the payment is spatially homogenous and the same for all landowners for an analysis of heterogeneous payments see w√§tzold and drechsler 2005 and participation in the payment scheme is voluntary for these reasons the conservation agency has no control over the spatial locations and arrangement of the land parcels that the landowners manage extensively in response to the payment to induce a spatial agglomeration of the landowners conservation efforts the conservation agency considers the introduction of an agglomeration bonus that is paid on top of the homogenous payment parkhurst et al 2002 if adjacent land parcels including those owned by other landowners are extensively managed as well the response of landowners to the agglomeration bonus may depend on their behavioural traits typically it is assumed that they maximise their economic profits but other motives do exist and could be considered section 4 1 1 the policy maker may then be confronted with the task of designing the agglomeration bonus scheme in the described setting to conserve the focal species in a cost effective manner having defined the conservation problem a model purpose may be to understand the functioning of the agglomeration bonus in the described setting better raising two general research questions how does an agglomeration bonus affect the survival of species in agricultural landscapes and how can it be made cost effective from these general research questions more specific ones may be derived that refer to the peculiarities of the considered system for instance one might ask how the cost effective level of the agglomeration bonus depends on the spatial variation in the conservation costs profit losses and the dispersal range of the species the analysis of these questions section 5 may be simplified considerably if the questions are formulated in a dichotomic manner and can have only two possible answers yes and no for instance one may ask whether the cost effective level of the agglomeration bonus depends on the dispersal range or not and whether there is a positive or negative relation between dispersal and cost effectiveness although new or refined research questions may also come up over the course of model building and analysis cf the modelling cycle of grimm and railsback 2005 see section 6 below it is important to formulate them as early in the modelling process as possible since they are most likely to influence the model structure and the outputs the model should deliver the questions need to focus on the aspects of the modelled systems that are considered essential for answering the research question while other aspects may be ignored or represented in a more aggregated simplified way of course whether a certain aspect is essential must be explored when analysing the model behaviour certain aspects may turn out to not affect the model behaviour or the model may not lead to dynamics and structures that are compatible with observations or general principles cf section 4 3 which indicates that at least one key factor has not yet been considered last one needs to consider the realism of the model to be developed models are simplified representations of real systems so even for generic models we need some indicators that the model makes sense in terms of representing features of the real systems it is important to discuss which features will be used to claim that the model is realistic enough for its purpose from the start of a modelling project because this issue will affect the model design both in terms of its entities variables and scales and its acceptance by stakeholders and policy makers instead of features it helps to think about the patterns that characterise the real system or the class of real systems we are representing with patterns we refer to anything that is beyond random variation and therefore must have some underlying mechanism for generic models usually only broad patterns are of interest for example that an equilibrium e g between the reproduction and mortality of individuals in a population or the demand and supply of a good in a market exists or that high payments for extensive land use will strongly affect land use patterns often however models are in fact designed to reproduce specific patterns of interest to explore their underlying mechanism cyclic dynamics such as the famous pork cycle hanau 1928 or the hare lynx cycle stenseth et al 1998 striking spatial zinck and grimm 2009 p√©rez and janssen 2015 or spatiotemporal patterns thulke et al 1999 van de leemput et al 2015 or patterns in distributions of species richness m begon et al 1990 ch 22 2 or land use type iwamura et al 2016 taubert et al 2018 are examples if more than one observed broad pattern is reproduced by a model it is more likely that it captures the real mechanisms rather than being tweaked by some artificial model mechanisms this strategy of pattern orientated modelling grimm et al 2005 grimm and railsback 2012 railsback and grimm 2019 is widely used for complex specific models but can also help to parameterise generic models efficiently jakoby et al 2014 see section 4 3 gallagher et al 2021 review the kind of patterns that have been used so far for pattern orientated modelling in ecology in economics patterns are often referred to as stylised facts meyer 2019 introduces to the use of stylised facts in economics and other fields 3 specification of the relevant system entities and processes and conceptual construction of the model having identified the conservation problem including the major issues that should be considered and the associated model purpose patterns and research questions we now develop the model in more detail at this stage the development is of a conceptual nature involving verbal and graphical representations of the system the translation into formal or mathematical language as well as the implementation in computer code will be addressed in section 4 the conceptual development of the model consists of a few elements grimm et al 2020 i a description of the entities and ii processes in the model system including interactions between entities iii specification of boundary conditions and iv the introduction of model parameters and model variables 3 1 model entities in the description of the system entities and processes we consider that an ecological economic land model typically consists of three primary components an ecological component an economic component and the model landscape in which the entities are located and the processes operate ecological entities may include m begon et al 1990 individuals populations which are sets of individuals of the same species that interact particularly through mating and reproduction and communities which are sets of populations that interact with each other e g through competition or predation ecosystem models also include abiotic factors with a strong focus on stocks and flows of nutrients and energy instead of organisms and biodiversity and therefore will not be considered here cf grimm et al 2017 the most important entities of the economic model component are usually the individual landowners when derived from these components an entity of a higher organisational order may be split by groups of e g neighbouring landowners or the entirety of all landowners which operates in a market section 4 1 the conservation agency can in principle also be regarded as an economic entity but this categorisation is meaningful only if it is affected by other model entities if the policy maker adapts a policy in response to changes in the system cf polasky and segerson 2009 if such feedback does not exist it is more practical to consider the policy maker as an external driver last the landscape entities must be defined in disciplinary research both within ecology and economics one may distinguish between patch based and grid based approaches to consider the spatial structure in the patch based approach the landscape consists of polygons patches within a matrix of voids such as islands in a sea and the model considers only the patches largely disregarding the matrix examples include simple models consisting of two regions with different ecological and economic characteristics in which a policy maker allocates a conservation budget over both regions to maximise some aggregate ecological benefit e g wu and boggess 1999 w√§tzold and drechsler 2005 here only the size of the regions matters but not their locations in ecology the metapopulation concept which allows the description of population dynamics in spatially structured landscapes see section 4 2 assumes at least in its basic formulation a patch based landscape the ecological processes take place only within the habitat patches while the matrix between the patches is considered only in that individuals may disperse between habitat patches and the probability of an emigrant from one habitat patch reaching another habitat patch may depend on the distance between the two patches for problems and questions that also include land use it is often more appropriate to consider the entire landscape explicitly which can usually be better achieved with a grid based approach here the landscape is structured as a grid of cells usually of quadratic shape although hexagonal grid cells have also been considered by liu 1993 and leonard et al 2017 each grid cell can have properties e g soil quality and be in a particular state e g managed in a particular manner occupied by an individual or a population of a particular species etc spatial heterogeneity within the grid cells is however ignored 3 2 model processes the defined ecological economic and landscape entities interact and change their states locations behaviour etc through processes for instance the land use change on a particular grid cell may change the suitability of the cell as habitat for a species or a group of individuals of the species may through dispersal from a neighbouring cell immigrate and establish a population in this cell through these processes the model becomes dynamic interactions between model entities may be global in that each entity can interact with each other entity or local in that an entity interacts only with some entities such as neighbouring entities global interactions are often assumed for mathematical convenience and make sense if 1 the interactions are very long ranged or 2 the populations are well mixed so that during their lifetime everyone will have contact with many or all other individuals in landscapes however interactions are usually local for example the change in species occupancy of a particular grid cell usually does not depend on the occupancies in all the other grid cells in the model region but due to limited dispersal only on the occupancies in neighbouring cells or in the presence of dispersal corridors on the occupancies in connected grid cells similarly the land use in a grid cell may change via communication between neighbouring landowners depending on the land use in neighbouring grid cells interactions can thus be described by networks that specify for each grid cell with which of the other grid cells it interacts e g minor and urban 2008 or by distance dependant interactions examples of these distance dependant interactions are the probability of a dispersing individual reaching a habitat patch which declines with increasing distance section 4 1 2 or when assuming that the choice of trading partners in a water quality trading market depends on the distance between possible partners nguyen et al 2013 processes may be deterministic or stochastic the outcome of a deterministic process is fully determined by the model parameters and variables while a stochastic process contains random elements so that the outcome of the process may be predictable on average but may vary around its mean in an unpredictable manner stochasticity sections 4 1 3 and 4 1 4 is included whenever it is assumed that observed variation and heterogeneity matter for the question addressed with a model but that the mechanisms causing this variation are unknown or not of interest examples of processes that may be represented stochastically are the reproduction and mortality of individuals burgman et al 1993 or a land use change in response to the changing profitability of land use measures appendix a processes may operate not only between different entities within the modelled system but also from the outside these processes are called exogenous or external and may relate to a changing crop price polhill et al 2013 or rainfall bell et al 2016 that affect the land use profitability as a particular type of external driver one may also regard environmental policies such as a conservation payment scheme in which a particular conservation measure is rewarded via a payment similar to crop price or rainfall the magnitude of such a payment is usually determined exogenously by a conservation agency and is not affected by the state of the system to designate an entity as exogenous or external we assume that there is no feedback from the modelled system on those exogenous processes or drivers of course policies can also be influenced by endogenous processes within the modelled system but studies involving such considerations are rare groeneveld et al 2017 3 3 boundary conditions a final choice regarding the overall model structure concerns the boundary conditions that specify what happens at the physical boundary of the system this question turns up if e g an animal at the northern boundary of the model region wants to move north or if a landowner with the decision rule to adopt neighbouring land use that is observed in at least four of the eight adjacent grid cells has a parcel in the north western corner of the model region that has only three neighbours altogether in specific models one may consider so called open boundaries in which an entity on the system boundary interacts with entities outside the system e g a species population may be affected by the immigration of individuals from the outside but this consideration is less relevant in generic models here boundaries are usually considered either closed or periodic a closed boundary may be imagined as an impermeable wall around the model region the behaviour and decision rules of ecological and economic entities must be formulated accordingly such that an animal moves north only if it is not at the northern boundary and otherwise takes another direction or rests however this assumption implies that the spatiotemporal model dynamics at the boundary differ from those in the interior of the model region if these differences between the interior and the boundary are considered inadequate for the description of the system one may introduce periodic boundaries so that the grid cells at the western border of the model landscape are neighboured or wrapped to the eastern grid cells and or the most northern grid cells are neighboured to the most southern ones depending on whether periodic boundaries are considered in one or two geometric dimensions the model landscape has the shape of a cylinder or a torus wikipedia contributors 2021a the latter is a model world without boundaries and the underlying assumption is that the corresponding real system is much larger than the model system so we can assume that for example as many entities that leave to the east will enter in the same time step from the west or that the grid cells bordering the northern edge will have a similar distribution of properties as those bordering the southern edge the choice of the boundary conditions completes the conceptual description of the generic ecological economic model 3 4 model variables and parameters as a preliminary step towards the formal description of the model we now define mathematical quantities that characterise the entities and processes here we distinguish between variables that we understand as quantities that change over time or that characterise and distinguish the entities while the parameters are constants examples of variables are behavioural traits such as the level of risk aversion see section 4 1 1 the size of a species population in a grid cell or the economic profit gained in a land parcel in a given year in addition to such endogenous variables that change due to processes within the system variables can also characterise external drivers such as a changing crop price or rainfall model parameters are constants that quantify changes mediated by the model s processes for example the per capita population growth rate in eq 8 if they are the same for all processes and entities they are just parameters but if they differ between entities for example the soil type in grid cells they are also variables grimm et al 2020b in this case variation refers to features or attributes of entities not to variation in time all the variables of a model taken together characterise at a given point in time the state of the model system and are therefore referred to as state variables grimm et al 2020b some of these variables plus the possible variables characterising the state in a more aggregated way form the output of a model analysis section 5 3 these output variables may be the total cost of a conservation scheme the mean size of a species population in the model region etc parameters are usually inputs to the model such as the spatial variation in soil quality or the dispersal range of a species which affect the dynamics of the model system and eventually the state variables and model output in the modelling literature the initial values of state variables are also referred to as inputs lorscheid et al 2012 relating model output to model input is a central task in the causal analysis of a model section 5 3 the result of the considerations in this section the conceptual model can be represented verbally or graphically or both a useful and popular tool here is the odd protocol grimm et al 2006 2020 which has been developed for describing so called agent based models but can be used for simulation models in general here o stands for overview including the primary purpose of the model and the model s entities and processes d stands for design concepts such as interactions or stochasticity and d stands for details such as how a stochastic movement behaviour of an individual is modelled or how a landowner predicts future profits of a land use measure the odd protocol is like a checklist in that it guides the modeller through the structured description of all the model elements including the entities processes drivers and boundary conditions for habitat suitability models fig 1 often also referred to as species distribution models a similar protocol exists odmap zurell et al 2020 an example of a graphical representation of a model is shown in fig 1 which takes up the conservation problem outlined in section 2 this representation comprises a landscape component an economic component an ecological component and an external driver the landscape component contains the geographic data of the model region such as the coordinates sizes and soil productivities of the land parcels from the soil productivity Œ∑i determined amongst others by the soil type an economic model calculates the agricultural profitability œÄi xi of each land use measure xi for each grid cell land parcel subtracting the profitability associated with a conservation measure from the profitability associated with the most profitable land use measure yields the opportunity cost of the conservation measure together with the conservation payment which consists of a base component pa and an agglomeration bonus component pb this calculation is the input into a landowner decision model for which the output is the land use xi a habitat suitability model as part of the ecological model component translates land use xi into habitat suitability si which is the basis of the landscape as perceived by the species of concern in applying the metapopulation concept section 4 the dynamics of the species in this landscape are governed by the extinction of local populations in the individual habitat patches land parcels and the colonisation of empty habitat patches the key model variable affected by these processes is the occupancy qi for each habitat patch i e the information on whether the species is present in the patch this text completes the conceptual description of the model system as outlined the aim of the model is to understand how the cost effective design of the payment scheme in particular base payment and bonus pb and pa depend on ecological and economic conditions such as the spatial distribution of the land parcel profitability and the species dispersal range cost effectiveness involves optimisation in which control variables pb and pa are varied to maximise an objective the survival of the species under constraints e g a conservation budget the model in fig 1 is embedded in this optimisation scheme by delivering the associated budget the sum of the payments over all conserving landowners for a given choice of pb and pa and the resulting viability of the species e g its survival probability see section 5 2 2 in obeying the scope of the present paper we will not address optimisation issues any further but will instead focus on the construction and analysis of ecological economic models 4 formal construction implementation and parameterisation of the model 4 1 mathematical formulation once the model is conceptually established it must be translated into formal language here we distinguish between two primary approaches equation based models in which the model processes are formulated through mathematical equations and rule based or algorithmic models that are driven by processes formulated in the form if condition u applies event v happens the rules themselves can include equations so that condition u may be formulated by an equation an advantage of fully equation based models is that they provide a compact and rather transparent mathematical representation of the model and can sometimes be solved analytically so that essential features of the model behaviour are immediately visible the downside is that these advantages are quite rapidly lost when the model system becomes complex due to the large number of factors that are considered important such as spatial dependencies behaviour and variability of agents in these situations rule based models may be required for example they may be grid based jeltsch et al 2008 seltzer 2019 or agent based barfuss et al 2017 muneepeerakul et al 2017 seltzer 2019 grimm and railsback 2005 railsback and grimm 2019 models most generic models employ a mixture of rules and equations for instance the decisions of landowners are often modelled so that some utility function section 4 1 1 is maximised most simply one may assume that utility is proportional to economic profit with an example given by eq 1 and the dynamics of a population are in generic models often described through a differential equation such as eq 8 rules may enter here if landowners observe the behaviour of other landowners and adapt their land use appendix a or if the population growth rate depends on the applied land use measure in a specific model the modelling of the processes is strongly based on the specific knowledge of the focal system but in a generic model we refer to established concepts such as density dependant growth in ecology or market equilibrium in economics reviewing all potentially relevant ecological and economic concepts would be far beyond the present article these concepts can be found in the various disciplinary textbooks in the fields of environmental economics and theoretical ecology e g hanley et al 2016 may and mclean 2007 an extensive overview of concepts relevant for ecological economic modelling is provided by drechsler 2020 but even this publication still covers only a subset of all the concepts that may be of interest in fact the choice of concepts largely depends on the considered system the conservation problem the model s purpose section 2 and in the practice of research of course on the knowledge background of the individual researcher below we present a few general concepts that may be useful 4 1 1 economic concepts 4 1 1 1 modelling the economic profit of land use measures in ecological economic systems socioeconomic processes often affect land use which in turn affects the dynamics of populations and ecosystems fig 1 we therefore first consider the economic component of ecological economic modelling in fig 1 the economic component contains the economic model and the landowner decision making model the economic model determines profitability as a function of land productivity and land use the simplest approach is to assume that the landowner can choose between two land use measures intensive use xi 0 which maximises profit œÄi xi 0 but is not beneficial for biodiversity see section 4 1 2 and an alternative biodiversity friendly or extensive land use measure xi 1 with lower profit œÄi xi 1 in case the conserved area is taken completely out of production one may think of a strictly protected nature reserve and economic activity is not feasible the profit is obviously zero profit is typically defined as the difference between revenue and production cost c in which the revenue is the product of the agricultural yield yi and the market price p for the produced crop e g polhill et al 2013 1 œÄ i p y i c to model the yield one may assume that it is proportional to the local land productivity Œ∑i 2 y i g Œ∑ i with g being some constant additionally one may assume that eq 1 applies only to the intensive profit maximising land use measure xi 0 while for the extensive biodiversity friendly land use measure the profit may be constant and identical for all land parcels œÄi xi 1 œÄ below we model the landowner decisions as functions of the difference between œÄi xi 0 and œÄi xi 1 in this case the profit œÄ can without loss of generality be set to zero which simplifies the calculations in addition yields may be influenced not only by land productivity but also by climatic factors such as rainfall bell et al 2016 furthermore eq 1 motivates another extension profit may depend on the travel distance of land users to a land parcel groeneveld et al 2005 because more distant land parcels incur higher transport costs c distance dependence may also be relevant under other circumstances for example armsworth 2018 considered that the risk of deforestation declines with the distance from settlements last one may consider more than two land use measures and more than a single product from land use polhill et al 2013 4 1 1 2 landowner decision model ecological economic models which address specific challenges of conservation planning see the references in the introduction often apply a top down approach explicitly or implicitly the perspective of a welfare maximising planning agency is adopted that optimises a spatio temporal land use pattern to achieve a conservation goal under a budget or cost constraint armsworth 2018 in this context the decision of the landowners does not need to be explicitly modelled however this is different for incentive based conservation policies such as conservation payments and conservation offsets in this context the decision of the landowner or often equivalently the land user which includes farmers forest owners etc needs to be explicitly addressed landowners are at the intersection between the ecological and the economic subsystem because they respond to economic influences and may interact with other landowners while their actions affect the ecological subsystem and might in turn be influenced by it the simplest concept for modelling human behaviour and often a useful starting point for the development of a generic ecological economic model is the model of homo economicus the homo economicus is a perfectly informed rational and self interested decision maker who strives for the maximisation of his her utility the way to proceed from the heuristic homo economicus model is described below in a very narrow sense utility may be a function of monetary profit but in general it can also include non monetary aspects that determine human well being utility functions are usually assumed to have a concave shape e g u x x 1 2 for x 0 fig 2 to consider that the marginal i e added utility of an additional unit of a good generally declines with increasing possession of the good in addition concave utility functions allow for considering risk aversion as is typically assumed in human decision makers if the outcomes of an action are uncertain for a detailed explanation see pindyck and rubinfeld 2014 or drechsler 2020 assume that a decision maker can choose between some actions ai i 1 m the monetary profit of each action ai is uncertain and can assume one out of n possible values œÄij j 1 n each occurring with probability pj consider further a utility function u œÄ that maps profit onto utility the decision maker will choose the action ai that maximises the expected utility eu 3 e u a i 1 n j 1 n p j u œÄ i j as noted a risk averse decision maker is modelled by a concave utility function such as the von neumann morgenstern utility function 4 u œÄ œÄ 1 œÅ 1 1 œÅ where œÅ is the coefficient of constant relative risk aversion eeckhoudt et al 2005 quaas et al 2007 at œÅ 0 the utility function u œÄ 1 is linear in œÄ and the decision maker effectively maximises their expected profit 5 e œÄ a i 1 n j 1 n p j œÄ i j representing risk neutral decision behaviour with an increasing œÅ the utility function becomes increasingly concave which implies that the expected utility eu of an alternative in which profits œÄj vary over j declines relative to that of an alternative in which profits are certain modelling the behaviour of an individual who is averse to risk for further details see appendix a and drechsler 2020 in addition to the described uncertain variation profits may also change over time œÄ œÄ t so the expected utility in eq 5 is time dependant eu ai eu ai t or equivalently eœÄ ai eœÄ ai t in eq 5 decision makers are generally assumed to have a time preference in the sense that they place a higher value on current benefits and costs compared with future ones several reasons may explain this time preference they include an empirically observed pure time preference impatience of human beings uncertainty about the occurrence of future costs and benefits and the foregone opportunity to invest financial resources today to have a higher amount of financial resources in the future boardman et al 2017 in models with continuous or discrete time this preference is modelled by maximising the present value pv of the expected utility or profit taking into account that future costs and benefits are discounted 6 p v e u a i t 0 e u a i t exp Œ¥ t p v e u a i t 0 e u a i t 1 Œ¥ t respectively where Œ¥ is the discount rate an increasing Œ¥ models an increasing time preference i e future costs and benefits are given increasingly less weight than present costs and benefits a generic modelling example in which the size of the discount rates plays an important role in where and when to conserve an area is armsworth 2018 the model of homo economicus as represented by eqs 3 6 is the classical model of human decisions and the simplest one however clearly this model does not fully capture the complexity of human behaviour for example the behaviour of landowners can be influenced by other factors such as farmer characteristics e g age education or personality social influences e g the attitudes of trusted friends and the availability of information edwards jones 2006 frondel et al 2012 recently dessart et al 2019 reviewed the findings of the past 20 years on the behavioural factors that influence farmers decisions to adopt environmentally sustainable practices the factors were sorted into three classes i dispositional factors including resistance to change risk tolerance which is to a large extent covered by eq 3 and moral or environmental concerns ii social factors including social norms such that a landowner adopts a particular land use if the number or proportion of landowners who employ that land use exceeds a particular threshold and iii cognitive factors including the perceived costs and benefits of land use measures and perceived risks which may differ from the true risks that are considered in the risk utility function associated with the costs and benefits of land use measures the literature provides a number of modelling approaches that address at least some of these factors an 2012 groeneveld et al 2017 schl√ºter et al 2017 huber et al 2018 schwarz et al 2020 in appendix a some useful examples are provided that focus on resistance to change the presence of conflicting objectives social norms perceived costs and benefits and perceived risks all these factors consider the land use decision of each individual landowner they partly include stochastic elements and or consider not only the state of their own land parcel s but also the states e g land use of the land parcels belonging to other landowners taking such complex decision making into account requires agent based modelling approaches tesfatsion 2005 railsback and grimm 2019 whether it is sufficient to assume homo economicus as a decision maker or to assume more complex human behaviour depends amongst other issues on the research question and the model purpose drechsler 2021 ideally the patterns the model is supposed to reproduce may help to identify the most suitable behavioural model the pattern orientated selection of a specific submodel is increasingly used in ecology railsback and grimm 2019 but requires a minimum level of model complexity which can make the model less generic 4 1 1 3 modelling economic incentives for extensive biodiversity friendly land use an important application of ecological economic models is the analysis of economic or market based instruments for the conservation of biodiversity basically these instruments provide a financial incentive to landowners who implement biodiversity friendly land use measures or avoid biodiversity harmful measures employing these measures usually reduces the profit from intensive land use and an economic instrument is aimed at establishing a payment to offset this foregone profit below we briefly outline major types of these instruments in a conservation payment scheme the policy maker offers a payment usually the same payment per measure and area of land for all landowners to those landowners in a region who implement a biodiversity friendly land use measure a key reason for the use of spatially homogeneous payments is that differentiation according to landowners costs is generally not feasible because this information is private and landowners have no incentive to share it with the regulator ferraro 2008 each landowner i then determines whether it is more profitable to perform the intensive land use measure xi 0 which maximises profit œÄi xi 0 or the extensive biodiversity friendly measure xi 1 with lower profit œÄi xi 1 œÄi xi 0 but with the award of the conservation payment p 7 x i 1 œÄ i x i 1 p œÄ i x i 0 0 œÄ i x i 1 p œÄ i x i 0 assuming the homo economicus model landowners for which conservation is too costly so that payment p cannot offset profit loss œÄi 0 œÄi 1 will prefer intensive land use while those for whom the profit loss is smaller than the payment will implement the extensive land use measure as one can observe landowner i responds only to payment p but assuming this consideration is the same for all landowners the payment is not affected by the land use decisions of other landowners in appendix b we will present an example of a payment scheme the agglomeration bonus by parkhurst et al 2002 in which landowners interact with one another examples of generic models that consider the agglomeration bonus concept include albers et al 2008 drechsler et al 2010 bell et al 2016 parkhurst et al 2016 and drechsler 2021 another strain of research on conservation payments addresses the question of whether payments should reward conservation efforts such as a biodiversity friendly land use measure or conservation results such as the presence of a target species on the land parcel examples of generic modelling studies in this context include zabel 2009 derissen and quaas 2013 and drechsler 2017 alternative economic instruments to conservation payments include conservation auctions and offsets box 2 4 1 2 ecological concepts the dynamics of species populations on land parcels with spatially varying habitat suitability are described by population models fig 1 after the following section on habitat suitability we outline four standard modelling approaches which are distinguished by i whether a single habitat patch suitable land parcel or multiple patches the whole landscape are considered and ii whether a single or multiple interacting species are considered 4 1 2 1 habitat suitability model in fig 1 the ecological module contains a habitat suitability model and a population dynamics model habitat suitability models often referred to as species distribution model guisan et al 2017 are based on identifying statistical correlations between habitat features and the observed presence and absence of a species since this approach ties models to specific regions and data sets in a generic model one has to work with informed simplifying assumptions for instance one can assume that the carrying capacity for the species of concern on a land parcel is proportional to the area managed in a species friendly manner alternatively if a land parcel can be managed with different levels of intensity each intensity may be represented by a particular magnitude of the land parcel s carrying capacity another option is if an intensively used land parcel is turned to extensive use one can specify the gradual increase in habitat suitability by using a linear or other mathematical function drechsler and hartig 2011 4 1 2 2 single patch single species population model for the population dynamics of a single species in a single spatially homogenous habitat patch the simplest model reaching back to the economist thomas malthus in the 18th century is the unlimited growth equation 8 d n d t r n which considers that the rate of population change as expressed by the time derivative dn dt is proportional to the current population size with proportionality factor r being the intrinsic per capita population growth rate the model assumes that the growth rate r is constant consequently there is no limit to growth so the population size increases exponentially over time to consider limits to population growth the logistic growth function also more than 100 years old adds a carrying capacity k to eq 8 so that the growth rate dn dt declines with increasing n 9 d n d t r 1 n k this model demonstrates the concept of density dependence and regulation the growth of the population size n depends on the current value of n as n grows the growth dn dt rate declines and this negative feedback leads to the regulation of the population because at n k we have zero growth regulation refers to the fact that after disturbances or events that lead to values of n below or above that of k the population regulates itself back to a value at or close to n k density dependence is a logical postulate because resources e g food are limited so that population growth must stop somewhere however the model does not say anything about the specific mechanisms which might be complex and vary over time and space and not about the role of environmental limitations of growth nevertheless for generic models it is often sufficient to represent density dependence phenomenologically as in eq 9 more details about the models in eqs 8 and 9 in particular their variants for the case of discrete e g annual time steps can be found in textbooks such as wissel 1989 otto and day 2011 or drechsler 2020 the logistic model is deterministic but for small populations random influences can lead to low densities and therefore possibly to extinction this can occur even if the population growth rate is positive when e g a sequence of unfavourable weather conditions reduced the population to low densities so that the random factors that act on the level of the individuals become affective and cause extinction random temporal variations in the population growth rate are called environmental noise whereas the effect of variations at the level of individual life histories is called demographic noise the simulation of a population under demographic noise is demonstrated in detail in burgman et al 1993 and drechsler 2020 hence for small populations under random influences the probability p t of the population surviving for some time t declines exponentially at a local extinction rate if we denote this rate by e quantity e eŒ¥t is the probability of the population going extinct during time interval Œ¥t grimm and wissel 2004 4 1 2 3 multiple patches single species population model if the landscape consists of several habitat patches and individuals can move between habitat patches empty habitat patches are colonised at some colonisation rate c so the probability of a habitat patch becoming colonised during some time interval Œ¥t is c cŒ¥t the colonisation rate c can be modelled as the rate of individuals immigrating into the focal patch multiplied by their probability of establishing a local population the rate of immigration im s into patch s can be modelled as 10 i m s s 1 s e m s Œ≥ d s s where em s is the rate of individuals emigrating from patch s and the so called dispersal kernel Œ≥ dss 1 is a function that models the distance dss dependant probability of an emigrant from patch s reaching patch s often the exponential function Œ≥ dss exp dss Œ¥ is used where Œ¥ is the species dispersal range the model described above forms the essence of hanski s 1999 famous metapopulation model box 3 which is based on the model by levins 1969 this model is probably the most widely used in the field of landscape ecology and the basis of numerous empirical and theoretical studies it is admittedly simplistic but can easily be extended to consider not only whether a local population is present on a habitat patch or not so called patch occupancy models but also the internal dynamics of the population size including life stages random influences and more hanski 1999 in addition the dispersal function in eq 10 can be extended to consider the directed intentional movement of individuals as well as heterogeneous conditions such as land cover for their movements with individual based models even more complicated dispersal models are possible that consider the adaptive movement behaviour of individuals but this approach requires more effort in model development parameterisation and analysis and usually ties the model to specific systems which limits the general insights that can be gained for the complex relation between model simplicity and generality see evans et al 2013 4 1 2 4 single patch multi species population model the above described population dynamic models go quite far in their ability to describe the dynamics of populations however a missing key feature for the modelling of biodiversity or even entire ecosystems is the interaction between different species classical examples of models on the interaction of species are those by lotka 1920 and volterra 1931 for competing species and predator prey systems here when considering a non spatial setting the dynamics of two competing species 1 and 2 with abundances n 1 and n 2 competing for two resources as represented by the carrying capacities k 1 and k 2 are given by 11 d n 1 d t r 1 1 n 1 Œ≤ n 2 k 1 d n 2 d t r 2 1 n 2 Œ≥ n 1 k 2 the competitive influence of species 2 on species 1 is considered by increasing the number of individuals n 1 in the first equation by the term Œ≤n 2 where Œ≤ 1 measures how strongly an individual from species 2 competes compared with an individual from species 1 the competitive influence of species 1 on species 2 is modelled analogously in the second equation the two species can coexist if the strength of the interspecific competition between the two species is smaller than the intraspecific competition amongst individuals of the same species conspecifics Œ≥ k 2 1 k 1 and Œ≤ k 1 1 k 2 the biological interpretation of these conditions is that resource requirements within a species are identical while they should differ to some degree from those of the competing species in this case competition with conspecifics is thus higher so that a species growth is more limited by competition with its conspecifics which is known as negative conspecific density dependence may et al 2020 than by the presence of the other species notably each species at a low density is largely released from intraspecific competition and therefore uses this advantage of being rare to grow faster than the competitor this combination of assumptions about ecological niches and the advantage of rarity plays a key role in the so called modern coexistence theory chesson 2000 which is intended to explain why species rich communities and hence high species diversity can exist for a spatial version of eq 11 one could consider n 1 and n 2 as functions of spatial location and in the intra and interspecific competition one could consider only the number of individuals within a specific radius in a grid based model one could consider n 1 and n 2 as local variables for each grid cell with the grid cells possibly connected with each of their eight adjacent neighbours through dispersal and simulate the dynamics of n 1 and n 2 in each grid cell using eq 11 in addition to competition species may interact as predators and prey via parasitism mutualism or other mechanisms m begon et al 1990 in the context of ecological economic modelling baumg√§rtner 2004 developed a generic model to analyse the efficient conservation of two species as a function of their interaction type the author showed that the interaction between the species can completely reverse the efficient rank order of conservation investments so that e g a species of low priority may due to its influence on another species gain a high priority 4 1 2 5 multiple patches multi species population model last we consider multiple interacting species in a spatially structured landscape a central issue here is the competition for empty habitat patches if the seeds of several plant species are dispersed into empty habitat patches the question is which species will prevail and establish a local population in the patch a simple and intuitive approach here is to assign each species i a competitive strength compi and relate the probability p est i of species i establishing a local population at that strength 12 p est i c o m p i j c o m p j an alternative to eq 12 is to rank all the considered species by their competitive strength compi and assume that in the presence of several species the most competitive one with the highest compi establishes a population with probability one and the others fail with probability one if compi is modelled as the number of seeds in the habitat patch eq 12 describes the so called lottery competition in which the species with the highest number of seeds has the highest chance of establishment banitz et al 2008 usinovicz et al 2012 to facilitate coexistence the more competitive species should have a lower ability to colonise empty habitat patches e g through a smaller dispersal distance in eq 10 since otherwise all other factors being equal it will eventually replace the less competitive species from the region this correlation between species traits is called the competition colonisation trade off which may be modelled at the level of individuals banitz et al 2008 or at the population level tilman 1994 all the presented concepts consider the levels of meta populations and meta communities roughly speaking a community is an ensemble of interacting populations of different species and a metacommunity is an ensemble of interacting metapopulations of different species alternatively one can consider the level of individuals which involves individual based models we refer to the vast literature on the application of individual based models in the field of biodiversity conservation e g grimm and railsback 2005 grimm et al 2017 next to the scale of individuals populations and communities much of ecological research focuses on the ecosystem scale e g m begon et al 1990 historically however ecosystems were conceptualized as compartments characterized by stocks of nutrients and energy and dynamics was assumed to be driven by flows of nutrient and energy between departments there is accordingly still a divide between ecosystem and landscape ecology so that land use models often focus on single species or at specific ecosystem functions such as carbon sequestration but not necessarily at mechanism underlying these functions verburg et al 2009 likewise biodiversity research and ecosystem ecology are still more or less disjunct but would need to be integrated grimm et al 2017 the rationale of focusing on single species in conservation biology is their potential role as umbrella or indicator species if they thrive chance should be high that other species with similar or less complex habitat requirements can persist as well roberge and angelstamm 2004 an increasing number of ecological economic models considers even complex food webs see papers in the research topic policies and strategies for the conservation of metacommunities in frontiers in ecology and evolution more aggregate models employ species area curves that relate the number of species to the size of the conserved area e g w√§tzold and drechsler 2005 for simplicity in this primer we do not consider multiple species nor address the ecosystem scale but it should be kept in mind as the ultimate target scale 4 1 3 modelling the landscape many factors that drive ecological and economic processes are spatially heterogeneous such as soil productivity land cover or the distribution of human settlements within a specific study these features can usually be obtained from real world data but in a generic model these features must be made up by defining stylised landscapes that include aspects of spatial heterogeneity and relationships considered essential for the problem and question addressed by the model the simplest approach to obtaining spatial heterogeneity is to sample the features randomly in a grid based model one can draw the level of an environmental parameter such as soil productivity from a probability distribution for each grid cell the most useful approaches for this purpose are the uniform normal and log normal distributions appendix c a challenge here is to include spatial auto correlation between those random environmental variables a straightforward approach for a single variables like conservation cost is presented in appendix c an algorithm for the creation of landscapes with several features can be found in saura and martin√©z mill√°n 2000 while many research questions can be addressed with these generic random landscapes it can also be useful to model landscapes more realistically and or in more detail bami√®re et al 2013 salecker et al 2019 bartkowski et al 2020 landscape generators can construct complex landscapes consisting of features such as agricultural fields of different shapes and sizes roads hedgerows and more langhammer et al 2019 similar to analyses on the influences of model parameters the systematic evaluation of the effects of the landscape structure becomes increasingly difficult as the complexity of the landscape increases 4 1 4 implementing stochasticity and boundary conditions ecological and economic dynamics usually involve some stochastic elements often an event occurs with some probability p to decide in a simulation whether the event occurs a random number is drawn from the uniform distribution with the bounds of zero and one and if the number happens to be smaller than p the event occurs otherwise the event does not occur if a random number should be drawn from a probability distribution with more than just two possible outcomes in which each possible outcome k 1 k has a probability pk œÉ kpk 1 the cumulative distribution i e the probability qk of observing some k below or equal to k has to be calculated according to 13 q k k 1 k p k then analogous to the case with only two possible outcomes a random number r is drawn from the interval 0 1 outcome 1 is chosen if and only if r q 1 and outcome k is chosen if and only if pk 1 r pk see e g drechsler 2020 as a final issue in this section we consider the geographical boundary conditions closed boundaries are implemented in a straightforward manner by defining maximum and minimum x and y coordinates for the model landscape x min x max y min and y max and if a coordinate occurs within the model process that exceeds the maximum possible value or undercuts the minimum possible value it is set at that maximum or minimum respectively to consider periodic boundaries coordinates x y outside the ranges x min x max and y min y max must be transformed using the modulo or mod command which is available in all programming environments and delivers the remainder of the division of two integer numbers we transform x into x or y into y via 14 x x x min x x min mod x max x min 1 y y y min y y min mod y max y min 1 for instance in the case of x min 1 and x max 10 a value of x 13 three units above x max is transformed to x 1 12 mod 10 1 2 3 or a value of x 2 three units below x min is transformed to x 1 3 mod 10 1 7 8 4 2 implementation of the model the mathematical formulation of the model developed in the previous section must be implemented as a simulation programme on a computer here we briefly introduce a few popular software tools for this task non spatial models that are mathematically represented by a system of coupled differential or difference equations such as eq 8 can be implemented using the software tools stella wikipedia contributors 2021b https www iseesystems com or vensim wikipedia contributors 2021c https vensim com spatially structured models can be conveniently implemented in netlogo https ccl northwestern edu netlogo which is most suitable not only for the implementation of agent based models but also for grid based models compared with programming languages such as c see below in this section software tools such as the three tools mentioned here usually offer an easier and faster way to implement simulation models this is because various components of computer code are already provided that otherwise would have to be written in house netlogo can support the straightforward construction of graphical user interfaces that include buttons and elements for the specification of parameter values up to a graphical representation of the model world which is presented as an array of grid cells it also provides tools for sensitivity analyses section 5 3 in addition various commands in netlogo are effectively small procedures subprograms called primitives that are composed of several lower level commands for example for making an agent move to the neighbouring grid cell with the highest value of a certain feature the primitive uphill is used this action simplifies the programming work and allows for the implementation of many processes by using tested standardised subprograms netlogo is particularly suited for programming beginners while more experienced programmers will favour their known languages for example c or java being based on a code interpreter instead of a compiler netlogo tends to be slower by nature than compiled languages however important algorithms for example for identifying all other landowners or grid cells with specific attributes within a certain radius are highly optimised so that using c for example does not guarantee by itself that the programme will run faster railsback et al 2017 netlogo still has the disadvantage that it does not provide a convenient debugging capacity in which the programmer can trace through the code step by step and observe the changing quantities of the model variables furthermore it has limitations when simulating large systems with millions of grid cells or hundreds of thousands of agents generic model landscapes are however usually not that large another modelling platform is the r software wikipedia contributors 2021d https www r project org originally developed for statistical analysis it also supports the implementation of causal relationships algorithms like loops and more it is less powerful than c and probably less convenient than netlogo but has the advantage that model results can be analysed in the same programming environment and a vast library of free packages exists for this task while netlogo and r are ideally suited for generic models which are usually not very complex for more realistic and thus complex specific software tools exist for example clue s verburg et al 2002 terrame de senna carneiro et al 2013 or pluc verstegen et al 2012 4 3 plausible ranges for the model parameters the central approach to analysing and understanding the dynamics of a generic model is through a sensitivity analysis in which the model parameters are varied and their effects on the model dynamics and model output are explored section 5 3 the present section addresses the choice of plausible ranges for the model parameters although generic models abstract from the specifics of real systems their structure and parameterisation should reflect to the extent possible what is regarded as typical or possible in these real systems in contrast to specific models generic models are made to generate knowledge about relationships rather than to provide absolute predictions of model variables to provide a trivial example for a specific model of a region in germany land prices would be measured in euros and so would reflect the overall expenses of a conservation payment scheme while in the us they would be measured in us dollars however both systems would behave identically all other factors being equal what would probably influence the dynamics of the systems are qualitative relationships such as the coefficient of spatial variation in the land prices which is the ratio of the standard deviation in land prices and the mean and thus independent of the magnitude of the mean or the rate by which the land prices change over time which again would sensibly be measured in percentages of the current land price rather than the absolute value of the land price again if these relationships are equal or unequal between the two systems the two systems will all other things equal behave equally or unequally the following provides examples of this relative scaling of model parameters as a first example soil productivity generally varies amongst land parcels in a region but usually not by orders of magnitude spatial variation in the soil productivity would be measured relative to some mean which for convenience could be set to one another example is a bounded rational landowner who may fail to identify the profit maximising land use measure every time but the probability of such a failure should generally be much smaller than one some other relationships represent specific assumptions of the conservation problem for instance if the assumed size of a grid cell is on the order of one hectare see below within this section a ground beetle with a movement range of approximately ten metres will not be able to disperse over many grid cells but only to the cell s direct neighbours if the assumed time scale of the model is one year see below within this section for species that have at maximum one generation per year it makes no biological sense to assume that a local population survives only for one year so the extinction probability per model time step would be much smaller than one altogether the chosen spatial and temporal scales i e resolution and extent often provide a good starting point for delineating meaningful parameter ranges in selecting a small conservation budget one would need to consider that a conservation payment must be small compared with the median conservation opportunity cost because a payment equal to the median or larger would imply that provided voluntary participation of landowners half or more of the land parcels grid cells will be conserved contrasting what one would generally associate with a small budget this argument relates to what was indicated at the end of section 2 about pattern orientated modelling one such pattern could be the assumption that the proportion of conserved land parcels is on the order of ten percent since there are usually monotonic relationships between conservation payments and the proportion of conserved land parcels one could choose the payment so that the proportion of conserved land parcels is of the desired order of magnitude in an analysis of cost effectiveness or budget efficiency it is usually practical to choose the conservation budget rather than the payment but since these two are also generally monotonically related the above argument also applies for the appropriate choice of budget similar considerations can be made on the ecological side the conservation status of a species structured as a metapopulation box 3 can be measured quite well by using the proportion of occupied habitat patches conserved land parcels if the focus is on endangered species it is sensible to choose the colonisation and extinction rates so that the resulting proportion of occupied habitat patches is rather small in a static landscape this proportion is quite uniquely determined by the ratio of colonisation and extinction rates box 3 which thus can be chosen so that the proportion of occupied land parcels is rather small together with the above consideration of the local population extinction rates this item determined plausible values for the colonisation and extinction rates in drechsler 2021 of course the mentioned relationships between the budget conservation payment and proportion of conserved land parcels as well as the relationship between colonisation and extinction rates and the proportion of occupied land parcels are not fixed but depend amongst others on the design of the modelled payment scheme and the analysis of different designs was introduced as one of the tasks of many ecological economic model analyses therefore the model parameter values cannot and should not be tied to the patterns with high numerical precision which may be sensible in specific models but ranges in the patterns should be allowed so that the proportion of conserved land parcels or the proportion of occupied habitat patches might range between five and twenty percent for small budgets of course even these bounds should not be understood as crisp but as rough guardrails for the analysis having discussed the specification of ranges for the model parameters we now turn to the spatial and temporal dimensions and resolutions of the model even in a generic model these parameters are not entirely arbitrary for instance one should be clear about whether a grid cell is meant to represent the area occupied by a forest stand zinck and grimm 2009 or a local population of an insect species or even a large mammal on the economic side a grid cell would typically represent a land parcel or agricultural field if the field sizes are assumed to differ one may consider the smallest field although it is not necessary to specify the size of the grid cell in square metres or hectares the cell size should be chosen to be appropriate in both ecological and economic dimensions therefore while it may be sensible to assume that an agricultural field harbours a local insect population it is usually not sensible to assume that it contains a single tree from a forest instead it should represent a forest patch whose ecological dynamics would be simulated by differential equations such as eq 8 or in an individual based manner however even though a close match between ecological and economic scales is desirable one should keep in mind that a generic model is designed to create general knowledge rather than precise numerical predictions the same holds for the temporal resolution of the model in many real systems land use changes in annual steps and at least in regions with seasonality population dynamics follow annual life cycles of species and are often modelled on annual time steps therefore in general it is sensible to assume a match between the clock of land use decisions and changes in population sizes or species occupancies of habitat patches one should note here that generic models have rarely considered individuals e g trees or life stages of species but in case this consideration is advised by the research question there is no reason not to do so next for resolution a decision has to be made about the extent of the model landscape i e the number of grid cells for example if one assumes that a grid cell represents an agricultural field the number of grid cells may simply reflect the typical number of agricultural fields in the considered type of region however for testing purposes especially when developing the model it can be useful to work with smaller systems additionally for the final model checking for possible effects of the system size should be a routine part of a model analysis the appropriate time horizon number of simulation steps largely depends on the research question if one is interested in the steady state behaviour of the model the number of time steps should be chosen so that this steady state is reached cf section 5 2 however if the model should describe the dynamics of a policy with a limited duration such as agri environmental schemes with a duration of five years or if a transient ecological process such as the restoration of degraded habitat is considered one may decide to cover a shorter time horizon of only ten time steps years to simplify and if one is interested only in the difference between system behaviours before and after some intervention the consideration of only two time steps can be sufficient e g pindyck 2002 langpap 2006 drechsler and w√§tzold 2020 in addition to those arguments of plausibility or realism another argument for choosing the size and time horizon of a model is to allow for the detection of interesting patterns such as feedback loops e g between land use and species abundance or spatial aggregations e g of conservation efforts as induced by the agglomeration bonus mentioned in section 2 it makes no sense e g to analyse the spatial aggregation of conservation efforts in a landscape with two by two grid cells detecting these patterns generally requires at least and possibly only as a starting point approximately 10 by 10 or 20 by 20 grid cells but some effects become visible only in large landscapes with 100 by 100 grid cells or more e g drechsler and w√§tzold 2009 bell et al 2016 regarding the term scales in the context of ecological economic modelling it should be noted that it is not necessarily understood in the same way in ecology and economics drechsler et al 2007 the same applies in the context of modelling environmental systems in general while for example in ecology scales refers to temporal and spatial scales in environmental modelling in general in particular for integrated modelling linking different environmental compartments scales also refers to different levels of organization and sometimes even different disciplines iwanaga et al 2021 a concluding note may be added in the context of very large numbers of grid cells computation times may become unacceptably large especially given that for a thorough analysis the model must be simulated many times section 5 therefore in the end the optimal choice of the size of the model region and the number of simulation steps is a compromise between the chance of detecting all relevant patterns in a single model run and the comprehensiveness of the model analysis however run time issues have become less important over approximately the last 10 years because high performance computing clusters are increasingly available and convenient to use 5 model analysis 5 1 simulation experiments 5 1 1 choice of initial conditions to analyse the model its dynamics must be simulated these simulations follow the same rationale as experiments in real systems they start from a specific question the settings are controlled accordingly and only certain inputs are varied and the model output of interest is analysed systematically inputs in model analysis comprise all the model parameters and the initial settings of model entities and their variables a first decision often must be made on the initial conditions i e the initial values of the model variables in a model of a forest ecosystem the development of forest cover depends on the initial level so that high forest cover leads to a fast decline bauch et al 2016 in the analysis of a reef ecosystem thampi et al 2018 whether the model system runs into a state with high or with zero macroalgal cover depends amongst others on the initial amount of macroalgae and corals and grimm and wissel 2004 demonstrated that the initial number of individuals in a population substantially affects the survival probability of the population similar to the values of the model parameters the initial values of the model variables should be plausible and reflect the research question if the question concerns the effect of a biodiversity restoration project one may assume that initially there are only a few conservation efforts being performed in the model region population sizes may not be chosen at mathematically possible maxima but at typical values relative to the carrying capacity however similar to the choice of the model parameter values it is sensible to consider a range of initial conditions and explore their influence on the model behaviour through sensitivity analysis section 5 3 the choice of the initial conditions may not only affect the model dynamics quantitatively e g that a higher initial number of individuals increases the population s survival probability but it can also affect the qualitative behaviour of the model in bulte and horan 2003 the model system has two different steady states and the steady state that is eventually assumed depends on the initial conditions moreover systems may include feedback loops that give rise to oscillations and the occurrence and nature of these oscillations can depend on the initial conditions henderson et al 2016 multiple states or domains with different dynamics model behaviour e g oscillations versus steady state are typical features of complex systems thurner et al 2018 that are characterised by entities interacting with each other in a non linear manner complex systems show behaviour that cannot be predicted from the properties of their components in isolation emergence if the assumed state of a system depends on the initial condition disturbances are able tip the system from one state to another scheffer et al 2001 lenton et al 2008 which raises the issue of the system s resilience holling 1973 walker et al 2004 5 1 2 updating of model variables an often ignored but critical issue is the updating of model variables within processes and between consecutive simulation time steps a central challenge here are the interactions between entities in an agglomeration bonus scheme the payment for a particular land parcel depends on the land use in the neighbouring land parcels thus changing the state land use of a land parcel will affect the way in which the states of the neighbouring land parcels will change simulations use discrete time steps within each time step basically two options for updating the variables exist synchronously and asynchronously for the synchronous type of updating all the new values of the variables that were calculated are stored in auxiliary temporary variables therefore the current state of the system and the new state are clearly separated in the above example the current and new states are not mixed so that the sequence by which the landowners in the example are processed in the simulation does not matter only after the values of all the variables have been calculated are they updated synchronously by contrast with asynchronous updating every variable is updated immediately after it has been calculated landowners might thus have a mix of neighbours in both their current and their new state this updating scheme can lead to priority effects for example if individual based model calculations are sorted by a certain identity number of agents or by any of their variables such as age or wealth they might have initial advantages or disadvantages compared with other agents alternatively if computationally convenient grid cells are always processed row by row priority effects may occur to prevent priority effects the sequence by which entities such as agents or grid cells are simulated can be randomised for each time step 5 1 3 replicating simulations stochastic elements such as randomly changing crop prices or conservation costs or randomly changing weather conditions lead to spatial and temporal variability in model variables a population that is affected by random weather events may go extinct within a few time steps or survive for a long time thus a single model run does not reflect the behaviour of a stochastic model to account for this stochasticity the model must be simulated for a sufficiently large number of times and the model outputs of the various replicates are then evaluated statistically there is no general rule for the choice of an appropriate number of replicates instead it must be identified experimentally for instance one can generate a small number of sets of model replicates if the statistics of the model output cf section 5 2 does not change between these sets then the chosen number of replicates is clearly sufficient to encompass the stochasticity in the model when analysing model output statistically however one should be aware of the risk of p hacking by increasing the number of replicates virtually any result can be made significant significance tests should be avoided when analysing stochastic simulation models white et al 2014 rather one should compare confidence intervals or consider effect sizes eq 17 5 2 recording state variables and calculating quantities for model output 5 2 1 what type of output should we take from the model to answer the research questions formulated prior to the model development section 2 the relevant state variables of the model system must be recorded these variables may include the economic profits of landowners the sizes of local species populations etc in the next step these temporally and spatially varying variables must be aggregated into a few meaningful quantities this aggregation is important because to understand the behaviour of the model we must be able to plot and analyse the relationship between model inputs and model output if the model output has too many dimensions it is difficult to systematically explore model behaviour to give an extreme example it is generally infeasible to create overview plots of a model landscape explicitly depicting the state of each grid cell for several time steps and for many model parameter combinations rather we require metrics ideally single numbers that characterise the system state these numbers are usually summary statistics of the model variables such as the means variations and correlations such aggregate outputs can be thought of as currencies railsback and grimm 2019 because we are using them to evaluate the model behaviour in general finding meaningful output variables is an important element of any type of modelling even for generic models which tend to be of lower complexity a single output variable may not be sufficient to understand how the dynamics and structure of the model systems are emerging moreover when trying to make a model match several patterns observed see sections 2 and 6 we will need a set of output variables to characterise those patterns nevertheless in most cases a small number of output variables say two or three is sufficient next the simulation time steps over which the output variables should be recorded must be decided upon only at the final time step or for a number of final time steps furthermore if a model creates complex dynamics such as multiple steady states or oscillations it can take from a given initial condition a considerable number of simulation time steps until these dynamics can be observed and fully captured in the recording of the evaluation quantities the duration of this type of burn in phase depends on the structure of the model in particular its level of stochasticity and the initial conditions in the analysis of a model this phase can only be determined experimentally by simulating the model and identifying the time from which the model variables or the pattern of their dynamics change only marginally or not at all below we present several examples for aggregate quantities or currencies to characterise the state of the model system 5 2 2 temporal statistics if the variables of interest change over time due to stochasticity in the model feedback loops or other factor they should be summarised into statistics such as temporal averages and standard deviations if the focus is on the system dynamics the variables of interest include i the mean time to change from one system state to another and ii the probability of the system remaining in a particular state goel and richter dyn 1974 in the field of conservation biology the most popular representative of type i is the mean time to population extinction while the most popular representative of type ii is the probability of surviving with a non zero population size a particular time frame grimm and wissel 2004 show that there is a close relationship between the mean time to extinction and the probability of extinction a variant in the probability of survival or its complement the probability of extinction i e zero population size is the quasi extinction risk which measures the risk of falling below a particular threshold within a particular time frame ferson and burgman 1995 by this measure the quasi extinction risk depends on the considered extinction threshold and the time over which population sizes are recorded ferson and burgman 1995 the preferred statistics depend largely on the model dynamics if the population never reaches a size of zero a mean time to extinction or probability of extinction does not make much sense instead one should focus on the quasi extinction risk or the mean time until the population falls below a non zero threshold for the first time alternatively one could choose simpler statistics such as the mean and standard deviation of the population size these measures provide an easy and intuitive representation of an ecological benefit however they are of course not meaningful if the population has a high risk of extinction so the population size will be zero for most of the time over which the model dynamics are simulated in ecological economic models which often have two or more relevant ecological and economic state variables a useful extension of the concept of quasi extinction risk is coviability mouysset et al 2014 based on baumg√§rtner and quaas 2009 coviability is the probability of the system staying in a particular state which may be characterised not only by a single state variable e g the species population size but also by other variables such as economic costs 5 2 3 spatial statistics we have focused on temporal statistics so far however spatial statistics can be of equal importance since the spatial structure of the system as represented by the spatial distribution of model variables usually characterises and affects the dynamics of a system similar to the temporal dimension basic spatial statistics include the mean and the standard deviation of a variable over all the land parcels grid cells in the model region the state of a metapopulation section 4 1 2 may be characterised by the mean size of its local populations alternatively if the model distinguishes only between occupied and empty land parcels it may be measured using the proportion of occupied land parcels in addition to its mean and variation the spatial distribution of a model variable may be of interest particularly the degree of the variable s autocorrelation or spatial clustering consider as an example the case of a binary model variable which can take only the values of one or zero y 0 1 here the degree of spatial clustering on a square grid of n grid cells can be measured quite simply by determining the proportion of grid cells pi within the moore neighbourhood mi of the eight adjacent grid cells which have yj 1 j mi for each grid cell i and taking the average of these pi over all grid cells i with yi 1 drechsler 2021 15 c l u s t y i 1 n y i p i i 1 n y i w i t h p i 1 8 j m i y i in eq 15 clusty can range between p and 1 where p œÉyi n is the proportion of grid cells with y 1 a value of clusty p indicates a random distribution of the grid cells with y 1 so each grid cell has on average of 8p neighbours with x 1 while clusty 1 indicates perfect clustering in which all grid cells with y 1 except for those on the cluster boundary have only neighbours with y 1 note that for eq 15 there are numerous alternative measures to quantify the spatial correlation of variables ripley 2005 wiegand and moloney 2013 5 2 4 quantities for characterising complex dynamics if a model creates complex dynamics such as multiple steady states oscillations or spatial patterns measures are needed to characterise this complex model behaviour while steady states can be characterised by the corresponding levels of the model state variables oscillations can be characterised by their mean level amplitude and frequency the spatial analogue for these quantities would be the lengths of the spatial correlations wiegand and moloney 2013 in addition to the characterisation of complex dynamics one may be interested in the set of conditions ranges of model parameters and initial conditions that lead to a particular type of dynamics e g steady state versus oscillations henderson et al 2016 the delineation between different sets of conditions that lead to different dynamics are often called tipping points because they indicate when the system tips from one type of behaviour to another see the references at the end of section 5 1 1 as well as gerling et al 2019 in addition to the identification of these thresholds one may ask how long it takes until the system returns to a stable state after it has been disturbed which is related to the mean transition times introduced above for the lotka volterra model eq 11 fig 3 shows the times to reach the equilibrium state for an exemplary model parameter combination in which n 1 and n 2 are constant in time as a function of the initial state n 1 t 0 n 2 t 0 these two issues tipping points and return times are central to the concept of resilience folke et al 2004 egli et al 2019 a related concept is emergence which refers to the establishment of complex spatial and temporal patterns for example the spatial distributions of trees in savannas jeltsch et al 1996 the mosaic of forest stands in different successional stages as observed in natural beech forests rademacher et al 2004 the spatial distributions of biomass in a disturbed ecological system van de leemput et al 2015 or the level of cooperation in the management of a common pool resource nhim et al 2019 and the level of cooperation in the management of a common pool resource sometimes complex model dynamics can be analysed by scaling them up wu and david 2002 to a markov process a markov process e g goel and richter dyn 1974 grimm and wissel 2004 is a process without memory so the change in the system is determined by its current state only memory effects can however be represented in the state variables used to characterise the model s entities markov processes are represented by a set of equations or rules that give the probabilities pr s s of transitioning into another state s for each system state s the states are characterised by the values of a few aggregate state variables such as those introduced in the previous sections during the simulation of the model the frequency at which this characteristic is assumed is recorded for each state and from a given state how often the system transitions into any of the other states the full model dynamics can then be summarised into a matrix of transition probabilities called the markov matrix while the provision of further details would be beyond the scope of this primer two applications of the described upscaling may be mentioned touza et al 2013 used the approach to detect different modes of cooperative behaviour in forest owners in which cooperation was defined by the benefit accruing from one s own actions to the neighbouring forest owners only two modes of behaviour exist the level of cooperation is either proportional or inversely proportional to the level of culling intensity and determining which mode dominates depends on the preferences trophy hunting vs biodiversity conservation of the forest owners drechsler 2020 ch 17 used the approach to detect a spatiotemporal feedback loop in the land use dynamics induced by an output based payment which rewards the presence of a species on the land rather than a conservation measure the aggregate state variables comprised the proportion and spatial clustering eq 15 of the conserved land parcels and the land parcels occupied by the species 5 2 5 policy performance criteria and optimisation as noted above an important application of ecological economic modelling is the design and assessment of biodiversity conservation instruments a central matter of interest here are policy performance criteria one of these criteria is effectiveness i e the ability of a policy to achieve a given ecological objective this type of objective may be the survival of one or several interacting species see the research topic policies and strategies for the conservation of metacommunities in frontiers in ecology and evolution or a given level of resilience of the system to disturbances bauch et al 2016 bieg et al 2017 dressler et al 2019 if financial resources are limited cost effectiveness is of equal importance i e the ability of a policy instrument to achieve given ecological objectives at the lowest costs or equivalently to maximise ecological objectives for given costs w√§tzold and schwerdtner 2005 last the model output and the conclusions that are drawn are likely to depend on the values of the model parameters see section 5 3 another performance criterion of a policy is its robustness regarding uncertainty in these model parameters see section 5 3 5 here the way in which a policy performs if parameter values deviate from best guessed values is analysed and the most robust policy is the one whose worst performance over all the alternative parameter values is best amongst all the compared policies ben haim 2001 often the task is to maximise a policy performance criterion which requires numerical optimisation the simplest method for this purpose is to vary the policy parameters such as the level of the agglomeration bonus in drechsler 2021 or the level of decentralisation in bareille and zavalloni 2020 within their plausible ranges simulate the model dynamics and identify the values that maximise the policy criterion cost effectiveness in drechsler 2021 and economic welfare in bareille and zavalloni 2020 however this method is rather slow and may lead to unacceptable computation times in these cases more efficient optimisation routines must be used many textbooks on numerical optimisation are available such as nocedal and wright 2006 and talbi 2009 and the libraries of some software packages such as gams wikipedia contributors 2021e https www gams com or r see reference in section 4 2 include optimisation routines the netlogo installation see reference in section 4 2 includes the programme behaviorsearch stonedahl and wilensky 2010 which provides a collection of optimisation algorithms for netlogo programmes covering the issue of optimisation in more detail would clearly be beyond the scope of this article 5 3 sensitivity and statistical analyses to explore model behaviour 5 3 1 sensitivity experiments and local sensitivity analysis to explore and understand the behaviour of the model and the modelled system the assumptions behind the model and the values of the model parameters are varied and the response of the model output section 5 2 is recorded and related to the variations in the model parameters this type of model exploration is known as a sensitivity analysis saltelli et al 2009 the simplest and most popular type of sensitivity analysis are sensitivity experiments railsback and grimm 2019 in which each model parameter a is varied in turn from some baseline value a base within its plausible range and changes in the model output variable y are recorded all the other parameters are fixed at their baseline values the results of these experiments are usually depicted in plots of one or more output variables versus the varied parameter a special case of an entire set of sensitivity experiments is a local sensitivity analysis in which the model parameters are varied only by very small magnitudes such as ten percent from the baseline value again only one parameter is varied at a time therefore these analyses are also referred to as one at a time analyses oat dividing the change in the output variable by the change in the model parameter yields a sensitivity coefficient here one can consider the deviations in absolute or relative fashions relative to the baseline values a baseline and y a baseline 16a s abs y varied y baseline a varied a baseline 16b s rel y varied y baseline y baseline a varied a baseline a baseline 1 mathematically this analysis resembles the derivative dy da of y with respect to a at point a a baseline eq 16a and the derivative of the logarithms dlny dlna at point a a baseline eq 16b these sensitivity coefficients show the main effects of the model parameters their rank order indicates which parameter and hence the process it controls has the strongest effect on the output variable while straightforward to perform and easy to interpret oat analyses have three limitations the results might differ when starting from different base parameter values interactions between parameters such that the sensitivity of one parameter depends on the level of another parameter are not captured and non linear effects are not captured to detect nonlinearities the sensitivity coefficient must be calculated for several values of a to capture the interactions between parameters and their processes two parameters can be varied systematically at the same time i e both vary over their ranges with a sufficiently high resolution for example over ten values plotting the output variable as a function of the two model parameters with the two parameters measured on the two axes yields a contour plot or heat map which helps us to understand the interaction between these two parameters an example of this type of plot is shown in fig 3 it is important to consider these analyses or even more complex analyses as described in the following section not just as technical exercises but as the means for 1 gaining an understanding of the sensitivity of parameters and their processes and 2 developing possible explanations for these sensitivities subsequently these explanations can often be tested using additional simulation experiments that are targeted at dominant processes in a complex model with many parameters identifying all these two way interactions or three way or higher order interactions may be infeasible instead one would usually analyse only the interactions of the parameters with the largest primary effects as determined above 5 3 2 global sensitivity analysis in global sensitivity analyses all the model parameters can take any value within their respective ranges so that the entire parameter space is covered saltelli et al 2009 thiele et al 2014 several approaches are available to choose parameter values during a global sensitivity analysis a basic approach is to cover the parameter space completely either i by defining for each parameter i i 1 i a number ni of possible equidistant values and building all œÄ ini ni if n 1 n 2 ni n parameter combinations or ii by forming a desired number of parameter combinations by randomly drawing each model parameter from its range an advantage of variant i is that some software tools for drawing multidimensional plots of model output as a function of model parameters require systematic coverage of the parameter space as inputs an advantage of variant ii is that the model output can be related to the model parameters through statistical methods see section 5 3 3 a more efficient systematic coverage of the parameter space can be achieved through subsampling the most common approach here is latin hypercube sampling e g thiele et al 2014 in which the ranges of all the model parameters are split into small intervals and the parameter combinations are sampled so that each of these intervals is occupied only once for a two dimensional parameter space equivalent to the task of positioning several rooks on a chess board so that they cannot threaten each other now the challenge is to analyse the data jumble that comes out of these procedures a simple first step can be to calculate the correlations between a model output variable and each model parameter a large positive negative correlation indicates that an increase in the model parameter significantly increases decreases the model output variable similar to a simulation experiment this action identifies the main effects more demanding are the variance partitioning methods such as the sobol method in saltelli et al 2009 which explores how much the variation in parameters both by themselves and in interaction with others explains the variation in the model output for complex models the resulting statistical model is often used as a meta or surrogate model that is used for further model analysis and application pietzsch et al 2020 a simpler alternative to the mentioned variance partitioning methods which only consider the primary effects is the analysis of variance anova anova is available through practically any statistics package and spreadsheet software and rather easy to apply drechsler 2021 used it to determine how much of the variance in the model output is due to a set of parameters describing the decision making of landowners relative to the variance that is caused by other model parameters such as the spatial variation in conservation costs usually generic models have a relatively small number of parameters for models with many parameters these global analyses cannot be performed for all the model parameters because the results would be virtually impossible to interpret therefore first so called morris screening can be performed which ranks all the parameters by their global importance global methods such as the sobol are then performed only for the about five most important parameters see for example ayll√≥n et al 2016 software platforms devoted to data science and statistical analyses such as r see reference in section 4 2 or python wikipedia contributors 2021f https www python org provide packages for running and analysing all the common methods of sensitivity analysis global sensitivity analysis is increasingly used because of these packages and the increasing popularity of r and other statistical software however it is important like with any method provided by some packages to ensure that these packages are driven by questions and that their output is interpreted in terms of these questions simply presenting the plots produced by the sobol method is not sufficient the relevant result is the interpretation of these plots sometimes a simple interpretation is possible but very often this is not the case because the model shows different behaviours in different parts of its parameter space this is however not necessarily a bad thing because not all the parts of the parameter space are always relevant to the research question thus a global sensitivity analysis should be performed with a sense of proportion 5 3 3 statistical methods for model output analyses as mentioned in section 5 1 3 for stochastic models it can be adequate to support observations of parameter influences on model output through statistical analyses a typical question here is whether a change in a model parameter from some value a baseline to another value a varied has a relevant effect on some model output y for this determination the model is analysed many times to obtain replicates of the model variable y for both parameter values a baseline and a varied an effect size t is calculated as 17 t e y a varied y a baseline s d y a varied s d y a baseline where e y a varied y a baseline is the expected value of the difference in y caused by varying a over the replicates and sd y a varied and sd y a baseline are the standard deviations of y for the two levels of a cohen 1988 here t relates the difference between the means to the variation standard deviations in the model output the effect size is independent of the number of replicates to obtain the t statistic for a t test one would divide the t in eq 17 by the square root of the number of replicates which avoids the risk of p hacking mentioned in section 5 1 3 statistical methods also support the investigation of dichotomic research questions such as is conservation scheme a more cost effective than another conservation scheme b or does the increase in parameter x increase or decrease the cost effectiveness of scheme a compared with scheme b related to this are questions such as which model parameter combinations are associated with a particular type of model outputs as examples p√©rez and janssen 2015 determined via a t test whether the level of cooperation amongst resource users differed between different assumptions regarding the amount and spatial distribution of the resource and drechsler and w√§tzold 2020 identified model parameter combinations in which the lock in and path dependence of biodiversity conservation measures are particularly relevant while drechsler 2021 analysed many random model parameter combinations and identified those in which bounded rational landowner behaviour has a large effect on the performance of a conservation scheme to analyse the output of a global sensitivity analysis multivariate analyses such as ordination and classification have proven useful these methods basically sort objects such as model parameter combinations into groups that are similar with respect to some characteristic such as a model output describing these methods in detail would be far beyond the scope of this article so we refer to textbooks such as pielou 1984 and johnson and wichern 2013 two examples may demonstrate the potential of such methods the ordination by drechsler 1998 arranged nine parameters of a population dynamical model into three groups so that the parameters in each group had a qualitatively very similar influence on the rank order of four conservation measures surun and drechsler 2018 arranged 10 000 model parameter combinations each representing the combination of two species traits of two competing species into five groups so that the species trait combinations in each group responded similarly to the choice of two conservation scheme design parameters this reduction in the model parameter space substantially simplified the analysis of how the coexistence of the two competing species depends on the scheme design similar tasks can be performed using regression trees breiman et al 2017 which split the parameter space by identifying bounds on specific model parameters that lead to similar levels of a model output variable polhill et al 2013 used the method to explore the effects of model parameters including policy design parameters on the species richness in a fictitious model region 5 3 4 robustness analysis to address uncertainty in the model structure while sensitivity analyses focus on parameters a robustness analysis ra also includes the model structure and the choice of submodels describing specific processes the primary motivation for performing an ra is that model development is path dependant depending on the specific formulation of the research question the data and expert knowledge used and the output metrics applied model development can take different paths because each step on this path constrains the available design choices for the next step as a result models of even the same system and similar questions often differ greatly the aim of an ra is thus weisberg 2012 after wimsatt 1981 to separate the scientifically important parts and predictions of our models from the illusory ones which are accidents of representations the basic idea of the ra is to try to break a model i e to see when the model ceases to explain certain phenomena grimm and berger 2016 suggested augmenting the current culture of communicating models as working just fine with a culture of presenting analyses in which we try to break models i e model mechanisms explaining certain observations break down they defined ra as the systematic deconstruction of a model by forcefully changing the model parameters structure and representation of processes ra thus helps to tell the features of a model that are essential for the answers provided by the model from the path dependant accidents of representation in practice an ra comprises heuristics such as turning certain processes off how much do they matter or making the model world simpler or more complex for example by contrasting simple and complex process representations or by contrasting homogeneous and heterogeneous environments an ra and its elements are helpful for understanding how model results are emerging this understanding is essential for a model to be useful because blind trust in model output is unacceptable grimm and berger 2016 provide an overall scheme and examples of ra ra is particularly important for complex models but even in the usually simpler generic models assuming different functional relationships in the submodels can have strong effects 6 good modelling practice the ecological economic models considered in this primer are about instruments and policies that affect the real world ultimately the hope is that lessons learned from the model will support the development and implementation of the best e g in terms of cost effectiveness biodiversity conservation instruments this approach requires that both the model and its analysis are transparent and replicable so that the model and its results are credible since the iterative process of model development comprises several steps question formulation conceptual model development implementation testing analysis and application good modelling practice must cover all of these steps one way to document that good practice was followed throughout and that all aspects are transparent and replicable is by using the trace transparent and comprehensive ecological modelling documentation framework schmolke et al 2010 grimm et al 2014 trace documents trace all relevant aspects of model development they provide a standard template with sections corresponding to all steps of model development ideally modellers keep a notebook during model development in which they concisely document their activities daily by using the terminology of trace to tag their notebook entries these modelling notebooks ayll√≥n et al 2021 can then be used to compile trace documents that are attached as supplements to articles or reports by using trace to document the iterative development testing and application of a model modellers know where to put what type of information including the model description data and output files etc and when model users have specific questions they know exactly where in the trace document to look for this information keeping modelling notebooks based on trace terminology considerably adds transparency and credibility to models and their results but also has direct benefits to modellers because these notebooks force us to explicitly reflect upon what we planned and have achieved and trace provides a checklist of all the important aspects of model development analysis and use the credibility of models is important given their aim of supporting the development of conservation policies one key aspect of credibility is how well the model represents the real system potential model users often require that a model is making correct predictions before they are willing to consider its results however testing model predictions is usually not possible with social ecological systems because we cannot perform controlled experiments moreover models cannot in principle predict the future because there are always drivers for example climate politics or epidemics that cannot be predicted it is therefore important to distinguish three primary purposes of models grimm et al 2020 demonstrating a specific concept understanding the mechanisms underlying a certain phenomenon and prediction the prediction function usually must be confined to specific situations short time horizons and different scenarios regarding the drivers the generic models described here are meant for demonstration and understanding and therefore not for making specific predictions nevertheless there must be some generic features reproduced by generic models that still allow us to use the lessons learned in the real world the most widely used feature is that the modelled system exists often in some sort of equilibrium possibly including some variation or oscillations around some mean in addition the behaviour of the model especially for extreme values of the model parameters should at least to some extent and with respect to the important features be explicable by arguments of plausibility and logic for example an increase in the conservation payment or budget should unless there are good counterarguments such as threshold effects increase the number of conserved land parcels in a region or an increase in the number of habitats should again unless there are good counterarguments such as threshold effects increase the viability of the species in the region an agglomeration bonus should generally lead to more spatial aggregation of conservation efforts which according to the metapopulation theory outlined in box 3 should generally increase the viability of the species in that way a generic model may generate a set of trivial predictions or weak patterns that are straightforward to reproduce however reproducing a set of largely independent patterns is non trivial because it requires a specific level of complexity and realism which is the primary idea of pattern orientated modelling see section 2 notably the trivial predictions from plausibility tests often consider extreme or simplified scenarios there can always be factors that were not considered within the generic model that would lead to different results for example while it is plausible to observe a beneficial effect of the agglomeration bonus on a single dispersal limited species the presence of a predator that also benefits from habitat agglomeration and places predation pressure on the species may of course reverse the original outcome thus if predation is a concern within the scope of the research question the predator and its population dynamics should be explicitly included in the model unfortunately generic models and their results are often presented without referring to their primary purpose and their level or realism which has led to cases in which their results were viewed as predictions and used for making decisions affecting the real world for instance the famous hare lynx cycle in canada has long been regarded as a prime application of the generic 2 species models of lotka 1920 and volterra 1931 similar to the model of eq 11 above until recently empirical research and improved specific models have shown that other factors such as climatic factors and self regulation in the populations are of the same or probably even of much higher importance zhang et al 2007 yan et al 2013 7 interpretation and discussion of model results to answer the research questions having descended in section 3 from the real world into the world of mathematics or depending on one s personal taste ascended into it we must now return by interpreting and translating the results of the model analysis particularly the sensitivity analyses into a narrative by using ordinary language of course the details of this process depend on the research question s in a first step one could consider the primary effects identified in the sensitivity analysis which in the example of drechsler 2021 revealed that the influence of two out of four parameters of landowner behaviour were rather small compared with that of other ecological and economic model parameters while the influence of the other two behavioural parameters was moderate similarly or next one could present interaction effects as in w√§tzold and drechsler 2005 in which spatially differentiated conservation payments turned out to be more cost effective than homogeneous payments especially if conservation efforts in the subregion with the higher marginal conservation cost also generated a higher marginal ecological benefit in this manner the most important results of the sensitivity analyses are presented in which it is advisable to start with the simple results such as the primary effects and end with the more complex results after or depending on personal taste parallel to the presentation of these results plausible explanations of the results should ideally follow recalling that the purpose of generic modelling is understanding making explanations and arguments of plausibility form a central part in the discussion of the results of generic model analyses these explanations have their roots in the results of the sensitivity analyses described in section 5 3 underlining the value of this sometimes tedious but important part of modelling often our explanations are hypotheses that can be tested by performing additional simulation experiments more generally a model can often not be fully understood in a single viewing instead with rather little preliminary understanding of the model one usually starts with a rather broad and shallow sensitivity analysis that focuses on the primary effects the understanding gained by this viewing as well as any remaining gaps stimulates a more informed analysis which continues until a satisfactory understanding of the model is achieved this approach somewhat relates to the modelling cycle described by grimm and railsback 2005 of course one should be aware that complete understanding is only an ideal that can be achieved if at all only at high costs in terms of work time so it is up to the researcher to find a reasonable compromise in any case at least the primary effects regarding the original research question should be understood and their reasons explained because otherwise the model would not be very useful given that for policy support it is usually not the model itself but the drawn narratives that are decisive this characterisation replicates the conclusion of section 6 in which modelling requires not only computational but also intellectual efforts next it is important to highlight the limitations of the analysis this consideration is particularly relevant regarding the basic assumptions underlying the model one reason for assumptions that purposely ignore aspects of the analysed system may be that their inclusion would produce foreseeable straightforward results and thus would complicate the model without any major gains in terms of understanding an example is the neglect of transaction costs here the costs of setting up and running a policy in the study by w√§tzold and drechsler 2005 these costs were ignored or assumed to be zero since they are always higher in spatially differentiated than in homogenous conservation payments armsworth et al 2012 including them would have led to the straightforward result that an increase decrease in transaction costs makes spatially differentiated payments less more cost effective in comparison to spatially homogeneous payments hence including transaction costs would have made the model more complex and the modelling more tedious without generating any insights however when drawing policy relevant conclusions from the model it is useful to remind the reader and oneself about this limiting assumption because the resulting policy recommendations may otherwise be biased another reason for simplifying assumptions may be that their inclusion would make the model overly complex or they are simply not deemed relevant at the time of modelling unlike in the abovementioned case of transaction costs it may not be straightforward to understand how the inclusion of these aspects may change the model results this aspect should be acknowledged in the discussion of the model limitations and one may suggest further research to investigate this previously ignored consideration an example of such a case in which a previously ignored aspect was later included in a model is vortkamp et al 2020 who extended a model by barraquand and martinet 2011 to include allee effects i e the increase in the population growth rate with an increasing population size which can be observed at low densities and is often due to the effects of the mating behaviour which requires specific minimum densities the authors found that including allee effects substantially alters the performance ranking of conservation policies last one should bear in mind that the results of the model are only valid within the considered parameter range although parameter values should have been selected in a way that they represent rather general situations it cannot be excluded that parameter values outside the considered ranges but still relevant for real conservation problems may lead to qualitatively different results an appropriate way of addressing these unavoidable limitations of generic models is to formulate policy recommendations with caution bearing in mind that the model may miss aspects that may change the conclusions drawn from its analysis thus if policy recommendations are derived from a model analysis it is advisable to formulate these recommendations in a careful manner using wordings such as the model results indicate the model results suggest or within the considered parameter range we find that or similar this advice however should in no way diminish the power of generic models which lies in the generation of understanding and the factors that are likely to be important in the design of biodiversity conservation policies 8 conclusion ecological economic modelling is a very useful approach for the integration of ecological and economic knowledge we focus on generic ecological economic models that are rather abstract and aim at the general understanding of mechanisms that drive the interaction of ecological and economic factors as compared to specific models that are usually more detailed and focus on real systems we limit ourselves here to generic models because on the one hand these are associated with particular challenges such as the abstract and generic formulation of processes and their interaction as well as systematic model analysis to develop general understanding and on the other hand a primer for generic ecological economic modelling does not yet exist like textbooks this guide is unlikely to be read from cover to cover rather beginners in ecological economic modelling will benefit from the introductory sections in particular the parts on concepts and formulating the research question then while iteratively going through the different steps of model development implementation testing analysis and use readers will find guidance for the corresponding steps the culture of modelling differs widely between disciplines and between ecological and economic modelling drechsler et al 2007 mathematical models based on calculus which have been so successful in physics have been and are still used in ecology and economics but in ecology these models now more or less peacefully coexist with simulation approaches such as agent based or grid based models economic theory is still dominated by mathematical formulations but simulations also seem to be gaining ground we therefore presented guidance for the entire modelling cycle to help establish a consistent and coherent culture for ecological economic modelling while the cultures may differ the basic challenges and steps of modelling are independent of specific disciplines for beginners in ecological economic modelling it can be helpful not to necessarily start developing a model from scratch but to re implement and then develop an existing model this approach can be used to practice the various steps of modelling but it can also help the novice to enter a productive modelling cycle faster and more efficiently and it can improve theory development in general thiele and grimm 2015 our guide will also facilitate understanding of the existing models which is a prerequisite for advancing the field only if we fully understand a model and its rationale will we able to critically evaluate both and where appropriate improve and extend them the existing disciplinary guides and textbooks are still needed and useful for ecological economic modellers but they do not prepare users well for interdisciplinary modelling we hope that our guide helps to close this gap declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements we would like to thank two reviewers for their insightful comments and suggestions supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2021 109861 appendix supplementary materials image application 1 
24497,this article describes a coupled physical biological model for reproducing the ecological processes in a freshwater lake during the evolution of the thermal bar a phenomenon of sinking of maximum density waters in a narrow zone the biological part of the model includes 10 prognostic variables nitrate phosphate ammonium chlorophyll a phytoplankton zooplankton and nitrate and phosphate detritus of small and large sizes the results of modeling of hydrodynamic processes in barguzin bay of lake baikal using meteorological data for june 2019 demonstrate a short term period of the thermal bar existence the analysis of spatial distributions of biochemical variables of the model showed that the thermal bar acts as a natural barrier limiting the transfer of phosphates and plankton to the open lake keywords thermal bar lake ecosystem numerical modeling phosphorus limitation freshwater lake 1 introduction in recent decades anthropogenic activities have led to a noticeable worsening of ecological conditions in large freshwater lakes on our planet among the key sources of pollution and eutrophication of bodies of water are untreated sewage from industrial centers clustered at the waterfronts and or in lake catchment basins petroleum products from water vehicles emissions from fuel combustion and agricultural fertilizer manure etc and domestic waste in particular the lake baikal littoral zone has been witnessing active growth of the spirogyra alga volkova et al 2018 timoshkin et al 2019 lately which is connected to urban sewage and industrial wastewater rich in nitrogen and phosphorus the thermal bar is one of the natural phenomena promoting the accumulation of plankton and other microorganisms in the littoral area of a lake it is formed in dimictic lakes in spring and autumn and is a narrow zone of water sinking around the area of temperature of maximum density farrow 1995 holland and kay 2003 chubarenko and demchenko 2008 the role of the thermal bar for the ecological functioning of a lake is versatile it divides the lake into thermoactive near the shore and thermoinert open part of a lake regions tikhomirov 1982 and acts as a barrier limiting the spread of coastal waters with high concentrations of pollutants and biota in the central lake at the same time vertical flows forming in the location of the thermal bar may promote transport of suspended matter in the deep water part of a lake shimaraev et al 1995 tsydenov et al 2015 tsydenov 2020a the understanding of particular aspects of the thermal bar influence on hydrobiological processes is important for the purposes of predicting and monitoring of the ecological status of a freshwater lake taking timely measures for emergency damage control in anthropogenic and natural disasters field studies note organic matter and nutrients are distributed very unevenly in lake baikal tarasova 1975 goldman et al 1996 moreover the qualitative and quantitative variability of phytoplankton in lake baikal has not only a seasonal but also an annual nature the spring development of lake baikal phytoplankton explicitly differs from year to year evstafyev and bondarenko 2007 there is a tenfold difference in phytoplankton biomass between a high production year melosira year and a low production year bondarenko and evstafyev 2002 satoh et al 2006 also nitrate depletion and phytoplankton biomass may change significantly over a 2 week period during the initiation of thermal stratification goldman et al 1996 as an example water sampling in barguzin bay in summer 2002 showed that the concentrations of nitrogen nutrients were 1 0 Œºmol n l 1 in the epilimnion katano et al 2008 the concentrations of chlorophyll a were 0 5 Œºg l 1 below 30 m satoh et al 2006 and the concentrations of soluble reactive phosphorus were 0 05 Œºmol l 1 except for 0 2 Œºmol l 1 at the station nearest to the barguzin river satoh et al 2006 the most important biochemical elements of the lacustrine ecosystem are phosphorus and nitrogen since one of these elements is a limiting factor for biomass growth in a lake concentration levels of phosphorus in a freshwater lake are crucial to predicting the bursts of phytoplankton bloom thus there is a challenging issue for the up to date stage of development of mathematical methods in limnology to create integrative numerical models aimed at reproduction of biochemical processes of phosphorus and nitrogen limitation in the lake ecosystem during the thermal bar evolution despite the long history of studies devoted to primary production in lake baikal the question of limiting factors for its biomass development is still open for example some researchers weiss et al 1991 watanabe and drucker 1999 suppose that the phytoplankton productivity in lake baikal is limited by nitrogen however at the same time goldman at al 1996 note that in summer the significance of both phosphorus and nitrogen limitation becomes more evident nutrient enrichment experiments in barguzin bay in late august 2002 showed that the first limiting nutrient is thought to be phosphorus but once phosphorus is supplied to the surface water the limiting nutrient will quickly shift from phosphorus to nitrogen satoh et al 2006 obviously it is important to consider the presence of not only nitrogen in a water environment while modeling biochemical processes in freshwater ecosystems phosphorus should also be taken into account since phosphate groups are basic structural elements of nucleic acids in plant cells and they take part in energy metabolism studies aimed at understanding the effect of a thermal bar on plankton dynamics were carried out using nitrogen based biological models botte and kay 2000 holland et al 2003 tsydenov 2019b the objective of this study is to reproduce the biogeochemical processes during the spring thermal bar evolution in barguzin bay of lake baikal by means of the coupled physical biological model that considers as a limiting nutrient not only nitrogen but also phosphorous 2 model description the coupled physical biological model was developed on the basis of a 2 5d physical model that uses approximations which transform the problem into 2d vertical cross section of a lake but take into account all three components of the velocity vector to include the coriolis force related to the earth s rotation tsydenov et al 2016 the biological part of the model contains ten prognostic variables nitrate phosphate ammonium chlorophyll a phytoplankton zooplankton small nitrate detritus large nitrate detritus small phosphate detritus and large phosphate detritus the geographic domain of the coupled model is a vertical cross section of barguzin bay of lake baikal the origin of the system of coordinates coincides with the mouth of the barguzin river 53 25 30 n and 108 59 50 e fig 1 –∞ the calculation domain having a simplified geometry with a length of 20 km and a depth of 100 m fig 1b is based on bathymetric data from ueno et al 2005 and covered by a uniform orthogonal grid with steps hx 25 m and hz 2 5 m 2 1 physical model the 2 5d hydrostatic model for the reproduction of hydrodynamic processes in a lake expressed in the boussinesq approximation is comprised of the following equations –∞ momentum equations 1 u t u 2 x u w z 1 œÅ 0 p x x k x u x z k z u z 2 œâ z v 2 œâ y w 2 v t u v x w v z x k x v x z k z v z 2 œâ x w 2 œâ z u 3 w t u w x w 2 z 1 œÅ 0 p z x k x w x z k z w z g œÅ œÅ 0 2 œâ y u 2 œâ x v b continuity equation 4 u x w z 0 c energy equation 5 t t u t x w t z x d x t x z d z t z 1 œÅ 0 c p h s o l z d equations of salinity balance 6 s t u s x w s z x d x s x z d z s z where u v are the horizontal velocity components along ox and oy axes respectively w is the vertical velocity component œâx œây and œâz are the vector components of the earth s rotation angular velocity g is the acceleration of gravity cp is the specific heat capacity t is the temperature s is the salinity p is the pressure œÅ0 is the water density at standard atmospheric pressure and temperature tl and salinity sl are a reference temperature and salinity of the lake respectively the chen millero equation 1986 which is widely used in freshwater lakes flood et al 2021 de carvalho bueno et al 2021 wu et al 2020 to connect water density with temperature salinity and pressure and is valid within the range of 0 t 30 c 0 s 0 6 g kg 0 p 180 bar was taken as the state equation œÅ s t p œÅ 0 1 p k s t p where œÅ 0 999 8395 6 7914 10 2 t 9 0894 10 3 t 2 1 0171 10 4 t 3 1 2846 10 6 t 4 1 1592 10 8 t 5 5 0125 10 11 t 6 0 8181 3 85 10 3 t 4 96 10 5 t 2 s and k s t p 19625 17 148 113 t 2 293 t 2 1 256 10 2 t 3 4 18 10 5 t 4 3 2726 2 147 10 4 t 1 128 10 4 t 2 p 53 238 0 313 t 5 728 10 3 p s many important thermodynamic parameters for example temperature of maximum density and thermal expansibility calculated from this equation of state are presented in chen and millero 1986 in their easy to use form for application in physical limnology 2 2 biological model the biological model is based on nitrogen based ecosystem models of fasham et al 1990 fennel et al 2006 and hofmann et al 2008 and includes seven state variables nitrate eq 7 ammonium eq 8 chlorophyll a eq 10 phytoplankton eq 11 zooplankton eq 12 and small eq 13 and large eq 14 nitrate detritus to describe the phosphorus limitation in the freshwater lake three additional variables phosphate eq 9 and small eq 15 and large eq 16 phosphate detritus are introduced into the model according to gan et al s formulation gan et al 2014 a biological model schematic that demonstrates the relationship between the ecosystem components is presented in fig 2 in the model the phytoplankton growth rate is defined by the nitrogen and phosphorus modules in accordance with their respective roles in limitation of primary production as an indicator of nutrient limitation the molar ratio of dissolved inorganic nitrogen n and dissolved inorganic phosphate p concentrations n p ratio is often used according to redfield 1958 a n p ratio 16 1 corresponds to n limitation and a n p ratio 16 1 corresponds to p limitation biochemical processes in the model are described by the following reaction convection diffusion equations n t u n x w n z x d x n x z d z n z 7 Œº max f i p h y t o œÉ n n k n n 1 1 a k a œÉ p n n a p k p p n a a t u a x w a z x d x a x z d z a z Œº max f i p h y t o œÉ n a k a a œÉ p a n a p k p p 8 n a l b m z o o l e p h y t o 2 k p h y t o p h y t o 2 Œ≤ z o o r s d n s d n r l d n l d n p t u p x w p z x d x p x z d z p z Œº max f i p h y t o œÉ n n k n n 1 1 a k a a k n a r p n œÉ p p k p p r p n 9 l b m r p n z o o l e r p n p h y t o 2 k p h y t o p h y t o 2 Œ≤ z o o r s d p s d p r l d p l d p c h l t u c h l x w c h l z x d x c h l x z d z c h l z œÅ c h l Œº c h l m p h y t o c h l 10 œÑ s d n p h y t o c h l g max p h y t o 2 k p h y t o p h y t o 2 z o o c h l p h y t o p h y t o t u p h y t o x w p h y t o z x d x p h y t o x z d z p h y t o z Œº p h y t o m p h y t o p h y t o 11 œÑ s d n p h y t o p h y t o g max p h y t o 2 k p h y t o p h y t o 2 z o o z o o t u z o o x w z o o z x d x z o o x z d z z o o z g max p h y t o 2 k p h y t o p h y t o 2 Œ≤ z o o l b m z o o 12 l e p h y t o 2 k p h y t o p h y t o 2 Œ≤ z o o m z o o z o o 2 s d n t u s d n x w s d n z x d x s d n x z d z s d n z g max p h y t o 2 k p h y t o p h y t o 2 1 Œ≤ z o o 13 m z o o z o o 2 m p h y t o p h y t o œÑ s d n p h y t o s d n r s d n s d n 14 l d n t u l d n x w l d n z x d x l d n x z d z l d n z œÑ s d n p h y t o 2 r l d n l d n s d p t u s d p x w s d p z x d x s d p x z d z s d p z g max p h y t o 2 k p h y t o p h y t o 2 r p n 1 Œ≤ z o o 15 m z o o r p n z o o 2 m p h y t o r p n p h y t o œÑ s d n p h y t o s d p r s d p s d p l d p t u l d p x w l d p z x d x l d p x z d z l d p z 16 œÑ s d n p h y t o s d p r p n p h y t o r l d p l d p where n a p chl phyto and zoo are the concentrations of nitrates no3 ammonium nh4 phosphate po4 chlorophyll a phytoplankton and zooplankton respectively sdn and sdp are the concentrations of small detritus for no3 and po4 respectively ldn and ldp are the concentrations of large detritus for no3 and po4 respectively small detrital particles smaller than 10 ¬µm and phytoplankton are assumed to aggregate and form larger detrital particles fennel et al 2006 gan et al 2014 a two parameter k œâ model of turbulence developed by wilcox 1988 and consisting of equations for kinetic energy and turbulent fluctuation frequency to find vertical eddy diffusivity is used to close the set of eqs 1 16 the horizontal diffusion coefficients are assumed to be constant as kx dx 2 5 m2 s the phytoplankton growth rate is determined as 17 Œº Œº max f i œÉ n n k n n 1 1 a k a a k a a œÉ p p k p p where ¬µmax is the maximum growth rate of phytoplankton eppley 1972 18 Œº max t Œº 0 1 066 t the coefficients œÉn and œÉp are responsible for the limitation of lake productivity through major biogenic elements if n k n n 1 1 a k a a k a a p k p p then œÉn 0 and œÉp 1 p limitation otherwise œÉn 1 and œÉp 0 n limitation the function f i represents the photosynthesis light relationship evans and parslow 1985 19 f i Œ± i Œº max 2 Œ± 2 i 2 20 i i s p a r exp d k w a t e r k c h l d l z c h l z d z where is is the incoming light just below the lake surface par is the fraction of light that is available for photosynthesis par 0 43 fennel et al 2006 in the model is is the shortwave radiation flux calculated according to the formula 8 from b o tsydenov and starchenko 2015 the fraction of phytoplankton growth that devoted to chlorophyll synthesis is defined as 21 œÅ c h l Œ∏ max Œº p h y t o Œ± i c h l because the amount of chlorophyll is associated with intracellular pigmentation arising from light driven photoacclimation and nutrient driven physiological responses behrenfeld et al 2016 liu et al 2019 the relationship between concentrations of phytoplankton and chlorophyll is nonlinear the model takes into account the effects of photoacclimation on the basis of the model of geider et al 1996 1997 the chlorophyll content is derived from the phytoplankton equation by multiplication with the ratio of chlorophyll to phytoplankton biomass and the assumption that only a fraction of phytoplankton growth œÅ c h l is devoted to chlorophyll synthesis fennel et al 2006 detrital remineralization products go to the phosphate and ammonium pool ammonium is nitrified afterward to produce nitrate the nitrification rate is given by olson 1981 22 n n max 1 max 0 i i 0 k i i i 0 where nmax is the maximum nitrification rate values for the parameters used in this model are listed in table 1 fennel et al 2006 spitz et al 2005 gan et al 2014 the problem was solved using the finite volume method patankar 1980 the scalar quantities concentrations of the nitrate phosphate ammonium chlorophyll a phytoplankton zooplankton small nitrate detritus large nitrate detritus small phosphate detritus and large phosphate detritus water temperature salinity and pressure and turbulent diffusion coefficients were calculated in the center of a grid cell and the velocity vector components at the midpoints of the cell boundaries the numerical algorithm for finding the flow and temperature fields was based on a crank nicolson difference scheme the convective terms in the equations were approximated with a second order upstream scheme quick leonard 1979 the velocity and pressure fields calculated were correlated by a procedure for buoyant flows simpled semi implicit method for pressure linked equations with density correction tsydenov et al 2016 the numerical simulations show that the simpled method can increase the time step twice in comparison to simple tsydenov et al 2016 and therefore speed up the computational process validation of the model of the hydrodynamics of the thermal bar was conducted in previous works tsydenov 2018 2019a 2019b a qualitative comparison of results of the biological model which was applied to temperature conditions of barguzin bay in august with field data satoh et al 2006 katano et al 2008 is presented in tsydenov 2020b 2 3 initial and boundary conditions initial conditions for eqs 1 16 of the physical biological model were set as u 0 v 0 w 0 t t l s s l n n l a a l p p l c h l c h l l p h y t o p h y t o l z o o z o o l s d n s d n l l d n l d n l s d p s d p l l d p l d p l where t l s l n l a l p l c h l l p h y t o l z o o l s d n l l d n l s d p l and l d p l are the temperature salinity nitrates ammonium phosphates chlorophyll a phytoplankton zooplankton small nitrate detritus large nitrate detritus small phosphate detritus and large phosphate detritus in the lake respectively boundary conditions for the system of eqs 1 16 were a at the surface of the lake k z u z œÑ s u r f u œÅ 0 k z v z œÑ s u r f v œÅ 0 w 0 d z t z h n e t œÅ 0 c p s z 0 n z 0 a z 0 p z 0 c h l z 0 p h y t o z 0 z o o z 0 s d n z 0 l d n z 0 s d p z 0 l d p z 0 where hnet is the net flux of longwave radiation and latent and sensible heat the parametrization of these heat fluxes can be found in tsydenov 2018 and tsydenov et al 2018 b at the solid boundaries u 0 v 0 w 0 t n 0 s n 0 n n 0 a n 0 p n 0 c h l n 0 p h y t o n 0 z o o n 0 s d n n 0 l d n n 0 s d p n 0 l d p n 0 where n is the direction of the outward normal to the domain c at the river inflow boundary u u r v 0 w 0 t t r s s r n n r a a r p p r c h l c h l r p h y t o p h y t o r z o o z o o r s d n s d n r l d n l d n r s d p s d p r l d p l d p r where ur is the river inflow velocity and t r s r n r a r p r c h l r p h y t o r z o o r s d n r l d n r s d p r and l d p r are the temperature salinity nitrates ammonium phosphates chlorophyll a phytoplankton zooplankton small nitrate detritus large nitrate detritus small phosphate detritus and large phosphate detritus in the river respectively and d at the open boundary conditions of the radiation type were set œÜ t c œÜ œÜ x 0 œÜ u v t s n a p c h l p h y t o z o o s d n l d n s d p l d p w x 0 the phase velocity cœï was calculated here from the space and time trends œï in the domain near the boundary orlanski 1976 an initial lake water temperature equal to 3 c approximately corresponds to the average data in the upper 100 m layer of lake baikal in the central basin in june shimaraev et al 1994 the water temperature in the mouth of the barguzin river monotonically increased from 12 c to 18 c water mineralization in the lake was 96 mg kg shimaraev et al 1994 in the river it was set to 149 mg kg votintsev 1978 the barguzin river flowed into the lake at a velocity of 0 5 cm s modeling of the riverine thermal bar and its ecological consequences involves the choice of appropriate initial and boundary conditions for the biological model selecting these conditions for ecosystem models is a major difficulty in the physical setting of a continuously interacting river and lake holland et al 2003 it is observed that in rivers the plankton growth rate is much lower than in lakes under similar nutrient availability conditions because of rapid flushing and high turbulence and turbidity soballe and kimmel 1987 reynolds 1994 jasper et al 1983 also there is a significant difference between the annual concentrations of phytoplankton in lake baikal evstafyev and bondarenko 2007 satoh et al 2006 in this situation it is more essential to obtain a qualitative picture of the effect of the thermal bar on the hydrobiological state of the lake in this study the initial and boundary conditions adopted for the biological model are based on observation data in barguzin bay of lake baikal in summer 2002 katano et al 2008 satoh et al 2006 and the experience of simulation of biological processes in the aquatic environment holland et al 2003 fennel et al 2006 initial values of the concentration of the nitrates ammonium phosphates chlorophyll a phytoplankton and zooplankton were spatially homogeneous and set at 1 0 mmol m 3 1 0 mmol m 3 0 05 mmol m 3 0 3 mg m 3 0 3 mmol n m 3 and 0 3 mmol n m 3 respectively the concentrations of all detrital components at the initial time were a small value of 0 1 mmol n m 3 experience shows this approach to work well because the adjustment timescales for these variables are short fennel et al 2006 selecting the boundary conditions at the river inflow for 2 5d models is extremely problematic because upstream values of each biological component will have a very strong influence on the near river region of the lake throughout the entire simulation holland et al 2003 the preferred modeling approach would be to couple a 1d biological model of the river to the 2d cross section of the lake and use the 1d results to provide the riverine levels of biological components that flow into the lake model holland et al 2003 but at the moment this approach cannot be realized due to a lack of spatial and temporal high resolution field studies at the river inflow boundary n r 1 0 mmol m 3 a r 1 0 mmol m 3 p r 0 2 mmol m 3 chl r 1 0 mg m 3 phyto r 0 3 mmol n m 3 zoo r 0 3 mmol n m 3 sdn r 0 1 mmol n m 3 ldn r 0 1 mmol n m 3 sdp r 0 1 mmol n m 3 and ldp r 0 1 mmol n m 3 it is important to note that the values of p r and chl r are greater than p l and chl l which is consistent with observations in barguzin bay satoh et al 2006 ueno et al 2005 the available atmospheric data air temperature relative humidity atmospheric pressure cloudiness and wind speed for june 2019 from the goryachinsk weather station archive https rp5 ru were used for calculating the values of heat fluxes at the water air interface the wind shear stress on the lake surface was described according to the law œÑ s u r f u c 10 œÅ a v 10 2 u 10 2 u 10 œÑ s u r f v c 10 œÅ a v 10 2 u 10 2 v 10 where œÅa is the air density at the water surface u 10 and v 10 are the wind speed components at 10 m above the lake surface and c 10 1 3 10 3 3 results 3 1 weather conditions and heat fluxes to give a more realistic description of energy balance exchanges between the atmosphere and the water surface the numerical model takes into account the diurnal variability of the air temperature relative humidity atmospheric pressure cloudiness wind speed and direction according to the data from the meteorological station in goryachinsk village located near the study area based on these atmospheric data fluxes of shortwave and longwave radiation and latent and sensible heat were calculated fig 3 the diagrams fig 3 show that the heating of the upper layers occurs due to sensible heat fluxes and shortwave radiation the latter makes the greatest contribution to the heat balance of the lake surface in the first ten days of june 2019 the range of variation of the sensible heat flux changes from 11 4 to 58 6 w m 2 if air temperature dropped below water surface temperature sensible heat flux became negative at night maximum shortwave radiation was 769 7 w m 2 note that in day 3 and 4 of the month the peak values for this heat flux were below the maximums of other days due to heavy cloud cover 417 2 and 360 4 w m 2 respectively the fluxes of longwave radiation and sensible heat were the sources of heat loss for the body of water and varied from 2 3 to 102 6 w m 2 respectively average values for short and longwave radiation and sensible and latent heat fluxes are given in table 2 the wind was weak fig 4 a and mainly westward fig 4b in the first ten days of june 2019 stronger wind was registered in days 1 3 and 4 of the month and its speed in these days did not exceed 6 m s 4 m s and 5 m s respectively the average wind speed in the considered time interval was 1 8 m s 3 2 temperature distribution and the thermal bar in the bay the spatial temporal distributions of temperature and current velocities were obtained based on numerical modeling they indicate a short term period of the existence of the thermal bar in barguzin bay in lake baikal under the weather conditions for june 2019 on day 2 the 4 c isotherm was located 2 1 km from the river mouth fig 5 a the surface water temperature in the open lake reached 3 6 c water heating in the near mouth area of the bay was mainly provided by the river inflow the inclined structure of isotherms and high temperature gradients in the thermoactive region reveal weak wind influence on the mixing processes in the near mouth area of the body of water on day 4 further water heating in the bay was observed the thermal bar moved to 3 7 km from the mouth of the barguzin river fig 5b according to the streamlines water masses at the thermal bar front sank due to thermobaric instability while in the thermoactive zone of the lake a circulation flow containing two inner cells in the center was formed fig 5d the average velocity of water sinking within the thermal bar front was 0 5 cm s from the temperature distribution obtained on day 6 we can conclude that heat exchange processes between the bay surface and the atmosphere led to quick heating of upper layers up to the temperature above 4 c and this resulted in the destruction of the thermal bar front on the lake surface however the structure of 3 c and 3 5 c isotherms fig 5c indicates that the dynamic processes occurring due to thermobaric instability were continued in lower layers the motion of water masses down the bed slope was observed from the model results 3 2 biogeochemical processes during the thermal bar spatial distributions of the components of the biological model on day 4 demonstrate the barrier function of the thermal bar the thermal bar divides the body of water into two parts with obviously different qualitative and quantitative results fig 6 phytoplankton vegetated faster in the thermoactive region its maximum 3 1 mmol n m 3 was located on the water surface at 1 8 km from the shore fig 6a note that waters in the thermoinert region were still relatively unproductive and in open waters of the bay the phytoplankton was horizontally uniform distributed the increase in chlorophyll –∞ the basic pigment essential for photosynthesis in plant cells occurred in the littoral zone of the lake its highest concentration 0 75 mg m 3 was observed near the river lake interface fig 6b note that there is a difference between the patterns of phytoplankton biomass fig 6a and chlorophyll content fig 6b in the thermoactive region high values of zooplankton biomass were also registered in the thermoinert region of the body of water the zooplankton was concentrated in the upper 5 m layer where its values were more than 0 283 mmol n m 3 fig 6c there is a negative correlation between distributions of phytoplankton biomass and content of nitrates and ammonium in water the intensive growth of phytoplankton causes the reduction of no3 and nh4 fig 6d fig 6e the depletion of the ammonium and nitrate pool in areas with high concentrations of phytoplankton near the surface of the lake at 1 8 km from the river mouth also demonstrates the effect of the thermal bar the results simulated showed that the depletion of no3 in the near surface layer occurs faster fig 6d the highest content of nh4 1 0 mmol m 3 was located in the 15 25 m layer fig 6e the concentration of po4 in the thermoinert region was less than 0 06 mmol m 3 fig 6f fig 6f shows that the thermal bar prevents horizontal propagation of waters with high values of po4 concentrated in the littoral zone toward the open lake to evaluate the effect of the higher concentrations of nutrients in the river on the phytoplankton dynamics in the lake a numerical experiment with the boundary conditions chl r chl l 0 3 mg m 3 and p r p l 0 05 mmol m 3 in this simulation the riverine boundary conditions of prognostic variables of the biological model coincide with the initial lake conditions was performed comparing the distributions of phytoplankton and chlorophyll presented in fig 6 a b and fig 7 we see no significant qualitative distinction consequently we can conclude that the impact of the thermal bar on the phytoplankton biomass and chlorophyll content in the thermoactive region of the lake is dominant 4 discussion an important feature of the results obtained for the bathymetry of barguzin bay in lake baikal and the meteorological scenario for june 2019 is a short term period of the thermal bar existence as the simulation has shown in the shallow water environment fast heating of the upper layers in the thermoinert region of the body of water leads to a shorter life span of the spring thermal bar despite the destruction of the front of the thermal bar day 6 in the subsurface layer the dynamic processes in the lower layers initiated by the thermobaric instability proceed in the form of the flows sinking along the slope of the lake floor streamlines on day 4 fig 5d demonstrate that the location of temperature of maximum density coincides with the zone of water sinking which corresponds with the classical interpretation of the thermal bar forel 1880 tikhomirov 1982 but it is important to note that the amplification of wind stress on the lake surface may result in a shift of the water mass convergence zone from the 4 c isotherm blokhina 2013 tsydenov 2019a and sometimes a sporadic destruction of convective patterns generated by the thermal bar tsydenov 2018 the isotherms shown in fig 5 also demonstrate a classical structure forel 1880 tikhomirov 1982 they are inclined to the shore boundary with a high temperature gradient in the thermoactive region the wind regime at the beginning of june 2019 did not have any significant influence on thermohydrodynamic processes during the thermal bar development there can be two causes to explain this the first lies in the weak wind action on the water surface the average wind speed was 1 8 m s the second is connected to thermal and dynamic river inflow characteristics which were dominating the convective processes during the presence of the thermal bar the difference in spatial distributions between phytoplankton and chlorophyll a in fig 6 a b and fig 7 is due to a nonlinear relationship between them that reflects the acclimation to changes in light and nutrient conditions in the model unfortunately these results are difficult to verify in the absence of appropriate measurements during the spring thermal bar in barguzin bay of lake baikal nevertheless there is not always a clear relationship between chlorophyll and phytoplankton biomass laws et al 2016 liu et al 2019 they are usually correlated especially at large time and space scales liu et al 2019 but in shallow lakes type of limitation light or nutrients and wind action can significantly affect the correlation between planktonic biomass and chlorophyll a v√∂r√∂s and padis√°k 1991 previous results of numerical modeling conducted for the temperature conditions in barguzin bay of lake baikal in august tsydenov 2020b showed the qualitative correspondence with the monitoring data of the chemical composition of water satoh et al 2006 katano et al 2008 there are no complex field studies aimed to define the content of nutrients and organic substances in barguzin bay during the spring thermal bar nevertheless the results of this modeling that illustrate high levels of chlorophyll a phyto and zooplankton in the thermoactive region are consistent with the data from the in situ measurements at the south eastern coast of central baikal 70 km from the selenga river delta shimaraev et al 1995 likhoshway et al 1996 parfenova et al 2000 we can identify a certain similarity between the nature of formation of the phytoplankton concentrations local maximum on the surface of the thermoactive mid area fig 6a and the peculiarities of distribution of some species of diatoms sampled at the boldakov river maloe more strait cross section likhoshway et al 1996 in particular such distribution is characteristic of synedra acus var radiance k√ºtz skabitsch a typical representative of the open part of lake baikal and shallow water delta zones of the selenga river with a wide temperature range of vital activities 1 17 c the conducted previously numerical simulation of hydrobiological processes based on a nutrient phytoplankton zooplankton detritus model of parker 1991 had also shown the location of maximum of phytoplankton population in the near shore area during the spring thermal bar tsydenov 2019b high content of chlorophyll a was registered in water samples from the south eastern coast of central baikal on june 5 1993 shimaraev et al 1995 likhoshway et al 1996 the concentration of chlorophyll a and suspended matter in near coast waters was 1 2 orders of magnitude greater than their values in the open lake shimaraev et al 1995 if we take the po4 index as an indicator of water movement isoline 0 06 mmol m 3 fig 6 we can conclude that the along slope flows generated by the thermal bar contribute to the propagation of coastal waters to the near bottom area a similar effect was described by shimaraev et al 1995 on the basis of an analysis of distribution of a numerical abundance of heterotrophic ammonium producing and phosphorus fixing microorganisms in central baikal on june 5 1993 the results of simulations show that by restricting the horizontal water exchange the thermal bar creates favorable conditions for phytoplankton growth in the thermoactive region of the lake that could lead to eutrophication problems holland et al 2001 also considered that the nutrient rich stable regions inshore of a thermal bar might initiate phytoplankton bloom using a nutrient phytoplankton zooplankton model of franks et al 1986 botte and kay 2000 hypothesized that the bloom is sustained by the increase in the phytoplankton population produced by the flows converging toward the thermal bar phosphates that are high in river water can be regarded as a tracer of lake pollution by the barguzin river from the distribution of phosphates we can conclude that converging flows at the front of the thermal bar inhibit the pollutant propagation to open waters at the same time these flows contribute to the transport of pollution to the deeper region of the bay if the river inflow water density remained lower than the lake water density as would happen without thermobaric instability the pollutant would concentrate close to the lake surface the role of the spring and autumn thermal bar in pollutant propagation is more fully discussed on an example of the selenga shallow waters of lake baikal in tsydenov et al 2015 and tsydenov 2020a it is also important to point out that according to the chemical analysis of water samples from the cross section kharauz arm selenga river cape krasnyj yar in 2002 2007 tomberg et al 2014 the concentrations of nutrients and phytoplankton in shallow waters up to the thermal bar were much higher than in waters of open baikal the results of numerical simulation demonstrate that the flows converging at the temperature of maximum density point serve as a barrier for horizontal propagation of organic and biogenic matter toward the open lake hubbard and spain 1973 in lake superior scavia and bennett 1980 in lake ontario and moll et al 1993 in lake michigan registered the similar ecological function of the thermal bar 5 conclusions a numerical model was developed that enables reproducing biogeochemical processes in a freshwater lake during the formation of the spring thermal bar the model considers phosphorous and nitrogen limitation numerical modeling of physical and biological processes in barguzin bay in lake baikal showed the following 1 fast heating of the upper layers of the bay led to a shorter life of the spring thermal bar despite the destruction of the thermal bar front at the lake surface dynamic processes related to the thermobaric instability continued in deeper layers 2 a local area with the maximum phytoplankton concentration was formed in the near surface layer of the thermoactive region simulations show that by restricting the horizontal water exchange the thermal bar creates favorable conditions for phytoplankton growth in the thermoactive region of the bay that could lead to eutrophication problems 3 a decrease in levels of nitrate and ammonium was observed in waters with high concentrations of phytoplankton a greater concentration of ammonium was localized in the 15 25 m layer 4 the thermal bar impeded the horizontal propagation of waters with high concentrations of phosphates chlorophyll a phyto and zooplankton to the open lake the along slope flows generated by the thermal bar contribute to the propagation of phosphates to the near bottom area of the bay 5 the thermal bar effect has a dominant influence on the phytoplankton distribution in the thermoactive region of the lake compared with phosphate limitation credit author statement bair o tsydenov conceptualization methodology software visualization investigation writing original draft preparation and editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the reported study was funded by rfbr project number 19 31 60003 
24497,this article describes a coupled physical biological model for reproducing the ecological processes in a freshwater lake during the evolution of the thermal bar a phenomenon of sinking of maximum density waters in a narrow zone the biological part of the model includes 10 prognostic variables nitrate phosphate ammonium chlorophyll a phytoplankton zooplankton and nitrate and phosphate detritus of small and large sizes the results of modeling of hydrodynamic processes in barguzin bay of lake baikal using meteorological data for june 2019 demonstrate a short term period of the thermal bar existence the analysis of spatial distributions of biochemical variables of the model showed that the thermal bar acts as a natural barrier limiting the transfer of phosphates and plankton to the open lake keywords thermal bar lake ecosystem numerical modeling phosphorus limitation freshwater lake 1 introduction in recent decades anthropogenic activities have led to a noticeable worsening of ecological conditions in large freshwater lakes on our planet among the key sources of pollution and eutrophication of bodies of water are untreated sewage from industrial centers clustered at the waterfronts and or in lake catchment basins petroleum products from water vehicles emissions from fuel combustion and agricultural fertilizer manure etc and domestic waste in particular the lake baikal littoral zone has been witnessing active growth of the spirogyra alga volkova et al 2018 timoshkin et al 2019 lately which is connected to urban sewage and industrial wastewater rich in nitrogen and phosphorus the thermal bar is one of the natural phenomena promoting the accumulation of plankton and other microorganisms in the littoral area of a lake it is formed in dimictic lakes in spring and autumn and is a narrow zone of water sinking around the area of temperature of maximum density farrow 1995 holland and kay 2003 chubarenko and demchenko 2008 the role of the thermal bar for the ecological functioning of a lake is versatile it divides the lake into thermoactive near the shore and thermoinert open part of a lake regions tikhomirov 1982 and acts as a barrier limiting the spread of coastal waters with high concentrations of pollutants and biota in the central lake at the same time vertical flows forming in the location of the thermal bar may promote transport of suspended matter in the deep water part of a lake shimaraev et al 1995 tsydenov et al 2015 tsydenov 2020a the understanding of particular aspects of the thermal bar influence on hydrobiological processes is important for the purposes of predicting and monitoring of the ecological status of a freshwater lake taking timely measures for emergency damage control in anthropogenic and natural disasters field studies note organic matter and nutrients are distributed very unevenly in lake baikal tarasova 1975 goldman et al 1996 moreover the qualitative and quantitative variability of phytoplankton in lake baikal has not only a seasonal but also an annual nature the spring development of lake baikal phytoplankton explicitly differs from year to year evstafyev and bondarenko 2007 there is a tenfold difference in phytoplankton biomass between a high production year melosira year and a low production year bondarenko and evstafyev 2002 satoh et al 2006 also nitrate depletion and phytoplankton biomass may change significantly over a 2 week period during the initiation of thermal stratification goldman et al 1996 as an example water sampling in barguzin bay in summer 2002 showed that the concentrations of nitrogen nutrients were 1 0 Œºmol n l 1 in the epilimnion katano et al 2008 the concentrations of chlorophyll a were 0 5 Œºg l 1 below 30 m satoh et al 2006 and the concentrations of soluble reactive phosphorus were 0 05 Œºmol l 1 except for 0 2 Œºmol l 1 at the station nearest to the barguzin river satoh et al 2006 the most important biochemical elements of the lacustrine ecosystem are phosphorus and nitrogen since one of these elements is a limiting factor for biomass growth in a lake concentration levels of phosphorus in a freshwater lake are crucial to predicting the bursts of phytoplankton bloom thus there is a challenging issue for the up to date stage of development of mathematical methods in limnology to create integrative numerical models aimed at reproduction of biochemical processes of phosphorus and nitrogen limitation in the lake ecosystem during the thermal bar evolution despite the long history of studies devoted to primary production in lake baikal the question of limiting factors for its biomass development is still open for example some researchers weiss et al 1991 watanabe and drucker 1999 suppose that the phytoplankton productivity in lake baikal is limited by nitrogen however at the same time goldman at al 1996 note that in summer the significance of both phosphorus and nitrogen limitation becomes more evident nutrient enrichment experiments in barguzin bay in late august 2002 showed that the first limiting nutrient is thought to be phosphorus but once phosphorus is supplied to the surface water the limiting nutrient will quickly shift from phosphorus to nitrogen satoh et al 2006 obviously it is important to consider the presence of not only nitrogen in a water environment while modeling biochemical processes in freshwater ecosystems phosphorus should also be taken into account since phosphate groups are basic structural elements of nucleic acids in plant cells and they take part in energy metabolism studies aimed at understanding the effect of a thermal bar on plankton dynamics were carried out using nitrogen based biological models botte and kay 2000 holland et al 2003 tsydenov 2019b the objective of this study is to reproduce the biogeochemical processes during the spring thermal bar evolution in barguzin bay of lake baikal by means of the coupled physical biological model that considers as a limiting nutrient not only nitrogen but also phosphorous 2 model description the coupled physical biological model was developed on the basis of a 2 5d physical model that uses approximations which transform the problem into 2d vertical cross section of a lake but take into account all three components of the velocity vector to include the coriolis force related to the earth s rotation tsydenov et al 2016 the biological part of the model contains ten prognostic variables nitrate phosphate ammonium chlorophyll a phytoplankton zooplankton small nitrate detritus large nitrate detritus small phosphate detritus and large phosphate detritus the geographic domain of the coupled model is a vertical cross section of barguzin bay of lake baikal the origin of the system of coordinates coincides with the mouth of the barguzin river 53 25 30 n and 108 59 50 e fig 1 –∞ the calculation domain having a simplified geometry with a length of 20 km and a depth of 100 m fig 1b is based on bathymetric data from ueno et al 2005 and covered by a uniform orthogonal grid with steps hx 25 m and hz 2 5 m 2 1 physical model the 2 5d hydrostatic model for the reproduction of hydrodynamic processes in a lake expressed in the boussinesq approximation is comprised of the following equations –∞ momentum equations 1 u t u 2 x u w z 1 œÅ 0 p x x k x u x z k z u z 2 œâ z v 2 œâ y w 2 v t u v x w v z x k x v x z k z v z 2 œâ x w 2 œâ z u 3 w t u w x w 2 z 1 œÅ 0 p z x k x w x z k z w z g œÅ œÅ 0 2 œâ y u 2 œâ x v b continuity equation 4 u x w z 0 c energy equation 5 t t u t x w t z x d x t x z d z t z 1 œÅ 0 c p h s o l z d equations of salinity balance 6 s t u s x w s z x d x s x z d z s z where u v are the horizontal velocity components along ox and oy axes respectively w is the vertical velocity component œâx œây and œâz are the vector components of the earth s rotation angular velocity g is the acceleration of gravity cp is the specific heat capacity t is the temperature s is the salinity p is the pressure œÅ0 is the water density at standard atmospheric pressure and temperature tl and salinity sl are a reference temperature and salinity of the lake respectively the chen millero equation 1986 which is widely used in freshwater lakes flood et al 2021 de carvalho bueno et al 2021 wu et al 2020 to connect water density with temperature salinity and pressure and is valid within the range of 0 t 30 c 0 s 0 6 g kg 0 p 180 bar was taken as the state equation œÅ s t p œÅ 0 1 p k s t p where œÅ 0 999 8395 6 7914 10 2 t 9 0894 10 3 t 2 1 0171 10 4 t 3 1 2846 10 6 t 4 1 1592 10 8 t 5 5 0125 10 11 t 6 0 8181 3 85 10 3 t 4 96 10 5 t 2 s and k s t p 19625 17 148 113 t 2 293 t 2 1 256 10 2 t 3 4 18 10 5 t 4 3 2726 2 147 10 4 t 1 128 10 4 t 2 p 53 238 0 313 t 5 728 10 3 p s many important thermodynamic parameters for example temperature of maximum density and thermal expansibility calculated from this equation of state are presented in chen and millero 1986 in their easy to use form for application in physical limnology 2 2 biological model the biological model is based on nitrogen based ecosystem models of fasham et al 1990 fennel et al 2006 and hofmann et al 2008 and includes seven state variables nitrate eq 7 ammonium eq 8 chlorophyll a eq 10 phytoplankton eq 11 zooplankton eq 12 and small eq 13 and large eq 14 nitrate detritus to describe the phosphorus limitation in the freshwater lake three additional variables phosphate eq 9 and small eq 15 and large eq 16 phosphate detritus are introduced into the model according to gan et al s formulation gan et al 2014 a biological model schematic that demonstrates the relationship between the ecosystem components is presented in fig 2 in the model the phytoplankton growth rate is defined by the nitrogen and phosphorus modules in accordance with their respective roles in limitation of primary production as an indicator of nutrient limitation the molar ratio of dissolved inorganic nitrogen n and dissolved inorganic phosphate p concentrations n p ratio is often used according to redfield 1958 a n p ratio 16 1 corresponds to n limitation and a n p ratio 16 1 corresponds to p limitation biochemical processes in the model are described by the following reaction convection diffusion equations n t u n x w n z x d x n x z d z n z 7 Œº max f i p h y t o œÉ n n k n n 1 1 a k a œÉ p n n a p k p p n a a t u a x w a z x d x a x z d z a z Œº max f i p h y t o œÉ n a k a a œÉ p a n a p k p p 8 n a l b m z o o l e p h y t o 2 k p h y t o p h y t o 2 Œ≤ z o o r s d n s d n r l d n l d n p t u p x w p z x d x p x z d z p z Œº max f i p h y t o œÉ n n k n n 1 1 a k a a k n a r p n œÉ p p k p p r p n 9 l b m r p n z o o l e r p n p h y t o 2 k p h y t o p h y t o 2 Œ≤ z o o r s d p s d p r l d p l d p c h l t u c h l x w c h l z x d x c h l x z d z c h l z œÅ c h l Œº c h l m p h y t o c h l 10 œÑ s d n p h y t o c h l g max p h y t o 2 k p h y t o p h y t o 2 z o o c h l p h y t o p h y t o t u p h y t o x w p h y t o z x d x p h y t o x z d z p h y t o z Œº p h y t o m p h y t o p h y t o 11 œÑ s d n p h y t o p h y t o g max p h y t o 2 k p h y t o p h y t o 2 z o o z o o t u z o o x w z o o z x d x z o o x z d z z o o z g max p h y t o 2 k p h y t o p h y t o 2 Œ≤ z o o l b m z o o 12 l e p h y t o 2 k p h y t o p h y t o 2 Œ≤ z o o m z o o z o o 2 s d n t u s d n x w s d n z x d x s d n x z d z s d n z g max p h y t o 2 k p h y t o p h y t o 2 1 Œ≤ z o o 13 m z o o z o o 2 m p h y t o p h y t o œÑ s d n p h y t o s d n r s d n s d n 14 l d n t u l d n x w l d n z x d x l d n x z d z l d n z œÑ s d n p h y t o 2 r l d n l d n s d p t u s d p x w s d p z x d x s d p x z d z s d p z g max p h y t o 2 k p h y t o p h y t o 2 r p n 1 Œ≤ z o o 15 m z o o r p n z o o 2 m p h y t o r p n p h y t o œÑ s d n p h y t o s d p r s d p s d p l d p t u l d p x w l d p z x d x l d p x z d z l d p z 16 œÑ s d n p h y t o s d p r p n p h y t o r l d p l d p where n a p chl phyto and zoo are the concentrations of nitrates no3 ammonium nh4 phosphate po4 chlorophyll a phytoplankton and zooplankton respectively sdn and sdp are the concentrations of small detritus for no3 and po4 respectively ldn and ldp are the concentrations of large detritus for no3 and po4 respectively small detrital particles smaller than 10 ¬µm and phytoplankton are assumed to aggregate and form larger detrital particles fennel et al 2006 gan et al 2014 a two parameter k œâ model of turbulence developed by wilcox 1988 and consisting of equations for kinetic energy and turbulent fluctuation frequency to find vertical eddy diffusivity is used to close the set of eqs 1 16 the horizontal diffusion coefficients are assumed to be constant as kx dx 2 5 m2 s the phytoplankton growth rate is determined as 17 Œº Œº max f i œÉ n n k n n 1 1 a k a a k a a œÉ p p k p p where ¬µmax is the maximum growth rate of phytoplankton eppley 1972 18 Œº max t Œº 0 1 066 t the coefficients œÉn and œÉp are responsible for the limitation of lake productivity through major biogenic elements if n k n n 1 1 a k a a k a a p k p p then œÉn 0 and œÉp 1 p limitation otherwise œÉn 1 and œÉp 0 n limitation the function f i represents the photosynthesis light relationship evans and parslow 1985 19 f i Œ± i Œº max 2 Œ± 2 i 2 20 i i s p a r exp d k w a t e r k c h l d l z c h l z d z where is is the incoming light just below the lake surface par is the fraction of light that is available for photosynthesis par 0 43 fennel et al 2006 in the model is is the shortwave radiation flux calculated according to the formula 8 from b o tsydenov and starchenko 2015 the fraction of phytoplankton growth that devoted to chlorophyll synthesis is defined as 21 œÅ c h l Œ∏ max Œº p h y t o Œ± i c h l because the amount of chlorophyll is associated with intracellular pigmentation arising from light driven photoacclimation and nutrient driven physiological responses behrenfeld et al 2016 liu et al 2019 the relationship between concentrations of phytoplankton and chlorophyll is nonlinear the model takes into account the effects of photoacclimation on the basis of the model of geider et al 1996 1997 the chlorophyll content is derived from the phytoplankton equation by multiplication with the ratio of chlorophyll to phytoplankton biomass and the assumption that only a fraction of phytoplankton growth œÅ c h l is devoted to chlorophyll synthesis fennel et al 2006 detrital remineralization products go to the phosphate and ammonium pool ammonium is nitrified afterward to produce nitrate the nitrification rate is given by olson 1981 22 n n max 1 max 0 i i 0 k i i i 0 where nmax is the maximum nitrification rate values for the parameters used in this model are listed in table 1 fennel et al 2006 spitz et al 2005 gan et al 2014 the problem was solved using the finite volume method patankar 1980 the scalar quantities concentrations of the nitrate phosphate ammonium chlorophyll a phytoplankton zooplankton small nitrate detritus large nitrate detritus small phosphate detritus and large phosphate detritus water temperature salinity and pressure and turbulent diffusion coefficients were calculated in the center of a grid cell and the velocity vector components at the midpoints of the cell boundaries the numerical algorithm for finding the flow and temperature fields was based on a crank nicolson difference scheme the convective terms in the equations were approximated with a second order upstream scheme quick leonard 1979 the velocity and pressure fields calculated were correlated by a procedure for buoyant flows simpled semi implicit method for pressure linked equations with density correction tsydenov et al 2016 the numerical simulations show that the simpled method can increase the time step twice in comparison to simple tsydenov et al 2016 and therefore speed up the computational process validation of the model of the hydrodynamics of the thermal bar was conducted in previous works tsydenov 2018 2019a 2019b a qualitative comparison of results of the biological model which was applied to temperature conditions of barguzin bay in august with field data satoh et al 2006 katano et al 2008 is presented in tsydenov 2020b 2 3 initial and boundary conditions initial conditions for eqs 1 16 of the physical biological model were set as u 0 v 0 w 0 t t l s s l n n l a a l p p l c h l c h l l p h y t o p h y t o l z o o z o o l s d n s d n l l d n l d n l s d p s d p l l d p l d p l where t l s l n l a l p l c h l l p h y t o l z o o l s d n l l d n l s d p l and l d p l are the temperature salinity nitrates ammonium phosphates chlorophyll a phytoplankton zooplankton small nitrate detritus large nitrate detritus small phosphate detritus and large phosphate detritus in the lake respectively boundary conditions for the system of eqs 1 16 were a at the surface of the lake k z u z œÑ s u r f u œÅ 0 k z v z œÑ s u r f v œÅ 0 w 0 d z t z h n e t œÅ 0 c p s z 0 n z 0 a z 0 p z 0 c h l z 0 p h y t o z 0 z o o z 0 s d n z 0 l d n z 0 s d p z 0 l d p z 0 where hnet is the net flux of longwave radiation and latent and sensible heat the parametrization of these heat fluxes can be found in tsydenov 2018 and tsydenov et al 2018 b at the solid boundaries u 0 v 0 w 0 t n 0 s n 0 n n 0 a n 0 p n 0 c h l n 0 p h y t o n 0 z o o n 0 s d n n 0 l d n n 0 s d p n 0 l d p n 0 where n is the direction of the outward normal to the domain c at the river inflow boundary u u r v 0 w 0 t t r s s r n n r a a r p p r c h l c h l r p h y t o p h y t o r z o o z o o r s d n s d n r l d n l d n r s d p s d p r l d p l d p r where ur is the river inflow velocity and t r s r n r a r p r c h l r p h y t o r z o o r s d n r l d n r s d p r and l d p r are the temperature salinity nitrates ammonium phosphates chlorophyll a phytoplankton zooplankton small nitrate detritus large nitrate detritus small phosphate detritus and large phosphate detritus in the river respectively and d at the open boundary conditions of the radiation type were set œÜ t c œÜ œÜ x 0 œÜ u v t s n a p c h l p h y t o z o o s d n l d n s d p l d p w x 0 the phase velocity cœï was calculated here from the space and time trends œï in the domain near the boundary orlanski 1976 an initial lake water temperature equal to 3 c approximately corresponds to the average data in the upper 100 m layer of lake baikal in the central basin in june shimaraev et al 1994 the water temperature in the mouth of the barguzin river monotonically increased from 12 c to 18 c water mineralization in the lake was 96 mg kg shimaraev et al 1994 in the river it was set to 149 mg kg votintsev 1978 the barguzin river flowed into the lake at a velocity of 0 5 cm s modeling of the riverine thermal bar and its ecological consequences involves the choice of appropriate initial and boundary conditions for the biological model selecting these conditions for ecosystem models is a major difficulty in the physical setting of a continuously interacting river and lake holland et al 2003 it is observed that in rivers the plankton growth rate is much lower than in lakes under similar nutrient availability conditions because of rapid flushing and high turbulence and turbidity soballe and kimmel 1987 reynolds 1994 jasper et al 1983 also there is a significant difference between the annual concentrations of phytoplankton in lake baikal evstafyev and bondarenko 2007 satoh et al 2006 in this situation it is more essential to obtain a qualitative picture of the effect of the thermal bar on the hydrobiological state of the lake in this study the initial and boundary conditions adopted for the biological model are based on observation data in barguzin bay of lake baikal in summer 2002 katano et al 2008 satoh et al 2006 and the experience of simulation of biological processes in the aquatic environment holland et al 2003 fennel et al 2006 initial values of the concentration of the nitrates ammonium phosphates chlorophyll a phytoplankton and zooplankton were spatially homogeneous and set at 1 0 mmol m 3 1 0 mmol m 3 0 05 mmol m 3 0 3 mg m 3 0 3 mmol n m 3 and 0 3 mmol n m 3 respectively the concentrations of all detrital components at the initial time were a small value of 0 1 mmol n m 3 experience shows this approach to work well because the adjustment timescales for these variables are short fennel et al 2006 selecting the boundary conditions at the river inflow for 2 5d models is extremely problematic because upstream values of each biological component will have a very strong influence on the near river region of the lake throughout the entire simulation holland et al 2003 the preferred modeling approach would be to couple a 1d biological model of the river to the 2d cross section of the lake and use the 1d results to provide the riverine levels of biological components that flow into the lake model holland et al 2003 but at the moment this approach cannot be realized due to a lack of spatial and temporal high resolution field studies at the river inflow boundary n r 1 0 mmol m 3 a r 1 0 mmol m 3 p r 0 2 mmol m 3 chl r 1 0 mg m 3 phyto r 0 3 mmol n m 3 zoo r 0 3 mmol n m 3 sdn r 0 1 mmol n m 3 ldn r 0 1 mmol n m 3 sdp r 0 1 mmol n m 3 and ldp r 0 1 mmol n m 3 it is important to note that the values of p r and chl r are greater than p l and chl l which is consistent with observations in barguzin bay satoh et al 2006 ueno et al 2005 the available atmospheric data air temperature relative humidity atmospheric pressure cloudiness and wind speed for june 2019 from the goryachinsk weather station archive https rp5 ru were used for calculating the values of heat fluxes at the water air interface the wind shear stress on the lake surface was described according to the law œÑ s u r f u c 10 œÅ a v 10 2 u 10 2 u 10 œÑ s u r f v c 10 œÅ a v 10 2 u 10 2 v 10 where œÅa is the air density at the water surface u 10 and v 10 are the wind speed components at 10 m above the lake surface and c 10 1 3 10 3 3 results 3 1 weather conditions and heat fluxes to give a more realistic description of energy balance exchanges between the atmosphere and the water surface the numerical model takes into account the diurnal variability of the air temperature relative humidity atmospheric pressure cloudiness wind speed and direction according to the data from the meteorological station in goryachinsk village located near the study area based on these atmospheric data fluxes of shortwave and longwave radiation and latent and sensible heat were calculated fig 3 the diagrams fig 3 show that the heating of the upper layers occurs due to sensible heat fluxes and shortwave radiation the latter makes the greatest contribution to the heat balance of the lake surface in the first ten days of june 2019 the range of variation of the sensible heat flux changes from 11 4 to 58 6 w m 2 if air temperature dropped below water surface temperature sensible heat flux became negative at night maximum shortwave radiation was 769 7 w m 2 note that in day 3 and 4 of the month the peak values for this heat flux were below the maximums of other days due to heavy cloud cover 417 2 and 360 4 w m 2 respectively the fluxes of longwave radiation and sensible heat were the sources of heat loss for the body of water and varied from 2 3 to 102 6 w m 2 respectively average values for short and longwave radiation and sensible and latent heat fluxes are given in table 2 the wind was weak fig 4 a and mainly westward fig 4b in the first ten days of june 2019 stronger wind was registered in days 1 3 and 4 of the month and its speed in these days did not exceed 6 m s 4 m s and 5 m s respectively the average wind speed in the considered time interval was 1 8 m s 3 2 temperature distribution and the thermal bar in the bay the spatial temporal distributions of temperature and current velocities were obtained based on numerical modeling they indicate a short term period of the existence of the thermal bar in barguzin bay in lake baikal under the weather conditions for june 2019 on day 2 the 4 c isotherm was located 2 1 km from the river mouth fig 5 a the surface water temperature in the open lake reached 3 6 c water heating in the near mouth area of the bay was mainly provided by the river inflow the inclined structure of isotherms and high temperature gradients in the thermoactive region reveal weak wind influence on the mixing processes in the near mouth area of the body of water on day 4 further water heating in the bay was observed the thermal bar moved to 3 7 km from the mouth of the barguzin river fig 5b according to the streamlines water masses at the thermal bar front sank due to thermobaric instability while in the thermoactive zone of the lake a circulation flow containing two inner cells in the center was formed fig 5d the average velocity of water sinking within the thermal bar front was 0 5 cm s from the temperature distribution obtained on day 6 we can conclude that heat exchange processes between the bay surface and the atmosphere led to quick heating of upper layers up to the temperature above 4 c and this resulted in the destruction of the thermal bar front on the lake surface however the structure of 3 c and 3 5 c isotherms fig 5c indicates that the dynamic processes occurring due to thermobaric instability were continued in lower layers the motion of water masses down the bed slope was observed from the model results 3 2 biogeochemical processes during the thermal bar spatial distributions of the components of the biological model on day 4 demonstrate the barrier function of the thermal bar the thermal bar divides the body of water into two parts with obviously different qualitative and quantitative results fig 6 phytoplankton vegetated faster in the thermoactive region its maximum 3 1 mmol n m 3 was located on the water surface at 1 8 km from the shore fig 6a note that waters in the thermoinert region were still relatively unproductive and in open waters of the bay the phytoplankton was horizontally uniform distributed the increase in chlorophyll –∞ the basic pigment essential for photosynthesis in plant cells occurred in the littoral zone of the lake its highest concentration 0 75 mg m 3 was observed near the river lake interface fig 6b note that there is a difference between the patterns of phytoplankton biomass fig 6a and chlorophyll content fig 6b in the thermoactive region high values of zooplankton biomass were also registered in the thermoinert region of the body of water the zooplankton was concentrated in the upper 5 m layer where its values were more than 0 283 mmol n m 3 fig 6c there is a negative correlation between distributions of phytoplankton biomass and content of nitrates and ammonium in water the intensive growth of phytoplankton causes the reduction of no3 and nh4 fig 6d fig 6e the depletion of the ammonium and nitrate pool in areas with high concentrations of phytoplankton near the surface of the lake at 1 8 km from the river mouth also demonstrates the effect of the thermal bar the results simulated showed that the depletion of no3 in the near surface layer occurs faster fig 6d the highest content of nh4 1 0 mmol m 3 was located in the 15 25 m layer fig 6e the concentration of po4 in the thermoinert region was less than 0 06 mmol m 3 fig 6f fig 6f shows that the thermal bar prevents horizontal propagation of waters with high values of po4 concentrated in the littoral zone toward the open lake to evaluate the effect of the higher concentrations of nutrients in the river on the phytoplankton dynamics in the lake a numerical experiment with the boundary conditions chl r chl l 0 3 mg m 3 and p r p l 0 05 mmol m 3 in this simulation the riverine boundary conditions of prognostic variables of the biological model coincide with the initial lake conditions was performed comparing the distributions of phytoplankton and chlorophyll presented in fig 6 a b and fig 7 we see no significant qualitative distinction consequently we can conclude that the impact of the thermal bar on the phytoplankton biomass and chlorophyll content in the thermoactive region of the lake is dominant 4 discussion an important feature of the results obtained for the bathymetry of barguzin bay in lake baikal and the meteorological scenario for june 2019 is a short term period of the thermal bar existence as the simulation has shown in the shallow water environment fast heating of the upper layers in the thermoinert region of the body of water leads to a shorter life span of the spring thermal bar despite the destruction of the front of the thermal bar day 6 in the subsurface layer the dynamic processes in the lower layers initiated by the thermobaric instability proceed in the form of the flows sinking along the slope of the lake floor streamlines on day 4 fig 5d demonstrate that the location of temperature of maximum density coincides with the zone of water sinking which corresponds with the classical interpretation of the thermal bar forel 1880 tikhomirov 1982 but it is important to note that the amplification of wind stress on the lake surface may result in a shift of the water mass convergence zone from the 4 c isotherm blokhina 2013 tsydenov 2019a and sometimes a sporadic destruction of convective patterns generated by the thermal bar tsydenov 2018 the isotherms shown in fig 5 also demonstrate a classical structure forel 1880 tikhomirov 1982 they are inclined to the shore boundary with a high temperature gradient in the thermoactive region the wind regime at the beginning of june 2019 did not have any significant influence on thermohydrodynamic processes during the thermal bar development there can be two causes to explain this the first lies in the weak wind action on the water surface the average wind speed was 1 8 m s the second is connected to thermal and dynamic river inflow characteristics which were dominating the convective processes during the presence of the thermal bar the difference in spatial distributions between phytoplankton and chlorophyll a in fig 6 a b and fig 7 is due to a nonlinear relationship between them that reflects the acclimation to changes in light and nutrient conditions in the model unfortunately these results are difficult to verify in the absence of appropriate measurements during the spring thermal bar in barguzin bay of lake baikal nevertheless there is not always a clear relationship between chlorophyll and phytoplankton biomass laws et al 2016 liu et al 2019 they are usually correlated especially at large time and space scales liu et al 2019 but in shallow lakes type of limitation light or nutrients and wind action can significantly affect the correlation between planktonic biomass and chlorophyll a v√∂r√∂s and padis√°k 1991 previous results of numerical modeling conducted for the temperature conditions in barguzin bay of lake baikal in august tsydenov 2020b showed the qualitative correspondence with the monitoring data of the chemical composition of water satoh et al 2006 katano et al 2008 there are no complex field studies aimed to define the content of nutrients and organic substances in barguzin bay during the spring thermal bar nevertheless the results of this modeling that illustrate high levels of chlorophyll a phyto and zooplankton in the thermoactive region are consistent with the data from the in situ measurements at the south eastern coast of central baikal 70 km from the selenga river delta shimaraev et al 1995 likhoshway et al 1996 parfenova et al 2000 we can identify a certain similarity between the nature of formation of the phytoplankton concentrations local maximum on the surface of the thermoactive mid area fig 6a and the peculiarities of distribution of some species of diatoms sampled at the boldakov river maloe more strait cross section likhoshway et al 1996 in particular such distribution is characteristic of synedra acus var radiance k√ºtz skabitsch a typical representative of the open part of lake baikal and shallow water delta zones of the selenga river with a wide temperature range of vital activities 1 17 c the conducted previously numerical simulation of hydrobiological processes based on a nutrient phytoplankton zooplankton detritus model of parker 1991 had also shown the location of maximum of phytoplankton population in the near shore area during the spring thermal bar tsydenov 2019b high content of chlorophyll a was registered in water samples from the south eastern coast of central baikal on june 5 1993 shimaraev et al 1995 likhoshway et al 1996 the concentration of chlorophyll a and suspended matter in near coast waters was 1 2 orders of magnitude greater than their values in the open lake shimaraev et al 1995 if we take the po4 index as an indicator of water movement isoline 0 06 mmol m 3 fig 6 we can conclude that the along slope flows generated by the thermal bar contribute to the propagation of coastal waters to the near bottom area a similar effect was described by shimaraev et al 1995 on the basis of an analysis of distribution of a numerical abundance of heterotrophic ammonium producing and phosphorus fixing microorganisms in central baikal on june 5 1993 the results of simulations show that by restricting the horizontal water exchange the thermal bar creates favorable conditions for phytoplankton growth in the thermoactive region of the lake that could lead to eutrophication problems holland et al 2001 also considered that the nutrient rich stable regions inshore of a thermal bar might initiate phytoplankton bloom using a nutrient phytoplankton zooplankton model of franks et al 1986 botte and kay 2000 hypothesized that the bloom is sustained by the increase in the phytoplankton population produced by the flows converging toward the thermal bar phosphates that are high in river water can be regarded as a tracer of lake pollution by the barguzin river from the distribution of phosphates we can conclude that converging flows at the front of the thermal bar inhibit the pollutant propagation to open waters at the same time these flows contribute to the transport of pollution to the deeper region of the bay if the river inflow water density remained lower than the lake water density as would happen without thermobaric instability the pollutant would concentrate close to the lake surface the role of the spring and autumn thermal bar in pollutant propagation is more fully discussed on an example of the selenga shallow waters of lake baikal in tsydenov et al 2015 and tsydenov 2020a it is also important to point out that according to the chemical analysis of water samples from the cross section kharauz arm selenga river cape krasnyj yar in 2002 2007 tomberg et al 2014 the concentrations of nutrients and phytoplankton in shallow waters up to the thermal bar were much higher than in waters of open baikal the results of numerical simulation demonstrate that the flows converging at the temperature of maximum density point serve as a barrier for horizontal propagation of organic and biogenic matter toward the open lake hubbard and spain 1973 in lake superior scavia and bennett 1980 in lake ontario and moll et al 1993 in lake michigan registered the similar ecological function of the thermal bar 5 conclusions a numerical model was developed that enables reproducing biogeochemical processes in a freshwater lake during the formation of the spring thermal bar the model considers phosphorous and nitrogen limitation numerical modeling of physical and biological processes in barguzin bay in lake baikal showed the following 1 fast heating of the upper layers of the bay led to a shorter life of the spring thermal bar despite the destruction of the thermal bar front at the lake surface dynamic processes related to the thermobaric instability continued in deeper layers 2 a local area with the maximum phytoplankton concentration was formed in the near surface layer of the thermoactive region simulations show that by restricting the horizontal water exchange the thermal bar creates favorable conditions for phytoplankton growth in the thermoactive region of the bay that could lead to eutrophication problems 3 a decrease in levels of nitrate and ammonium was observed in waters with high concentrations of phytoplankton a greater concentration of ammonium was localized in the 15 25 m layer 4 the thermal bar impeded the horizontal propagation of waters with high concentrations of phosphates chlorophyll a phyto and zooplankton to the open lake the along slope flows generated by the thermal bar contribute to the propagation of phosphates to the near bottom area of the bay 5 the thermal bar effect has a dominant influence on the phytoplankton distribution in the thermoactive region of the lake compared with phosphate limitation credit author statement bair o tsydenov conceptualization methodology software visualization investigation writing original draft preparation and editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the reported study was funded by rfbr project number 19 31 60003 
24498,soil degradation affecting around 38 of the world s cropland threatens the global food supply due to the soil s complexity the measure of soil degradation that involves the loss of soil fertility due to crop system management processes represents an unsolved problem exergy is a property with the potential to be used in soil fertility and or degradation analysis a methodology to determine the exergy value fenced in a fertile soil due to its inorganic and organic components is established in this study and will be applied to evaluate soil fertility degradation and quality as a first step the exergy of perfect topsoil with optimum characteristics called optsoil is determined the optsoil is established by agronomic expertise and will allow establishing a general theoretical reference suitable to execute exergy assessments of soils and compare the degradation grade of any soil concerning the best possible consequently we introduce a perfect fertile planetary crust made of optnut and optsom invariant and independent of the different local textures but not independent of their water content and aeration we call this imaginary crust copiously fertile pristinia as opposed to thanatia a dead state referring to abiotic resources thus any real agricultural soil will be an intermediate soil between pristinia and thanatia this idea might serve to quantitatively diagnose an assessment of all the concepts by which soil is degraded the methodology has been validated through laboratory agronomic tests for different soils concluding that exergy is a rigorous indicator to measure topsoil fertility keywords exergy soil fertility soil degradation thanatia pristinia sustainability abbreviations fao food and agricultural organization som soil organic matter om organic matter soc soil organic carbon oc organic carbon hhv higher heating value optsoil optimum topsoil established opttext optimum topsoil texture optnut optimum topsoil nutrients content optsom optimum topsoil organic matter content 1 introduction valero and valero 2014 valero et al 2011a developed a reference baseline to evaluate the planet s abiotic resources in previous studies this reference baseline was called thanatia and represented a degraded planet where all resources would have been extracted and dispersed throughout the earth s crust it is composed of a degraded atmosphere hydrosphere and upper continental crust particularly for the upper continental crust it represents the starting point to assess the exergy of mineral capital on earth because it provides the concentration of the around 300 most abundant elements found in the earth s crust the degradation of the mineral capital is an important source of concern since the transition to low carbon technologies will require a considerable amount and variety of raw materials some of which are scarce and with serious supply problems calvo et al 2016 valero et al 2018 exergy is defined as a thermodynamic property that measures the quantity and quality of any resource and exergoecology is a discipline whose objective is to evaluate natural resources through the exergy property valero and valero 2014 exergoecology has been widely developed in the evaluation of water resources opening the branch called physical hydronomics and mineral resources with the branch physical geonomics this study the aims to develop a new and innovative application of exergoecology for the exergy assessment of soil fertility like water and minerals the soil is a valuable and limited natural resource the irreversible degradation of this resource is a problem and a challenge for securing the world s food supply and the production of biomass and biofuels for the future maintaining the quality and fertility of soils is therefore a global priority the sustainability of the agroecosystems is also an important issue considering that the global population is expected to continue growing reaching almost 11 to 13 billion in 2100 united nations 2019 consequently food demand will continue to grow and is expected to be satisfied for example by increasing about 49 percent in the agricultural production required by 2050 food and agriculture organization of the united nations 2019 crop production yield has been raised employing intensive agriculture based on high inputs of inorganic fertilizers and pesticides resulting in severe environmental impacts erosion and soil quality loss the agricultural sector causes approximately 25 percent of the global greenhouse gasses food and agriculture organization of the united nations 2019 besides degradation caused in soils threatens around 40 percent of the land area in europe it is estimated that there are 12 million hectares affected by erosion which currently generates losses of 1 250 million euros per year g√∂rlach et al 2004 the continued degradation of soil fertility due to human actions threatens the sustainability on earth that will turn into thanatia as it has been done for the mineral capital one can assess soil fertility through exergy however for an exergy evaluation of soil the thanatia model is not enough since it does not consider the specific attributes that make a given soil fertile therefore it is necessary to establish an adequate methodology that serves as a starting point to evaluate soil fertility fao defines soil fertility as the capacity of the soil to support the growth of plants on a sustained basis yielding quantities of expected products that are close to the known potential gachene and kimaru 2003 soil science society of america defines soil quality as the capacity of a specific kind of soil to function within natural or managed ecosystem boundaries to sustain plant and animal productivity karlen et al 1997 soil quality can be considered for agricultural and natural ecosystems where the main objectives are to maintain environmental quality and biodiversity conservation the decline in soil quality caused by its improper use or poor management usually for agricultural industrial or urban purposes is defined as soil degradation this study focuses on agricultural soils agricultural soils are complex systems formed by physical chemical and biological properties interacting with each other due to this complexity a unified approach does not exist to evaluate soil fertility or soil quality despite the high number of studies performed arshad and martin 2002 the incapacity of using a single indicator in the characterization and evaluation of a soil is one of the main and most important disadvantages that can be found in the study of the soil system bongiorno et al 2019 b√ºnemann et al 2018 dexter 2004 johannes et al 2019 due to the complexity of soil and a large number of factors and parameters that interact in the system studies have been found in the literature that focuses on determining a minimum data set mds of soil characteristics with the most significant effect on quality garrigues et al 2012 reynolds et al 2009 2008 thoumazeau et al 2019 xu et al 2017 then this study use exergy as a unifying tool to assess soil fertility and degradation to lay the foundations of the fourth dimension of thanatia soils and its fertility assessment 2 definition of an optimum soil in any exergy evaluation it is necessary first to define a reference state usually a reference state is contemplated a dead figure the most degraded state with the minimum exergy valero et al 2011 in soil our initial endeavor has been to determine the minimum attributes above which the system is inefficient and a plant s growth is not possible valero et al 2019 nevertheless the implementation of an optimum level is more appropriate in the case of fertile soils study in this way to assess the degradation and deterioration suffered by soil szargut s reference environment and the baseline defines as thanatia will be applied to define an optimum state called optsoil instead of considering the degraded worst case as a reference we adopt a new strategy proposing an optimum soil that allows us to analyze all real soils as deviations from the optimum towards thanatia the establishment of the optsoil will provide an ideal top level by quantifying the exergy content of the optimal fertile soil selected according to the chemical concentration and comminution exergy from the dispersed state thanatia although optsoil will be established using agronomic values our objective is far from providing agronomic recommendations furthermore agricultural soil preferences depend not only on intrinsic characteristics but also on other factors such as crop selection or climate conditions on the planet there are numerous fertile soils following their location and climate thus optimum soil does not exist from an agronomical point of view that said the purpose of the definition of optsoil is to establish a general theoretical line that will allow an exergy evaluation of soil degradation fig 1 the main components that define fertile soil and a methodology to calculate its exergy are identified and developed in this study furthermore we select these components levels to establish the optsoil needed as a reference state 3 assessment of the inorganic part of the soil a great variety of interactions between the different parameters and properties take place in the soil soil parameters are categorized into physical chemical and biological properties the texture is one of the soil parameters included in the physical properties texture plays an important role in the soil as it defines soil porosity the texture also influences other physical properties such as soil aeration plant available water compaction bulk density structure in addition to physical properties texture also impacts chemical properties different textural composition influences the processes of nutrient retention soil permeability and breakdown of organic matter in addition aeration and water holding capacity influence the microorganisms biological interactions in the soil processes the interactions of texture on soil properties cause the texture to be indirectly responsible for the biogeochemical processes of the soil system therefore as a representative for physical properties texture has been selected as a key to be considered to quantify soil exergy on the other hand as a representation of chemical properties nutrients have been chosen nutrients play a very significant role in the soil because their concentration and composition influence the biogeochemical cycles of the soil and the development and growth of the plant therefore they are essential in healthy soils valero et al 2020 3 1 texture the texture is defined by the three primary particles size distribution sand silt and clay each of these primary groups has a distinct particle size according to the us department of agriculture usda classification sand is formed by particles smaller and larger than 2 mm and 0 05 mm respectively silt particles are smaller than 0 05 mm and larger than 0 002 mm clay is constituted by particles smaller than 0 002 mm the texture of each soil is determined by the ratio of the elemental particles in the soil the various properties influenced by texture can be shown for example in sandy soils these are loose and gritty systems which have few and large pores therefore these soils are often well aerated and permeable and thus they cannot provide the plants with high amounts of water and nutrients stored on the contrary clay soils are sturdy systems with many pores but smaller pore sizes as a result this kind of soil is more condensed less permeable and can be a major reservoir of water and nutrients kirkham 2014 weil and brady 2017 white 2006 although there is no optimal soil texture suitable for any crop and weather loam texture can be selected loam texture situated around in the middle of the usda nrcs 1999 texture triangle is thought to have optimum characteristics among sandy silty and clay soils fao generally loam soils blend the three elemental soil particles with equal quantities of silt and sand and smaller clay particles the clay fraction influences soil properties more significantly and more robustly such as cation exchange capacity and water retention thus the required proportion of clay is lower compared to the silt and sand fractions in loam soils water retention capacity and nutrients reservoir are more beneficial than in sandy soils while their aeration drainage and management characteristics are more advantageous than in clay soils hillel 2008 moreover loams are potently fertile soils and can be suitable for various crop types such as cereals potatoes oilseed rape and sugar beet among others finch et al 2014 based on jaja 2016 one of the best loam s textures is around 40 40 and 20 of sand silt and clay correspondingly therefore these values composed what we denoted opttext are chosen as characteristics of the texture in our optsoil 3 1 1 mineral composition of the texture to establish the mineral composition of the different textural fractions the mineral composition proposed in weil and brady 2017 was adopted as shown in table 1 table 1 indicates four major mineral categories in soil quartz primary silicate minerals secondary silicate minerals and other secondary minerals sand and silt particles are mainly composed of quartz in clay particles they have predominantly secondary silicate minerals and a minor quartz fraction the components contained in each category of minerals have been established by extensive and completely bibliographic analysis silica minerals are composed of quartz which has a course packing of the crystal structure and significant activation energy is required to modify the bonds resulting in very stable quartz and hence an inactive and non soluble mineral huang and wang 2005 primary silicate minerals combine feldspars amphiboles micas olivines and pyroxenes among other things feldspars are reservoirs of potassium and calcium macronutrients micas are the leading supplier of potassium in soils in the case of olivines minerals provide the concentration of the nutrient magnesium and iron pyroxenes amphiboles and olivines are crucial in keeping soil carbon from mineralization and losses to the atmosphere hillel 2008 huang and wang 2005 schulze and lafayette 2005 sparks 2003 weil and brady 2017 secondary silicate minerals are aluminosilicates identified as phyllosilicates hillel 2008 schulze and lafayette 2005 sparks 2003 weil and brady 2017 white 2006 other secondary minerals are typically metallic oxides carbonates and sulfates this mineral group is present in soils but generally at minor concentrations despite their minor concentration oxides are significant in chemical procedures for instance manganese oxides offer a resource of manganese vital for plants and can adsorb heavy metals schulze and lafayette 2005 sparks 2003 weil and brady 2017 we have accepted that each mineral s relative abundance in each category is related to the abundance of the minerals in the earth s crust as defined in valero and valero 2014 based on a model established in valero 2008 hence the following equation is employed eq 1 1 r e l a t i v e a b u n d a n c e m i n e r a l m a s s e a r t h s c r u s t m i n e r a l a b u n d a n c e m a s s m i n e r a l a b u n d a n c e o f t h e g r o u p 100 3 1 2 texture chemical exergy the relative abundance established was applied to determine the chemical exergy jointly with the exergy values of the minerals in the earth s crust valero and valero 2014 2 e x a m c h j k g e x c h m i n e r a l k j m o l m o l e c u l a r w e i g h t g m o l r e l a t i v e a b u n d a n c e m i n e r a l m a s s 10 6 100 as shown in the equation below the chemical exergy is calculated for the case of hematite it has a chemical exergy value of 3 30 kj kg with the data of the abundance in the earth s crust and the relative abundance in primary silicate minerals e x a b c h h e m a t i t e k j k g 17 23 k j m o l 159 68 g m o l 3 05 m a s s 1000 100 3 30 k j k g we have proceeded in this way for each mineral of each category a complete inventory of the chemical exergy and abundance in mass percentage of all the minerals studied can be seen in supplementary documents tables c 1 c 2 c 3 c 4 after obtaining the contribution of every mineral of the respective categories the chemical exergy was obtained with szargut s reference environment szargut 1989 per unit of mass values of quartz primary silicate secondary silicate and other secondary minerals is determined it could be appreciated that the secondary silicate minerals have the greatest specific chemical exergy and quartz has the most negligible specific chemical exergy value table 2 based on the data calculated in table 2 and the quantity of every category of minerals in sand silt and clay divisions table 1 every textural fractions specific chemical exergy is estimated table 3 every particle size has a specific chemical exergy value the data indicates the substantial impact and dominance of clay in the soil texture s specific chemical exergy this is so because the clay fraction has the three mineral groups with the most significant exergy values on the contrary sand and silt fractions have quartz a great and most stabilized mineral hence the most negligible chemical exergy value successively by studying the values of the three particle sizes that establish soil texture table 3 and eq 3 one can determine the soil texture s chemical exergy 3 e x ch text ure kj kg sand e x ch sand 100 silt e x ch silt 100 clay e x ch clay 100 in the case of the opttext chemical exergy will have a value of 95 26kjkg 1 e x c h t e x t u r e k j k g 40 47 32 k j k g 100 s a n d 40 107 67 k j k g 100 s i l t 20 166 33 k j k g 100 c l a y 18 93 s a n d 43 07 s i l t 33 26 c l a y 95 26 k j k g 3 1 3 texture concentration exergy as well as the chemical exergy a substance has concentration exergy because of its specific structure a substance that is higher in concentration than in the reference state can do work and thus it has concentration exergy the concentration exergy related to texture is determined by applying the relative abundance the minimum theoretical work needed to concentrate a substance from an ideal mixture of two components is given by the concentration exergy which derives from the expression of the entropy of mixing eq 4 thus the concentration exergy eq 5 of each one of the minerals that form the soil is estimated as the variation among the mineral concentration in the optsoil state and the average concentration in the earth s crust derived from the abundance in mass percentage in thanatia established in valero et al 2011 2013 2014 2011b 4 œÉ r i 1 2 x i ln x i œÉ is the minimum entropy generation of mixing xi is the concentration of a mineral or substance r is the universal gas constant 8 314 10 3kjmol 1k 1 5 e x c m i n e r a l k j m o l r t 0 l n x i 1 x i x i l n 1 x i r is the universal gas constant 8 314 10 3kjmol 1k 1 t0 is the standard ambient temperature 298 15 k xi is the concentration of a mineral or substance each mineral or substance has specific concentration exergy the variation among the concentration of the mineral in the earth s crust with the average mass concentration of xc g g 1 and the concentration of the mineral in the opttext selected with a mass concentration of xm g g 1 is the concentration exergy per unit of mol of the mineral this variation indicates the lowest exergy required to constitute and concentrate the mineral from the earth s average crust to the opttext or the reverse valero et al 2013 valero and valero 2014 6 Œ¥ e x c e x c x i x c e x c x i x m table 4 indicates xm the involvement of every category of soil minerals for the opttext designated as a reference state based on these data the estimate of the value of xm for each mineral involved in every mineral category is feasible consequently the concentration exergy per unit of mol and hence per unit of mass is estimated for all the soil minerals quartz primary silicate minerals secondary silicate minerals and other secondary minerals valero et al 2020 in the opttext the total concentration exergy value is calculated as 492 1 kjkg 1 3 1 4 texture comminution exergy considering the method reported in valero and valero 2014 2012 the specific comminution exergy for the texture elements has been determined as an example the comminution exergy per unit of mass of clay partition in hematite is 0 245 kjkg 1 which is a minor amount compared to the concentration exergy per unit of mass 23 0 kjkg 1 because of the small influence of the comminution exergy only chemical and concentration exergy will be studied to calculate the total texture exergy this agrees with what valero et al valero and valero 2014 2012 demonstrated affirming that the comminution exergy is irrelevant related to chemical and concentration exergy values 3 2 nutrients nutrients are usually categorized into two groups the macronutrients which are needed in elevated concentrations and the micronutrients required in lower concentrations but not less significant all of them are presented in table 5 additionally sodium silicon cobalt selenium and aluminum are recognized beneficial elements that promote growth but are only necessary for specific species or in particular circumstances marschner 2011 valero et al 2019 nutrients in agricultural soils undergo immediate alterations from outside forces but with an intermediary timescale of alteration due to inside procedures and exchanges these variations might happen over days to months wiesmeier et al 2018 forming helpful knowledge for the development of soil quality or degradation this work s aim is far removed from assessing all the procedures and components implicated in acquiring every nutrient or as previously discussed from providing suggestions appropriate for harvest management following this the most favorable values for determining the optsoil from several resources are chosen in most situations applying average values between the different references quoted table 5 the exergy of the nutrient is calculated by studying a combination of substances whose quantitative formula is presented in table 5 what we could name optnut the deficiency or overload of one of its elements produces injury to the plant thus it should be the concentration of every of its elements that is the significant property that can be assessed with the concentration exergy regardless of the detail of which chemical compounds are components of a provided soil 3 2 1 nutrients concentration exergy the optimal concentration level of the various nutrients optnut has been defined based on the literature review the chosen values and the cations or anions are taken into consideration for every nutrient are presented in table 5 the concentration exergy will be calculated based on the concentration of the nutrients chosen table 5 a nutrient that is more concentrated than in the reference environment has the potential to do work and hence it has concentration exergy then the variation among the concentration of the nutrient in a reference state with an average mass concentration of xc gg 1 and the optnut selected with a mass concentration of xm gg 1 is the specific concentration exergy of the nutrient eqs 7 6 this variation indicates the minor exergy required to produce and concentrate the nutrient to the optsoil or the reverse valero et al 2013 valero and valero 2014 7 e x e c n u t r i e n t k j m o l r t 0 l n x i 1 x i x i l n 1 x i the optimum concentration selected has been applied to determine the amount of each nutrient s mass fractions xm in the optsoil these mass fractions are applied to analyze the specific concentration exergy table 5 we have chosen the concentration exergy of the earth s crust as a reference state for the texture however plants nutrients are anions and cations in solution and not minerals as it occurs in the texture thus the hydrosphere is selected as a reference state for nutrients the hydrosphere contains oceans seas rivers rain ice and even atmospheric water vapor the hydrosphere s major factor is oceans that include more than 97 of all earth s water in this investigation the composition of minor elements in seawater also found in thanatia and reported in quinby hunt and turehian 1983 will be applied to calculate the mass fraction in the reference state xc the reference state concentration seawater is lower than in the optnut in certain elements therefore the value of specific concentration exergy is positive in contrast if the concentration is higher in the reference state seawater than in the optnut state the nutrient s specific concentration exergy value is negative the total concentration exergy per unit of mass estimated for the nutrients gives a value of 3684 1 kjkg 1 table 6 as it is indicated it is considerable support to the total soil exergy in the optsoil for a laborious and meticulous exergy assessment of a provided soil it would be ideal for taking into account all nutrients nevertheless in reality the evaluation of all 19 nutrients is generally unrealistic therefore we involve only the most significant and simply established nutrients in the calculations nitrogen phosphorus potassium calcium magnesium copper sodium iron manganese and zinc valero et al 2020 the specific concentration exergy estimated for the chosen nutrients resulted in 1626 3 kjkg 1 4 assessment of the soil organic matter soil organic matter som is a primary and essential component because it influences all factors of a fertile soil physical chemical and biological properties are linked to the organic matter om fraction b√ºnemann et al 2018 lal 2016 liebig and doran 1999 parisi et al 2005 fig 2 in the case of physical properties som influences the structural stability of the soil soil aggregates are made up of organic binding agents like polysaccharides and humic acids associated with polyvalent metal cations then som interacts with the soil s physical fraction contributing to the structure bulk density and porosity am√©zketa 1999 dexter et al 2008 hillel 2004 pieri 1992 schj√∏nning et al 2012 tisdall and oades 1982 weil and brady 2017 white 2006 moreover som improves the water retention in the soil due to the hydrophilic nature and the influence on the structure bauer and black 1992 haynes and naidu 1998 huntington 2003 minasny and mcbratney 2018 olness and archer 2005 however the influence and specific relationships remain unclear the content of som also influences the chemical properties such as cation exchange capacity ph and cation complexes a fraction of the cation exchange capacity is ph dependent allison 1973 in other words soil possesses cation exchange sites activated with increased ph these cation exchange sites are the carboxyl and hydroxyl functional groups among others that form om allison 1973 in particular humus represents between 50 and 90 of the cation adsorption capacity on its surface weil and brady 2017 om can also behave as a chelating agent some of the enclosed cations would be available as reservoirs for the plant weil and brady 2017 white 2006 som also influences the soil s biological properties because it is a source of energy and nutrients for soil biota differents fractions with different chemical compositions conforming som act as a nutrient reservoir for various microorganisms or fauna haynes 2005 hazelton and murphy 2017 weil and brady 2017 white 2006 regarding som exergy value j√∏rgensen in previous articles and investigations had already determined an average exergy value for detritus 18 7 kjg 1 this value corresponds to an average of green grass s energy values standing dead vegetation litter roots and green herbs j√∏rgensen 2002 2001 j√∏rgensen et al 2004 j√∏rgensen considered the approximation that detritus represent the total som equalizing their exergy value som is a resource with a complex and heterogeneous composition it is commonly accepted that som is composed of rapid turnover carbon defined as labile organic carbon and protected or slow turnover carbon defined as hummus adhya et al 2017 campbell 2008 gregory and nortcliff 2013 haynes 2005 lal 2017 murphy 2014 weil and brady 2017 detritus constitutes a part of the labile organic matter fraction not the total of som consequently the approximation suggested by j√∏rgensen in which the detritus exergy value is considered similar to the total exergy of som is going to be revised firstly according to the updated knowledge of the composition of som an average composition will be selected then an experimental model will be used to calculate its exergy content 4 1 composition of som nowadays due to the significant development and progress of new analytical techniques such as electron microscopic analytical pyrolisis ir 13 c nmr x ray spectroscopic it has been possible to study the composition of om in greater detail jansen et al 1996 schulten and schnitzer 1997 1995 in this way a molecular representation of som which contained 3 of water was firstly proposed by schulten and schnitzer 1997 and subsequently improved by the same authors schulten and leinweber 2000 also considering the molecule of total humic substance schulten and schnitzer 1995 the molecule representing som contains one trapped trisaccharide one hexapeptide and 12 water molecules one of which is protonated then the elemental formula of this complex is c349h401n26o173s with a molecular weight of 7760 16 gmol 1 the hexapeptide is aspglyargglualalys with an elemental composition of c26h46o10n10 it is chosen because it is formed by the amino acids usually found in soils the trisaccharide selected as an example of a sugar molecule is cellotriose cellotriose is considered as a cellulose subunit presented in som and has the elemental composition of c18h32o16 table 7 authors like weil and brady 2017 or white 2006 exposed the ranges in which the elemental chemical composition of humus may be found these ranges are in agreement with the chemical formula for humic substances proposed by schulten and leinweber however other authors disagree with the schulten and leinweber model of som because it can not explain some of the analytical data obtained mao et al 2000 piccolo 2002 this is due to the heterogeneity of the om the soil variety and environmental conditions despite that the molecule proposed by schulten and leinweber 2000 has been selected as a representation of the composition of som in any given soil to calculate a representing value for exergy of som 4 2 organic matter exergy value like texture om is a substance that can do work and hence it has an exergy value j√∏rgensen et al 2004 in this way om s exergy will be calculated through its higher heating value hhv the free energy of om is assumed to be the same as its hhv like biomass and municipal solid waste the hhv of om reveals the energy it possesses inside in a combustion process it is released and converted into heat energy when all the water formed by combustion is in liquid form erol et al 2010 several empirical models and linear regressions in the literature estimate the hhv of biomass and municipal solid wastes alves et al 2018 amen et al 2020 bagheri et al 2019 erol et al 2010 friedl et al 2005 kathiravale et al 2003 khuriati et al 2017 2015 komilis et al 2012 liu et al 1996 nzihou et al 2014 sheng and azevedo 2005 yin 2011 the regressions have been developed from the elemental composition ultimate components physical composition and the ash moisture content etc of solid waste proximate analysis alves et al 2018 amen et al 2020 bagheri et al 2019 erol et al 2010 friedl et al 2005 kathiravale et al 2003 khuriati et al 2017 2015 komilis et al 2012 liu et al 1996 nzihou et al 2014 sheng and azevedo 2005 yin 2011 municipal solid wastes and biomass are compounds with a similar chemical composition to om then the hhv of om will be estimated with the empirical models as a function of the elemental composition the more common models based on ultimate analysis have been studied due to the great amplitude of equations models and studies on the higher heating value determination corbitt 1989 kathiravale et al 2003 komilis et al 2012 tchobanoglous et al 1993 among these equations and models the most widely and reported in the bibliography are those of dulong the dulong model is suitable for biomass while the modified dulong model is suitable for biomass and municipal solid waste all the models and linear regressions used to estimate the hhv are empirical and always include an experimental error likewise the models developed and improved in recent years have been compared to dulong s equation and the difference was insignificant kathiravale et al 2003 in this way modified dulong s model is selected due to its greater versatility concerning the material s composition and origin then the hhv of the som is calculated using the total chemical formula previously selected table 8 hence we propose that the exergy of som is 19 406 12kjkg 1 this value seems slightly higher than that offered by j√∏rgensen 18 700 kj kg confirming that his approximation is accurate and reliable 4 3 organic matter optimal content optsom an optimal level or range of som concentration optsom in the agricultural system is essential for studying soil quality for years an optimal or ideal value for the content of som has been investigated however as seen in the previous sections om influences and modifies many soil parameters this is why it has not been possible to establish any standard range loveland and webb 2003 consequently the optimal levels will depend on the soil properties considered in the different studies in crop production a decrease of som produces an insufficient nutrient reservoir 84 85 if the organic carbon oc content is less than 2 in soil physical properties the soil structure is vulnerable to decline greenland et al 1975 after all spink et al 2010 concluded that a concentration of soil organic carbon soc of 2 should be considered as a precautionary threshold above this value no action is required nevertheless below 2 of soc soils may have a poor structural condition and more specific studies should be carried out to determine their agronomic conditions the 2 threshold in oc has been subsequently used in other studies feiza et al 2011 haynes 2005 mukherjee and lal 2014 olaya abril et al 2017 hence in the definition of optsoil as a reference soil for assessing soil fertility and degradation an optimum value for oc of 2 will be selected although there are studies where lower om values do not generate production changes johnston 1991 kemper and koch 1966 k√∂rschens et al 1998 loveland and webb 2003 the established limit is optimal both in production also related to nutrients and in the soil structural aspect commonly since som is estimated to contain 58 of oc the relation between organic matter and organic carbon is om oc 1 724kgkg 1 in this research the chemical formula employed for som enclosed 54 of oc thus the ratio between organic matter and organic carbon is slightly different eq 8 8 s o m 1 851 s o c the value is considered optimal soc 2 and eq 10 allows obtaining the optsom the option is 3 7 this value will be the om concentration in the optsoil 9 s o m 1 851 2 3 7 thus to know the contribution of om in the optsoil considering the optsom selected 3 7 and the proportions of the topsoil chosen depth 0 2 m and bulk density 1400 kg m3 10 e x c h o m 19 406 12 k j k g 3 7 100 1400 k g m 3 10 000 m 2 h a 0 2 m 2 01 10 9 k j h a in conclusion the optsom suggested in this paper contributes with a chemical exergy value of 2 01 109 kjha 1 or 48 0 toe ha 1 tonne of oil equivalent hectare 1 to the total exergy of the optsoil 5 results and validation in the previous sections the methodology for calculating the exergy values of the inorganic fraction of the soil represented by texture and nutrients and the organic fraction represented by som is detailed furthermore the different components defined values conforming to the reference state selected as optsoil are given thus in this section firstly the exergy value of the optsoil is summarised and discussed then it is compared with the exergy values obtained for three soils determined experimentally table 9 shown the exergy values calculate for the previously defined optsoil considering a density of 1400 kg m 3 and a depth of 20 cm the exergy value of the optsoil calculate with the developed methodology as a sum of the contributions of opttext optnut and optsom defined shows an exergy value of 196 1toe ha 1 the total texture specific exergy estimated is 39 3 toe ha 1 as it is shown the concentration exergy contribution is higher than the chemical nutrients are the ones that offer the most significant contribution equivalent to 108 7 toe ha 1 which represents 55 of the total the som fraction represents a 48 0 toe ha 1 value equivalent to 25 of the total we validated the developed exergy methodology through the sampling of three soils in a greenhouse pilot test samples of 2 to 3 kg were taken homogeneously in a zig zag pattern at different points of the field and at a depth of 30 cm sampling was carried out with a shovel digging a small v shaped hole 20 to 30 cm deep all samples were mixed and prepared for the laboratory by sieving to eliminate any remains of previous harvests soil analysis to determine texture nutrients and om was performed the greenhouse pilot testing design integrated into each homogeneous block the three types of soil under study a total of 10 homogeneous distributed pots were prepared for each soil experimental conditions were optimal minimizing external influences and weather conditions allowing the soil s impact as a whole to be evaluated lactuca sativa was planted and the average weight of leaves and stems and roots were determined based on the laboratory soil analysis data each soil was evaluated using the exergy methodology developed in this study when a value is greater than the optsoil threshold the excess is not considered values obtained are shown in table 10 6 discussion as explained in previous sections soils are complex systems in which many different elements interact thus the three components opttext optnut and optsom are not independent for example the texture influences and affects the soil nutrients due to the interactions between the minerals that form the texture and nutrient ions elemental particles om also interacts with nutrients through mineralization processes and with texture as om conforms soil aggregates consequently the independent study of the different components is useful to assign an exergy value to the soil but fertile soils from an agronomical point of view cannot be understood interpreting each part independently but as a whole fig 3 shows optsoil and compares the specific exergy values obtained for different soils under analysis in all the cases the optsoil shows higher values than the studied soils soil 1 results in total exergy of 170 8 toe ha 1 it is the closest one to the optsoil value 196 1 toe ha 1 soil 2 and 3 show a slight difference in their total exergy value 130 35 and 120 16 toe ha 1 respectively due mainly to som soil 1 showed a better crop yield with a higher dry matter in leaves stems and roots this corresponds with the higher value in exergy obtained in soil 3 the dry matter obtained is slightly higher than soil 2 despite the lower exergy value fig 4 however in these two cases the values in both parameters exergy and yield are so close that the differences cannot be considered significant this confirms that the methodology to calculate the exergy value of fertile soils is consistent with agronomic performances that said much more data would be needed to establish a relation between the exergy of soil and its yield including the use of different crops 7 conclusions exergy is a useful tool to assess the complex problem of evaluating soil fertility or quality using szargut and thanatia as references a methodology to calculate the exergy contained infertile soils due to their inorganic and organic components has been developed in this work to do that the establishment of an optional is proposed the parameters considered to form a fertile soil are texture opttext nutrients optnut and organic matter optsom as a result of the methodology developed in the optsoil nutrients and som specific exergy are the predominant contributors therefore as the main advantage experimental validation has shown that the exergy values obtained agree with agronomic performance and showed the quality and quantity of energy contained in soil however exergy does not value and consider the interactions between these factors or the influences on the rest of the parameters and processes in the soil and slight differences between soils in agronomic yield cannot be explained when exergy values are very close despite that this methodology s development establishes the ground to assess the value of fertile soils using exergy as a unifying tool soil texture is highly variable across the globe and is difficult to amend the only thing that can be done in practical terms is to improve aeration and increase its water content according to its porosity however its energy value is relatively stable for different concentrations of silt sand and clay and lower than that of nutrients and in turn lower than that of organic matter however the latter two can be modified at a lower cost this means that one can select different opttext without significant changes in their exergy value but take optnut and optsom as a universal basis to analyze the level of degradation of a real soil against the optimum following these ideas there is no universal optimum soil but soils with a great multiplicity of textures nutrients and organic matter soils are pretty edaphic diverse however from the point of view of exergy we have seen that all textures hardly differ from each other what soil degradation depends on most is the lack of nutrients and organic matter to feed its microbiome these soil components are essential for all living things this idea can introduce an ideal fertile crust made of optinut and optisom invariant and independent of the different local textures but not independent of their water content and aeration let us call this imaginary crust copiously fertile pristinia pristinia from latin pristine former early original meaning unspoiled untouched pure pristinia 2021 as opposed to thanatia a dead state referring to abiotic resources thus any real agricultural soil will be an intermediate soil between pristinia and thantia unfortunately fertile soils take thousands of years to regenerate and humans are accelerating their degradation to thanatia the dialog between pristinia and thanatia will serve to quantitatively diagnose an assessment of all the concepts by which soil is degraded using exergy kwh as the universal unit of measurement from here we will be able to apply thermo economic theory to accurately assess the exergy replacement cost kwh or of any soil degraded by multiple effects both by excess or lack of nutrients we are also exploring the possibility of including the biotic part of the soil in the exergy methodology due to the numerous functions soil microorganisms play a relevant role in soil fertility which is currently a priority focus of soil science research credit authorship contribution statement antonio valero conceptualization methodology writing review editing supervision b√°rbara palacino methodology validation investigation writing original draft writing review editing sonia ascaso methodology validation investigation writing original draft writing review editing alicia valero conceptualization methodology writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this paper has received funding from feder fund the ministry of science innovation and universities under the project fertiligencia rtc 2017 5887 5 and project reset pid2020 116851rb i00 special thanks are owed to fertinagro biotech particularly to sergio atares for the project support and maria ferrer for collection and preparation of the soil samples also thanks to manuel marquez raquel anadon and sandra ortega from pctad for the greenhouse tests supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2021 109802 appendix supplementary materials image application 1 
24498,soil degradation affecting around 38 of the world s cropland threatens the global food supply due to the soil s complexity the measure of soil degradation that involves the loss of soil fertility due to crop system management processes represents an unsolved problem exergy is a property with the potential to be used in soil fertility and or degradation analysis a methodology to determine the exergy value fenced in a fertile soil due to its inorganic and organic components is established in this study and will be applied to evaluate soil fertility degradation and quality as a first step the exergy of perfect topsoil with optimum characteristics called optsoil is determined the optsoil is established by agronomic expertise and will allow establishing a general theoretical reference suitable to execute exergy assessments of soils and compare the degradation grade of any soil concerning the best possible consequently we introduce a perfect fertile planetary crust made of optnut and optsom invariant and independent of the different local textures but not independent of their water content and aeration we call this imaginary crust copiously fertile pristinia as opposed to thanatia a dead state referring to abiotic resources thus any real agricultural soil will be an intermediate soil between pristinia and thanatia this idea might serve to quantitatively diagnose an assessment of all the concepts by which soil is degraded the methodology has been validated through laboratory agronomic tests for different soils concluding that exergy is a rigorous indicator to measure topsoil fertility keywords exergy soil fertility soil degradation thanatia pristinia sustainability abbreviations fao food and agricultural organization som soil organic matter om organic matter soc soil organic carbon oc organic carbon hhv higher heating value optsoil optimum topsoil established opttext optimum topsoil texture optnut optimum topsoil nutrients content optsom optimum topsoil organic matter content 1 introduction valero and valero 2014 valero et al 2011a developed a reference baseline to evaluate the planet s abiotic resources in previous studies this reference baseline was called thanatia and represented a degraded planet where all resources would have been extracted and dispersed throughout the earth s crust it is composed of a degraded atmosphere hydrosphere and upper continental crust particularly for the upper continental crust it represents the starting point to assess the exergy of mineral capital on earth because it provides the concentration of the around 300 most abundant elements found in the earth s crust the degradation of the mineral capital is an important source of concern since the transition to low carbon technologies will require a considerable amount and variety of raw materials some of which are scarce and with serious supply problems calvo et al 2016 valero et al 2018 exergy is defined as a thermodynamic property that measures the quantity and quality of any resource and exergoecology is a discipline whose objective is to evaluate natural resources through the exergy property valero and valero 2014 exergoecology has been widely developed in the evaluation of water resources opening the branch called physical hydronomics and mineral resources with the branch physical geonomics this study the aims to develop a new and innovative application of exergoecology for the exergy assessment of soil fertility like water and minerals the soil is a valuable and limited natural resource the irreversible degradation of this resource is a problem and a challenge for securing the world s food supply and the production of biomass and biofuels for the future maintaining the quality and fertility of soils is therefore a global priority the sustainability of the agroecosystems is also an important issue considering that the global population is expected to continue growing reaching almost 11 to 13 billion in 2100 united nations 2019 consequently food demand will continue to grow and is expected to be satisfied for example by increasing about 49 percent in the agricultural production required by 2050 food and agriculture organization of the united nations 2019 crop production yield has been raised employing intensive agriculture based on high inputs of inorganic fertilizers and pesticides resulting in severe environmental impacts erosion and soil quality loss the agricultural sector causes approximately 25 percent of the global greenhouse gasses food and agriculture organization of the united nations 2019 besides degradation caused in soils threatens around 40 percent of the land area in europe it is estimated that there are 12 million hectares affected by erosion which currently generates losses of 1 250 million euros per year g√∂rlach et al 2004 the continued degradation of soil fertility due to human actions threatens the sustainability on earth that will turn into thanatia as it has been done for the mineral capital one can assess soil fertility through exergy however for an exergy evaluation of soil the thanatia model is not enough since it does not consider the specific attributes that make a given soil fertile therefore it is necessary to establish an adequate methodology that serves as a starting point to evaluate soil fertility fao defines soil fertility as the capacity of the soil to support the growth of plants on a sustained basis yielding quantities of expected products that are close to the known potential gachene and kimaru 2003 soil science society of america defines soil quality as the capacity of a specific kind of soil to function within natural or managed ecosystem boundaries to sustain plant and animal productivity karlen et al 1997 soil quality can be considered for agricultural and natural ecosystems where the main objectives are to maintain environmental quality and biodiversity conservation the decline in soil quality caused by its improper use or poor management usually for agricultural industrial or urban purposes is defined as soil degradation this study focuses on agricultural soils agricultural soils are complex systems formed by physical chemical and biological properties interacting with each other due to this complexity a unified approach does not exist to evaluate soil fertility or soil quality despite the high number of studies performed arshad and martin 2002 the incapacity of using a single indicator in the characterization and evaluation of a soil is one of the main and most important disadvantages that can be found in the study of the soil system bongiorno et al 2019 b√ºnemann et al 2018 dexter 2004 johannes et al 2019 due to the complexity of soil and a large number of factors and parameters that interact in the system studies have been found in the literature that focuses on determining a minimum data set mds of soil characteristics with the most significant effect on quality garrigues et al 2012 reynolds et al 2009 2008 thoumazeau et al 2019 xu et al 2017 then this study use exergy as a unifying tool to assess soil fertility and degradation to lay the foundations of the fourth dimension of thanatia soils and its fertility assessment 2 definition of an optimum soil in any exergy evaluation it is necessary first to define a reference state usually a reference state is contemplated a dead figure the most degraded state with the minimum exergy valero et al 2011 in soil our initial endeavor has been to determine the minimum attributes above which the system is inefficient and a plant s growth is not possible valero et al 2019 nevertheless the implementation of an optimum level is more appropriate in the case of fertile soils study in this way to assess the degradation and deterioration suffered by soil szargut s reference environment and the baseline defines as thanatia will be applied to define an optimum state called optsoil instead of considering the degraded worst case as a reference we adopt a new strategy proposing an optimum soil that allows us to analyze all real soils as deviations from the optimum towards thanatia the establishment of the optsoil will provide an ideal top level by quantifying the exergy content of the optimal fertile soil selected according to the chemical concentration and comminution exergy from the dispersed state thanatia although optsoil will be established using agronomic values our objective is far from providing agronomic recommendations furthermore agricultural soil preferences depend not only on intrinsic characteristics but also on other factors such as crop selection or climate conditions on the planet there are numerous fertile soils following their location and climate thus optimum soil does not exist from an agronomical point of view that said the purpose of the definition of optsoil is to establish a general theoretical line that will allow an exergy evaluation of soil degradation fig 1 the main components that define fertile soil and a methodology to calculate its exergy are identified and developed in this study furthermore we select these components levels to establish the optsoil needed as a reference state 3 assessment of the inorganic part of the soil a great variety of interactions between the different parameters and properties take place in the soil soil parameters are categorized into physical chemical and biological properties the texture is one of the soil parameters included in the physical properties texture plays an important role in the soil as it defines soil porosity the texture also influences other physical properties such as soil aeration plant available water compaction bulk density structure in addition to physical properties texture also impacts chemical properties different textural composition influences the processes of nutrient retention soil permeability and breakdown of organic matter in addition aeration and water holding capacity influence the microorganisms biological interactions in the soil processes the interactions of texture on soil properties cause the texture to be indirectly responsible for the biogeochemical processes of the soil system therefore as a representative for physical properties texture has been selected as a key to be considered to quantify soil exergy on the other hand as a representation of chemical properties nutrients have been chosen nutrients play a very significant role in the soil because their concentration and composition influence the biogeochemical cycles of the soil and the development and growth of the plant therefore they are essential in healthy soils valero et al 2020 3 1 texture the texture is defined by the three primary particles size distribution sand silt and clay each of these primary groups has a distinct particle size according to the us department of agriculture usda classification sand is formed by particles smaller and larger than 2 mm and 0 05 mm respectively silt particles are smaller than 0 05 mm and larger than 0 002 mm clay is constituted by particles smaller than 0 002 mm the texture of each soil is determined by the ratio of the elemental particles in the soil the various properties influenced by texture can be shown for example in sandy soils these are loose and gritty systems which have few and large pores therefore these soils are often well aerated and permeable and thus they cannot provide the plants with high amounts of water and nutrients stored on the contrary clay soils are sturdy systems with many pores but smaller pore sizes as a result this kind of soil is more condensed less permeable and can be a major reservoir of water and nutrients kirkham 2014 weil and brady 2017 white 2006 although there is no optimal soil texture suitable for any crop and weather loam texture can be selected loam texture situated around in the middle of the usda nrcs 1999 texture triangle is thought to have optimum characteristics among sandy silty and clay soils fao generally loam soils blend the three elemental soil particles with equal quantities of silt and sand and smaller clay particles the clay fraction influences soil properties more significantly and more robustly such as cation exchange capacity and water retention thus the required proportion of clay is lower compared to the silt and sand fractions in loam soils water retention capacity and nutrients reservoir are more beneficial than in sandy soils while their aeration drainage and management characteristics are more advantageous than in clay soils hillel 2008 moreover loams are potently fertile soils and can be suitable for various crop types such as cereals potatoes oilseed rape and sugar beet among others finch et al 2014 based on jaja 2016 one of the best loam s textures is around 40 40 and 20 of sand silt and clay correspondingly therefore these values composed what we denoted opttext are chosen as characteristics of the texture in our optsoil 3 1 1 mineral composition of the texture to establish the mineral composition of the different textural fractions the mineral composition proposed in weil and brady 2017 was adopted as shown in table 1 table 1 indicates four major mineral categories in soil quartz primary silicate minerals secondary silicate minerals and other secondary minerals sand and silt particles are mainly composed of quartz in clay particles they have predominantly secondary silicate minerals and a minor quartz fraction the components contained in each category of minerals have been established by extensive and completely bibliographic analysis silica minerals are composed of quartz which has a course packing of the crystal structure and significant activation energy is required to modify the bonds resulting in very stable quartz and hence an inactive and non soluble mineral huang and wang 2005 primary silicate minerals combine feldspars amphiboles micas olivines and pyroxenes among other things feldspars are reservoirs of potassium and calcium macronutrients micas are the leading supplier of potassium in soils in the case of olivines minerals provide the concentration of the nutrient magnesium and iron pyroxenes amphiboles and olivines are crucial in keeping soil carbon from mineralization and losses to the atmosphere hillel 2008 huang and wang 2005 schulze and lafayette 2005 sparks 2003 weil and brady 2017 secondary silicate minerals are aluminosilicates identified as phyllosilicates hillel 2008 schulze and lafayette 2005 sparks 2003 weil and brady 2017 white 2006 other secondary minerals are typically metallic oxides carbonates and sulfates this mineral group is present in soils but generally at minor concentrations despite their minor concentration oxides are significant in chemical procedures for instance manganese oxides offer a resource of manganese vital for plants and can adsorb heavy metals schulze and lafayette 2005 sparks 2003 weil and brady 2017 we have accepted that each mineral s relative abundance in each category is related to the abundance of the minerals in the earth s crust as defined in valero and valero 2014 based on a model established in valero 2008 hence the following equation is employed eq 1 1 r e l a t i v e a b u n d a n c e m i n e r a l m a s s e a r t h s c r u s t m i n e r a l a b u n d a n c e m a s s m i n e r a l a b u n d a n c e o f t h e g r o u p 100 3 1 2 texture chemical exergy the relative abundance established was applied to determine the chemical exergy jointly with the exergy values of the minerals in the earth s crust valero and valero 2014 2 e x a m c h j k g e x c h m i n e r a l k j m o l m o l e c u l a r w e i g h t g m o l r e l a t i v e a b u n d a n c e m i n e r a l m a s s 10 6 100 as shown in the equation below the chemical exergy is calculated for the case of hematite it has a chemical exergy value of 3 30 kj kg with the data of the abundance in the earth s crust and the relative abundance in primary silicate minerals e x a b c h h e m a t i t e k j k g 17 23 k j m o l 159 68 g m o l 3 05 m a s s 1000 100 3 30 k j k g we have proceeded in this way for each mineral of each category a complete inventory of the chemical exergy and abundance in mass percentage of all the minerals studied can be seen in supplementary documents tables c 1 c 2 c 3 c 4 after obtaining the contribution of every mineral of the respective categories the chemical exergy was obtained with szargut s reference environment szargut 1989 per unit of mass values of quartz primary silicate secondary silicate and other secondary minerals is determined it could be appreciated that the secondary silicate minerals have the greatest specific chemical exergy and quartz has the most negligible specific chemical exergy value table 2 based on the data calculated in table 2 and the quantity of every category of minerals in sand silt and clay divisions table 1 every textural fractions specific chemical exergy is estimated table 3 every particle size has a specific chemical exergy value the data indicates the substantial impact and dominance of clay in the soil texture s specific chemical exergy this is so because the clay fraction has the three mineral groups with the most significant exergy values on the contrary sand and silt fractions have quartz a great and most stabilized mineral hence the most negligible chemical exergy value successively by studying the values of the three particle sizes that establish soil texture table 3 and eq 3 one can determine the soil texture s chemical exergy 3 e x ch text ure kj kg sand e x ch sand 100 silt e x ch silt 100 clay e x ch clay 100 in the case of the opttext chemical exergy will have a value of 95 26kjkg 1 e x c h t e x t u r e k j k g 40 47 32 k j k g 100 s a n d 40 107 67 k j k g 100 s i l t 20 166 33 k j k g 100 c l a y 18 93 s a n d 43 07 s i l t 33 26 c l a y 95 26 k j k g 3 1 3 texture concentration exergy as well as the chemical exergy a substance has concentration exergy because of its specific structure a substance that is higher in concentration than in the reference state can do work and thus it has concentration exergy the concentration exergy related to texture is determined by applying the relative abundance the minimum theoretical work needed to concentrate a substance from an ideal mixture of two components is given by the concentration exergy which derives from the expression of the entropy of mixing eq 4 thus the concentration exergy eq 5 of each one of the minerals that form the soil is estimated as the variation among the mineral concentration in the optsoil state and the average concentration in the earth s crust derived from the abundance in mass percentage in thanatia established in valero et al 2011 2013 2014 2011b 4 œÉ r i 1 2 x i ln x i œÉ is the minimum entropy generation of mixing xi is the concentration of a mineral or substance r is the universal gas constant 8 314 10 3kjmol 1k 1 5 e x c m i n e r a l k j m o l r t 0 l n x i 1 x i x i l n 1 x i r is the universal gas constant 8 314 10 3kjmol 1k 1 t0 is the standard ambient temperature 298 15 k xi is the concentration of a mineral or substance each mineral or substance has specific concentration exergy the variation among the concentration of the mineral in the earth s crust with the average mass concentration of xc g g 1 and the concentration of the mineral in the opttext selected with a mass concentration of xm g g 1 is the concentration exergy per unit of mol of the mineral this variation indicates the lowest exergy required to constitute and concentrate the mineral from the earth s average crust to the opttext or the reverse valero et al 2013 valero and valero 2014 6 Œ¥ e x c e x c x i x c e x c x i x m table 4 indicates xm the involvement of every category of soil minerals for the opttext designated as a reference state based on these data the estimate of the value of xm for each mineral involved in every mineral category is feasible consequently the concentration exergy per unit of mol and hence per unit of mass is estimated for all the soil minerals quartz primary silicate minerals secondary silicate minerals and other secondary minerals valero et al 2020 in the opttext the total concentration exergy value is calculated as 492 1 kjkg 1 3 1 4 texture comminution exergy considering the method reported in valero and valero 2014 2012 the specific comminution exergy for the texture elements has been determined as an example the comminution exergy per unit of mass of clay partition in hematite is 0 245 kjkg 1 which is a minor amount compared to the concentration exergy per unit of mass 23 0 kjkg 1 because of the small influence of the comminution exergy only chemical and concentration exergy will be studied to calculate the total texture exergy this agrees with what valero et al valero and valero 2014 2012 demonstrated affirming that the comminution exergy is irrelevant related to chemical and concentration exergy values 3 2 nutrients nutrients are usually categorized into two groups the macronutrients which are needed in elevated concentrations and the micronutrients required in lower concentrations but not less significant all of them are presented in table 5 additionally sodium silicon cobalt selenium and aluminum are recognized beneficial elements that promote growth but are only necessary for specific species or in particular circumstances marschner 2011 valero et al 2019 nutrients in agricultural soils undergo immediate alterations from outside forces but with an intermediary timescale of alteration due to inside procedures and exchanges these variations might happen over days to months wiesmeier et al 2018 forming helpful knowledge for the development of soil quality or degradation this work s aim is far removed from assessing all the procedures and components implicated in acquiring every nutrient or as previously discussed from providing suggestions appropriate for harvest management following this the most favorable values for determining the optsoil from several resources are chosen in most situations applying average values between the different references quoted table 5 the exergy of the nutrient is calculated by studying a combination of substances whose quantitative formula is presented in table 5 what we could name optnut the deficiency or overload of one of its elements produces injury to the plant thus it should be the concentration of every of its elements that is the significant property that can be assessed with the concentration exergy regardless of the detail of which chemical compounds are components of a provided soil 3 2 1 nutrients concentration exergy the optimal concentration level of the various nutrients optnut has been defined based on the literature review the chosen values and the cations or anions are taken into consideration for every nutrient are presented in table 5 the concentration exergy will be calculated based on the concentration of the nutrients chosen table 5 a nutrient that is more concentrated than in the reference environment has the potential to do work and hence it has concentration exergy then the variation among the concentration of the nutrient in a reference state with an average mass concentration of xc gg 1 and the optnut selected with a mass concentration of xm gg 1 is the specific concentration exergy of the nutrient eqs 7 6 this variation indicates the minor exergy required to produce and concentrate the nutrient to the optsoil or the reverse valero et al 2013 valero and valero 2014 7 e x e c n u t r i e n t k j m o l r t 0 l n x i 1 x i x i l n 1 x i the optimum concentration selected has been applied to determine the amount of each nutrient s mass fractions xm in the optsoil these mass fractions are applied to analyze the specific concentration exergy table 5 we have chosen the concentration exergy of the earth s crust as a reference state for the texture however plants nutrients are anions and cations in solution and not minerals as it occurs in the texture thus the hydrosphere is selected as a reference state for nutrients the hydrosphere contains oceans seas rivers rain ice and even atmospheric water vapor the hydrosphere s major factor is oceans that include more than 97 of all earth s water in this investigation the composition of minor elements in seawater also found in thanatia and reported in quinby hunt and turehian 1983 will be applied to calculate the mass fraction in the reference state xc the reference state concentration seawater is lower than in the optnut in certain elements therefore the value of specific concentration exergy is positive in contrast if the concentration is higher in the reference state seawater than in the optnut state the nutrient s specific concentration exergy value is negative the total concentration exergy per unit of mass estimated for the nutrients gives a value of 3684 1 kjkg 1 table 6 as it is indicated it is considerable support to the total soil exergy in the optsoil for a laborious and meticulous exergy assessment of a provided soil it would be ideal for taking into account all nutrients nevertheless in reality the evaluation of all 19 nutrients is generally unrealistic therefore we involve only the most significant and simply established nutrients in the calculations nitrogen phosphorus potassium calcium magnesium copper sodium iron manganese and zinc valero et al 2020 the specific concentration exergy estimated for the chosen nutrients resulted in 1626 3 kjkg 1 4 assessment of the soil organic matter soil organic matter som is a primary and essential component because it influences all factors of a fertile soil physical chemical and biological properties are linked to the organic matter om fraction b√ºnemann et al 2018 lal 2016 liebig and doran 1999 parisi et al 2005 fig 2 in the case of physical properties som influences the structural stability of the soil soil aggregates are made up of organic binding agents like polysaccharides and humic acids associated with polyvalent metal cations then som interacts with the soil s physical fraction contributing to the structure bulk density and porosity am√©zketa 1999 dexter et al 2008 hillel 2004 pieri 1992 schj√∏nning et al 2012 tisdall and oades 1982 weil and brady 2017 white 2006 moreover som improves the water retention in the soil due to the hydrophilic nature and the influence on the structure bauer and black 1992 haynes and naidu 1998 huntington 2003 minasny and mcbratney 2018 olness and archer 2005 however the influence and specific relationships remain unclear the content of som also influences the chemical properties such as cation exchange capacity ph and cation complexes a fraction of the cation exchange capacity is ph dependent allison 1973 in other words soil possesses cation exchange sites activated with increased ph these cation exchange sites are the carboxyl and hydroxyl functional groups among others that form om allison 1973 in particular humus represents between 50 and 90 of the cation adsorption capacity on its surface weil and brady 2017 om can also behave as a chelating agent some of the enclosed cations would be available as reservoirs for the plant weil and brady 2017 white 2006 som also influences the soil s biological properties because it is a source of energy and nutrients for soil biota differents fractions with different chemical compositions conforming som act as a nutrient reservoir for various microorganisms or fauna haynes 2005 hazelton and murphy 2017 weil and brady 2017 white 2006 regarding som exergy value j√∏rgensen in previous articles and investigations had already determined an average exergy value for detritus 18 7 kjg 1 this value corresponds to an average of green grass s energy values standing dead vegetation litter roots and green herbs j√∏rgensen 2002 2001 j√∏rgensen et al 2004 j√∏rgensen considered the approximation that detritus represent the total som equalizing their exergy value som is a resource with a complex and heterogeneous composition it is commonly accepted that som is composed of rapid turnover carbon defined as labile organic carbon and protected or slow turnover carbon defined as hummus adhya et al 2017 campbell 2008 gregory and nortcliff 2013 haynes 2005 lal 2017 murphy 2014 weil and brady 2017 detritus constitutes a part of the labile organic matter fraction not the total of som consequently the approximation suggested by j√∏rgensen in which the detritus exergy value is considered similar to the total exergy of som is going to be revised firstly according to the updated knowledge of the composition of som an average composition will be selected then an experimental model will be used to calculate its exergy content 4 1 composition of som nowadays due to the significant development and progress of new analytical techniques such as electron microscopic analytical pyrolisis ir 13 c nmr x ray spectroscopic it has been possible to study the composition of om in greater detail jansen et al 1996 schulten and schnitzer 1997 1995 in this way a molecular representation of som which contained 3 of water was firstly proposed by schulten and schnitzer 1997 and subsequently improved by the same authors schulten and leinweber 2000 also considering the molecule of total humic substance schulten and schnitzer 1995 the molecule representing som contains one trapped trisaccharide one hexapeptide and 12 water molecules one of which is protonated then the elemental formula of this complex is c349h401n26o173s with a molecular weight of 7760 16 gmol 1 the hexapeptide is aspglyargglualalys with an elemental composition of c26h46o10n10 it is chosen because it is formed by the amino acids usually found in soils the trisaccharide selected as an example of a sugar molecule is cellotriose cellotriose is considered as a cellulose subunit presented in som and has the elemental composition of c18h32o16 table 7 authors like weil and brady 2017 or white 2006 exposed the ranges in which the elemental chemical composition of humus may be found these ranges are in agreement with the chemical formula for humic substances proposed by schulten and leinweber however other authors disagree with the schulten and leinweber model of som because it can not explain some of the analytical data obtained mao et al 2000 piccolo 2002 this is due to the heterogeneity of the om the soil variety and environmental conditions despite that the molecule proposed by schulten and leinweber 2000 has been selected as a representation of the composition of som in any given soil to calculate a representing value for exergy of som 4 2 organic matter exergy value like texture om is a substance that can do work and hence it has an exergy value j√∏rgensen et al 2004 in this way om s exergy will be calculated through its higher heating value hhv the free energy of om is assumed to be the same as its hhv like biomass and municipal solid waste the hhv of om reveals the energy it possesses inside in a combustion process it is released and converted into heat energy when all the water formed by combustion is in liquid form erol et al 2010 several empirical models and linear regressions in the literature estimate the hhv of biomass and municipal solid wastes alves et al 2018 amen et al 2020 bagheri et al 2019 erol et al 2010 friedl et al 2005 kathiravale et al 2003 khuriati et al 2017 2015 komilis et al 2012 liu et al 1996 nzihou et al 2014 sheng and azevedo 2005 yin 2011 the regressions have been developed from the elemental composition ultimate components physical composition and the ash moisture content etc of solid waste proximate analysis alves et al 2018 amen et al 2020 bagheri et al 2019 erol et al 2010 friedl et al 2005 kathiravale et al 2003 khuriati et al 2017 2015 komilis et al 2012 liu et al 1996 nzihou et al 2014 sheng and azevedo 2005 yin 2011 municipal solid wastes and biomass are compounds with a similar chemical composition to om then the hhv of om will be estimated with the empirical models as a function of the elemental composition the more common models based on ultimate analysis have been studied due to the great amplitude of equations models and studies on the higher heating value determination corbitt 1989 kathiravale et al 2003 komilis et al 2012 tchobanoglous et al 1993 among these equations and models the most widely and reported in the bibliography are those of dulong the dulong model is suitable for biomass while the modified dulong model is suitable for biomass and municipal solid waste all the models and linear regressions used to estimate the hhv are empirical and always include an experimental error likewise the models developed and improved in recent years have been compared to dulong s equation and the difference was insignificant kathiravale et al 2003 in this way modified dulong s model is selected due to its greater versatility concerning the material s composition and origin then the hhv of the som is calculated using the total chemical formula previously selected table 8 hence we propose that the exergy of som is 19 406 12kjkg 1 this value seems slightly higher than that offered by j√∏rgensen 18 700 kj kg confirming that his approximation is accurate and reliable 4 3 organic matter optimal content optsom an optimal level or range of som concentration optsom in the agricultural system is essential for studying soil quality for years an optimal or ideal value for the content of som has been investigated however as seen in the previous sections om influences and modifies many soil parameters this is why it has not been possible to establish any standard range loveland and webb 2003 consequently the optimal levels will depend on the soil properties considered in the different studies in crop production a decrease of som produces an insufficient nutrient reservoir 84 85 if the organic carbon oc content is less than 2 in soil physical properties the soil structure is vulnerable to decline greenland et al 1975 after all spink et al 2010 concluded that a concentration of soil organic carbon soc of 2 should be considered as a precautionary threshold above this value no action is required nevertheless below 2 of soc soils may have a poor structural condition and more specific studies should be carried out to determine their agronomic conditions the 2 threshold in oc has been subsequently used in other studies feiza et al 2011 haynes 2005 mukherjee and lal 2014 olaya abril et al 2017 hence in the definition of optsoil as a reference soil for assessing soil fertility and degradation an optimum value for oc of 2 will be selected although there are studies where lower om values do not generate production changes johnston 1991 kemper and koch 1966 k√∂rschens et al 1998 loveland and webb 2003 the established limit is optimal both in production also related to nutrients and in the soil structural aspect commonly since som is estimated to contain 58 of oc the relation between organic matter and organic carbon is om oc 1 724kgkg 1 in this research the chemical formula employed for som enclosed 54 of oc thus the ratio between organic matter and organic carbon is slightly different eq 8 8 s o m 1 851 s o c the value is considered optimal soc 2 and eq 10 allows obtaining the optsom the option is 3 7 this value will be the om concentration in the optsoil 9 s o m 1 851 2 3 7 thus to know the contribution of om in the optsoil considering the optsom selected 3 7 and the proportions of the topsoil chosen depth 0 2 m and bulk density 1400 kg m3 10 e x c h o m 19 406 12 k j k g 3 7 100 1400 k g m 3 10 000 m 2 h a 0 2 m 2 01 10 9 k j h a in conclusion the optsom suggested in this paper contributes with a chemical exergy value of 2 01 109 kjha 1 or 48 0 toe ha 1 tonne of oil equivalent hectare 1 to the total exergy of the optsoil 5 results and validation in the previous sections the methodology for calculating the exergy values of the inorganic fraction of the soil represented by texture and nutrients and the organic fraction represented by som is detailed furthermore the different components defined values conforming to the reference state selected as optsoil are given thus in this section firstly the exergy value of the optsoil is summarised and discussed then it is compared with the exergy values obtained for three soils determined experimentally table 9 shown the exergy values calculate for the previously defined optsoil considering a density of 1400 kg m 3 and a depth of 20 cm the exergy value of the optsoil calculate with the developed methodology as a sum of the contributions of opttext optnut and optsom defined shows an exergy value of 196 1toe ha 1 the total texture specific exergy estimated is 39 3 toe ha 1 as it is shown the concentration exergy contribution is higher than the chemical nutrients are the ones that offer the most significant contribution equivalent to 108 7 toe ha 1 which represents 55 of the total the som fraction represents a 48 0 toe ha 1 value equivalent to 25 of the total we validated the developed exergy methodology through the sampling of three soils in a greenhouse pilot test samples of 2 to 3 kg were taken homogeneously in a zig zag pattern at different points of the field and at a depth of 30 cm sampling was carried out with a shovel digging a small v shaped hole 20 to 30 cm deep all samples were mixed and prepared for the laboratory by sieving to eliminate any remains of previous harvests soil analysis to determine texture nutrients and om was performed the greenhouse pilot testing design integrated into each homogeneous block the three types of soil under study a total of 10 homogeneous distributed pots were prepared for each soil experimental conditions were optimal minimizing external influences and weather conditions allowing the soil s impact as a whole to be evaluated lactuca sativa was planted and the average weight of leaves and stems and roots were determined based on the laboratory soil analysis data each soil was evaluated using the exergy methodology developed in this study when a value is greater than the optsoil threshold the excess is not considered values obtained are shown in table 10 6 discussion as explained in previous sections soils are complex systems in which many different elements interact thus the three components opttext optnut and optsom are not independent for example the texture influences and affects the soil nutrients due to the interactions between the minerals that form the texture and nutrient ions elemental particles om also interacts with nutrients through mineralization processes and with texture as om conforms soil aggregates consequently the independent study of the different components is useful to assign an exergy value to the soil but fertile soils from an agronomical point of view cannot be understood interpreting each part independently but as a whole fig 3 shows optsoil and compares the specific exergy values obtained for different soils under analysis in all the cases the optsoil shows higher values than the studied soils soil 1 results in total exergy of 170 8 toe ha 1 it is the closest one to the optsoil value 196 1 toe ha 1 soil 2 and 3 show a slight difference in their total exergy value 130 35 and 120 16 toe ha 1 respectively due mainly to som soil 1 showed a better crop yield with a higher dry matter in leaves stems and roots this corresponds with the higher value in exergy obtained in soil 3 the dry matter obtained is slightly higher than soil 2 despite the lower exergy value fig 4 however in these two cases the values in both parameters exergy and yield are so close that the differences cannot be considered significant this confirms that the methodology to calculate the exergy value of fertile soils is consistent with agronomic performances that said much more data would be needed to establish a relation between the exergy of soil and its yield including the use of different crops 7 conclusions exergy is a useful tool to assess the complex problem of evaluating soil fertility or quality using szargut and thanatia as references a methodology to calculate the exergy contained infertile soils due to their inorganic and organic components has been developed in this work to do that the establishment of an optional is proposed the parameters considered to form a fertile soil are texture opttext nutrients optnut and organic matter optsom as a result of the methodology developed in the optsoil nutrients and som specific exergy are the predominant contributors therefore as the main advantage experimental validation has shown that the exergy values obtained agree with agronomic performance and showed the quality and quantity of energy contained in soil however exergy does not value and consider the interactions between these factors or the influences on the rest of the parameters and processes in the soil and slight differences between soils in agronomic yield cannot be explained when exergy values are very close despite that this methodology s development establishes the ground to assess the value of fertile soils using exergy as a unifying tool soil texture is highly variable across the globe and is difficult to amend the only thing that can be done in practical terms is to improve aeration and increase its water content according to its porosity however its energy value is relatively stable for different concentrations of silt sand and clay and lower than that of nutrients and in turn lower than that of organic matter however the latter two can be modified at a lower cost this means that one can select different opttext without significant changes in their exergy value but take optnut and optsom as a universal basis to analyze the level of degradation of a real soil against the optimum following these ideas there is no universal optimum soil but soils with a great multiplicity of textures nutrients and organic matter soils are pretty edaphic diverse however from the point of view of exergy we have seen that all textures hardly differ from each other what soil degradation depends on most is the lack of nutrients and organic matter to feed its microbiome these soil components are essential for all living things this idea can introduce an ideal fertile crust made of optinut and optisom invariant and independent of the different local textures but not independent of their water content and aeration let us call this imaginary crust copiously fertile pristinia pristinia from latin pristine former early original meaning unspoiled untouched pure pristinia 2021 as opposed to thanatia a dead state referring to abiotic resources thus any real agricultural soil will be an intermediate soil between pristinia and thantia unfortunately fertile soils take thousands of years to regenerate and humans are accelerating their degradation to thanatia the dialog between pristinia and thanatia will serve to quantitatively diagnose an assessment of all the concepts by which soil is degraded using exergy kwh as the universal unit of measurement from here we will be able to apply thermo economic theory to accurately assess the exergy replacement cost kwh or of any soil degraded by multiple effects both by excess or lack of nutrients we are also exploring the possibility of including the biotic part of the soil in the exergy methodology due to the numerous functions soil microorganisms play a relevant role in soil fertility which is currently a priority focus of soil science research credit authorship contribution statement antonio valero conceptualization methodology writing review editing supervision b√°rbara palacino methodology validation investigation writing original draft writing review editing sonia ascaso methodology validation investigation writing original draft writing review editing alicia valero conceptualization methodology writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this paper has received funding from feder fund the ministry of science innovation and universities under the project fertiligencia rtc 2017 5887 5 and project reset pid2020 116851rb i00 special thanks are owed to fertinagro biotech particularly to sergio atares for the project support and maria ferrer for collection and preparation of the soil samples also thanks to manuel marquez raquel anadon and sandra ortega from pctad for the greenhouse tests supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j ecolmodel 2021 109802 appendix supplementary materials image application 1 
24499,risks of drought complicate decision making in grass based livestock systems here we assessed the pertinence of the stochastic viability framework sv for making relevant decisions in a system exposed to climate shocks sv involves maximizing the probability of satisfying predefined constraints over time through adapted decision making we applied the approach to the case of mongolia where climate hazards combined with high animal densities regularly cause massive livestock die offs we used a livestock system model on which we made preliminary simplifications based on a thorough understanding of its behaviour to allow for sv use then we used sv to iteratively identify based on herd size and plant biomass the most adapted management decisions decisions involve selling purchasing a certain number of heads of the five local species we obtained 100 year trajectories satisfying herders constraints of income and subsistence consumption at a 94 rate this results from i cautious stocking rates reducing die off frequency and ii sales of heads of resistant species to buy heads of fragile species after die offs to compensate losses of fragile species these management actions generate resilience as they mitigate the effects of climate variability and offer reorganization mechanisms after a crisis we thereby confirm the potential of sv for adaptive decision making when resilience is at stake keywords stochastic viability constraints income subsistence multispecies mongolia 1 introduction grass bushes and other herbaceous plants play an important role in livestock production in the global food system this natural forage serves as the main feed source for herbivores in the subsistence based systems of africa america and asia suttie et al 2005 it is also a significant source of feed for the less intensive systems of developed countries dumont et al 2013 such vegetation can grow in drylands unsuitable for crop production iiasa and fao 2021 and is not edible to humans therefore it does not compete with human food sources for space unlike the grain used by swine and poultry mottet et al 2017 wilkinson 2011 this vegetation is also essential to systems providing a wide array of services to society such as water cycling biodiversity refuge and landscape cultural identity ryschawy et al 2019 however a reliance on natural forage exposes livestock systems to climate hazards such as droughts mace 1989 ryschawy et al 2019 these systems must therefore be resilient enough to absorb hazards and adapt to them to maintain a satisfactory level of performance darnhofer 2014 decision making processes adapted to uncertainty and offering sufficient resilience are therefore essential in this article we examine the pertinence of viability theory in proposing such decision making processes viability theory has been adapted to quantify resilience martin 2004 martin et al 2011 roug√© et al 2013 and has been successfully applied in extensive livestock systems in africa accatino et al 2014 south america tichit 2007 and asia sabatier et al 2017 the theory proposes a mathematical framework used to assess the satisfaction of predefined constraints through a state control approach aubin 1991 this is studied through viable trajectories defined as successions of states compatible with the satisfaction of predefined constraints oubraham and zaccour 2018 these states are reached through adapted management decisions called controls in the viability terminology the assessment of constraint satisfaction can be either binary yes no which is the approach of robust viability or probabilistic in the case of stochastic viability de lara and doyen 2008 de lara and martinet 2009 this probabilistic aspect is well adapted to situations involving drivers that can only be forecasted through probabilities such as climate hazards we tested the stochastic viability sv framework in relation to livestock systems of the desert steppes of mongolia these systems are quasi exclusively grass based with limited possibilities of winter fodder storage the systems are exposed to climate shocks that can cause in combination with poor livestock body conditions severe peaks of livestock mortality called dzud suttie et al 2005 the last dzud of the winter of 2009 2010 caused economic losses of 345 million usd and killed 10 million animals 23 4 of the total national livestock nandintsetseg et al 2018 such events typically take place when high animal densities droughts poor pasture conditions and cold temperatures weaken livestock populations while heavy snowfall complicates access to grass joly et al 2018b nandintsetseg et al 2017 2018 mongolian systems are in addition subject to poverty nsom 2015 world bank 2009 and pasture degradation hilker et al 2013 jamsranjav et al 2018 liu et al 2013 such systems thus face a variety of challenges and hazards which make them particularly interesting for testing a framework involving stochasticity and the satisfaction of constraints to be efficient in this context sv must propose management decisions ensuring regular and sufficient income to herders while maintaining pasture conditions the tool must propose stocking rates i e animal densities high enough to preserve herder incomes but low enough to prevent dzud risk and pasture degradation to test the ability of the sv framework to make appropriate decisions on stocking rates we used the model previously developed for the mongolian context by joly et al 2018a and sabatier et al 2017 the model simulates the interactions between vegetation animal and climate dynamics and can be managed through the selling and buying practices of the five local livestock species through these practices the model can adjust the stocking rate and pilot the state of a system the model can assess the satisfaction of herders constraints e g income and subsistence consumption based on the system state and selling and buying decisions the model has been previously used to assess the impact of current herder practices on plant underground biomass and the implications of competition between herders joly et al 2018a it has also been used within the sv framework to propose metrics of resilience for different states defined by herd size and forage biomass sabatier et al 2017 these metrics concern i the magnitude of weather perturbations that can be absorbed without compromising constraint satisfaction and ii the return time to a state enabling constraint satisfaction if a system has strayed from such a state by a climate shock these metrics were computed with the help of sv algorithms for states defined as starting points of viable trajectories here we used these algorithms to derive management decisions preventing deviations from viable trajectories under randomly generated weather scenarios from the rate of constraint satisfaction of these trajectories and comparisons to simpler rules on stocking rates we assessed the pertinence of sv for the decision making process we thus go a step further in the study of the sv framework by testing its pertinence for practical management guidance we also discuss the technical implications of implementing sv based decision making 2 material and methods 2 1 study area the model is parametrized for the conditions of khomyn tal an area of durvuljin district in western mongolia we summarize here the area s main characteristics and a full description is given in joly et al 2013 2018a 2019 the region is characterized by semi desert steppe vegetation and the mean annual temperature is 0 42 c the mean temperature over the four coldest months is 18 c november december january and february and the mean annual precipitation level is 97 mm precipitation mostly falls in the form of rain in the summer and its coefficient of variation cv is 0 46 denoting a high degree of variability von wehrden et al 2012 approximately 50 herder households live in khomyn tal with the five species of livestock common to mongolia in 2019 the national livestock census registered approximately 13 000 goats 10 000 sheep 2300 horses 1400 cattle and 800 camels nsom 2020 livestock is quasi exclusively fed natural forage exploited through mobile pastoralism khomyn tal and surrounding areas suffered two dzuds in the winters of 2001 2002 and 2009 2010 joly et al 2018a in the years between these dzud events herders rebuilt their herds which caused livestock numbers to fluctuate this pattern was visible at both the durvuljin and national scales fig 1 2 2 livestock system modelling the model takes into account local mobility practices by focusing on grazing areas in the summer as during this season livestock must accumulate fat reserves to survive the winter during this season vegetation is also the most vulnerable to degradation the model is household based and allocates a portion of land to each household equal to 1 50 of the summer area based on household numbers the model simulates the vegetation state through underground biomass because long term forage renewal depends on underground organs most of the local plant species are perennial the model simulates herd size through livestock dynamics and from this herders abilities to satisfy their constraints fig 2 to satisfy these constraints livestock management must offer the following i generate income above the poverty line from live animals and fibre wool and cashmere ii provide enough animals for subsistence consumption of meat and milk iii provide enough transport animals horses used to herd animals and camels for moving camps we used a version of the model that merges the 5 local species into 2 functional types sabatier et al 2017 these types are based on the bog bod traditional mongolian body size typology fijn 2011 small animals called bogs sheep and goats exhibit on average more fecundity and are less resistant to dzud events than large species called bods horses cattle and camels joly et al 2018a 2 3 model dynamics the model is time discrete and the state variables are underground plant biomass and bog and bod herd size appendix a the dynamics of underground biomass depend on the precipitation available for vegetation and the amount of standing aboveground biomass the renewal of underground organs indeed depends on reserves produced by aboveground photosynthetic leaves which are themselves impacted by animal grazing assessed through herd size animal dynamics are driven by the death rate which depends on the occurrence or absence of dzud events animal fecundity that impacts births the number of old animals culled and decisions regarding the sale or purchase of other animals animal fecundity in year t depends on the pasture use factor ratio forage demand supply of year t 1 which is notably due to the duration of gestation joly et al 2018b similarly survival at the end of the winter of year t is impacted by animal fat reserves which also depend on the previous summer pasture use of t 1 plant biomass processes in year t are only dependent on rainfall in year t the dynamics of the model for year t thus depend on events taking place in years t 1 and t for this reason we express the state x t x r 6 of the system in year t as follows x t u b t n b o g t n b o d t u b t 1 n b o g t 1 n b o d t 1 where u b t is underground biomass kg ha and n b o g t and n b o d t reflect herd size through bog and bod numbers heads respectively animals are allocated to a given surface which is why n b o g t and n b o d t reflect stocking rates animal number per hectare n b o g t and n b o d t are capped by the maximum number of heads herders can look after respectively 500 and 90 heads on average joly et al 2019 climate variability w t œµ w r 6 is w t p t w p t w t t p t 1 w p t 1 w t t 1 where p t denotes precipitation available for vegetation mostly falling in the form of rain w p t denotes winter precipitation falling in the form of snow and w t t is the mean winter temperature p t w p t and w t t follow the distributions observed in historical series 1 1 p has a poisson shape type distribution mean 80 64 sd 41 47 wp has a normal distribution mean 8 17 sd 4 40 and wt has a normal distribution mean 12 84 sd 2 14 and they are independent from each other in the model for a given year therefore for any year t 1 p t 1 w p t 1 and w t t 1 are independent from each other and are also independent between years e g for any couple of distinct years t 1 and t 2 p t 1 and p t 2 are independent this configuration correctly simulates dzud frequency joly et al 2018a the control management action u t u r 2 is u t u b o g t u b o d t where u b o g t and u b o d t are the sales and purchases of bog and bod respectively heads when u is positive animals are sold and when it is negative they are purchased contrary to dynamics it applies to a single year because decisions only influence year t they cannot apply to past states the model s dynamics are expressed by eq 1 1 x t 1 x t f x t u t w t the model expresses herders constraint satisfaction with function c s x t u t w t which is equal to one when constraints are satisfied and zero otherwise this function is based on model dynamics weather and management decisions the expressions of c s and f are given in appendix a 2 4 stochastic viability to apply the sv framework we considered the trajectory of the system during time steps 0 t the controls applied during these steps are denoted by u u 0 u t and the climate values are denoted by w w 0 w t the state reached at time t when applying controls u over time period 0 t starting from state x 0 is x x 0 u w t eq 2 2 x x 0 u w t x 0 œÑ 0 t f x x 0 u w œÑ u œÑ w œÑ the purpose of relevant strategy u in a context of uncertainty is to ensure that constraints will be satisfied over time with the highest possible probability the sv decision making process must therefore identify controls u x 0 which starting from state x 0 maximize the expected value of c s along time steps 0 t this approach is formally expressed by eq 3 3 u x 0 arg max u u t 1 e w w t 1 t 0 t c s x x 0 u w t u t w t where arg identifies the specific u value s satisfying the condition shown between parentheses and e is the expected value of the expression shown between parentheses eq 3 hence indicates that management strategy u maximizes the probability that constraints are satisfied over time and this probability is assessed by the expected value of the product of annual c s values identifying this u strategy is challenging because it implies for instance identifying a series of management options amongst a number of possible candidates that increases exponentially with time e g 1020 candidates for 10 yearly possible control options over 20 years we identified strategy u through the backward procedure of dynamic programming applied to stochastic viability as in doyen and de lara 2010 this procedure makes it possible to identify the given strategy by finding recursively year by year the best possible decision for a given year the method applies this approach while maintaining the dynamics between years as explained below years connected through eq 4 and 5 by doing so the procedure solves a very difficult problem concerning a trajectory spanning 20 years for example by solving 20 simpler annual sub problems bellman 2003 this procedure uses value function v that returns for a given state and year the highest probability of constraint satisfaction this probability is obtained by scanning a range of possible u values eq 4 and 5 by finding the pair of controls u b o g t and u b o d t providing the highest probability of constraint satisfaction the most adapted decisions for a given year and state are identified we used this approach to derive our decision making process using dynamic programming involved two modelling simplifications the first concerns the dynamics of the system which depend on the weather of two subsequent years the dynamic programming algorithm computing v only refers to the weather of a single year see eq 4 and 5 leading us to approach the pasture use factor of t 1 with that of t because they are closely correlated in the area joly et al 2018b these simplified dynamics are denoted as f s and use simplified arguments x s and w s f s is calculated by replacing p u t 1 with p u t in eqs a 3 and a 7 see appendix a x s t 1 x s t f s x s t u t w s t x s t u b t n b o g t n b o d t w s t p t w p t w t t this simplification did not prevent us from using c s due to the form of the equations on which it is built see appendix a second to save computing time we only considered typical weather configurations for w s w s these configurations are based on cut off values and distributions of rainfall p t and an indicator of winter harshness w h t derived from w p t and w t t appendix a these cut offs separate p t and w h t for dzud and non dzud years based on their values in historical series values above cut offs were averaged and their proportions were calculated for example the mean p for dzud years is 36 4 mm and p is below this value for 20 of the years the mean p value during non dzud years is 91 mm and p is above this value for 80 of years values summarized in appendix a table a 2 we obtained in this way four types of years as follows w s w 1 s wet mild w 2 s wet harsh w 3 s dry mild w 4 s dry harsh each type of year w k s has a probability p w k s that is not dependent on t hence for any couple of distinct years t 1 and t 2 w s t 1 and w s t 2 are independent which ensures that dynamic programming can be applied value function v is expressed through eq 4 and 5 and computed for the following ranges of state variables the maximum n b o g t and n b o d t are 500 and 90 heads respectively due to the above explained workforce limits and the minimum value for both livestock types is 0 based on trials using these livestock values u b t ranges between 100 and 700 kg ha t is set to 20 years for computing time constraints computing v implies scanning large numbers of states and controls with the above simplifications value function v is computed as follows 4 v t x s max u u e w s w s cs x s u w s v t x s max u u e w s w s cs x s u w s v t 1 x s f s x s u w s where 5 e w s w s cs x s u w s k 1 4 cs x s u w k s p w k s e w s w s cs x s u w s v t 1 x s f s x s u w s k 1 4 cs x s u w k s v t 1 x s f s x s u w k s p w k s 2 5 trajectories 2 5 1 types of trajectories to formally assess the pertinence of sv for making management decisions we built trajectories derived through sv then as mentioned in introduction we compared these trajectories to a second type based on a livestock number capping rule we evaluated in this way the added value of sv relative to a simple adjustment rule we compared in addition sv trajectories to a third type built without a rule we assessed this way the baseline performance of no rule management in these no rule trajectories herders let animal numbers grow until a dzud occurs in the three types of trajectories apart from animals sold herders obtain income from fibre and the culling of older animals see appendix a hence even in no rule trajectories herders obtain an income the three types of trajectories built are called viability capping and default trajectories table 1 we built 1000 simulated trajectories of each type for 100 years and assessed mean constraint satisfaction c s for two levels of annual income constraints above once and twice the poverty line for a household from parameter conspoverty multiplied by 1 or 2 see appendix a we assessed this way the capacity for sv to handle different income objectives the income objective is indicated in trajectories by suffixes povx1 and povx2 table 1 2 5 2 trajectory building we built the three types of trajectories based on nonsimplified dynamics f and climate distributions w simplified ones were only used to compute v we randomly set for each year a value for p w p and w t according to the same mean standard deviation and distribution of historical series starting point x 0 is defined as n b o g 252 n b o d 36 and u b 500 for both years of the state based on the most recent surveys joly et al 2018a we built viability trajectories by considering for each year t vector n b o g t n b o d t u b t this vector corresponds to simplified state x s and we extracted the most adapted control u x s 0 identified when calculating v 0 x s eq 4 this extraction according to x s makes our sv procedure adaptive when several values of u x s 0 were possible we randomly selected one we built capping trajectories with a rule involving selling animals when the overall size of the herd in sheep forage units sfus exceeds a threshold from this overall threshold we declined bog and bod thresholds in heads above which animals were sold we used 360 and 400 sfu thresholds for povx1 and povx2 respectively as they returned the best c s obtention of these thresholds explained in appendix b the capping trajectories also integrate a mechanism of bog bod exchange after a dzud this resilience mechanism practised by herders involves selling resistant bod heads after a dzud to buy fragile bog heads joly et al 2019 we finally built our default trajectories by simply setting u b o g t and u b o d t to 0 further details on the trajectory building of the three types are given in appendix b models were written in python 3 7 0 with the help of spyder 3 3 1 available at https github com fejoly stochastic viability 3 results 3 1 constraint satisfaction of all types of trajectories for both income objectives poverty line x1 or x2 mean c s increases from default to capping and then to viability table 1 capping and viability trajectories have mean c s values ranging from 0 71 to 0 94 whereas mean default c s ranges from 0 08 to 0 18 this poor default performance is attributable to the violation of the subsistence consumption constraint bog and bod meats are not substitutable for preservation purposes and due to the high dzud frequency in default trajectories bog livestock is superseded by bod livestock fig 4 as a result bog herds fail to satisfy the bog meat constraint viability trajectories are thus the most efficient and they are also the most stable as illustrated by the c s coefficient of variation table 1 such stability is further illustrated by the shape of the trajectories which reach plateaus for both c s and state variables figs 3 and 4 the other trajectories show less stable trends and for example default trajectories are unable to prevent a decrease in underground biomass moreover capping trajectories are unable to prevent a slight decrease in c s over 100 years fig 3 it is of interest to note that the capping and viability trajectories maintain a stable level of underground biomass close to the starting value 500 kg ha it is also noteworthy to mention that viability trajectories succeeded in providing mean incomes of above the parametrized threshold table 1 with the highest c s found for viability povx1 table 1 viability povx1 trajectories are therefore the most efficient in terms of stability but viability povx2 trajectories are the most efficient in terms of income the difference in c s found between the capping and viability trajectories is finally more important for povx2 Œ¥ 0 15 than for povx1 Œ¥ 0 08 which indicates that when the level of constraint increases the higher efficiency of sv becomes more apparent 3 2 factors affecting trajectory efficiency the better performance of the viability and capping trajectories are due to the reduction in dzud frequency increase in livestock fecundity table 1 and stabilization of bog bod proportions fig 4 the bog bod proportion was parametrized in the capping trajectories from the maximum possible number of animals while it was automatically adjusted in the sv trajectories by the viability process this is notably obtained through a post dzud exchange mechanism of bogs and bods illustrated by the relationship between post dzud bog numbers and bog sales fig 5 this relationship between livestock numbers and bog sales u b o g t shows that after a dzud if bog herds become too small sv models buy animals livestock numbers are assessed here from herd size before culling and sale or purchase see appendix a solving the associated linear regression indicates that the purchase takes place on average for both sv trajectories when the post dzud bog herd falls below 100 heads fig 5 in other words most of the time the sv process chooses to buy animals if the bog herd falls below 100 heads this 100 head value is close to that recorded from interviews of local herders joly et al 2019 in addition the bog purchases concern batches of bogs of 40 heads or less in 91 and 93 of the dzud years for viable povx1 and povx2 respectively fig 5 finally the post dzud mechanism is further characterized by the relationship between bog and bod sales u b o g t and u b o d t showing that the purchase of bogs is typically associated with a bod sale fig 5 in other words most of the time the sv process chooses to sell bods when it buys bogs 4 discussion 4 1 stochastic viability pertinence our objective was to assess the ability of the sv approach to define a pertinent stocking strategy in the context of environmental uncertainty sv provides a mathematical definition for such a strategy through u eq 3 and offers tools with which to translate this strategy into concrete management decisions u t through the dynamic programming of doyen and de lara 2010 by using these tools we obtained trajectories that clearly demonstrate sv pertinence by ensuring high rates of constraint satisfaction mean c s and preserving long term forage potential we observed this efficiency without a duration limit as systems are stabilized several decades before the end of the 100 year horizon in this respect our results extend beyond studies of agrosystems exposed to environmental stochasticity reported by oubraham and zaccour 2018 these studies are either based on a shorter duration sabatier 2010 sabatier et al 2012 or stabilize performance less efficiently baumg√§rtner and quaas 2009 tichit et al 2004 the comparison of the default and capping trajectories helps illustrate through which drivers strategy u is implemented the comparison shows that post dzud bog bod exchange the capping of livestock numbers to reduce dzud frequency and underground biomass stabilization are drivers of efficiency these drivers generate resilience as they enable the absorption of climate shocks and reorganization after crises dzud walker et al 2004 sv management uses these drivers more efficiently especially when income constraints are high which is attributable to the dynamic programming procedure this procedure helps obtain these states that ensure the highest probability of constraint satisfaction over time which obviously contributes to improved long term performance the procedure also makes decisions adaptively i e based on the state of the system our results thus demonstrate that sv through its long term focus and adaptive approach makes it possible to derive a decision making process pertinent in the context of climate variability our results also illustrate interesting aspects of the sv framework itself first they show that the simplifications made to the weather distribution from w to w s and to system dynamics from f to f s did not prevent building trajectories with high rates of constraint satisfaction these simplifications were made because of the complexity of the system and based on a thorough knowledge of its dynamics this illustrates that dynamic programming applied to stochastic viability can be used in complex systems following relevant simplifications the fact that trajectories are stable over 100 years despite training over 20 years v computed over 20 years illustrates an additional level of robustness this shows that an initial momentum ensuring sustainability can be given to the system second our use of different levels of income constraints and identification of different levels of constraint satisfaction represent a quantitative application of the viability framework showing that the focus can be placed on income viability povx2 or stability viable povx1 this indicates that trade offs can be studied through viability theory even though this was not its initial purpose aubin 1991 finally we focused on assessing sv efficiency to manage stochasticity around a mean and therefore did not take climate change into account however it could be possible to integrate this process and in this case for a given starting state the management and value functions u and v would depend on an initial date a climate trend could be this way integrated in v computation 4 2 towards the development of a decision making tool from a technical perspective decision making tools could be built from the applied sv procedure they would involve defining management decisions according to the system state as modelled here the state would be defined by herd size which is easily accessible to herders and underground biomass which is more difficult to measure but can be assessed through plant cover joly et al 2018a bog number bod number and underground biomass values could be sent through sms or smartphone applications to a server and control values the sale or purchase of animals could be returned this control extraction method is fast once value function v has been computed i e over 20 s on our regular laptop computer while v computation over 20 years took several hours the control value could then be sent back to a phone through a mass messaging system similar to that developed in mongolia to warn of weather hazards people in need 2018 from a nontechnical perspective these decision making tools would have both advantages and disadvantages a first advantage is that income levels can be parametrized which offers interesting options viability povx2 is in this regard particularly interesting and could be chosen by herders who have bank cash saving mechanisms ifrc 2017 herders might for this reason be more interested in the mean level of income over time than in the annual satisfaction of the poverty line a second advantage is that some of the controls applied by the sv procedure are in line with a resilience mechanism found in traditional pastoral societies of africa and asia post disaster animal exchange is indeed commonly practised within multispecies herds as mentioned above the method is practised in khomyn tal and is based on a portfolio of species with distinct traits such as resistance to hazards to provide a safety net and high fecundity to provide a growth asset blench and marriage 1999 joly et al 2019 mace 1989 by continuously adjusting the numbers of animals of the different species types herders maintain stable performance despite hazards and die offs the 100 head threshold above which models and herders restock their bog herd i e choosing to buy animals suggests that this mechanism is very similar in sv trajectories and real systems regarding the disadvantages of the sv process viable trajectories first have a dzud avoidance approach that differs from pastoralist practices pastoralists indeed commonly maximize their herd numbers as part of a risk mitigating strategy to accumulate wealth in anticipation of hardship hendricks et al 2004 naess and bardsen 2013 roe 1998 rota 2009 thrift and ichinkhorloo 2015 by using small herds sv trajectories do the opposite and following an sv strategy would require herders to change their risk perceptions this is a challenge because smaller herds involve an immediate and visible loss of earnings through reduced annual income from fibre and culled animals oppositely gains are less tangible as they are obtained through fecundity increases which may be difficult to assess and through dzud frequency reductions i e on a certain time horizon in a probabilistic manner reducing numbers may therefore be perceived by herders as gambling on hypothetical gains a second disadvantage is that applying sv management implies a fluid market the approach requires the presence of a pool of animals that can be purchased and a demand that can absorb animals for sale the availability of bogs to purchase after a dzud and their price might be the most acute problem as most people may need animals at the same time however restocking animals could be transported from less to more severely impacted areas as dzuds have variable intensity across mongolia nandintsetseg et al 2017 the number of animals purchased were in addition most of the time in our models below 40 which is close to transactions locally observed joly 2015 purchasing enough animals may therefore not be a problem a final difficulty of this decision making process is that livestock of several households can mix between seasonal camps this could affect the assessment of the size of herds grazing in a seasonal area and reduce the precision of the management decision made however it may be possible to solve this problem by using the tool at the scale of community groups such as those already established in the country ulambayar et al 2016 this above list of pros and cons hence suggests that there may be more sociocultural market and land governance obstacles than technical difficulties for the adoption of sv based decision making tools these factors should be addressed before considering large scale application the integration of sv processes with other pastoral management tools such as mobility should also be addressed 4 3 precision livestock farming beyond the mongolian context our results can contribute to research on livestock precision farming plf to date plf is mostly applied to indoor industrial contexts shalloo et al 2018 for example to adjust levels of feed to individual animal needs and prevent the systematic use of medicine shalloo et al 2018 tullo et al 2019 our sv management approach could be used as part of a plf scheme in outdoor grass based systems it would be relevant in the case of herds involving a diversity of animals with distinct traits species or races as using such diversity for resilience is one of the principles of agroecology applied to livestock farming systems dumont et al 2013 the approach we used with bogs bods could hence be extrapolated to any kind of diversity such support would be valuable since diverse livestock systems are more complex to manage than simple ones martin et al 2020 in addition the ergonomics of agroecological practices are receiving interest joly et al 2021 which justifies the investigation of tools that could be used to ease their implementation our results therefore illustrate how models and computer decision making tools could be used in an agroecological context 5 conclusion we demonstrated in this article the potential for sv to be used to make pertinent decisions in a complex system exposed to environmental shocks sv decisions generate trajectories that are more effective and resilient than those proposed by a simple livestock number capping rule through a long term and adaptive approach our use of sv was possible due to specific modelling simplifications based on a thorough comprehension of the studied system we thereby illustrated that the benefits of sv are not only theoretical but also practical from the possibility of deriving a concrete decision making process regarding applicability to mongolia we identified several developments that would be needed to implement our decision making process add a climate change trend in the value function calculation study the fluidity of the livestock market to confirm the possibility of buying enough bog heads after a dzud assess the attitudes of herders towards livestock number reduction as a risk avoidance strategy assess the possibility of implementing decisions at the community level incorporate the process into a broader decision framework integrating pastoral mobility credit authorship contribution statement fr√©d√©ric joly conceptualization methodology software formal analysis writing original draft visualization rodolphe sabatier conceptualization methodology software laurent tatin writing review editing claire mosnier writing review editing ariell ahearn writing review editing marc benoit writing review editing bernard hubert writing review editing guillaume deffuant conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge support received from the agence nationale de la recherche of the french government through the program investissements d avenir 16 idex 0001 cap 20 25 appendix a model dynamics vegetation submodel u b t is modelled according to eq a 1 which describes how biomass allocation from underground biomass enables aboveground biomass ab to grow at the beginning of the growing season when photosynthesis has not yet started m√ºller et al 2007 it describes how u b requires regular biomass reallocation from ab to compensate for biomass previously used this reallocation from ab compensates for u b natural mortality without this reloading u b is slightly depleted a 1 ub t 1 ub t m ub t 1 d ub t w res w gr p t ub t co t 1 d ub t where m is a natural mortality rate and d is a density dependence parameter the higher the level of underground biomass is the slower it is replenished and the faster it dies w res denotes the proportion of ab allocated to u b replenishment and w gr is a factor of rain use efficiency accounting for run off and evapotranspiration p t is precipitation occurring over the first 8 months of the calendar year considered usable by vegetation it accounts for the soil moisturizing effect of winter precipitation in the spring at the time vegetation starts growing nandintsetseg and shinoda 2011 c o t is the livestock consumption of aboveground biomass per ha and reduces the amount of plant standing foliage of plants eq a 2 a 2 co t conssu i bog bod n i t sf u i Œ∑ œÉ where conssu is the mean daily amount of forage consumed by a sheep and sf u i is a coefficient that converts the daily forage intake of type i into an equivalent in sfu Œ∑ is the stay duration in the summer zone day and œÉ is the area used by one household ha livestock submodel the livestock submodel distinguishes dzud and non dzud years with the help of index i d z u d t the index illustrates how a low availability of forage and a cold and snowy winter result in a dzud eq a 3 i d z u d t p u t 1 w h t a 3 with w h t w p t m a x 0 w t threshold w t t Œ∏ where p u t 1 is the pasture use ratio of forage consumed to available forage and w h t is an indicator of winter harshness we used the pasture use of year t 1 to express the i d z u d t value of year t because dzud mortality occurs at the end of the winter during the first months of the year as a consequence of the previous year s conditions w p t is the cumulative precipitation of the six coldest months of years t 1 and t october to december of year t 1 and january to march of year t representing the snow water equivalent for the winter used to quantify snow abundance w t t is the mean temperature of the six coldest months of years t 1 and t october to december of year t 1 and january to march of year t w t threshold is a temperature threshold and Œ∏ is a coefficient making i d z u d t equal to 1 to separate dzud from non dzud years in simulations p u t is expressed by eq a 4 a 4 p u t c o t œÉ w gr p t u b t œÉ œÜ reserve where œÜ reserve is a local riverbed forage used for reserve grazing and is expressed by a constant because this vegetation is less prone to degradation than desert steppes as it is not used continuously and it is abundantly watered by the river water table dynamics of animal type i are expressed by eq a 5 a 5 n i t 1 n i t n i t l idzud t i b i t subs orcu l i t u i t where l i d z u d t i is the death rate of a type i animal according to the occurrence or absence of a dzud b i t represents the number of born animals s u b s o r c u l i t denotes the number of old animals either slaughtered for subsistence consumption or culled and u i t is the control term that defines the number of animals sold or purchased when it is positive animals are sold and when the value is negative animals are purchased b i t is expressed by eq a 6 a 6 b i t n i t 1 l idzud t i fe m i acu l i are p i acu l i pro d idzud t i t where femi is the percentage of females arepi is the age at which gravid females give birth for the first time aculi is the age of culling for subsistence or the sale of old animals and p r o d t i d z u d t i is the productivity assessed by the number of young born animals per female of breeding age this value depends on dzud occurrence because females can miscarry during such a disaster and on p u t 1 which affects body condition at the time of reproduction especially at the time of gestation joly et al 2018b the value is expressed according to eq a 7 and bounded by minprodi and maxprodi a 7 if idzud t 1 pro d idzud t i t Œ≥ i 1 pu t 1 œà i if idzud t 1 pro d idzud t i t Œ¥ i where Œ≥ i and œà i are coefficients and Œ¥ i is a constant s u b s o r c u l i t is equal to the proportion of animals culled if it is higher than the number of animals that herders consume in year t and corresponds to the renewal rate of species i in the herd if this rate is too low to satisfy subsistence consumption herders slaughter more animals eq a 8 a 8 s u b s o r c u l i t max n i t 1 l i d z u d t i b i t acu l i con s i subs where cons i subs represents the number of heads needed for subsistence consumption constraints the constraints are expressed for convenience according to variable n i b c s t that describes livestock numbers before culling and sale or purchase eq a 9 this variable is also used to study the relationships between livestock numbers and the number of bog heads purchased after a dzud a 9 n i b c s t n i t 1 l i d z u d t i b i t the first two constraints concern the availability of animals for subsistence consumption of bog and bod meat before culling ineq a 1 and a 2 both types are distinguished because they are not substitutable bogs are consumed during the warm months when they have enough body fat and bods are consumed in the winter when their carcasses can be frozen outside of herders camps bods are slaughtered at the beginning of the season and bog bod consumption practices ensure a year round availability of meat ineq a 1 n b o g b c s t c o n s bog subs if ineq a 2 n b o d b c s t c o n s bod subs the third constraint refers to the subsistence consumption of milk and milk products and its expression depends on livestock productivity as females that produce milk are only those that have given birth ineq a 3 ineq a 3 i bog bod n i bcs t prod t idzud t i Œº i con s subsmilk where con s subsmilk is the milk consumption threshold and Œº i the amount of milk produced by a head of livestock accounting for the age and sex structure of the herd the fourth constraint refers to the availability of transport animals for household con s ride draft i e the availability of horses used for herd management and camels used for draft ineq a 4 ineq a 4 n b o d b c s t con s ride draft n b o d t con s ride draft both n b o d b c s and n b o d are considered as draft animals are used year round the fifth constraint refers to household revenue three types of income were taken into account and overall household income was calculated by summing the income values and subtracting the mean herding cost the difference had to be superior to poverty line conspoverty at the household scale ineq a 5 ineq a 5 i n f i b r e t i n l i v e t i n s k i n h i d e t hc con s poverty where infibre t inlive t and inskinhide t are respectively the annual incomes generated through the sale of fibre live animals and skins hides of animals slaughtered for subsistence hc denotes the herding costs and conspoverty represents the poverty line value as herders use very few inputs such as fodder or concentrates per head of livestock joly et al 2019 we considered hc to be constant the different incomes were quantified according to eqs a 10 a 12 a 10 i n f i b r e t i bog bod n i b c s t i i fibre a 11 i n l i v e t i bog bod max 0 n i b c s t acu l i c o n s i s u b s u i t i i live a 12 i n s k i n h i d e t i bog bod cons i subs i i skinhide where i i f i b r e i i l i v e and i i s k i n h i d e are the annual incomes generated by one head of animal of type i for each kind of product if ineqs a 1 to a 5 hold true constraint satisfaction function c s is equal to 1 and is equal to 0 otherwise if only one ineq is wrong c s 0 the parameters used in appendix a and their values are given in table a 1 appendix b trajectory building trajectories derived from sv for animal type i u x s 0 is capped by n i t 1 l idzud t i b i t subs orcu l i t to avoid selling more animals than is available this can happen for the most extreme values generated from nonsimplified weather space w since u is based on a simplified w s trajectories derived from a capping number rule the capping trajectories are based on a maximum livestock number eq b 1 b 1 n i max sf u max œÅ i sf u i where sf u max is the overall herd size in sfu bog bod n i max is the maximal number in heads of type i and œÅ i is the proportion of i in sfu within n i 0 from n i max controls u were derived eq b 2 b 2 u b o g t r i d z u d t n b o g t b c s s u b s o r c u l b o g t max 0 1 r i d z u d t n b o g t b c s s u b s o r c u l b o g t n bog max u b o d t r i d z u d t n b o d t b c s s u b s o r c u l b o d t max 0 1 r i d z u d t n b o d t b c s s u b s o r c u l b o d t n bod max where r i d z u d t is an adjustment ratio designed to exchange bog heads against bod heads after a dzud the value is equal to zero for i d z u d t 1 and l i d z u d t b o g l i d z u d t b o d 2 for i d z u d t 1 to assess the n i max that returned the best c s for both types of income objectives povx1 and povx2 we scanned values of between 0 and 1500 sfu 
24499,risks of drought complicate decision making in grass based livestock systems here we assessed the pertinence of the stochastic viability framework sv for making relevant decisions in a system exposed to climate shocks sv involves maximizing the probability of satisfying predefined constraints over time through adapted decision making we applied the approach to the case of mongolia where climate hazards combined with high animal densities regularly cause massive livestock die offs we used a livestock system model on which we made preliminary simplifications based on a thorough understanding of its behaviour to allow for sv use then we used sv to iteratively identify based on herd size and plant biomass the most adapted management decisions decisions involve selling purchasing a certain number of heads of the five local species we obtained 100 year trajectories satisfying herders constraints of income and subsistence consumption at a 94 rate this results from i cautious stocking rates reducing die off frequency and ii sales of heads of resistant species to buy heads of fragile species after die offs to compensate losses of fragile species these management actions generate resilience as they mitigate the effects of climate variability and offer reorganization mechanisms after a crisis we thereby confirm the potential of sv for adaptive decision making when resilience is at stake keywords stochastic viability constraints income subsistence multispecies mongolia 1 introduction grass bushes and other herbaceous plants play an important role in livestock production in the global food system this natural forage serves as the main feed source for herbivores in the subsistence based systems of africa america and asia suttie et al 2005 it is also a significant source of feed for the less intensive systems of developed countries dumont et al 2013 such vegetation can grow in drylands unsuitable for crop production iiasa and fao 2021 and is not edible to humans therefore it does not compete with human food sources for space unlike the grain used by swine and poultry mottet et al 2017 wilkinson 2011 this vegetation is also essential to systems providing a wide array of services to society such as water cycling biodiversity refuge and landscape cultural identity ryschawy et al 2019 however a reliance on natural forage exposes livestock systems to climate hazards such as droughts mace 1989 ryschawy et al 2019 these systems must therefore be resilient enough to absorb hazards and adapt to them to maintain a satisfactory level of performance darnhofer 2014 decision making processes adapted to uncertainty and offering sufficient resilience are therefore essential in this article we examine the pertinence of viability theory in proposing such decision making processes viability theory has been adapted to quantify resilience martin 2004 martin et al 2011 roug√© et al 2013 and has been successfully applied in extensive livestock systems in africa accatino et al 2014 south america tichit 2007 and asia sabatier et al 2017 the theory proposes a mathematical framework used to assess the satisfaction of predefined constraints through a state control approach aubin 1991 this is studied through viable trajectories defined as successions of states compatible with the satisfaction of predefined constraints oubraham and zaccour 2018 these states are reached through adapted management decisions called controls in the viability terminology the assessment of constraint satisfaction can be either binary yes no which is the approach of robust viability or probabilistic in the case of stochastic viability de lara and doyen 2008 de lara and martinet 2009 this probabilistic aspect is well adapted to situations involving drivers that can only be forecasted through probabilities such as climate hazards we tested the stochastic viability sv framework in relation to livestock systems of the desert steppes of mongolia these systems are quasi exclusively grass based with limited possibilities of winter fodder storage the systems are exposed to climate shocks that can cause in combination with poor livestock body conditions severe peaks of livestock mortality called dzud suttie et al 2005 the last dzud of the winter of 2009 2010 caused economic losses of 345 million usd and killed 10 million animals 23 4 of the total national livestock nandintsetseg et al 2018 such events typically take place when high animal densities droughts poor pasture conditions and cold temperatures weaken livestock populations while heavy snowfall complicates access to grass joly et al 2018b nandintsetseg et al 2017 2018 mongolian systems are in addition subject to poverty nsom 2015 world bank 2009 and pasture degradation hilker et al 2013 jamsranjav et al 2018 liu et al 2013 such systems thus face a variety of challenges and hazards which make them particularly interesting for testing a framework involving stochasticity and the satisfaction of constraints to be efficient in this context sv must propose management decisions ensuring regular and sufficient income to herders while maintaining pasture conditions the tool must propose stocking rates i e animal densities high enough to preserve herder incomes but low enough to prevent dzud risk and pasture degradation to test the ability of the sv framework to make appropriate decisions on stocking rates we used the model previously developed for the mongolian context by joly et al 2018a and sabatier et al 2017 the model simulates the interactions between vegetation animal and climate dynamics and can be managed through the selling and buying practices of the five local livestock species through these practices the model can adjust the stocking rate and pilot the state of a system the model can assess the satisfaction of herders constraints e g income and subsistence consumption based on the system state and selling and buying decisions the model has been previously used to assess the impact of current herder practices on plant underground biomass and the implications of competition between herders joly et al 2018a it has also been used within the sv framework to propose metrics of resilience for different states defined by herd size and forage biomass sabatier et al 2017 these metrics concern i the magnitude of weather perturbations that can be absorbed without compromising constraint satisfaction and ii the return time to a state enabling constraint satisfaction if a system has strayed from such a state by a climate shock these metrics were computed with the help of sv algorithms for states defined as starting points of viable trajectories here we used these algorithms to derive management decisions preventing deviations from viable trajectories under randomly generated weather scenarios from the rate of constraint satisfaction of these trajectories and comparisons to simpler rules on stocking rates we assessed the pertinence of sv for the decision making process we thus go a step further in the study of the sv framework by testing its pertinence for practical management guidance we also discuss the technical implications of implementing sv based decision making 2 material and methods 2 1 study area the model is parametrized for the conditions of khomyn tal an area of durvuljin district in western mongolia we summarize here the area s main characteristics and a full description is given in joly et al 2013 2018a 2019 the region is characterized by semi desert steppe vegetation and the mean annual temperature is 0 42 c the mean temperature over the four coldest months is 18 c november december january and february and the mean annual precipitation level is 97 mm precipitation mostly falls in the form of rain in the summer and its coefficient of variation cv is 0 46 denoting a high degree of variability von wehrden et al 2012 approximately 50 herder households live in khomyn tal with the five species of livestock common to mongolia in 2019 the national livestock census registered approximately 13 000 goats 10 000 sheep 2300 horses 1400 cattle and 800 camels nsom 2020 livestock is quasi exclusively fed natural forage exploited through mobile pastoralism khomyn tal and surrounding areas suffered two dzuds in the winters of 2001 2002 and 2009 2010 joly et al 2018a in the years between these dzud events herders rebuilt their herds which caused livestock numbers to fluctuate this pattern was visible at both the durvuljin and national scales fig 1 2 2 livestock system modelling the model takes into account local mobility practices by focusing on grazing areas in the summer as during this season livestock must accumulate fat reserves to survive the winter during this season vegetation is also the most vulnerable to degradation the model is household based and allocates a portion of land to each household equal to 1 50 of the summer area based on household numbers the model simulates the vegetation state through underground biomass because long term forage renewal depends on underground organs most of the local plant species are perennial the model simulates herd size through livestock dynamics and from this herders abilities to satisfy their constraints fig 2 to satisfy these constraints livestock management must offer the following i generate income above the poverty line from live animals and fibre wool and cashmere ii provide enough animals for subsistence consumption of meat and milk iii provide enough transport animals horses used to herd animals and camels for moving camps we used a version of the model that merges the 5 local species into 2 functional types sabatier et al 2017 these types are based on the bog bod traditional mongolian body size typology fijn 2011 small animals called bogs sheep and goats exhibit on average more fecundity and are less resistant to dzud events than large species called bods horses cattle and camels joly et al 2018a 2 3 model dynamics the model is time discrete and the state variables are underground plant biomass and bog and bod herd size appendix a the dynamics of underground biomass depend on the precipitation available for vegetation and the amount of standing aboveground biomass the renewal of underground organs indeed depends on reserves produced by aboveground photosynthetic leaves which are themselves impacted by animal grazing assessed through herd size animal dynamics are driven by the death rate which depends on the occurrence or absence of dzud events animal fecundity that impacts births the number of old animals culled and decisions regarding the sale or purchase of other animals animal fecundity in year t depends on the pasture use factor ratio forage demand supply of year t 1 which is notably due to the duration of gestation joly et al 2018b similarly survival at the end of the winter of year t is impacted by animal fat reserves which also depend on the previous summer pasture use of t 1 plant biomass processes in year t are only dependent on rainfall in year t the dynamics of the model for year t thus depend on events taking place in years t 1 and t for this reason we express the state x t x r 6 of the system in year t as follows x t u b t n b o g t n b o d t u b t 1 n b o g t 1 n b o d t 1 where u b t is underground biomass kg ha and n b o g t and n b o d t reflect herd size through bog and bod numbers heads respectively animals are allocated to a given surface which is why n b o g t and n b o d t reflect stocking rates animal number per hectare n b o g t and n b o d t are capped by the maximum number of heads herders can look after respectively 500 and 90 heads on average joly et al 2019 climate variability w t œµ w r 6 is w t p t w p t w t t p t 1 w p t 1 w t t 1 where p t denotes precipitation available for vegetation mostly falling in the form of rain w p t denotes winter precipitation falling in the form of snow and w t t is the mean winter temperature p t w p t and w t t follow the distributions observed in historical series 1 1 p has a poisson shape type distribution mean 80 64 sd 41 47 wp has a normal distribution mean 8 17 sd 4 40 and wt has a normal distribution mean 12 84 sd 2 14 and they are independent from each other in the model for a given year therefore for any year t 1 p t 1 w p t 1 and w t t 1 are independent from each other and are also independent between years e g for any couple of distinct years t 1 and t 2 p t 1 and p t 2 are independent this configuration correctly simulates dzud frequency joly et al 2018a the control management action u t u r 2 is u t u b o g t u b o d t where u b o g t and u b o d t are the sales and purchases of bog and bod respectively heads when u is positive animals are sold and when it is negative they are purchased contrary to dynamics it applies to a single year because decisions only influence year t they cannot apply to past states the model s dynamics are expressed by eq 1 1 x t 1 x t f x t u t w t the model expresses herders constraint satisfaction with function c s x t u t w t which is equal to one when constraints are satisfied and zero otherwise this function is based on model dynamics weather and management decisions the expressions of c s and f are given in appendix a 2 4 stochastic viability to apply the sv framework we considered the trajectory of the system during time steps 0 t the controls applied during these steps are denoted by u u 0 u t and the climate values are denoted by w w 0 w t the state reached at time t when applying controls u over time period 0 t starting from state x 0 is x x 0 u w t eq 2 2 x x 0 u w t x 0 œÑ 0 t f x x 0 u w œÑ u œÑ w œÑ the purpose of relevant strategy u in a context of uncertainty is to ensure that constraints will be satisfied over time with the highest possible probability the sv decision making process must therefore identify controls u x 0 which starting from state x 0 maximize the expected value of c s along time steps 0 t this approach is formally expressed by eq 3 3 u x 0 arg max u u t 1 e w w t 1 t 0 t c s x x 0 u w t u t w t where arg identifies the specific u value s satisfying the condition shown between parentheses and e is the expected value of the expression shown between parentheses eq 3 hence indicates that management strategy u maximizes the probability that constraints are satisfied over time and this probability is assessed by the expected value of the product of annual c s values identifying this u strategy is challenging because it implies for instance identifying a series of management options amongst a number of possible candidates that increases exponentially with time e g 1020 candidates for 10 yearly possible control options over 20 years we identified strategy u through the backward procedure of dynamic programming applied to stochastic viability as in doyen and de lara 2010 this procedure makes it possible to identify the given strategy by finding recursively year by year the best possible decision for a given year the method applies this approach while maintaining the dynamics between years as explained below years connected through eq 4 and 5 by doing so the procedure solves a very difficult problem concerning a trajectory spanning 20 years for example by solving 20 simpler annual sub problems bellman 2003 this procedure uses value function v that returns for a given state and year the highest probability of constraint satisfaction this probability is obtained by scanning a range of possible u values eq 4 and 5 by finding the pair of controls u b o g t and u b o d t providing the highest probability of constraint satisfaction the most adapted decisions for a given year and state are identified we used this approach to derive our decision making process using dynamic programming involved two modelling simplifications the first concerns the dynamics of the system which depend on the weather of two subsequent years the dynamic programming algorithm computing v only refers to the weather of a single year see eq 4 and 5 leading us to approach the pasture use factor of t 1 with that of t because they are closely correlated in the area joly et al 2018b these simplified dynamics are denoted as f s and use simplified arguments x s and w s f s is calculated by replacing p u t 1 with p u t in eqs a 3 and a 7 see appendix a x s t 1 x s t f s x s t u t w s t x s t u b t n b o g t n b o d t w s t p t w p t w t t this simplification did not prevent us from using c s due to the form of the equations on which it is built see appendix a second to save computing time we only considered typical weather configurations for w s w s these configurations are based on cut off values and distributions of rainfall p t and an indicator of winter harshness w h t derived from w p t and w t t appendix a these cut offs separate p t and w h t for dzud and non dzud years based on their values in historical series values above cut offs were averaged and their proportions were calculated for example the mean p for dzud years is 36 4 mm and p is below this value for 20 of the years the mean p value during non dzud years is 91 mm and p is above this value for 80 of years values summarized in appendix a table a 2 we obtained in this way four types of years as follows w s w 1 s wet mild w 2 s wet harsh w 3 s dry mild w 4 s dry harsh each type of year w k s has a probability p w k s that is not dependent on t hence for any couple of distinct years t 1 and t 2 w s t 1 and w s t 2 are independent which ensures that dynamic programming can be applied value function v is expressed through eq 4 and 5 and computed for the following ranges of state variables the maximum n b o g t and n b o d t are 500 and 90 heads respectively due to the above explained workforce limits and the minimum value for both livestock types is 0 based on trials using these livestock values u b t ranges between 100 and 700 kg ha t is set to 20 years for computing time constraints computing v implies scanning large numbers of states and controls with the above simplifications value function v is computed as follows 4 v t x s max u u e w s w s cs x s u w s v t x s max u u e w s w s cs x s u w s v t 1 x s f s x s u w s where 5 e w s w s cs x s u w s k 1 4 cs x s u w k s p w k s e w s w s cs x s u w s v t 1 x s f s x s u w s k 1 4 cs x s u w k s v t 1 x s f s x s u w k s p w k s 2 5 trajectories 2 5 1 types of trajectories to formally assess the pertinence of sv for making management decisions we built trajectories derived through sv then as mentioned in introduction we compared these trajectories to a second type based on a livestock number capping rule we evaluated in this way the added value of sv relative to a simple adjustment rule we compared in addition sv trajectories to a third type built without a rule we assessed this way the baseline performance of no rule management in these no rule trajectories herders let animal numbers grow until a dzud occurs in the three types of trajectories apart from animals sold herders obtain income from fibre and the culling of older animals see appendix a hence even in no rule trajectories herders obtain an income the three types of trajectories built are called viability capping and default trajectories table 1 we built 1000 simulated trajectories of each type for 100 years and assessed mean constraint satisfaction c s for two levels of annual income constraints above once and twice the poverty line for a household from parameter conspoverty multiplied by 1 or 2 see appendix a we assessed this way the capacity for sv to handle different income objectives the income objective is indicated in trajectories by suffixes povx1 and povx2 table 1 2 5 2 trajectory building we built the three types of trajectories based on nonsimplified dynamics f and climate distributions w simplified ones were only used to compute v we randomly set for each year a value for p w p and w t according to the same mean standard deviation and distribution of historical series starting point x 0 is defined as n b o g 252 n b o d 36 and u b 500 for both years of the state based on the most recent surveys joly et al 2018a we built viability trajectories by considering for each year t vector n b o g t n b o d t u b t this vector corresponds to simplified state x s and we extracted the most adapted control u x s 0 identified when calculating v 0 x s eq 4 this extraction according to x s makes our sv procedure adaptive when several values of u x s 0 were possible we randomly selected one we built capping trajectories with a rule involving selling animals when the overall size of the herd in sheep forage units sfus exceeds a threshold from this overall threshold we declined bog and bod thresholds in heads above which animals were sold we used 360 and 400 sfu thresholds for povx1 and povx2 respectively as they returned the best c s obtention of these thresholds explained in appendix b the capping trajectories also integrate a mechanism of bog bod exchange after a dzud this resilience mechanism practised by herders involves selling resistant bod heads after a dzud to buy fragile bog heads joly et al 2019 we finally built our default trajectories by simply setting u b o g t and u b o d t to 0 further details on the trajectory building of the three types are given in appendix b models were written in python 3 7 0 with the help of spyder 3 3 1 available at https github com fejoly stochastic viability 3 results 3 1 constraint satisfaction of all types of trajectories for both income objectives poverty line x1 or x2 mean c s increases from default to capping and then to viability table 1 capping and viability trajectories have mean c s values ranging from 0 71 to 0 94 whereas mean default c s ranges from 0 08 to 0 18 this poor default performance is attributable to the violation of the subsistence consumption constraint bog and bod meats are not substitutable for preservation purposes and due to the high dzud frequency in default trajectories bog livestock is superseded by bod livestock fig 4 as a result bog herds fail to satisfy the bog meat constraint viability trajectories are thus the most efficient and they are also the most stable as illustrated by the c s coefficient of variation table 1 such stability is further illustrated by the shape of the trajectories which reach plateaus for both c s and state variables figs 3 and 4 the other trajectories show less stable trends and for example default trajectories are unable to prevent a decrease in underground biomass moreover capping trajectories are unable to prevent a slight decrease in c s over 100 years fig 3 it is of interest to note that the capping and viability trajectories maintain a stable level of underground biomass close to the starting value 500 kg ha it is also noteworthy to mention that viability trajectories succeeded in providing mean incomes of above the parametrized threshold table 1 with the highest c s found for viability povx1 table 1 viability povx1 trajectories are therefore the most efficient in terms of stability but viability povx2 trajectories are the most efficient in terms of income the difference in c s found between the capping and viability trajectories is finally more important for povx2 Œ¥ 0 15 than for povx1 Œ¥ 0 08 which indicates that when the level of constraint increases the higher efficiency of sv becomes more apparent 3 2 factors affecting trajectory efficiency the better performance of the viability and capping trajectories are due to the reduction in dzud frequency increase in livestock fecundity table 1 and stabilization of bog bod proportions fig 4 the bog bod proportion was parametrized in the capping trajectories from the maximum possible number of animals while it was automatically adjusted in the sv trajectories by the viability process this is notably obtained through a post dzud exchange mechanism of bogs and bods illustrated by the relationship between post dzud bog numbers and bog sales fig 5 this relationship between livestock numbers and bog sales u b o g t shows that after a dzud if bog herds become too small sv models buy animals livestock numbers are assessed here from herd size before culling and sale or purchase see appendix a solving the associated linear regression indicates that the purchase takes place on average for both sv trajectories when the post dzud bog herd falls below 100 heads fig 5 in other words most of the time the sv process chooses to buy animals if the bog herd falls below 100 heads this 100 head value is close to that recorded from interviews of local herders joly et al 2019 in addition the bog purchases concern batches of bogs of 40 heads or less in 91 and 93 of the dzud years for viable povx1 and povx2 respectively fig 5 finally the post dzud mechanism is further characterized by the relationship between bog and bod sales u b o g t and u b o d t showing that the purchase of bogs is typically associated with a bod sale fig 5 in other words most of the time the sv process chooses to sell bods when it buys bogs 4 discussion 4 1 stochastic viability pertinence our objective was to assess the ability of the sv approach to define a pertinent stocking strategy in the context of environmental uncertainty sv provides a mathematical definition for such a strategy through u eq 3 and offers tools with which to translate this strategy into concrete management decisions u t through the dynamic programming of doyen and de lara 2010 by using these tools we obtained trajectories that clearly demonstrate sv pertinence by ensuring high rates of constraint satisfaction mean c s and preserving long term forage potential we observed this efficiency without a duration limit as systems are stabilized several decades before the end of the 100 year horizon in this respect our results extend beyond studies of agrosystems exposed to environmental stochasticity reported by oubraham and zaccour 2018 these studies are either based on a shorter duration sabatier 2010 sabatier et al 2012 or stabilize performance less efficiently baumg√§rtner and quaas 2009 tichit et al 2004 the comparison of the default and capping trajectories helps illustrate through which drivers strategy u is implemented the comparison shows that post dzud bog bod exchange the capping of livestock numbers to reduce dzud frequency and underground biomass stabilization are drivers of efficiency these drivers generate resilience as they enable the absorption of climate shocks and reorganization after crises dzud walker et al 2004 sv management uses these drivers more efficiently especially when income constraints are high which is attributable to the dynamic programming procedure this procedure helps obtain these states that ensure the highest probability of constraint satisfaction over time which obviously contributes to improved long term performance the procedure also makes decisions adaptively i e based on the state of the system our results thus demonstrate that sv through its long term focus and adaptive approach makes it possible to derive a decision making process pertinent in the context of climate variability our results also illustrate interesting aspects of the sv framework itself first they show that the simplifications made to the weather distribution from w to w s and to system dynamics from f to f s did not prevent building trajectories with high rates of constraint satisfaction these simplifications were made because of the complexity of the system and based on a thorough knowledge of its dynamics this illustrates that dynamic programming applied to stochastic viability can be used in complex systems following relevant simplifications the fact that trajectories are stable over 100 years despite training over 20 years v computed over 20 years illustrates an additional level of robustness this shows that an initial momentum ensuring sustainability can be given to the system second our use of different levels of income constraints and identification of different levels of constraint satisfaction represent a quantitative application of the viability framework showing that the focus can be placed on income viability povx2 or stability viable povx1 this indicates that trade offs can be studied through viability theory even though this was not its initial purpose aubin 1991 finally we focused on assessing sv efficiency to manage stochasticity around a mean and therefore did not take climate change into account however it could be possible to integrate this process and in this case for a given starting state the management and value functions u and v would depend on an initial date a climate trend could be this way integrated in v computation 4 2 towards the development of a decision making tool from a technical perspective decision making tools could be built from the applied sv procedure they would involve defining management decisions according to the system state as modelled here the state would be defined by herd size which is easily accessible to herders and underground biomass which is more difficult to measure but can be assessed through plant cover joly et al 2018a bog number bod number and underground biomass values could be sent through sms or smartphone applications to a server and control values the sale or purchase of animals could be returned this control extraction method is fast once value function v has been computed i e over 20 s on our regular laptop computer while v computation over 20 years took several hours the control value could then be sent back to a phone through a mass messaging system similar to that developed in mongolia to warn of weather hazards people in need 2018 from a nontechnical perspective these decision making tools would have both advantages and disadvantages a first advantage is that income levels can be parametrized which offers interesting options viability povx2 is in this regard particularly interesting and could be chosen by herders who have bank cash saving mechanisms ifrc 2017 herders might for this reason be more interested in the mean level of income over time than in the annual satisfaction of the poverty line a second advantage is that some of the controls applied by the sv procedure are in line with a resilience mechanism found in traditional pastoral societies of africa and asia post disaster animal exchange is indeed commonly practised within multispecies herds as mentioned above the method is practised in khomyn tal and is based on a portfolio of species with distinct traits such as resistance to hazards to provide a safety net and high fecundity to provide a growth asset blench and marriage 1999 joly et al 2019 mace 1989 by continuously adjusting the numbers of animals of the different species types herders maintain stable performance despite hazards and die offs the 100 head threshold above which models and herders restock their bog herd i e choosing to buy animals suggests that this mechanism is very similar in sv trajectories and real systems regarding the disadvantages of the sv process viable trajectories first have a dzud avoidance approach that differs from pastoralist practices pastoralists indeed commonly maximize their herd numbers as part of a risk mitigating strategy to accumulate wealth in anticipation of hardship hendricks et al 2004 naess and bardsen 2013 roe 1998 rota 2009 thrift and ichinkhorloo 2015 by using small herds sv trajectories do the opposite and following an sv strategy would require herders to change their risk perceptions this is a challenge because smaller herds involve an immediate and visible loss of earnings through reduced annual income from fibre and culled animals oppositely gains are less tangible as they are obtained through fecundity increases which may be difficult to assess and through dzud frequency reductions i e on a certain time horizon in a probabilistic manner reducing numbers may therefore be perceived by herders as gambling on hypothetical gains a second disadvantage is that applying sv management implies a fluid market the approach requires the presence of a pool of animals that can be purchased and a demand that can absorb animals for sale the availability of bogs to purchase after a dzud and their price might be the most acute problem as most people may need animals at the same time however restocking animals could be transported from less to more severely impacted areas as dzuds have variable intensity across mongolia nandintsetseg et al 2017 the number of animals purchased were in addition most of the time in our models below 40 which is close to transactions locally observed joly 2015 purchasing enough animals may therefore not be a problem a final difficulty of this decision making process is that livestock of several households can mix between seasonal camps this could affect the assessment of the size of herds grazing in a seasonal area and reduce the precision of the management decision made however it may be possible to solve this problem by using the tool at the scale of community groups such as those already established in the country ulambayar et al 2016 this above list of pros and cons hence suggests that there may be more sociocultural market and land governance obstacles than technical difficulties for the adoption of sv based decision making tools these factors should be addressed before considering large scale application the integration of sv processes with other pastoral management tools such as mobility should also be addressed 4 3 precision livestock farming beyond the mongolian context our results can contribute to research on livestock precision farming plf to date plf is mostly applied to indoor industrial contexts shalloo et al 2018 for example to adjust levels of feed to individual animal needs and prevent the systematic use of medicine shalloo et al 2018 tullo et al 2019 our sv management approach could be used as part of a plf scheme in outdoor grass based systems it would be relevant in the case of herds involving a diversity of animals with distinct traits species or races as using such diversity for resilience is one of the principles of agroecology applied to livestock farming systems dumont et al 2013 the approach we used with bogs bods could hence be extrapolated to any kind of diversity such support would be valuable since diverse livestock systems are more complex to manage than simple ones martin et al 2020 in addition the ergonomics of agroecological practices are receiving interest joly et al 2021 which justifies the investigation of tools that could be used to ease their implementation our results therefore illustrate how models and computer decision making tools could be used in an agroecological context 5 conclusion we demonstrated in this article the potential for sv to be used to make pertinent decisions in a complex system exposed to environmental shocks sv decisions generate trajectories that are more effective and resilient than those proposed by a simple livestock number capping rule through a long term and adaptive approach our use of sv was possible due to specific modelling simplifications based on a thorough comprehension of the studied system we thereby illustrated that the benefits of sv are not only theoretical but also practical from the possibility of deriving a concrete decision making process regarding applicability to mongolia we identified several developments that would be needed to implement our decision making process add a climate change trend in the value function calculation study the fluidity of the livestock market to confirm the possibility of buying enough bog heads after a dzud assess the attitudes of herders towards livestock number reduction as a risk avoidance strategy assess the possibility of implementing decisions at the community level incorporate the process into a broader decision framework integrating pastoral mobility credit authorship contribution statement fr√©d√©ric joly conceptualization methodology software formal analysis writing original draft visualization rodolphe sabatier conceptualization methodology software laurent tatin writing review editing claire mosnier writing review editing ariell ahearn writing review editing marc benoit writing review editing bernard hubert writing review editing guillaume deffuant conceptualization writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements the authors acknowledge support received from the agence nationale de la recherche of the french government through the program investissements d avenir 16 idex 0001 cap 20 25 appendix a model dynamics vegetation submodel u b t is modelled according to eq a 1 which describes how biomass allocation from underground biomass enables aboveground biomass ab to grow at the beginning of the growing season when photosynthesis has not yet started m√ºller et al 2007 it describes how u b requires regular biomass reallocation from ab to compensate for biomass previously used this reallocation from ab compensates for u b natural mortality without this reloading u b is slightly depleted a 1 ub t 1 ub t m ub t 1 d ub t w res w gr p t ub t co t 1 d ub t where m is a natural mortality rate and d is a density dependence parameter the higher the level of underground biomass is the slower it is replenished and the faster it dies w res denotes the proportion of ab allocated to u b replenishment and w gr is a factor of rain use efficiency accounting for run off and evapotranspiration p t is precipitation occurring over the first 8 months of the calendar year considered usable by vegetation it accounts for the soil moisturizing effect of winter precipitation in the spring at the time vegetation starts growing nandintsetseg and shinoda 2011 c o t is the livestock consumption of aboveground biomass per ha and reduces the amount of plant standing foliage of plants eq a 2 a 2 co t conssu i bog bod n i t sf u i Œ∑ œÉ where conssu is the mean daily amount of forage consumed by a sheep and sf u i is a coefficient that converts the daily forage intake of type i into an equivalent in sfu Œ∑ is the stay duration in the summer zone day and œÉ is the area used by one household ha livestock submodel the livestock submodel distinguishes dzud and non dzud years with the help of index i d z u d t the index illustrates how a low availability of forage and a cold and snowy winter result in a dzud eq a 3 i d z u d t p u t 1 w h t a 3 with w h t w p t m a x 0 w t threshold w t t Œ∏ where p u t 1 is the pasture use ratio of forage consumed to available forage and w h t is an indicator of winter harshness we used the pasture use of year t 1 to express the i d z u d t value of year t because dzud mortality occurs at the end of the winter during the first months of the year as a consequence of the previous year s conditions w p t is the cumulative precipitation of the six coldest months of years t 1 and t october to december of year t 1 and january to march of year t representing the snow water equivalent for the winter used to quantify snow abundance w t t is the mean temperature of the six coldest months of years t 1 and t october to december of year t 1 and january to march of year t w t threshold is a temperature threshold and Œ∏ is a coefficient making i d z u d t equal to 1 to separate dzud from non dzud years in simulations p u t is expressed by eq a 4 a 4 p u t c o t œÉ w gr p t u b t œÉ œÜ reserve where œÜ reserve is a local riverbed forage used for reserve grazing and is expressed by a constant because this vegetation is less prone to degradation than desert steppes as it is not used continuously and it is abundantly watered by the river water table dynamics of animal type i are expressed by eq a 5 a 5 n i t 1 n i t n i t l idzud t i b i t subs orcu l i t u i t where l i d z u d t i is the death rate of a type i animal according to the occurrence or absence of a dzud b i t represents the number of born animals s u b s o r c u l i t denotes the number of old animals either slaughtered for subsistence consumption or culled and u i t is the control term that defines the number of animals sold or purchased when it is positive animals are sold and when the value is negative animals are purchased b i t is expressed by eq a 6 a 6 b i t n i t 1 l idzud t i fe m i acu l i are p i acu l i pro d idzud t i t where femi is the percentage of females arepi is the age at which gravid females give birth for the first time aculi is the age of culling for subsistence or the sale of old animals and p r o d t i d z u d t i is the productivity assessed by the number of young born animals per female of breeding age this value depends on dzud occurrence because females can miscarry during such a disaster and on p u t 1 which affects body condition at the time of reproduction especially at the time of gestation joly et al 2018b the value is expressed according to eq a 7 and bounded by minprodi and maxprodi a 7 if idzud t 1 pro d idzud t i t Œ≥ i 1 pu t 1 œà i if idzud t 1 pro d idzud t i t Œ¥ i where Œ≥ i and œà i are coefficients and Œ¥ i is a constant s u b s o r c u l i t is equal to the proportion of animals culled if it is higher than the number of animals that herders consume in year t and corresponds to the renewal rate of species i in the herd if this rate is too low to satisfy subsistence consumption herders slaughter more animals eq a 8 a 8 s u b s o r c u l i t max n i t 1 l i d z u d t i b i t acu l i con s i subs where cons i subs represents the number of heads needed for subsistence consumption constraints the constraints are expressed for convenience according to variable n i b c s t that describes livestock numbers before culling and sale or purchase eq a 9 this variable is also used to study the relationships between livestock numbers and the number of bog heads purchased after a dzud a 9 n i b c s t n i t 1 l i d z u d t i b i t the first two constraints concern the availability of animals for subsistence consumption of bog and bod meat before culling ineq a 1 and a 2 both types are distinguished because they are not substitutable bogs are consumed during the warm months when they have enough body fat and bods are consumed in the winter when their carcasses can be frozen outside of herders camps bods are slaughtered at the beginning of the season and bog bod consumption practices ensure a year round availability of meat ineq a 1 n b o g b c s t c o n s bog subs if ineq a 2 n b o d b c s t c o n s bod subs the third constraint refers to the subsistence consumption of milk and milk products and its expression depends on livestock productivity as females that produce milk are only those that have given birth ineq a 3 ineq a 3 i bog bod n i bcs t prod t idzud t i Œº i con s subsmilk where con s subsmilk is the milk consumption threshold and Œº i the amount of milk produced by a head of livestock accounting for the age and sex structure of the herd the fourth constraint refers to the availability of transport animals for household con s ride draft i e the availability of horses used for herd management and camels used for draft ineq a 4 ineq a 4 n b o d b c s t con s ride draft n b o d t con s ride draft both n b o d b c s and n b o d are considered as draft animals are used year round the fifth constraint refers to household revenue three types of income were taken into account and overall household income was calculated by summing the income values and subtracting the mean herding cost the difference had to be superior to poverty line conspoverty at the household scale ineq a 5 ineq a 5 i n f i b r e t i n l i v e t i n s k i n h i d e t hc con s poverty where infibre t inlive t and inskinhide t are respectively the annual incomes generated through the sale of fibre live animals and skins hides of animals slaughtered for subsistence hc denotes the herding costs and conspoverty represents the poverty line value as herders use very few inputs such as fodder or concentrates per head of livestock joly et al 2019 we considered hc to be constant the different incomes were quantified according to eqs a 10 a 12 a 10 i n f i b r e t i bog bod n i b c s t i i fibre a 11 i n l i v e t i bog bod max 0 n i b c s t acu l i c o n s i s u b s u i t i i live a 12 i n s k i n h i d e t i bog bod cons i subs i i skinhide where i i f i b r e i i l i v e and i i s k i n h i d e are the annual incomes generated by one head of animal of type i for each kind of product if ineqs a 1 to a 5 hold true constraint satisfaction function c s is equal to 1 and is equal to 0 otherwise if only one ineq is wrong c s 0 the parameters used in appendix a and their values are given in table a 1 appendix b trajectory building trajectories derived from sv for animal type i u x s 0 is capped by n i t 1 l idzud t i b i t subs orcu l i t to avoid selling more animals than is available this can happen for the most extreme values generated from nonsimplified weather space w since u is based on a simplified w s trajectories derived from a capping number rule the capping trajectories are based on a maximum livestock number eq b 1 b 1 n i max sf u max œÅ i sf u i where sf u max is the overall herd size in sfu bog bod n i max is the maximal number in heads of type i and œÅ i is the proportion of i in sfu within n i 0 from n i max controls u were derived eq b 2 b 2 u b o g t r i d z u d t n b o g t b c s s u b s o r c u l b o g t max 0 1 r i d z u d t n b o g t b c s s u b s o r c u l b o g t n bog max u b o d t r i d z u d t n b o d t b c s s u b s o r c u l b o d t max 0 1 r i d z u d t n b o d t b c s s u b s o r c u l b o d t n bod max where r i d z u d t is an adjustment ratio designed to exchange bog heads against bod heads after a dzud the value is equal to zero for i d z u d t 1 and l i d z u d t b o g l i d z u d t b o d 2 for i d z u d t 1 to assess the n i max that returned the best c s for both types of income objectives povx1 and povx2 we scanned values of between 0 and 1500 sfu 
