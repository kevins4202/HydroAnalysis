index,text
3805,in this manuscript we discuss the capabilities of a deep learning algorithm implemented with the conventional neural network concept to characterize the hydraulic properties of aquifers the algorithm called cnn ht is designed to predict the inverse operator of hydraulic tomography using a synthetic training dataset in which the hydraulic head data associated with pumping tests are linked to hydraulic transmissivity field this approach relies on an adaptation of the segnet network that was initially developed to process image segmentation the segnet is composed of encoders and decoders networks in the encoder sequential operations with multiple filters as convolution batch normalization max pooling are performed to identify feature maps of the input data in the decoder the up sampling convolution batch normalization and regression operations are used to prepare the output by recovering the loss of spatial resolution that occurred in the encoder process in this adaptation we used the least square iterative formulation at the initial iteration with jacobian matrix to resize the hydraulic head data to match the size of the output transmissivity field this protocol was applied to the hydraulic head data computed numerically by solving the groundwater flow equation for a given transmissivity field generated geostatistically with gaussian and spherical variograms a part of this data was used for training the network and the other part to test its performance the test step confirmed the effectiveness of this tool in reconstructing the main heterogeneities of the hydraulic properties and its effectiveness is related to the nature and quantity of the training data moreover the cnn ht method provided inversion results of the same quality than those obtained with the gauss newton algorithm using the finite difference or adjoint state method in the computation of the jacobian matrix however the computational time is longer in cnn ht but this time can be less or of the same order as that of gauss newton using finite difference method keywords inverse problem hydraulic tomography deep learning convolutional neural networks 1 introduction since the 1980 s the hydraulic tomography has been adopted in hydrology as an effective technique for mapping the heterogeneity of the hydraulic properties of aquifers neuman 1987 gottlieb and dietrich 1995 bohling et al 2002 yeh and liu 2000 indeed this approach can effectively provide insights into the spatial variability of the hydraulic transmissivity and storage coefficient of a porous or fractured aquifer through a combined interpretation of hydraulic data obtained from several pumping tests bohling et al 2002 berg and illman 2011 cardiff et al 2013 fischer et al 2018 the approach consists of using an inversion algorithm either deterministic or stochastic to retrieve the best models that could match the observed piezometric data fu and gómez hernández 2009a kitanidis 1997 in general the inverse solution is not unique for that reason the inverse formulation usually incorporates a regularization term in the optimization of the objective function ψ m that is defined as the sum of data misfit and regularization terms as below tarantola and valette 1982 1 ψ m f m h obs t c d 1 f m h obs data m i s f i t term m m 0 t c m 1 m m 0 constr aint term where the data misfit term assesses the pertinence of the model in term of matching the data and is expressed as a sum of square differences between the observed hydraulic data h obs and the numerical hydraulic data derived by solving a forward operator f m in hydraulic tomography the forward problem involves a numerical discretization for solving the groundwater flow equation subject to darcy s law in transient or steady modes m log t is the spatial distribution of the negative logarithm of the hydraulic transmissivity t which is regarded as an unknown field and is expressed logarithmically to ensure its positivity during the inverse process c d is a diagonal matrix for incorporating data uncertainty in the optimization on the other side the regularization term is expressed with a prior model m 0 and its covariance matrix c m this term can be obtained from geological geophysical and tracer investigations to constrain the inversion to offer only plausible solutions lochbühler et al 2013 zhao et al 2016 soueid et al 2016 in general the use of geostatistical constraints is still widely applied in hydraulic tomography by using statistical properties such as mean and covariance to obtain an imagery of hydraulic properties with smooth features kitanidis 1997 yeh and liu 2000 once the parameters of the objective function are formulated its optimization is processed iteratively using one of the three categories of optimization algorithms deterministic li et al 2005 stochastic jiménez et al 2016 or global castagna and bellin 2009 these algorithms involve a repetitive numerical solving of the forward problem by applying finite elements or finite difference methods to assess the ability of the proposed model to reach the convergence state therefore the computation time is dependent on the numerical tools the dimensionality of the unknown parameters and the nature of the optimization algorithm employed in general deterministic algorithms are the most used in high dimensional inverse problems due to their advantage of reaching convergence in a short time compared to stochastic or global algorithms by exploiting the geometric properties of the objective function gradient and hessian tarantola and valette 1982 nevertheless their efficiency depends strongly on the choice of the initial model as they only provide local minima on the other hand stochastic methods such as markov chain monte carlo mcmc are based on the concept of sampling where the solution is obtained by exploring the optimization performance of many randomly generated models and selecting the best of them in terms of minimization of the objective function most of the time algorithms belonging to this category are easy to implement and insensitive to the initial model however their applicability to inverse problems with a large number of unknown parameters remains limited due to the high repetitive and heavy computation of the forward problem during the sampling process oliver et al 1997 fu and jaime gómez hernández 2009b wang et al 2017 jardani et al 2012 elsheikh et al 2012 other global optimization algorithms such as particle swarm optimization genetic simulated annealing can also be used to identify the best solution by iteratively evaluating the objective function until the state of convergence however convergence can be slow especially in the case of high dimensional inverse problems scales et al 1992 fernández martínez et al 2011 in this paper we test a new generation of deep learning algorithm that can be considered as a global optimizer in which prediction does not depend on an initial model and the computation of the sensitivity matrix as it is the case for gradient based methods zio 1997 the concept of this approach is different from previous optimization methods as the process focuses on approximating the inverse function by finding a universal relationship linking the input and output data in the case of hydraulic tomography between hydraulic pressure and hydraulic transmissivity indeed the deep learning is a powerful generalizer of non linear and complex functions by identifying a set of parameters such as weights and biases allocated to the hidden layer neurons that process the input data and link them to their corresponding output the first generation of deep learning algorithms uses a set of hidden layers with a large number of neurons fully connected via high dimensional weights which complicates computation and requires a lot of time especially for handling the imaging tasks shen 2018 however the emergence of new deep learning architectures with convolutional neural networks cnn concept that have been proven in high resolution image processing have opened the way for broadening their applicability in the hydraulic characterization lecun et al 1998 sun 2018 zhu and zabaras 2018 indeed the cnn concept has succeeded in reducing drastically the image processing time thanks to the convolution calculation which allows to retrieve the local features of the image through small filters indolia et al 2018 these filters cover the whole input image but their activation is done zone by zone with local connections between pixels this local convolution reduces the number of parameters to optimize during the learning process lecun et al 1998 among the first attempts at adopting the cnn concept in the realm of tomography by inversion in geosciences we cite sun 2018 trained the generative adversarial networks for linking the hydraulic head map and the spatial distribution of hydraulic conductivity zhu and zabaras 2018 proposed a deep convolutional encoder decoder network to reconstruct the image of hydraulic conductivity from hydraulic head map laloy et al 2018 used the generative adversarial networks to generate randomly in 2d and 3d binary hydraulic conductivity fields and mcmc to perform the inversion process in geophysics realm wu and lin 2018 applied cnn with encoder decoder networks for mapping the subsurface velocity from seismogram data puzyrev and swidinsky 2021 used the cnn network to determine the vertical subsurface heterogeneity of electrical conductivity by training electromagnetic data in this article we discuss the use of the convolution neural networks formed according to the segnet architecture to process hydraulic tomography this technique was initially designed for the semantic segmentation of objects learned on the images badrinarayanan et al 2017 to illustrate the inversion principle with the cnn ht structure we organize this manuscript with the following outline the first section will be devoted to the generation of data used in training validation and test and the second to the introduction of concept of the cnn segnet structure in the application sections we discuss the relevance of the approach on theoretical cases under different conditions on training data with high and low resolution and contaminated or not by the noise we also devote a section to the comparison of the results obtained with cnn segnet code with those determined with the gauss newton algorithm 2 theoretical concept 2 1 preparation of training data in deep learning algorithm the first step concerns the construction of training data that will condition the accuracy of the result obtained from the predicted inversion operator see fig 1 given the impossibility of having a real dataset connecting the spatial distribution of hydraulic properties of aquifers and the piezometric responses we use synthetic models in which the hydraulic parameter fields are generated geostatistically and their corresponding piezometric responses are obtained by solving the numerical groundwater equation in steady state forward problem 2 f m t h q p δ x p x h h 0 γ d where m is the negative of logarithm of transmissivity t 10 m randomly generated and distributed on the studied domain h is the hydraulic head responses due to water extraction represented by a point source term q p δ x p x defined at pumping well locations x p δ is dirac delta function the pumping tests will be done sequentially on several wells the forward problem is solved by finite element technique using the comsol software with a constant hydraulic level h 0 imposed as dirichlet boundary at all limit of the domain γ d that are positioned far from the studied area for reducing their impact as the nature of the training models conditions the result of the cnn ht inversion we have to use the prior information on the studied field to establish a cluster of models for training and targeting a type of solution with certain characteristics in this paper prior information is expressed in statistical terms with a gaussian distribution wherein the mean and covariance are held constants during model generation once the parameters of the distribution are defined we launch the generation of thousands of hydraulic transmissivity fields using the sgems code implemented in matlab remy et al 2009 the generated transmissivity fields are then assigned to a domain of 40 m 40 m on which we set up a dense distribution of wells to better cover the heterogeneity of the field on this configuration we conduct 5 pumping tests in such a way to hydraulically disturb the whole area each pumping test allows us to retrieve 44 measurements from the remaining observation wells in the end we obtain 220 measurements for each field see fig 2 to predict an inversion operator using convolutional neural networks with the encoder decoder architecture we need to reshape the piezometric data into a field with the same dimension than the hydraulic transmissivity field in order to link tow images with the same size to do this we can use one of two methods i the first consists in interpolating the piezometric data recorded on the observation wells for each pumping test in order to form images with the same resolution in the target transmissivity field in this case the input data are composed of a number of maps equal to the number of pumping tests in our example we have 5 pumping tests and we will then obtain 5 maps that will be treated jointly as 5 channels in convolutional neural networks ii this second is more compact than the first in which all piezometric data set recorded for different pumping tests are introduced by a single map using a projection operation derived from the gauss newton formulation this formulation results from the minimization of the objective function presented in the introduction section ψ m m 0 tarantola valette 1982 3 m i 1 m i j i t c d 1 j i c m 1 1 j i t c d 1 h obs f m i c m 1 m i m 0 where j i is jacobian matrix with a size of n m n and m are number of the data and the unknown parameters respectively at the first iteration usually we start with the prior model then 4 m 1 m 0 j 0 t c d 1 j 0 c m 1 1 j 0 t c d 1 h obs f m 0 and this equation can be reformulated under this following form 5 m 1 β λ h obs 6 β m 0 j 0 t c d 1 j 0 c m 1 1 j 0 t c d 1 f m 0 and 7 λ j 0 t c d 1 j 0 c m 1 1 j 0 t c d 1 m 1 is the hydraulic transmissivity model resulting from the first iteration obviously it does not fit the observed data but it can be applied as a projection term for all piezometric data in order to convert them into matrices with same size as the transmissivity fields j 0 is the sensitivity matrix of the prior homogenous model m 0 representing the mean of the fields in this case the jacobian can be derived analytically using the thiem s equation for confined aquifers to express the radial flow field and its adjoint state operator for details see appendix to further simplify this projection term so that it is less dependent on prior information we remove the bias term β replace the covariance matrices c m and c d by simple identity matrices now the new projection term takes this form 8 h obs p λ h obs w i t h λ j 0 t j 0 i m 1 j 0 t thanks to this simple multiplication the hydraulic data h obs will be transformed into a vector h obs p of the same size as the output hydraulic transmissivity field and used in matrix form as the input field in the network this formulation allows to link linearly h obs and h obs p and preserves all the hydraulic information to establish a relationship between h obs p and transmissivity field the comparison of the results of the two methods linear interpolation and projection in terms of inverse operator prediction is presented in the last section however the first sections all applications are done with the projection method 2 2 inversion by convolutional neural networks with encoder decoder structure in this article we will explore for the first time the efficiency of segnet architecture to process the inversion in hydraulic tomography the approach uses the conventional neural networks concept built with an encoder decoder architecture see fig 3 this approach was originally conceived to process semantic segmentation of images by delineating the shapes of learned objects badrinarayanan et al 2017 in the encoder network the input image is processed sequentially by a set of encoders in our case we use only 2 encoders chosen after an analysis of the inversion results obtained with networks having 1 2 and 3 encoders the network with 2 encoders gave the best result in terms of training and generalization with a low sensitivity to overfitting each encoder starts with a convolutional process in which multiple filters with the small size 3 3 64 are convoluted on the input layer zone by zone to identify their features badrinarayanan et al 2017 this calculus permits to establish a local connectivity between pixels with these shared small filters which remain simple to predict in the training process the convolutional operations are followed by batch normalization which is a linear operation that plays the role of a regularizer in scaling the convolution outputs in order facilitate and accelerate the training ioffe and szegedy 2015 this step is followed by the application of the relu function which introduces the nonlinearity in the process then the dimensionality of the result of the previous sequence will be considerably reduced in the max pooling layer with stride of 2 and 2 2 windows to keep only the main features therefore the construction of feature maps in the encoder network leads to a decrease in the spatial resolution that will be restored in the decoder network indeed the decoder network is configured in a symmetrical form with 2 decoders to prepare the output by recovering the resolution lost in the decoder with up sampling operations from the max pooling indices obtained in the previous max pooling layers carried out in each encoder badrinarayanan et al 2017 these results of up sampling will be convoluted with other filters to build feature maps with more details then the batch normalization and relu are applied successively on the convolutional outputs as in the encoder network at the end of the encoder network we add a convolution layer having the same size of the output and a regression layer to assess the performance of the training this last layer replaces the softmax layer used in the original version of segnet network for the segmentation task the set of weights and biases υ used in the various encoder decoder operations are chosen in way to match the training data m i h obs i p by minimizing this objective function 9 υ arg min i 1 nt m i f 1 h obs i p υ where i is the sample index of the training data set with nt as size of the training data f 1 h obs i p υ denotes the inverse function to identify by using the training data in the prediction of the networks parameters υ with adam optimization algorithm kingma and ba 2014 this optimizer was run with a batch size of 70 and a learning rate starting at 0 01 and decreasing by 0 1 every 50 epochs the computation was performed on a workstation with intel r xeon r silver 4110 cpu 2 10 ghz and 128 g of ram with a single gpu after training is complete we use a sample of generated data not used during training phase to check the quality of the inversion results by the cnn ht code 3 applications to synthetic cases in this section we apply the inversion concept with cnn encoder decoder networks on theoretical cases where the log of hydraulic transmissivity fields are generated randomly with a gaussian variogram and their hydraulic head responses by the groundwater equation as explained in the data preparation section this distribution has μ 10 5 m2 s as mean and an isotropic gaussian variogram with 0 5 and 10 m as variance and range respectively with this variogram model we performed 11 000 realizations in which the transmissivity is ranging over 10 8 3 10 1 6 m2 s however 95 of these models have transmissivities between 10 6 4 and 10 3 5 m2 s see fig 4 then these models are used in a forward operator that takes 2 s per simulation to get the hydraulic head responses these realizations aim to evaluate the effectiveness of the cnn segnet approach in the reconstruction of hydraulic transmissivity field and to analyze the sensitivity of this reconstruction to the size of the training dataset and the amount and uncertainties of the hydraulic head data collected during the pumping tests 3 1 effect of training data size in the first analysis we examine the impact of training data size on the reliability of the inverse operator prediction and determine the amount of data required to obtain a satisfactory prediction for this purpose we performed three assessments with different training data sizes t1 1000 t2 3000 t3 10000 the validation was done with 1000 models and the test with 500 models different from those used in the learning phase training and validation during the optimization process we followed the quality of the minimization of loss functions with the training and validation data until they reached optimal values to stop the process manually or wait until the maximum number of epochs was met see fig 5 in this way we avoid the problem of overfitting which appears especially when we tried to build the network with a limited number of training data t1 1000 the results obtained with these different sizes of training data are presented in the table 1 a in which we can easily identify through the analysis of the correlation coefficient between the real and predicted models of test sample that the accuracy of the prediction improved with increasing training data size indeed the reliability of the predictive model derived from a deep learning algorithm is highly dependent on the amount of data used in the training in which a large amount of data guarantees a good prediction this implies a long computational time in the generation of training data in any case the degree of accuracy desired remains linked to the nature of the problem studied in our case training with t1 1000 data allowed us to predict 500 test models with a correlation coefficient r between real and predicted models ranging from 0 74 to 0 93 and a mean of 0 86 see table 1a from these models we choose 3 models the first one m1 with a relative poor prediction r 0 75 a second model m2 r 0 83 close to the mean representing quality of the majority of predicted models and the last one m3 with a good reconstruction r 0 91 see fig 6 these models will be used to analyze the impact of training data size on the quality of their estimations see fig 6 the first model m1 is characterized by a high degree of variability with the small heterogeneities at the boundary of the domain and a logarithm of the hydraulic transmissivity that varies between 6 2 5 over this range there are outliers in the gaussian distribution of training data in particular which are around 2 5 thus in this case only a few models have been seen in the training with this feature which explains the poor reconstruction see fig 6 the same problem occurs in the prediction of models with low outliers 6 5 however the models having variabilities well covered by training models such as m2 and m3 with transmissivities values between 6 5 3 5 the reconstructions are more accurate however if the number of training models increases the models with outliers will be more frequent and will be reconsidered in the generalization as shown in the table where the reconstructions of these models have been well improved 3 2 effect of amount of observation wells in the second analysis we study the influence of the number of hydraulic data collected during the pumping tests on the efficiency of the network to approximate the inverse operator in this analysis we first reduce the number of observation wells to half 22 observation wells and in the second step to one quarter 11 observations wells however we maintain the number of pumping tests and the size of the spatial discretization of the transmissivity fields 16 16 as used in previous test these new well configurations are illustrated in the fig 7 in practice only the hydraulic responses of abandoned wells are removed from previous training data thus these data acquired with the two new observation well configurations are used as training input to determine the corresponding inverse operators and the results obtained were compared to the previous configuration with 44 wells the training operations were performed with 10 000 models and the tests were also done on the previous unseen samples the reconstruction results of the test models with different series of piezometric data expressed in terms of correlation coefficients reveal a degradation of the accuracy of prediction with the decrease in the number of hydraulic data see table 1b because the number of piezometers becomes insufficient to cover all the heterogeneities and the complexities of the medium and this also occurs with classical inversion methods this is further confirmed by analyzing the spatial aspect of the reconstructions of models m1 m2 and m3 in which we observe a loss of resolution and an increase in smoothness degrees with the reduction of hydraulic data fig 8 however the main heterogeneities can still be identified with less data 3 3 effect of observation uncertainties in this section we analyze the effect of uncertainties that may be associated with hydraulic pressure measurements collected during pumping tests this involves contaminating the numerical piezometric data with a random gaussian noise of 0 5 as the standard deviation and verifying its impact on the quality of hydraulic field reconstructions of test models as a first analysis we use an inverse operator established on the basis of uncontaminated training data to interpret hydraulic head data from a test set that are contaminated by noise here the training operation did not take into account the noise the result of this test is presented by the benchmark models in fig 9 and table 1c of correlation coefficients which reveal a sharp degradation in the quality of the predictions compared to the noise free test models with a decrease in the correlation coefficient from 0 92 to 0 79 mean for all test models in the second strategy noise is taken into account in the estimation of the inversion function by adding noise to the hydraulic data used in the learning process this method has led to a significant improvement in the prediction quality of the test models as shown by the three models m1 m2 m3 and the correlation coefficient noted in table 1c with the average r of the set of models increasing from 0 79 to 0 84 however this prediction is less accurate when compared to the noise free training and test data as shown by the r values we can therefore conclude that uncertainties in the measured data may have an impact on the results of inversion as is the case with classical optimization techniques but to reduce their impacts it is necessary to incorporate these uncertainties in the construction of the inversion model i e in the learning process 4 comparison of cnn ht and gauss newton algorithms in this section we compare the inversion results obtained with the cnn ht algorithm with those determined by the traditional gauss newton gn method to this end we apply both algorithms to the reconstruction of a transmissivity field with a mean of 10 5 m2 s 1 and generated with a spherical covariance having 0 5 and 10 m as variance and range respectively however this time the models are highly discretized 32 32 compared to those used in the previous sections the gauss newton algorithm as described in the introductory section is a deterministic approach that relies on the minimization of an objective function eq 1 by iteratively computing the jacobian matrix until obtaining a local minimum the calculation of the jacobian matrix remains the most demanding part of this process especially when the number of unknowns is important this calculation is usually done either by the finite difference or the adjoint state technique the finite difference method is simple to implement but its computation is time consuming because it involves to solve the forward problem for each unknown parameters cardiff kitanidis 2008 fischer et al 2017 in our case study where the model is discretized into 32 32 cells the construction of the jacobian will therefore involve solving the forward problem 1024 times on the other hand the adjoint state technique requires less computation by iteratively solving an adjoint operator with the form of the forward problem on the number of observation wells but its implementation is quite complex for more details see sykes et al 1985 cardiff kitanidis 2008 in this section we test the implementation of gauss newton algorithm to invert the synthetic hydraulic data determined with a hydraulic transmissivity field shown in fig 10 called true model and using the piezometric coverage shown in fig 2 these data were then contaminated with noise with a variance of 5 cm2 the inversion of these datasets was constrained as explained in the introduction by geostatistical parameters such as covariance and mean the results of the inversions with the gn algorithm using the finite difference and adjoint state methods are presented in fig 10 where we can conclude that the gn algorithm succeeded in both cases in identifying the main heterogeneities of the real field with certain smoothness in the case where the jacobian is computed with the finite difference method convergence was achieved after 7 iterations in 4h10min and solving the forward problem 7 1024 1 7175 times in contrast the adjoint state method took only 1min24s regarding the application of the cnn ht algorithm we geostatistically generate 11 000 transmissivity models with the same variogram as the real model used for the comparison we keep 10 000 models for the training and the rest of the models are equally split for validation and testing in this case study we test two different ways of resizing the piezometric data the first method called projection method uses the hessian matrix to reshape the input data into the same size as the transmissivity field output as described in the section 2 this method requires the calculation of a jacobian matrix with a homogeneous field for example the mean field value the second method is based on a linear interpolation of the hydraulic data recorded during each pumping test to form 5 maps of size 32 32 i e one map for each pumping test so the input data has the form of a matrix of 5 channels 32 32 5 both approaches were used to build the segnet networks and then tested on the test sample the analysis of the predictions obtained on this sample shows that both methods provide almost the same prediction qualities with a small advantage for the projection method according to the correlation coefficients see table 2 however when we reduced the training size to t 500 and t 2500 models the network using the projection method was able to provide accurate generalization while the network with interpolated data failed we believe this is due to the fact that the interpolation of piezometric data does not preserve all the information masking the degree of variability in hydraulic responses which makes learning difficult with few training data in addition using the interpolation method increases the size of the input data which requires more memory and makes the training process more cumbersome compared to the projection technique that brings the data into a compact form regarding the application of these two networks on the hydraulic data of the real model we find that the network built with compact data provides a better reconstruction of the spatial variability of transmissivity field with a correlation coefficient r 0 80 see fig 10 moreover this prediction has almost the same accuracy as the result determined by the gauss newton algorithm r 0 83 we also mention that the time used in the gn with the finite difference method is perhaps comparable to the time spent in the dl method mainly devoted to the construction of the data set in particular the dl method becomes faster when we reduce the amount of training data to t 500 and t 2500 20 min and 1 h41 min because even with these small samples the transmissivity field can be well reconstructed well in a reasonable amount of time as demonstrated by the comparison of real and inverted fields fig 10 at the end of this comparison we conclude that both the cnn ht and gauss newton codes are based on the forward problem for which the computation time depends on the numerical method and the degree of mesh refinement used to solve the groundwater flow equation the machine learning technique uses this forward problem to generate a training database to build the cnn network the time spent in this construction can be equivalent or less to the time spent in finding a local minimum with the gauss newton using the finite difference method to calculate the jacobian matrix over a large number of unknown parameters however it is difficult to have an idea in advance of the time that will be spent in building this database because the size needed to get accurate results is related to the degree of complexity of the input output relationship and the type of network the optimal size as well as the rest of the network parameters epochs number of encoders are only established by a trial and error analysis which can take a considerable amount of time therefore the data size used in this paper cannot be generalized to all cases treated by this network or others both methods also share their dependence on prior information in the gauss newton algorithm this prior information is introduced as a constraint to guide the optimization towards realistic models and reduce the uncertainties associated with the non uniqueness of the solution on the other hand the cnn ht algorithm uses it to generate the training models the cnn ht offers the possibility of incorporating multiple prior models into the construction of the training dataset which is difficult to perform in a deterministic algorithm where the mathematical forms of these constraints must be differentiable in addition both methods are sensitive to the uncertainties associated with the measured data the cnn ht allows simultaneous learning with data affected by several degrees of uncertainty by adding noise to the training data then combining this set with the original to double the size of the training data and take into account the impact of noise regarding the quantification of the prediction uncertainties in the gauss newton method we use the a posteriori covariance formulation to get an idea of the uncertainty interval concerning the local minimum tarantola and valette 1982 however in the cnn ht algorithm it is difficult to construct an uncertainty map of the predicted model we can only build an uncertainty map on the model used in the test 5 conclusion and summary in this work we explore the relevance of a deep learning tool called the segnet network in the mapping of spatial variability of hydraulic parameters by interpreting the piezometric data recorded during pumping tests this approach relies on the approximation of the non linear inverse operator connecting the hydraulic head data to the hydraulic transmissivity field this approach is the outcome of an adaptation of the segnet network that has been successfully applied in the realm of image segmentation by identifying the objects studied on the pixels of images the segnet is designed to establish a relationship between two images sharing the same size and certain similarities which is not the case for hydraulic head data which are less numerous than the hydraulic transmissivity values to be estimated to meet this point we test the projection and interpolation methods projection method is based on the classical iterative formulation of a least square method at the initial iteration to build a projection operator with the hessian and jacobian matrices derived from the mean value of transmissivity fields used in the training data to resize the hydraulic data into the hydraulic transmissivity field size interpolation method involves reshaping the data size by interpolating the hydraulic head data to form a map with the same size as the output transmissivity field for each pumping test as a result the interpolation significantly increases the size of the input data which can slow down the numerical calculation without improving the quality of the prediction compared to the projection method which better preserves the hydraulic information in compact form in the projection method the operator is applied to the totality of the hydraulic pressure data used in training which are determined numerically as responses to pumping tests carried out on geostatistically generated hydraulic transmissivity fields with certain statistical properties once the training data has been gathered the inverse operator is established by identifying the different filters used in the segnet which is composed of encoders and decoders networks the encoder network allows through multiple application of filters and sequential calculations of convolution batch normalization relu and max pooling operations to extract the main features of the input data this encoder process induces a drop in spatial resolution which will be recovered in the decoder network which is designed to prepare the output with the applications of up sampling convolution batch normalization and relu operations this network ends with a regression layer to evaluate the performance of the inverse operator approximation the quality of this approximation is highly dependent on the amount of data used in the training with an accurate approximation when the dataset is large this makes the assembly of the training data the most expensive step in time requiring several hours compared to the learning process that in this case does not exceed 30 min in practice it is preferable to launch the learning with few data and check whether or not the desired accuracy is achieved before generating large amounts of data unnecessarily in terms of comparison the time spent in forming a training database can be equivalent to the time spent to reach a local minimum with gauss newton using the finite difference method to compute the jacobian matrix in addition to the amount of training data the nature of this data also controls the prediction results of the network indeed the trained network is only intended to handle certain types of models with similar characteristics to the models used in training thus it is by no means a universal inversion operator which makes the choice of the nature of the training models a crucial step that must be based on realistic prior information in real application case it should also be verified that the transmissivity fields used in the training allow to generate hydraulic data with the magnitude of the piezometric data observed in the field it is also necessary to ensure that the degree of heterogeneity of the generated models can be easily mapped to the piezometric data during training process because if the piezometric coverage does not allow to cover transmissivity models with high heterogeneity the learning process will fail to establish this relation the result of the inversion with cnn ht depends on the prior information and this particularity is also found with classical inversion techniques such as gauss newton noise can alter the information carried by the piezometric data and is a frequent problem in inversion algorithms the deep learning algorithms are no exception but its impact can be reduced by integrating it into the learning step by contaminating the input of training data the number of wells and their spatial configurations used in the study also had a determining effect on the effectiveness of the cnn segnet inversion tool with more reliable reconstructions when these piezometers are well distributed over the study area which was also observed in the use of conventional deterministic and stochastic methods at the end of this conclusion we enumerate and discuss the main advantages and limitations of the proposed method regarding the advantages we point out that the cnn ht method uses the forward problem as a black box to generate the training data with user selected transmissivity fields thus avoiding numerical instability and outliers in hydraulic head simulations related to its solving these numerical problems can be encountered when using conventional inversion methods stochastic and deterministic if they are ill constrained once the inverse operator is trained the network permits to interpret the piezometric data in a few seconds without the user having to add new parameters the cnn ht code provides predictions that require any initial hydraulic transmissivity models or computation of sensitivity matrix as is the case with deterministic methods this advantage makes cnn ht an effective inversion tool for dealing with highly nonlinear inverse problems with large scale parameterization that are difficult to handle with deterministic codes especially when the computation of sensitivity is complex the cnn ht code performs reconstructions of the transmissivity field that depend on the a priori model used in the generation of transmissivity field for the training data this dependence to the a priori model is a property shared with other inversion methods however in this cnn ht tool the mathematical form of this a priori model is not subject to any condition which is not the case with deterministic methods where the model must have a quadratic and differentiable form the cnn ht algorithm also provides great flexibility for the user to incorporate multiple prior models especially when in doubt about which a priori information to use the proposed method is based on a simple network that can be generalized and applied to handle hydraulic tomography in 3d or in time domain in order to identify the storativity coefficient as well by only modifying the training dataset it is also easily adaptable to deal with hydraulic tomographies with complex heterogeneities having for example multiple discontinuous hydrofacies with contrasting transmissivities or parameterized in discrete fracture network mode these types of problems can be treated as a classification task by replacing the regression layer of the network with the softmax layer in this way the network can identify fracture geometries or hydrofacies shapes the code allows the incorporation of uncertainties on the boundary conditions imposed in the numerical solving of the forward problem by randomly choosing their values within a confidence interval when building the training data set this code like other deep learning algorithms that use the convolutional neural network technique are able to better reduce the effects of noise in the data this is thanks to the convolution concept that processes the input data with some local connectivity and not in a pointwise manner as in other conventional inversion methods vu and jardani 2021 the impact of noise could be minimized and accounted for in the inversion results by contaminating the hydraulic data used in the training data with a noise signal regarding the disadvantages of this method we mention that it is based on a repetitive and time consuming numerical resolution of the forward problem which is involved in the construction of the training database the size of this database conditions the quality of the predictions and its optimal size can only be obtained by a long trial and error procedure the method requires important computing resources to carry out the learning the code also uses a large number of parameters that intervene in the construction of the networks such as size of the decoder encoder number of filters and their size and in the optimization algorithm used in the training phase number of epochs regularization parameters initialization of filters batchsize dropout the determination of all these parameters implies a tedious sensitivity analysis with several training operations to choose the best parameters the method does not provide an uncertainty assessment of the predicted transmissivity fields this is a major weakness of this method compared to classical approaches there are some attempts in the literature to estimate the uncertainty of the prediction determined with dl algorithms by performing the learning in a probabilistic way kendall and cipolla 2016 gal and ghahramani 2016 however this type of approach requires a lot of computational time and it does not take into account all the uncertainties that can come from all the parameters used in the learning the method is highly dependent on prior information this dependence can be an obstacle to its application especially when the network fails in the learning phase to relate the transmissivity fields to their piezometric data this can occur when the transmissivity fields have complex heterogeneities that are not captured by low piezometric resolution this dependence can also lead to a misinterpretation even with a well trained inversion operator when the magnitudes of the piezometric data used in the training are so different from those we desire to predict to avoid both of these problems it is necessary to ensure that generated transmissivity fields have a degree of heterogeneity that can be mapped with the piezometer coverage and that they produce hydraulic head data that include the magnitude of the hydraulic observations to be interpreted in conventional inversion methods the predicted transmissivity distribution is the result of a compromise between the a priori model and the piezometric data however here the result is strongly linked to the a priori model and the piezometric data to be interpreted come only at the end of the learning process credit authorship contribution statement a jardani writing original draft conceptualization methodology software t m vu p fischer declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we thank normandy region for its financial support to our consortium on the hydraulic characterization of aquifers appendix here we present the mathematical formulation to analytically calculate the jacobian matrix of a homogeneous transmissivity field this matrix is used in the projection method to transform the hydraulic data to the same size as the transmissivity field to form the segnet network we recall that in the joint state method the sensitivity matrix can be expressed as an integral sykes et al 1985 a1 h i m j log 10 ω j t h ϕ d ω where h is the hydraulic head measured at location o x obs y obs due to a pumping source placed at p x p y p with a rate q p ϕ is the adjoint operator with a source term q adj 1 placed at the observation point o x obs y obs t is transmissivity hydraulic with m log t when the transmissivity is constant h and ϕ can be determined analytically with thiem s equation for a confined aquifer a2 h h 0 q p 2 π t ln r rp and ϕ ϕ 0 q adj 2 π t ln r r obs with r obs x o b s x 2 y o b s y 2 a n d r p x p x 2 y p y 2 h0 and ϕ 0 are the values imposed as the boundary of the domain located at a distance r away from the study area r is radial distance then the sensitivity of hydraulic head at point o to a variation of the transmissivity at cell ω j can be approximated with this integral a3 h i m j log 10 q p q adj 4 π 2 t ω j x obs x x p x y obs y y p y r obs 2 r p 2 d ω 
3805,in this manuscript we discuss the capabilities of a deep learning algorithm implemented with the conventional neural network concept to characterize the hydraulic properties of aquifers the algorithm called cnn ht is designed to predict the inverse operator of hydraulic tomography using a synthetic training dataset in which the hydraulic head data associated with pumping tests are linked to hydraulic transmissivity field this approach relies on an adaptation of the segnet network that was initially developed to process image segmentation the segnet is composed of encoders and decoders networks in the encoder sequential operations with multiple filters as convolution batch normalization max pooling are performed to identify feature maps of the input data in the decoder the up sampling convolution batch normalization and regression operations are used to prepare the output by recovering the loss of spatial resolution that occurred in the encoder process in this adaptation we used the least square iterative formulation at the initial iteration with jacobian matrix to resize the hydraulic head data to match the size of the output transmissivity field this protocol was applied to the hydraulic head data computed numerically by solving the groundwater flow equation for a given transmissivity field generated geostatistically with gaussian and spherical variograms a part of this data was used for training the network and the other part to test its performance the test step confirmed the effectiveness of this tool in reconstructing the main heterogeneities of the hydraulic properties and its effectiveness is related to the nature and quantity of the training data moreover the cnn ht method provided inversion results of the same quality than those obtained with the gauss newton algorithm using the finite difference or adjoint state method in the computation of the jacobian matrix however the computational time is longer in cnn ht but this time can be less or of the same order as that of gauss newton using finite difference method keywords inverse problem hydraulic tomography deep learning convolutional neural networks 1 introduction since the 1980 s the hydraulic tomography has been adopted in hydrology as an effective technique for mapping the heterogeneity of the hydraulic properties of aquifers neuman 1987 gottlieb and dietrich 1995 bohling et al 2002 yeh and liu 2000 indeed this approach can effectively provide insights into the spatial variability of the hydraulic transmissivity and storage coefficient of a porous or fractured aquifer through a combined interpretation of hydraulic data obtained from several pumping tests bohling et al 2002 berg and illman 2011 cardiff et al 2013 fischer et al 2018 the approach consists of using an inversion algorithm either deterministic or stochastic to retrieve the best models that could match the observed piezometric data fu and gómez hernández 2009a kitanidis 1997 in general the inverse solution is not unique for that reason the inverse formulation usually incorporates a regularization term in the optimization of the objective function ψ m that is defined as the sum of data misfit and regularization terms as below tarantola and valette 1982 1 ψ m f m h obs t c d 1 f m h obs data m i s f i t term m m 0 t c m 1 m m 0 constr aint term where the data misfit term assesses the pertinence of the model in term of matching the data and is expressed as a sum of square differences between the observed hydraulic data h obs and the numerical hydraulic data derived by solving a forward operator f m in hydraulic tomography the forward problem involves a numerical discretization for solving the groundwater flow equation subject to darcy s law in transient or steady modes m log t is the spatial distribution of the negative logarithm of the hydraulic transmissivity t which is regarded as an unknown field and is expressed logarithmically to ensure its positivity during the inverse process c d is a diagonal matrix for incorporating data uncertainty in the optimization on the other side the regularization term is expressed with a prior model m 0 and its covariance matrix c m this term can be obtained from geological geophysical and tracer investigations to constrain the inversion to offer only plausible solutions lochbühler et al 2013 zhao et al 2016 soueid et al 2016 in general the use of geostatistical constraints is still widely applied in hydraulic tomography by using statistical properties such as mean and covariance to obtain an imagery of hydraulic properties with smooth features kitanidis 1997 yeh and liu 2000 once the parameters of the objective function are formulated its optimization is processed iteratively using one of the three categories of optimization algorithms deterministic li et al 2005 stochastic jiménez et al 2016 or global castagna and bellin 2009 these algorithms involve a repetitive numerical solving of the forward problem by applying finite elements or finite difference methods to assess the ability of the proposed model to reach the convergence state therefore the computation time is dependent on the numerical tools the dimensionality of the unknown parameters and the nature of the optimization algorithm employed in general deterministic algorithms are the most used in high dimensional inverse problems due to their advantage of reaching convergence in a short time compared to stochastic or global algorithms by exploiting the geometric properties of the objective function gradient and hessian tarantola and valette 1982 nevertheless their efficiency depends strongly on the choice of the initial model as they only provide local minima on the other hand stochastic methods such as markov chain monte carlo mcmc are based on the concept of sampling where the solution is obtained by exploring the optimization performance of many randomly generated models and selecting the best of them in terms of minimization of the objective function most of the time algorithms belonging to this category are easy to implement and insensitive to the initial model however their applicability to inverse problems with a large number of unknown parameters remains limited due to the high repetitive and heavy computation of the forward problem during the sampling process oliver et al 1997 fu and jaime gómez hernández 2009b wang et al 2017 jardani et al 2012 elsheikh et al 2012 other global optimization algorithms such as particle swarm optimization genetic simulated annealing can also be used to identify the best solution by iteratively evaluating the objective function until the state of convergence however convergence can be slow especially in the case of high dimensional inverse problems scales et al 1992 fernández martínez et al 2011 in this paper we test a new generation of deep learning algorithm that can be considered as a global optimizer in which prediction does not depend on an initial model and the computation of the sensitivity matrix as it is the case for gradient based methods zio 1997 the concept of this approach is different from previous optimization methods as the process focuses on approximating the inverse function by finding a universal relationship linking the input and output data in the case of hydraulic tomography between hydraulic pressure and hydraulic transmissivity indeed the deep learning is a powerful generalizer of non linear and complex functions by identifying a set of parameters such as weights and biases allocated to the hidden layer neurons that process the input data and link them to their corresponding output the first generation of deep learning algorithms uses a set of hidden layers with a large number of neurons fully connected via high dimensional weights which complicates computation and requires a lot of time especially for handling the imaging tasks shen 2018 however the emergence of new deep learning architectures with convolutional neural networks cnn concept that have been proven in high resolution image processing have opened the way for broadening their applicability in the hydraulic characterization lecun et al 1998 sun 2018 zhu and zabaras 2018 indeed the cnn concept has succeeded in reducing drastically the image processing time thanks to the convolution calculation which allows to retrieve the local features of the image through small filters indolia et al 2018 these filters cover the whole input image but their activation is done zone by zone with local connections between pixels this local convolution reduces the number of parameters to optimize during the learning process lecun et al 1998 among the first attempts at adopting the cnn concept in the realm of tomography by inversion in geosciences we cite sun 2018 trained the generative adversarial networks for linking the hydraulic head map and the spatial distribution of hydraulic conductivity zhu and zabaras 2018 proposed a deep convolutional encoder decoder network to reconstruct the image of hydraulic conductivity from hydraulic head map laloy et al 2018 used the generative adversarial networks to generate randomly in 2d and 3d binary hydraulic conductivity fields and mcmc to perform the inversion process in geophysics realm wu and lin 2018 applied cnn with encoder decoder networks for mapping the subsurface velocity from seismogram data puzyrev and swidinsky 2021 used the cnn network to determine the vertical subsurface heterogeneity of electrical conductivity by training electromagnetic data in this article we discuss the use of the convolution neural networks formed according to the segnet architecture to process hydraulic tomography this technique was initially designed for the semantic segmentation of objects learned on the images badrinarayanan et al 2017 to illustrate the inversion principle with the cnn ht structure we organize this manuscript with the following outline the first section will be devoted to the generation of data used in training validation and test and the second to the introduction of concept of the cnn segnet structure in the application sections we discuss the relevance of the approach on theoretical cases under different conditions on training data with high and low resolution and contaminated or not by the noise we also devote a section to the comparison of the results obtained with cnn segnet code with those determined with the gauss newton algorithm 2 theoretical concept 2 1 preparation of training data in deep learning algorithm the first step concerns the construction of training data that will condition the accuracy of the result obtained from the predicted inversion operator see fig 1 given the impossibility of having a real dataset connecting the spatial distribution of hydraulic properties of aquifers and the piezometric responses we use synthetic models in which the hydraulic parameter fields are generated geostatistically and their corresponding piezometric responses are obtained by solving the numerical groundwater equation in steady state forward problem 2 f m t h q p δ x p x h h 0 γ d where m is the negative of logarithm of transmissivity t 10 m randomly generated and distributed on the studied domain h is the hydraulic head responses due to water extraction represented by a point source term q p δ x p x defined at pumping well locations x p δ is dirac delta function the pumping tests will be done sequentially on several wells the forward problem is solved by finite element technique using the comsol software with a constant hydraulic level h 0 imposed as dirichlet boundary at all limit of the domain γ d that are positioned far from the studied area for reducing their impact as the nature of the training models conditions the result of the cnn ht inversion we have to use the prior information on the studied field to establish a cluster of models for training and targeting a type of solution with certain characteristics in this paper prior information is expressed in statistical terms with a gaussian distribution wherein the mean and covariance are held constants during model generation once the parameters of the distribution are defined we launch the generation of thousands of hydraulic transmissivity fields using the sgems code implemented in matlab remy et al 2009 the generated transmissivity fields are then assigned to a domain of 40 m 40 m on which we set up a dense distribution of wells to better cover the heterogeneity of the field on this configuration we conduct 5 pumping tests in such a way to hydraulically disturb the whole area each pumping test allows us to retrieve 44 measurements from the remaining observation wells in the end we obtain 220 measurements for each field see fig 2 to predict an inversion operator using convolutional neural networks with the encoder decoder architecture we need to reshape the piezometric data into a field with the same dimension than the hydraulic transmissivity field in order to link tow images with the same size to do this we can use one of two methods i the first consists in interpolating the piezometric data recorded on the observation wells for each pumping test in order to form images with the same resolution in the target transmissivity field in this case the input data are composed of a number of maps equal to the number of pumping tests in our example we have 5 pumping tests and we will then obtain 5 maps that will be treated jointly as 5 channels in convolutional neural networks ii this second is more compact than the first in which all piezometric data set recorded for different pumping tests are introduced by a single map using a projection operation derived from the gauss newton formulation this formulation results from the minimization of the objective function presented in the introduction section ψ m m 0 tarantola valette 1982 3 m i 1 m i j i t c d 1 j i c m 1 1 j i t c d 1 h obs f m i c m 1 m i m 0 where j i is jacobian matrix with a size of n m n and m are number of the data and the unknown parameters respectively at the first iteration usually we start with the prior model then 4 m 1 m 0 j 0 t c d 1 j 0 c m 1 1 j 0 t c d 1 h obs f m 0 and this equation can be reformulated under this following form 5 m 1 β λ h obs 6 β m 0 j 0 t c d 1 j 0 c m 1 1 j 0 t c d 1 f m 0 and 7 λ j 0 t c d 1 j 0 c m 1 1 j 0 t c d 1 m 1 is the hydraulic transmissivity model resulting from the first iteration obviously it does not fit the observed data but it can be applied as a projection term for all piezometric data in order to convert them into matrices with same size as the transmissivity fields j 0 is the sensitivity matrix of the prior homogenous model m 0 representing the mean of the fields in this case the jacobian can be derived analytically using the thiem s equation for confined aquifers to express the radial flow field and its adjoint state operator for details see appendix to further simplify this projection term so that it is less dependent on prior information we remove the bias term β replace the covariance matrices c m and c d by simple identity matrices now the new projection term takes this form 8 h obs p λ h obs w i t h λ j 0 t j 0 i m 1 j 0 t thanks to this simple multiplication the hydraulic data h obs will be transformed into a vector h obs p of the same size as the output hydraulic transmissivity field and used in matrix form as the input field in the network this formulation allows to link linearly h obs and h obs p and preserves all the hydraulic information to establish a relationship between h obs p and transmissivity field the comparison of the results of the two methods linear interpolation and projection in terms of inverse operator prediction is presented in the last section however the first sections all applications are done with the projection method 2 2 inversion by convolutional neural networks with encoder decoder structure in this article we will explore for the first time the efficiency of segnet architecture to process the inversion in hydraulic tomography the approach uses the conventional neural networks concept built with an encoder decoder architecture see fig 3 this approach was originally conceived to process semantic segmentation of images by delineating the shapes of learned objects badrinarayanan et al 2017 in the encoder network the input image is processed sequentially by a set of encoders in our case we use only 2 encoders chosen after an analysis of the inversion results obtained with networks having 1 2 and 3 encoders the network with 2 encoders gave the best result in terms of training and generalization with a low sensitivity to overfitting each encoder starts with a convolutional process in which multiple filters with the small size 3 3 64 are convoluted on the input layer zone by zone to identify their features badrinarayanan et al 2017 this calculus permits to establish a local connectivity between pixels with these shared small filters which remain simple to predict in the training process the convolutional operations are followed by batch normalization which is a linear operation that plays the role of a regularizer in scaling the convolution outputs in order facilitate and accelerate the training ioffe and szegedy 2015 this step is followed by the application of the relu function which introduces the nonlinearity in the process then the dimensionality of the result of the previous sequence will be considerably reduced in the max pooling layer with stride of 2 and 2 2 windows to keep only the main features therefore the construction of feature maps in the encoder network leads to a decrease in the spatial resolution that will be restored in the decoder network indeed the decoder network is configured in a symmetrical form with 2 decoders to prepare the output by recovering the resolution lost in the decoder with up sampling operations from the max pooling indices obtained in the previous max pooling layers carried out in each encoder badrinarayanan et al 2017 these results of up sampling will be convoluted with other filters to build feature maps with more details then the batch normalization and relu are applied successively on the convolutional outputs as in the encoder network at the end of the encoder network we add a convolution layer having the same size of the output and a regression layer to assess the performance of the training this last layer replaces the softmax layer used in the original version of segnet network for the segmentation task the set of weights and biases υ used in the various encoder decoder operations are chosen in way to match the training data m i h obs i p by minimizing this objective function 9 υ arg min i 1 nt m i f 1 h obs i p υ where i is the sample index of the training data set with nt as size of the training data f 1 h obs i p υ denotes the inverse function to identify by using the training data in the prediction of the networks parameters υ with adam optimization algorithm kingma and ba 2014 this optimizer was run with a batch size of 70 and a learning rate starting at 0 01 and decreasing by 0 1 every 50 epochs the computation was performed on a workstation with intel r xeon r silver 4110 cpu 2 10 ghz and 128 g of ram with a single gpu after training is complete we use a sample of generated data not used during training phase to check the quality of the inversion results by the cnn ht code 3 applications to synthetic cases in this section we apply the inversion concept with cnn encoder decoder networks on theoretical cases where the log of hydraulic transmissivity fields are generated randomly with a gaussian variogram and their hydraulic head responses by the groundwater equation as explained in the data preparation section this distribution has μ 10 5 m2 s as mean and an isotropic gaussian variogram with 0 5 and 10 m as variance and range respectively with this variogram model we performed 11 000 realizations in which the transmissivity is ranging over 10 8 3 10 1 6 m2 s however 95 of these models have transmissivities between 10 6 4 and 10 3 5 m2 s see fig 4 then these models are used in a forward operator that takes 2 s per simulation to get the hydraulic head responses these realizations aim to evaluate the effectiveness of the cnn segnet approach in the reconstruction of hydraulic transmissivity field and to analyze the sensitivity of this reconstruction to the size of the training dataset and the amount and uncertainties of the hydraulic head data collected during the pumping tests 3 1 effect of training data size in the first analysis we examine the impact of training data size on the reliability of the inverse operator prediction and determine the amount of data required to obtain a satisfactory prediction for this purpose we performed three assessments with different training data sizes t1 1000 t2 3000 t3 10000 the validation was done with 1000 models and the test with 500 models different from those used in the learning phase training and validation during the optimization process we followed the quality of the minimization of loss functions with the training and validation data until they reached optimal values to stop the process manually or wait until the maximum number of epochs was met see fig 5 in this way we avoid the problem of overfitting which appears especially when we tried to build the network with a limited number of training data t1 1000 the results obtained with these different sizes of training data are presented in the table 1 a in which we can easily identify through the analysis of the correlation coefficient between the real and predicted models of test sample that the accuracy of the prediction improved with increasing training data size indeed the reliability of the predictive model derived from a deep learning algorithm is highly dependent on the amount of data used in the training in which a large amount of data guarantees a good prediction this implies a long computational time in the generation of training data in any case the degree of accuracy desired remains linked to the nature of the problem studied in our case training with t1 1000 data allowed us to predict 500 test models with a correlation coefficient r between real and predicted models ranging from 0 74 to 0 93 and a mean of 0 86 see table 1a from these models we choose 3 models the first one m1 with a relative poor prediction r 0 75 a second model m2 r 0 83 close to the mean representing quality of the majority of predicted models and the last one m3 with a good reconstruction r 0 91 see fig 6 these models will be used to analyze the impact of training data size on the quality of their estimations see fig 6 the first model m1 is characterized by a high degree of variability with the small heterogeneities at the boundary of the domain and a logarithm of the hydraulic transmissivity that varies between 6 2 5 over this range there are outliers in the gaussian distribution of training data in particular which are around 2 5 thus in this case only a few models have been seen in the training with this feature which explains the poor reconstruction see fig 6 the same problem occurs in the prediction of models with low outliers 6 5 however the models having variabilities well covered by training models such as m2 and m3 with transmissivities values between 6 5 3 5 the reconstructions are more accurate however if the number of training models increases the models with outliers will be more frequent and will be reconsidered in the generalization as shown in the table where the reconstructions of these models have been well improved 3 2 effect of amount of observation wells in the second analysis we study the influence of the number of hydraulic data collected during the pumping tests on the efficiency of the network to approximate the inverse operator in this analysis we first reduce the number of observation wells to half 22 observation wells and in the second step to one quarter 11 observations wells however we maintain the number of pumping tests and the size of the spatial discretization of the transmissivity fields 16 16 as used in previous test these new well configurations are illustrated in the fig 7 in practice only the hydraulic responses of abandoned wells are removed from previous training data thus these data acquired with the two new observation well configurations are used as training input to determine the corresponding inverse operators and the results obtained were compared to the previous configuration with 44 wells the training operations were performed with 10 000 models and the tests were also done on the previous unseen samples the reconstruction results of the test models with different series of piezometric data expressed in terms of correlation coefficients reveal a degradation of the accuracy of prediction with the decrease in the number of hydraulic data see table 1b because the number of piezometers becomes insufficient to cover all the heterogeneities and the complexities of the medium and this also occurs with classical inversion methods this is further confirmed by analyzing the spatial aspect of the reconstructions of models m1 m2 and m3 in which we observe a loss of resolution and an increase in smoothness degrees with the reduction of hydraulic data fig 8 however the main heterogeneities can still be identified with less data 3 3 effect of observation uncertainties in this section we analyze the effect of uncertainties that may be associated with hydraulic pressure measurements collected during pumping tests this involves contaminating the numerical piezometric data with a random gaussian noise of 0 5 as the standard deviation and verifying its impact on the quality of hydraulic field reconstructions of test models as a first analysis we use an inverse operator established on the basis of uncontaminated training data to interpret hydraulic head data from a test set that are contaminated by noise here the training operation did not take into account the noise the result of this test is presented by the benchmark models in fig 9 and table 1c of correlation coefficients which reveal a sharp degradation in the quality of the predictions compared to the noise free test models with a decrease in the correlation coefficient from 0 92 to 0 79 mean for all test models in the second strategy noise is taken into account in the estimation of the inversion function by adding noise to the hydraulic data used in the learning process this method has led to a significant improvement in the prediction quality of the test models as shown by the three models m1 m2 m3 and the correlation coefficient noted in table 1c with the average r of the set of models increasing from 0 79 to 0 84 however this prediction is less accurate when compared to the noise free training and test data as shown by the r values we can therefore conclude that uncertainties in the measured data may have an impact on the results of inversion as is the case with classical optimization techniques but to reduce their impacts it is necessary to incorporate these uncertainties in the construction of the inversion model i e in the learning process 4 comparison of cnn ht and gauss newton algorithms in this section we compare the inversion results obtained with the cnn ht algorithm with those determined by the traditional gauss newton gn method to this end we apply both algorithms to the reconstruction of a transmissivity field with a mean of 10 5 m2 s 1 and generated with a spherical covariance having 0 5 and 10 m as variance and range respectively however this time the models are highly discretized 32 32 compared to those used in the previous sections the gauss newton algorithm as described in the introductory section is a deterministic approach that relies on the minimization of an objective function eq 1 by iteratively computing the jacobian matrix until obtaining a local minimum the calculation of the jacobian matrix remains the most demanding part of this process especially when the number of unknowns is important this calculation is usually done either by the finite difference or the adjoint state technique the finite difference method is simple to implement but its computation is time consuming because it involves to solve the forward problem for each unknown parameters cardiff kitanidis 2008 fischer et al 2017 in our case study where the model is discretized into 32 32 cells the construction of the jacobian will therefore involve solving the forward problem 1024 times on the other hand the adjoint state technique requires less computation by iteratively solving an adjoint operator with the form of the forward problem on the number of observation wells but its implementation is quite complex for more details see sykes et al 1985 cardiff kitanidis 2008 in this section we test the implementation of gauss newton algorithm to invert the synthetic hydraulic data determined with a hydraulic transmissivity field shown in fig 10 called true model and using the piezometric coverage shown in fig 2 these data were then contaminated with noise with a variance of 5 cm2 the inversion of these datasets was constrained as explained in the introduction by geostatistical parameters such as covariance and mean the results of the inversions with the gn algorithm using the finite difference and adjoint state methods are presented in fig 10 where we can conclude that the gn algorithm succeeded in both cases in identifying the main heterogeneities of the real field with certain smoothness in the case where the jacobian is computed with the finite difference method convergence was achieved after 7 iterations in 4h10min and solving the forward problem 7 1024 1 7175 times in contrast the adjoint state method took only 1min24s regarding the application of the cnn ht algorithm we geostatistically generate 11 000 transmissivity models with the same variogram as the real model used for the comparison we keep 10 000 models for the training and the rest of the models are equally split for validation and testing in this case study we test two different ways of resizing the piezometric data the first method called projection method uses the hessian matrix to reshape the input data into the same size as the transmissivity field output as described in the section 2 this method requires the calculation of a jacobian matrix with a homogeneous field for example the mean field value the second method is based on a linear interpolation of the hydraulic data recorded during each pumping test to form 5 maps of size 32 32 i e one map for each pumping test so the input data has the form of a matrix of 5 channels 32 32 5 both approaches were used to build the segnet networks and then tested on the test sample the analysis of the predictions obtained on this sample shows that both methods provide almost the same prediction qualities with a small advantage for the projection method according to the correlation coefficients see table 2 however when we reduced the training size to t 500 and t 2500 models the network using the projection method was able to provide accurate generalization while the network with interpolated data failed we believe this is due to the fact that the interpolation of piezometric data does not preserve all the information masking the degree of variability in hydraulic responses which makes learning difficult with few training data in addition using the interpolation method increases the size of the input data which requires more memory and makes the training process more cumbersome compared to the projection technique that brings the data into a compact form regarding the application of these two networks on the hydraulic data of the real model we find that the network built with compact data provides a better reconstruction of the spatial variability of transmissivity field with a correlation coefficient r 0 80 see fig 10 moreover this prediction has almost the same accuracy as the result determined by the gauss newton algorithm r 0 83 we also mention that the time used in the gn with the finite difference method is perhaps comparable to the time spent in the dl method mainly devoted to the construction of the data set in particular the dl method becomes faster when we reduce the amount of training data to t 500 and t 2500 20 min and 1 h41 min because even with these small samples the transmissivity field can be well reconstructed well in a reasonable amount of time as demonstrated by the comparison of real and inverted fields fig 10 at the end of this comparison we conclude that both the cnn ht and gauss newton codes are based on the forward problem for which the computation time depends on the numerical method and the degree of mesh refinement used to solve the groundwater flow equation the machine learning technique uses this forward problem to generate a training database to build the cnn network the time spent in this construction can be equivalent or less to the time spent in finding a local minimum with the gauss newton using the finite difference method to calculate the jacobian matrix over a large number of unknown parameters however it is difficult to have an idea in advance of the time that will be spent in building this database because the size needed to get accurate results is related to the degree of complexity of the input output relationship and the type of network the optimal size as well as the rest of the network parameters epochs number of encoders are only established by a trial and error analysis which can take a considerable amount of time therefore the data size used in this paper cannot be generalized to all cases treated by this network or others both methods also share their dependence on prior information in the gauss newton algorithm this prior information is introduced as a constraint to guide the optimization towards realistic models and reduce the uncertainties associated with the non uniqueness of the solution on the other hand the cnn ht algorithm uses it to generate the training models the cnn ht offers the possibility of incorporating multiple prior models into the construction of the training dataset which is difficult to perform in a deterministic algorithm where the mathematical forms of these constraints must be differentiable in addition both methods are sensitive to the uncertainties associated with the measured data the cnn ht allows simultaneous learning with data affected by several degrees of uncertainty by adding noise to the training data then combining this set with the original to double the size of the training data and take into account the impact of noise regarding the quantification of the prediction uncertainties in the gauss newton method we use the a posteriori covariance formulation to get an idea of the uncertainty interval concerning the local minimum tarantola and valette 1982 however in the cnn ht algorithm it is difficult to construct an uncertainty map of the predicted model we can only build an uncertainty map on the model used in the test 5 conclusion and summary in this work we explore the relevance of a deep learning tool called the segnet network in the mapping of spatial variability of hydraulic parameters by interpreting the piezometric data recorded during pumping tests this approach relies on the approximation of the non linear inverse operator connecting the hydraulic head data to the hydraulic transmissivity field this approach is the outcome of an adaptation of the segnet network that has been successfully applied in the realm of image segmentation by identifying the objects studied on the pixels of images the segnet is designed to establish a relationship between two images sharing the same size and certain similarities which is not the case for hydraulic head data which are less numerous than the hydraulic transmissivity values to be estimated to meet this point we test the projection and interpolation methods projection method is based on the classical iterative formulation of a least square method at the initial iteration to build a projection operator with the hessian and jacobian matrices derived from the mean value of transmissivity fields used in the training data to resize the hydraulic data into the hydraulic transmissivity field size interpolation method involves reshaping the data size by interpolating the hydraulic head data to form a map with the same size as the output transmissivity field for each pumping test as a result the interpolation significantly increases the size of the input data which can slow down the numerical calculation without improving the quality of the prediction compared to the projection method which better preserves the hydraulic information in compact form in the projection method the operator is applied to the totality of the hydraulic pressure data used in training which are determined numerically as responses to pumping tests carried out on geostatistically generated hydraulic transmissivity fields with certain statistical properties once the training data has been gathered the inverse operator is established by identifying the different filters used in the segnet which is composed of encoders and decoders networks the encoder network allows through multiple application of filters and sequential calculations of convolution batch normalization relu and max pooling operations to extract the main features of the input data this encoder process induces a drop in spatial resolution which will be recovered in the decoder network which is designed to prepare the output with the applications of up sampling convolution batch normalization and relu operations this network ends with a regression layer to evaluate the performance of the inverse operator approximation the quality of this approximation is highly dependent on the amount of data used in the training with an accurate approximation when the dataset is large this makes the assembly of the training data the most expensive step in time requiring several hours compared to the learning process that in this case does not exceed 30 min in practice it is preferable to launch the learning with few data and check whether or not the desired accuracy is achieved before generating large amounts of data unnecessarily in terms of comparison the time spent in forming a training database can be equivalent to the time spent to reach a local minimum with gauss newton using the finite difference method to compute the jacobian matrix in addition to the amount of training data the nature of this data also controls the prediction results of the network indeed the trained network is only intended to handle certain types of models with similar characteristics to the models used in training thus it is by no means a universal inversion operator which makes the choice of the nature of the training models a crucial step that must be based on realistic prior information in real application case it should also be verified that the transmissivity fields used in the training allow to generate hydraulic data with the magnitude of the piezometric data observed in the field it is also necessary to ensure that the degree of heterogeneity of the generated models can be easily mapped to the piezometric data during training process because if the piezometric coverage does not allow to cover transmissivity models with high heterogeneity the learning process will fail to establish this relation the result of the inversion with cnn ht depends on the prior information and this particularity is also found with classical inversion techniques such as gauss newton noise can alter the information carried by the piezometric data and is a frequent problem in inversion algorithms the deep learning algorithms are no exception but its impact can be reduced by integrating it into the learning step by contaminating the input of training data the number of wells and their spatial configurations used in the study also had a determining effect on the effectiveness of the cnn segnet inversion tool with more reliable reconstructions when these piezometers are well distributed over the study area which was also observed in the use of conventional deterministic and stochastic methods at the end of this conclusion we enumerate and discuss the main advantages and limitations of the proposed method regarding the advantages we point out that the cnn ht method uses the forward problem as a black box to generate the training data with user selected transmissivity fields thus avoiding numerical instability and outliers in hydraulic head simulations related to its solving these numerical problems can be encountered when using conventional inversion methods stochastic and deterministic if they are ill constrained once the inverse operator is trained the network permits to interpret the piezometric data in a few seconds without the user having to add new parameters the cnn ht code provides predictions that require any initial hydraulic transmissivity models or computation of sensitivity matrix as is the case with deterministic methods this advantage makes cnn ht an effective inversion tool for dealing with highly nonlinear inverse problems with large scale parameterization that are difficult to handle with deterministic codes especially when the computation of sensitivity is complex the cnn ht code performs reconstructions of the transmissivity field that depend on the a priori model used in the generation of transmissivity field for the training data this dependence to the a priori model is a property shared with other inversion methods however in this cnn ht tool the mathematical form of this a priori model is not subject to any condition which is not the case with deterministic methods where the model must have a quadratic and differentiable form the cnn ht algorithm also provides great flexibility for the user to incorporate multiple prior models especially when in doubt about which a priori information to use the proposed method is based on a simple network that can be generalized and applied to handle hydraulic tomography in 3d or in time domain in order to identify the storativity coefficient as well by only modifying the training dataset it is also easily adaptable to deal with hydraulic tomographies with complex heterogeneities having for example multiple discontinuous hydrofacies with contrasting transmissivities or parameterized in discrete fracture network mode these types of problems can be treated as a classification task by replacing the regression layer of the network with the softmax layer in this way the network can identify fracture geometries or hydrofacies shapes the code allows the incorporation of uncertainties on the boundary conditions imposed in the numerical solving of the forward problem by randomly choosing their values within a confidence interval when building the training data set this code like other deep learning algorithms that use the convolutional neural network technique are able to better reduce the effects of noise in the data this is thanks to the convolution concept that processes the input data with some local connectivity and not in a pointwise manner as in other conventional inversion methods vu and jardani 2021 the impact of noise could be minimized and accounted for in the inversion results by contaminating the hydraulic data used in the training data with a noise signal regarding the disadvantages of this method we mention that it is based on a repetitive and time consuming numerical resolution of the forward problem which is involved in the construction of the training database the size of this database conditions the quality of the predictions and its optimal size can only be obtained by a long trial and error procedure the method requires important computing resources to carry out the learning the code also uses a large number of parameters that intervene in the construction of the networks such as size of the decoder encoder number of filters and their size and in the optimization algorithm used in the training phase number of epochs regularization parameters initialization of filters batchsize dropout the determination of all these parameters implies a tedious sensitivity analysis with several training operations to choose the best parameters the method does not provide an uncertainty assessment of the predicted transmissivity fields this is a major weakness of this method compared to classical approaches there are some attempts in the literature to estimate the uncertainty of the prediction determined with dl algorithms by performing the learning in a probabilistic way kendall and cipolla 2016 gal and ghahramani 2016 however this type of approach requires a lot of computational time and it does not take into account all the uncertainties that can come from all the parameters used in the learning the method is highly dependent on prior information this dependence can be an obstacle to its application especially when the network fails in the learning phase to relate the transmissivity fields to their piezometric data this can occur when the transmissivity fields have complex heterogeneities that are not captured by low piezometric resolution this dependence can also lead to a misinterpretation even with a well trained inversion operator when the magnitudes of the piezometric data used in the training are so different from those we desire to predict to avoid both of these problems it is necessary to ensure that generated transmissivity fields have a degree of heterogeneity that can be mapped with the piezometer coverage and that they produce hydraulic head data that include the magnitude of the hydraulic observations to be interpreted in conventional inversion methods the predicted transmissivity distribution is the result of a compromise between the a priori model and the piezometric data however here the result is strongly linked to the a priori model and the piezometric data to be interpreted come only at the end of the learning process credit authorship contribution statement a jardani writing original draft conceptualization methodology software t m vu p fischer declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we thank normandy region for its financial support to our consortium on the hydraulic characterization of aquifers appendix here we present the mathematical formulation to analytically calculate the jacobian matrix of a homogeneous transmissivity field this matrix is used in the projection method to transform the hydraulic data to the same size as the transmissivity field to form the segnet network we recall that in the joint state method the sensitivity matrix can be expressed as an integral sykes et al 1985 a1 h i m j log 10 ω j t h ϕ d ω where h is the hydraulic head measured at location o x obs y obs due to a pumping source placed at p x p y p with a rate q p ϕ is the adjoint operator with a source term q adj 1 placed at the observation point o x obs y obs t is transmissivity hydraulic with m log t when the transmissivity is constant h and ϕ can be determined analytically with thiem s equation for a confined aquifer a2 h h 0 q p 2 π t ln r rp and ϕ ϕ 0 q adj 2 π t ln r r obs with r obs x o b s x 2 y o b s y 2 a n d r p x p x 2 y p y 2 h0 and ϕ 0 are the values imposed as the boundary of the domain located at a distance r away from the study area r is radial distance then the sensitivity of hydraulic head at point o to a variation of the transmissivity at cell ω j can be approximated with this integral a3 h i m j log 10 q p q adj 4 π 2 t ω j x obs x x p x y obs y y p y r obs 2 r p 2 d ω 
3806,the monthly terrestrial water storage anomaly twsa observations during the gap period between the gravity recovery and climate experiment grace satellite and its follow on grace fo are missing leading to discontinuity in the time series and thus impeding full utilization and analysis of the data despite previous efforts undertaken to tackle this issue a gap filling twsa product with desirable accuracy at a global scale is still lacking in this study a straightforward and hydroclimatic data driven bayesian convolutional neural network bcnn is proposed to bridge this gap benefiting from the excellent capability of bcnn in handling image data and the integration of recent deep learning advances including residual skip connections and spatial channel attentions the proposed method can automatically extract informative features for twsa predictions from multiple predictor data the bcnn predictions are compared with reanalyzed simulated twsa swarm solution and the twsa prediction products generated by three recent studies using commonly used accuracy metrics results demonstrate bcnn s superior performance to obtain higher quality twsa predictions particularly in relatively arid regions additionally a comparison with two independent datasets at the basin scale further suggests that the bcnn infilled twsa is reliable to bridge the gap and enhance data consistency our gap filling product can ultimately contribute to correcting the bias in long term trend estimates maintaining the continuity of twsa time series and thus benefiting subsequent applications desiring continuous data records keywords grace bayesian convolutional neural network gap filling era5 deep learning 1 introduction the gravity recovery and climate experiment grace satellite and its successor grace follow on grace fo provide unprecedentedly accurate observations of the spatiotemporal dynamics of terrestrial water storage anomaly twsa these twsa observations have been widely utilized often together with hydrological models to assess water cycle droughts and floods and impacts of changing climate on terrestrial water storage e g aghakouchak et al 2015 famiglietti et al 2011 feng et al 2018 gentine et al 2019 long et al 2013 rateb et al 2020 richey et al 2015 rodell et al 2018 soltani et al 2021 tapley et al 2019 yan et al 2021 yin et al 2021 zhong et al 2018 these studies have substantially augmented our knowledge toward the complex hydrological systems consequently informing restricted water resources management initially grace was targeted to cover a 5 year period which was exceeded by 10 years to october 2017 its follow on grace fo was then launched in may 2018 this has led to approximately one year of data gap july 2017 may 2018 li et al 2020 leading to discontinuity in the time series and thus impeding full utilization and analysis of the data sun et al 2020 yi and sneeuw 2021 particularly considering that the twsa observations are usually assimilated into hydrological models for higher reliability li et al 2019 mehrnegar et al 2020 mehrnegar et al 2021 nie et al 2019 soltani et al 2021 yin et al 2020 zaitchik et al 2008 discontinuity in the time series observations may introduce significant biases and uncertainties in the model predictions and consequently mislead decision making sun et al 2020 this is especially the case when there existed climate extremes during the gap as they usually cause abnormal changes in the twsa signals two alternatives to the grace satellites that provide measurements of twsa are the geodetic satellite laser ranging slr and the european space agency esa s swarm earth explorer mission friis christensen et al 2008 while there have been studies that bridged the gap between grace and grace fo missions based on the slr and swarm data e g forootan et al 2020 meyer et al 2019 richter et al 2021 their inherent low resolution relative to grace fo limits the gap filling quality bridging this gap with comparably accurate twsa predictions is thus of crucial importance for practical applications there have been many efforts undertaken to reconstruct the missing grace twsa signals at regional or global scales using data driven methods e g ahmed et al 2019 forootan et al 2014 forootan et al 2020 humphrey et al 2017 humphrey and gudmundsson 2019 jing et al 2020 li et al 2020 li et al 2021 long et al 2014 sun et al 2019 sun et al 2020 sun et al 2020 wang et al 2021 yi and sneeuw 2021 for example long et al 2014 utilized artificial neural network ann to learn the relationship between grace twsa and hydroclimatic variables to reconstruct the basin averaged twsa a similar method was then proposed in sun et al 2020 to reconstruct the gridded twsa at the global scale more recently li et al 2020 2021 reconstructed the gridded twsa by integrating machine learning and spatiotemporal decomposition techniques to extract and leverage the spatiotemporally correlated features of data for higher performance while these studies have generally obtained desired performances in specific humid regions a gap filling product with generally high accuracy over the global scale especially in the relatively arid regions see fig 1 for the climate regions is still lacking calling for innovative solutions filling the gap between grace and grace fo at a global scale is challenging due to 1 the difficulty in capturing the long term twsa trends caused by anthropogenic activities and or climate change which accounts for the decreased performance of existing methods in the relatively arid regions humphrey and gudmundsson 2019 li et al 2020 sun et al 2020 and 2 the lack of efficient algorithms to extract informative features from multi source predictor data and suppress unnecessary ones for twsa predictions so that the prediction models can achieve higher accuracy li et al 2020 sun et al 2020 recent years have witnessed a rapid development of deep learning and its impressive performance in a variety of applications gu et al 2018 lecun et al 2015 the advent of deep learning provides new opportunities for addressing many long standing challenges facing research in hydrology and earth sciences reichstein et al 2019 shen 2018 sun and scanlon 2019 thus in this study we aim to develop a new bayesian convolutional neural network bcnn driven by hydroclimatic inputs to bridge the grace and grace fo gap the two mentioned challenges regarding to filling the gap between grace and grace fo will be addressed by 1 using the long term trends retrieved from the available grace fo data in the pre and post gap periods and 2 by developing a deep learning based prediction model one superior advantage of convolutional neural network cnn over the traditional statistical and machine learning methods including the deep fully connected ann with multiple layers employed in previous grace grace fo gap filling studies is its ability to directly take raw data fields images as inputs without requiring additional prepossessing gu et al 2018 mo et al 2019 mo et al 2019 mo et al 2020 shen 2018 sun et al 2019 this property makes cnn very suitable for handling computer vision tasks involving image data gu et al 2018 lecun et al 2015 cnn can fully extract and utilize the spatially correlated features associated with images for predictions sun et al 2019 applied cnn for prediction of twsa fields in india and it outperformed the hydrological models in providing more accurate twsa estimates to the best of our knowledge we present the first attempt to employ cnn for filling the grace and grace fo gap at the global scale in bcnn the global scale hydroclimatic predictor fields and target grace twsa fields are treated as images to leverage cnn s superior capability in image processing to obtain improved gap filling results the development of our bcnn model integrates the recent advances in deep learning including the channel and spatial attention mechanisms woo et al 2018 residual he et al 2016 and skip ronneberger et al 2015 connection modules and bayesian training strategy liu and wang 2016 zhu and zabaras 2018 particularly the bayesian training strategy enables bcnn to quantify the predictive uncertainties to evaluate bcnn s gap filling results we conduct comparisons with era5 land reanalyzed twsa muöoz sabater 2019 noah simulated twsa rodell et al 2004 and the prediction products generated by three recent studies humphrey and gudmundsson 2019 li et al 2021 sun et al 2020 at a grid cell scale and with the swarm solution bezděk et al 2016 at a basin scale for 15 world s major river basins it will be shown that the combination of residual skip connections and spatial channel attentions enables bcnn to automatically and efficiently extract informative features from multi source data and consequently achieve a clearly improved performance in filling the gap the gap filling quality is further validated through comparison with two independent standardized datasets namely the cpc climate prediction center soil moisture van den dool et al 2003 and noah twsa rodell et al 2004 at the basin scale the standardization here is to exclude the influence of amplitude and magnitude differences scanlon et al 2019 the rest of the paper is organized as follows the data used are described in section 2 in section 3 the bcnn model including its architecture design and training is introduced in section 4 we evaluate bcnn s predictions by comparing with multiple twsa products finally the conclusions are summarized in section 5 2 data and processing 2 1 grace twsa data the grace mascon product released by the jet propulsion laboratory jpl which has a spatial resolution of 0 5 0 5 watkins et al 2015 is used in this study the jpl grace twsa data are provided as anomalies with respect to the 2004 to 2009 mean the observations cover two periods that is april 2002 june 2017 grace mission and june 2018 present grace fo mission with a 11 month gap in between in addition there are some one or two month gaps within each mission these gaps are interpolated using the data of neighboring months our aim is to fill the 11 month gap i e july 2017 may 2018 for the land areas with the bcnn method to facilitate the comparison with previous grace prediction studies we resampled averagely the data to 1 1 grids 2 2 era5 land driving data the driving data used to predict the grace twsa are extracted from the era5 land era5l climate reanalysis dataset released by the european centre for medium range weather forecasts muöoz sabater 2019 the data are provided at a spatial resolution of 0 1 0 1 four predictors are considered including the monthly precipitation temperature cumulative water storage change cwsc and era5l derived twsa the spatial resolution of these data is averagely resampled to 1 1 to be consistent with grace twsa cwsc is calculated as the cumulative difference between the inflow i e precipitation p and outflow i e evapotranspiration et and runoff ro of a grid cell 1 cwsc t i 1 t p i et i ro i where t denotes the month index anthropogenic activities e g groundwater extraction can also influence the water storage but they are difficult to quantify and thus not considered here the era5l dataset includes water storage in soil moisture snow and canopy thus the era5l twsa is calculated by summing these components and then subtracting the long term mean between 2004 and 2009 to be consistent with grace twsa as represented by 2 twsa era 5 l sms sws cws tws 0409 where sms sws and cws are soil moisture snow water and canopy water storage respectively tws 0409 denotes the 2004 2009 mean 2 3 time series data detrending the grace twsa time series may exhibit long term declining rising trends caused by the human interventions and or changing climate this presents challenges for twsa prediction as the hydroclimatic predictor data may not be able to fully capture these trends humphrey and gudmundsson 2019 li et al 2020 sun et al 2020 for the gap filling task considered here fortunately the grace data before april 2002 june 2017 and after june 2018 the gap are available therefore we can obtain directly the long term trends covering the gap period from existing data then we predict in the gap filling task the detrended twsas instead which is generally less challenging relative to predicting the original signals humphrey and gudmundsson 2019 li et al 2020 mathematically the grace twsa time series are decomposed via linear detrending into two components 3 twsa grace twsa grace detrend trend grace where twsa grace detrend is the detrended data trend grace is the linear long term trend obtained by linear fitting with the available grace fo data between 2002 and 2020 correspondingly the driving data described in section 2 2 are also detrended in the prediction task bcnn learns to predict the twsa grace detrend signals and the predictions for the original twsas are then obtained by adding the grace trend 4 twsa bcnn twsa bcnn detrend trend grace 3 methods 3 1 bcnn deep learning model the bcnn model is proposed to learn the underlying relationship between twsa grace detrend and its four predictors i e the detrended p t cwsc and twsa era 5 l here we denote the network inputs i e predictors and outputs i e twsa grace detrend as x and y respectively the global fields of grace twsa and hydroclimatic predictors are arranged as images the learning of high dimensional and complex mapping between the outputs and inputs becomes an image regression problem and can leverage cnn s robust capability in image processing gu et al 2018 mo et al 2019 shen 2018 as represented by 5 η x r n x h w y r n y h w where η η x w is a bcnn model with w denoting all trainable network parameters the inputs x and outputs y become n x and n y images respectively all with h w pixels grids it is worth mentioning that the spherical cnn su and grauman 2017 may be an alternative to vanilla cnn for the image regression task considered here as the grace mascons are defined on a sphere this though out the scope of this work deserves further investigation the network predictions are inevitably associated with epistemic uncertainties induced by a lack of training data to quantify the predictive uncertainties we treat the network parameters w as random variables given a set of training data d x i y i i 1 n train the network training is to infer the posterior distribution of w p w d consequently one can obtain the predictive distribution of the target y p y w w p w d and in particular the mean e y w and standard deviation std y w in bcnn a bayesian training strategy called stein variational gradient descent svgd liu and wang 2016 zhu and zabaras 2018 is employed to estimate the posterior distribution p w d mathematically the bcnn model is expressed as follows 6 y η x w n x w where y denotes bcnn s prediction and n is an additive gaussian noise term modeling the aleatoric uncertainty the svgd algorithm is similar to standard gradient descent while maintaining the particle methods high efficiency liu and wang 2016 in implementation we use n s particles of w to approximate the posterior distribution the n s samples w i i 1 n s are respectively optimized using the adam optimizer kingma and ba 2015 whose gradient derives from svgd the predictive mean and standard deviation i e uncertainty of bcnn for an arbitrary input x can be then computed using the n s predictions y i η x w i n x w i i 1 n s for more details regarding the svgd bayesian training strategy one can refer to liu and wang 2016 and zhu and zabaras 2018 3 2 bcnn architecture design and training the bcnn network architecture is depicted in fig 2 the convolutional block attention module cbam woo et al 2018 is used as the basic block given n x images with a resolution of h w as inputs to the network they are passed through an alternating cascade of convolutional transposed convolutional layers and cbams each of which produces n f feature maps with a resolution of h w to extract multi scale and hierarchical features to finally predict n y images for the targets the cbam block contains two attention modules namely the channel and spatial attentions as depicted in fig 2 and detailed in fig 3 more specifically the channel module outputs n f weights between 0 and 1 assigning to the n f feature maps to tell the network what i e which maps to attend the spatial module outputs a h w weight matrix assigning to the h w pixel feature maps to tell the network where i e which regions to emphasize or suppress as such the network is able to automatically focus on important features and suppress unnecessary ones woo et al 2018 the residual he et al 2016 and skip ronneberger et al 2015 connections are also adopted in our bcnn model it has been extensively shown that they can effectively resolve the vanishing gradient problem and enhance information flow through the deep networks substantially improving the network performance in the residual connection the feature maps with the same shape n f h w but at different layers are connected by applying element wise addition he et al 2016 in the skip connection the feature maps with the same size h w but at different layers are cascaded together and subsequently fed as inputs into the next layer ronneberger et al 2015 fig 2 the mish function misra 2019 is employed in bcnn as the activation function unless otherwise stated we use twelve years of monthly grace twsa data from april 2002 to march 2014 i e 144 months 69 to train the bcnn network and those from april 2014 to june 2017 and june 2018 to august 2020 i e 66 months 31 to test the performance we set the number of lags for predictors to 2 after preliminary test experiments as the increased lag did not clearly improve the performance not shown that is for month t the inputs to bcnn are the four predictors in months t 2 to t thus each sample contains n x 12 input images and n y 1 output image i e twsa grace t detrend the region spanning from 60 s to 84 n and 180 w to 180 e i e h w 144 360 is considered during network training we use n s 20 particles of w in the svgd algorithm to approximate the posterior distribution as suggested in zhu and zabaras 2018 the network is trained for 200 epochs with a mean squared error loss function quantifying the predictive accuracy an initial learning rate of 0 0025 and a batch size of 12 the training performed on a single gpu nvidia tesla v100 takes 80 min the network performance is evaluated with the testing data using three commonly used metrics namely the correlation coefficient r nash sutcliffe efficiency coefficient nse and normalized root mean squared error nrmse 7 r i 1 n test y i y y i y i 1 n test y i y 2 i 1 n test y i y 2 8 nse 1 i 1 n test y i y i 2 i 1 n test y i y 2 9 nrmse 1 n test i 1 n test y i y i 2 y max y min where y denotes the observations and y the predictions with y and y respectively denoting their means n test is the number of testing samples y max and y min represent the maximum and minimum values of y respectively a r or nse value closer to 1 0 and a nrmse value closer to 0 indicate better performances 4 results and discussion 4 1 accuracy assessment with testing grace data the prediction accuracy is assessed using the grace data in 66 testing months to illustrate the performance of bcnn the r nse and nrmse metrics are also computed for the era5l reanalyzed twsas muöoz sabater 2019 and noah simulated twsas rodell et al 2004 fig 4 shows the spatial maps of the accuracy metrics obtained by noah era5l and bcnn while noah and era5l both show relatively good correlations with grace in most regions except greenland and the hyper arid areas like sahara gobi and arabian figs 4 a b bcnn s r values are clearly higher than those of noah and era5l in almost all regions fig 4c for the nse metric which measures directly the matching quality between the predicted and observed values both noah and era5l obtain unsatisfactorily low values 0 in most regions except in some humid regions like amazon and southeastern united states fig 4 d e in contrast bcnn provides relatively high values 0 5 in most regions fig 4f note that although bcnn achieves higher accuracy than noah and era5l in the hyper arid regions the nse values are still low relative to other regions this is due to the fact that the twsa signals in these regions is dominated by noise humphrey et al 2016 the improved performance of bcnn over noah and era5l can be also illustrated by the nrmse maps depicted in figs 4 g i and the cumulative distribution functions of the three metrics depicted in fig 4 j l which indicate that bcnn provides significantly better accuracy i e much higher r and nse values and much lower nrmse values note that the outperformance of bcnn benefits not only from its own robust capability in learning complex mappings but also from the use of grace data for training the inability of noah and era5l to consider the groundwater and surface water components in their water storage estimates may be another cause for the inconsistency it can be seen from fig 4 that the performance is highly dependent on the regional climate conditions we further compare the three models r nse and nrmse values at grids in the hyper arid arid semi arid semi humid and humid regions see fig 1 for the climate regions the results are summarized in the boxplots depicted in fig 5 with the metric medians being listed in table 1 in general higher performances are achieved as expected in regions with more humid climate this is probably because the arid regions usually have relatively low signal to noise ratios and are often associated with heavy human interventions e g groundwater extractions and reservoir operations humphrey et al 2016 sun et al 2020 likewise bcnn clearly outperforms noah and era5l in all climate regions for example the median nse values of noah era5l and bcnn in the hyper arid region are 10 50 8 51 and 0 27 respectively table 1 fig 6 depicts bcnn s twsa predictions for three testing months in june 2014 june 2017 and june 2020 note that the grace data of the three months were not seen by bcnn during model training for comparison the reference grace twsa fields are also shown due to the bayesian nature of bcnn the predictive uncertainties can be quantified and are depicted as standard deviation in the plot it can be seen that bcnn successfully captures the spatial patterns of grace twsa and provides close predictions in the three months figs 6 a f the predictive errors and uncertainties in humid regions e g amazon central africa south asia and greenland are generally larger compared to other regions figs 6 g l which are mainly because of the relatively high signal variability in the humid regions the bcnn s twsa predictions for all of the 66 testing months are shown in the gif animation attached as supporting materials 4 2 evaluation of gap filling quality at the basin scale the results presented in section 4 1 indicate that bcnn is able to provide close predictions to the testing grace data in the pre and post gap periods to further validate that bcnn s infilling data are grace like and reliable two independent datasets namely the cpc climate prediction center soil moisture van den dool et al 2003 and noah simulated twsas rodell et al 2004 are used for verification at the basin scale more specifically we compare the basin averaged time series of these datasets as shown in section 4 1 and by scanlon et al 2019 the amplitude and magnitude differences of two time series may lead to poor consistency therefore these basin averaged time series are respectively standardized to make the data comparable 10 y y μ y σ y where μ y and σ y are the mean and standard deviation respectively of the time series for consistency the bcnn and grace twsa time series are both standardized using grace s μ y and σ y the grid scale nse values between the standardized grace twsas and soil moisture noah twsas during the testing periods indicate that they agree relatively well in most regions fig 7 particularly after excluding the influence of amplitude and magnitude differences by standardization the consistency between noah and grace is significantly improved see figs 4d and 7b the idea behind the validation is suppose that the standardized time series of soil moisture noah twsa agree well with that of grace twsa in the pre and post gap testing periods the gap filling results can be thought to be reliable if the bcnn twsa time series fit well with those of soil moisture noah twsa during the testing and gap periods the basin averaged standardized time series of the grace twsa bcnn twsa cpc soil moisture noah twsa for 40 major river basins see fig 8 for the basin locations are compared in fig 9 with the nse values between them being summarized in table 2 these plots manifest that bcnn twsas show favorable consistency with grace twsas during the testing periods in the 40 basins the nse values between them are generally larger than 0 7 with the exception of indus nse 0 67 orange nse 0 44 pearl nse 0 67 and yellow nse 0 63 river basins the mismatch in these basins is probably because of the insufficient quality and or ability of driving data to capture the impacts of anthropogenic activities on water cycle it is worthy noting that although bcnn may slightly underestimate overestimate grace twsas the grace curves are almost completely enveloped within bcnn s 95 prediction interval calculated using an ensemble of n s 20 bcnn predictions section 3 1 additionally the standardized time series of soil moisture and noah twsa agree relatively well with those of grace twsa in most basins during the grace covered periods as also indicated by the nse values listed in table 2 therefore the good consistency between bcnn twsas and soil moisture noah twsas in these basins suggests the reliability of bcnn s gap filling results for the remaining few basins with the nse values between the grace bcnn twsa and soil moisture noah twsa time series all less than 0 4 marked in bold in table 2 it is found that all of these basins have declining grace twsa trends while the precipitation exhibits oppositely rising trends an exception is the hai river basin but the twsa time series are more significantly declining the decreased water storage in these basins are mainly resulted from glacier retreating yukon river basin or groundwater depletion hai indus and yellow river basins rodell et al 2018 the inability of soil moisture and noah to reflect the twsa declines induced by glacier retreating and groundwater depletion leads to the poor consistency despite this bcnn s close predictions to grace twsas in the pre and post gap periods still suggest the reliability of gap filling results figs 9 k l z i l for the gap filling purpose one can also simply bridge the gap with the long term trend and seasonal signals derived from the available grace observations i e twsa grace t s trend grace season grace fig 10 depicts the basin averaged time series of the original without standardizing grace twsa bcnn twsa and twsa grace t s for the 40 river basins it is observed that bcnn achieves a better consistency higher nse values with grace than twsa grace t s in all basins fig 11 displays the nse field between grace twsa and twsa grace t s the regions with high nse values are as expected generally the seasonal component dominant regions see fig 9 in humphrey et al 2016 for the spatial distribution of seasonal component dominant regions one popular use of the twsa data is to estimate the long term trend of water storage chen et al 2014 feng et al 2013 feng et al 2018 scanlon et al 2018 tapley et al 2019 here we investigate the impact of the 11 month gap on the long term april 2002 august 2020 trend estimation the trend field after the gap is filled with bcnn predicted twsas is illustrated in fig 12 the difference between the trends before and after gap filling is also shown which can be as large as 0 2 cm year in many regions taking the amazon river basin the area is over 6 10 6 km2 as an example a bias of 0 2 cm year in the trend estimate would lead to a deviation of over 12 gt year in the water storage loss gain estimate the differences in trend estimates may be partially caused by dry or wet climate conditions during the gap period as they usually lead to decreased or increased twsa signals respectively to examine this the 6 month standardized precipitation evapotranspiration index spei 6 available at https spei csic es spei database fields during the gap period are plotted in fig 13 it is observed that the trend difference patterns fig 12b are spatially similar to the wet dry patterns in the spei 6 fields indicating that the overestimation underestimation of the original long term trends is mainly related to the the dry wet conditions during the gap period bcnn reproduces the dry wet condition induced abnormal twsa signals from hydroclimatic inputs and thus contributes to improving the trend estimation it should be mentioned that for the extremely dry wet conditions caused by climate extremes bcnn s generalization on such extreme induced abnormal signals may be limited due to the well known long tail distribution issue in deep learning the extremes are associated with only a few samples because of their rare occurrence menon et al 2021 integrating the long tailed learning menon et al 2021 with bcnn may be a better solution 4 3 comparison with swarm solution in this section we conduct a comparison between bcnn and swarm derived twsas to illustrate the merits of bcnn in providing more reliable gap filling products the swarm satellite provides the observations of twsas since december 2013 but at much lower resolution relative to grace friis christensen et al 2008 the data quality is not stable in early years but expected to increase as the mission progresses da encarnação et al 2016 the monthly swarm level 2 gravity field model provided by the astronomical institute at the czech academy of sciences asu bezděk et al 2016 in terms of spherical harmonic coefficients up to degree and order 40 is used to estimate global twsas to reduce the high magnitude noise in the swarm solution we apply a 1000 km gaussian filter to smooth the data fields considering the low resolution of swarm data we make a basin scale comparison for only 15 world s major river basins the time series of twsas from grace swarm and bcnn during april 2014 and december 2019 are compared in fig 14 the nse values of swarm and bcnn twsas with the reference grace twsas are also attached in each subplot the figure manifests that although the swarm twsas can generally capture the variability patterns of grace twsas the differences in their amplitudes lead to relatively large deviations in many basins e g amur murray yangtze on the contrary bcnn twsas fit appreciably better with those of grace with much higher nses suggesting bcnn s higher reliability in bridging the grace and grace fo gap 4 4 comparison with previous studies here we restrict the comparison with humphrey and gudmundsson 2019 sun et al 2020 and li et al 2021 who provided publicly accessible global scale twsa prediction products the predicted twsa product by humphrey and gudmundsson 2019 is known as grace rec the original grace rec dataset provides the detrended and deseasonalized twsas we add the trend and seasonal signals obtained from the grace twsas and humphrey et al 2017 respectively to the original grace rec twsas for consistency the twsa product generated in sun et al 2020 with a deep fully connected neural network is used here for comparison the spatial resolution of predicted twsas in humphrey and gudmundsson 2019 and li et al 2021 is 0 5 0 5 for consistency we predict the twsas at the same resolution and thus the input output image size of bcnn is h w 288 720 for a fair comparison the grace twsa data and the training periods used for bcnn network training are respectively the same as those employed in the three studies the detailed descriptions of the three twsa products are summarized in table 3 the comparison results are shown in fig 15 for simplicity we show in the plot only the nse metric as it measures directly the matching quality in terms of both magnitude and phase between the predicted and target time series in addition we also compare separately the performances in the hyper arid arid semi arid semi humid and humid regions in fig 16 which summarizes the boxplots of the gridded nse values in the five climate regions the medians of the boxplots are listed in tables 4 figs 15 and 16 clearly suggest bcnn s better performance relative to the three previous methods humphrey and gudmundsson 2019 li et al 2021 sun et al 2020 which obtain relatively high accuracy in the humid semi humid regions but their performances decrease in the hyper arid arid semi arid regions our bcnn method successfully improves the prediction accuracy in these hyper arid arid semi arid regions to a relatively high level for instance compared to humphrey and gudmundsson 2019 our bcnn improves the median nse values in the hyper arid arid and semi arid regions from 0 41 0 01 and 0 39 respectively to 0 17 0 57 and 0 69 table 4 the results suggest bcnn s superior performance in providing improved twsa predictions to bridge the grace and grace fo gap which is attributed jointly to the use of grace trend section 2 3 and bcnn s outstanding capability in learning the high dimensional and highly complex mappings between the twsa and hydroclimatic inputs two additional noteworthy merits of bcnn compared to prior methods are the few assumptions preprocessing involved and its ability to handle directly the global scale note that we set in bcnn for simplicity all inputs and outputs to the same spatial resolution and consider only the land components it is flexible and straightforward for bcnn to handle inputs outputs with different sizes and ocean components e g sea surface temperature this property benefits from the flexibility of cnn in architecture design and performing downsampling upsampling concatenation and many other operations 5 conclusions in this study we propose a deep learning based bcnn method driven by era5l hydroclimatic data to fill the one year twsa observation gap between the grace and grace fo satellites at the global scale the integration of residual skip connections spatial channel attentions and bayesian training strategy in bcnn enables it to effectively extract informative features for twsa predictions from multiple predictor data and quantify the predictive uncertainties results show that bcnn successfully captures twsa s complex spatiotemporal patterns the comparisons with reanalyzed simulated twsa products swarm solution and three previous studies further suggest bcnn s clearly higher gap filling performance particularly in the relatively arid regions the gap filling quality in maintaining the data continuity is further validated and confirmed through comparison with the standardized cpc soil moisture and noah simulated twsa at the basin scale the improvements in restoring the missing twsa signals can be of great significance for applications desiring continuous data records in the time series analysis correcting the bias in long term trend estimates due to missing data and enhancing the reliability of hydrological model predictions the outperformance of bcnn is mainly attributed to the use of twsa trends which are derived from the available grace fo data in the pre and post gap periods and its outstanding performance in feature extraction the long term twsa trends induced by anthropogenic and or natural factors are usually challenging to learn humphrey and gudmundsson 2019 li et al 2020 sun et al 2020 the utilization of this trend information makes full use of the existing data and essentially eases the learning task for bcnn the bcnn s capability for informative feature extraction inherits the outstanding performance of cnn in image processing which is further enhanced by integrating recent advances in deep learning note that we are concerned with bridging the gap between grace and grace fo in the current work for the task reconstructing twsas in the pre grace period which is beyond the scope of this study the trend information is unavailable the performance of bcnn for such a task remains to be explored credit authorship contribution statement shaoxing mo conceptualization methodology investigation formal analysis validation writing original draft ehsan forootan data curation validation writing review editing nooshin mehrnegar data curation writing review editing xin yin data curation writing review editing jichun wu supervision funding acquisition writing review editing wei feng supervision data curation validation writing review editing xiaoqing shi supervision funding acquisition writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the jpl and csr grace mascon data used in this study are available at https podaac jpl nasa gov dataset tellus grac grfo mascon cri grid rl06 v2 and http www2 csr utexas edu grace rl06 mascons html respectively era5 land data are available at https doi org 10 24381 cds 68d2bb30 noah twsa dataset is downloaded from https disc gsfc nasa gov datasets gldas noah10 m 2 1 summary we thank dr vincent humphrey dr zhangli sun and dr fupeng li for sharing their twsa prediction products this work was funded by the national natural science foundation of china 41730856 41874095 41977157 42002248 42004073 china postdoctoral science foundation 2020m681550 jiangsu planned projects for postdoctoral research funds 2020z133 and fundamental research funds for the central universities 020614380106 s mo thanks dr yinhao zhu from qualcomm ai research for his valuable suggestions on bcnn we are also grateful to the editor associate editor and three anonymous reviewers for their constructive comments the predicted twsa dataset generated in this work is available at https doi org 10 5281 zenodo 4589755 
3806,the monthly terrestrial water storage anomaly twsa observations during the gap period between the gravity recovery and climate experiment grace satellite and its follow on grace fo are missing leading to discontinuity in the time series and thus impeding full utilization and analysis of the data despite previous efforts undertaken to tackle this issue a gap filling twsa product with desirable accuracy at a global scale is still lacking in this study a straightforward and hydroclimatic data driven bayesian convolutional neural network bcnn is proposed to bridge this gap benefiting from the excellent capability of bcnn in handling image data and the integration of recent deep learning advances including residual skip connections and spatial channel attentions the proposed method can automatically extract informative features for twsa predictions from multiple predictor data the bcnn predictions are compared with reanalyzed simulated twsa swarm solution and the twsa prediction products generated by three recent studies using commonly used accuracy metrics results demonstrate bcnn s superior performance to obtain higher quality twsa predictions particularly in relatively arid regions additionally a comparison with two independent datasets at the basin scale further suggests that the bcnn infilled twsa is reliable to bridge the gap and enhance data consistency our gap filling product can ultimately contribute to correcting the bias in long term trend estimates maintaining the continuity of twsa time series and thus benefiting subsequent applications desiring continuous data records keywords grace bayesian convolutional neural network gap filling era5 deep learning 1 introduction the gravity recovery and climate experiment grace satellite and its successor grace follow on grace fo provide unprecedentedly accurate observations of the spatiotemporal dynamics of terrestrial water storage anomaly twsa these twsa observations have been widely utilized often together with hydrological models to assess water cycle droughts and floods and impacts of changing climate on terrestrial water storage e g aghakouchak et al 2015 famiglietti et al 2011 feng et al 2018 gentine et al 2019 long et al 2013 rateb et al 2020 richey et al 2015 rodell et al 2018 soltani et al 2021 tapley et al 2019 yan et al 2021 yin et al 2021 zhong et al 2018 these studies have substantially augmented our knowledge toward the complex hydrological systems consequently informing restricted water resources management initially grace was targeted to cover a 5 year period which was exceeded by 10 years to october 2017 its follow on grace fo was then launched in may 2018 this has led to approximately one year of data gap july 2017 may 2018 li et al 2020 leading to discontinuity in the time series and thus impeding full utilization and analysis of the data sun et al 2020 yi and sneeuw 2021 particularly considering that the twsa observations are usually assimilated into hydrological models for higher reliability li et al 2019 mehrnegar et al 2020 mehrnegar et al 2021 nie et al 2019 soltani et al 2021 yin et al 2020 zaitchik et al 2008 discontinuity in the time series observations may introduce significant biases and uncertainties in the model predictions and consequently mislead decision making sun et al 2020 this is especially the case when there existed climate extremes during the gap as they usually cause abnormal changes in the twsa signals two alternatives to the grace satellites that provide measurements of twsa are the geodetic satellite laser ranging slr and the european space agency esa s swarm earth explorer mission friis christensen et al 2008 while there have been studies that bridged the gap between grace and grace fo missions based on the slr and swarm data e g forootan et al 2020 meyer et al 2019 richter et al 2021 their inherent low resolution relative to grace fo limits the gap filling quality bridging this gap with comparably accurate twsa predictions is thus of crucial importance for practical applications there have been many efforts undertaken to reconstruct the missing grace twsa signals at regional or global scales using data driven methods e g ahmed et al 2019 forootan et al 2014 forootan et al 2020 humphrey et al 2017 humphrey and gudmundsson 2019 jing et al 2020 li et al 2020 li et al 2021 long et al 2014 sun et al 2019 sun et al 2020 sun et al 2020 wang et al 2021 yi and sneeuw 2021 for example long et al 2014 utilized artificial neural network ann to learn the relationship between grace twsa and hydroclimatic variables to reconstruct the basin averaged twsa a similar method was then proposed in sun et al 2020 to reconstruct the gridded twsa at the global scale more recently li et al 2020 2021 reconstructed the gridded twsa by integrating machine learning and spatiotemporal decomposition techniques to extract and leverage the spatiotemporally correlated features of data for higher performance while these studies have generally obtained desired performances in specific humid regions a gap filling product with generally high accuracy over the global scale especially in the relatively arid regions see fig 1 for the climate regions is still lacking calling for innovative solutions filling the gap between grace and grace fo at a global scale is challenging due to 1 the difficulty in capturing the long term twsa trends caused by anthropogenic activities and or climate change which accounts for the decreased performance of existing methods in the relatively arid regions humphrey and gudmundsson 2019 li et al 2020 sun et al 2020 and 2 the lack of efficient algorithms to extract informative features from multi source predictor data and suppress unnecessary ones for twsa predictions so that the prediction models can achieve higher accuracy li et al 2020 sun et al 2020 recent years have witnessed a rapid development of deep learning and its impressive performance in a variety of applications gu et al 2018 lecun et al 2015 the advent of deep learning provides new opportunities for addressing many long standing challenges facing research in hydrology and earth sciences reichstein et al 2019 shen 2018 sun and scanlon 2019 thus in this study we aim to develop a new bayesian convolutional neural network bcnn driven by hydroclimatic inputs to bridge the grace and grace fo gap the two mentioned challenges regarding to filling the gap between grace and grace fo will be addressed by 1 using the long term trends retrieved from the available grace fo data in the pre and post gap periods and 2 by developing a deep learning based prediction model one superior advantage of convolutional neural network cnn over the traditional statistical and machine learning methods including the deep fully connected ann with multiple layers employed in previous grace grace fo gap filling studies is its ability to directly take raw data fields images as inputs without requiring additional prepossessing gu et al 2018 mo et al 2019 mo et al 2019 mo et al 2020 shen 2018 sun et al 2019 this property makes cnn very suitable for handling computer vision tasks involving image data gu et al 2018 lecun et al 2015 cnn can fully extract and utilize the spatially correlated features associated with images for predictions sun et al 2019 applied cnn for prediction of twsa fields in india and it outperformed the hydrological models in providing more accurate twsa estimates to the best of our knowledge we present the first attempt to employ cnn for filling the grace and grace fo gap at the global scale in bcnn the global scale hydroclimatic predictor fields and target grace twsa fields are treated as images to leverage cnn s superior capability in image processing to obtain improved gap filling results the development of our bcnn model integrates the recent advances in deep learning including the channel and spatial attention mechanisms woo et al 2018 residual he et al 2016 and skip ronneberger et al 2015 connection modules and bayesian training strategy liu and wang 2016 zhu and zabaras 2018 particularly the bayesian training strategy enables bcnn to quantify the predictive uncertainties to evaluate bcnn s gap filling results we conduct comparisons with era5 land reanalyzed twsa muöoz sabater 2019 noah simulated twsa rodell et al 2004 and the prediction products generated by three recent studies humphrey and gudmundsson 2019 li et al 2021 sun et al 2020 at a grid cell scale and with the swarm solution bezděk et al 2016 at a basin scale for 15 world s major river basins it will be shown that the combination of residual skip connections and spatial channel attentions enables bcnn to automatically and efficiently extract informative features from multi source data and consequently achieve a clearly improved performance in filling the gap the gap filling quality is further validated through comparison with two independent standardized datasets namely the cpc climate prediction center soil moisture van den dool et al 2003 and noah twsa rodell et al 2004 at the basin scale the standardization here is to exclude the influence of amplitude and magnitude differences scanlon et al 2019 the rest of the paper is organized as follows the data used are described in section 2 in section 3 the bcnn model including its architecture design and training is introduced in section 4 we evaluate bcnn s predictions by comparing with multiple twsa products finally the conclusions are summarized in section 5 2 data and processing 2 1 grace twsa data the grace mascon product released by the jet propulsion laboratory jpl which has a spatial resolution of 0 5 0 5 watkins et al 2015 is used in this study the jpl grace twsa data are provided as anomalies with respect to the 2004 to 2009 mean the observations cover two periods that is april 2002 june 2017 grace mission and june 2018 present grace fo mission with a 11 month gap in between in addition there are some one or two month gaps within each mission these gaps are interpolated using the data of neighboring months our aim is to fill the 11 month gap i e july 2017 may 2018 for the land areas with the bcnn method to facilitate the comparison with previous grace prediction studies we resampled averagely the data to 1 1 grids 2 2 era5 land driving data the driving data used to predict the grace twsa are extracted from the era5 land era5l climate reanalysis dataset released by the european centre for medium range weather forecasts muöoz sabater 2019 the data are provided at a spatial resolution of 0 1 0 1 four predictors are considered including the monthly precipitation temperature cumulative water storage change cwsc and era5l derived twsa the spatial resolution of these data is averagely resampled to 1 1 to be consistent with grace twsa cwsc is calculated as the cumulative difference between the inflow i e precipitation p and outflow i e evapotranspiration et and runoff ro of a grid cell 1 cwsc t i 1 t p i et i ro i where t denotes the month index anthropogenic activities e g groundwater extraction can also influence the water storage but they are difficult to quantify and thus not considered here the era5l dataset includes water storage in soil moisture snow and canopy thus the era5l twsa is calculated by summing these components and then subtracting the long term mean between 2004 and 2009 to be consistent with grace twsa as represented by 2 twsa era 5 l sms sws cws tws 0409 where sms sws and cws are soil moisture snow water and canopy water storage respectively tws 0409 denotes the 2004 2009 mean 2 3 time series data detrending the grace twsa time series may exhibit long term declining rising trends caused by the human interventions and or changing climate this presents challenges for twsa prediction as the hydroclimatic predictor data may not be able to fully capture these trends humphrey and gudmundsson 2019 li et al 2020 sun et al 2020 for the gap filling task considered here fortunately the grace data before april 2002 june 2017 and after june 2018 the gap are available therefore we can obtain directly the long term trends covering the gap period from existing data then we predict in the gap filling task the detrended twsas instead which is generally less challenging relative to predicting the original signals humphrey and gudmundsson 2019 li et al 2020 mathematically the grace twsa time series are decomposed via linear detrending into two components 3 twsa grace twsa grace detrend trend grace where twsa grace detrend is the detrended data trend grace is the linear long term trend obtained by linear fitting with the available grace fo data between 2002 and 2020 correspondingly the driving data described in section 2 2 are also detrended in the prediction task bcnn learns to predict the twsa grace detrend signals and the predictions for the original twsas are then obtained by adding the grace trend 4 twsa bcnn twsa bcnn detrend trend grace 3 methods 3 1 bcnn deep learning model the bcnn model is proposed to learn the underlying relationship between twsa grace detrend and its four predictors i e the detrended p t cwsc and twsa era 5 l here we denote the network inputs i e predictors and outputs i e twsa grace detrend as x and y respectively the global fields of grace twsa and hydroclimatic predictors are arranged as images the learning of high dimensional and complex mapping between the outputs and inputs becomes an image regression problem and can leverage cnn s robust capability in image processing gu et al 2018 mo et al 2019 shen 2018 as represented by 5 η x r n x h w y r n y h w where η η x w is a bcnn model with w denoting all trainable network parameters the inputs x and outputs y become n x and n y images respectively all with h w pixels grids it is worth mentioning that the spherical cnn su and grauman 2017 may be an alternative to vanilla cnn for the image regression task considered here as the grace mascons are defined on a sphere this though out the scope of this work deserves further investigation the network predictions are inevitably associated with epistemic uncertainties induced by a lack of training data to quantify the predictive uncertainties we treat the network parameters w as random variables given a set of training data d x i y i i 1 n train the network training is to infer the posterior distribution of w p w d consequently one can obtain the predictive distribution of the target y p y w w p w d and in particular the mean e y w and standard deviation std y w in bcnn a bayesian training strategy called stein variational gradient descent svgd liu and wang 2016 zhu and zabaras 2018 is employed to estimate the posterior distribution p w d mathematically the bcnn model is expressed as follows 6 y η x w n x w where y denotes bcnn s prediction and n is an additive gaussian noise term modeling the aleatoric uncertainty the svgd algorithm is similar to standard gradient descent while maintaining the particle methods high efficiency liu and wang 2016 in implementation we use n s particles of w to approximate the posterior distribution the n s samples w i i 1 n s are respectively optimized using the adam optimizer kingma and ba 2015 whose gradient derives from svgd the predictive mean and standard deviation i e uncertainty of bcnn for an arbitrary input x can be then computed using the n s predictions y i η x w i n x w i i 1 n s for more details regarding the svgd bayesian training strategy one can refer to liu and wang 2016 and zhu and zabaras 2018 3 2 bcnn architecture design and training the bcnn network architecture is depicted in fig 2 the convolutional block attention module cbam woo et al 2018 is used as the basic block given n x images with a resolution of h w as inputs to the network they are passed through an alternating cascade of convolutional transposed convolutional layers and cbams each of which produces n f feature maps with a resolution of h w to extract multi scale and hierarchical features to finally predict n y images for the targets the cbam block contains two attention modules namely the channel and spatial attentions as depicted in fig 2 and detailed in fig 3 more specifically the channel module outputs n f weights between 0 and 1 assigning to the n f feature maps to tell the network what i e which maps to attend the spatial module outputs a h w weight matrix assigning to the h w pixel feature maps to tell the network where i e which regions to emphasize or suppress as such the network is able to automatically focus on important features and suppress unnecessary ones woo et al 2018 the residual he et al 2016 and skip ronneberger et al 2015 connections are also adopted in our bcnn model it has been extensively shown that they can effectively resolve the vanishing gradient problem and enhance information flow through the deep networks substantially improving the network performance in the residual connection the feature maps with the same shape n f h w but at different layers are connected by applying element wise addition he et al 2016 in the skip connection the feature maps with the same size h w but at different layers are cascaded together and subsequently fed as inputs into the next layer ronneberger et al 2015 fig 2 the mish function misra 2019 is employed in bcnn as the activation function unless otherwise stated we use twelve years of monthly grace twsa data from april 2002 to march 2014 i e 144 months 69 to train the bcnn network and those from april 2014 to june 2017 and june 2018 to august 2020 i e 66 months 31 to test the performance we set the number of lags for predictors to 2 after preliminary test experiments as the increased lag did not clearly improve the performance not shown that is for month t the inputs to bcnn are the four predictors in months t 2 to t thus each sample contains n x 12 input images and n y 1 output image i e twsa grace t detrend the region spanning from 60 s to 84 n and 180 w to 180 e i e h w 144 360 is considered during network training we use n s 20 particles of w in the svgd algorithm to approximate the posterior distribution as suggested in zhu and zabaras 2018 the network is trained for 200 epochs with a mean squared error loss function quantifying the predictive accuracy an initial learning rate of 0 0025 and a batch size of 12 the training performed on a single gpu nvidia tesla v100 takes 80 min the network performance is evaluated with the testing data using three commonly used metrics namely the correlation coefficient r nash sutcliffe efficiency coefficient nse and normalized root mean squared error nrmse 7 r i 1 n test y i y y i y i 1 n test y i y 2 i 1 n test y i y 2 8 nse 1 i 1 n test y i y i 2 i 1 n test y i y 2 9 nrmse 1 n test i 1 n test y i y i 2 y max y min where y denotes the observations and y the predictions with y and y respectively denoting their means n test is the number of testing samples y max and y min represent the maximum and minimum values of y respectively a r or nse value closer to 1 0 and a nrmse value closer to 0 indicate better performances 4 results and discussion 4 1 accuracy assessment with testing grace data the prediction accuracy is assessed using the grace data in 66 testing months to illustrate the performance of bcnn the r nse and nrmse metrics are also computed for the era5l reanalyzed twsas muöoz sabater 2019 and noah simulated twsas rodell et al 2004 fig 4 shows the spatial maps of the accuracy metrics obtained by noah era5l and bcnn while noah and era5l both show relatively good correlations with grace in most regions except greenland and the hyper arid areas like sahara gobi and arabian figs 4 a b bcnn s r values are clearly higher than those of noah and era5l in almost all regions fig 4c for the nse metric which measures directly the matching quality between the predicted and observed values both noah and era5l obtain unsatisfactorily low values 0 in most regions except in some humid regions like amazon and southeastern united states fig 4 d e in contrast bcnn provides relatively high values 0 5 in most regions fig 4f note that although bcnn achieves higher accuracy than noah and era5l in the hyper arid regions the nse values are still low relative to other regions this is due to the fact that the twsa signals in these regions is dominated by noise humphrey et al 2016 the improved performance of bcnn over noah and era5l can be also illustrated by the nrmse maps depicted in figs 4 g i and the cumulative distribution functions of the three metrics depicted in fig 4 j l which indicate that bcnn provides significantly better accuracy i e much higher r and nse values and much lower nrmse values note that the outperformance of bcnn benefits not only from its own robust capability in learning complex mappings but also from the use of grace data for training the inability of noah and era5l to consider the groundwater and surface water components in their water storage estimates may be another cause for the inconsistency it can be seen from fig 4 that the performance is highly dependent on the regional climate conditions we further compare the three models r nse and nrmse values at grids in the hyper arid arid semi arid semi humid and humid regions see fig 1 for the climate regions the results are summarized in the boxplots depicted in fig 5 with the metric medians being listed in table 1 in general higher performances are achieved as expected in regions with more humid climate this is probably because the arid regions usually have relatively low signal to noise ratios and are often associated with heavy human interventions e g groundwater extractions and reservoir operations humphrey et al 2016 sun et al 2020 likewise bcnn clearly outperforms noah and era5l in all climate regions for example the median nse values of noah era5l and bcnn in the hyper arid region are 10 50 8 51 and 0 27 respectively table 1 fig 6 depicts bcnn s twsa predictions for three testing months in june 2014 june 2017 and june 2020 note that the grace data of the three months were not seen by bcnn during model training for comparison the reference grace twsa fields are also shown due to the bayesian nature of bcnn the predictive uncertainties can be quantified and are depicted as standard deviation in the plot it can be seen that bcnn successfully captures the spatial patterns of grace twsa and provides close predictions in the three months figs 6 a f the predictive errors and uncertainties in humid regions e g amazon central africa south asia and greenland are generally larger compared to other regions figs 6 g l which are mainly because of the relatively high signal variability in the humid regions the bcnn s twsa predictions for all of the 66 testing months are shown in the gif animation attached as supporting materials 4 2 evaluation of gap filling quality at the basin scale the results presented in section 4 1 indicate that bcnn is able to provide close predictions to the testing grace data in the pre and post gap periods to further validate that bcnn s infilling data are grace like and reliable two independent datasets namely the cpc climate prediction center soil moisture van den dool et al 2003 and noah simulated twsas rodell et al 2004 are used for verification at the basin scale more specifically we compare the basin averaged time series of these datasets as shown in section 4 1 and by scanlon et al 2019 the amplitude and magnitude differences of two time series may lead to poor consistency therefore these basin averaged time series are respectively standardized to make the data comparable 10 y y μ y σ y where μ y and σ y are the mean and standard deviation respectively of the time series for consistency the bcnn and grace twsa time series are both standardized using grace s μ y and σ y the grid scale nse values between the standardized grace twsas and soil moisture noah twsas during the testing periods indicate that they agree relatively well in most regions fig 7 particularly after excluding the influence of amplitude and magnitude differences by standardization the consistency between noah and grace is significantly improved see figs 4d and 7b the idea behind the validation is suppose that the standardized time series of soil moisture noah twsa agree well with that of grace twsa in the pre and post gap testing periods the gap filling results can be thought to be reliable if the bcnn twsa time series fit well with those of soil moisture noah twsa during the testing and gap periods the basin averaged standardized time series of the grace twsa bcnn twsa cpc soil moisture noah twsa for 40 major river basins see fig 8 for the basin locations are compared in fig 9 with the nse values between them being summarized in table 2 these plots manifest that bcnn twsas show favorable consistency with grace twsas during the testing periods in the 40 basins the nse values between them are generally larger than 0 7 with the exception of indus nse 0 67 orange nse 0 44 pearl nse 0 67 and yellow nse 0 63 river basins the mismatch in these basins is probably because of the insufficient quality and or ability of driving data to capture the impacts of anthropogenic activities on water cycle it is worthy noting that although bcnn may slightly underestimate overestimate grace twsas the grace curves are almost completely enveloped within bcnn s 95 prediction interval calculated using an ensemble of n s 20 bcnn predictions section 3 1 additionally the standardized time series of soil moisture and noah twsa agree relatively well with those of grace twsa in most basins during the grace covered periods as also indicated by the nse values listed in table 2 therefore the good consistency between bcnn twsas and soil moisture noah twsas in these basins suggests the reliability of bcnn s gap filling results for the remaining few basins with the nse values between the grace bcnn twsa and soil moisture noah twsa time series all less than 0 4 marked in bold in table 2 it is found that all of these basins have declining grace twsa trends while the precipitation exhibits oppositely rising trends an exception is the hai river basin but the twsa time series are more significantly declining the decreased water storage in these basins are mainly resulted from glacier retreating yukon river basin or groundwater depletion hai indus and yellow river basins rodell et al 2018 the inability of soil moisture and noah to reflect the twsa declines induced by glacier retreating and groundwater depletion leads to the poor consistency despite this bcnn s close predictions to grace twsas in the pre and post gap periods still suggest the reliability of gap filling results figs 9 k l z i l for the gap filling purpose one can also simply bridge the gap with the long term trend and seasonal signals derived from the available grace observations i e twsa grace t s trend grace season grace fig 10 depicts the basin averaged time series of the original without standardizing grace twsa bcnn twsa and twsa grace t s for the 40 river basins it is observed that bcnn achieves a better consistency higher nse values with grace than twsa grace t s in all basins fig 11 displays the nse field between grace twsa and twsa grace t s the regions with high nse values are as expected generally the seasonal component dominant regions see fig 9 in humphrey et al 2016 for the spatial distribution of seasonal component dominant regions one popular use of the twsa data is to estimate the long term trend of water storage chen et al 2014 feng et al 2013 feng et al 2018 scanlon et al 2018 tapley et al 2019 here we investigate the impact of the 11 month gap on the long term april 2002 august 2020 trend estimation the trend field after the gap is filled with bcnn predicted twsas is illustrated in fig 12 the difference between the trends before and after gap filling is also shown which can be as large as 0 2 cm year in many regions taking the amazon river basin the area is over 6 10 6 km2 as an example a bias of 0 2 cm year in the trend estimate would lead to a deviation of over 12 gt year in the water storage loss gain estimate the differences in trend estimates may be partially caused by dry or wet climate conditions during the gap period as they usually lead to decreased or increased twsa signals respectively to examine this the 6 month standardized precipitation evapotranspiration index spei 6 available at https spei csic es spei database fields during the gap period are plotted in fig 13 it is observed that the trend difference patterns fig 12b are spatially similar to the wet dry patterns in the spei 6 fields indicating that the overestimation underestimation of the original long term trends is mainly related to the the dry wet conditions during the gap period bcnn reproduces the dry wet condition induced abnormal twsa signals from hydroclimatic inputs and thus contributes to improving the trend estimation it should be mentioned that for the extremely dry wet conditions caused by climate extremes bcnn s generalization on such extreme induced abnormal signals may be limited due to the well known long tail distribution issue in deep learning the extremes are associated with only a few samples because of their rare occurrence menon et al 2021 integrating the long tailed learning menon et al 2021 with bcnn may be a better solution 4 3 comparison with swarm solution in this section we conduct a comparison between bcnn and swarm derived twsas to illustrate the merits of bcnn in providing more reliable gap filling products the swarm satellite provides the observations of twsas since december 2013 but at much lower resolution relative to grace friis christensen et al 2008 the data quality is not stable in early years but expected to increase as the mission progresses da encarnação et al 2016 the monthly swarm level 2 gravity field model provided by the astronomical institute at the czech academy of sciences asu bezděk et al 2016 in terms of spherical harmonic coefficients up to degree and order 40 is used to estimate global twsas to reduce the high magnitude noise in the swarm solution we apply a 1000 km gaussian filter to smooth the data fields considering the low resolution of swarm data we make a basin scale comparison for only 15 world s major river basins the time series of twsas from grace swarm and bcnn during april 2014 and december 2019 are compared in fig 14 the nse values of swarm and bcnn twsas with the reference grace twsas are also attached in each subplot the figure manifests that although the swarm twsas can generally capture the variability patterns of grace twsas the differences in their amplitudes lead to relatively large deviations in many basins e g amur murray yangtze on the contrary bcnn twsas fit appreciably better with those of grace with much higher nses suggesting bcnn s higher reliability in bridging the grace and grace fo gap 4 4 comparison with previous studies here we restrict the comparison with humphrey and gudmundsson 2019 sun et al 2020 and li et al 2021 who provided publicly accessible global scale twsa prediction products the predicted twsa product by humphrey and gudmundsson 2019 is known as grace rec the original grace rec dataset provides the detrended and deseasonalized twsas we add the trend and seasonal signals obtained from the grace twsas and humphrey et al 2017 respectively to the original grace rec twsas for consistency the twsa product generated in sun et al 2020 with a deep fully connected neural network is used here for comparison the spatial resolution of predicted twsas in humphrey and gudmundsson 2019 and li et al 2021 is 0 5 0 5 for consistency we predict the twsas at the same resolution and thus the input output image size of bcnn is h w 288 720 for a fair comparison the grace twsa data and the training periods used for bcnn network training are respectively the same as those employed in the three studies the detailed descriptions of the three twsa products are summarized in table 3 the comparison results are shown in fig 15 for simplicity we show in the plot only the nse metric as it measures directly the matching quality in terms of both magnitude and phase between the predicted and target time series in addition we also compare separately the performances in the hyper arid arid semi arid semi humid and humid regions in fig 16 which summarizes the boxplots of the gridded nse values in the five climate regions the medians of the boxplots are listed in tables 4 figs 15 and 16 clearly suggest bcnn s better performance relative to the three previous methods humphrey and gudmundsson 2019 li et al 2021 sun et al 2020 which obtain relatively high accuracy in the humid semi humid regions but their performances decrease in the hyper arid arid semi arid regions our bcnn method successfully improves the prediction accuracy in these hyper arid arid semi arid regions to a relatively high level for instance compared to humphrey and gudmundsson 2019 our bcnn improves the median nse values in the hyper arid arid and semi arid regions from 0 41 0 01 and 0 39 respectively to 0 17 0 57 and 0 69 table 4 the results suggest bcnn s superior performance in providing improved twsa predictions to bridge the grace and grace fo gap which is attributed jointly to the use of grace trend section 2 3 and bcnn s outstanding capability in learning the high dimensional and highly complex mappings between the twsa and hydroclimatic inputs two additional noteworthy merits of bcnn compared to prior methods are the few assumptions preprocessing involved and its ability to handle directly the global scale note that we set in bcnn for simplicity all inputs and outputs to the same spatial resolution and consider only the land components it is flexible and straightforward for bcnn to handle inputs outputs with different sizes and ocean components e g sea surface temperature this property benefits from the flexibility of cnn in architecture design and performing downsampling upsampling concatenation and many other operations 5 conclusions in this study we propose a deep learning based bcnn method driven by era5l hydroclimatic data to fill the one year twsa observation gap between the grace and grace fo satellites at the global scale the integration of residual skip connections spatial channel attentions and bayesian training strategy in bcnn enables it to effectively extract informative features for twsa predictions from multiple predictor data and quantify the predictive uncertainties results show that bcnn successfully captures twsa s complex spatiotemporal patterns the comparisons with reanalyzed simulated twsa products swarm solution and three previous studies further suggest bcnn s clearly higher gap filling performance particularly in the relatively arid regions the gap filling quality in maintaining the data continuity is further validated and confirmed through comparison with the standardized cpc soil moisture and noah simulated twsa at the basin scale the improvements in restoring the missing twsa signals can be of great significance for applications desiring continuous data records in the time series analysis correcting the bias in long term trend estimates due to missing data and enhancing the reliability of hydrological model predictions the outperformance of bcnn is mainly attributed to the use of twsa trends which are derived from the available grace fo data in the pre and post gap periods and its outstanding performance in feature extraction the long term twsa trends induced by anthropogenic and or natural factors are usually challenging to learn humphrey and gudmundsson 2019 li et al 2020 sun et al 2020 the utilization of this trend information makes full use of the existing data and essentially eases the learning task for bcnn the bcnn s capability for informative feature extraction inherits the outstanding performance of cnn in image processing which is further enhanced by integrating recent advances in deep learning note that we are concerned with bridging the gap between grace and grace fo in the current work for the task reconstructing twsas in the pre grace period which is beyond the scope of this study the trend information is unavailable the performance of bcnn for such a task remains to be explored credit authorship contribution statement shaoxing mo conceptualization methodology investigation formal analysis validation writing original draft ehsan forootan data curation validation writing review editing nooshin mehrnegar data curation writing review editing xin yin data curation writing review editing jichun wu supervision funding acquisition writing review editing wei feng supervision data curation validation writing review editing xiaoqing shi supervision funding acquisition writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the jpl and csr grace mascon data used in this study are available at https podaac jpl nasa gov dataset tellus grac grfo mascon cri grid rl06 v2 and http www2 csr utexas edu grace rl06 mascons html respectively era5 land data are available at https doi org 10 24381 cds 68d2bb30 noah twsa dataset is downloaded from https disc gsfc nasa gov datasets gldas noah10 m 2 1 summary we thank dr vincent humphrey dr zhangli sun and dr fupeng li for sharing their twsa prediction products this work was funded by the national natural science foundation of china 41730856 41874095 41977157 42002248 42004073 china postdoctoral science foundation 2020m681550 jiangsu planned projects for postdoctoral research funds 2020z133 and fundamental research funds for the central universities 020614380106 s mo thanks dr yinhao zhu from qualcomm ai research for his valuable suggestions on bcnn we are also grateful to the editor associate editor and three anonymous reviewers for their constructive comments the predicted twsa dataset generated in this work is available at https doi org 10 5281 zenodo 4589755 
3807,accurately estimating the reference evapotranspiration et0 is a basic requirement for precision irrigation and the correct planning of regional water resources this study aimed to investigate the spatiotemporal variations in et0 in china and to improve the accuracy of et0 calculations on different spatiotemporal scales meteorological data collected at 100 stations in china during 1961 to 2019 were used to calculate et0 with the penman monteith model and the temporal and spatial patterns in et0 pm were analyzed with the mann kendall nonparametric trend test method three machine learning models comprising convolutional neural network cnn extreme learning machine elm and multiple adaptive regression splines mars and seven empirical models calibrated with mind evolutionary algorithm mea were compared to assess their suitability for calculating et0 on different spatiotemporal scales in china the results showed that the annual mean et0 pm value 413 29 2772 35 mm in china gradually increased from north to south and from west to east et0 exhibited an upward trend in the temperate continental zone tcz and mountain plateau zone mpz but a downward trend in the temperate monsoon zone tmz and subtropical monsoon region smz by comparing the global performance indicators gpi the machine learning models generally performed better than the empirical models at different spatiotemporal scales and cnn was the best model for calculating et0 in terms of the model accuracy and stability on the daily scale mars performed well in mpz whereas elm performed well in tmz and tcz on the monthly scale mars performed well in tmz whereas elm performed well in smz and mpz at the annual scale the accuracy of elm was higher than that of mars keywords et0 convolutional neural network extreme learning machine multiple adaptive regression splines 1 introduction more than 90 of the water applied in agricultural ecosystems is lost through evapotranspiration et shan et al 2020 wang et al 2019 therefore accurate et predictions are very important for the planning and design of irrigation and improving the efficient utilization of water resources bellido jiménez et al 2020 feng et al 2016 et involves two processes comprising evaporation from soil and plant surfaces and transpiration from crops into the atmosphere chen et al 2020b the et process is an essential part of the energy cycle and land atmosphere water cycle hadria et al 2021 the main methods used to measure et include the vorticity correlation method isotope tracer method liquid flow method and lysimeter method however these methods are time consuming laborious costly and challenging to implement in a large area jiang et al 2016 therefore various et calculation models have been developed the reference evapotranspiration et0 is a basic requirement for these models shan et al 2020 and it is essential to calculate et0 accurately and rapidly in 1998 the penman monteith pm equation was adopted by the food and agriculture organization fao of the united nations as the only standard for calculating et0 fan et al 2018 feng et al 2017 the pm equation is based on the theory of energy balance and water vapor diffusion where it considers both the physiological characteristics of crops and variations in aerodynamic parameters chen et al 2020b the accuracy of the pm equation is high but comprehensive meteorological data are required almorox et al 2015 ferreira et al 2019 it is difficult to use the pm equation to calculate et0 in some poor and remote areas due to the lack of meteorological stations or meteorological data records tabari et al 2012 due to the limitations described above empirical models have been investigated that require fewer input parameters to calculate et0 these empirical models can be divided into 1 combination models 2 radiation based models 3 temperature based models 4 humidity based models 5 water budget based models 6 mass transfer based models and 7 pan based models chen et al 2020b among these empirical models the most commonly used are combination radiation based and temperature based models and many studies have employed these models hadria et al 2021 todorovic et al 2013 valipour et al 2017 zheng et al 2017 in particular yang et al 2021 calculated et0 with eighteen different empirical models in the climatic regions of china and they concluded that the combination models performed the best followed by the radiation based models whereas the temperature based models obtained the worst performance feng et al 2016 compared the accuracy of two temperature based models and three radiation based models for calculating et0 in southwest china and they concluded that the radiation based models were superior to the temperature based models mehdizadeh et al 2017 used sixteen empirical models to calculate the monthly mean et0 and concluded that the hargreaves samani and romanenko models performed best recently machine learning methods have been used for et0 calculations due to the development of 5g connection technology and the widespread use of automatic weather stations bellido jiménez et al 2020 research into machine learning can be traced back to the 1950 s and it has developed from classical machine learning to deep learning various machine learning models have been used for calculating et0 where the classical machine learning models include multiple adaptive regression splines mars support vector regression svr extreme learning machine elm and multilayer perceptron mlp bellido jiménez et al 2020 fan et al 2018 feng et al 2017 ferreira et al 2019 mehdizadeh et al 2017 fan et al 2018 calculated et0 using support vector machine svm elm and four tree based ensemble models in different climate zones in china and they found that extreme gradient boosting xgboost and gradient boosting decision tree gbdt models performed best yu et al 2020 used artificial neural network svr and elm models to calculate et0 in northwest china and concluded that svr and elm obtained the best performance feng et al 2016 used elm generalized regression neural network grnn wavelet neural networks wnn models to calculate et0 in southwest china and concluded that elm and grnn performed much better than wnn bellido jiménez et al 2020 calculated et0 in southern spain using mlp grnn elm svm random forest rf and xgboost models and concluded that elm obtained the best performance in this century deep learning models have developed rapidly mainly for applications in computer vision speech analysis and natural language processing chen et al 2020a lara hernandez et al 2020 lucas et al 2020 deep learning models mainly extract the external input data layer by layer learn the complex features from the data through a nonlinear activation function and finally complete the training and prediction tasks for the multi layer neural network deep learning models include convolutional neural network cnn deep neural network dnn long short term memory neural network lstm and temporal convolution neural network tcn models saggi and jain 2019 yin et al 2020 aslam et al 2020 used a deep learning model based on mlp for year ahead solar radiation forecasting and concluded that the deep learning model performed better than other models atila et al 2021 applied the efficientnet deep learning model for plant leaf disease classification and concluded that the b5 and b4 models in the efficientnet architecture performed better than other deep learning models however few studies have investigated the application of deep learning to et0 computation chen et al 2020b compared empirical models svm rf dnn tcn and lstm models for calculating the daily et0 in the northeast plain region of china and concluded that lstm dnn and tcn performed better than the other models china covers a vast area and the climate varies greatly previous studies of et0 estimation mainly focused on a particular time scale in local regions china instead of considering different spatiotemporal scales machine learning has been used for et0 calculation because it can deal with nonlinear relationships and it has high accuracy and stability classical machine learning models have been used for calculating et0 but few deep learning models have been developed thus the present study employed daily meteorological data from 100 national meteorological stations in china between 1961 and 2019 to test the following methods 1 the fao 56 penman monteith pm method was used to calculate et0 pm in china from 1961 to 2019 where the temporal and spatial patterns in et0 pm were determined with the mann kendall nonparametric trend test method 2 the parameters of seven empirical models were determined using the mind evolutionary algorithm mea and the suitable ranges of the parameter values for china were obtained and 3 the accuracy and stability of et0 calculations using cnn elm mars and seven empirical models in different climate zones of china were compared on daily monthly and yearly scale 2 materials and methods 2 1 study area china is located in the east of asia and the pacific ocean lies to its east according to differences in the temperature rainfall and altitude china can be divided into mountain plateau zone mpz subtropical monsoon zone smz temperate continental zone tcz and temperate monsoon zone tmz fig 1 song et al 2011 tcz denotes an arid region with an average altitude of 912 m and average annual rainfall of 269 mm mpz denotes a semiarid area with average annual rainfall of 382 mm and an average altitude of 4236 m tmz denotes a semi humid area with average annual rainfall of 585 mm and an average altitude of 288 m smz denotes a humid region with an average altitude of 611 m and average annual rainfall of 1320 mm 2 2 data the meteorological data provided by the china national meteorological scientific data sharing network http data cma cn comprised precipitation p average temperature tmean maximum temperature tmax minimum temperature tmin wind speed u2 sunshine hours n and average relative humidity rh measurement collected from one hundred stations throughout the country between 1961 and 2019 sixteen sites were distributed in mpz twenty five in smz twenty seven in tcz and thirty two in tmz fig 1 and appendix a the selection criteria for the stations were as follows 1 meteorological stations were selected with less than ninety days of missing data and less than seven days of continuously missing data 2 missing daily meteorological elements were recorded as the lack of measurement of et0 in that month and 3 missing data were interpolated based on the regression relationships with those of the adjacent stations or replaced by averages from other years at the same station the meteorological data from 1961 to 2019 were equally divided into five parts by k fold cross validation method table 1 four stages were selected to train the machine learning models and the remaining one was used for verification five different rounds of pieces of training and tests were conducted and the values of the five trials were finally averaged as the final evaluation index of the model the inverse distance weighted idw interpolation method is used to interpret the spatial distribution of et0 based on each stations the multi year average of et0 during 1961 2019 are interpolated to show the spatial distribution 2 3 fao 56 pm method in 1998 the fao recommended the pm method as the standard method for et0 calculation allen et al 1998 because of its suitability for different climatic regions bellido jiménez et al 2020 in the present study the et0 value calculated using this method was treated as the standard value et0 was calculated as follows 1 e t 0 0 408 δ r n g γ 900 273 t mean u 2 e s e a δ γ 1 0 34 u 2 where et0 is the reference evapotranspiration mm day 1 rn is the net radiation mj m 2 day 1 g is the soil heat flux mj m 2 day 1 u2 is the wind speed at a height of 2 m m s 1 tmean is the mean air temperature c es and ea are the saturation and actual vapor pressures respectively kpa δ is the slope of the saturation vapor pressure curve kpa c 1 and γ is the psychrometric constant kpa c 1 allen et al 1998 2 4 empirical models seven empirical models were tested in this study with two types of combination three radiation based and two temperature based empirical models the formulae used for calculating the specific empirical models are shown in table 2 2 5 machine learning models three types of machine learning methods were used to calculate et0 the input parameters are shown in table 3 for the combination radiation based and temperature based styles 2 5 1 cnn cnn was developed by lecun et al 1998 as a feedforward neural network and deep neural network by combining a two dimensional discrete convolution operation and artificial neural networks cnns are employed for automatic extraction where a cnn comprises an input layer hidden layer tile layer full connection layer and output layer the hidden layer comprises a convolution layer pooling layer and activation layer there are usually five or more hidden layers at the convolution layer in this study the number of convolution kernels was 100 and the size of the convolution kernels was 3 3 the stride was 1 the padding was set to same and the activation function used was relu the pooling layer is in the mode of average pooling and the stride was 5 the number of neurons in the full connection layer was 200 the number of training epochs was defined using early stopping with maximum training epochs equal to 150 and patience equal to 10 epochs the learning rate was 0 001 and batch size was 512 cnn model could be built by the pytorch package which is in python 3 6 software the following formula can express the convolution process 9 c f x w b where c is the output of the convolution layer x denotes the input data f is the nonlinear activation function is the convolution operation w is the weight vector of the convolution kernel and b is the bias term 2 5 2 elm elm was developed as a feedforward neural network model by huang et al 2006 for solving single hidden layer neural networks elm comprises an input layer hidden layer and output layer elm is faster and more accurate compared with a single hidden layer feedforward neural network elm can also randomly initialize the input weight and bias and obtain the corresponding output weight in different climate regions of china the number of hidden nodes for elm is different in smz and tcz 40 hidden nodes have been proved efficient to estimate et0 in mpz and tmz the number of hidden nodes is 50 the software packages can be downloaded from http www ntu edu sg home egbhuang the simplified expression for the elm neural network is 10 f n χ i 1 n β i g α i χ i b i y i i 1 2 n where xi is the input layer yi is the output layer αi is the input weight bi is the threshold and βi is the output weight 2 5 3 mars the mars data analysis method proposed by friedman in 1991 shan et al 2020 takes the tensor product of spline functions as the basis function and it can be divided into forward and backward processes the advantage of mars is that it can deal with large amounts and high dimensions in rapid and accurate calculations in the forward process all of the dependent and independent variables are added to the model and scanned before the basis functions are constructed and then paired into the model finally a model is built using all of the basic functions as an overfitting model the backward process involves pruning the model the initially generated basis functions may contribute little or nothing to the final model so the mars backward process deletes the basis functions that have little influence on the accuracy in this study the maximum number of basis functions is 40 the interaction degree is 2 and the penalty factor is 3 the software packages can be downloaded from http www cs rtu lv jekabsons the mathematical model of mars is expressed as follows 11 y i a 0 m 1 m a m k 1 k m s km x v k m t m where k 1 k m s km x v k m t m denotes the basis function a0 and am are the two parameters of the function m is the number of basis functions km is the number of divisions of the m basis function the value of skm is either 1 or 1 and it indicates the direction of the step function v k m represents the risk factors and tm represents the threshold of each basis function 2 6 mann kendall nonparametric trend test the mann kendall nonparametric trend test does not assume that the data follow a normal distribution and it is widely used in time series trend analysis the definition of the mann kendall s test statistics is as follows 12 z s 1 v a r s if s 0 0 if s 0 s 1 v a r s if s 0 13 s i 1 n 1 k i 1 n sgn x k x i where xk and xi are random variables used for hypothesis testing and n is the total length when x k x i is greater than equal to or less than zero the s values are 1 0 and 1 respectively when z greater than 1 96 p 0 05 the sequence trend is considered significant but not otherwise hamed and ramachandra rao 1998 2 7 mea mea is an evolutionary algorithm derived from the genetic algorithm and it is similar to the human thinking evolutionary process two new operations comprising convergence and dissimilation are proposed based on preserving the genetic algorithm the convergence and dissimilation operations allow the predicted value and expected value to gradually converge by continuous iteration the initial population is generated using a combination of the data in the training set and test set the winning sub population and temporary sub population are generated according to the initial score for the population moreover the whole population s maturity is assessed and the optimal individuals are produced by the convergence and dissimilation operations the parameters of the seven empirical models calibrated by mea are shown in table 4 2 8 performance evaluations for models the following five indicators were used to evaluate the accuracy of the models 1 mean absolute error mae 14 mae 1 n i 1 n y i x i 2 nash sutcliffe efficiency nse 15 nse 1 i 1 n y i x i 2 i 1 n x i x i 2 3 coefficient of determination r2 16 r 2 i 1 n y i y i x i x i 2 i 1 n y i y i 2 i 1 n x i x i 2 4 root mean square error rmse 17 rmse 1 n i 1 n y i x i 2 the four indicators given above cannot be used to comprehensively evaluate a model so the global performance indicator gpi feng et al 2020a was employed as a comprehensive indicator based on mae nse r2 and rmse in order to objectively evaluate the accuracy of the models gpi is defined as follows 5 global performance indicator gpi 18 gpi i 1 4 α i t i t i where xi and yi represent the reference value and simulated value respectively x and y represent averages n is the number of samples in the verification set ti is the normalized value of rmse mae r2 and nse t i is the median of the corresponding indexes and αi is 1 when ti is rmse and mae but 1 in other cases 3 results 3 1 spatiotemporal variation of et0 pm in china fig 2 shows that the average annual range of variation for et0 pm in china between 1961 and 2019 was 413 29 mm to 2772 35 mm and the trend generally increased from north to south and from west to east the mann kendall trend analysis results for et0 pm based on 100 meteorological stations in china between 1961 and 2019 showed that ten stations exhibited significant upward trends in tcz nine had significant downward trends six had upward trends and two had downward trends in general et0 pm exhibited an upward trend in tcz p 0 05 in mpz six stations had significant upward trends four had significant downward trends five had upward trends and one had a downward trend in general et0 pm exhibited an upward trend in mpz p 0 05 in tmz six stations had significant upward trends seven had significant downward trends eight had upward trends and eleven had downward trends in general et0 pm exhibited a downward trend in tmz p 0 05 in smz four stations had significant upward trends ten had significant downward trends four had upward trends and seven had downward trends in general et0 pm exhibited a downward trend in smz p 0 05 3 2 calibration of empirical models using mea fig 3 compares the results obtained before and after calibrating the parameters of the seven empirical models where the accuracy of the et0 estimations produced by the empirical models improved after parameter optimization with mea the r2 and nse values increased for each model whereas the rmse and mae values decreased in particular the most obvious changes were obtained with pm 1992 and harg with pm 1992 r2 and nse increased by 0 25 and 1 15 respectively and rmse and mae decreased by 2 31 mm day 1 and 2 10 mm day 1 with harg r2 and nse increased by 0 22 and 1 11 respectively and rmse and mae decreased by 2 13 mm day 1 and 1 88 mm day 1 3 3 analysis of the suitability of machine learning models and empirical models at the daily scale in china fig 4 shows the daily gpi rankings for the smz mpz tmz and tcz of china bluer colors indicate better model performance and higher rankings redder colors indicate worse model performance and lower rankings the results demonstrated that the machine learning models ranked higher overall than the empirical models in the four region types the r2 rmse mae and nse values for the machine learning models are shown in table 5 fig 5 shows the specific daily gpi indexes for the cnn elm and mars models in the four region types in china according to the median gpi index in smz when the input parameters were combination radiation based and temperature based the gpi index for cnn 1 was 0 26 higher than those for both mars 1 and elm 1 that for cnn 2 was 0 47 and 0 45 higher than those for elm 2 and mars 2 respectively and that for cnn 3 was 0 22 and 0 68 higher than those for elm 3 and mars 3 therefore the accuracies of the models were ranked as follows cnn 1 elm 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 mars 3 according to the gpi ranges and areas of the violin plots the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 mars 3 therefore cnn obtained the best performance in terms of its accuracy and stability and elm had higher stability than mars in mpz fig 5 the gpi index for cnn 1 was 0 52 and 0 36 higher than those for elm 1 and mars 1 respectively that for cnn 2 was 0 32 and 0 26 higher than those for elm 2 and mars 2 and that for cnn 3 was 0 15 higher than those for both elm 3 and mars 3 therefore the accuracies of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 elm 3 mars 3 according to the gpi ranges and areas of the violin plots the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 mars 3 elm 3 therefore cnn was better than mars in terms of its accuracy and stability and mars was better than elm in tmz fig 5 the gpi index for cnn 1 was 0 12 and 0 14 higher than those for elm 1 and mars 1 respectively that for cnn 2 was 0 22 and 0 73 higher than those for elm 2 and mars 2 and that for cnn 3 was 0 12 and 0 68 higher than those for elm 3 and mars 3 therefore the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 according to the gpi ranges and areas of the violin plots the stabilities of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 therefore cnn was superior to elm in terms of the model accuracy and stability and elm was superior to mars in tcz fig 5 the gpi index for cnn 1 was 0 13 and 0 14 higher than those for elm 1 and mars 1 respectively that for cnn 2 was 0 44 and 0 80 higher than those for elm 2 and mars 2 and that for cnn 3 was 0 12 and 0 37 higher than those for elm 3 and mars 3 therefore the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 according to the gpi ranges and areas of the violin plots the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 mars 3 elm 3 therefore cnn was better than elm in terms of the model accuracy and stability and elm was superior to mars therefore the results showed that cnn performed better than mars and elm on the national daily scale mars performed better in mpz and elm performed better in tmz and tcz in addition according to the median and gpi ranges for the same types of machine learning methods shown in fig 5 as well as the areas of the violin plots the stability and precision of the cnn elm and mars models in the four region types in china decreased to some extent as the number of input parameters decreased 3 4 analysis of the suitability of machine learning models and empirical models at the monthly scale in china fig 6 shows the monthly gpi rankings for the smz mpz tmz and tcz region types in china where the overall rankings of the cnn elm and mars models were higher than those of the empirical models the r2 rmse mae and nse values for machine learning models are shown in table 5 fig 7 shows the gpi indexes for the three machine learning models in the four region types in china the analysis method was the same as that used for the daily scale in smz the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 mars 3 elm 3 the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 mars 3 therefore cnn performed better than elm in terms of the model accuracy and stability and elm was better than mars in mpz the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 mars 3 elm 3 therefore cnn performed better than elm in terms of the model accuracy and stability and elm was better than mars in tmz the accuracies and stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 mars 3 elm 3 therefore cnn performed better than mars in terms of the model accuracy and stability and mars was better than elm in tcz the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 mars 3 the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 mars 3 elm 3 therefore cnn performed better than elm and mars in terms of the model accuracy and stability elm performed better than mars in terms of accuracy and mars performed better than elm in terms of stability in summary cnn was superior to elm and mars on the monthly scale in china elm performed better in smz and mpz and mars performed better in tmz in addition as the number of input parameters decreased the stability and precision of the cnn elm and mars models all decreased to some extent in terms of the gpi size and range for the same model as well as the areas of the violin plots 3 5 analysis of the suitability of machine learning models and empirical models at the annual scale in china fig 8 shows the annual gpi rankings for the smz mpz tmz and tcz region types in china the results demonstrated that the overall rankings of the machine learning models were higher than those of the empirical models the r2 rmse mae and nse values for machine learning models are shown in table 5 fig 9 shows the specific gpi indexes for cnn elm and mars models in the four region types in china on an annual scale in smz the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 the stabilities of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 thus cnn performed better than elm and elm was better than mars in mpz the accuracies and stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 thus cnn performed better than elm and elm was better than mars in tmz the accuracies of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 the stabilities of the models were ranked as follows cnn 1 elm 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 thus cnn performed better than elm and elm was better than mars in tcz the accuracies and stabilities of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 thus cnn performed better than elm and elm was better than mars in summary cnn performed better than elm in terms of the model accuracy and stability at the national annual scale and elm was better than mars in addition as the number of input parameters decreased the stability and precision of the cnn elm and mars models all decreased to some extent 4 discussion 4 1 implications of spatiotemporal variation of et0 in hydrology agriculture meteorology and other fields et0 is one of the significant indicators to measure atmospheric evapotranspiration capacity estimate crop water demand and production potential and also plays an important role in surface energy and water balance therefore the study of spatiotemporal variation characteristics of et0 in china is crucial for improving grain yield predicting extreme climate and rational utilization of water resources zhao et al 2020 studied the variation characteristics of et0 in ningxia from 1957 to 2018 and found that the et0 showed a significant upward trend on an annual scale this is consistent with the results of this study in tcz wang et al 2017 studied the spatiotemporal changes of et0 in china during 1961 2013 and concluded that et0 in the qinghai tibet plateau region presented an upward trend which is similar to the results of this study in mpz fan et al 2016 studied the variation of et0 in different climate zones in china during 1956 2015 and concluded that et0 showed a downward trend in smz and tmz which is consistent with the results of this study et0 showed different trends in various climatic zones of china during 1961 2019 in arid areas of china et0 showed an increasing trend which might lead to the need for more water in crop growth therefore in the critical period of crop growth increasing irrigation amount to a certain extent can improve yield fan et al 2016 on the contrary et0 showed a decreasing trend in humid areas and irrigation amount could be reduced appropriately in conclusion understanding the spatiotemporal variation characteristics of et0 is of great significance for agricultural water management 4 2 evaluation of suitability of machine learning models and empirical models for et0 computation at different spatial and temporal scales previous studies of et0 calculation models mainly focused on specific temporal or spatial scales feng et al 2017 ferreira et al 2019 hossein kazemi et al 2020 in particular valipour et al 2017 calculated et0 based on 50 years of monthly meteorological data in iran they compared five temperature based models five radiation based models and five mass transfer based models in different climate regions and concluded that modified hargreaves samani performed best in arid and semiarid regions and radiation based and mass transfer based models performed best in warm and cold regions feng et al 2016 considered yearly monthly and daily scales and used three machine learning methods elm back propagation neural networks optimized by genetic algorithm gann and wnn two temperature based models hargreaves and modified hargreaves and three radiation based models makkink priestley taylor and ritchie to calculate et0 in southwest china and they concluded that the elm and gann models were the most accurate fan et al 2018 compared the accuracy of the et0 calculations obtained by svm elm and four tree based ensemble models in different climate regions of china on a daily scale and they concluded that the xgboost and gbdt models were the most accurate the present study compared the accuracy of seven empirical models and three machine learning models at calculating et0 on different temporal and spatial scales throughout china the results showed that the deep learning models represented by cnn were much more accurate and stable than other empirical models and classical machine learning models on different time scales and similar findings were obtained by chen et al 2020b further analysis on a daily basis showed that mars performed better in mpz regions whereas elm performed better in tmz and tcz regions on a monthly scale elm performed better in mpz and smz regions whereas mars performs better in tmz regions the applicability of different spatial and temporal scale analysis models in calculating et0 is more comprehensive than that of a single spatial and temporal scale 4 3 advantages and disadvantages of machine learning models and empirical models for calculating et0 the most common empirical models for estimating et0 are temperature based radiation based and combination models thornthwaite 1948 first proposed a temperature based model for estimating et0 and many temperature based models have been developed subsequently in particular the hargreaves method is used widely throughout the world because it employs simple meteorological data as inputs and it can obtain highly accurate results allen et al 1998 radiation based models were proposed based on the relationship between radiation and et0 priestley and taylor 1972 proposed a formula for calculating et0 and it is the most widely used radiation based model various types of combination models have been proposed for calculating et0 based on the pm equation and by considering different actual situations however the pm equation is still the most widely used model and it is the most accurate therefore the united nations fao adopted the pm equation as the standard for calculating et0 in 1998 machine learning was proposed in 1950 by turing in 2012 alexnet won the imagenet ilsvrc 2012 competition and its classification accuracy was nearly 11 higher than that of the method ranked in second place the development of machine learning has progressed from classical machine learning to deep learning in addition the deep learning models represented by cnn have made many important achievements in various tasks such as computer vision speech analysis and natural language processing however few studies have investigated the calculation of et0 with deep learning which was investigated in the present study the present study compared the accuracy of et0 calculation in different region types in china using two temperature based models three radiation based models and two combination models which were calibrated with mea as well as three machine learning models the results demonstrated that the machine learning models performed better than the empirical models the machine learning models performed well in terms of their accuracy and stability but they were prone to overfitting and required a large amount of data for training in the early stage thus the accuracy of these models was not high with a small amount of data and insufficient preliminary training moreover machine learning involves a type of black box model which is a general term for a class of algorithms these algorithms aim to mine hidden patterns from large amounts of historical data and use them for prediction or classification however the theoretical basis for calculating et0 cannot be explained based on the mechanism by contrast the empirical models are mathematical models based on rigorous assumptions regarding aerodynamics and the energy balance moreover the empirical models do not require prior training so they are more suitable for calculating samples with small amounts of data however the high accuracy of the empirical models can only be maintained with more input parameters and the precision of the model will decrease significantly when the number of input parameters is reduced by contrast machine learning models can obtain accurate results with few input parameters moreover the parameters must be calibrated according to the localization when calculating et0 using empirical models or the calculated et0 value is meaningless 4 4 advantages of deep learning models with the development of computer technology machine learning methods have been widely applied in various fields fan et al 2021 gong et al 2021 feng et al 2020b used a new machine learning method hybrid particle swarm optimization and extreme learning machine pso elm to calculate the daily global solar radiation on the loess plateau of china and obtained the pso elm model with high accuracy however previous studies have rarely applied deep learning models for calculating et0 which was the focus of the present study the results obtained in this study showed that the accuracy of the deep learning model was significantly higher than those of the classical machine learning models thus deep learning models are highly suitable for et0 estimation compared with the classical machine learning models the structure of deep learning models is characterized by local connections and weight sharing local connections refers to the fact that only some of the neurons in the external layer network are connected with neurons in the deep layer and all neurons in the same layer share the same connection weight these two structural characteristics mean that the parameter scale is significantly reduced in a cnn and it can mine the inherent correlations among data to make the model more accurate the application of deep learning models to calculate et0 at different spatiotemporal scales is of great significance for estimating et0 in remote areas with incomplete meteorological data where it can obtain more accurate et0 with fewer meteorological parameters it plays an important role in understanding the regional water cycle and energy balance making regional water demand plans and water resource optimization decisions and evaluating crop water demand 5 conclusion this study analyzed the temporal and spatial variations in et0 pm in china between 1961 and 2019 based on the mann kendall method the suitability for et0 estimation was compared for cnn elm and mars machine learning models and seven empirical models improved with the mea the et0 estimation models were selected with the greatest suitability to different spatial and temporal scales in china the conclusions based on the results obtained in this study are as follows the average annual range of et0 pm in china between 1961 and 2019 was determined as 413 29 mm to 2772 35 mm and the trend generally increased from north to south and from west to east et0 pm exhibited an upward trend in tcz and mpz but a downward trend in tmz and smz the parameters of the seven empirical models were calibrated with mea and their accuracy improved greatly where the models with the most obvious changes were pm 1992 and harg the suitable parameters ranges were determined for the seven empirical models in china on a daily scale cnn was superior to mars and elm in terms of the model accuracy and stability mars performed better in mpz and elm performed better in tmz and tcz on a monthly scale cnn was better than elm and mars in terms of the model accuracy and stability elm performed better in smz and mpz whereas mars was better in tmz on an annual scale cnn was better than elm in terms of the model accuracy and stability and elm was better than mars moreover the accuracy and stability of the same type of machine learning model decreased when the number of input parameters was reduced on different time scales credit authorship contribution statement juan dong conceptualization methodology software writing original draft yuanjun zhu writing review editing funding acquisition project administration xiaoxu jia validation ming an shao supervision xiaoyang han writing review editing jiangbo qiao writing review editing chenyun bai data curation investigation xiaodi tang data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the strategy priority research program of chinese academy of sciences xdb40000000 and the natural science foundation of china 41530854 and 42007011 appendix a basic information about the 100 meteorological stations considered in this study station region latitude n longitude e altitude m u2 m s 1 n h tmean c tmax c tmin c rh p mm year 1 mohe tmz 53 0 122 5 439 1 4 2409 6 4 1 4 5 11 7 69 3 439 9 huma tmz 51 7 126 6 174 1 6 2548 9 0 9 5 9 7 1 66 0 457 8 tulihe tmz 50 5 121 7 733 1 6 2537 1 4 4 4 3 12 5 70 8 451 4 xiaorgou tmz 49 2 123 7 286 1 2 2655 1 0 1 8 3 7 4 66 2 508 1 sunwu tmz 49 4 127 4 235 1 9 2502 7 0 2 7 1 7 1 69 3 547 3 mingshui tmz 47 2 125 9 240 2 6 2639 6 2 9 8 4 2 2 63 7 504 2 suolun tmz 46 6 121 2 500 2 1 2832 5 2 7 10 3 4 0 56 7 465 8 jiamusi tmz 46 8 130 3 82 2 3 2443 9 3 6 9 5 2 1 66 5 539 0 qian an tmz 45 0 124 0 146 2 5 2753 3 5 5 11 5 0 1 59 4 414 4 shangzhi tmz 45 2 128 0 190 2 1 2458 8 3 1 9 8 2 9 72 2 654 7 yuzhong tmz 35 9 104 2 1874 1 3 2582 0 6 9 14 1 1 1 62 7 388 7 hequ tmz 39 4 111 2 1036 1 1 2668 7 8 4 16 1 1 9 55 7 411 9 taiyuan tmz 37 6 112 6 776 1 5 2513 0 10 2 17 2 4 3 58 3 441 8 yanchang tmz 36 6 110 1 805 1 0 2470 8 10 3 18 0 4 3 62 1 519 8 xifeng tmz 35 7 107 6 1421 1 8 2429 9 9 0 14 2 4 9 61 7 557 7 suifenhe tmz 44 4 131 2 568 2 4 2408 2 2 9 8 8 2 4 67 0 586 7 siping tmz 43 1 124 4 180 2 1 2657 4 6 7 12 5 1 4 63 8 620 5 dunhua tmz 43 4 128 2 525 2 0 2310 6 3 5 10 0 2 3 67 6 624 0 kaiyuan tmz 42 5 124 1 98 2 2 2569 5 7 1 13 3 1 5 65 2 673 8 shenyang tmz 41 7 123 5 49 2 1 2476 3 8 3 14 1 3 1 63 2 684 9 zhangjiakou tmz 40 8 114 9 773 2 0 2776 8 8 8 15 2 3 4 47 4 405 1 zunhua tmz 40 2 118 0 55 1 2 2603 3 11 3 17 6 5 7 58 0 707 5 dawa tmz 41 0 122 1 6 2 8 2693 5 9 3 14 1 5 1 65 6 629 2 tianjin tmz 39 1 117 1 4 1 9 2466 3 12 8 18 2 8 3 60 8 537 7 raoyang tmz 38 2 115 7 18 1 6 2624 7 12 6 19 0 7 4 63 8 509 0 dalian tmz 38 9 121 6 92 3 3 2693 2 11 0 14 6 7 9 64 6 614 7 chengshantou tmz 37 4 122 7 48 4 5 2467 7 11 5 14 2 9 3 74 1 708 1 shenxian tmz 36 2 115 6 38 2 1 2286 3 13 5 19 5 8 6 68 6 537 0 pingdu tmz 36 8 120 0 62 2 4 2593 9 12 4 18 1 7 6 68 8 636 9 wugong tmz 34 3 108 2 471 1 2 1897 9 13 4 19 0 8 8 70 9 600 6 kaifeng tmz 34 8 114 3 74 2 1 2088 4 14 6 20 1 10 0 66 4 618 0 pizhou tmz 34 4 118 0 26 1 7 2242 3 14 2 19 5 9 9 72 6 857 7 lenghu mpz 38 8 93 3 2770 2 9 3432 4 3 1 11 9 5 3 29 5 17 2 geermu mpz 36 4 94 9 2808 1 9 3061 6 5 4 13 1 1 1 32 2 45 0 dulan mpz 36 3 98 1 3189 1 9 3035 4 3 3 10 2 2 3 39 8 207 7 gonghe mpz 36 3 100 6 2835 1 4 2914 5 4 3 12 1 2 1 49 4 327 5 xining mpz 36 7 101 8 2295 1 1 2645 4 6 0 14 0 0 1 56 2 394 2 shiquan mpz 32 5 80 1 4279 2 0 3484 0 0 9 8 5 6 9 32 0 72 3 damxung mpz 30 5 91 1 4200 1 8 2885 1 1 9 10 0 4 8 53 4 474 8 tingri mpz 28 6 87 1 4300 1 9 3360 0 2 8 11 8 5 2 40 9 281 1 ulan moron mpz 34 2 92 4 4533 2 9 2883 3 3 7 4 6 10 7 52 9 295 9 ruoergai mpz 33 6 103 0 3441 1 7 2443 7 1 4 9 5 4 8 67 6 658 7 nangqian mpz 32 2 96 5 3644 1 2 2571 5 4 5 12 8 1 9 53 0 538 7 changdu mpz 31 2 97 2 3315 0 9 2391 0 7 8 16 8 0 9 50 2 482 1 garzê mpz 31 6 100 0 3394 1 4 2594 3 5 9 14 3 0 3 56 0 653 2 litang mpz 30 0 100 3 3949 1 4 2669 9 3 5 11 3 2 3 56 1 733 3 linzhi mpz 29 7 94 3 2992 1 3 1989 3 8 9 16 3 4 1 63 0 679 5 dêqên mpz 28 5 98 9 3319 1 6 1965 2 5 6 11 8 1 8 70 4 635 1 dujiangyan smz 31 0 103 7 699 0 9 920 5 15 5 19 3 12 6 79 7 1182 6 yibin smz 28 8 104 6 341 0 7 1015 8 18 0 21 9 15 4 80 4 1073 7 yanyuan smz 27 4 101 5 2517 1 8 2580 9 12 4 19 2 7 1 59 5 803 4 tengchong smz 25 0 98 5 1696 1 2 2168 0 15 2 21 6 10 7 77 4 1484 8 simao smz 22 8 101 0 1302 0 7 2125 4 18 6 25 1 14 4 78 2 1484 4 yanshan smz 23 6 104 3 1561 2 2 1875 4 16 2 22 1 12 5 79 3 1000 8 nanyang smz 33 1 112 5 181 1 6 1888 8 15 2 20 5 10 7 71 4 784 6 ankang smz 32 7 109 0 291 1 0 1697 5 15 8 21 1 12 0 73 3 822 1 dachuan smz 31 2 107 5 345 0 9 1254 9 17 3 21 7 14 1 78 7 1214 3 xingshan smz 31 4 110 7 337 0 7 1584 1 17 0 22 9 12 8 72 8 980 8 xupu smz 27 9 110 6 204 1 5 1430 2 17 1 21 8 13 6 77 3 1418 5 huishui smz 26 1 106 6 991 1 5 1214 8 16 0 20 9 12 7 79 8 1208 9 jiahe smz 25 6 112 4 215 1 4 1467 2 18 3 23 0 14 9 78 2 1415 8 bengbu smz 32 9 117 3 27 1 8 2077 9 15 6 20 5 11 5 72 0 942 2 rugao smz 32 5 117 7 70 2 1 2125 0 15 2 20 1 11 2 75 0 951 8 shengsi smz 30 7 122 5 80 5 0 2032 7 16 3 19 0 14 2 78 6 1064 7 yangxin smz 29 9 115 2 57 1 4 1746 0 17 4 21 7 14 0 77 1 1432 6 fuding smz 27 3 120 2 36 1 0 1686 7 18 8 23 5 15 5 77 8 1706 8 guangchang smz 26 8 116 3 166 1 2 1676 9 18 4 23 7 14 7 80 0 1755 7 pingtan smz 25 5 119 8 32 3 8 1705 9 19 9 22 4 18 0 80 4 1241 4 laibin smz 23 8 109 2 97 1 5 1535 7 21 0 25 5 17 7 76 7 1356 2 gaoyao smz 23 0 112 5 60 1 3 1695 5 22 4 26 5 19 4 77 5 1650 1 nan ao smz 23 4 117 0 8 2 7 2198 0 21 8 25 0 19 2 78 3 1360 7 qiongzhong smz 19 0 109 8 251 0 9 1877 5 22 9 28 2 19 4 84 7 2384 9 qionghai smz 19 2 110 5 24 1 8 2008 0 24 5 28 7 21 7 84 5 2066 2 hailar tcz 49 3 119 7 650 2 4 2699 0 0 9 5 5 6 7 66 1 348 0 xin baragright banner tcz 48 7 116 8 542 2 8 3054 3 1 2 7 8 4 5 59 3 236 9 dongwuqi tcz 45 5 117 0 839 2 3 2986 8 1 7 8 9 4 9 57 0 251 3 habahe tcz 48 1 86 4 533 2 8 2889 5 5 0 11 0 0 3 60 4 196 4 bole tcz 44 9 82 1 532 1 2 2705 8 6 5 13 1 0 7 65 8 195 3 hutubi tcz 44 2 86 9 575 1 9 2984 8 7 2 13 7 1 5 60 9 183 0 tulufan tcz 43 0 89 2 39 0 9 2896 0 14 9 21 9 8 8 39 0 14 7 shaya tcz 41 2 82 8 980 1 2 2989 3 11 5 18 9 5 2 49 5 58 7 wuqia tcz 39 7 75 3 2176 1 8 2839 6 7 4 14 1 1 5 46 0 192 1 tieganlik tcz 40 6 87 7 846 1 4 3003 3 11 2 19 9 3 4 44 9 37 2 pishan tcz 37 6 78 3 1375 1 1 2622 1 12 3 19 6 5 8 43 6 57 1 minfeng tcz 37 1 82 7 1410 1 2 2869 2 11 8 20 0 4 3 40 7 42 5 qiemo tcz 38 2 85 6 1247 1 5 2786 6 10 7 18 9 3 2 41 5 25 7 balikun tcz 43 6 93 1 1679 1 8 3097 5 2 3 10 1 4 5 55 0 228 1 jiuquan tcz 39 8 98 5 1477 1 7 3078 4 7 7 15 0 1 2 47 0 92 2 zhangye tcz 39 1 100 3 1461 1 6 3092 4 7 6 16 0 0 7 51 1 130 8 wuwei tcz 37 9 102 7 1532 1 3 2895 3 8 4 15 7 1 9 51 2 172 1 erenhot tcz 43 6 111 9 963 3 0 3204 2 4 4 11 9 2 2 47 1 137 2 abagaqi tcz 44 0 115 0 1148 2 5 3035 4 1 7 8 9 4 6 55 9 240 1 damaoqi tcz 41 7 110 4 1377 2 6 3017 7 4 4 11 8 2 0 48 1 259 4 tsining tcz 41 0 113 1 1419 2 1 2892 4 4 4 11 2 1 7 51 4 362 1 linhe tcz 40 7 107 4 1041 1 7 3169 1 8 1 15 0 2 0 48 3 141 6 dongsheng tcz 39 8 110 0 1462 2 3 3078 3 6 5 12 2 1 7 48 9 388 8 yinchuan tcz 38 5 106 2 1111 1 5 2873 0 9 4 16 1 3 5 55 1 193 6 jarud banner tcz 44 6 120 9 265 2 0 2886 8 6 8 13 2 1 2 48 1 373 9 zuoqi tcz 44 0 119 4 486 2 0 3041 6 5 7 12 9 1 1 49 9 369 3 duolun tcz 42 2 116 5 1245 2 5 3004 3 2 5 9 7 3 9 59 9 377 1 
3807,accurately estimating the reference evapotranspiration et0 is a basic requirement for precision irrigation and the correct planning of regional water resources this study aimed to investigate the spatiotemporal variations in et0 in china and to improve the accuracy of et0 calculations on different spatiotemporal scales meteorological data collected at 100 stations in china during 1961 to 2019 were used to calculate et0 with the penman monteith model and the temporal and spatial patterns in et0 pm were analyzed with the mann kendall nonparametric trend test method three machine learning models comprising convolutional neural network cnn extreme learning machine elm and multiple adaptive regression splines mars and seven empirical models calibrated with mind evolutionary algorithm mea were compared to assess their suitability for calculating et0 on different spatiotemporal scales in china the results showed that the annual mean et0 pm value 413 29 2772 35 mm in china gradually increased from north to south and from west to east et0 exhibited an upward trend in the temperate continental zone tcz and mountain plateau zone mpz but a downward trend in the temperate monsoon zone tmz and subtropical monsoon region smz by comparing the global performance indicators gpi the machine learning models generally performed better than the empirical models at different spatiotemporal scales and cnn was the best model for calculating et0 in terms of the model accuracy and stability on the daily scale mars performed well in mpz whereas elm performed well in tmz and tcz on the monthly scale mars performed well in tmz whereas elm performed well in smz and mpz at the annual scale the accuracy of elm was higher than that of mars keywords et0 convolutional neural network extreme learning machine multiple adaptive regression splines 1 introduction more than 90 of the water applied in agricultural ecosystems is lost through evapotranspiration et shan et al 2020 wang et al 2019 therefore accurate et predictions are very important for the planning and design of irrigation and improving the efficient utilization of water resources bellido jiménez et al 2020 feng et al 2016 et involves two processes comprising evaporation from soil and plant surfaces and transpiration from crops into the atmosphere chen et al 2020b the et process is an essential part of the energy cycle and land atmosphere water cycle hadria et al 2021 the main methods used to measure et include the vorticity correlation method isotope tracer method liquid flow method and lysimeter method however these methods are time consuming laborious costly and challenging to implement in a large area jiang et al 2016 therefore various et calculation models have been developed the reference evapotranspiration et0 is a basic requirement for these models shan et al 2020 and it is essential to calculate et0 accurately and rapidly in 1998 the penman monteith pm equation was adopted by the food and agriculture organization fao of the united nations as the only standard for calculating et0 fan et al 2018 feng et al 2017 the pm equation is based on the theory of energy balance and water vapor diffusion where it considers both the physiological characteristics of crops and variations in aerodynamic parameters chen et al 2020b the accuracy of the pm equation is high but comprehensive meteorological data are required almorox et al 2015 ferreira et al 2019 it is difficult to use the pm equation to calculate et0 in some poor and remote areas due to the lack of meteorological stations or meteorological data records tabari et al 2012 due to the limitations described above empirical models have been investigated that require fewer input parameters to calculate et0 these empirical models can be divided into 1 combination models 2 radiation based models 3 temperature based models 4 humidity based models 5 water budget based models 6 mass transfer based models and 7 pan based models chen et al 2020b among these empirical models the most commonly used are combination radiation based and temperature based models and many studies have employed these models hadria et al 2021 todorovic et al 2013 valipour et al 2017 zheng et al 2017 in particular yang et al 2021 calculated et0 with eighteen different empirical models in the climatic regions of china and they concluded that the combination models performed the best followed by the radiation based models whereas the temperature based models obtained the worst performance feng et al 2016 compared the accuracy of two temperature based models and three radiation based models for calculating et0 in southwest china and they concluded that the radiation based models were superior to the temperature based models mehdizadeh et al 2017 used sixteen empirical models to calculate the monthly mean et0 and concluded that the hargreaves samani and romanenko models performed best recently machine learning methods have been used for et0 calculations due to the development of 5g connection technology and the widespread use of automatic weather stations bellido jiménez et al 2020 research into machine learning can be traced back to the 1950 s and it has developed from classical machine learning to deep learning various machine learning models have been used for calculating et0 where the classical machine learning models include multiple adaptive regression splines mars support vector regression svr extreme learning machine elm and multilayer perceptron mlp bellido jiménez et al 2020 fan et al 2018 feng et al 2017 ferreira et al 2019 mehdizadeh et al 2017 fan et al 2018 calculated et0 using support vector machine svm elm and four tree based ensemble models in different climate zones in china and they found that extreme gradient boosting xgboost and gradient boosting decision tree gbdt models performed best yu et al 2020 used artificial neural network svr and elm models to calculate et0 in northwest china and concluded that svr and elm obtained the best performance feng et al 2016 used elm generalized regression neural network grnn wavelet neural networks wnn models to calculate et0 in southwest china and concluded that elm and grnn performed much better than wnn bellido jiménez et al 2020 calculated et0 in southern spain using mlp grnn elm svm random forest rf and xgboost models and concluded that elm obtained the best performance in this century deep learning models have developed rapidly mainly for applications in computer vision speech analysis and natural language processing chen et al 2020a lara hernandez et al 2020 lucas et al 2020 deep learning models mainly extract the external input data layer by layer learn the complex features from the data through a nonlinear activation function and finally complete the training and prediction tasks for the multi layer neural network deep learning models include convolutional neural network cnn deep neural network dnn long short term memory neural network lstm and temporal convolution neural network tcn models saggi and jain 2019 yin et al 2020 aslam et al 2020 used a deep learning model based on mlp for year ahead solar radiation forecasting and concluded that the deep learning model performed better than other models atila et al 2021 applied the efficientnet deep learning model for plant leaf disease classification and concluded that the b5 and b4 models in the efficientnet architecture performed better than other deep learning models however few studies have investigated the application of deep learning to et0 computation chen et al 2020b compared empirical models svm rf dnn tcn and lstm models for calculating the daily et0 in the northeast plain region of china and concluded that lstm dnn and tcn performed better than the other models china covers a vast area and the climate varies greatly previous studies of et0 estimation mainly focused on a particular time scale in local regions china instead of considering different spatiotemporal scales machine learning has been used for et0 calculation because it can deal with nonlinear relationships and it has high accuracy and stability classical machine learning models have been used for calculating et0 but few deep learning models have been developed thus the present study employed daily meteorological data from 100 national meteorological stations in china between 1961 and 2019 to test the following methods 1 the fao 56 penman monteith pm method was used to calculate et0 pm in china from 1961 to 2019 where the temporal and spatial patterns in et0 pm were determined with the mann kendall nonparametric trend test method 2 the parameters of seven empirical models were determined using the mind evolutionary algorithm mea and the suitable ranges of the parameter values for china were obtained and 3 the accuracy and stability of et0 calculations using cnn elm mars and seven empirical models in different climate zones of china were compared on daily monthly and yearly scale 2 materials and methods 2 1 study area china is located in the east of asia and the pacific ocean lies to its east according to differences in the temperature rainfall and altitude china can be divided into mountain plateau zone mpz subtropical monsoon zone smz temperate continental zone tcz and temperate monsoon zone tmz fig 1 song et al 2011 tcz denotes an arid region with an average altitude of 912 m and average annual rainfall of 269 mm mpz denotes a semiarid area with average annual rainfall of 382 mm and an average altitude of 4236 m tmz denotes a semi humid area with average annual rainfall of 585 mm and an average altitude of 288 m smz denotes a humid region with an average altitude of 611 m and average annual rainfall of 1320 mm 2 2 data the meteorological data provided by the china national meteorological scientific data sharing network http data cma cn comprised precipitation p average temperature tmean maximum temperature tmax minimum temperature tmin wind speed u2 sunshine hours n and average relative humidity rh measurement collected from one hundred stations throughout the country between 1961 and 2019 sixteen sites were distributed in mpz twenty five in smz twenty seven in tcz and thirty two in tmz fig 1 and appendix a the selection criteria for the stations were as follows 1 meteorological stations were selected with less than ninety days of missing data and less than seven days of continuously missing data 2 missing daily meteorological elements were recorded as the lack of measurement of et0 in that month and 3 missing data were interpolated based on the regression relationships with those of the adjacent stations or replaced by averages from other years at the same station the meteorological data from 1961 to 2019 were equally divided into five parts by k fold cross validation method table 1 four stages were selected to train the machine learning models and the remaining one was used for verification five different rounds of pieces of training and tests were conducted and the values of the five trials were finally averaged as the final evaluation index of the model the inverse distance weighted idw interpolation method is used to interpret the spatial distribution of et0 based on each stations the multi year average of et0 during 1961 2019 are interpolated to show the spatial distribution 2 3 fao 56 pm method in 1998 the fao recommended the pm method as the standard method for et0 calculation allen et al 1998 because of its suitability for different climatic regions bellido jiménez et al 2020 in the present study the et0 value calculated using this method was treated as the standard value et0 was calculated as follows 1 e t 0 0 408 δ r n g γ 900 273 t mean u 2 e s e a δ γ 1 0 34 u 2 where et0 is the reference evapotranspiration mm day 1 rn is the net radiation mj m 2 day 1 g is the soil heat flux mj m 2 day 1 u2 is the wind speed at a height of 2 m m s 1 tmean is the mean air temperature c es and ea are the saturation and actual vapor pressures respectively kpa δ is the slope of the saturation vapor pressure curve kpa c 1 and γ is the psychrometric constant kpa c 1 allen et al 1998 2 4 empirical models seven empirical models were tested in this study with two types of combination three radiation based and two temperature based empirical models the formulae used for calculating the specific empirical models are shown in table 2 2 5 machine learning models three types of machine learning methods were used to calculate et0 the input parameters are shown in table 3 for the combination radiation based and temperature based styles 2 5 1 cnn cnn was developed by lecun et al 1998 as a feedforward neural network and deep neural network by combining a two dimensional discrete convolution operation and artificial neural networks cnns are employed for automatic extraction where a cnn comprises an input layer hidden layer tile layer full connection layer and output layer the hidden layer comprises a convolution layer pooling layer and activation layer there are usually five or more hidden layers at the convolution layer in this study the number of convolution kernels was 100 and the size of the convolution kernels was 3 3 the stride was 1 the padding was set to same and the activation function used was relu the pooling layer is in the mode of average pooling and the stride was 5 the number of neurons in the full connection layer was 200 the number of training epochs was defined using early stopping with maximum training epochs equal to 150 and patience equal to 10 epochs the learning rate was 0 001 and batch size was 512 cnn model could be built by the pytorch package which is in python 3 6 software the following formula can express the convolution process 9 c f x w b where c is the output of the convolution layer x denotes the input data f is the nonlinear activation function is the convolution operation w is the weight vector of the convolution kernel and b is the bias term 2 5 2 elm elm was developed as a feedforward neural network model by huang et al 2006 for solving single hidden layer neural networks elm comprises an input layer hidden layer and output layer elm is faster and more accurate compared with a single hidden layer feedforward neural network elm can also randomly initialize the input weight and bias and obtain the corresponding output weight in different climate regions of china the number of hidden nodes for elm is different in smz and tcz 40 hidden nodes have been proved efficient to estimate et0 in mpz and tmz the number of hidden nodes is 50 the software packages can be downloaded from http www ntu edu sg home egbhuang the simplified expression for the elm neural network is 10 f n χ i 1 n β i g α i χ i b i y i i 1 2 n where xi is the input layer yi is the output layer αi is the input weight bi is the threshold and βi is the output weight 2 5 3 mars the mars data analysis method proposed by friedman in 1991 shan et al 2020 takes the tensor product of spline functions as the basis function and it can be divided into forward and backward processes the advantage of mars is that it can deal with large amounts and high dimensions in rapid and accurate calculations in the forward process all of the dependent and independent variables are added to the model and scanned before the basis functions are constructed and then paired into the model finally a model is built using all of the basic functions as an overfitting model the backward process involves pruning the model the initially generated basis functions may contribute little or nothing to the final model so the mars backward process deletes the basis functions that have little influence on the accuracy in this study the maximum number of basis functions is 40 the interaction degree is 2 and the penalty factor is 3 the software packages can be downloaded from http www cs rtu lv jekabsons the mathematical model of mars is expressed as follows 11 y i a 0 m 1 m a m k 1 k m s km x v k m t m where k 1 k m s km x v k m t m denotes the basis function a0 and am are the two parameters of the function m is the number of basis functions km is the number of divisions of the m basis function the value of skm is either 1 or 1 and it indicates the direction of the step function v k m represents the risk factors and tm represents the threshold of each basis function 2 6 mann kendall nonparametric trend test the mann kendall nonparametric trend test does not assume that the data follow a normal distribution and it is widely used in time series trend analysis the definition of the mann kendall s test statistics is as follows 12 z s 1 v a r s if s 0 0 if s 0 s 1 v a r s if s 0 13 s i 1 n 1 k i 1 n sgn x k x i where xk and xi are random variables used for hypothesis testing and n is the total length when x k x i is greater than equal to or less than zero the s values are 1 0 and 1 respectively when z greater than 1 96 p 0 05 the sequence trend is considered significant but not otherwise hamed and ramachandra rao 1998 2 7 mea mea is an evolutionary algorithm derived from the genetic algorithm and it is similar to the human thinking evolutionary process two new operations comprising convergence and dissimilation are proposed based on preserving the genetic algorithm the convergence and dissimilation operations allow the predicted value and expected value to gradually converge by continuous iteration the initial population is generated using a combination of the data in the training set and test set the winning sub population and temporary sub population are generated according to the initial score for the population moreover the whole population s maturity is assessed and the optimal individuals are produced by the convergence and dissimilation operations the parameters of the seven empirical models calibrated by mea are shown in table 4 2 8 performance evaluations for models the following five indicators were used to evaluate the accuracy of the models 1 mean absolute error mae 14 mae 1 n i 1 n y i x i 2 nash sutcliffe efficiency nse 15 nse 1 i 1 n y i x i 2 i 1 n x i x i 2 3 coefficient of determination r2 16 r 2 i 1 n y i y i x i x i 2 i 1 n y i y i 2 i 1 n x i x i 2 4 root mean square error rmse 17 rmse 1 n i 1 n y i x i 2 the four indicators given above cannot be used to comprehensively evaluate a model so the global performance indicator gpi feng et al 2020a was employed as a comprehensive indicator based on mae nse r2 and rmse in order to objectively evaluate the accuracy of the models gpi is defined as follows 5 global performance indicator gpi 18 gpi i 1 4 α i t i t i where xi and yi represent the reference value and simulated value respectively x and y represent averages n is the number of samples in the verification set ti is the normalized value of rmse mae r2 and nse t i is the median of the corresponding indexes and αi is 1 when ti is rmse and mae but 1 in other cases 3 results 3 1 spatiotemporal variation of et0 pm in china fig 2 shows that the average annual range of variation for et0 pm in china between 1961 and 2019 was 413 29 mm to 2772 35 mm and the trend generally increased from north to south and from west to east the mann kendall trend analysis results for et0 pm based on 100 meteorological stations in china between 1961 and 2019 showed that ten stations exhibited significant upward trends in tcz nine had significant downward trends six had upward trends and two had downward trends in general et0 pm exhibited an upward trend in tcz p 0 05 in mpz six stations had significant upward trends four had significant downward trends five had upward trends and one had a downward trend in general et0 pm exhibited an upward trend in mpz p 0 05 in tmz six stations had significant upward trends seven had significant downward trends eight had upward trends and eleven had downward trends in general et0 pm exhibited a downward trend in tmz p 0 05 in smz four stations had significant upward trends ten had significant downward trends four had upward trends and seven had downward trends in general et0 pm exhibited a downward trend in smz p 0 05 3 2 calibration of empirical models using mea fig 3 compares the results obtained before and after calibrating the parameters of the seven empirical models where the accuracy of the et0 estimations produced by the empirical models improved after parameter optimization with mea the r2 and nse values increased for each model whereas the rmse and mae values decreased in particular the most obvious changes were obtained with pm 1992 and harg with pm 1992 r2 and nse increased by 0 25 and 1 15 respectively and rmse and mae decreased by 2 31 mm day 1 and 2 10 mm day 1 with harg r2 and nse increased by 0 22 and 1 11 respectively and rmse and mae decreased by 2 13 mm day 1 and 1 88 mm day 1 3 3 analysis of the suitability of machine learning models and empirical models at the daily scale in china fig 4 shows the daily gpi rankings for the smz mpz tmz and tcz of china bluer colors indicate better model performance and higher rankings redder colors indicate worse model performance and lower rankings the results demonstrated that the machine learning models ranked higher overall than the empirical models in the four region types the r2 rmse mae and nse values for the machine learning models are shown in table 5 fig 5 shows the specific daily gpi indexes for the cnn elm and mars models in the four region types in china according to the median gpi index in smz when the input parameters were combination radiation based and temperature based the gpi index for cnn 1 was 0 26 higher than those for both mars 1 and elm 1 that for cnn 2 was 0 47 and 0 45 higher than those for elm 2 and mars 2 respectively and that for cnn 3 was 0 22 and 0 68 higher than those for elm 3 and mars 3 therefore the accuracies of the models were ranked as follows cnn 1 elm 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 mars 3 according to the gpi ranges and areas of the violin plots the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 mars 3 therefore cnn obtained the best performance in terms of its accuracy and stability and elm had higher stability than mars in mpz fig 5 the gpi index for cnn 1 was 0 52 and 0 36 higher than those for elm 1 and mars 1 respectively that for cnn 2 was 0 32 and 0 26 higher than those for elm 2 and mars 2 and that for cnn 3 was 0 15 higher than those for both elm 3 and mars 3 therefore the accuracies of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 elm 3 mars 3 according to the gpi ranges and areas of the violin plots the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 mars 3 elm 3 therefore cnn was better than mars in terms of its accuracy and stability and mars was better than elm in tmz fig 5 the gpi index for cnn 1 was 0 12 and 0 14 higher than those for elm 1 and mars 1 respectively that for cnn 2 was 0 22 and 0 73 higher than those for elm 2 and mars 2 and that for cnn 3 was 0 12 and 0 68 higher than those for elm 3 and mars 3 therefore the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 according to the gpi ranges and areas of the violin plots the stabilities of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 therefore cnn was superior to elm in terms of the model accuracy and stability and elm was superior to mars in tcz fig 5 the gpi index for cnn 1 was 0 13 and 0 14 higher than those for elm 1 and mars 1 respectively that for cnn 2 was 0 44 and 0 80 higher than those for elm 2 and mars 2 and that for cnn 3 was 0 12 and 0 37 higher than those for elm 3 and mars 3 therefore the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 according to the gpi ranges and areas of the violin plots the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 mars 3 elm 3 therefore cnn was better than elm in terms of the model accuracy and stability and elm was superior to mars therefore the results showed that cnn performed better than mars and elm on the national daily scale mars performed better in mpz and elm performed better in tmz and tcz in addition according to the median and gpi ranges for the same types of machine learning methods shown in fig 5 as well as the areas of the violin plots the stability and precision of the cnn elm and mars models in the four region types in china decreased to some extent as the number of input parameters decreased 3 4 analysis of the suitability of machine learning models and empirical models at the monthly scale in china fig 6 shows the monthly gpi rankings for the smz mpz tmz and tcz region types in china where the overall rankings of the cnn elm and mars models were higher than those of the empirical models the r2 rmse mae and nse values for machine learning models are shown in table 5 fig 7 shows the gpi indexes for the three machine learning models in the four region types in china the analysis method was the same as that used for the daily scale in smz the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 mars 3 elm 3 the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 mars 3 therefore cnn performed better than elm in terms of the model accuracy and stability and elm was better than mars in mpz the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 mars 3 elm 3 therefore cnn performed better than elm in terms of the model accuracy and stability and elm was better than mars in tmz the accuracies and stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 mars 3 elm 3 therefore cnn performed better than mars in terms of the model accuracy and stability and mars was better than elm in tcz the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 elm 3 mars 3 the stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 mars 2 elm 2 cnn 3 mars 3 elm 3 therefore cnn performed better than elm and mars in terms of the model accuracy and stability elm performed better than mars in terms of accuracy and mars performed better than elm in terms of stability in summary cnn was superior to elm and mars on the monthly scale in china elm performed better in smz and mpz and mars performed better in tmz in addition as the number of input parameters decreased the stability and precision of the cnn elm and mars models all decreased to some extent in terms of the gpi size and range for the same model as well as the areas of the violin plots 3 5 analysis of the suitability of machine learning models and empirical models at the annual scale in china fig 8 shows the annual gpi rankings for the smz mpz tmz and tcz region types in china the results demonstrated that the overall rankings of the machine learning models were higher than those of the empirical models the r2 rmse mae and nse values for machine learning models are shown in table 5 fig 9 shows the specific gpi indexes for cnn elm and mars models in the four region types in china on an annual scale in smz the accuracies of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 the stabilities of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 thus cnn performed better than elm and elm was better than mars in mpz the accuracies and stabilities of the models were ranked as follows cnn 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 thus cnn performed better than elm and elm was better than mars in tmz the accuracies of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 the stabilities of the models were ranked as follows cnn 1 elm 1 elm 1 mars 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 thus cnn performed better than elm and elm was better than mars in tcz the accuracies and stabilities of the models were ranked as follows cnn 1 mars 1 elm 1 cnn 2 elm 2 mars 2 cnn 3 elm 3 mars 3 thus cnn performed better than elm and elm was better than mars in summary cnn performed better than elm in terms of the model accuracy and stability at the national annual scale and elm was better than mars in addition as the number of input parameters decreased the stability and precision of the cnn elm and mars models all decreased to some extent 4 discussion 4 1 implications of spatiotemporal variation of et0 in hydrology agriculture meteorology and other fields et0 is one of the significant indicators to measure atmospheric evapotranspiration capacity estimate crop water demand and production potential and also plays an important role in surface energy and water balance therefore the study of spatiotemporal variation characteristics of et0 in china is crucial for improving grain yield predicting extreme climate and rational utilization of water resources zhao et al 2020 studied the variation characteristics of et0 in ningxia from 1957 to 2018 and found that the et0 showed a significant upward trend on an annual scale this is consistent with the results of this study in tcz wang et al 2017 studied the spatiotemporal changes of et0 in china during 1961 2013 and concluded that et0 in the qinghai tibet plateau region presented an upward trend which is similar to the results of this study in mpz fan et al 2016 studied the variation of et0 in different climate zones in china during 1956 2015 and concluded that et0 showed a downward trend in smz and tmz which is consistent with the results of this study et0 showed different trends in various climatic zones of china during 1961 2019 in arid areas of china et0 showed an increasing trend which might lead to the need for more water in crop growth therefore in the critical period of crop growth increasing irrigation amount to a certain extent can improve yield fan et al 2016 on the contrary et0 showed a decreasing trend in humid areas and irrigation amount could be reduced appropriately in conclusion understanding the spatiotemporal variation characteristics of et0 is of great significance for agricultural water management 4 2 evaluation of suitability of machine learning models and empirical models for et0 computation at different spatial and temporal scales previous studies of et0 calculation models mainly focused on specific temporal or spatial scales feng et al 2017 ferreira et al 2019 hossein kazemi et al 2020 in particular valipour et al 2017 calculated et0 based on 50 years of monthly meteorological data in iran they compared five temperature based models five radiation based models and five mass transfer based models in different climate regions and concluded that modified hargreaves samani performed best in arid and semiarid regions and radiation based and mass transfer based models performed best in warm and cold regions feng et al 2016 considered yearly monthly and daily scales and used three machine learning methods elm back propagation neural networks optimized by genetic algorithm gann and wnn two temperature based models hargreaves and modified hargreaves and three radiation based models makkink priestley taylor and ritchie to calculate et0 in southwest china and they concluded that the elm and gann models were the most accurate fan et al 2018 compared the accuracy of the et0 calculations obtained by svm elm and four tree based ensemble models in different climate regions of china on a daily scale and they concluded that the xgboost and gbdt models were the most accurate the present study compared the accuracy of seven empirical models and three machine learning models at calculating et0 on different temporal and spatial scales throughout china the results showed that the deep learning models represented by cnn were much more accurate and stable than other empirical models and classical machine learning models on different time scales and similar findings were obtained by chen et al 2020b further analysis on a daily basis showed that mars performed better in mpz regions whereas elm performed better in tmz and tcz regions on a monthly scale elm performed better in mpz and smz regions whereas mars performs better in tmz regions the applicability of different spatial and temporal scale analysis models in calculating et0 is more comprehensive than that of a single spatial and temporal scale 4 3 advantages and disadvantages of machine learning models and empirical models for calculating et0 the most common empirical models for estimating et0 are temperature based radiation based and combination models thornthwaite 1948 first proposed a temperature based model for estimating et0 and many temperature based models have been developed subsequently in particular the hargreaves method is used widely throughout the world because it employs simple meteorological data as inputs and it can obtain highly accurate results allen et al 1998 radiation based models were proposed based on the relationship between radiation and et0 priestley and taylor 1972 proposed a formula for calculating et0 and it is the most widely used radiation based model various types of combination models have been proposed for calculating et0 based on the pm equation and by considering different actual situations however the pm equation is still the most widely used model and it is the most accurate therefore the united nations fao adopted the pm equation as the standard for calculating et0 in 1998 machine learning was proposed in 1950 by turing in 2012 alexnet won the imagenet ilsvrc 2012 competition and its classification accuracy was nearly 11 higher than that of the method ranked in second place the development of machine learning has progressed from classical machine learning to deep learning in addition the deep learning models represented by cnn have made many important achievements in various tasks such as computer vision speech analysis and natural language processing however few studies have investigated the calculation of et0 with deep learning which was investigated in the present study the present study compared the accuracy of et0 calculation in different region types in china using two temperature based models three radiation based models and two combination models which were calibrated with mea as well as three machine learning models the results demonstrated that the machine learning models performed better than the empirical models the machine learning models performed well in terms of their accuracy and stability but they were prone to overfitting and required a large amount of data for training in the early stage thus the accuracy of these models was not high with a small amount of data and insufficient preliminary training moreover machine learning involves a type of black box model which is a general term for a class of algorithms these algorithms aim to mine hidden patterns from large amounts of historical data and use them for prediction or classification however the theoretical basis for calculating et0 cannot be explained based on the mechanism by contrast the empirical models are mathematical models based on rigorous assumptions regarding aerodynamics and the energy balance moreover the empirical models do not require prior training so they are more suitable for calculating samples with small amounts of data however the high accuracy of the empirical models can only be maintained with more input parameters and the precision of the model will decrease significantly when the number of input parameters is reduced by contrast machine learning models can obtain accurate results with few input parameters moreover the parameters must be calibrated according to the localization when calculating et0 using empirical models or the calculated et0 value is meaningless 4 4 advantages of deep learning models with the development of computer technology machine learning methods have been widely applied in various fields fan et al 2021 gong et al 2021 feng et al 2020b used a new machine learning method hybrid particle swarm optimization and extreme learning machine pso elm to calculate the daily global solar radiation on the loess plateau of china and obtained the pso elm model with high accuracy however previous studies have rarely applied deep learning models for calculating et0 which was the focus of the present study the results obtained in this study showed that the accuracy of the deep learning model was significantly higher than those of the classical machine learning models thus deep learning models are highly suitable for et0 estimation compared with the classical machine learning models the structure of deep learning models is characterized by local connections and weight sharing local connections refers to the fact that only some of the neurons in the external layer network are connected with neurons in the deep layer and all neurons in the same layer share the same connection weight these two structural characteristics mean that the parameter scale is significantly reduced in a cnn and it can mine the inherent correlations among data to make the model more accurate the application of deep learning models to calculate et0 at different spatiotemporal scales is of great significance for estimating et0 in remote areas with incomplete meteorological data where it can obtain more accurate et0 with fewer meteorological parameters it plays an important role in understanding the regional water cycle and energy balance making regional water demand plans and water resource optimization decisions and evaluating crop water demand 5 conclusion this study analyzed the temporal and spatial variations in et0 pm in china between 1961 and 2019 based on the mann kendall method the suitability for et0 estimation was compared for cnn elm and mars machine learning models and seven empirical models improved with the mea the et0 estimation models were selected with the greatest suitability to different spatial and temporal scales in china the conclusions based on the results obtained in this study are as follows the average annual range of et0 pm in china between 1961 and 2019 was determined as 413 29 mm to 2772 35 mm and the trend generally increased from north to south and from west to east et0 pm exhibited an upward trend in tcz and mpz but a downward trend in tmz and smz the parameters of the seven empirical models were calibrated with mea and their accuracy improved greatly where the models with the most obvious changes were pm 1992 and harg the suitable parameters ranges were determined for the seven empirical models in china on a daily scale cnn was superior to mars and elm in terms of the model accuracy and stability mars performed better in mpz and elm performed better in tmz and tcz on a monthly scale cnn was better than elm and mars in terms of the model accuracy and stability elm performed better in smz and mpz whereas mars was better in tmz on an annual scale cnn was better than elm in terms of the model accuracy and stability and elm was better than mars moreover the accuracy and stability of the same type of machine learning model decreased when the number of input parameters was reduced on different time scales credit authorship contribution statement juan dong conceptualization methodology software writing original draft yuanjun zhu writing review editing funding acquisition project administration xiaoxu jia validation ming an shao supervision xiaoyang han writing review editing jiangbo qiao writing review editing chenyun bai data curation investigation xiaodi tang data curation declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the strategy priority research program of chinese academy of sciences xdb40000000 and the natural science foundation of china 41530854 and 42007011 appendix a basic information about the 100 meteorological stations considered in this study station region latitude n longitude e altitude m u2 m s 1 n h tmean c tmax c tmin c rh p mm year 1 mohe tmz 53 0 122 5 439 1 4 2409 6 4 1 4 5 11 7 69 3 439 9 huma tmz 51 7 126 6 174 1 6 2548 9 0 9 5 9 7 1 66 0 457 8 tulihe tmz 50 5 121 7 733 1 6 2537 1 4 4 4 3 12 5 70 8 451 4 xiaorgou tmz 49 2 123 7 286 1 2 2655 1 0 1 8 3 7 4 66 2 508 1 sunwu tmz 49 4 127 4 235 1 9 2502 7 0 2 7 1 7 1 69 3 547 3 mingshui tmz 47 2 125 9 240 2 6 2639 6 2 9 8 4 2 2 63 7 504 2 suolun tmz 46 6 121 2 500 2 1 2832 5 2 7 10 3 4 0 56 7 465 8 jiamusi tmz 46 8 130 3 82 2 3 2443 9 3 6 9 5 2 1 66 5 539 0 qian an tmz 45 0 124 0 146 2 5 2753 3 5 5 11 5 0 1 59 4 414 4 shangzhi tmz 45 2 128 0 190 2 1 2458 8 3 1 9 8 2 9 72 2 654 7 yuzhong tmz 35 9 104 2 1874 1 3 2582 0 6 9 14 1 1 1 62 7 388 7 hequ tmz 39 4 111 2 1036 1 1 2668 7 8 4 16 1 1 9 55 7 411 9 taiyuan tmz 37 6 112 6 776 1 5 2513 0 10 2 17 2 4 3 58 3 441 8 yanchang tmz 36 6 110 1 805 1 0 2470 8 10 3 18 0 4 3 62 1 519 8 xifeng tmz 35 7 107 6 1421 1 8 2429 9 9 0 14 2 4 9 61 7 557 7 suifenhe tmz 44 4 131 2 568 2 4 2408 2 2 9 8 8 2 4 67 0 586 7 siping tmz 43 1 124 4 180 2 1 2657 4 6 7 12 5 1 4 63 8 620 5 dunhua tmz 43 4 128 2 525 2 0 2310 6 3 5 10 0 2 3 67 6 624 0 kaiyuan tmz 42 5 124 1 98 2 2 2569 5 7 1 13 3 1 5 65 2 673 8 shenyang tmz 41 7 123 5 49 2 1 2476 3 8 3 14 1 3 1 63 2 684 9 zhangjiakou tmz 40 8 114 9 773 2 0 2776 8 8 8 15 2 3 4 47 4 405 1 zunhua tmz 40 2 118 0 55 1 2 2603 3 11 3 17 6 5 7 58 0 707 5 dawa tmz 41 0 122 1 6 2 8 2693 5 9 3 14 1 5 1 65 6 629 2 tianjin tmz 39 1 117 1 4 1 9 2466 3 12 8 18 2 8 3 60 8 537 7 raoyang tmz 38 2 115 7 18 1 6 2624 7 12 6 19 0 7 4 63 8 509 0 dalian tmz 38 9 121 6 92 3 3 2693 2 11 0 14 6 7 9 64 6 614 7 chengshantou tmz 37 4 122 7 48 4 5 2467 7 11 5 14 2 9 3 74 1 708 1 shenxian tmz 36 2 115 6 38 2 1 2286 3 13 5 19 5 8 6 68 6 537 0 pingdu tmz 36 8 120 0 62 2 4 2593 9 12 4 18 1 7 6 68 8 636 9 wugong tmz 34 3 108 2 471 1 2 1897 9 13 4 19 0 8 8 70 9 600 6 kaifeng tmz 34 8 114 3 74 2 1 2088 4 14 6 20 1 10 0 66 4 618 0 pizhou tmz 34 4 118 0 26 1 7 2242 3 14 2 19 5 9 9 72 6 857 7 lenghu mpz 38 8 93 3 2770 2 9 3432 4 3 1 11 9 5 3 29 5 17 2 geermu mpz 36 4 94 9 2808 1 9 3061 6 5 4 13 1 1 1 32 2 45 0 dulan mpz 36 3 98 1 3189 1 9 3035 4 3 3 10 2 2 3 39 8 207 7 gonghe mpz 36 3 100 6 2835 1 4 2914 5 4 3 12 1 2 1 49 4 327 5 xining mpz 36 7 101 8 2295 1 1 2645 4 6 0 14 0 0 1 56 2 394 2 shiquan mpz 32 5 80 1 4279 2 0 3484 0 0 9 8 5 6 9 32 0 72 3 damxung mpz 30 5 91 1 4200 1 8 2885 1 1 9 10 0 4 8 53 4 474 8 tingri mpz 28 6 87 1 4300 1 9 3360 0 2 8 11 8 5 2 40 9 281 1 ulan moron mpz 34 2 92 4 4533 2 9 2883 3 3 7 4 6 10 7 52 9 295 9 ruoergai mpz 33 6 103 0 3441 1 7 2443 7 1 4 9 5 4 8 67 6 658 7 nangqian mpz 32 2 96 5 3644 1 2 2571 5 4 5 12 8 1 9 53 0 538 7 changdu mpz 31 2 97 2 3315 0 9 2391 0 7 8 16 8 0 9 50 2 482 1 garzê mpz 31 6 100 0 3394 1 4 2594 3 5 9 14 3 0 3 56 0 653 2 litang mpz 30 0 100 3 3949 1 4 2669 9 3 5 11 3 2 3 56 1 733 3 linzhi mpz 29 7 94 3 2992 1 3 1989 3 8 9 16 3 4 1 63 0 679 5 dêqên mpz 28 5 98 9 3319 1 6 1965 2 5 6 11 8 1 8 70 4 635 1 dujiangyan smz 31 0 103 7 699 0 9 920 5 15 5 19 3 12 6 79 7 1182 6 yibin smz 28 8 104 6 341 0 7 1015 8 18 0 21 9 15 4 80 4 1073 7 yanyuan smz 27 4 101 5 2517 1 8 2580 9 12 4 19 2 7 1 59 5 803 4 tengchong smz 25 0 98 5 1696 1 2 2168 0 15 2 21 6 10 7 77 4 1484 8 simao smz 22 8 101 0 1302 0 7 2125 4 18 6 25 1 14 4 78 2 1484 4 yanshan smz 23 6 104 3 1561 2 2 1875 4 16 2 22 1 12 5 79 3 1000 8 nanyang smz 33 1 112 5 181 1 6 1888 8 15 2 20 5 10 7 71 4 784 6 ankang smz 32 7 109 0 291 1 0 1697 5 15 8 21 1 12 0 73 3 822 1 dachuan smz 31 2 107 5 345 0 9 1254 9 17 3 21 7 14 1 78 7 1214 3 xingshan smz 31 4 110 7 337 0 7 1584 1 17 0 22 9 12 8 72 8 980 8 xupu smz 27 9 110 6 204 1 5 1430 2 17 1 21 8 13 6 77 3 1418 5 huishui smz 26 1 106 6 991 1 5 1214 8 16 0 20 9 12 7 79 8 1208 9 jiahe smz 25 6 112 4 215 1 4 1467 2 18 3 23 0 14 9 78 2 1415 8 bengbu smz 32 9 117 3 27 1 8 2077 9 15 6 20 5 11 5 72 0 942 2 rugao smz 32 5 117 7 70 2 1 2125 0 15 2 20 1 11 2 75 0 951 8 shengsi smz 30 7 122 5 80 5 0 2032 7 16 3 19 0 14 2 78 6 1064 7 yangxin smz 29 9 115 2 57 1 4 1746 0 17 4 21 7 14 0 77 1 1432 6 fuding smz 27 3 120 2 36 1 0 1686 7 18 8 23 5 15 5 77 8 1706 8 guangchang smz 26 8 116 3 166 1 2 1676 9 18 4 23 7 14 7 80 0 1755 7 pingtan smz 25 5 119 8 32 3 8 1705 9 19 9 22 4 18 0 80 4 1241 4 laibin smz 23 8 109 2 97 1 5 1535 7 21 0 25 5 17 7 76 7 1356 2 gaoyao smz 23 0 112 5 60 1 3 1695 5 22 4 26 5 19 4 77 5 1650 1 nan ao smz 23 4 117 0 8 2 7 2198 0 21 8 25 0 19 2 78 3 1360 7 qiongzhong smz 19 0 109 8 251 0 9 1877 5 22 9 28 2 19 4 84 7 2384 9 qionghai smz 19 2 110 5 24 1 8 2008 0 24 5 28 7 21 7 84 5 2066 2 hailar tcz 49 3 119 7 650 2 4 2699 0 0 9 5 5 6 7 66 1 348 0 xin baragright banner tcz 48 7 116 8 542 2 8 3054 3 1 2 7 8 4 5 59 3 236 9 dongwuqi tcz 45 5 117 0 839 2 3 2986 8 1 7 8 9 4 9 57 0 251 3 habahe tcz 48 1 86 4 533 2 8 2889 5 5 0 11 0 0 3 60 4 196 4 bole tcz 44 9 82 1 532 1 2 2705 8 6 5 13 1 0 7 65 8 195 3 hutubi tcz 44 2 86 9 575 1 9 2984 8 7 2 13 7 1 5 60 9 183 0 tulufan tcz 43 0 89 2 39 0 9 2896 0 14 9 21 9 8 8 39 0 14 7 shaya tcz 41 2 82 8 980 1 2 2989 3 11 5 18 9 5 2 49 5 58 7 wuqia tcz 39 7 75 3 2176 1 8 2839 6 7 4 14 1 1 5 46 0 192 1 tieganlik tcz 40 6 87 7 846 1 4 3003 3 11 2 19 9 3 4 44 9 37 2 pishan tcz 37 6 78 3 1375 1 1 2622 1 12 3 19 6 5 8 43 6 57 1 minfeng tcz 37 1 82 7 1410 1 2 2869 2 11 8 20 0 4 3 40 7 42 5 qiemo tcz 38 2 85 6 1247 1 5 2786 6 10 7 18 9 3 2 41 5 25 7 balikun tcz 43 6 93 1 1679 1 8 3097 5 2 3 10 1 4 5 55 0 228 1 jiuquan tcz 39 8 98 5 1477 1 7 3078 4 7 7 15 0 1 2 47 0 92 2 zhangye tcz 39 1 100 3 1461 1 6 3092 4 7 6 16 0 0 7 51 1 130 8 wuwei tcz 37 9 102 7 1532 1 3 2895 3 8 4 15 7 1 9 51 2 172 1 erenhot tcz 43 6 111 9 963 3 0 3204 2 4 4 11 9 2 2 47 1 137 2 abagaqi tcz 44 0 115 0 1148 2 5 3035 4 1 7 8 9 4 6 55 9 240 1 damaoqi tcz 41 7 110 4 1377 2 6 3017 7 4 4 11 8 2 0 48 1 259 4 tsining tcz 41 0 113 1 1419 2 1 2892 4 4 4 11 2 1 7 51 4 362 1 linhe tcz 40 7 107 4 1041 1 7 3169 1 8 1 15 0 2 0 48 3 141 6 dongsheng tcz 39 8 110 0 1462 2 3 3078 3 6 5 12 2 1 7 48 9 388 8 yinchuan tcz 38 5 106 2 1111 1 5 2873 0 9 4 16 1 3 5 55 1 193 6 jarud banner tcz 44 6 120 9 265 2 0 2886 8 6 8 13 2 1 2 48 1 373 9 zuoqi tcz 44 0 119 4 486 2 0 3041 6 5 7 12 9 1 1 49 9 369 3 duolun tcz 42 2 116 5 1245 2 5 3004 3 2 5 9 7 3 9 59 9 377 1 
3808,different indicators such as precipitation surface and groundwater availability vegetation and soil types are indispensable in developing land management plans for detecting monitoring and evaluating drought impacts at the watershed scale because of the complex interactions among these indicators it is well known that one single hydrometeorological variable would be unable to capture all the aspects of drought characteristics in this study a methodology based on principal component analysis pca copula was proposed to assess the frequency of different drought events and improve mitigation in watersheds a comprehensive approach for an integrated drought indicator idi was proposed using a combination of three hydrometeorological variables precipitation runoff and soil moisture based on pca and tested for the upstream nanpan river in china idi confirmed the cumulative contribution rate of the first and second principal components 85 and its design included simulation of monthly average soil moisture content from 0 to 0 4 meter soil layer using soil and water assessment tool swat model the parameters were calibrated using the sufi 2 optimization algorithm in swat cup then the idi relative anomaly characterization was used to identify drought processes based on the run theory two major drought characteristics duration and severity were abstracted from the observed drought events finally two dimensional copulas were applied for analyzing comprehensive drought characteristics in the region our results showed that significant differences in drought duration periods could be identified drought duration predicted by runoff and soil moisture were found longer than those assessed using the precipitation index idi suggest our proposed model was suitable to identify comprehensive drought events and describe the overall drought characteristics of the region in the same way pca copula methodology was found with high potential for drought analysis in areas where no previous studies have been performed keywords principal component analysis pca watershed management drought indicators hydrological model drought frequency 1 introduction drought is the shortage of water supply in a specific geographical area for a prolonged period affected by several factors such as precipitation evaporation runoff and soil moisture content rossi and cancelliere 2013 the magnitude and frequency of drought have dramatically increased over the last few decades coinciding with new evidence of climate change ipcc 2019 compared to other natural disasters the impact of droughts is non structural and could be much larger in terms of its spatial extent reddy and ganguli 2012 xu et al 2019 miralles et al 2019 it has been estimated that for the whole amount of extreme hydro meteorological events 22 of economic damages and 33 of affected inhabitants accounted are related to droughts belayneh et al 2014 receiving major attention and becoming a hotspot in water resources management and natural disaster study field drought indicators are indispensable tools to develop successful management plans for detecting monitoring and evaluating drought impact at the watershed scale bachmair et al 2015 it has been stated that one single indicator is not enough to adequately describe all aspects of droughts van lanen et al 2016 ahmadi and moradkhani 2019 highlighting the significance of integrated or multivariate indicators using different variables or indices guo et al 2019 hao and singh 2015 mazdiyasni and aghakouchak 2015 vicente serrano et al 2010 different scholars have developed indicators using hydro meteorological elements e g rainfall evaporation and runoff to analyze drought frequency leading to an inconsistent description or lack of standardization of the return period of drought events xu et al 2018 a drought event corresponds to one frequency and generating appropriate indicators for accurately estimating their onset severity and duration is a significant need to ensure effective mitigation measures and strategies for specific conditions for a comprehensive drought analysis it is appropriate considering multiple climatic and hydrologic variables at different scales to consistently and comparably determine their interdependent connection therefore considering the above mentioned background the main aim of this study is to propose a comprehensive approach for an integrated drought indicator idi combining three hydrometeorological variables e g precipitation runoff and soil moisture using the pca pca reduced original multiple variables into a few independent composite variables that reflect the inherent law of drought characteristics a pca copula based methodology is proposed for assessing the frequency of different drought events to improve their mitigation at the watershed scale the objectives of our study are to 1 develop a methodology for a comprehensive drought index based on the hydrological processes and use pca to solve the interdependency between hydro meteorological variables 2 simulate soil moisture using swat model for lacking long term observation data and 3 evaluate method s performance by comparing with results using a single index 2 materials and methods 2 1 study area the nanpan river 102 10 106 10 e 23 04 26 00 n which originates from the eastern foothills of the maxiong mountain in the aftermath of wumeng mountain qujing city yunnan province was selected as the study area in china it belongs to the xijiang river system of the pearl river basin and it is the main source of the pearl river the nanpan river drains an area of approximately 43 200 km2 the length of the river in yunnan is 655 km fig 1 the climate is primarily subtropical monsoonal with a mean annual precipitation of 1 070 mm and mean air temperature ranging 13 0 20 0 c because of the differences in topography and atmospheric circulation the spatial distribution of precipitation in the area is extremely uneven the central and western parts of the river basin are arid while the eastern part is a humid and rainy area the watershed is located in the lake basin and karst mountain area in eastern yunnan there are five main types of land uses e g agriculture forest grassland and urban areas and water bodies distributed in the watershed the xiqiao hydrological station was selected as the outlet of the experimental area to assess the drought events which is in the upstream nanpan river 103 33 104 09 e 25 01 25 56 n the controlled watershed area from the basin origin to xiqiao hydrological station has an estimated 3 253 km2 and the river length is 162 4 km2 fig 1 the zhanyi and qilin districts as well as the luliang district upstream of the nanpan river see fig 1 where severe drought occurred frequently were selected as study areas 2 2 watershed swat model the data set included monthly mean rainfall runoff and soil moisture content series between 1991 and 2012 obtained from xiqiao hydrological station the digital elevation model dem with a 90 meter spatial resolution was derived from the geospatial data cloud http www gscloud cn sources and the land use data were obtained from the 2010 resource and environment data cloud platform these data were classified and converted to be recognizable in the swat model soil data 1 100 000 vector data were adopted from nanjing institute of soil science using the harmonized world soil database hwsd fao 2012 projection transformation and boundary cutting were conducted using arcgis 10 2 software esri usa daily observation data e g precipitation maximum and minimum temperature average wind speed average relative humidity and solar radiation were acquired from the china meteorological administration and the stations of the national meteorological bureaus fig 1 were used as meteorological input data in swat model the river basin features database was established based on the data described above the swat model was developed for the area above xiqiao hydrological station in the upper reaches of nanpan river during simulation the preheating period was set from 1990 to 1991 calibration period from 1992 to 2002 and verification period from 2003 to 2012 using measured monthly flow data from xiqiao hydrological station the model process was calibrated and verified in swat cup calibration and uncertainty procedures abbaspour et al 2015 using available observed discharge at the basin outlet the swat cup optimization algorithm sufi 2 was used to calibrate the model parameters azimi et al 2020 watershed stream networks and sub basins were generated using arcswat watershed analysis http swat tamu edu software arcswat in sufi 2 uncertainty was calculated from all the sources omer et al 2020 and 95 prediction uncertainty 95ppu was used to quantify the degree of the uncertainties of the parameters to evaluate the performance of the model the following statistical score metrics were used yaseen et al 2016 i the correlation coefficient r 2 expressed as equation 1 1 r 2 i 1 n q obs i q obs i q sim i q sim i 2 i 1 n q o b s i q o b s i 2 i 1 n q s i m i q s i m i 2 ii nash sutcliffe coefficient e ns expressed as equation 2 2 e ns 1 i 1 n q o b s i q s i m i 2 i 1 n q o b s i q o b s i 2 e ns 1 where q obs i and q sim i are the observed and simulated i t h value of the discharge respectively and n is the length of the time series q obs i and q sim i are average of observed and simulated q e ns equal to 1 corresponds to a perfect match of modelled to observed discharge data the monthly average soil moisture content e g 0 to 0 4 m depth of soil layer was simulated by the calibrated swat model 2 3 comprehensive drought indicator construction based on pca in this study pca bro and smilde 2014 was selected to develop an integrated drought characteristic index through dimensionality reduction synthesis and independence correlation between the three parameters e g precipitation runoff and soil moisture was considered for the idi model using pca to synthesize hydrological and meteorological parameters defined from equation 3 to 5 3 idi i 1 p ω i d i where linear combination d i was expressed as 4 d i v 1 p r v 2 r f v 3 s m where d i is the principal component i number of principal components p r is the standardized surface mean precipitation indicator r f is the standardized surface mean runoff indicator s m is the standardized surface mean soil moisture indicator and v 1 v 2 v 3 are eigenvectors in the variance covariance matrix for precipitation runoff and soil moisture the weighted coefficient ω i was calculated by 5 ω i g i i 1 p g i where ω i is the weighted coefficient of a principal component i and g i is the contribution rate of principal component i the idi can be calculated at the different temporal scales daily 10 15 days or monthly when insufficient soil moisture observation series occurs soil moisure should be simulated by the previously established swat model at the same time scales 2 4 drought process identification run theory zuo et al 2014 was used to identify the drought process using monthly relative anomaly data for precipitation runoff soil moisture and idi separately for drought identification we used the deviation of a single hydrological element and comprehensive drought index from a multi year average value during the same period monthly relative anomaly values for a single indicator were expressed as follows equation 6 6 p a p i j p j p j r a r i j r j r j s a s i j s j s j where p a r a s a are the relative precipitation runoff and soil moisture anomaly values respectively p i j r i j and s i j are precipitation runoff and soil moisture values of the ith year and jth month respectively finally i is the year number and j is the month number p j r j s j are multi year mean of three single indicators of the j th month respectively negative pa ra or sa values indicate precipitation runoff or soil moisture below average while the largest absolute value represents the greatest deviation from the mean the monthly relative idi anomaly value was calculated using equation 7 7 idi a idi i j idi j idi j where idi i j is the idi value of the ith year and jth month idi j is the multi year idi mean and idi a is the index relative anomaly negative idi a values denote results below average when idi a values remain below x 0 threshold for a consecutive number of months drought period is identified fig 2 drought duration d is the number of consecutive intervals months where idi a remains below the threshold value and drought severity s is the cumulative value of idi a within drought duration reddy and ganguli 2012 the following threshold values x 0 0 1 0 2 0 3 0 4 0 6 and 0 8 were used to identify drought processes these values were selected considering historical drought in the study area registered in the yunnan disaster reduction yearbook 1991 2012 the identified drought events were compared to historical drought in the yunnan disaster reduction yearbook the results showed in supplementary tables s1 s6 and fig 3 where 65 drought events were identified all of them below the 0 1 threshold level green line additionally 68 drought events were identified for x 0 0 2 59 for x 0 0 3 55 for x 0 0 4 37 for x 0 0 6 and 17 for x 0 0 8 from fig 3 less drought events were identified using the smaller truncation level and severe drought events could not be identified when truncation levels x 0 0 6 and x 0 0 8 were used such as the historical drought events described in the yunnan disaster reduction yearbook 1991 2012 like spring summer continuous drought of 1993 winter spring continuous drought of from 1995 to 1996 winter spring continuous drought of from 2007 to 2008 and winter spring continuous drought of from 2011 to 2012 more drought events were identified with x 0 0 1 x 0 0 2 x 0 0 3 and x 0 0 4 truncation level including all representative severe drought process described in the yunnan disaster reduction yearbook 1991 2012 from the 65 events identified 43 drought processes 66 showed less than average severity 0 81 using the x 0 0 1 truncation level 44 out of 68 events identified 64 showed drought severity less than average severity 0 59 using the x 0 0 2 truncation level total 59 events identified 36 drought processes 61 showed drought severity less than average severity of 0 5 with the truncation level of x 0 0 3 while a total of 55 events were identified only 28 drought processes 50 showed drought severity less than the average severity of 0 38 with the truncation level of x 0 0 4 as the above showed the identified drought events were almost mild drought using the truncation level of x 0 0 1 x 0 0 2 and x 0 0 3 then the truncation level of 0 4 was selected to identify the drought processes and the drought processes could be identified by three single indicators precipitation runoff and soil moisture and the idi from 1991 to 2012 respectively 2 5 drought characteristics and return period drought events differ from other extreme hydrological events with a long lasting interval affected by different weather conditions drought may last for years or occurs many times during the same year therefore the maximum sequence frequency analysis used in floods is not suitable for drought recurrence intervals to address this issue the ultra quantitative method was adopted shiau and shen 2001 defined droughts return period as duration greater than or equal to a certain value as a function of the expected drought inter arrival time and cumulative drought duration since both severity and duration play a significant role in drought assessment and management it is necessary to estimate the joint return period of drought characteristics to construct bivariate distribution for drought duration and severity series several probability distributions were considered e g weibull gamma lognormal pearson type iii and exponential distributions the best fit univariate marginal distributions for representing duration and severity were checked by the chi square χ 2 goodness of fit test and χ 2 value can be calculated by using equation 8 tosunoglu and can 2016 8 χ 2 k 1 n o k e k 2 e k where e k is the number of expected observations in the k th class interval determined by the distribution being tested o k is the observations number in the k th class interval and n is the class intervals number the distribution probability with minimum χ 2 value was chosen as the best distribution the copula based joint return period of drought duration d and severity s shiau and modarres 2009 were applied to develop bivariate probability distributions in this study three types of archimedean copulas frank gumbel hougaard and clayton were applied for modelling drought duration and severity bivariate joint distribution their performances for each region were evaluated based on the root mean square error rmse and q q plot kwon and lall 2016 the return period generally described as the number of arrivals per year t y was transformed from time return period t e into annual return period t y from the annual maximum sampling method using equation 9 maidment 1992 9 1 t y 1 exp 1 t e where t e values may be lower than t y because more than one event can occur per year equation 9 transforms the average arrival rate for events larger than d and s into the annual exceedance probability 1 t y transformed results were shown in table 1 for d and s values with t y 10 corresponding to infrequent events the annual exceedance probability 1 t y equals the average arrival rate e g t y t e this study focus on relatively rare drought events i e drought over 10 years regardless of whether the ultra quantitative method or the annual maximum method is adopted the results of drought frequency could be consistent 3 results 3 1 soil moisture simulation by swat model fig 4 showed reclassified land use and soil type distribution along the river basin the whole river basin was divided into 25 sub basins established by the swat model as shown in fig 5 after applying the arcswat hydrological response units hru module using 10 land use percentage over sub basin area 10 soil class percentage over the land use area and 10 slope class percentage over soil area a total of 216 hrus were obtained after the re arrangement the simulated and measured monthly runoff values during the calibration period 1992 2002 using the parameters outlined in table 2 were shown in table 3 and fig 6 from table 3 the simulated average monthly runoff was 36 3 m3 s with nash sutcliffe coefficient e ns 0 86 and correlation coefficient r 2 0 86 during the calibration period verification results are also shown in table 3 which includes the observed monthly runoff 19 08 m3 s during the verification period from 2003 to 2012 the simulated average monthly runoff mean was 22 71 m3 s with a correlation coefficient of 0 89 the nash sutcliffe coefficient e ns of simulated monthly runoff was 0 84 which met the model calibration requirements during calibration and verification periods the nash sutcliffe coefficient e ns and correlation coefficient r 2 of simulated monthly runoff were all above 0 8 suggesting swat model registered an acceptable simulation effect on monthly scale water balance 3 2 pca based idi according to pca the cumulative contribution rate of the first and second principal components for the zhanyi qilin and luliang regions were 89 3 90 9 and 89 3 respectively the cumulative contribution rate was over 85 suggesting the first two components comprehensively reflect the entire initial information then an integrated drought indicator reflecting comprehensive characteristics was included and summarized in table 4 as shown according to equations 3 to 5 the idi for zhanyi idi z is expressed as idi z 0 79 d 1 z 0 21 d 2 z d 1 z 0 57 p rz 0 61 r fz 0 55 s mz 10 d 2 z 0 63 p rz 0 10 r fz 0 77 s mz where d 1 z d 2 z are the first and second principal component of zhanyi respectively representing a linear combination of precipitation runoff and soil moisture p rz is the standardized mean surface precipitation data for zhanyi r fz is the standardized surface mean runoff data for zhanyi s mz is the standardized surface mean soil moisture data for zhanyi once standardized surface mean precipitation runoff and soil moisture data were obtained the idi for zhanyi was estimated similarly the idi for qilin i d i q and luliang i d i l were constructed expressed as follows equations 11 and 12 idi q 0 65 d 1 q 0 35 d 2 q d 1 q 0 69 p rq 0 70 r fq 0 23 s mq 11 d 2 q 0 18 p rq 0 14 r fq 0 97 s mq idi l 0 71 d 1 l 0 29 d 2 l d 1 l 0 62 p rl 0 64 r fl 0 45 s ml 12 d 2 l 0 37 p rl 0 26 r fl 0 89 s ml where d 1 q d 2 q are the first and second principal component for qilin respectively d 1 l d 2 l are the first and second principal components for luliang respectively the standardized surface mean precipitation p rq runoff r fq and soil moisture s mq data for qilin were obtained and the idi for qilin was assessed the same procedure was followed to generate idi for luliang 3 3 drought process identification 3 3 1 drought process identified by idi the drought process and characteristic variables of idi in the zhanyi region were included in supplementary material table s7 from table s7 32 drought events were identified with an average drought duration of 1 8 months the longest drought duration identified was 7 months and occurred from september 2009 to march 2010 event no 25 drought severity was estimated at 2 4 the second longest drought duration was 4 months from june to september of 1992 event no 2 for this event drought severity was found 1 1 other shorter drought duration events ranged from 1 to 3 months similarly the drought process at the qilin region 1991 2012 based on idi is shown in supplementary material table s8 from table s8 45 drought events were identified with an average drought duration of 2 4 months the longest drought duration event identified was 7 months from september 2002 to march 2003 event no 21 the second longest drought duration event was 6 months from december 1996 to may 1997 event no 12 the third longest drought duration event was 5 months including 3 drought events from july to november of 2009 event no 36 september 1998 to january 1999 event no 15 and november 2010 to march 2011 event no 40 other shorter drought duration events ranged from 1 to 4 months the drought severity in the qinlin region was cumulative worse than that identified for the zhanyi region the drought process for the luliang region was shown in supplementary material table s9 from table s9 42 drought events were identified with an average duration of 1 5 months the longest drought duration event identified was 8 months from august 2009 to march 2010 event no 37 and july 2011 to february 2012 event no 40 other shorter drought duration events ranged from 1 to 2 months 3 3 2 drought process identified by a single indicator 1 zhanyi from fig 7 58 drought events were identified using precipitation data all of them below the 0 4 threshold level green line in total 25 drought events were identified using the runoff indicator the longest drought lasted 12 months from june 2011 to may 2012 the second longest drought duration was 9 months from september 2009 to may 2010 suggesting the drought process from november 2009 to march 2010 continued based on the precipitation indicator the differences in time sequence affected by the precipitation and runoff variables and the lag of the runoff occurrence may be the reason for the discrepancy when soil moisture was used to identify the drought process 35 events were identified among them the longest drought lasted 10 months from august 2009 to may 2010 the second longest drought occurred from july 2010 to january 2011 2 qilin the monthly relative anomaly values of the single indicator for qilin are displayed in fig 8 as shown 54 droughts events were identified using the precipitation indicator below the 0 4 threshold level green line among them the longest drought event duration was 7 months from fig 8 42 drought processes were identified using the runoff indicator the longest drought lasted 18 months and the second longest drought event lasted 10 months droughts events lasting 5 to 7 months occurred twice while other drought events showed duration ranging 1 to 4 months there were 20 drought processes registered by the soil moisture indicator the longest duration was 12 months and one drought event with a duration of 6 months occurred from october 2009 to march 2010 3 luliang the monthly relative anomaly values of the single indicators for the luliang region are depicted in fig 9 as shown 55 drought events were identified using the precipitation indicator below the 0 4 threshold level green line the longest drought event duration was 5 months and one drought lasted 4 months other drought events with shorter durations 1 to 3 months were the most usual drought was less severe in the luliang region than qilin region from fig 9 45 drought events were identified using the runoff indicator among them the longest drought event recorded last 14 months april 2011 to may 2014 the second longest drought event amounted to 11 months july 2009 to may 2010 it is worth remarking that shorter duration droughts occurred several times a total of 41 drought processes were identified using the soil moisture indicator the longest drought duration was 9 months from september 2005 to may 2006 3 3 3 comparing different indicators for drought process drought events identified using different indicators were summarized and compared in table 5 as shown 32 drought events were identified using the idi in zhanyi within the minimum 25 and maximum 58 drought events described by runoff and precipitation respectively for qilin 45 drought events were identified using idi also between the minimum 20 and maximum 54 drought events described using soil moisture and precipitation respectively similarly 42 drought events were identified using idi in luliang between the minimum 20 and maximum 55 drought events identified using soil moisture and precipitation respectively the number of identified drought events using idi was between that of the single indicators which were consistent with the current drought description included in the yunnan disaster reduction yearbook 1991 2012 average drought duration estimated using idi was found between that obtained using single indicators average drought duration using runoff and soil moisture was longer than that estimated using precipitation probably because of runoff lag and infiltration according to the yunnan disaster reduction yearbook 1991 2012 the study area experienced the worst summer drought in 2011 which prolonged through the winter spring drought 2011 to 2012 table 5 showed that typical severe drought events described in the yearbook could be accurately identified using idi while drought events using single fails in accurately identifying these events consequently idi was found able to comprehensively describe real drought characteristics and accurately identified drought events from a hydrological cycle perspective 3 4 copula based drought frequency analysis 3 4 1 determining drought characteristics and return periods using idi drought characteristics for each region were identified using idi first the marginal distributions of drought duration and severity were fitted by weibull gamma lognormal pearson type iii and exponential distributions parameters of the distribution were estimated using the maximum likelihood estimation mle method and l moments ben nasr and chebana 2019 the best fit distributions for each region were identified using chi square χ 2 goodness of fit test and the results were shown in table 6 for α 0 05 exponential distribution was considered the best fit marginal distribution for duration series while pearson type iii distribution were selected as the most suitable marginal distribution for severity series the graphical evaluation by probability plots was shown in fig 10 then kendall s correlation coefficient τ of drought duration and severity were calculated to measure the dependency between drought duration and severity estimated τ values were shown in table 6 kendall s correlation coefficient τ of drought duration and severity were 0 72 0 67 and 0 64 for zhanyi qilin and luliang regions respectively three types of archimedean copulas e g frank gumbel hougaard clayton were applied for modelling drought duration and severity bivariate joint distribution the different performances for each region were evaluated based on root mean square error rmse table 7 as shown the gumbel hougaard copula generated the minimum value for all regions moreover the q q plot procedure was used to assess the performance of each copula the plot suggested that quantiles of the empirical and theoretical joint distribution were in agreement 95 confidence intervals around the line of perfect agreement 45 degree line yue et al 1999 based on the q q of the gumbel hougaard copula fig 11 it was the most suitable copula for representing drought duration and severity joint distribution in the regions based on the statistical and graphical test the gumbel hougaard copula was selected for representing the relationship between the drought duration and severity of each region since different combinations of correlated duration and severity variables can occur in the same period the contour lines are used to represent the return period tosunoglu and can 2016 using bivariate copulas these joint return periods of drought duration and severity can be derived and contours of different return periods 5 10 15 20 25 50 100 200 years recurrence intervals of bivariate drought variables were shown in fig 12 from fig 12 return periods of duration and severity ranging from 5 to 200 years can be found these results showed values as extreme as 7 months were much greater under this analysis reinforcing the extreme climate change effect on a recent event runoff data from qilin hydrological station fig 1 were used to represent its runoff variability data analysis showed smaller values than the outlet in the nanpan river suggesting the drought severity index was worse than those recorded for zhanyi and luliang regions 3 4 2 return period of a single indicator drought events and return period based on single indicators precipitation runoff and soil moisture were investigated for example looking at the zhanyi database fig 13 the joint return period derived using precipitation indicator was 50 years of duration and severity exceeding 3 months and 1 0 respectively however when runoff indicator was used 50 years of duration and severity exceeding 8 months and 2 0 were found and the same when soil moisture was used these results showed that the return period derived by precipitation was relatively longer than those obtained using runoff and soil moisture indicators with a certain duration and severity precipitation seems to be a more sensitive variable to describe drought characteristics due to the hydrological cycle meanwhile drought events identified using precipitation showed return period values shorter than 20 years compared to that estimated using runoff and soil moisture indicators 3 4 3 comparison of drought analysis by different indicators bivariate return periods of drought characteristics derived using idi and single indicators are summarized and compared in table 5 as shown the joint return periods of typical drought events 2011 2012 for each region varies from 5 to longer than 200 years recurrence intervals and the return period of summer drought and winter spring drought identified using idi was calculated between 37 and 102 years for the zhanyi region however the return period for summer drought events estimated using precipitation and soil moisture ranged 17 and 9 years while the runoff indicator could not describe the characteristics of summer drought separately also the return period for this winter spring drought event estimated using precipitation and runoff ranged 42 and 253 years the event by runoff combined with a long duration of 12 months due to the runoff lag these results were consistent with the actual drought characteristics consequently idi comprehensively describes drought characteristics provided by precipitation runoff and soil moisture indicators and can integrate drought reduction management from a water resources system perspective 4 discussion drought is among the worst natural disasters therefore detecting and following its evolution is of great importance to water resources and disaster risk management ahmadi and moradkhani 2019 from the hydrological cycle perspective multiple drought characterization will provide an extensive path about the spatial and temporal drought our results show different drought duration values when precipitation and runoff are used as single indicators probably because of differences in time sequence affected by variables of precipitation and runoff and the lag of the runoff drought duration values predicted using runoff and soil moisture were longer than those obtained when precipitation was used as the single indicator continuous drought durations based on runoff and soil moisture in qilin and luliang regions were relatively longer than the values for zhanyi region probably because the former two regions are located downstream in the basin and greatly affected by runoff events the results suggest that drought events are more significant downstream than upstream of the river basin this indicated that the drought duration could be comprehensively identified by the indicator composed by the precipitation runoff and soil moisture due to the runoff lag many contemporary drought indices for instance standardized precipitation index spi standardized precipitation evapotranspiration index spei palmer drought severity index pdsi and standardized runoff index sri are frequently used to quantify degrees of drought using different single or multiple observed variables it should be noted that the spi only reliant on precipitation other meteorological indices such as the spei and the pdsi considering the effects of evapotranspiration the sri only depending on runoff ho et al 2021 in addition these standardized drought indices over at least 1 month and have lead times of 1 to several months sutanto and van lanen 2021 however it is unclear how these indicators should be understood if the drought index time scale is not 1 month xu et al 2019 our study attempts to construct an idi using different variables of hydrological cycle precipitation runoff and soil moisture based on pca according to the definition and elaboration of the idi this indicator presents new opportunities to deal with short term drought events that last shorter than 1 month when the regions have sufficient data in parallel time scale sub daily or 10 15d to support such details in order to provide the driving force attribution of drought propagation further studies are required to quantify higher temporal resolution enable tracing the short time drought response ho et al 2021 besides the run theory underlays the identification of drought events and a sequence of drought events can be obtained using the hydrological variables and truncation level or threshold the threshold choice is the key procedure of drought identification below which drought events were predicted to occur previous studies gu et al 2019 jamro et al 2019 have shown that threshold can vary depending on the research interest region and available data the relatively low threshold in the range of 70 to 95 discharge is often used for perennial river sung and chung 2014 showed that percentile of the data can be used as the threshold and compared the of four threshold level methods fixed monthly daily and desired yield levels for water use liang et al 2016 proposed to use the maximum survey period of historical drought as a reference to determine the threshold and showed that the resulted maximum return period based on frequency analysis should not exceed the maximum survey period of historic drought razmkhah 2017 compared q70 and q90 and monthly level threshold approaches revealed that the q70 and q90 level durations and deficits were much higher than those from monthly from above the threshold can be fixed value or a seasonally or monthly varying level so the threshold in each time interval is somewhat arbitrary this will cause a certain uncertainty of the drought identification and drought frequency accordingly the truncation level of drought events should be crucially consistent with the regional current drought description however how to select an appropriate threshold level this study adopted the different threshold levels to identify drought processes and compared the identified drought events with the description of historical drought in the yunnan disaster reduction yearbook 1991 2012 current studies indicated that sensitivity analysis of fixed and variable thresholds seasonal monthly and daily in estimation of drought severities for various return periods and derivation of severity duration frequency sdf curves were investigated to select the suitable threshold which enable to capture abnormal drought events sung and chung 2014 sutanto and van lanen 2021 sarailidis et al 2019 so future work may focus on identifying the uncertainty of the threshold and take them into account due to the influence of different drought indicators on time series the calculation results of the drought return period were significantly diverse then the copula function was applied to analyze the drought frequency and the joint distribution function of drought duration and severity were established it is well known and confirmed that a combination of shorter duration and greater severity may result in a larger return period under the joint probability distributions meanwhile according to the drought frequency results calculated by the copula for the same drought process in the same region different return periods corresponded to different degrees of droughts similarly drought processes occurred in different regions in the same period due to differences in natural endowments such as different regional meteorology underlying conditions and socio economic development levels zhang et al 2015 and yang et al 2019 showed that higher drought frequency and the risk was observed in the middle parts and the northeast parts of yunnan province than those of other parts and spatial distributions of drought characteristics such as duration the severity of more frequent and less severe drought events were found to be different from those of less frequent and more severe droughts in the same period trends in theseat return periods are different at some locations ge et al 2016 since climate change has the potential to affect both precipitation and temperature variables of the hydrological cycle it can increase drought frequency and rainfall extremes over longer periods strzepek et al 2010 frequency changes for the 100 year droughts were more significant than those expected for the 2 and 20 year droughts in north america zhao et al 2020 there is a large uncertainty related to the extent of the global land area that will be impacted by enhanced climatological and hydrological droughts vicente serrano et al 2020 it has been well documented that climatic and hydrologic variables often exhibit non stationarity kwon and lall 2016 so future works should emphasize on drought evolutionary uncertainties associated with climate variability 5 conclusions this study provides a method for constructing drought indicators considering the physical process of the water cycle we confirm if there is a long series of observation data of soil moisture at the same time as precipitation and runoff the principal component analysis method can be directly used to construct comprehensive indicators it was possible without a long series of soil moisture observation data simulate the soil moisture content using the swat model first and then establish the comprehensive drought indicator the swat pca copula based methodology proposed in this study is confirmed to be a highly efficient and high precision approach for assessing drought frequency 1 considering the correlation between the elements of the hydrological cycle precipitation deficit led to a runoff deficit and two previous conditions resulted in a reduction of the soil moisture then pca was applied to convert a set of original variables namely precipitation runoff and soil moisture into less uncorrelated integrated variables idi 2 different threshold levels were used to identify drought processes and compared with the description of historical drought in the yunnan disaster reduction yearbook finally the truncation level of 0 4 was selected to identify the drought processes also the drought events were identified by the idi and single indicators and then compared the idi could comprehensively describe the real drought characteristics and can be recommended to accurately identify the comprehensive drought events from a hydrological cycle perspective 3 to define the univariate marginal distribution of duration and severity series for each region five widely used probability distributions were fitted according to the chi square χ 2 goodness of fit test the drought duration series were best described by exponential distribution while the severity series were best fitted by pearson type iii distribution and copulas were applied to develop the joint distributions and their performance was evaluated by statistical and graphical methods then gumbel copula which had the smaller rmse values provide the best fit for describing joint dependence of drought characteristics for each region and were used to estimate the probabilities of the drought characteristics the joint return periods of the various combinations of duration and severity series for each region the research showed that the idi could comprehensively describe the drought characteristics provided by the precipitation runoff and soil moisture indicators in conclusion the method can provide helpful information in drought monitor and drought strategies planning to reduce the effects of future drought in the watershed also the study can solve the interdependency between hydro meteorological variables of the hydrological cycle and improve our understanding of the drought evolution even in other regions over the world declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national natural science foundation of china grant number 51709151 the national key research and development project of china grant number 2017yfc0405606 yang yu received the young elite scientist sponsorship program by china association for science and technology 2017 to 2019 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127248 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3808,different indicators such as precipitation surface and groundwater availability vegetation and soil types are indispensable in developing land management plans for detecting monitoring and evaluating drought impacts at the watershed scale because of the complex interactions among these indicators it is well known that one single hydrometeorological variable would be unable to capture all the aspects of drought characteristics in this study a methodology based on principal component analysis pca copula was proposed to assess the frequency of different drought events and improve mitigation in watersheds a comprehensive approach for an integrated drought indicator idi was proposed using a combination of three hydrometeorological variables precipitation runoff and soil moisture based on pca and tested for the upstream nanpan river in china idi confirmed the cumulative contribution rate of the first and second principal components 85 and its design included simulation of monthly average soil moisture content from 0 to 0 4 meter soil layer using soil and water assessment tool swat model the parameters were calibrated using the sufi 2 optimization algorithm in swat cup then the idi relative anomaly characterization was used to identify drought processes based on the run theory two major drought characteristics duration and severity were abstracted from the observed drought events finally two dimensional copulas were applied for analyzing comprehensive drought characteristics in the region our results showed that significant differences in drought duration periods could be identified drought duration predicted by runoff and soil moisture were found longer than those assessed using the precipitation index idi suggest our proposed model was suitable to identify comprehensive drought events and describe the overall drought characteristics of the region in the same way pca copula methodology was found with high potential for drought analysis in areas where no previous studies have been performed keywords principal component analysis pca watershed management drought indicators hydrological model drought frequency 1 introduction drought is the shortage of water supply in a specific geographical area for a prolonged period affected by several factors such as precipitation evaporation runoff and soil moisture content rossi and cancelliere 2013 the magnitude and frequency of drought have dramatically increased over the last few decades coinciding with new evidence of climate change ipcc 2019 compared to other natural disasters the impact of droughts is non structural and could be much larger in terms of its spatial extent reddy and ganguli 2012 xu et al 2019 miralles et al 2019 it has been estimated that for the whole amount of extreme hydro meteorological events 22 of economic damages and 33 of affected inhabitants accounted are related to droughts belayneh et al 2014 receiving major attention and becoming a hotspot in water resources management and natural disaster study field drought indicators are indispensable tools to develop successful management plans for detecting monitoring and evaluating drought impact at the watershed scale bachmair et al 2015 it has been stated that one single indicator is not enough to adequately describe all aspects of droughts van lanen et al 2016 ahmadi and moradkhani 2019 highlighting the significance of integrated or multivariate indicators using different variables or indices guo et al 2019 hao and singh 2015 mazdiyasni and aghakouchak 2015 vicente serrano et al 2010 different scholars have developed indicators using hydro meteorological elements e g rainfall evaporation and runoff to analyze drought frequency leading to an inconsistent description or lack of standardization of the return period of drought events xu et al 2018 a drought event corresponds to one frequency and generating appropriate indicators for accurately estimating their onset severity and duration is a significant need to ensure effective mitigation measures and strategies for specific conditions for a comprehensive drought analysis it is appropriate considering multiple climatic and hydrologic variables at different scales to consistently and comparably determine their interdependent connection therefore considering the above mentioned background the main aim of this study is to propose a comprehensive approach for an integrated drought indicator idi combining three hydrometeorological variables e g precipitation runoff and soil moisture using the pca pca reduced original multiple variables into a few independent composite variables that reflect the inherent law of drought characteristics a pca copula based methodology is proposed for assessing the frequency of different drought events to improve their mitigation at the watershed scale the objectives of our study are to 1 develop a methodology for a comprehensive drought index based on the hydrological processes and use pca to solve the interdependency between hydro meteorological variables 2 simulate soil moisture using swat model for lacking long term observation data and 3 evaluate method s performance by comparing with results using a single index 2 materials and methods 2 1 study area the nanpan river 102 10 106 10 e 23 04 26 00 n which originates from the eastern foothills of the maxiong mountain in the aftermath of wumeng mountain qujing city yunnan province was selected as the study area in china it belongs to the xijiang river system of the pearl river basin and it is the main source of the pearl river the nanpan river drains an area of approximately 43 200 km2 the length of the river in yunnan is 655 km fig 1 the climate is primarily subtropical monsoonal with a mean annual precipitation of 1 070 mm and mean air temperature ranging 13 0 20 0 c because of the differences in topography and atmospheric circulation the spatial distribution of precipitation in the area is extremely uneven the central and western parts of the river basin are arid while the eastern part is a humid and rainy area the watershed is located in the lake basin and karst mountain area in eastern yunnan there are five main types of land uses e g agriculture forest grassland and urban areas and water bodies distributed in the watershed the xiqiao hydrological station was selected as the outlet of the experimental area to assess the drought events which is in the upstream nanpan river 103 33 104 09 e 25 01 25 56 n the controlled watershed area from the basin origin to xiqiao hydrological station has an estimated 3 253 km2 and the river length is 162 4 km2 fig 1 the zhanyi and qilin districts as well as the luliang district upstream of the nanpan river see fig 1 where severe drought occurred frequently were selected as study areas 2 2 watershed swat model the data set included monthly mean rainfall runoff and soil moisture content series between 1991 and 2012 obtained from xiqiao hydrological station the digital elevation model dem with a 90 meter spatial resolution was derived from the geospatial data cloud http www gscloud cn sources and the land use data were obtained from the 2010 resource and environment data cloud platform these data were classified and converted to be recognizable in the swat model soil data 1 100 000 vector data were adopted from nanjing institute of soil science using the harmonized world soil database hwsd fao 2012 projection transformation and boundary cutting were conducted using arcgis 10 2 software esri usa daily observation data e g precipitation maximum and minimum temperature average wind speed average relative humidity and solar radiation were acquired from the china meteorological administration and the stations of the national meteorological bureaus fig 1 were used as meteorological input data in swat model the river basin features database was established based on the data described above the swat model was developed for the area above xiqiao hydrological station in the upper reaches of nanpan river during simulation the preheating period was set from 1990 to 1991 calibration period from 1992 to 2002 and verification period from 2003 to 2012 using measured monthly flow data from xiqiao hydrological station the model process was calibrated and verified in swat cup calibration and uncertainty procedures abbaspour et al 2015 using available observed discharge at the basin outlet the swat cup optimization algorithm sufi 2 was used to calibrate the model parameters azimi et al 2020 watershed stream networks and sub basins were generated using arcswat watershed analysis http swat tamu edu software arcswat in sufi 2 uncertainty was calculated from all the sources omer et al 2020 and 95 prediction uncertainty 95ppu was used to quantify the degree of the uncertainties of the parameters to evaluate the performance of the model the following statistical score metrics were used yaseen et al 2016 i the correlation coefficient r 2 expressed as equation 1 1 r 2 i 1 n q obs i q obs i q sim i q sim i 2 i 1 n q o b s i q o b s i 2 i 1 n q s i m i q s i m i 2 ii nash sutcliffe coefficient e ns expressed as equation 2 2 e ns 1 i 1 n q o b s i q s i m i 2 i 1 n q o b s i q o b s i 2 e ns 1 where q obs i and q sim i are the observed and simulated i t h value of the discharge respectively and n is the length of the time series q obs i and q sim i are average of observed and simulated q e ns equal to 1 corresponds to a perfect match of modelled to observed discharge data the monthly average soil moisture content e g 0 to 0 4 m depth of soil layer was simulated by the calibrated swat model 2 3 comprehensive drought indicator construction based on pca in this study pca bro and smilde 2014 was selected to develop an integrated drought characteristic index through dimensionality reduction synthesis and independence correlation between the three parameters e g precipitation runoff and soil moisture was considered for the idi model using pca to synthesize hydrological and meteorological parameters defined from equation 3 to 5 3 idi i 1 p ω i d i where linear combination d i was expressed as 4 d i v 1 p r v 2 r f v 3 s m where d i is the principal component i number of principal components p r is the standardized surface mean precipitation indicator r f is the standardized surface mean runoff indicator s m is the standardized surface mean soil moisture indicator and v 1 v 2 v 3 are eigenvectors in the variance covariance matrix for precipitation runoff and soil moisture the weighted coefficient ω i was calculated by 5 ω i g i i 1 p g i where ω i is the weighted coefficient of a principal component i and g i is the contribution rate of principal component i the idi can be calculated at the different temporal scales daily 10 15 days or monthly when insufficient soil moisture observation series occurs soil moisure should be simulated by the previously established swat model at the same time scales 2 4 drought process identification run theory zuo et al 2014 was used to identify the drought process using monthly relative anomaly data for precipitation runoff soil moisture and idi separately for drought identification we used the deviation of a single hydrological element and comprehensive drought index from a multi year average value during the same period monthly relative anomaly values for a single indicator were expressed as follows equation 6 6 p a p i j p j p j r a r i j r j r j s a s i j s j s j where p a r a s a are the relative precipitation runoff and soil moisture anomaly values respectively p i j r i j and s i j are precipitation runoff and soil moisture values of the ith year and jth month respectively finally i is the year number and j is the month number p j r j s j are multi year mean of three single indicators of the j th month respectively negative pa ra or sa values indicate precipitation runoff or soil moisture below average while the largest absolute value represents the greatest deviation from the mean the monthly relative idi anomaly value was calculated using equation 7 7 idi a idi i j idi j idi j where idi i j is the idi value of the ith year and jth month idi j is the multi year idi mean and idi a is the index relative anomaly negative idi a values denote results below average when idi a values remain below x 0 threshold for a consecutive number of months drought period is identified fig 2 drought duration d is the number of consecutive intervals months where idi a remains below the threshold value and drought severity s is the cumulative value of idi a within drought duration reddy and ganguli 2012 the following threshold values x 0 0 1 0 2 0 3 0 4 0 6 and 0 8 were used to identify drought processes these values were selected considering historical drought in the study area registered in the yunnan disaster reduction yearbook 1991 2012 the identified drought events were compared to historical drought in the yunnan disaster reduction yearbook the results showed in supplementary tables s1 s6 and fig 3 where 65 drought events were identified all of them below the 0 1 threshold level green line additionally 68 drought events were identified for x 0 0 2 59 for x 0 0 3 55 for x 0 0 4 37 for x 0 0 6 and 17 for x 0 0 8 from fig 3 less drought events were identified using the smaller truncation level and severe drought events could not be identified when truncation levels x 0 0 6 and x 0 0 8 were used such as the historical drought events described in the yunnan disaster reduction yearbook 1991 2012 like spring summer continuous drought of 1993 winter spring continuous drought of from 1995 to 1996 winter spring continuous drought of from 2007 to 2008 and winter spring continuous drought of from 2011 to 2012 more drought events were identified with x 0 0 1 x 0 0 2 x 0 0 3 and x 0 0 4 truncation level including all representative severe drought process described in the yunnan disaster reduction yearbook 1991 2012 from the 65 events identified 43 drought processes 66 showed less than average severity 0 81 using the x 0 0 1 truncation level 44 out of 68 events identified 64 showed drought severity less than average severity 0 59 using the x 0 0 2 truncation level total 59 events identified 36 drought processes 61 showed drought severity less than average severity of 0 5 with the truncation level of x 0 0 3 while a total of 55 events were identified only 28 drought processes 50 showed drought severity less than the average severity of 0 38 with the truncation level of x 0 0 4 as the above showed the identified drought events were almost mild drought using the truncation level of x 0 0 1 x 0 0 2 and x 0 0 3 then the truncation level of 0 4 was selected to identify the drought processes and the drought processes could be identified by three single indicators precipitation runoff and soil moisture and the idi from 1991 to 2012 respectively 2 5 drought characteristics and return period drought events differ from other extreme hydrological events with a long lasting interval affected by different weather conditions drought may last for years or occurs many times during the same year therefore the maximum sequence frequency analysis used in floods is not suitable for drought recurrence intervals to address this issue the ultra quantitative method was adopted shiau and shen 2001 defined droughts return period as duration greater than or equal to a certain value as a function of the expected drought inter arrival time and cumulative drought duration since both severity and duration play a significant role in drought assessment and management it is necessary to estimate the joint return period of drought characteristics to construct bivariate distribution for drought duration and severity series several probability distributions were considered e g weibull gamma lognormal pearson type iii and exponential distributions the best fit univariate marginal distributions for representing duration and severity were checked by the chi square χ 2 goodness of fit test and χ 2 value can be calculated by using equation 8 tosunoglu and can 2016 8 χ 2 k 1 n o k e k 2 e k where e k is the number of expected observations in the k th class interval determined by the distribution being tested o k is the observations number in the k th class interval and n is the class intervals number the distribution probability with minimum χ 2 value was chosen as the best distribution the copula based joint return period of drought duration d and severity s shiau and modarres 2009 were applied to develop bivariate probability distributions in this study three types of archimedean copulas frank gumbel hougaard and clayton were applied for modelling drought duration and severity bivariate joint distribution their performances for each region were evaluated based on the root mean square error rmse and q q plot kwon and lall 2016 the return period generally described as the number of arrivals per year t y was transformed from time return period t e into annual return period t y from the annual maximum sampling method using equation 9 maidment 1992 9 1 t y 1 exp 1 t e where t e values may be lower than t y because more than one event can occur per year equation 9 transforms the average arrival rate for events larger than d and s into the annual exceedance probability 1 t y transformed results were shown in table 1 for d and s values with t y 10 corresponding to infrequent events the annual exceedance probability 1 t y equals the average arrival rate e g t y t e this study focus on relatively rare drought events i e drought over 10 years regardless of whether the ultra quantitative method or the annual maximum method is adopted the results of drought frequency could be consistent 3 results 3 1 soil moisture simulation by swat model fig 4 showed reclassified land use and soil type distribution along the river basin the whole river basin was divided into 25 sub basins established by the swat model as shown in fig 5 after applying the arcswat hydrological response units hru module using 10 land use percentage over sub basin area 10 soil class percentage over the land use area and 10 slope class percentage over soil area a total of 216 hrus were obtained after the re arrangement the simulated and measured monthly runoff values during the calibration period 1992 2002 using the parameters outlined in table 2 were shown in table 3 and fig 6 from table 3 the simulated average monthly runoff was 36 3 m3 s with nash sutcliffe coefficient e ns 0 86 and correlation coefficient r 2 0 86 during the calibration period verification results are also shown in table 3 which includes the observed monthly runoff 19 08 m3 s during the verification period from 2003 to 2012 the simulated average monthly runoff mean was 22 71 m3 s with a correlation coefficient of 0 89 the nash sutcliffe coefficient e ns of simulated monthly runoff was 0 84 which met the model calibration requirements during calibration and verification periods the nash sutcliffe coefficient e ns and correlation coefficient r 2 of simulated monthly runoff were all above 0 8 suggesting swat model registered an acceptable simulation effect on monthly scale water balance 3 2 pca based idi according to pca the cumulative contribution rate of the first and second principal components for the zhanyi qilin and luliang regions were 89 3 90 9 and 89 3 respectively the cumulative contribution rate was over 85 suggesting the first two components comprehensively reflect the entire initial information then an integrated drought indicator reflecting comprehensive characteristics was included and summarized in table 4 as shown according to equations 3 to 5 the idi for zhanyi idi z is expressed as idi z 0 79 d 1 z 0 21 d 2 z d 1 z 0 57 p rz 0 61 r fz 0 55 s mz 10 d 2 z 0 63 p rz 0 10 r fz 0 77 s mz where d 1 z d 2 z are the first and second principal component of zhanyi respectively representing a linear combination of precipitation runoff and soil moisture p rz is the standardized mean surface precipitation data for zhanyi r fz is the standardized surface mean runoff data for zhanyi s mz is the standardized surface mean soil moisture data for zhanyi once standardized surface mean precipitation runoff and soil moisture data were obtained the idi for zhanyi was estimated similarly the idi for qilin i d i q and luliang i d i l were constructed expressed as follows equations 11 and 12 idi q 0 65 d 1 q 0 35 d 2 q d 1 q 0 69 p rq 0 70 r fq 0 23 s mq 11 d 2 q 0 18 p rq 0 14 r fq 0 97 s mq idi l 0 71 d 1 l 0 29 d 2 l d 1 l 0 62 p rl 0 64 r fl 0 45 s ml 12 d 2 l 0 37 p rl 0 26 r fl 0 89 s ml where d 1 q d 2 q are the first and second principal component for qilin respectively d 1 l d 2 l are the first and second principal components for luliang respectively the standardized surface mean precipitation p rq runoff r fq and soil moisture s mq data for qilin were obtained and the idi for qilin was assessed the same procedure was followed to generate idi for luliang 3 3 drought process identification 3 3 1 drought process identified by idi the drought process and characteristic variables of idi in the zhanyi region were included in supplementary material table s7 from table s7 32 drought events were identified with an average drought duration of 1 8 months the longest drought duration identified was 7 months and occurred from september 2009 to march 2010 event no 25 drought severity was estimated at 2 4 the second longest drought duration was 4 months from june to september of 1992 event no 2 for this event drought severity was found 1 1 other shorter drought duration events ranged from 1 to 3 months similarly the drought process at the qilin region 1991 2012 based on idi is shown in supplementary material table s8 from table s8 45 drought events were identified with an average drought duration of 2 4 months the longest drought duration event identified was 7 months from september 2002 to march 2003 event no 21 the second longest drought duration event was 6 months from december 1996 to may 1997 event no 12 the third longest drought duration event was 5 months including 3 drought events from july to november of 2009 event no 36 september 1998 to january 1999 event no 15 and november 2010 to march 2011 event no 40 other shorter drought duration events ranged from 1 to 4 months the drought severity in the qinlin region was cumulative worse than that identified for the zhanyi region the drought process for the luliang region was shown in supplementary material table s9 from table s9 42 drought events were identified with an average duration of 1 5 months the longest drought duration event identified was 8 months from august 2009 to march 2010 event no 37 and july 2011 to february 2012 event no 40 other shorter drought duration events ranged from 1 to 2 months 3 3 2 drought process identified by a single indicator 1 zhanyi from fig 7 58 drought events were identified using precipitation data all of them below the 0 4 threshold level green line in total 25 drought events were identified using the runoff indicator the longest drought lasted 12 months from june 2011 to may 2012 the second longest drought duration was 9 months from september 2009 to may 2010 suggesting the drought process from november 2009 to march 2010 continued based on the precipitation indicator the differences in time sequence affected by the precipitation and runoff variables and the lag of the runoff occurrence may be the reason for the discrepancy when soil moisture was used to identify the drought process 35 events were identified among them the longest drought lasted 10 months from august 2009 to may 2010 the second longest drought occurred from july 2010 to january 2011 2 qilin the monthly relative anomaly values of the single indicator for qilin are displayed in fig 8 as shown 54 droughts events were identified using the precipitation indicator below the 0 4 threshold level green line among them the longest drought event duration was 7 months from fig 8 42 drought processes were identified using the runoff indicator the longest drought lasted 18 months and the second longest drought event lasted 10 months droughts events lasting 5 to 7 months occurred twice while other drought events showed duration ranging 1 to 4 months there were 20 drought processes registered by the soil moisture indicator the longest duration was 12 months and one drought event with a duration of 6 months occurred from october 2009 to march 2010 3 luliang the monthly relative anomaly values of the single indicators for the luliang region are depicted in fig 9 as shown 55 drought events were identified using the precipitation indicator below the 0 4 threshold level green line the longest drought event duration was 5 months and one drought lasted 4 months other drought events with shorter durations 1 to 3 months were the most usual drought was less severe in the luliang region than qilin region from fig 9 45 drought events were identified using the runoff indicator among them the longest drought event recorded last 14 months april 2011 to may 2014 the second longest drought event amounted to 11 months july 2009 to may 2010 it is worth remarking that shorter duration droughts occurred several times a total of 41 drought processes were identified using the soil moisture indicator the longest drought duration was 9 months from september 2005 to may 2006 3 3 3 comparing different indicators for drought process drought events identified using different indicators were summarized and compared in table 5 as shown 32 drought events were identified using the idi in zhanyi within the minimum 25 and maximum 58 drought events described by runoff and precipitation respectively for qilin 45 drought events were identified using idi also between the minimum 20 and maximum 54 drought events described using soil moisture and precipitation respectively similarly 42 drought events were identified using idi in luliang between the minimum 20 and maximum 55 drought events identified using soil moisture and precipitation respectively the number of identified drought events using idi was between that of the single indicators which were consistent with the current drought description included in the yunnan disaster reduction yearbook 1991 2012 average drought duration estimated using idi was found between that obtained using single indicators average drought duration using runoff and soil moisture was longer than that estimated using precipitation probably because of runoff lag and infiltration according to the yunnan disaster reduction yearbook 1991 2012 the study area experienced the worst summer drought in 2011 which prolonged through the winter spring drought 2011 to 2012 table 5 showed that typical severe drought events described in the yearbook could be accurately identified using idi while drought events using single fails in accurately identifying these events consequently idi was found able to comprehensively describe real drought characteristics and accurately identified drought events from a hydrological cycle perspective 3 4 copula based drought frequency analysis 3 4 1 determining drought characteristics and return periods using idi drought characteristics for each region were identified using idi first the marginal distributions of drought duration and severity were fitted by weibull gamma lognormal pearson type iii and exponential distributions parameters of the distribution were estimated using the maximum likelihood estimation mle method and l moments ben nasr and chebana 2019 the best fit distributions for each region were identified using chi square χ 2 goodness of fit test and the results were shown in table 6 for α 0 05 exponential distribution was considered the best fit marginal distribution for duration series while pearson type iii distribution were selected as the most suitable marginal distribution for severity series the graphical evaluation by probability plots was shown in fig 10 then kendall s correlation coefficient τ of drought duration and severity were calculated to measure the dependency between drought duration and severity estimated τ values were shown in table 6 kendall s correlation coefficient τ of drought duration and severity were 0 72 0 67 and 0 64 for zhanyi qilin and luliang regions respectively three types of archimedean copulas e g frank gumbel hougaard clayton were applied for modelling drought duration and severity bivariate joint distribution the different performances for each region were evaluated based on root mean square error rmse table 7 as shown the gumbel hougaard copula generated the minimum value for all regions moreover the q q plot procedure was used to assess the performance of each copula the plot suggested that quantiles of the empirical and theoretical joint distribution were in agreement 95 confidence intervals around the line of perfect agreement 45 degree line yue et al 1999 based on the q q of the gumbel hougaard copula fig 11 it was the most suitable copula for representing drought duration and severity joint distribution in the regions based on the statistical and graphical test the gumbel hougaard copula was selected for representing the relationship between the drought duration and severity of each region since different combinations of correlated duration and severity variables can occur in the same period the contour lines are used to represent the return period tosunoglu and can 2016 using bivariate copulas these joint return periods of drought duration and severity can be derived and contours of different return periods 5 10 15 20 25 50 100 200 years recurrence intervals of bivariate drought variables were shown in fig 12 from fig 12 return periods of duration and severity ranging from 5 to 200 years can be found these results showed values as extreme as 7 months were much greater under this analysis reinforcing the extreme climate change effect on a recent event runoff data from qilin hydrological station fig 1 were used to represent its runoff variability data analysis showed smaller values than the outlet in the nanpan river suggesting the drought severity index was worse than those recorded for zhanyi and luliang regions 3 4 2 return period of a single indicator drought events and return period based on single indicators precipitation runoff and soil moisture were investigated for example looking at the zhanyi database fig 13 the joint return period derived using precipitation indicator was 50 years of duration and severity exceeding 3 months and 1 0 respectively however when runoff indicator was used 50 years of duration and severity exceeding 8 months and 2 0 were found and the same when soil moisture was used these results showed that the return period derived by precipitation was relatively longer than those obtained using runoff and soil moisture indicators with a certain duration and severity precipitation seems to be a more sensitive variable to describe drought characteristics due to the hydrological cycle meanwhile drought events identified using precipitation showed return period values shorter than 20 years compared to that estimated using runoff and soil moisture indicators 3 4 3 comparison of drought analysis by different indicators bivariate return periods of drought characteristics derived using idi and single indicators are summarized and compared in table 5 as shown the joint return periods of typical drought events 2011 2012 for each region varies from 5 to longer than 200 years recurrence intervals and the return period of summer drought and winter spring drought identified using idi was calculated between 37 and 102 years for the zhanyi region however the return period for summer drought events estimated using precipitation and soil moisture ranged 17 and 9 years while the runoff indicator could not describe the characteristics of summer drought separately also the return period for this winter spring drought event estimated using precipitation and runoff ranged 42 and 253 years the event by runoff combined with a long duration of 12 months due to the runoff lag these results were consistent with the actual drought characteristics consequently idi comprehensively describes drought characteristics provided by precipitation runoff and soil moisture indicators and can integrate drought reduction management from a water resources system perspective 4 discussion drought is among the worst natural disasters therefore detecting and following its evolution is of great importance to water resources and disaster risk management ahmadi and moradkhani 2019 from the hydrological cycle perspective multiple drought characterization will provide an extensive path about the spatial and temporal drought our results show different drought duration values when precipitation and runoff are used as single indicators probably because of differences in time sequence affected by variables of precipitation and runoff and the lag of the runoff drought duration values predicted using runoff and soil moisture were longer than those obtained when precipitation was used as the single indicator continuous drought durations based on runoff and soil moisture in qilin and luliang regions were relatively longer than the values for zhanyi region probably because the former two regions are located downstream in the basin and greatly affected by runoff events the results suggest that drought events are more significant downstream than upstream of the river basin this indicated that the drought duration could be comprehensively identified by the indicator composed by the precipitation runoff and soil moisture due to the runoff lag many contemporary drought indices for instance standardized precipitation index spi standardized precipitation evapotranspiration index spei palmer drought severity index pdsi and standardized runoff index sri are frequently used to quantify degrees of drought using different single or multiple observed variables it should be noted that the spi only reliant on precipitation other meteorological indices such as the spei and the pdsi considering the effects of evapotranspiration the sri only depending on runoff ho et al 2021 in addition these standardized drought indices over at least 1 month and have lead times of 1 to several months sutanto and van lanen 2021 however it is unclear how these indicators should be understood if the drought index time scale is not 1 month xu et al 2019 our study attempts to construct an idi using different variables of hydrological cycle precipitation runoff and soil moisture based on pca according to the definition and elaboration of the idi this indicator presents new opportunities to deal with short term drought events that last shorter than 1 month when the regions have sufficient data in parallel time scale sub daily or 10 15d to support such details in order to provide the driving force attribution of drought propagation further studies are required to quantify higher temporal resolution enable tracing the short time drought response ho et al 2021 besides the run theory underlays the identification of drought events and a sequence of drought events can be obtained using the hydrological variables and truncation level or threshold the threshold choice is the key procedure of drought identification below which drought events were predicted to occur previous studies gu et al 2019 jamro et al 2019 have shown that threshold can vary depending on the research interest region and available data the relatively low threshold in the range of 70 to 95 discharge is often used for perennial river sung and chung 2014 showed that percentile of the data can be used as the threshold and compared the of four threshold level methods fixed monthly daily and desired yield levels for water use liang et al 2016 proposed to use the maximum survey period of historical drought as a reference to determine the threshold and showed that the resulted maximum return period based on frequency analysis should not exceed the maximum survey period of historic drought razmkhah 2017 compared q70 and q90 and monthly level threshold approaches revealed that the q70 and q90 level durations and deficits were much higher than those from monthly from above the threshold can be fixed value or a seasonally or monthly varying level so the threshold in each time interval is somewhat arbitrary this will cause a certain uncertainty of the drought identification and drought frequency accordingly the truncation level of drought events should be crucially consistent with the regional current drought description however how to select an appropriate threshold level this study adopted the different threshold levels to identify drought processes and compared the identified drought events with the description of historical drought in the yunnan disaster reduction yearbook 1991 2012 current studies indicated that sensitivity analysis of fixed and variable thresholds seasonal monthly and daily in estimation of drought severities for various return periods and derivation of severity duration frequency sdf curves were investigated to select the suitable threshold which enable to capture abnormal drought events sung and chung 2014 sutanto and van lanen 2021 sarailidis et al 2019 so future work may focus on identifying the uncertainty of the threshold and take them into account due to the influence of different drought indicators on time series the calculation results of the drought return period were significantly diverse then the copula function was applied to analyze the drought frequency and the joint distribution function of drought duration and severity were established it is well known and confirmed that a combination of shorter duration and greater severity may result in a larger return period under the joint probability distributions meanwhile according to the drought frequency results calculated by the copula for the same drought process in the same region different return periods corresponded to different degrees of droughts similarly drought processes occurred in different regions in the same period due to differences in natural endowments such as different regional meteorology underlying conditions and socio economic development levels zhang et al 2015 and yang et al 2019 showed that higher drought frequency and the risk was observed in the middle parts and the northeast parts of yunnan province than those of other parts and spatial distributions of drought characteristics such as duration the severity of more frequent and less severe drought events were found to be different from those of less frequent and more severe droughts in the same period trends in theseat return periods are different at some locations ge et al 2016 since climate change has the potential to affect both precipitation and temperature variables of the hydrological cycle it can increase drought frequency and rainfall extremes over longer periods strzepek et al 2010 frequency changes for the 100 year droughts were more significant than those expected for the 2 and 20 year droughts in north america zhao et al 2020 there is a large uncertainty related to the extent of the global land area that will be impacted by enhanced climatological and hydrological droughts vicente serrano et al 2020 it has been well documented that climatic and hydrologic variables often exhibit non stationarity kwon and lall 2016 so future works should emphasize on drought evolutionary uncertainties associated with climate variability 5 conclusions this study provides a method for constructing drought indicators considering the physical process of the water cycle we confirm if there is a long series of observation data of soil moisture at the same time as precipitation and runoff the principal component analysis method can be directly used to construct comprehensive indicators it was possible without a long series of soil moisture observation data simulate the soil moisture content using the swat model first and then establish the comprehensive drought indicator the swat pca copula based methodology proposed in this study is confirmed to be a highly efficient and high precision approach for assessing drought frequency 1 considering the correlation between the elements of the hydrological cycle precipitation deficit led to a runoff deficit and two previous conditions resulted in a reduction of the soil moisture then pca was applied to convert a set of original variables namely precipitation runoff and soil moisture into less uncorrelated integrated variables idi 2 different threshold levels were used to identify drought processes and compared with the description of historical drought in the yunnan disaster reduction yearbook finally the truncation level of 0 4 was selected to identify the drought processes also the drought events were identified by the idi and single indicators and then compared the idi could comprehensively describe the real drought characteristics and can be recommended to accurately identify the comprehensive drought events from a hydrological cycle perspective 3 to define the univariate marginal distribution of duration and severity series for each region five widely used probability distributions were fitted according to the chi square χ 2 goodness of fit test the drought duration series were best described by exponential distribution while the severity series were best fitted by pearson type iii distribution and copulas were applied to develop the joint distributions and their performance was evaluated by statistical and graphical methods then gumbel copula which had the smaller rmse values provide the best fit for describing joint dependence of drought characteristics for each region and were used to estimate the probabilities of the drought characteristics the joint return periods of the various combinations of duration and severity series for each region the research showed that the idi could comprehensively describe the drought characteristics provided by the precipitation runoff and soil moisture indicators in conclusion the method can provide helpful information in drought monitor and drought strategies planning to reduce the effects of future drought in the watershed also the study can solve the interdependency between hydro meteorological variables of the hydrological cycle and improve our understanding of the drought evolution even in other regions over the world declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this work was supported by the national natural science foundation of china grant number 51709151 the national key research and development project of china grant number 2017yfc0405606 yang yu received the young elite scientist sponsorship program by china association for science and technology 2017 to 2019 appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127248 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3809,accurate remotely sensed snow depth sd data are essential for monitoring and modeling hydrological processes in cold regions while the available passive microwave sd data have been widely used by the community the coarse spatial resolution typically at 0 25 of these data impedes the explicit representation of the hydrological processes in snow dominated regions especially in mountainous regions with complex terrain to improve the spatial resolution and quality of passive microwave sd data for the tibetan plateau tp we develop a spatial temporal downscaling method to produce a 19 year daily 0 05 sd product by combining the existing high temporal resolution daily sd data and the high spatial resolution 8 day cloud free moderate resolution imaging spectroradiometer modis based snow cover probability scp data the latter of which were produced using an new advanced temporal filter algorithm validations against the observed sd data from 92 meteorological stations suggest that the newly developed 0 05 sd product greatly improves upon the original 0 25 version based on this 0 05 sd product we found that higher sd values are mainly distributed on the southeastern and eastern tp as well as the himalaya and karakoram while much lower sd values occur on the inner tp during 2000 2018 the tp averaged annual sd showed a slight p 0 05 increasing trend because there were little changes in sd for most grids across the tp regarding different basins within tp the annual sd during 2000 2018 slightly increased over most basins except for the amu dayra ganges brahmaputra and inner tp where the basin scale sd showed insignificant decreasing tendencies in general the spatial temporal variations in the sd across the tp were very heterogeneous because sd was affected by multiple climatic factors the newly developed 0 05 sd product could facilitate our understanding of the hydrological processes on the tp through a more explicit representation of the gridded based snow water information keywords snow depth downscaling snow cover probability tibetan plateau 1 introduction snow is a key component of the hydrological cycle and an important indicator of climate change pulliainen et al 2020 musselman et al 2021 it also plays a key role in the energy balance because of its strong effect on the surface albedo and soil temperature thereby modulating the local and regional weather and climate henderson et al 2018 jia et al 2021 you et al 2020 as the snowpack can store a large amount of the precipitation that falls during the cold season it also plays a vital role in the spring runoff formulation barnett et al 2005 huning and aghakouchak 2020 impacting the downstream agricultural production which relies on irrigation qin et al 2020 the snow depth sd is the most important variable that describes the amount of snow for a given region kinar and pomeroy 2015 matiu et al 2021 hence reliable high quality sd datasets are essential for the above applications related to the weather and climate water resource management and flood monitoring in cold regions several approaches have been extensively used to monitor the sd including field observations land surface modeling optical remote sensing and passive microwave remote sensing although meteorological stations can provide accurate sd observation data for a long time series ma et al 2020 matiu et al 2021 the number of stations in mountainous regions where the snow often occurs remains low lundquist et al 2019 impeding the understanding of snow dynamics in high elevation areas in terms of the model based sd estimates including the lumped conceptual models e g snow 17 model and the physically based land surface models e g those from the global land data assimilation system version 2 1 the uncertainties in the modeling forcing and the parameters may bring potential errors in regional scale sd estimation which is especially true for remote areas where ground observed meteorological data are very sparse bian et al 2019 ma et al 2020 while certain atmospheric reanalysis data e g the japanese 55 year reanalysis jra 55 has also assimilated the ground observations in deriving the gridded sd data they are typically at the relatively coarse spatial resolutions with an order of 0 5 or larger bian et al 2020 orsolini et al 2019 although snow cover information can be extracted from optical remote sensing data under clear sky conditions hall and riggs 2007 bhatti et al 2016 zhang et al 2014 it is difficult to estimate the sd using the visible and infrared bands dai et al 2018 with the rapid development of passive remote sensing over the last four decades this technique has become widely used for detecting sd information by taking advantage of the difference in the microwave brightness temperature at different frequencies regardless of cloud contamination since the 1970s chang et al 1987 che et al 2008 liang et al 2015 tait 1998 tedesco et al 2004 this is because the deeper the snowpack is the more positive the microwave energy difference detected between the horizontally polarized brightness temperatures of the 19 or 18 ghz and 37 or 36 ghz bands kelly et al 2003 che et al 2008 xiao et al 2018 previous studies have dedicated much effort to developing and calibrating numerous sd estimation algorithms for use with passive microwave remote sensing data for example the relationship between the sd and the brightness temperature gradients of the 18 and 37 ghz bands was used for sd retrievals from nimbus 7 scanning multichannel microwave radiometer smmr data chang et al 1987 considering the effects of forested areas and crystal size on sd estimation foster et al 1997 presented an algorithm to improve the original one proposed by chang et al 1987 for north america and eurasia the chang et al 1987 algorithm was also adjusted to consider several factors influencing the sd retrieval to achieve a more accurate result in china che et al 2008 this valuable effort produced a chinese long term sd dataset based on this algorithm for the last four decades using three passive microwave remote sensing sensors i e the smmr special sensor microwave imager ssm i and special sensor microwave imager sounder ssmi s che et al 2008 dai et al 2015 dai et al 2017 although the microwave remote sensing sd data allow us to eliminate cloud contamination its coarse spatial resolution mostly at 0 25 is too coarse to capture the fine scale characteristics of sd which is especially true in mountainous areas with a complex terrain in addition the coarse resolution of such sd products is not adequate for hydrological modeling studies in small watersheds where the runoff is often simulated at the kilometer scale the combination of optical snow cover products and microwave snow products is an important step in developing accurate snow cover and sd products to mitigate the uncertainty of microwave remote sensing snow products e g sd and snow water equivalent due to its low spatial resolution it may be preferable to blend the existing coarse resolution microwave remote sensing sd products and other auxiliary datasets with higher spatial resolutions to improve the spatial resolution of the sd product to this end various types of snow cover information e g binarized snow cover fractional snow cover and annual snow cover duration usually have much higher spatial resolutions and thus are widely used to enhance passive microwave snow products gao et al 2010 tang et al 2016 huang et al 2016 dai et al 2018 wei et al 2021 the three main factors derived from the optical based snow cover information were used to enhance the coarse resolution microwave sd and snow water equivalent datasets first a binarized snow cover image was used gao et al 2010 redistributed the snow water equivalent information using the number of snow covered pixels from the moderate resolution imaging spectroradiometer modis data in a passive microwave pixel however a binarized snow cover image classified using a threshold tends to underestimate patchy snow cover information to a large extent zhang et al 2019 thus compared to the binarized snow cover the fractional snow cover should be given priority to enhance the coarse resolution microwave sd second the spatial information about the daily fractional snow cover was used tang et al 2016 used a daily fractional snow cover product to enhance the daily microwave sd data based on the strong relationship between these two snow parameters by combining ground emissivity land surface temperature and fractional snow cover the sd data was further improved using a novel spatial dynamic method with a higher spatial resolution on the tp dai et al 2018 however the accuracy of the daily snow cover product is largely affected by cloud cover zhang et al 2019 third the annual snow cover duration was used mhawej et al 2014 huang et al 2016 wang et al 2019 wei et al 2021 because there is a strong relationship between the snow cover duration and the sd during a given year the annual snow cover duration obtained from modis data was introduced to redistribute the microwave snow water equivalent data mhawej et al 2014 and the sd data huang et al 2016 the relationships between the sd and several factors e g longitude latitude terrain and snow cover duration were built using multi factor regression models in order to reconstruct the high resolution sd products wang et al 2019 wei et al 2021 however using the annual snow cover duration to reconstruct the daily passive microwave sd pixels is problematic because of the temporal difference while progress in downscaling the sd snow water equivalent has been made by taking advantage of more factors less attention has been paid to enhancing the sd product by taking advantage of the high spatial resolution modis snow cover probability scp product in previous studies in short neither the annual snow cover duration nor the daily snow cover product e g the binarized snow cover and fractional snow cover are suitable for use as a downscaling factor to produce sd datasets with high temporal spatial resolutions the utilization of the modis scp information during several days can provide new opportunities thereby improving the spatial resolution of the passive microwave sd data with an average altitude higher than 4000 m above sea level a s l the tibetan plateau tp is the source region of several major asian rivers including the indus ganges brahmaputra salween mekong yellow and yangtze rivers fig 1 which is therefore known as the asian water tower immerzeel et al 2010 in this context snow is extremely important because it is one of the key water resources that supply 1 6 billion people downstream in china india pakistan nepal bhutan and bangladesh immerzeel et al 2020 however in situ observations of snow information are particularly sparse on the tp because of its complex terrain and harsh climate ma et al 2020 for this reason satellite observed sd products for the tp have attracted increasing attention because of their ability to estimate the snow water resources in this inaccessible region with formidable natural conditions tang et al 2016 xiong et al 2017 zhang and ma 2018 however the development of high resolution both spatially and temporally remote sensing sd data in the tibetan plateau is challenging because of its heterogeneous landscape and scarce ground observations bian et al 2019 orsolini et al 2019 having recognized this need the objectives of this study are i to develop a spatiotemporal downscaling method by taking advantage of the spatial information of the 0 05 modis scp and the temporal information of the daily passive microwave sd during an 8 day period to produce a finer resolution i e 0 05 sd product across the tp ii to determine whether the accuracy of this newly developed 0 05 sd product is better than that of the previous coarse resolution sd dataset and iii to investigate the spatial and temporal variations in sd over tp during the last two decades 2 data 2 1 fractional snow cover and clear index the modis snow cover data version 006 from 2000 to 2018 from the terra mod10c1 and aqua myd10c1 satellites were downloaded hall and riggs 2016 accessible from the national snow and ice data center nsidc http nsidc org the spatial and temporal resolutions are 0 05 and daily respectively hall et al 2002 both datasets are comprised of three sub datasets i e the fractional snow cover fsc cloud obscuration percentage and clear index ci data ranging from 0 to 100 each sub dataset of the modis snow cover data includes the following categories lake ice inland water ocean cloud obscured water data not mapped and data filled table 1 because lake ice inland water ocean and cloud obscured water have no snow cover information these variables were reclassified to 100 in the clear index data the data that were not mapped and the filled data were considered as cloud cover so they were reclassified to 0 in clear index data the fsc and ci were calculated as follows hall et al 1995 salomonson and appel 2006 hall and riggs 2016 1 f s c t e r r a 1 45 ρ g r e e n ρ s w i r 1 ρ g r e e n ρ s w i r 1 0 01 where fscterra is the fractional snow cover obtained using the modis terra instrument ρgreen is the reflectance of the green band and ρswir1 is the reflectance of the swir1 band 2 f s c a q u a 1 91 ρ g r e e n ρ s w i r 2 ρ g r e e n ρ s w i r 2 0 64 where fscaqua is the fractional snow cover obtained using the modis aqua instrument ρgreen is the reflectance of the green band and ρswir2 is the reflectance of the swir2 band 3 c i 1 f c c where ci is the daily clear index data and fcc is the daily fractional cloud cover 2 2 gridded sd product the long term daily 0 25 sd dataset from 2000 to 2018 was downloaded from the national tibetan plateau data center https data tpdc ac cn zh hans this dataset was obtained by the smmr ssm i and ssmi s che et al 2008 che 2015 dai et al 2015 dai et al 2017 to improve the consistency of the passive microwave remote sensing data derived from the various sensors the brightness temperature data derived from these instruments smmr ssm i and ssmi s were cross calibrated dai et al 2015 this sd dataset has long been regarded as the most accurate snow depth estimation for china and thus has been widely used not only in previous studies related to sd downscaling huang et al 2016 tang et al 2016 wei et al 2021 but also in understanding the effects of snow changes on regional runoff xu et al 2009 and that on vegetation dynamics yu et al 2013 2 3 ground measured sd data from meteorological stations the daily sd data during 2000 2010 observed at 92 meteorological stations fig 1 of the china meteorological administration were used as the ground truth values for assessing the accuracy of the gridded sd product wang and wan 2018 with elevations ranging from 1000 to 4800 m above sea level most meteorological stations are located on the southern and eastern parts of the tp the in situ sd measurements are the most accurate record of the sd and therefore they are widely used for evaluating not only satellite based sd products tang et al 2016 but also the snow products in reanalysis over the tp orsolini et al 2019 3 method 3 1 definition of the snow hydrological year according to the seasonal cycle of the sd in tp the lowest monthly mean sd occurs in september over the tp therefore the snow year was defined as september 1 to august 31 of the following year for example the snow year of 2000 was from september 1 of 2000 to august 31 of 2001 it should be noted that all analyses in the present study are based on the snow year instead of the calendar year 3 2 cloud removal method for estimating the spatial probability of the snow cover cloud contamination of optical remote sensing products greatly limits the usage of daily modis snow cover datasets to remove the clouds from the original modis snow cover product the ratio of the number of snow pixels to the number of cloud free pixels during a 15 day period was used to estimate the spatial probability of the snow cover by combining the regional snowline and an elevation zone with a 100 m interval li et al 2017 however the snow pixels were identified via binarization processing of the normalized difference snow index ndsi image data with a specific threshold on the regional scale which causes uncertainties in estimating the area of the snow cover zhang et al 2019 to achieve a more accurate spatial probability of snow the binary snow images with snow pixels and non snow pixels were replaced by the fsc images in this study similarly the binary cloud free images with cloud pixels and non cloud pixels were replaced by the clear index ci images the ratio of the sum of the fractional snow cover fscsum data to the sum of the clear index cisum data during a period is an improved method for estimating the spatial probability of the snow cover which makes full use of the snow cover and cloud information from the original modis snow product the new advanced scp dataset was generated by combining modis terra and aqua data for 2002 2018 at a spatial resolution of 0 05 over the entire tp during 2000 2001 only the modis terra data were used because aqua is not available detailed descriptions of the three steps of the new method are provided below figs 2 and 3 step 1 the sum of fsc and the sum of the clear index during an 8 day period for both the daily modis terra and modis aqua datasets covering each pixel of the entire tp was calculated as follows 4 c i s u m i 1 n c i i where cisum is the sum of the daily clear index data during an 8 day period 5 f s c s u m i 1 n f s c i where fscsum is the sum of the fractional snow cover from the original daily modis snow cover product during an 8 day period note that for eqs 4 and 5 when only modis terra was used during 2000 2001 1 i 8 n 8 when modis terra and aqua were used during 2002 2018 1 i 16 n 16 step 2 if the sum of the daily clear index for a pixel was higher than 0 within the 8 day period the spatial probability of snow cover in this pixel was estimated as follows 6 s c p f s c s u m c i s u m i 1 n f s c i i 1 n c i i where scp is the 8 day cloud free snow cover probability the above two steps effectively remove most of the clouds in the original modis snow cover product during an 8 day period note that for eq 6 when only modis terra was used during 2000 2001 1 i 8 n 8 when modis terra and aqua were used during 2002 2018 1 i 16 n 16 if ci is zero in all of the pixels from the terra and aqua sensors during this period a backup forecasting method was used in the next step step 3 if the pixel was completely 100 covered by clouds during the entire 8 day period the spatial probability of snow cover was estimated using the cloud free spatial probability of snow cover for the preceding 8 day period pscp and that of the following 8 day period fscp as follows 7 s c p p s c p f s c p 2 p s c p a n d f s c p a r e a v a i l a b l e p s c p f s c p i s n o t a v a i l a b l e f s c p p s c p i s n o t a v a i l a b l e using the above three steps we were able to estimate the scp regardless of almost all of the cloud cover with a time span of 24 days the results of the scp estimation are shown in fig 4 the scp could be easily estimated using step 2 when the sum of the ci in the pixels is 0 during an 8 day period when a small part of the pixels is fully covered by clouds for all time within a given period the preceding and the subsequent 8 day cloud free scp data for the same pixels estimated using step 3 are employed to fill such a gap as a result an 8 day scp dataset without cloud cover could be produced using the above three steps 3 3 relationship between passive microwave sd product and scp snow cover information with a high spatial resolution is a key factor and has been widely used as a spatial weight when redistributing passive microwave sd pixels in previous studies these studies identified a positive correlation between the fsc and sd over the tp tang et al 2016 dai et al 2018 indicating that the fsc can be used to determine the detailed spatial information for the passive microwave sd pixels therefore the scp generated from the fsc has the potential ability to redistribute passive microwave sd pixels to illustrate we selected two typical regions with a large amount of snow in the tp the 8 day mean sd and scp values from 300 grid points during winter 2000 were randomly extracted for the western tp and for the southeastern tp which are the two main snow covered regions on the tp thus a total of 600 grid points were sampled to test the relationship between the sd and scp in the cold season a simple linear regression model was then established based on these collected scp and sd data in each region we found a significant positive relationship between the sd and scp as can be seen from the r values of 0 74 for the western tp and 0 88 for the southeastern tp p 0 001 in both cases fig 5 thus the scp was determined to be an appropriate factor for downscaling the coarse resolution sd data used in this study 3 4 downscaling algorithms 3 4 1 spatial downscaling algorithm the above analysis suggests that a higher scp value may indicate a higher sd value therefore it is reasonable to use the scp derived from the fsc product to improve the spatial resolution of the sd grids to maintain the same temporal resolution for the sd and scp the total sd sdsum during an 8 day period dataset was produced by summing the daily sd data for each 8 day period by 8 sd sum i 1 8 sd i the area of a 0 25 passive microwave sd pixel is 25 times that of an 0 05 scp pixel thus each 0 25 sd pixel was equally divided into 25 subpixels by taking into consideration the spatial weight derived from the 0 05 scp in the same location dividing the sum of the 0 05 scp in the extent of the 0 25 sd pixel by each 0 05 scp pixel is an effective way to estimate each spatial weight that is used to redistribute the 0 25 sd pixels in this case the 8 day sdsum grids must be multiplied by 25 before multiplying by the subpixel level spatial weight value in this way an 8 day sdsum dataset with the 0 05 resolution subpixel spatial information was produced for 2000 2018 over the tp fig 6 the equations of spatial downscaling algorithm are as follows 9 ws scp j j 1 25 scp j w 11 w 15 w 51 w 55 10 sd sum sub 25 sd sum w s 25 sd sum w 11 25 sd sum w 15 25 sd sum w 51 25 sd sum w 55 where sdsum sub is the sum of the subpixel snow depth at 0 05 during an 8 day period sdi is the snow depth on the ith day during an 8 day period 1 i 8 ws is the spatial weight for redistributing the passive microwave snow depth pixel and scpj is the snow cover probability in the jth pixel in the area of each 0 25 snow depth pixel 1 j 25 3 4 2 temporal downscaling algorithm in the process of downscaling the passive microwave sd the advantage of its high temporal resolution has long been disregarded in previous studies using the ratio of daily sd to the 8 day sdsum the daily temporal weight can be calculated to improve the temporal resolution of the 8 day sdsum dataset containing subpixel spatial information a subpixel sd dataset with a daily temporal resolution during 2000 2018 in the study region was produced by multiplying the 8 day sdsum subpixel dataset and each daily temporal weight the flowchart of the temporal downscaling algorithm is shown in fig 7 and the equations are as follows 11 wt sd i i 1 8 sd i sd 1 i 1 8 sd i sd 8 i 1 8 sd i 12 sd i sub sd sum sub w t sd sum sub w 1 sd sum sub w 8 sd sum sub sd 1 i 1 8 sd i sd sum sub sd 8 i 1 8 sd i where sdi sub is the subpixel daily snow depth on the ith day sdsum sub is the sum of the subpixel snow depth during an 8 day period wt is the temporal weight and sdi is the snow depth on the ith day during an 8 day period 1 i 8 3 5 statistical metrics for assessing the sd product the daily in situ sd data measured at 92 meteorological stations of the china meteorological administration cma were used to evaluate the accuracy of the new daily 0 05 sd product and the original 0 25 one for 2001 01 01 2010 12 31 for each product the sd value of the grid in which the station is located was compared against that observed by the meteorological stations based on the elevations of the stations the comparisons were also aggregated into four elevation zones with a 1000 m interval the root mean square error rmse and the mean absolute error mae values were calculated to quantitatively evaluate the accuracy of these two products i e 13 rmse 1 n i 1 n x i y i 2 14 mae 1 n i 1 n x i y i where xi is the ith in situ snow depth value and yi is the ith passive microwave snow depth value 4 results 4 1 validations of the original 0 25 sd product and the new 0 05 sd product fig 8 shows the validation results of the new 0 05 and the original 0 25 sd data using the ground measured sd data as seen the rmse and mae values from the former are much smaller than those from the latter indicating a significant improvement in the 0 05 sd product across the tp for all 92 stations the mean rmse and mae values of the new 0 05 sd product are 1 54 and 0 67 cm d 1 respectively the spatial distribution for the rmse and mae of two sd products fig 9 shows that the improvement of new sd estimates is more obvious in the eastern part of tp regarding the stations in different elevation zones table 2 the rmse values of the new 0 05 sd product are all lower than those of the original 0 25 sd product this is also true for the mae values the improvement is most obvious in the 3000 4000 m a s l elevation zone in which the rmse decreases from 3 22 to 2 30 m d 1 table 2 the above validation suggests that our newly developed sd product with a higher spatial resolution outperforms the original 0 25 sd product regarding the accuracy 4 2 spatial pattern of the sd over the tp from the new and original sd products fig 10 presents the spatial characteristics of the multiyear 2000 2018 mean sd from the new 0 05 and original 0 25 sd products over the tp as can be seen the two sd products exhibit similar spatial distribution characteristics however the new sd product with a 0 05 spatial resolution captures much more detailed information and provides more heterogeneous spatial distribution patterns compared to the original version this is because the former assimilates the much spatial information of the scp the latter of which was derived from the modis with a high spatial resolution the difference between these two products is most obvious in the snow dominated regions i e the southeastern tp as well as the himalaya and karakoram to further illustrate the strength of the new 0 05 sd product at the monthly scale figs 11 s2 further illustrate the spatial distribution of the multiyear 2000 2018 mean monthly sd across tp as seen a more explicit spatial pattern of sd across tp could be detected every month by the new 0 05 sd product with this new 0 05 sd product we could describe the spatial characteristic of sd in a more detailed manner on the monthly scale the spatial pattern of the multiyear 2000 2018 average sd over the tp differs significantly in the cold and warm seasons figs 11 s2 during the cold season the large sd values mainly occur on the northwestern and southeastern tp while the sd values in the inner tp are much smaller during the warm season there is little snow on most parts of the tp except for the high elevation areas of karakorum kunlun himalaya and pamir where a certain amount of snow still exists during the warm season note that although the 0 05 sd product has an improved spatial resolution it may be less capable of presenting the spatial information about the snowpack in summer this is mainly because the microwave data cannot efficiently detect the sd in regions with shallow sd values 4 3 seasonal cycle of the sd over the tp and its basins the multiyear mean monthly sd averaged over the entire tp increases rapidly from september to january leading to a peak monthly value of 3 54 cm mo 1 fig 12 m this is followed by a gradual decrease until september in general the rate of increase of the monthly sd during september january is obviously faster than the rate of decrease of the monthly sd during january september which suggests that the duration of the snow melting period is likely longer than the snow accumulation period over the tp fig 12a l illustrate the seasonal cycle of the sd in 12 basins within the tp in general the lowest monthly sd occurs in july or august over the basins in the eastern tp but for the basins in the western and inner tp the lowest monthly sd occurs in september for most basins that are influenced by the asian monsoon the maximum monthly sd occurs in december or january however for the amu dayra indus and ganges which are obviously impacted by the westerlies the sd keeps large until april the above analysis highlights that the monsoon and westerlies play important roles in controlling the intra annual sd variations in the different basins across tp 4 4 trends in the sd over the entire tp and its basins fig 13 a shows the spatial pattern of the trends 2000 2018 in annual sd across the tp derived from the new 0 05 product the sd increased significantly in some parts of the tarim upper yangtze yellow and northwestern brahmaputra basins and the northern himalayas but it decreased significantly in some parts of the inner tp eastern brahmaputra and the southern himalayas however in most parts of tp the trends of the annual sd were not significant during 2000 2018 fig 13b to further illustrate the strength of the new high resolution sd data we also show the spatial pattern of the trends in annual sd derived from the 0 25 product in fig s2 although the spatial pattern of the linear trends derived from the 0 25 version is overall similar to those from the 0 05 product the new data obviously provide a more explicit representation of the changes in sd across tp therefore it is suggested that our newly developed sd data could serve as a useful tool for investigating the spatial and temporal variations in snow over tp when averaged over the entire tp the annual sd increased slightly with a rate of 0 005 cm yr 1 p 0 05 during 2000 2018 fig 14 m the annual sd generally increased during 2000 2008 and 2017 2018 but it decreased overall during 2008 2017 it should be highlighted that the trend in the sd depends highly on the temporal period analyzed since there was a sudden jump in the sd in 2018 which is also the largest annual sd during these 19 years for this reason the trend in tp averaged annual sd became a slight decreasing one with a value of 0 009 cm yr 1 p 0 05 during 2000 2017 fig s3m fig 14a l also illustrate the linear trends in the annual sd during 2000 2018 for 12 basins within the tp the annual sd increased in most of the basins in the tp except the amu dayra ganges brahmaputra and inner tp in which the annual sd decreased to some extent however the trends are mostly insignificant except for that of the tarim basin in which the annual sd increased significantly at a rate of 0 05 cm yr 1 p 0 05 during the 19 year study period when switching to the period of 2000 2017 fig s3 trends in basin scale annual sd change to some extent in particular trends in indus salween mekong yangtze and qaidam become decreasing though such trends are still not statistically significant 5 discussions although the sd dataset was improved with a better resolution of 0 05 the error of the representativeness is inevitable when validating pixel based sd products based on ground based sd measurements this is because a sample point is less capable of representing a pixel especially in regions with a heterogeneous underlying surface xiao et al 2018 to improve the reliability of the validation results of the sd products derived from remote sensing satellites across the entire tp progress should be made not only in developing downscaling algorithms but also in enhancing advanced sensors although the sd retrieval method has been calibrated and developed using several versions chang et al 1987 foster et al 1997 che et al 2008 jiang et al 2014 accurate knowledge of the physical properties of the snowpack e g snow temperature snow density snow grain size and snow water content is not explicitly and comprehensively considered used in most of the retrieval methods using the passive microwave remote sensing data dietz et al 2012 thus in future studies more dynamic sd retrieval methods should be developed to consider the various effects of these physical properties to improve the accuracy of the original sd products derived from passive microwave brightness temperature data it is more suitable to use passive microwave remote sensing to estimate the snow water equivalent rather than the sd this is mainly because the microwave brightness temperature of the snowpack is affected by both sd and snow density kelly et al 2003 however most of these algorithms involved the relationship between the sd value and the passive microwave brightness temperature chang et al 1987 foster et al 1997 che et al 2008 jiang et al 2014 therefore it is believed that these algorithms may also be appropriate for estimating the snow water equivalent after slight modifications in this case more attention should be paid to building more snow water equivalent measurement sites because of the limited global samples available for validation several factors may impact the trend of the snow parameters over the tp to some extent such as the study area and study period the effects of the size of the tp coverage on the trends of the snow parameters have long been disregarded for example the tp s extent in china is less than the entire tp region in this study zhang et al 2013 it is worthwhile to highlight the sd in certain areas of the western tp e g the karakoram is higher than other parts of the tp thus making them a significant contributor to the trend in the tp averaged annual sd a good example of this is that the seasonal cycle of the sd over the entire tp is influenced by the high sd values in the western tp to a large extent which is especially true in summer additionally the trend in the annual sd is also very sensitive to the length of the study period as can be seen from the comparisons between fig 14 and fig s3 although the sd in most of the basins in the tp increased slightly from 2000 to 2018 it decreased slightly from 2000 to 2017 different trends during these two different periods are also true for the tp averaged annual sd though both trends are not statically significant 6 conclusions by combining a high temporal resolution passive microwave sd dataset with a high spatial resolution cloud free scp dataset this study developed a spatial temporal downscaling method to successfully downscale the 0 25 sd dataset to a 0 05 sd product for the tp during 2000 2018 which is freely available to the public yan et al 2021 the validation against 92 ground meteorological stations demonstrates that the new 0 05 sd product significantly improves upon the original 0 25 version while the present study only focuses on the tp the spatial temporal downscaling method developed here could be applied to other snow dominated regions e g the high latitudes to produce new sd data with an improved spatial resolution based on the new 0 05 sd product we found that sd is typically higher in the southeastern tp as well as the himalaya and karakoram while the lowest sd value occurs mainly in the inner tp for the seasonal cycle of sd the maximum monthly sd occurs in december or january for most basins that are influenced by the asian monsoon however for the amu dayra indus and ganges which are obviously impacted by the westerlies the sd is large until april this indicates that the monsoon and westerlies play important roles in controlling the intra annual sd variations patterns across tp during 2000 2018 there was no significant trend in annual sd for most parts of tp the tp averaged annual sd showed a slight increasing trend 0 005 cm a 1 p 0 05 on the basin scale the annual sd slightly decreased in the amu dayra ganges brahmaputra and inner tp but an opposite trend was observed in the rest of the basins within tp it should be noted that the trends reported here depend greatly on the study period since there was a sudden jump in the sd for the last year i e 2018 we analyzed however trends are still not statistically significant after removing this year s data the demand for high resolution remote sensing based sd datasets can be met to some extent by the current sd data downscaling algorithms therefore it is believed that this new fine resolution sd dataset not only provides an accurate data source for estimating snow water storage and its variations over the tp but also presents new opportunities for hydrological and climatological studies related to the seasonal snowpack more importantly the response mechanism of sd to ongoing climate change on the tp is expected to be clarified in the future by using such an improved sd dataset credit authorship contribution statement dajiang yan conceptualization methodology formal analysis software investigation resources data curation writing original draft visualization ning ma resources investigation formal analysis writing original draft funding acquisition yinsheng zhang resources writing review editing funding acquisition supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was funded by the national key research and development program of china 2017yfa0603101 the second tibetan plateau scientific expedition and research program 2019qzkk0201 the cas strategic priority a research program xda20060201 the national natural science foundation of china 41801047 and 41801051 the china pakistan joint research center for earth science and the open research fund program of the state key laboratory of cryospheric science northwest institute of eco environment and resources cas sklcs op 2020 11 the fractional snow cover product was acquired from the nsidc http nsidc org the 0 25 sd dataset was provided by the national tibetan plateau data center https doi org 10 11888 geogra tpdc 270194 the 0 05 sd product is available from the national tibetan plateau data center https doi org 10 11888 snow tpdc 271743 or the corresponding authors the authors thank prof guoqing zhang and prof zhen li for their helpful suggestions on the manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127027 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
3809,accurate remotely sensed snow depth sd data are essential for monitoring and modeling hydrological processes in cold regions while the available passive microwave sd data have been widely used by the community the coarse spatial resolution typically at 0 25 of these data impedes the explicit representation of the hydrological processes in snow dominated regions especially in mountainous regions with complex terrain to improve the spatial resolution and quality of passive microwave sd data for the tibetan plateau tp we develop a spatial temporal downscaling method to produce a 19 year daily 0 05 sd product by combining the existing high temporal resolution daily sd data and the high spatial resolution 8 day cloud free moderate resolution imaging spectroradiometer modis based snow cover probability scp data the latter of which were produced using an new advanced temporal filter algorithm validations against the observed sd data from 92 meteorological stations suggest that the newly developed 0 05 sd product greatly improves upon the original 0 25 version based on this 0 05 sd product we found that higher sd values are mainly distributed on the southeastern and eastern tp as well as the himalaya and karakoram while much lower sd values occur on the inner tp during 2000 2018 the tp averaged annual sd showed a slight p 0 05 increasing trend because there were little changes in sd for most grids across the tp regarding different basins within tp the annual sd during 2000 2018 slightly increased over most basins except for the amu dayra ganges brahmaputra and inner tp where the basin scale sd showed insignificant decreasing tendencies in general the spatial temporal variations in the sd across the tp were very heterogeneous because sd was affected by multiple climatic factors the newly developed 0 05 sd product could facilitate our understanding of the hydrological processes on the tp through a more explicit representation of the gridded based snow water information keywords snow depth downscaling snow cover probability tibetan plateau 1 introduction snow is a key component of the hydrological cycle and an important indicator of climate change pulliainen et al 2020 musselman et al 2021 it also plays a key role in the energy balance because of its strong effect on the surface albedo and soil temperature thereby modulating the local and regional weather and climate henderson et al 2018 jia et al 2021 you et al 2020 as the snowpack can store a large amount of the precipitation that falls during the cold season it also plays a vital role in the spring runoff formulation barnett et al 2005 huning and aghakouchak 2020 impacting the downstream agricultural production which relies on irrigation qin et al 2020 the snow depth sd is the most important variable that describes the amount of snow for a given region kinar and pomeroy 2015 matiu et al 2021 hence reliable high quality sd datasets are essential for the above applications related to the weather and climate water resource management and flood monitoring in cold regions several approaches have been extensively used to monitor the sd including field observations land surface modeling optical remote sensing and passive microwave remote sensing although meteorological stations can provide accurate sd observation data for a long time series ma et al 2020 matiu et al 2021 the number of stations in mountainous regions where the snow often occurs remains low lundquist et al 2019 impeding the understanding of snow dynamics in high elevation areas in terms of the model based sd estimates including the lumped conceptual models e g snow 17 model and the physically based land surface models e g those from the global land data assimilation system version 2 1 the uncertainties in the modeling forcing and the parameters may bring potential errors in regional scale sd estimation which is especially true for remote areas where ground observed meteorological data are very sparse bian et al 2019 ma et al 2020 while certain atmospheric reanalysis data e g the japanese 55 year reanalysis jra 55 has also assimilated the ground observations in deriving the gridded sd data they are typically at the relatively coarse spatial resolutions with an order of 0 5 or larger bian et al 2020 orsolini et al 2019 although snow cover information can be extracted from optical remote sensing data under clear sky conditions hall and riggs 2007 bhatti et al 2016 zhang et al 2014 it is difficult to estimate the sd using the visible and infrared bands dai et al 2018 with the rapid development of passive remote sensing over the last four decades this technique has become widely used for detecting sd information by taking advantage of the difference in the microwave brightness temperature at different frequencies regardless of cloud contamination since the 1970s chang et al 1987 che et al 2008 liang et al 2015 tait 1998 tedesco et al 2004 this is because the deeper the snowpack is the more positive the microwave energy difference detected between the horizontally polarized brightness temperatures of the 19 or 18 ghz and 37 or 36 ghz bands kelly et al 2003 che et al 2008 xiao et al 2018 previous studies have dedicated much effort to developing and calibrating numerous sd estimation algorithms for use with passive microwave remote sensing data for example the relationship between the sd and the brightness temperature gradients of the 18 and 37 ghz bands was used for sd retrievals from nimbus 7 scanning multichannel microwave radiometer smmr data chang et al 1987 considering the effects of forested areas and crystal size on sd estimation foster et al 1997 presented an algorithm to improve the original one proposed by chang et al 1987 for north america and eurasia the chang et al 1987 algorithm was also adjusted to consider several factors influencing the sd retrieval to achieve a more accurate result in china che et al 2008 this valuable effort produced a chinese long term sd dataset based on this algorithm for the last four decades using three passive microwave remote sensing sensors i e the smmr special sensor microwave imager ssm i and special sensor microwave imager sounder ssmi s che et al 2008 dai et al 2015 dai et al 2017 although the microwave remote sensing sd data allow us to eliminate cloud contamination its coarse spatial resolution mostly at 0 25 is too coarse to capture the fine scale characteristics of sd which is especially true in mountainous areas with a complex terrain in addition the coarse resolution of such sd products is not adequate for hydrological modeling studies in small watersheds where the runoff is often simulated at the kilometer scale the combination of optical snow cover products and microwave snow products is an important step in developing accurate snow cover and sd products to mitigate the uncertainty of microwave remote sensing snow products e g sd and snow water equivalent due to its low spatial resolution it may be preferable to blend the existing coarse resolution microwave remote sensing sd products and other auxiliary datasets with higher spatial resolutions to improve the spatial resolution of the sd product to this end various types of snow cover information e g binarized snow cover fractional snow cover and annual snow cover duration usually have much higher spatial resolutions and thus are widely used to enhance passive microwave snow products gao et al 2010 tang et al 2016 huang et al 2016 dai et al 2018 wei et al 2021 the three main factors derived from the optical based snow cover information were used to enhance the coarse resolution microwave sd and snow water equivalent datasets first a binarized snow cover image was used gao et al 2010 redistributed the snow water equivalent information using the number of snow covered pixels from the moderate resolution imaging spectroradiometer modis data in a passive microwave pixel however a binarized snow cover image classified using a threshold tends to underestimate patchy snow cover information to a large extent zhang et al 2019 thus compared to the binarized snow cover the fractional snow cover should be given priority to enhance the coarse resolution microwave sd second the spatial information about the daily fractional snow cover was used tang et al 2016 used a daily fractional snow cover product to enhance the daily microwave sd data based on the strong relationship between these two snow parameters by combining ground emissivity land surface temperature and fractional snow cover the sd data was further improved using a novel spatial dynamic method with a higher spatial resolution on the tp dai et al 2018 however the accuracy of the daily snow cover product is largely affected by cloud cover zhang et al 2019 third the annual snow cover duration was used mhawej et al 2014 huang et al 2016 wang et al 2019 wei et al 2021 because there is a strong relationship between the snow cover duration and the sd during a given year the annual snow cover duration obtained from modis data was introduced to redistribute the microwave snow water equivalent data mhawej et al 2014 and the sd data huang et al 2016 the relationships between the sd and several factors e g longitude latitude terrain and snow cover duration were built using multi factor regression models in order to reconstruct the high resolution sd products wang et al 2019 wei et al 2021 however using the annual snow cover duration to reconstruct the daily passive microwave sd pixels is problematic because of the temporal difference while progress in downscaling the sd snow water equivalent has been made by taking advantage of more factors less attention has been paid to enhancing the sd product by taking advantage of the high spatial resolution modis snow cover probability scp product in previous studies in short neither the annual snow cover duration nor the daily snow cover product e g the binarized snow cover and fractional snow cover are suitable for use as a downscaling factor to produce sd datasets with high temporal spatial resolutions the utilization of the modis scp information during several days can provide new opportunities thereby improving the spatial resolution of the passive microwave sd data with an average altitude higher than 4000 m above sea level a s l the tibetan plateau tp is the source region of several major asian rivers including the indus ganges brahmaputra salween mekong yellow and yangtze rivers fig 1 which is therefore known as the asian water tower immerzeel et al 2010 in this context snow is extremely important because it is one of the key water resources that supply 1 6 billion people downstream in china india pakistan nepal bhutan and bangladesh immerzeel et al 2020 however in situ observations of snow information are particularly sparse on the tp because of its complex terrain and harsh climate ma et al 2020 for this reason satellite observed sd products for the tp have attracted increasing attention because of their ability to estimate the snow water resources in this inaccessible region with formidable natural conditions tang et al 2016 xiong et al 2017 zhang and ma 2018 however the development of high resolution both spatially and temporally remote sensing sd data in the tibetan plateau is challenging because of its heterogeneous landscape and scarce ground observations bian et al 2019 orsolini et al 2019 having recognized this need the objectives of this study are i to develop a spatiotemporal downscaling method by taking advantage of the spatial information of the 0 05 modis scp and the temporal information of the daily passive microwave sd during an 8 day period to produce a finer resolution i e 0 05 sd product across the tp ii to determine whether the accuracy of this newly developed 0 05 sd product is better than that of the previous coarse resolution sd dataset and iii to investigate the spatial and temporal variations in sd over tp during the last two decades 2 data 2 1 fractional snow cover and clear index the modis snow cover data version 006 from 2000 to 2018 from the terra mod10c1 and aqua myd10c1 satellites were downloaded hall and riggs 2016 accessible from the national snow and ice data center nsidc http nsidc org the spatial and temporal resolutions are 0 05 and daily respectively hall et al 2002 both datasets are comprised of three sub datasets i e the fractional snow cover fsc cloud obscuration percentage and clear index ci data ranging from 0 to 100 each sub dataset of the modis snow cover data includes the following categories lake ice inland water ocean cloud obscured water data not mapped and data filled table 1 because lake ice inland water ocean and cloud obscured water have no snow cover information these variables were reclassified to 100 in the clear index data the data that were not mapped and the filled data were considered as cloud cover so they were reclassified to 0 in clear index data the fsc and ci were calculated as follows hall et al 1995 salomonson and appel 2006 hall and riggs 2016 1 f s c t e r r a 1 45 ρ g r e e n ρ s w i r 1 ρ g r e e n ρ s w i r 1 0 01 where fscterra is the fractional snow cover obtained using the modis terra instrument ρgreen is the reflectance of the green band and ρswir1 is the reflectance of the swir1 band 2 f s c a q u a 1 91 ρ g r e e n ρ s w i r 2 ρ g r e e n ρ s w i r 2 0 64 where fscaqua is the fractional snow cover obtained using the modis aqua instrument ρgreen is the reflectance of the green band and ρswir2 is the reflectance of the swir2 band 3 c i 1 f c c where ci is the daily clear index data and fcc is the daily fractional cloud cover 2 2 gridded sd product the long term daily 0 25 sd dataset from 2000 to 2018 was downloaded from the national tibetan plateau data center https data tpdc ac cn zh hans this dataset was obtained by the smmr ssm i and ssmi s che et al 2008 che 2015 dai et al 2015 dai et al 2017 to improve the consistency of the passive microwave remote sensing data derived from the various sensors the brightness temperature data derived from these instruments smmr ssm i and ssmi s were cross calibrated dai et al 2015 this sd dataset has long been regarded as the most accurate snow depth estimation for china and thus has been widely used not only in previous studies related to sd downscaling huang et al 2016 tang et al 2016 wei et al 2021 but also in understanding the effects of snow changes on regional runoff xu et al 2009 and that on vegetation dynamics yu et al 2013 2 3 ground measured sd data from meteorological stations the daily sd data during 2000 2010 observed at 92 meteorological stations fig 1 of the china meteorological administration were used as the ground truth values for assessing the accuracy of the gridded sd product wang and wan 2018 with elevations ranging from 1000 to 4800 m above sea level most meteorological stations are located on the southern and eastern parts of the tp the in situ sd measurements are the most accurate record of the sd and therefore they are widely used for evaluating not only satellite based sd products tang et al 2016 but also the snow products in reanalysis over the tp orsolini et al 2019 3 method 3 1 definition of the snow hydrological year according to the seasonal cycle of the sd in tp the lowest monthly mean sd occurs in september over the tp therefore the snow year was defined as september 1 to august 31 of the following year for example the snow year of 2000 was from september 1 of 2000 to august 31 of 2001 it should be noted that all analyses in the present study are based on the snow year instead of the calendar year 3 2 cloud removal method for estimating the spatial probability of the snow cover cloud contamination of optical remote sensing products greatly limits the usage of daily modis snow cover datasets to remove the clouds from the original modis snow cover product the ratio of the number of snow pixels to the number of cloud free pixels during a 15 day period was used to estimate the spatial probability of the snow cover by combining the regional snowline and an elevation zone with a 100 m interval li et al 2017 however the snow pixels were identified via binarization processing of the normalized difference snow index ndsi image data with a specific threshold on the regional scale which causes uncertainties in estimating the area of the snow cover zhang et al 2019 to achieve a more accurate spatial probability of snow the binary snow images with snow pixels and non snow pixels were replaced by the fsc images in this study similarly the binary cloud free images with cloud pixels and non cloud pixels were replaced by the clear index ci images the ratio of the sum of the fractional snow cover fscsum data to the sum of the clear index cisum data during a period is an improved method for estimating the spatial probability of the snow cover which makes full use of the snow cover and cloud information from the original modis snow product the new advanced scp dataset was generated by combining modis terra and aqua data for 2002 2018 at a spatial resolution of 0 05 over the entire tp during 2000 2001 only the modis terra data were used because aqua is not available detailed descriptions of the three steps of the new method are provided below figs 2 and 3 step 1 the sum of fsc and the sum of the clear index during an 8 day period for both the daily modis terra and modis aqua datasets covering each pixel of the entire tp was calculated as follows 4 c i s u m i 1 n c i i where cisum is the sum of the daily clear index data during an 8 day period 5 f s c s u m i 1 n f s c i where fscsum is the sum of the fractional snow cover from the original daily modis snow cover product during an 8 day period note that for eqs 4 and 5 when only modis terra was used during 2000 2001 1 i 8 n 8 when modis terra and aqua were used during 2002 2018 1 i 16 n 16 step 2 if the sum of the daily clear index for a pixel was higher than 0 within the 8 day period the spatial probability of snow cover in this pixel was estimated as follows 6 s c p f s c s u m c i s u m i 1 n f s c i i 1 n c i i where scp is the 8 day cloud free snow cover probability the above two steps effectively remove most of the clouds in the original modis snow cover product during an 8 day period note that for eq 6 when only modis terra was used during 2000 2001 1 i 8 n 8 when modis terra and aqua were used during 2002 2018 1 i 16 n 16 if ci is zero in all of the pixels from the terra and aqua sensors during this period a backup forecasting method was used in the next step step 3 if the pixel was completely 100 covered by clouds during the entire 8 day period the spatial probability of snow cover was estimated using the cloud free spatial probability of snow cover for the preceding 8 day period pscp and that of the following 8 day period fscp as follows 7 s c p p s c p f s c p 2 p s c p a n d f s c p a r e a v a i l a b l e p s c p f s c p i s n o t a v a i l a b l e f s c p p s c p i s n o t a v a i l a b l e using the above three steps we were able to estimate the scp regardless of almost all of the cloud cover with a time span of 24 days the results of the scp estimation are shown in fig 4 the scp could be easily estimated using step 2 when the sum of the ci in the pixels is 0 during an 8 day period when a small part of the pixels is fully covered by clouds for all time within a given period the preceding and the subsequent 8 day cloud free scp data for the same pixels estimated using step 3 are employed to fill such a gap as a result an 8 day scp dataset without cloud cover could be produced using the above three steps 3 3 relationship between passive microwave sd product and scp snow cover information with a high spatial resolution is a key factor and has been widely used as a spatial weight when redistributing passive microwave sd pixels in previous studies these studies identified a positive correlation between the fsc and sd over the tp tang et al 2016 dai et al 2018 indicating that the fsc can be used to determine the detailed spatial information for the passive microwave sd pixels therefore the scp generated from the fsc has the potential ability to redistribute passive microwave sd pixels to illustrate we selected two typical regions with a large amount of snow in the tp the 8 day mean sd and scp values from 300 grid points during winter 2000 were randomly extracted for the western tp and for the southeastern tp which are the two main snow covered regions on the tp thus a total of 600 grid points were sampled to test the relationship between the sd and scp in the cold season a simple linear regression model was then established based on these collected scp and sd data in each region we found a significant positive relationship between the sd and scp as can be seen from the r values of 0 74 for the western tp and 0 88 for the southeastern tp p 0 001 in both cases fig 5 thus the scp was determined to be an appropriate factor for downscaling the coarse resolution sd data used in this study 3 4 downscaling algorithms 3 4 1 spatial downscaling algorithm the above analysis suggests that a higher scp value may indicate a higher sd value therefore it is reasonable to use the scp derived from the fsc product to improve the spatial resolution of the sd grids to maintain the same temporal resolution for the sd and scp the total sd sdsum during an 8 day period dataset was produced by summing the daily sd data for each 8 day period by 8 sd sum i 1 8 sd i the area of a 0 25 passive microwave sd pixel is 25 times that of an 0 05 scp pixel thus each 0 25 sd pixel was equally divided into 25 subpixels by taking into consideration the spatial weight derived from the 0 05 scp in the same location dividing the sum of the 0 05 scp in the extent of the 0 25 sd pixel by each 0 05 scp pixel is an effective way to estimate each spatial weight that is used to redistribute the 0 25 sd pixels in this case the 8 day sdsum grids must be multiplied by 25 before multiplying by the subpixel level spatial weight value in this way an 8 day sdsum dataset with the 0 05 resolution subpixel spatial information was produced for 2000 2018 over the tp fig 6 the equations of spatial downscaling algorithm are as follows 9 ws scp j j 1 25 scp j w 11 w 15 w 51 w 55 10 sd sum sub 25 sd sum w s 25 sd sum w 11 25 sd sum w 15 25 sd sum w 51 25 sd sum w 55 where sdsum sub is the sum of the subpixel snow depth at 0 05 during an 8 day period sdi is the snow depth on the ith day during an 8 day period 1 i 8 ws is the spatial weight for redistributing the passive microwave snow depth pixel and scpj is the snow cover probability in the jth pixel in the area of each 0 25 snow depth pixel 1 j 25 3 4 2 temporal downscaling algorithm in the process of downscaling the passive microwave sd the advantage of its high temporal resolution has long been disregarded in previous studies using the ratio of daily sd to the 8 day sdsum the daily temporal weight can be calculated to improve the temporal resolution of the 8 day sdsum dataset containing subpixel spatial information a subpixel sd dataset with a daily temporal resolution during 2000 2018 in the study region was produced by multiplying the 8 day sdsum subpixel dataset and each daily temporal weight the flowchart of the temporal downscaling algorithm is shown in fig 7 and the equations are as follows 11 wt sd i i 1 8 sd i sd 1 i 1 8 sd i sd 8 i 1 8 sd i 12 sd i sub sd sum sub w t sd sum sub w 1 sd sum sub w 8 sd sum sub sd 1 i 1 8 sd i sd sum sub sd 8 i 1 8 sd i where sdi sub is the subpixel daily snow depth on the ith day sdsum sub is the sum of the subpixel snow depth during an 8 day period wt is the temporal weight and sdi is the snow depth on the ith day during an 8 day period 1 i 8 3 5 statistical metrics for assessing the sd product the daily in situ sd data measured at 92 meteorological stations of the china meteorological administration cma were used to evaluate the accuracy of the new daily 0 05 sd product and the original 0 25 one for 2001 01 01 2010 12 31 for each product the sd value of the grid in which the station is located was compared against that observed by the meteorological stations based on the elevations of the stations the comparisons were also aggregated into four elevation zones with a 1000 m interval the root mean square error rmse and the mean absolute error mae values were calculated to quantitatively evaluate the accuracy of these two products i e 13 rmse 1 n i 1 n x i y i 2 14 mae 1 n i 1 n x i y i where xi is the ith in situ snow depth value and yi is the ith passive microwave snow depth value 4 results 4 1 validations of the original 0 25 sd product and the new 0 05 sd product fig 8 shows the validation results of the new 0 05 and the original 0 25 sd data using the ground measured sd data as seen the rmse and mae values from the former are much smaller than those from the latter indicating a significant improvement in the 0 05 sd product across the tp for all 92 stations the mean rmse and mae values of the new 0 05 sd product are 1 54 and 0 67 cm d 1 respectively the spatial distribution for the rmse and mae of two sd products fig 9 shows that the improvement of new sd estimates is more obvious in the eastern part of tp regarding the stations in different elevation zones table 2 the rmse values of the new 0 05 sd product are all lower than those of the original 0 25 sd product this is also true for the mae values the improvement is most obvious in the 3000 4000 m a s l elevation zone in which the rmse decreases from 3 22 to 2 30 m d 1 table 2 the above validation suggests that our newly developed sd product with a higher spatial resolution outperforms the original 0 25 sd product regarding the accuracy 4 2 spatial pattern of the sd over the tp from the new and original sd products fig 10 presents the spatial characteristics of the multiyear 2000 2018 mean sd from the new 0 05 and original 0 25 sd products over the tp as can be seen the two sd products exhibit similar spatial distribution characteristics however the new sd product with a 0 05 spatial resolution captures much more detailed information and provides more heterogeneous spatial distribution patterns compared to the original version this is because the former assimilates the much spatial information of the scp the latter of which was derived from the modis with a high spatial resolution the difference between these two products is most obvious in the snow dominated regions i e the southeastern tp as well as the himalaya and karakoram to further illustrate the strength of the new 0 05 sd product at the monthly scale figs 11 s2 further illustrate the spatial distribution of the multiyear 2000 2018 mean monthly sd across tp as seen a more explicit spatial pattern of sd across tp could be detected every month by the new 0 05 sd product with this new 0 05 sd product we could describe the spatial characteristic of sd in a more detailed manner on the monthly scale the spatial pattern of the multiyear 2000 2018 average sd over the tp differs significantly in the cold and warm seasons figs 11 s2 during the cold season the large sd values mainly occur on the northwestern and southeastern tp while the sd values in the inner tp are much smaller during the warm season there is little snow on most parts of the tp except for the high elevation areas of karakorum kunlun himalaya and pamir where a certain amount of snow still exists during the warm season note that although the 0 05 sd product has an improved spatial resolution it may be less capable of presenting the spatial information about the snowpack in summer this is mainly because the microwave data cannot efficiently detect the sd in regions with shallow sd values 4 3 seasonal cycle of the sd over the tp and its basins the multiyear mean monthly sd averaged over the entire tp increases rapidly from september to january leading to a peak monthly value of 3 54 cm mo 1 fig 12 m this is followed by a gradual decrease until september in general the rate of increase of the monthly sd during september january is obviously faster than the rate of decrease of the monthly sd during january september which suggests that the duration of the snow melting period is likely longer than the snow accumulation period over the tp fig 12a l illustrate the seasonal cycle of the sd in 12 basins within the tp in general the lowest monthly sd occurs in july or august over the basins in the eastern tp but for the basins in the western and inner tp the lowest monthly sd occurs in september for most basins that are influenced by the asian monsoon the maximum monthly sd occurs in december or january however for the amu dayra indus and ganges which are obviously impacted by the westerlies the sd keeps large until april the above analysis highlights that the monsoon and westerlies play important roles in controlling the intra annual sd variations in the different basins across tp 4 4 trends in the sd over the entire tp and its basins fig 13 a shows the spatial pattern of the trends 2000 2018 in annual sd across the tp derived from the new 0 05 product the sd increased significantly in some parts of the tarim upper yangtze yellow and northwestern brahmaputra basins and the northern himalayas but it decreased significantly in some parts of the inner tp eastern brahmaputra and the southern himalayas however in most parts of tp the trends of the annual sd were not significant during 2000 2018 fig 13b to further illustrate the strength of the new high resolution sd data we also show the spatial pattern of the trends in annual sd derived from the 0 25 product in fig s2 although the spatial pattern of the linear trends derived from the 0 25 version is overall similar to those from the 0 05 product the new data obviously provide a more explicit representation of the changes in sd across tp therefore it is suggested that our newly developed sd data could serve as a useful tool for investigating the spatial and temporal variations in snow over tp when averaged over the entire tp the annual sd increased slightly with a rate of 0 005 cm yr 1 p 0 05 during 2000 2018 fig 14 m the annual sd generally increased during 2000 2008 and 2017 2018 but it decreased overall during 2008 2017 it should be highlighted that the trend in the sd depends highly on the temporal period analyzed since there was a sudden jump in the sd in 2018 which is also the largest annual sd during these 19 years for this reason the trend in tp averaged annual sd became a slight decreasing one with a value of 0 009 cm yr 1 p 0 05 during 2000 2017 fig s3m fig 14a l also illustrate the linear trends in the annual sd during 2000 2018 for 12 basins within the tp the annual sd increased in most of the basins in the tp except the amu dayra ganges brahmaputra and inner tp in which the annual sd decreased to some extent however the trends are mostly insignificant except for that of the tarim basin in which the annual sd increased significantly at a rate of 0 05 cm yr 1 p 0 05 during the 19 year study period when switching to the period of 2000 2017 fig s3 trends in basin scale annual sd change to some extent in particular trends in indus salween mekong yangtze and qaidam become decreasing though such trends are still not statistically significant 5 discussions although the sd dataset was improved with a better resolution of 0 05 the error of the representativeness is inevitable when validating pixel based sd products based on ground based sd measurements this is because a sample point is less capable of representing a pixel especially in regions with a heterogeneous underlying surface xiao et al 2018 to improve the reliability of the validation results of the sd products derived from remote sensing satellites across the entire tp progress should be made not only in developing downscaling algorithms but also in enhancing advanced sensors although the sd retrieval method has been calibrated and developed using several versions chang et al 1987 foster et al 1997 che et al 2008 jiang et al 2014 accurate knowledge of the physical properties of the snowpack e g snow temperature snow density snow grain size and snow water content is not explicitly and comprehensively considered used in most of the retrieval methods using the passive microwave remote sensing data dietz et al 2012 thus in future studies more dynamic sd retrieval methods should be developed to consider the various effects of these physical properties to improve the accuracy of the original sd products derived from passive microwave brightness temperature data it is more suitable to use passive microwave remote sensing to estimate the snow water equivalent rather than the sd this is mainly because the microwave brightness temperature of the snowpack is affected by both sd and snow density kelly et al 2003 however most of these algorithms involved the relationship between the sd value and the passive microwave brightness temperature chang et al 1987 foster et al 1997 che et al 2008 jiang et al 2014 therefore it is believed that these algorithms may also be appropriate for estimating the snow water equivalent after slight modifications in this case more attention should be paid to building more snow water equivalent measurement sites because of the limited global samples available for validation several factors may impact the trend of the snow parameters over the tp to some extent such as the study area and study period the effects of the size of the tp coverage on the trends of the snow parameters have long been disregarded for example the tp s extent in china is less than the entire tp region in this study zhang et al 2013 it is worthwhile to highlight the sd in certain areas of the western tp e g the karakoram is higher than other parts of the tp thus making them a significant contributor to the trend in the tp averaged annual sd a good example of this is that the seasonal cycle of the sd over the entire tp is influenced by the high sd values in the western tp to a large extent which is especially true in summer additionally the trend in the annual sd is also very sensitive to the length of the study period as can be seen from the comparisons between fig 14 and fig s3 although the sd in most of the basins in the tp increased slightly from 2000 to 2018 it decreased slightly from 2000 to 2017 different trends during these two different periods are also true for the tp averaged annual sd though both trends are not statically significant 6 conclusions by combining a high temporal resolution passive microwave sd dataset with a high spatial resolution cloud free scp dataset this study developed a spatial temporal downscaling method to successfully downscale the 0 25 sd dataset to a 0 05 sd product for the tp during 2000 2018 which is freely available to the public yan et al 2021 the validation against 92 ground meteorological stations demonstrates that the new 0 05 sd product significantly improves upon the original 0 25 version while the present study only focuses on the tp the spatial temporal downscaling method developed here could be applied to other snow dominated regions e g the high latitudes to produce new sd data with an improved spatial resolution based on the new 0 05 sd product we found that sd is typically higher in the southeastern tp as well as the himalaya and karakoram while the lowest sd value occurs mainly in the inner tp for the seasonal cycle of sd the maximum monthly sd occurs in december or january for most basins that are influenced by the asian monsoon however for the amu dayra indus and ganges which are obviously impacted by the westerlies the sd is large until april this indicates that the monsoon and westerlies play important roles in controlling the intra annual sd variations patterns across tp during 2000 2018 there was no significant trend in annual sd for most parts of tp the tp averaged annual sd showed a slight increasing trend 0 005 cm a 1 p 0 05 on the basin scale the annual sd slightly decreased in the amu dayra ganges brahmaputra and inner tp but an opposite trend was observed in the rest of the basins within tp it should be noted that the trends reported here depend greatly on the study period since there was a sudden jump in the sd for the last year i e 2018 we analyzed however trends are still not statistically significant after removing this year s data the demand for high resolution remote sensing based sd datasets can be met to some extent by the current sd data downscaling algorithms therefore it is believed that this new fine resolution sd dataset not only provides an accurate data source for estimating snow water storage and its variations over the tp but also presents new opportunities for hydrological and climatological studies related to the seasonal snowpack more importantly the response mechanism of sd to ongoing climate change on the tp is expected to be clarified in the future by using such an improved sd dataset credit authorship contribution statement dajiang yan conceptualization methodology formal analysis software investigation resources data curation writing original draft visualization ning ma resources investigation formal analysis writing original draft funding acquisition yinsheng zhang resources writing review editing funding acquisition supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this research was funded by the national key research and development program of china 2017yfa0603101 the second tibetan plateau scientific expedition and research program 2019qzkk0201 the cas strategic priority a research program xda20060201 the national natural science foundation of china 41801047 and 41801051 the china pakistan joint research center for earth science and the open research fund program of the state key laboratory of cryospheric science northwest institute of eco environment and resources cas sklcs op 2020 11 the fractional snow cover product was acquired from the nsidc http nsidc org the 0 25 sd dataset was provided by the national tibetan plateau data center https doi org 10 11888 geogra tpdc 270194 the 0 05 sd product is available from the national tibetan plateau data center https doi org 10 11888 snow tpdc 271743 or the corresponding authors the authors thank prof guoqing zhang and prof zhen li for their helpful suggestions on the manuscript appendix a supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2021 127027 appendix a supplementary data the following are the supplementary data to this article supplementary data 1 
