index,text
7020,at the in situ long term sorption diffusion experiment ltde sd performed in the äspö hard rock laboratory sweden anomalous penetration profiles of tracers were observed the concentration of sorbing tracers particularly 137cs sharply decreased around the rock surface but was still quite high in the distance which was known that it is difficult to model with the classic fick s law to understand the mechanism of matrix diffusion and sorption of solute by reproducing the observed penetration profiles in the ltde sd test three cases for the matrix were proposed and evaluated 1 homogeneous medium with a disturbed zone 2 heterogeneous medium considering mineral grains with intragranular porosities and their intergranular pores and 3 heterogeneous medium considering vein and microfractures as well as porous mineral grains and intergranular pores the modelling domains for cases 2 and 3 were established using 2 d microstructure characterization results from analyses including chemical staining of minerals and 14c pmma autoradiography the numerical models for cases 1 3 were calibrated by minimizing the discrepancies between simulations and observations of the penetration profiles and the changes in concentration in the reservoir for the tracers 137cs and 22na the results show that only the calibrated transport parameter values for case 3 were within the reported ranges and we concluded that the sharp decrease in concentrations in the near surface zone in the observed penetration profiles was likely to result from disturbed biotite grains and the long tails in the observed penetration profiles might originate from diffusion along the vein and microfractures transecting minerals keywords ltde sd matrix diffusion sorption microstructure heterogeneity 1 introduction several countries that have used nuclear power energy for decades such as sweden finland switzerland and korea have made plans and preparations for geological disposal of high level radioactive waste hlw according to the concept of geological disposal system the hlw will be surrounded by engineered barriers consisting of canister bentonite buffer and tunnel backfill materials if these barriers fail to contain the hlw radionuclides due to aging or system failure they could migrate along with groundwater flow within the geological medium hosting the repository and might eventually reach biosphere matrix diffusion and sorption processes in bedrock are expected to retard such migration of radionuclides released and to prevent for them from reaching the biosphere over long time periods hölttä et al 1997 siitari kauppi et al 1997 sardini et al 2003 2007 voutilainen et al 2009 jokelainen et al 2013 kuva et al 2015 2016 therefore it is necessary to understand these retention mechanisms in bedrock to assess and assure the safety and performance of such geological repositories however despite many studies on this topic over decades it is still difficult to account for the observations from several in situ tracer tests performed earlier in crystalline rocks e g nilsson et al 2010 tachi et al 2015 the long term sorption diffusion experiment ltde sd is an in situ experiment performed in äspö hard rock laboratory hrl in order to understand matrix diffusion and sorption in bedrock in that experiment anomalous concentration profiles of tracers were observed that could not be reproduced by conventional theory assuming homogeneous diffusion with equilibrium sorption nilsson et al 2010 iraola et al 2017 in particular it was observed that for sorbing tracers such as 137cs and 22na most of the mass was detected at the rock surface exposed to the tracer cocktail but the rest diffused a much longer distance than expected deep into the rock matrix fig 1 nilsson et al 2010 iraola et al 2017 similar observations were also found in other laboratory and in situ experiments including the long term diffusion ltd project in grimsel site switzerland and the following phenomena were proposed as the origins of the observed anomalous concentration profiles heterogeneous mineral distribution particularly related to the biotite content at the surface of the rock samples tsukamoto and ohe 1993 increased sorption capacity of biotite disturbed near the rock surface jokelainen et al 2013 tachi et al 2015 or difference between sorption capacities of minerals in the rock matrix iraola et al 2017 voutilainen et al 2017 these previous studies gave insight into possible roles of microstructures in the retention of radionuclides in heterogeneous rocks however these approaches were insufficient to fully account for the penetration profiles observed in this in situ test in which strongly sorbing tracers e g cesium had migrated several tens of millimeters into the rock the geometry and distribution of the rock microstructures have been characterized in micrometer or smaller scale using techniques such as scanning electron microscopy sem sardini et al 1996 hölttä et al 1997 widestrand et al 2007 voutilainen et al 2009 2012 2013 x ray microcomputed tomography x ray μct voutilainen et al 2009 2012 2013 2017 kuva et al 2012 iraola et al 2017 14c labeled polymethylmethacrylate 14c pmma autoradiography hellmuth et al 1993 siitari kauppi et al 1997 widestrand et al 2007 2010 voutilainen et al 2012 2013 2017 sammaljärvi et al 2017 and chemical staining of minerals sardini et al 2006 voutilainen et al 2012 2013 voutilainen 2017 these characterization techniques can provide information including the apertures of microfractures three dimensional distributions of mineral grains connectivity of micropore spaces total porosity of the rock matrix and intragranular porosity and the analyzed results using them have been used to model diffusion of radionuclides in heterogeneous rock matrix simbierowicz and olin 1997 sardini et al 1999 2001 2003 2007 iraola et al 2017 voutilainen et al 2013 2017 in particular voutilainen et al 2013 2017 and iraola et al 2017 have respectively established the 3 d intra or intergranular pore network for their matrix diffusion models using the analyzed 3 d mineral distributions of rock samples with x ray μct to understand the observations at the ltd and ltde sd experiments however it could have a practical difficulty in incorporating a mix of micropores including inter intra and transgranular pores which exist in real rock matrix into the 3 d model on the other hand while being available in two dimensions the 14c pmma autoradiography can visualize the spatial distributions of the micropores that could act as actual migration pathways of radionuclides in the cross section of a rock core hellmuth et al 1993 widestrand et al 2007 2010 voutilainen et al 2012 the mineral staining has generally been used to reveal the 2 d mineral geometry and distribution in the cross section of a rock core voutilainen et al 2012 2013 voutilainen 2017 and it could be useful to investigate effects of mineral specific properties on the matrix diffusion and sorption of radionuclides within the 2 d model in this study we supposed that heterogeneity in the rock matrix from microstructures might significantly have affected the transport of radioactive tracers during the ltde sd test to prove this a case study was performed by incorporating a heterogeneous rock matrix into three conceptual models two of the cases were based on characterization of microstructures existing in a core sample drilled from the bedrock at äspö hrl which had been performed by voutilainen 2017 particularly the realistic geometry and features of the microstructures characterized using 14c pmma autoradiography and chemical staining of minerals were simultaneously considered in the establishment of the modelling domain and settings in the last case to simulate diffusion along various kinds of micropores and mineral specific sorption for all the cases inverse modelling was carried out to calibrate the parameter values for diffusion and sorption of each medium or microstructure that can reproduce the anomalous results observed in the in situ tracer test the adequacy of each case was evaluated based on the validity of the calibrated parameter values by comparing the calibrated values to the reported values from the laboratory and in situ experiments from these results the influences of rock heterogeneity on the matrix diffusion and sorption of tracers observed in the ltde sd test were discussed including the roles of each rock microstructure 2 material and methods 2 1 ltde sd project the ltde sd project was to understand long term matrix diffusion and sorption under in situ conditions and to provide data for assessing performance and safety of geological repository nilsson et al 2010 in this project the in situ tracer test was performed for 198 days in a borehole drilled at a depth of 410 m below sea level in the äspö hrl the borehole is mainly surrounded by ävrö granodiorite and includes a natural fracture at its far end the borehole was drilled to have a diameter of 177 mm from the tunnel wall to the fracture and to have a diameter of 36 mm within an extended interval 1 m from the fracture fig 2 a cup like packer was installed at the fracture surface so that a tracer cocktail injected into the void created between the fracture surface and packer as a reservoir could diffuse into the rock matrix through the fracture surface fig 2 the average width of the reservoir between the fracture surface and packer was about 3 25 mm the tracer cocktail was also injected into the packed off part of the extended interval so that the tracers could diffuse through the borehole wall which can be regarded as a surface of unaltered rock matrix during the experiment period the tracer cocktail was circulated and its changes in concentrations were monitored the tracer cocktail contained 22 sorbing or non sorbing radioactive tracers including 22na 36cl 57co 63ni 133ba and 137cs for about 230 days after the termination of the experiment the rock volume surrounding the test sections was overcored and then a number of small core samples diameter 24 mm were drilled axially from the fracture surface section a core and radially from the extended section d core of the over cored rock volume the surfaces of the a cores had fracture coating or were altered while the surfaces of d cores were regarded to be un or less altered or damaged from the drilling the core samples were cut into slices with 1 to 20 mm thick for about two months until completing the cutting process the tracers in the core samples are expected to continue to diffuse into matrix thereafter the individual tracer concentrations in the rock slices thus the penetration profiles were measured among the injected tracers 137cs and 22na were detected throughout almost all the slices of the core samples however their penetration profiles could not be simulated by assuming homogeneous diffusion nilsson et al 2010 iraola et al 2017 for example the profiles of 137cs observed in all the core samples have a sharp decrease around the surfaces that were exposed to the tracer cocktail and a flat slope of tailing in the inner rock matrix fig 1a the tailing mostly began at the depth of 5 10 mm from the rock surface and their concentrations were about four orders of magnitude lower than their peak values particularly it can be interpreted as fast diffusion of this strongly sorbing tracer 137cs in rock matrix this tailing was also observed in the profiles of 22na fig 1b despite various analyses on the experimental data and results these spatial distributions and levels of tracer concentrations in the rock slices could not be explained with only the geological characteristics observed on the surfaces of core samples that had been given in nilsson et al 2010 including their surface type locations microfractures mineralogy alteration and fracture coating the details for this experiment can be found in widestrand et al 2010 and nilsson et al 2010 2 2 microstructure characterization on the rock sample to characterize the microstructures of the matrix at the ltde sd test site various analyses including 14c pmma autoradiography and chemical staining of minerals were performed by voutilainen 2017 for the rock sample with diameter of 24 mm and length of 45 mm fig 3 which had been additionally sampled near the test site the 14c pmma autoradiography involves impregnation of a rock slice with the 14c labeled polymethylmethacrylate monomer irradiation polymerization autoradiography and optical densitometry using digital image processing techniques it can reveal the accessible micropores existing in rock matrix which are for example shown as the dark areas and lines in fig 3c the chemical staining of minerals for this rock sample involves sodium ferrocyanide treatment hf acid etching hcl cleaning and sodium cobaltnitride treatment after the treatment mica minerals plagioclase and k feldspar turn blue white and yellow respectively while quartz remain unchanged as shown in fig 3b the mineral staining result showed that the rock at the test site is mainly composed of four minerals plagioclase 39 4 k feldspar 32 6 quartz 26 6 and biotite 1 4 the intragranular porosity of each mineral was determined using the images from chemical staining of minerals and 14c pmma autoradiography which is given in table 1 in this study the geometry and distribution of the mineral grains and micropore network visualized with both techniques were used in incorporating the heterogeneous rock matrix into the modelling domains in the assumed cases fig 4 and this procedure will be described hereafter 2 3 case study to understand the mechanism of diffusion and sorption in a rock matrix by reproducing the observations in the in situ ltde sd test three cases were considered by assuming a matrix to be 1 a homogeneous medium with a disturbed zone at the surface 2 a heterogeneous medium considering mineral grains with intragranular porosities and their intergranular pores and 3 a heterogeneous medium considering vein and microfractures as well as mineral grains and intergranular pores based on the assumptions of each case 2 d modelling domains were established from 2 d microstructure characterization results and the diffusion and sorption parameter values were calibrated for 137cs and 22na using a trial and error method by minimizing the discrepancies between the observed and simulated results of their penetration profiles in rock cores and concentrations in the remained tracer cocktail at the reservoir during the ltde sd test fig 1 diffusion in rock matrix was assumed to be dependent only on geometrical properties of matrix or microstructures such as porosity or apertures of microfractures therefore the parameter values for diffusion were determined regardless of the kind of tracers the modelling work in this study was implemented using the commercial finite element software comsol multiphysics the total simulation time was set to 463 days including the experimental period 198 days and the post experimental period including overcoring core sampling and slicing periods 265 days the simulated penetration profiles shown in this study thus are the results after 463 days from the start of the experiment in the experiment the profiles of 137cs and 22na which are γ emitting radionuclides were obtained by measuring the radioactivity in the crushed and sliced rock samples using high purity germanium detector hpge therefore the measured activity was considered to be the total concentration of both the sorbed and dissolved phases of tracers contained in the rock matrix nilsson et al 2010 thereafter the adequacy of the calibrated parameter values for each case was assessed by comparing with the values obtained from the laboratory and in situ experiments 2 3 1 case 1 nilsson et al 2010 already suggested a two pathway model assuming slow migration in the near surface zone and fast migration in the matrix to fit the penetration profile of a ltde sd core sample similarly a conceptual model assuming a disturbed zone near rock surface and a homogeneous medium in undisturbed rock matrix was considered in this study as case 1 fig 5 a according to the results of the ltde sd test the depth at which the slopes in most of the 137cs profiles began to change was within 5 10 mm from the surfaces of the core samples we therefore assumed this to be the depth of the disturbed zone in the disturbed zone the parameter values for diffusion and sorption were assumed to decrease gradually with distance from the rock surface and were set to be identical to those of the undisturbed matrix at the end of this zone on the left part of the domain for the rock core in fig 5a a reservoir containing the tracer cocktail was assumed to represent the void between the cup like packer and the surface of a core which had a width of 3 25 mm as shown in fig 2 the size of the modelling domain corresponding to the rock core was 63 7 mm length 24 0 mm height 2 3 2 case 2 in the autoradiography analysis on the rock slices in the ltde sd experiment it was observed that the blackened areas which indicate locations of radioactive tracers were similar to the locations of dark minerals such as biotite and chlorite nilsson et al 2010 which was in agreement with the interpretation of the distribution of cs in the epma analysis by tachi et al 2015 muuri et al 2016 2017 also demonstrated through batch experiments the predominance of biotite for cesium sorption compared with the other major minerals in the bedrock at the grimsel and olkiluoto sites plagioclase is known to be another mineral available for cesium sorption muuri et al 2016 intergranular pores are usually invisible to the naked eye but its well connected networks can act as diffusion pathways in crystalline rocks having low porosity sardini et al 1999 tachi et al 2015 for case 2 it was assumed that radionuclides could diffuse through the mineral grains with intragranular porosities and the pore boundaries between them and would sorb only to biotite and plagioclase to simulate this a modelling domain with size nearly identical to that for case 1 was constructed with the 2 d mineral distribution in a rock sample characterized from the mineral staining analysis fig 3b from the picture of the mineral distribution in fig 3b polygons along the geometry and distribution of mineral grains were first delineated in autocad fig 4a these were imported into comsol multiphysics and then mirrored to simulate a deep penetration into the rock core fig 5b the interface between the reservoir and rock in the modelling domain was reconstructed with an irregular and rough surface of the matrix part in the rock sample the alteration rim existing above the interface of the rock sample was excluded from this model work the locations of biotite and plagioclase are identified with dark blue polygons and sky blue polygons in figs 4a and 5b respectively gray polygons in fig 5b indicate the locations of k feldspar and quartz which have low porosity and sorption capacity in the simulation the porosities of the non biotitic minerals i e plagioclase k feldspar and quartz were assumed to be identical because they had been estimated to be within a range of 0 2 to 0 3 table 1 the pore boundaries between all the mineral grains were assumed to be well connected and to have a constant aperture red lines in fig 5b for this case the vein crossing the rock sample shown in fig 3 was regarded as one of the non biotitic minerals without sorption capacity 2 3 3 case 3 in the 14c pmma autoradiograph given in voutilainen 2017 a complicated porous network consisting of a vein and microfractures was visualized while some intragranular porosities were found in biotite grains and in altered parts of non biotitic minerals fig 3c all these observed porous structures could be preferential diffusive pathways in the rock matrix and the entire matrix diffusion must therefore be dependent on their distribution and connectivity sardini et al 2001 2003 2006 for case 3 we considered the porous minerals and the vein with intragranular porosities and the microfractures as linear structures which were observed in the 14c pmma as well as the minerals and the intergranular pores that were considered for case 2 in particular the porous minerals and the vein were collectively called intragranular porous structures in this case it was assumed that radionuclides could mainly diffuse through these porous structures but would sorb only to biotite and plagioclase to reflect the distribution and connectivity of the porous structures in the model the 14c pmma image was modified by inverting its gray value and equalizing its brightness fig 4b then the geometry and locations of the porous structures were extracted from that image with consideration of the mineral staining image pink polygons for intragranular porous structures except for biotite and green lines for microfractures in fig 4b these were overlapped with the modelling domain obtained in the previous case fig 5c the porosities of all the intragranular porous structures detected in the 14c pmma image were assumed to be identical and the non biotitic minerals were also assumed to have the same porosity unlike case 2 it was assumed that diffusion along the intergranular pores drawn with red lines is available through only the grain boundaries between the quartz and the two feldspars that had been distinguished clearly in the mineral staining image fig 3b the grain boundaries between plagioclase and k feldspar in the mineral staining image were often vague to be defined in the model domain this may be because they have no or very tiny aperture of pores as a result in this case the intergranular pores were often disconnected within the core sample fig 5c 2 4 sensitivity analysis the adequacy of the cases considered was examined by evaluating whether the parameter values calibrated for each case are within ranges of the values estimated from laboratory and in situ experiments for the most plausible case thereafter a sensitivity analysis was carried out in order to investigate influences of each parameter and its uncertainty on the anomalous diffusion observed at the ltde sd test sensitivity to each parameter was evaluated by re simulating the model established in that case with its different input values which were for example obtained by multiplying a calibrated value by 0 2 0 5 2 and 5 respectively 2 5 numerical approach 2 5 1 diffusion and sorption in the 2 d planar structures although the matrix diffusion could be dependent on various factors including molecular size and charge of radionuclides sorption capacity of the minerals and groundwater composition havlová et al 2012 voutilainen et al 2013 kuva et al 2015 the geometrical properties of pores like porosity and tortuosity are most important because they control the diffusion pathways of radionuclides hellmuth et al 1993 sardini et al 1996 kuva et al 2015 tachi et al 2015 in this study the millington and quirk model was used to express the relation between the effective diffusion coefficient of saturated porous media and porosity millington and quirk 1961 with this porosity diffusion relation the effective diffusion coefficient d e l2 t of each 2 d planar structure such as a porous medium for case 1 or minerals and vein for cases 2 and 3 is defined as 1 d e ε τ d w f d w 2 τ ε 1 3 where ε is the porosity τ is the pore tortuosity d w is the diffusivity in free water l2 t assumed to be 2 1 10 9 m2 s for both 137cs and 22na and f is the formation factor effects of the chemical properties of tracers on the diffusion e g cation excess diffusion were neglected and equilibrium linear isotherm was applied for the sorption of 137cs and 22na because the measured concentrations were given by decay corrected activities using the injection date as time zero radioactive decay of the tracers was neglected the governing equation for transport of a radionuclide in a rock matrix assuming fickian diffusion and equilibrium linear sorption was given as follows 3 c t o t t d e c 4 c t o t α c ε k d ρ b c where c tot is the total concentration of radionuclide in the dissolved and sorbed phases m l3 t is the time t c is the concentration of radionuclide in the dissolved phase m l3 α is the rock capacity factor k d is the distribution coefficient l3 m and ρ b is the bulk density m l3 in case 1 the bulk density of the medium was set to 2700 kg m3 following nilsson et al 2010 for cases 2 and 3 the bulk densities of the minerals were assumed to be 3000 kg m3 for biotite and 2650 kg m3 for the other minerals 2 5 2 diffusion along the 1 d linear structures the 1 d linear structures such as intergranular pores of which the apertures were mostly 1 μm and microfractures of which the apertures were tens of micrometers were regarded as diffusion pathways of radionuclides in the rock matrix the former were applied to the modelling domains for cases 2 and 3 but the latter were included only in case 3 to simulate the diffusion along these structures the 1 d solute transport along the interior boundaries was incorporated into the 2 d modelling domain 5 ε l d l c t d l f l d w t c where ε l is the porosity of linear structure d l is the aperture of linear structure l f l is the formation factor of linear structure and t is the gradient operator to the tangential plane of a linear structure the porosities of all the linear structures were set to 1 by assuming a full opening neither sorption to nor reaction on these structures was considered in spite of the actual variation of their apertures sardini et al 2014 they were assumed to be uniform for simplicity 2 5 3 disturbed zone disturbed zone was mainly formed near rock surfaces altered by weathering or damaged by the borehole drilling the retention properties of the medium or the minerals in this zone could therefore be changed from those in the undisturbed rock matrix in this modelling work it was assumed that the parameter values decrease gradually within a specified depth from the rock surface which means the extent of disturbed zone and then remain constant in the undisturbed matrix as variables to assess the influence of disturbance the ratios of the respective parameter values for diffusion and sorption at the surface and in the undisturbed matrix were used to calibrate the model this means that the parameter values for the undisturbed matrix could be calculated using the calibrated ratios for disturbance and the calibrated values at the surface we also assumed that change in the characteristic parameter values in a disturbed zone followed the smoothed heaviside function so that the change could be gradual and smooth rather than sharp or linear for example in cases 2 and 3 the distribution coefficients k d of a tracer for minerals in the disturbed zone and undisturbed matrix were given by 6 log 10 k d x log 10 k d s f log 10 k d s f log 10 k d m t h x 0 x d d subject to h x 0 5 0 9375 2 x d d d d 0 625 2 x d d d d 3 0 1875 2 x d d d d 5 7 k d m t k d s f k f where x is the depth from the outermost point of the rock surface x 0 l k d m t is the distribution coefficient of the tracer for a mineral located in the rock matrix x d d l3 m k d s f is the distribution coefficient of the tracer for a mineral located at the rock surface x 0 l3 m h x is the smoothed heaviside function with a continuous second derivative without overshoot whose value changes gradually from 0 to 1 within a given interval kf is the ratio for disturbance on sorption and d d is the depth of the disturbed zone l in eq 6 the logarithms of k d were used to introduce gradual change of k d in the disturbed zone where k d can vary by several orders of magnitude the diffusion in the disturbed zone was also considered by adjusting the porosities in the disturbed zone as in eqs 6 and 7 the terms k d s f k d m t and kf in eqs 6 and 7 were replaced with the porosities i e ε d s f and ε d m t and the ratio for disturbance on porosity df 2 5 4 initial and boundary conditions for all three cases the initial concentrations of 137cs and 22na in the reservoir were set to the concentrations of those tracers in the cocktail injected at the beginning of the ltde test the background concentrations of the tracers in the rock matrix were assumed to be zero a no flux boundary condition was assigned to all the side boundaries of the domain the fickian diffusion of tracers in the reservoir was also simulated with their respective d w the decreases in tracer concentrations in the reservoir measured during the experiment period were compared with the area weighted average of concentration values at the nodes of the reservoir at each time step after the termination of the experiment despite stopping the exposure of the tracer cocktail to the rock surface the radionuclides that had already entered the rock matrix would continue to diffuse deep into the matrix until the rock cores were sliced for simulation of this process therefore a no flux boundary condition was also applied to the interior boundary corresponding to the interface of reservoir and rock called the rock surface in this study after 198 days 3 results and discussion 3 1 case 1 in this case the distribution coefficient and porosity of the medium at the surface the ratios of disturbance for sorption and diffusion and the depth of the disturbed zone were calibrated to simultaneously reproduce the observations reported for 137cs and 22na in the ltde sd test the calibrated parameters are listed in table 2 for 137cs in particular the simulated penetration profile had a dual slope like the observed one and the simulated change in the concentration within the reservoir fit the measured one fairly well fig 6 the depth of the disturbed zone was calibrated to 10 mm which was near the depth where the slopes of profiles for most of the core samples changed sharply the calibrated k d of 137cs for the undisturbed matrix however should have decreased by five orders of magnitude compared to that at the surface fig 7 this discrepancy is similar to the result from previous work by nilsson et al 2010 but such change within only several millimeters from the surface seems to be implausible in addition the calibrated k d of 137cs for the surface 1 0 10 3 m3 kg led to a peak concentration of about 2 6 103 bq g which was lower than the least value measured in the a5 core among all the cores if the k d at the surface was larger than the one determined the resulting peak concentration could increase however the penetration depth of the tracer or the tail of profile would become shorter and the concentration of tracer remaining in the reservoir would decrease 3 2 case 2 for case 2 the aperture and formation factor of the intergranular pores were calibrated along with the distribution coefficients and porosities of minerals at the surface the ratios of disturbance for sorption and diffusion on minerals and the depth of the disturbed zone table 3 fig 8 indicates the simulation results with the calibrated parameters as shown in table 3 the ratio of disturbance for sorption to biotite was calibrated to 1 0 10 4 which means that the k d of 137cs for biotite in the undisturbed matrix is four orders of magnitude smaller than that for biotite at the rock surface moreover the aperture and formation factor of the intergranular pores which must be a major diffusive pathway were calibrated to 0 5 μm and 1 0 10 1 respectively the resulting profile of k d over the entire rock core for this case is shown in fig 7 and is dependent on the contents of the mineral grains along the depth as well as their calibrated k d the profile of k d also indicates that the simulated sharp decrease of the 137cs concentration near the rock surface mainly originated from the decrease of k d for biotite located in the disturbed zone despite the agreement of the simulation results with the observations however it is still questionable that not only could the k d for biotite in the matrix differ from that at the surface this much within the depth of a few millimeters as also discussed for the results of case 1 but all the intergranular pores could also be connected with such a formation factor in crystalline rocks 3 3 case 3 the rock microstructures considered in this case included the porous structures detected in the 14c pmma autoradiography such as the vein and microfractures as well as the mineral grains and their intergranular pores detected in the mineral staining image the calibrated parameters for case 3 are listed in table 4 the simulation using the calibrated parameters reproduced the experimental results for 137cs and 22na of ltde sd test well fig 9 in particular the simulated 137cs penetration profiles exhibited peak concentrations at the rock surface then a sharp decrease in concentration within several millimeters of depth and a long tail within the range of measured concentrations in the experiment in this case the k d of 137cs for biotite at the rock surface was 8 0 10 2 m3 kg which was lower than that of case 2 this result seems to be related to the porous structures added in this case which could enhance diffusion into the rock matrix however there are still overall discrepancies between the simulations and observations for example the simulated penetration profiles began with a much lower concentration at the rock surface than the measured one fig 9a and b which was also observed in case 2 fig 8a and b this low concentration might originate from the cross section of the rock sample that we used to establish the modelling domains the cross section had no biotite where cs and na could sorb at the surface exposed to the tracer cocktail contained in the reservoir figs 4 and 5c this effect might be exaggerated due to the dimensions of the model the concentrations were observed using 3 d core samples but were simulated with a 2 d modelling domain therefore in the simulations the peak concentrations of the profiles were observed at the location of the biotite grains closest to the rock surface which was about 1 4 mm from the surface the fluctuations in the penetration profiles were dependent on the content and distribution of biotite grains in the rock matrix for example the ledge at 5 4 mm deep and the small peaks near 10 mm deep observed in the 137cs profile had biotite content 7 above the average fig 10 nevertheless near the depth of 18 mm the concentrations in the profile were relatively low even though the biotite content was as high as those of the local peaks mentioned above fig 10 this was because the increased content of biotite grains at that depth were far away and disconnected from the vein acting as the main diffusion pathway in this rock sample this can be seen at 8 2 9 4 and 21 4 23 4 mm in the y direction in fig 5c meanwhile several local peaks were observed despite the low biotite content for example at the depths of 19 3 30 0 and 34 0 mm fig 10 small biotite grains that were directly connected to the vein by microfractures or were located on the vein are found at those depths in fig 5c the decrease in the tracer concentration in the reservoir was underestimated in the early part of the experiment although the concentration reaching steady state thereafter was in agreement with the measurement fig 9c this result also seems to be related to the absence of biotite at the surface of the core sample if some biotite grains were located at the rock surface the diffusion from the reservoir into the rock matrix would be enhanced due to its high porosity however it needs to be noted that the measured tracer concentration in the in situ test was the result from averaging diffusion over the entire rock volume which had more severe heterogeneity in the content and distribution of minerals at its surface than did that of a core sample the calibrated k d of 137cs for biotite at the rock surface in this case was lower than those 3 0 5 8 10 1 m3 kg derived from the batch experiments in muuri et al 2016 2017 the peak of the resulting k d profile over the core sample fig 7 2 1 10 3 m3 kg was also lower than the value of the crushed rocks estimated in the batch test performed for the ltde sd project 1 0 10 2 to 9 0 10 1 m3 kg widestrand et al 2010 these differences may be explained partly by the dependency of the parameter estimated in batch tests on the grain size and the resulting specific surface area of crushed samples hölttä et al 1997 widestrand et al 2010 tachi et al 2015 muuri et al 2016 nevertheless the peak value of the profile was within the range of the conservative k d 1 4 8 7 10 3 m3 kg estimated by nilsson et al 2010 which had been calculated by dividing the tracer concentration in the slices closest to the surfaces of the core samples by the concentration in the tracer cocktail at the end of the experiment the calibrated k d of 137cs for plagioclase at the rock surface 1 0 10 4 m3 kg was much lower than those derived by muuri et al 2016 2017 however the weak sorption to plagioclase which was the most abundant mineral in the rock sample tested could alleviate fluctuation in the k d profile for 137cs over the core sample which might be more severe due to the sparse distribution of biotite in it the depth of the disturbed zone was 6 mm from the outermost point of the rock surface table 4 the kf of biotite for 137cs was determined to be 0 01 meaning that the k d of 137cs for biotite located in the undisturbed matrix was 8 0 10 4 m3 kg this ratio of disturbance is roughly in agreement within the result from the through diffusion test of the ltd project tachi et al 2015 in that test the k d of 137cs for undisturbed matrix was estimated to be lower by about two orders of magnitude than that for the rock surface the most distinctive intragranular porous structure observed in the 14c pmma image was the vein diagonally crossing the rock sample figs 3c and 4b the image indicated that this structure had high porosity and thus could be the main pathway for the diffusion of tracers occurring in this rock sample the remaining intragranular porous structures observed in the 14c pmma image were the biotite and the altered parts of the non biotitic minerals the porosity of biotite was calibrated to be 3 0 table 4 which is greater than the measured porosity table 1 this result seems to be associated with the assumption of uniform porosity for all the intragranular porous structures detected in the 14c pmma result in the modelling this is because under this assumption the porosity of biotite could also control the diffusion through the vein which was critical to the reproduction of the deep penetration of tracers observed in the ltde sd test another important parameter controlling the penetration profile was the ratio of disturbance for the porosity of the intragranular porous structures this parameter was calibrated to be 1 0 which means there was no disturbance of the porosities of these structures at the rock surface this is consistent with the observation in 14c pmma image which did not provide any clear evidence for disturbance of their porosities in the rock matrix region considered in this study fig 4b according to the millington and quirk model the formation factor estimated from the porosity of these structures was 9 3 10 3 the calibrated porosities of non biotitic minerals in the disturbed zone and in undisturbed matrix are very low table 4 this means that diffusion through non biotitic minerals might be very limited with their apertures of 10 μm the formation factor of microfractures transecting several mineral grains was calibrated to be 5 10 3 which was of the same order of magnitude as the formation factor of the vein the microfractures acted as the main pathways for migration of the tracers to the mineral grains far from the vein and made the penetration profiles of 137cs and 22na have long tails even though the vein was disconnected at depths of 27 30 mm figs 4b and 5c while the apertures of intergranular pores were 0 5 μm their formation factor was calibrated to be 1 10 4 these calibration results indicate that the diffusion along the intergranular pores might be relatively limited compared with the porous structures observed in the 14c pmma image it should be noted that although still regarded as a diffusive pathway in crystalline rocks the geometry and distribution of the main minerals or intergranular pores observed from only the mineral staining image are fairly different from those of the porous structures detected in the 14c pmma image figs 3 and 4 fig 11 illustrates the simulation results for diffusion of a sorbing tracer 137cs into the rock matrix during the in situ ltde sd test early in the simulation 137cs began to diffuse through the disturbed k feldspar occupying most of the rock surface and the microfractures exposed on the surface fig 11a then some of the 137cs penetrating the surface sorbed to the disturbed biotite near the surface this strong sorption of 137cs to the disturbed biotite was visualized with the grains being red near the rock surface in fig 11a d and was one of the main reasons for the peak concentration and the sharp decrease of the penetration profile in the near surface area the remaining mass that entered the rock matrix but was not sorbed to the minerals diffused into the deeper regions along the porous structures such as the microfractures and the vein in particular the vein was critical to the reproduction of the anomalous deep penetration of 137cs observed in the ltde sd test as shown in fig 11b d the tracer that migrated along the vein spread out through microfractures simultaneously and sometimes sorbed to nearby biotite and plagioclase fig 11c and d the bright colored polygons scattered around the vein correspond to such biotite grains as shown in fig 5c whose locations are accordant to the local peaks of simulated profile fig 10 from these results it is supposed that the different fluctuations in the tails of the penetration profiles observed in the respective core samples were associated with their different distributions of these minerals favorable to 137cs sorption near the porous structures under the assumption that the geometrical properties and diffusivity in free water are independent on tracer diffusion of 22na was also simulated and calibrated comparing to the 137cs result the simulated profile for 22na has the low peak concentration near the surface and the gentle fluctuation fig 9b which was originated from low calibrated mineral specific k d for 22na table 4 in the simulation we assumed that 22na as well as 137cs prefers to sorb to biotite and this assumption resulted in coincidence of the locations of local peaks between their simulated profiles fig 9a and b fig 11e h show that 22na which is a weakly sorbing tracer rapidly diffused along the vein into the matrix and spread to the mineral grains farther from the vein nevertheless due to lack of experimental data or literatures adequacy of the calibrated mineral specific k d for 22na cannot be evaluated in this study 3 4 sensitivity analysis the sensitivity analysis for all parameters calibrated for case 3 especially for migration of 137cs was carried out to investigate which characteristics of the microstructures had been critical to the anomalous observations in the ltde sd test and to evaluate the effects of parameter uncertainty fig 12 the results indicate that the most influential parameter on the modeled results was the k d of 137cs for biotite at the rock surface when this parameter increased the peak concentration increased the slope of the profile got steeper and the resulting penetration depth became shallower fig 12a on the other hand when it decreased to 1 6 10 2 m3 kg the penetration depth became deeper than the calibrated model but the peak concentration got lower than half that from the calibrated model this parameter was also critical to the concentration change of 137cs in the reservoir during the experiment and the remaining mass of 137cs at the end of experiment changed in the range from 12 to 68 of the injection mass while it was 34 for the calibrated model fig 12g however the simulation results were less sensitive to the porosity of biotite at the rock surface i e intragranular porous structures within its given range of 0 6 15 under the assumed porosity diffusion relation fig 12b the sensitivity analysis results also show that the sharp decrease in the concentration of 137cs in the reservoir during the early stage of the experiment might be related to the porosity of non biotitic minerals at the rock surface in fig 12i the concentration changes became similar to the ones observed in the ltde sd test when the porosity of them increased this seems reasonable because the penetration of tracers into the rock matrix would occur via these minerals particularly k feldspar covering most of the surface of the rock sample however this result might be valid only for this rock sample which had no biotite exposed at its surface in other words considering the ltde sd core samples where biotite grains were mostly observed in their first slices nilsson et al 2010 the porosity of non biotitic minerals calibrated here could be overestimated while that of the intragranular porous structures would thus be underestimated if this rock sample had a few biotite grains at its surface like the other ltde sd cores did the curve fitting result for the concentration of the tracer cocktail early in the experiment would be improved the depth of the disturbed zone was associated with the distribution of near surface minerals for example for the disturbance depth of 2 mm the peak concentration of 137cs was of one order of magnitude lower than the one observed fig 12d this is because the near surface biotite grains were hardly disturbed under this condition fig 5c moreover diffusion through the non biotitic minerals near the rock surface was limited on the other hand for the disturbed zone 20 mm deep the disturbed non biotitic minerals could transfer tracer deeper into the matrix and the biotite grains located deeper had higher sorption capacity therefore the resulting peak concentration was about one third of the fitted one and the penetration profile had a flat slope for its surface fig 12d because the diffusion through the disturbed non biotitic minerals at the surface determined the amount of tracers penetrating the rock matrix the depth of the disturbed zone was also critical to the concentration change in the reservoir fig 12h as mentioned previously no effect of disturbance on the porosity of the intragranular porous structures as revealed in the 14c pmma autoradiography was considered in the modelling for case 3 however fig 12f shows that as the ratio for disturbance on porosity decreased the penetration depth became shallower because it led to decrease in the diffusion along the vein when the ratio for disturbance on sorption capacity of biotite was lower than the calibrated one it could create a penetration profile with a gentler and flatter slope of tail fig 12e however it should be noted that there are many difficulties and uncertainties in measuring the impacts of disturbance on these transport properties using laboratory or in situ experiments the diffusion along the microfractures must also be one of the factors critical to reproducing the penetration profile when the formation factor of the microfractures increased the penetration depth became deeper than that of the calibrated one and the concentration values of local peaks observed in the tail of profile increased fig 12c from this result it could again be inferred that the microfractures had mainly transferred the tracers from the vein to the nearby sorbing mineral grains 4 conclusions in this study modelling work was carried out to reproduce the anomalous results observed in the in situ experiment about long term matrix diffusion and sorption performed at äspö hrl as the most probable reason for such results this study focused on the heterogeneity of the rock matrix which consists of various types of microstructures such as mineral grains and microfractures and then established three cases to incorporate the rock heterogeneity into the model among all three cases particularly in case 3 the modelling domain was established considering the geometry and properties of the microstructures characterized by chemical staining of minerals and by 14c pmma autoradiography on the rock core sample taken from the test site in particular the 14c pmma autoradiography which can visualize actual diffusive pathways provided a vital clue to reproduce the ltde sd results including the existence of a vein and microfractures transecting several minerals in the rock sample the case study results demonstrate that the diffusion and sorption parameter values for the microstructures were calibrated within reasonable ranges of their respective values only in case 3 even though the experimental results were reproduced fairly well in all three cases the model assumptions and settings for case 3 were generally observed in crystalline rocks and they might imply the interactions of various microstructures critical to the diffusion and sorption in rock matrix e g disturbance of minerals near the core surface selective sorption of cesium to biotite and vein and microfractures as highly diffusive pathways however our modelling based on the 2 d microstructure characterization had some limitations for example the presence of a vein diagonally transecting the rock sample must be critical to reproducing the deep penetration of sorbing tracers in the rock matrix observed in the in situ test however it is still questionable whether such result would be reproduced in other core samples where no clear vein was observed also if a few biotite grains were distributed on the rock surface unlike this sample all the parameter values calibrated here could be quite different in particular the three dimensional connectivity of micropore structures and mineral distribution in the real rock matrix cannot be fully characterized in two dimensions and this must also be responsible for the limitation of the results presented here to address this it would be necessary to enhance the spatial resolution of the 3 d microstructure characterization technique enough that the dominant diffusive pathways existing in a rock matrix could at least be detected and to handle efficiently the resulting enormous computation burden in modelling work matrix diffusion and sorption retard migration and or isolate radionuclides in bedrock which serves as the final barrier of the subsurface radioactive waste reposity and have been considered as one of the critical factors in the safety assessment of a subsurface repository for radioactive waste for more reliable and acceptable safety assessment thus it is essential to evaluate more realistic diffusion and sorption properties of bedrock in a repository site the ltde sd test showed that the matrix diffusion and sorption in a real site are different from predicted by the conventional theory assuming homogeneous diffusion with equilibrium sorption this means that the safety assessment based on the conventional theory could be unreliable because the estimated parameters could be different from the real ones and the resulting prediction of nuclide migration would be not true our results indicated that those anomalous observations on matrix diffusion and sorption can be explained by influences of various microstructures existing in a real rock sample from these results it is emphasized that the influences of various microstructures in the rock matrix should be considered in analyzing experimental results and predicting the migration of radionuclides in field scale furthermore it needs to develop the methods to consider the effects of microstructures in the safe assessment for the geological disposal of spent nuclear fuel acknowledgements this work was supported by the nuclear research and development program of the national research foundation of korea nrf funded by the ministry of science and ict no 2017m2a8a5014858 this work is related to task 9 of the äspö task force on modelling of groundwater flow and transport of solutes and we thank skb for providing the data used in this study 
7020,at the in situ long term sorption diffusion experiment ltde sd performed in the äspö hard rock laboratory sweden anomalous penetration profiles of tracers were observed the concentration of sorbing tracers particularly 137cs sharply decreased around the rock surface but was still quite high in the distance which was known that it is difficult to model with the classic fick s law to understand the mechanism of matrix diffusion and sorption of solute by reproducing the observed penetration profiles in the ltde sd test three cases for the matrix were proposed and evaluated 1 homogeneous medium with a disturbed zone 2 heterogeneous medium considering mineral grains with intragranular porosities and their intergranular pores and 3 heterogeneous medium considering vein and microfractures as well as porous mineral grains and intergranular pores the modelling domains for cases 2 and 3 were established using 2 d microstructure characterization results from analyses including chemical staining of minerals and 14c pmma autoradiography the numerical models for cases 1 3 were calibrated by minimizing the discrepancies between simulations and observations of the penetration profiles and the changes in concentration in the reservoir for the tracers 137cs and 22na the results show that only the calibrated transport parameter values for case 3 were within the reported ranges and we concluded that the sharp decrease in concentrations in the near surface zone in the observed penetration profiles was likely to result from disturbed biotite grains and the long tails in the observed penetration profiles might originate from diffusion along the vein and microfractures transecting minerals keywords ltde sd matrix diffusion sorption microstructure heterogeneity 1 introduction several countries that have used nuclear power energy for decades such as sweden finland switzerland and korea have made plans and preparations for geological disposal of high level radioactive waste hlw according to the concept of geological disposal system the hlw will be surrounded by engineered barriers consisting of canister bentonite buffer and tunnel backfill materials if these barriers fail to contain the hlw radionuclides due to aging or system failure they could migrate along with groundwater flow within the geological medium hosting the repository and might eventually reach biosphere matrix diffusion and sorption processes in bedrock are expected to retard such migration of radionuclides released and to prevent for them from reaching the biosphere over long time periods hölttä et al 1997 siitari kauppi et al 1997 sardini et al 2003 2007 voutilainen et al 2009 jokelainen et al 2013 kuva et al 2015 2016 therefore it is necessary to understand these retention mechanisms in bedrock to assess and assure the safety and performance of such geological repositories however despite many studies on this topic over decades it is still difficult to account for the observations from several in situ tracer tests performed earlier in crystalline rocks e g nilsson et al 2010 tachi et al 2015 the long term sorption diffusion experiment ltde sd is an in situ experiment performed in äspö hard rock laboratory hrl in order to understand matrix diffusion and sorption in bedrock in that experiment anomalous concentration profiles of tracers were observed that could not be reproduced by conventional theory assuming homogeneous diffusion with equilibrium sorption nilsson et al 2010 iraola et al 2017 in particular it was observed that for sorbing tracers such as 137cs and 22na most of the mass was detected at the rock surface exposed to the tracer cocktail but the rest diffused a much longer distance than expected deep into the rock matrix fig 1 nilsson et al 2010 iraola et al 2017 similar observations were also found in other laboratory and in situ experiments including the long term diffusion ltd project in grimsel site switzerland and the following phenomena were proposed as the origins of the observed anomalous concentration profiles heterogeneous mineral distribution particularly related to the biotite content at the surface of the rock samples tsukamoto and ohe 1993 increased sorption capacity of biotite disturbed near the rock surface jokelainen et al 2013 tachi et al 2015 or difference between sorption capacities of minerals in the rock matrix iraola et al 2017 voutilainen et al 2017 these previous studies gave insight into possible roles of microstructures in the retention of radionuclides in heterogeneous rocks however these approaches were insufficient to fully account for the penetration profiles observed in this in situ test in which strongly sorbing tracers e g cesium had migrated several tens of millimeters into the rock the geometry and distribution of the rock microstructures have been characterized in micrometer or smaller scale using techniques such as scanning electron microscopy sem sardini et al 1996 hölttä et al 1997 widestrand et al 2007 voutilainen et al 2009 2012 2013 x ray microcomputed tomography x ray μct voutilainen et al 2009 2012 2013 2017 kuva et al 2012 iraola et al 2017 14c labeled polymethylmethacrylate 14c pmma autoradiography hellmuth et al 1993 siitari kauppi et al 1997 widestrand et al 2007 2010 voutilainen et al 2012 2013 2017 sammaljärvi et al 2017 and chemical staining of minerals sardini et al 2006 voutilainen et al 2012 2013 voutilainen 2017 these characterization techniques can provide information including the apertures of microfractures three dimensional distributions of mineral grains connectivity of micropore spaces total porosity of the rock matrix and intragranular porosity and the analyzed results using them have been used to model diffusion of radionuclides in heterogeneous rock matrix simbierowicz and olin 1997 sardini et al 1999 2001 2003 2007 iraola et al 2017 voutilainen et al 2013 2017 in particular voutilainen et al 2013 2017 and iraola et al 2017 have respectively established the 3 d intra or intergranular pore network for their matrix diffusion models using the analyzed 3 d mineral distributions of rock samples with x ray μct to understand the observations at the ltd and ltde sd experiments however it could have a practical difficulty in incorporating a mix of micropores including inter intra and transgranular pores which exist in real rock matrix into the 3 d model on the other hand while being available in two dimensions the 14c pmma autoradiography can visualize the spatial distributions of the micropores that could act as actual migration pathways of radionuclides in the cross section of a rock core hellmuth et al 1993 widestrand et al 2007 2010 voutilainen et al 2012 the mineral staining has generally been used to reveal the 2 d mineral geometry and distribution in the cross section of a rock core voutilainen et al 2012 2013 voutilainen 2017 and it could be useful to investigate effects of mineral specific properties on the matrix diffusion and sorption of radionuclides within the 2 d model in this study we supposed that heterogeneity in the rock matrix from microstructures might significantly have affected the transport of radioactive tracers during the ltde sd test to prove this a case study was performed by incorporating a heterogeneous rock matrix into three conceptual models two of the cases were based on characterization of microstructures existing in a core sample drilled from the bedrock at äspö hrl which had been performed by voutilainen 2017 particularly the realistic geometry and features of the microstructures characterized using 14c pmma autoradiography and chemical staining of minerals were simultaneously considered in the establishment of the modelling domain and settings in the last case to simulate diffusion along various kinds of micropores and mineral specific sorption for all the cases inverse modelling was carried out to calibrate the parameter values for diffusion and sorption of each medium or microstructure that can reproduce the anomalous results observed in the in situ tracer test the adequacy of each case was evaluated based on the validity of the calibrated parameter values by comparing the calibrated values to the reported values from the laboratory and in situ experiments from these results the influences of rock heterogeneity on the matrix diffusion and sorption of tracers observed in the ltde sd test were discussed including the roles of each rock microstructure 2 material and methods 2 1 ltde sd project the ltde sd project was to understand long term matrix diffusion and sorption under in situ conditions and to provide data for assessing performance and safety of geological repository nilsson et al 2010 in this project the in situ tracer test was performed for 198 days in a borehole drilled at a depth of 410 m below sea level in the äspö hrl the borehole is mainly surrounded by ävrö granodiorite and includes a natural fracture at its far end the borehole was drilled to have a diameter of 177 mm from the tunnel wall to the fracture and to have a diameter of 36 mm within an extended interval 1 m from the fracture fig 2 a cup like packer was installed at the fracture surface so that a tracer cocktail injected into the void created between the fracture surface and packer as a reservoir could diffuse into the rock matrix through the fracture surface fig 2 the average width of the reservoir between the fracture surface and packer was about 3 25 mm the tracer cocktail was also injected into the packed off part of the extended interval so that the tracers could diffuse through the borehole wall which can be regarded as a surface of unaltered rock matrix during the experiment period the tracer cocktail was circulated and its changes in concentrations were monitored the tracer cocktail contained 22 sorbing or non sorbing radioactive tracers including 22na 36cl 57co 63ni 133ba and 137cs for about 230 days after the termination of the experiment the rock volume surrounding the test sections was overcored and then a number of small core samples diameter 24 mm were drilled axially from the fracture surface section a core and radially from the extended section d core of the over cored rock volume the surfaces of the a cores had fracture coating or were altered while the surfaces of d cores were regarded to be un or less altered or damaged from the drilling the core samples were cut into slices with 1 to 20 mm thick for about two months until completing the cutting process the tracers in the core samples are expected to continue to diffuse into matrix thereafter the individual tracer concentrations in the rock slices thus the penetration profiles were measured among the injected tracers 137cs and 22na were detected throughout almost all the slices of the core samples however their penetration profiles could not be simulated by assuming homogeneous diffusion nilsson et al 2010 iraola et al 2017 for example the profiles of 137cs observed in all the core samples have a sharp decrease around the surfaces that were exposed to the tracer cocktail and a flat slope of tailing in the inner rock matrix fig 1a the tailing mostly began at the depth of 5 10 mm from the rock surface and their concentrations were about four orders of magnitude lower than their peak values particularly it can be interpreted as fast diffusion of this strongly sorbing tracer 137cs in rock matrix this tailing was also observed in the profiles of 22na fig 1b despite various analyses on the experimental data and results these spatial distributions and levels of tracer concentrations in the rock slices could not be explained with only the geological characteristics observed on the surfaces of core samples that had been given in nilsson et al 2010 including their surface type locations microfractures mineralogy alteration and fracture coating the details for this experiment can be found in widestrand et al 2010 and nilsson et al 2010 2 2 microstructure characterization on the rock sample to characterize the microstructures of the matrix at the ltde sd test site various analyses including 14c pmma autoradiography and chemical staining of minerals were performed by voutilainen 2017 for the rock sample with diameter of 24 mm and length of 45 mm fig 3 which had been additionally sampled near the test site the 14c pmma autoradiography involves impregnation of a rock slice with the 14c labeled polymethylmethacrylate monomer irradiation polymerization autoradiography and optical densitometry using digital image processing techniques it can reveal the accessible micropores existing in rock matrix which are for example shown as the dark areas and lines in fig 3c the chemical staining of minerals for this rock sample involves sodium ferrocyanide treatment hf acid etching hcl cleaning and sodium cobaltnitride treatment after the treatment mica minerals plagioclase and k feldspar turn blue white and yellow respectively while quartz remain unchanged as shown in fig 3b the mineral staining result showed that the rock at the test site is mainly composed of four minerals plagioclase 39 4 k feldspar 32 6 quartz 26 6 and biotite 1 4 the intragranular porosity of each mineral was determined using the images from chemical staining of minerals and 14c pmma autoradiography which is given in table 1 in this study the geometry and distribution of the mineral grains and micropore network visualized with both techniques were used in incorporating the heterogeneous rock matrix into the modelling domains in the assumed cases fig 4 and this procedure will be described hereafter 2 3 case study to understand the mechanism of diffusion and sorption in a rock matrix by reproducing the observations in the in situ ltde sd test three cases were considered by assuming a matrix to be 1 a homogeneous medium with a disturbed zone at the surface 2 a heterogeneous medium considering mineral grains with intragranular porosities and their intergranular pores and 3 a heterogeneous medium considering vein and microfractures as well as mineral grains and intergranular pores based on the assumptions of each case 2 d modelling domains were established from 2 d microstructure characterization results and the diffusion and sorption parameter values were calibrated for 137cs and 22na using a trial and error method by minimizing the discrepancies between the observed and simulated results of their penetration profiles in rock cores and concentrations in the remained tracer cocktail at the reservoir during the ltde sd test fig 1 diffusion in rock matrix was assumed to be dependent only on geometrical properties of matrix or microstructures such as porosity or apertures of microfractures therefore the parameter values for diffusion were determined regardless of the kind of tracers the modelling work in this study was implemented using the commercial finite element software comsol multiphysics the total simulation time was set to 463 days including the experimental period 198 days and the post experimental period including overcoring core sampling and slicing periods 265 days the simulated penetration profiles shown in this study thus are the results after 463 days from the start of the experiment in the experiment the profiles of 137cs and 22na which are γ emitting radionuclides were obtained by measuring the radioactivity in the crushed and sliced rock samples using high purity germanium detector hpge therefore the measured activity was considered to be the total concentration of both the sorbed and dissolved phases of tracers contained in the rock matrix nilsson et al 2010 thereafter the adequacy of the calibrated parameter values for each case was assessed by comparing with the values obtained from the laboratory and in situ experiments 2 3 1 case 1 nilsson et al 2010 already suggested a two pathway model assuming slow migration in the near surface zone and fast migration in the matrix to fit the penetration profile of a ltde sd core sample similarly a conceptual model assuming a disturbed zone near rock surface and a homogeneous medium in undisturbed rock matrix was considered in this study as case 1 fig 5 a according to the results of the ltde sd test the depth at which the slopes in most of the 137cs profiles began to change was within 5 10 mm from the surfaces of the core samples we therefore assumed this to be the depth of the disturbed zone in the disturbed zone the parameter values for diffusion and sorption were assumed to decrease gradually with distance from the rock surface and were set to be identical to those of the undisturbed matrix at the end of this zone on the left part of the domain for the rock core in fig 5a a reservoir containing the tracer cocktail was assumed to represent the void between the cup like packer and the surface of a core which had a width of 3 25 mm as shown in fig 2 the size of the modelling domain corresponding to the rock core was 63 7 mm length 24 0 mm height 2 3 2 case 2 in the autoradiography analysis on the rock slices in the ltde sd experiment it was observed that the blackened areas which indicate locations of radioactive tracers were similar to the locations of dark minerals such as biotite and chlorite nilsson et al 2010 which was in agreement with the interpretation of the distribution of cs in the epma analysis by tachi et al 2015 muuri et al 2016 2017 also demonstrated through batch experiments the predominance of biotite for cesium sorption compared with the other major minerals in the bedrock at the grimsel and olkiluoto sites plagioclase is known to be another mineral available for cesium sorption muuri et al 2016 intergranular pores are usually invisible to the naked eye but its well connected networks can act as diffusion pathways in crystalline rocks having low porosity sardini et al 1999 tachi et al 2015 for case 2 it was assumed that radionuclides could diffuse through the mineral grains with intragranular porosities and the pore boundaries between them and would sorb only to biotite and plagioclase to simulate this a modelling domain with size nearly identical to that for case 1 was constructed with the 2 d mineral distribution in a rock sample characterized from the mineral staining analysis fig 3b from the picture of the mineral distribution in fig 3b polygons along the geometry and distribution of mineral grains were first delineated in autocad fig 4a these were imported into comsol multiphysics and then mirrored to simulate a deep penetration into the rock core fig 5b the interface between the reservoir and rock in the modelling domain was reconstructed with an irregular and rough surface of the matrix part in the rock sample the alteration rim existing above the interface of the rock sample was excluded from this model work the locations of biotite and plagioclase are identified with dark blue polygons and sky blue polygons in figs 4a and 5b respectively gray polygons in fig 5b indicate the locations of k feldspar and quartz which have low porosity and sorption capacity in the simulation the porosities of the non biotitic minerals i e plagioclase k feldspar and quartz were assumed to be identical because they had been estimated to be within a range of 0 2 to 0 3 table 1 the pore boundaries between all the mineral grains were assumed to be well connected and to have a constant aperture red lines in fig 5b for this case the vein crossing the rock sample shown in fig 3 was regarded as one of the non biotitic minerals without sorption capacity 2 3 3 case 3 in the 14c pmma autoradiograph given in voutilainen 2017 a complicated porous network consisting of a vein and microfractures was visualized while some intragranular porosities were found in biotite grains and in altered parts of non biotitic minerals fig 3c all these observed porous structures could be preferential diffusive pathways in the rock matrix and the entire matrix diffusion must therefore be dependent on their distribution and connectivity sardini et al 2001 2003 2006 for case 3 we considered the porous minerals and the vein with intragranular porosities and the microfractures as linear structures which were observed in the 14c pmma as well as the minerals and the intergranular pores that were considered for case 2 in particular the porous minerals and the vein were collectively called intragranular porous structures in this case it was assumed that radionuclides could mainly diffuse through these porous structures but would sorb only to biotite and plagioclase to reflect the distribution and connectivity of the porous structures in the model the 14c pmma image was modified by inverting its gray value and equalizing its brightness fig 4b then the geometry and locations of the porous structures were extracted from that image with consideration of the mineral staining image pink polygons for intragranular porous structures except for biotite and green lines for microfractures in fig 4b these were overlapped with the modelling domain obtained in the previous case fig 5c the porosities of all the intragranular porous structures detected in the 14c pmma image were assumed to be identical and the non biotitic minerals were also assumed to have the same porosity unlike case 2 it was assumed that diffusion along the intergranular pores drawn with red lines is available through only the grain boundaries between the quartz and the two feldspars that had been distinguished clearly in the mineral staining image fig 3b the grain boundaries between plagioclase and k feldspar in the mineral staining image were often vague to be defined in the model domain this may be because they have no or very tiny aperture of pores as a result in this case the intergranular pores were often disconnected within the core sample fig 5c 2 4 sensitivity analysis the adequacy of the cases considered was examined by evaluating whether the parameter values calibrated for each case are within ranges of the values estimated from laboratory and in situ experiments for the most plausible case thereafter a sensitivity analysis was carried out in order to investigate influences of each parameter and its uncertainty on the anomalous diffusion observed at the ltde sd test sensitivity to each parameter was evaluated by re simulating the model established in that case with its different input values which were for example obtained by multiplying a calibrated value by 0 2 0 5 2 and 5 respectively 2 5 numerical approach 2 5 1 diffusion and sorption in the 2 d planar structures although the matrix diffusion could be dependent on various factors including molecular size and charge of radionuclides sorption capacity of the minerals and groundwater composition havlová et al 2012 voutilainen et al 2013 kuva et al 2015 the geometrical properties of pores like porosity and tortuosity are most important because they control the diffusion pathways of radionuclides hellmuth et al 1993 sardini et al 1996 kuva et al 2015 tachi et al 2015 in this study the millington and quirk model was used to express the relation between the effective diffusion coefficient of saturated porous media and porosity millington and quirk 1961 with this porosity diffusion relation the effective diffusion coefficient d e l2 t of each 2 d planar structure such as a porous medium for case 1 or minerals and vein for cases 2 and 3 is defined as 1 d e ε τ d w f d w 2 τ ε 1 3 where ε is the porosity τ is the pore tortuosity d w is the diffusivity in free water l2 t assumed to be 2 1 10 9 m2 s for both 137cs and 22na and f is the formation factor effects of the chemical properties of tracers on the diffusion e g cation excess diffusion were neglected and equilibrium linear isotherm was applied for the sorption of 137cs and 22na because the measured concentrations were given by decay corrected activities using the injection date as time zero radioactive decay of the tracers was neglected the governing equation for transport of a radionuclide in a rock matrix assuming fickian diffusion and equilibrium linear sorption was given as follows 3 c t o t t d e c 4 c t o t α c ε k d ρ b c where c tot is the total concentration of radionuclide in the dissolved and sorbed phases m l3 t is the time t c is the concentration of radionuclide in the dissolved phase m l3 α is the rock capacity factor k d is the distribution coefficient l3 m and ρ b is the bulk density m l3 in case 1 the bulk density of the medium was set to 2700 kg m3 following nilsson et al 2010 for cases 2 and 3 the bulk densities of the minerals were assumed to be 3000 kg m3 for biotite and 2650 kg m3 for the other minerals 2 5 2 diffusion along the 1 d linear structures the 1 d linear structures such as intergranular pores of which the apertures were mostly 1 μm and microfractures of which the apertures were tens of micrometers were regarded as diffusion pathways of radionuclides in the rock matrix the former were applied to the modelling domains for cases 2 and 3 but the latter were included only in case 3 to simulate the diffusion along these structures the 1 d solute transport along the interior boundaries was incorporated into the 2 d modelling domain 5 ε l d l c t d l f l d w t c where ε l is the porosity of linear structure d l is the aperture of linear structure l f l is the formation factor of linear structure and t is the gradient operator to the tangential plane of a linear structure the porosities of all the linear structures were set to 1 by assuming a full opening neither sorption to nor reaction on these structures was considered in spite of the actual variation of their apertures sardini et al 2014 they were assumed to be uniform for simplicity 2 5 3 disturbed zone disturbed zone was mainly formed near rock surfaces altered by weathering or damaged by the borehole drilling the retention properties of the medium or the minerals in this zone could therefore be changed from those in the undisturbed rock matrix in this modelling work it was assumed that the parameter values decrease gradually within a specified depth from the rock surface which means the extent of disturbed zone and then remain constant in the undisturbed matrix as variables to assess the influence of disturbance the ratios of the respective parameter values for diffusion and sorption at the surface and in the undisturbed matrix were used to calibrate the model this means that the parameter values for the undisturbed matrix could be calculated using the calibrated ratios for disturbance and the calibrated values at the surface we also assumed that change in the characteristic parameter values in a disturbed zone followed the smoothed heaviside function so that the change could be gradual and smooth rather than sharp or linear for example in cases 2 and 3 the distribution coefficients k d of a tracer for minerals in the disturbed zone and undisturbed matrix were given by 6 log 10 k d x log 10 k d s f log 10 k d s f log 10 k d m t h x 0 x d d subject to h x 0 5 0 9375 2 x d d d d 0 625 2 x d d d d 3 0 1875 2 x d d d d 5 7 k d m t k d s f k f where x is the depth from the outermost point of the rock surface x 0 l k d m t is the distribution coefficient of the tracer for a mineral located in the rock matrix x d d l3 m k d s f is the distribution coefficient of the tracer for a mineral located at the rock surface x 0 l3 m h x is the smoothed heaviside function with a continuous second derivative without overshoot whose value changes gradually from 0 to 1 within a given interval kf is the ratio for disturbance on sorption and d d is the depth of the disturbed zone l in eq 6 the logarithms of k d were used to introduce gradual change of k d in the disturbed zone where k d can vary by several orders of magnitude the diffusion in the disturbed zone was also considered by adjusting the porosities in the disturbed zone as in eqs 6 and 7 the terms k d s f k d m t and kf in eqs 6 and 7 were replaced with the porosities i e ε d s f and ε d m t and the ratio for disturbance on porosity df 2 5 4 initial and boundary conditions for all three cases the initial concentrations of 137cs and 22na in the reservoir were set to the concentrations of those tracers in the cocktail injected at the beginning of the ltde test the background concentrations of the tracers in the rock matrix were assumed to be zero a no flux boundary condition was assigned to all the side boundaries of the domain the fickian diffusion of tracers in the reservoir was also simulated with their respective d w the decreases in tracer concentrations in the reservoir measured during the experiment period were compared with the area weighted average of concentration values at the nodes of the reservoir at each time step after the termination of the experiment despite stopping the exposure of the tracer cocktail to the rock surface the radionuclides that had already entered the rock matrix would continue to diffuse deep into the matrix until the rock cores were sliced for simulation of this process therefore a no flux boundary condition was also applied to the interior boundary corresponding to the interface of reservoir and rock called the rock surface in this study after 198 days 3 results and discussion 3 1 case 1 in this case the distribution coefficient and porosity of the medium at the surface the ratios of disturbance for sorption and diffusion and the depth of the disturbed zone were calibrated to simultaneously reproduce the observations reported for 137cs and 22na in the ltde sd test the calibrated parameters are listed in table 2 for 137cs in particular the simulated penetration profile had a dual slope like the observed one and the simulated change in the concentration within the reservoir fit the measured one fairly well fig 6 the depth of the disturbed zone was calibrated to 10 mm which was near the depth where the slopes of profiles for most of the core samples changed sharply the calibrated k d of 137cs for the undisturbed matrix however should have decreased by five orders of magnitude compared to that at the surface fig 7 this discrepancy is similar to the result from previous work by nilsson et al 2010 but such change within only several millimeters from the surface seems to be implausible in addition the calibrated k d of 137cs for the surface 1 0 10 3 m3 kg led to a peak concentration of about 2 6 103 bq g which was lower than the least value measured in the a5 core among all the cores if the k d at the surface was larger than the one determined the resulting peak concentration could increase however the penetration depth of the tracer or the tail of profile would become shorter and the concentration of tracer remaining in the reservoir would decrease 3 2 case 2 for case 2 the aperture and formation factor of the intergranular pores were calibrated along with the distribution coefficients and porosities of minerals at the surface the ratios of disturbance for sorption and diffusion on minerals and the depth of the disturbed zone table 3 fig 8 indicates the simulation results with the calibrated parameters as shown in table 3 the ratio of disturbance for sorption to biotite was calibrated to 1 0 10 4 which means that the k d of 137cs for biotite in the undisturbed matrix is four orders of magnitude smaller than that for biotite at the rock surface moreover the aperture and formation factor of the intergranular pores which must be a major diffusive pathway were calibrated to 0 5 μm and 1 0 10 1 respectively the resulting profile of k d over the entire rock core for this case is shown in fig 7 and is dependent on the contents of the mineral grains along the depth as well as their calibrated k d the profile of k d also indicates that the simulated sharp decrease of the 137cs concentration near the rock surface mainly originated from the decrease of k d for biotite located in the disturbed zone despite the agreement of the simulation results with the observations however it is still questionable that not only could the k d for biotite in the matrix differ from that at the surface this much within the depth of a few millimeters as also discussed for the results of case 1 but all the intergranular pores could also be connected with such a formation factor in crystalline rocks 3 3 case 3 the rock microstructures considered in this case included the porous structures detected in the 14c pmma autoradiography such as the vein and microfractures as well as the mineral grains and their intergranular pores detected in the mineral staining image the calibrated parameters for case 3 are listed in table 4 the simulation using the calibrated parameters reproduced the experimental results for 137cs and 22na of ltde sd test well fig 9 in particular the simulated 137cs penetration profiles exhibited peak concentrations at the rock surface then a sharp decrease in concentration within several millimeters of depth and a long tail within the range of measured concentrations in the experiment in this case the k d of 137cs for biotite at the rock surface was 8 0 10 2 m3 kg which was lower than that of case 2 this result seems to be related to the porous structures added in this case which could enhance diffusion into the rock matrix however there are still overall discrepancies between the simulations and observations for example the simulated penetration profiles began with a much lower concentration at the rock surface than the measured one fig 9a and b which was also observed in case 2 fig 8a and b this low concentration might originate from the cross section of the rock sample that we used to establish the modelling domains the cross section had no biotite where cs and na could sorb at the surface exposed to the tracer cocktail contained in the reservoir figs 4 and 5c this effect might be exaggerated due to the dimensions of the model the concentrations were observed using 3 d core samples but were simulated with a 2 d modelling domain therefore in the simulations the peak concentrations of the profiles were observed at the location of the biotite grains closest to the rock surface which was about 1 4 mm from the surface the fluctuations in the penetration profiles were dependent on the content and distribution of biotite grains in the rock matrix for example the ledge at 5 4 mm deep and the small peaks near 10 mm deep observed in the 137cs profile had biotite content 7 above the average fig 10 nevertheless near the depth of 18 mm the concentrations in the profile were relatively low even though the biotite content was as high as those of the local peaks mentioned above fig 10 this was because the increased content of biotite grains at that depth were far away and disconnected from the vein acting as the main diffusion pathway in this rock sample this can be seen at 8 2 9 4 and 21 4 23 4 mm in the y direction in fig 5c meanwhile several local peaks were observed despite the low biotite content for example at the depths of 19 3 30 0 and 34 0 mm fig 10 small biotite grains that were directly connected to the vein by microfractures or were located on the vein are found at those depths in fig 5c the decrease in the tracer concentration in the reservoir was underestimated in the early part of the experiment although the concentration reaching steady state thereafter was in agreement with the measurement fig 9c this result also seems to be related to the absence of biotite at the surface of the core sample if some biotite grains were located at the rock surface the diffusion from the reservoir into the rock matrix would be enhanced due to its high porosity however it needs to be noted that the measured tracer concentration in the in situ test was the result from averaging diffusion over the entire rock volume which had more severe heterogeneity in the content and distribution of minerals at its surface than did that of a core sample the calibrated k d of 137cs for biotite at the rock surface in this case was lower than those 3 0 5 8 10 1 m3 kg derived from the batch experiments in muuri et al 2016 2017 the peak of the resulting k d profile over the core sample fig 7 2 1 10 3 m3 kg was also lower than the value of the crushed rocks estimated in the batch test performed for the ltde sd project 1 0 10 2 to 9 0 10 1 m3 kg widestrand et al 2010 these differences may be explained partly by the dependency of the parameter estimated in batch tests on the grain size and the resulting specific surface area of crushed samples hölttä et al 1997 widestrand et al 2010 tachi et al 2015 muuri et al 2016 nevertheless the peak value of the profile was within the range of the conservative k d 1 4 8 7 10 3 m3 kg estimated by nilsson et al 2010 which had been calculated by dividing the tracer concentration in the slices closest to the surfaces of the core samples by the concentration in the tracer cocktail at the end of the experiment the calibrated k d of 137cs for plagioclase at the rock surface 1 0 10 4 m3 kg was much lower than those derived by muuri et al 2016 2017 however the weak sorption to plagioclase which was the most abundant mineral in the rock sample tested could alleviate fluctuation in the k d profile for 137cs over the core sample which might be more severe due to the sparse distribution of biotite in it the depth of the disturbed zone was 6 mm from the outermost point of the rock surface table 4 the kf of biotite for 137cs was determined to be 0 01 meaning that the k d of 137cs for biotite located in the undisturbed matrix was 8 0 10 4 m3 kg this ratio of disturbance is roughly in agreement within the result from the through diffusion test of the ltd project tachi et al 2015 in that test the k d of 137cs for undisturbed matrix was estimated to be lower by about two orders of magnitude than that for the rock surface the most distinctive intragranular porous structure observed in the 14c pmma image was the vein diagonally crossing the rock sample figs 3c and 4b the image indicated that this structure had high porosity and thus could be the main pathway for the diffusion of tracers occurring in this rock sample the remaining intragranular porous structures observed in the 14c pmma image were the biotite and the altered parts of the non biotitic minerals the porosity of biotite was calibrated to be 3 0 table 4 which is greater than the measured porosity table 1 this result seems to be associated with the assumption of uniform porosity for all the intragranular porous structures detected in the 14c pmma result in the modelling this is because under this assumption the porosity of biotite could also control the diffusion through the vein which was critical to the reproduction of the deep penetration of tracers observed in the ltde sd test another important parameter controlling the penetration profile was the ratio of disturbance for the porosity of the intragranular porous structures this parameter was calibrated to be 1 0 which means there was no disturbance of the porosities of these structures at the rock surface this is consistent with the observation in 14c pmma image which did not provide any clear evidence for disturbance of their porosities in the rock matrix region considered in this study fig 4b according to the millington and quirk model the formation factor estimated from the porosity of these structures was 9 3 10 3 the calibrated porosities of non biotitic minerals in the disturbed zone and in undisturbed matrix are very low table 4 this means that diffusion through non biotitic minerals might be very limited with their apertures of 10 μm the formation factor of microfractures transecting several mineral grains was calibrated to be 5 10 3 which was of the same order of magnitude as the formation factor of the vein the microfractures acted as the main pathways for migration of the tracers to the mineral grains far from the vein and made the penetration profiles of 137cs and 22na have long tails even though the vein was disconnected at depths of 27 30 mm figs 4b and 5c while the apertures of intergranular pores were 0 5 μm their formation factor was calibrated to be 1 10 4 these calibration results indicate that the diffusion along the intergranular pores might be relatively limited compared with the porous structures observed in the 14c pmma image it should be noted that although still regarded as a diffusive pathway in crystalline rocks the geometry and distribution of the main minerals or intergranular pores observed from only the mineral staining image are fairly different from those of the porous structures detected in the 14c pmma image figs 3 and 4 fig 11 illustrates the simulation results for diffusion of a sorbing tracer 137cs into the rock matrix during the in situ ltde sd test early in the simulation 137cs began to diffuse through the disturbed k feldspar occupying most of the rock surface and the microfractures exposed on the surface fig 11a then some of the 137cs penetrating the surface sorbed to the disturbed biotite near the surface this strong sorption of 137cs to the disturbed biotite was visualized with the grains being red near the rock surface in fig 11a d and was one of the main reasons for the peak concentration and the sharp decrease of the penetration profile in the near surface area the remaining mass that entered the rock matrix but was not sorbed to the minerals diffused into the deeper regions along the porous structures such as the microfractures and the vein in particular the vein was critical to the reproduction of the anomalous deep penetration of 137cs observed in the ltde sd test as shown in fig 11b d the tracer that migrated along the vein spread out through microfractures simultaneously and sometimes sorbed to nearby biotite and plagioclase fig 11c and d the bright colored polygons scattered around the vein correspond to such biotite grains as shown in fig 5c whose locations are accordant to the local peaks of simulated profile fig 10 from these results it is supposed that the different fluctuations in the tails of the penetration profiles observed in the respective core samples were associated with their different distributions of these minerals favorable to 137cs sorption near the porous structures under the assumption that the geometrical properties and diffusivity in free water are independent on tracer diffusion of 22na was also simulated and calibrated comparing to the 137cs result the simulated profile for 22na has the low peak concentration near the surface and the gentle fluctuation fig 9b which was originated from low calibrated mineral specific k d for 22na table 4 in the simulation we assumed that 22na as well as 137cs prefers to sorb to biotite and this assumption resulted in coincidence of the locations of local peaks between their simulated profiles fig 9a and b fig 11e h show that 22na which is a weakly sorbing tracer rapidly diffused along the vein into the matrix and spread to the mineral grains farther from the vein nevertheless due to lack of experimental data or literatures adequacy of the calibrated mineral specific k d for 22na cannot be evaluated in this study 3 4 sensitivity analysis the sensitivity analysis for all parameters calibrated for case 3 especially for migration of 137cs was carried out to investigate which characteristics of the microstructures had been critical to the anomalous observations in the ltde sd test and to evaluate the effects of parameter uncertainty fig 12 the results indicate that the most influential parameter on the modeled results was the k d of 137cs for biotite at the rock surface when this parameter increased the peak concentration increased the slope of the profile got steeper and the resulting penetration depth became shallower fig 12a on the other hand when it decreased to 1 6 10 2 m3 kg the penetration depth became deeper than the calibrated model but the peak concentration got lower than half that from the calibrated model this parameter was also critical to the concentration change of 137cs in the reservoir during the experiment and the remaining mass of 137cs at the end of experiment changed in the range from 12 to 68 of the injection mass while it was 34 for the calibrated model fig 12g however the simulation results were less sensitive to the porosity of biotite at the rock surface i e intragranular porous structures within its given range of 0 6 15 under the assumed porosity diffusion relation fig 12b the sensitivity analysis results also show that the sharp decrease in the concentration of 137cs in the reservoir during the early stage of the experiment might be related to the porosity of non biotitic minerals at the rock surface in fig 12i the concentration changes became similar to the ones observed in the ltde sd test when the porosity of them increased this seems reasonable because the penetration of tracers into the rock matrix would occur via these minerals particularly k feldspar covering most of the surface of the rock sample however this result might be valid only for this rock sample which had no biotite exposed at its surface in other words considering the ltde sd core samples where biotite grains were mostly observed in their first slices nilsson et al 2010 the porosity of non biotitic minerals calibrated here could be overestimated while that of the intragranular porous structures would thus be underestimated if this rock sample had a few biotite grains at its surface like the other ltde sd cores did the curve fitting result for the concentration of the tracer cocktail early in the experiment would be improved the depth of the disturbed zone was associated with the distribution of near surface minerals for example for the disturbance depth of 2 mm the peak concentration of 137cs was of one order of magnitude lower than the one observed fig 12d this is because the near surface biotite grains were hardly disturbed under this condition fig 5c moreover diffusion through the non biotitic minerals near the rock surface was limited on the other hand for the disturbed zone 20 mm deep the disturbed non biotitic minerals could transfer tracer deeper into the matrix and the biotite grains located deeper had higher sorption capacity therefore the resulting peak concentration was about one third of the fitted one and the penetration profile had a flat slope for its surface fig 12d because the diffusion through the disturbed non biotitic minerals at the surface determined the amount of tracers penetrating the rock matrix the depth of the disturbed zone was also critical to the concentration change in the reservoir fig 12h as mentioned previously no effect of disturbance on the porosity of the intragranular porous structures as revealed in the 14c pmma autoradiography was considered in the modelling for case 3 however fig 12f shows that as the ratio for disturbance on porosity decreased the penetration depth became shallower because it led to decrease in the diffusion along the vein when the ratio for disturbance on sorption capacity of biotite was lower than the calibrated one it could create a penetration profile with a gentler and flatter slope of tail fig 12e however it should be noted that there are many difficulties and uncertainties in measuring the impacts of disturbance on these transport properties using laboratory or in situ experiments the diffusion along the microfractures must also be one of the factors critical to reproducing the penetration profile when the formation factor of the microfractures increased the penetration depth became deeper than that of the calibrated one and the concentration values of local peaks observed in the tail of profile increased fig 12c from this result it could again be inferred that the microfractures had mainly transferred the tracers from the vein to the nearby sorbing mineral grains 4 conclusions in this study modelling work was carried out to reproduce the anomalous results observed in the in situ experiment about long term matrix diffusion and sorption performed at äspö hrl as the most probable reason for such results this study focused on the heterogeneity of the rock matrix which consists of various types of microstructures such as mineral grains and microfractures and then established three cases to incorporate the rock heterogeneity into the model among all three cases particularly in case 3 the modelling domain was established considering the geometry and properties of the microstructures characterized by chemical staining of minerals and by 14c pmma autoradiography on the rock core sample taken from the test site in particular the 14c pmma autoradiography which can visualize actual diffusive pathways provided a vital clue to reproduce the ltde sd results including the existence of a vein and microfractures transecting several minerals in the rock sample the case study results demonstrate that the diffusion and sorption parameter values for the microstructures were calibrated within reasonable ranges of their respective values only in case 3 even though the experimental results were reproduced fairly well in all three cases the model assumptions and settings for case 3 were generally observed in crystalline rocks and they might imply the interactions of various microstructures critical to the diffusion and sorption in rock matrix e g disturbance of minerals near the core surface selective sorption of cesium to biotite and vein and microfractures as highly diffusive pathways however our modelling based on the 2 d microstructure characterization had some limitations for example the presence of a vein diagonally transecting the rock sample must be critical to reproducing the deep penetration of sorbing tracers in the rock matrix observed in the in situ test however it is still questionable whether such result would be reproduced in other core samples where no clear vein was observed also if a few biotite grains were distributed on the rock surface unlike this sample all the parameter values calibrated here could be quite different in particular the three dimensional connectivity of micropore structures and mineral distribution in the real rock matrix cannot be fully characterized in two dimensions and this must also be responsible for the limitation of the results presented here to address this it would be necessary to enhance the spatial resolution of the 3 d microstructure characterization technique enough that the dominant diffusive pathways existing in a rock matrix could at least be detected and to handle efficiently the resulting enormous computation burden in modelling work matrix diffusion and sorption retard migration and or isolate radionuclides in bedrock which serves as the final barrier of the subsurface radioactive waste reposity and have been considered as one of the critical factors in the safety assessment of a subsurface repository for radioactive waste for more reliable and acceptable safety assessment thus it is essential to evaluate more realistic diffusion and sorption properties of bedrock in a repository site the ltde sd test showed that the matrix diffusion and sorption in a real site are different from predicted by the conventional theory assuming homogeneous diffusion with equilibrium sorption this means that the safety assessment based on the conventional theory could be unreliable because the estimated parameters could be different from the real ones and the resulting prediction of nuclide migration would be not true our results indicated that those anomalous observations on matrix diffusion and sorption can be explained by influences of various microstructures existing in a real rock sample from these results it is emphasized that the influences of various microstructures in the rock matrix should be considered in analyzing experimental results and predicting the migration of radionuclides in field scale furthermore it needs to develop the methods to consider the effects of microstructures in the safe assessment for the geological disposal of spent nuclear fuel acknowledgements this work was supported by the nuclear research and development program of the national research foundation of korea nrf funded by the ministry of science and ict no 2017m2a8a5014858 this work is related to task 9 of the äspö task force on modelling of groundwater flow and transport of solutes and we thank skb for providing the data used in this study 
7021,accurate forecast stages at river sections is of paramount importance to properly address flood forecasting and warning systems ffwss operating in real time the forecast values can be provided by flood wave routing models to be implemented when gauged sections are operative along the channel different models have been proposed in the literature and the forecast can be approached by neglecting or involving the contribution of lateral inflows among the latter recently stafom rcm stage forecasting model rating curve model has been proposed assuming a lateral contribution uniformly distributed along the reach therefore the model application is not suitable for future stage prediction at hydrometric sections located just downstream river confluences to overcome this issue we propose a methodology that exploits the probabilistic forecast estimated at a gauged site on a tributary through a bayesian approach and the probabilistic relationship between the stages recorded here and the ones at a downstream site located along the main channel where the forecasted stage estimate is of interest the paglia river basin in central italy is selected as case study the results indicate that the procedure can be useful to address real time hydraulic risk management even at river sections located downstream important confluences provided that gauged sites are operative along the tributary keywords flood forecasting river confluences real time lateral inflow predicative uncertainty 1 introduction last decades showed the steady increase of damages due to flooding highlighting the need of developing effective measures to reduce the flood events impacts to this end structural and non structural measures may be used to mitigate the hydraulic risk as regards the latter forecasting models providing future estimates of main hydrological quantities represent one of the fundamental components of real time flood monitoring and warning systems fmwss traditionally flood forecasting is approached through 1 rainfall runoff providing forecasted discharge at the basin outlet with a lead time close to the time of concentration of the basin or longer if quantitative precipitation forecast qpf are used 2 flood routing models providing forecasts at a downstream end of river reaches with a forecast horizon limited by the flood wave travel time vivoni et al 2006 the latter are more appealing for the limited data required and parameters involved for river reaches with negligible intermediate drainage area flood routing models without incorporating lateral inflow can be used moramarco et al 2008 perumal et al 2011 however for long river channels a model capable to quantify the lateral inflow has to be considered and different approaches have been proposed in the literature such as the use of rainfall runoff modelling price 2009 artificial neural networks and fuzzy system tayfur et al 2007 mukerji et al 2009 rezaeianzadeh et al 2014 and simplified methods o donnell 1985 barbetta et al 2011 2017a karahan et al 2014 yadav et al 2015 spada et al 2017 specifically the routing model proposed by barbetta et al 2011 for stage forecast named stafom rcm stage forecasting model rating curve model also incorporates lateral inflow assessment by exploiting a simple approach physically based this forecasting model essentially descends from the combination of a physically based muskingum model and an estimator of lateral inflow specifically stafom rcm assumes a uniform lateral contribution along the reach and assesses the lateral inflow for unit channel length through the continuity equation applied between an upstream and a downstream section moramarco et al 2005 therefore tributaries located immediately upstream the downstream gauged section where the forecast is of interest pose a sub optimal condition because the assumption of uniform lateral inflows does not accurately represent the real inflow distribution making the model application not suitable for stage prediction at hydrometric sections located just downstream river confluences barbetta et al 2017b to overcome this issue we propose a methodology based on the probabilistic forecast estimated at a gauged site on the tributary through the bayesian approach mcp model conditional processor coccia and todini 2011 barbetta et al 2017b and the probabilistic relationship between the stages recorded at tributary site and the ones at a downstream site along the main channel and where the forecast estimate is of interest mcp is a bayesian approach developed for predictive uncertainty pu estimate to support the flood forecasting activities in real time and it is essentially based on the definition of the multi variate conditional distribution i e the density of the predictand water level discharge etc conditional on multiple deterministic model predictions predictors mcp has been applied in previous studies considering both the single model and the multi model configuration coccia and todini 2011 barbetta et al 2016 2017b the results demonstrated that information provided by multiple deterministic forecasts can be useful for improving the performance mainly when deterministic models are characterized by almost homoscedastic error in this study mcp is selected to estimate the predictive uncertainty and the probabilistic relationship between the water levels recorded at two gauged river sites specifically the bayesian approach is applied considering only stafom rcm deterministic model with the main purpose to investigate if the proposed mcp based methodology is able to overcome the limitation of stafom rcm due to lateral inflow along the reach not accurately described as uniformly distributed to this end in this work mcp is also applied for the first time for deriving a probabilistic relationship between stage values recorded at two hydrometric sections based on statistical analysis different approaches are available in the literature for assessing uncertainty in models forecasts such as the hydrological uncertainty processor hup krzysztofowicz 1999 and the quantile regression qr koenker 2005 weerts et al 2011 however the purpose of this work is not the comparison of different approaches for predictive uncertainty assessment discussed in previous works coccia and todini 2011 moreover todini 2013 demonstrated that the results of hup and mcp are identical when predicting one step ahead while the qr does not produce a continuous predictive density but provides a discrete representation based on quantiles and does not guarantee proper results in the normal space koenker 2005 coccia and todini 2011 the paglia river basin in central italy is selected as case study for the presented study the paper is organized as follows section 2 describes the methodology proposed for probabilistic forecast estimate at river sections located just downstream confluences and presents the main characteristics of the deterministic forecasting model and the bayesian approach used in the study section 3 gives details on the selected case study and dataset section 4 presents and discusses the results obtained through the proposed methodology section 5 outlines the conclusions on the potential usefulness of the approach 2 methodology the methodology proposed in this work exploits a the probabilistic relationship between the stages recorded at a site located on the tributary and the ones delayed by the wave travel time tl at a section on the main river downstream the confluence b the probabilistic forecast estimated at the site on the tributary assessed through the model conditional processor mcp using as predictor the forecasts of deterministic models coupling the above information allows to achieve a probabilistic forecast stage at site located on the main river just downstream a concentrate lateral contribution specifically the methodology is based on three main steps 1 the probabilistic relationship between the stages recorded at a gauged site on tributary section b in fig 1 and at a site located on the main river downstream the confluence section c in fig 1 is derived by assigning at each level of tributary the corresponding probability distribution function of expected levels at site on the main channel delayed of tl therefore model conditional processor mcp is applied considering the mean observed travel time 2 the probabilistic forecast at section b is assessed through mcp for a fixed lead time lt the deterministic forecast provided by a forecasting model is used as predictor for the predictive uncertainty estimate by the application of mcp that identifies the probability density of the future stage conditional on the deterministic forecasts coccia and todini 2011 3 the forecast stage at section c is derived by leveraging the mcp expected value at section b and the probabilistic relationship between the stages recorded at the two gauged sections the total forecast horizon is equal to lt tl a brief description of the models used in the study is provided in the following sections 2 1 stage forecasting model stafom rcm stafom rcm staage forecasting model rating curve model provides real time forecast stages by estimating at each time of forecast tf the lateral inflow along the selected reach barbetta et al 2011 specifically stafom rcm approach unlike black box models essentially descends from the combination of a physically based muskingum model and an estimator of lateral inflow and is based on the coupling of two models i e stafom and rcm the final forecast stage is derived through the following main steps 1 stafom is applied providing a preliminary estimate of the forecast stage at the downstream end hd computed as 1 h d t f δ t 1 λ c 1 q u t f q for t f l c 2 h d t f δ 1 δ with hd tf stage observed at the downstream end at tf δt forecast lead time mean observed wave travel time of the reach qu tf observed upstream discharge at tf l river reach length λ and δ parameters of the downstream rating curve qd λ hd δ c1 and c2 refer to the muskingum parameters k and θ respecting the constraint δt 2kθ the lateral inflow contribution for unit channel length qfor is estimated considering the observations at previous time steps as moramarco et al 2005 2 q for t f a d t f a u t f t l t l where au and ad are the upstream and downstream flow areas respectively tl is the flood wave travel time assumed equal to the lead time δt for forecasting purposes the lateral inflow is considered uniformly distributed along the branch and hence the total lateral discharge entering in the reach in the time interval tf tf δt ql is equal to qfor tf l 2 rcm is used improving the preliminary forecast stage the rating curve model rcm is a simple method developed for reconstructing the discharge hydrograph at a river site where only the stage is monitored and the discharge is recorded at another section the model takes account of significant lateral inflow and without using a flood routing procedure permits it to relate the discharge at an upstream section qu with those at a downstream one qd through the following equation moramarco et al 2005 3 q d t t l α a d t t l a u t q u t β where α and β are the rcm model parameters specifically rcm is exploited to refine the preliminary forecast stage hd that is used to assess the downstream flow area ad at time tf δt and hence the quantity ad tf δt au tf qu tf in eq 3 from which the refined forecast stage is derived as 4 h d t f δ t 1 λ α a d t f δ t a u t f q u t f β 1 δ when the downstream section is located close to a river confluence i e section b in fig 1 the backwater effect due to the junction could affect the hydraulic regime at the site and it should be considered to this end the forecast stage assessed through eq 4 at site b is further adjusted by considering the error observed on the forecast stage at time tf 5 h d b a c k t f δ t h d t f δ t d h t f where dh is the forecast error i e h d t f h d t f 2 2 predictive uncertainty estimate the model conditional processor the model conditional processor mcp is the bayesian approach used in this study for estimating the flood predictive uncertainty pu defined as the probability density of a future outcome conditional on all the available information usually provided by model forecasts moreover the application of mcp in this study provides the probabilistic relationship between the water levels recorded at two gauged river sites the main characteristics of mcp are presented in what follows while for additional details the reader is referred to coccia and todini 2011 and barbetta et al 2017b mcp was developed for predictive uncertainty pu estimate to support the flood forecasting activities in real time and it is essentially based on the definition of the multi variate conditional distribution i e the density of the predictand water level discharge etc conditional on multiple deterministic model predictions predictors the analysis can be done by considering a unique forecast horizon single temporal approach or multiple lead times multi temporal approach mcp identifies the multi variate conditional distribution i e the probability density of the predictant conditional on the models predictions this distribution is obtained by dividing the joint predictand prediction distribution by the joint marginal distribution of the predictor s and is estimated by considering an identified calibration data period specifically the calibration consists in identifying the joint and marginal probability distributions required for bayes theorem application the mcp application is based on four steps 1 the observations y and the forecasts y k k 1 m m number of forecasts provided by m different models are converted into the normal space using the normal quantile transform nqt the variables y and y k whose empirical cumulative distribution functions are computed using the weibull plotting position are converted to their transformed values η and η k respectively which are normally distributed with zero mean and unit variance the probability of each element of η and η k is the same as its original corresponding value in y and y k 2 in the normal space the joint probability distribution of observed and predicted variables f η η with η η 1 η 2 η m is assumed to be a normal multivariate distribution 3 the predictive density is obtained applying the following equation that is known in the literature as the bayesian inversion problem which starts from the bayes formula 6 f η η f η η f η where f η η f η η 1 η 2 η m is the joint probability density of predictand and predictors and f η f η 1 η 2 η m the joint probability density of predictors given that both probability densities are multi gaussian the conditional predictive density f η η is a gaussian distribution mardia et al 1979 with mean μ η η and variance σ 2 η η defined as 7 μ η η σ η η σ η η 1 η 1 η 2 η m 8 σ 2 η η 1 σ η η σ η η 1 σ η η t when a single deterministic forecasting model is used m 1 and eq 6 is simplified as 9 f η η 1 f η η 1 f η 1 4 the predictive probability density in the normal space is finally reconverted to the real space through the inverse nqt the described approach is typically applied for flood forecasting purposes providing useful information in the context of probabilistic bayesian decision making in this work mcp is also applied by assuming the observed level at site c as the predictand i e y quantity and the observed level at site b as the predictor y therefore the predictive density is derived in this elaboration through the bayes theorem by considering the joint probability distribution of observed water levels at site b and c and the marginal probability distributions of the level at section b 3 case study and dataset the paglia river basin subtended by the hydrometric section of orvieto is selected as study area the basin shown in fig 2 is located in an inland region of central italy and has a drainage area of 1277 km2 the main tributary is the chiani river 470 km2 two hydrometric sections are located on the main river allerona and orvieto while four gauged stations are operative along the chiani river the forecast stage estimate at orvieto through stafom rcm implemented for allerona orvieto reach is actually not possible for the lack of an upstream rating curve and also the short distance between the two gauged sections moreover the confluence with the chiani river just upstream orvieto site makes the selected case study non optimal for the model application the presence of four gauged sites along the chiani river of which morrano section is immediately upstream the confluence fig 2 allows to verify the methodology here proposed specifically ponticelli station is selected as upstream site and the main properties of the investigated reaches are summarised in table 1 the main flood event periods recorded during the last 13 years 2005 2017 about 25 000 hourly data are selected for the analysis also considering the data reliability at all the three used gauged sections i e ponticelli morrano and orvieto the highest flood occurred on november 2012 caused extensive flooding it is worth noting that as shown in table 1 the lateral inflow between morrano and orvieto section is on average very high 76 due to the contribution flowing along the main channel that makes the estimate of the wave travel time along the selected reach tricky specifically for most floods the rising limb at orvieto is found contemporary or even earlier than the one observed at morrano site 4 results and discussion the proposed methodology is applied for the selected case study in the paglia river basin and shown in fig 2 1 first the probabilistic relationship between the stage data recorded at morrano and orvieto sections is derived through the mcp assuming tl 0 h 2 second the forecast stage at morrano site is obtained through stafom rcm implemented for ponticelli morrano reach with a lead time of 4 h the deterministic forecast is then used as predictor for the mcp application 3 third the forecast stage at orvieto is derived by exploiting the mcp expected value at morrano and the probabilistic relationship assessed during step 1 4 1 stage probabilistic relationship the stage data recorded at morrano and orvieto sections during the selected flood event periods are analyzed and the probabilistic relationship between them is derived through the mcp referring to the mcp expected value the mean and the standard deviation of the absolute error on stage reproduction er h are found equal to 0 0176 m and 0 0469 m respectively and the nash sutcliffe efficiency coefficient nash and sutcliffe 1970 very high and equal to 0 984 these results clearly indicate that the probabilistic relationship identified through mcp is able to accurately estimate the stage at orvieto site starting from the knowledge of the stage recorded or forecasted at morrano section at the same time as shown in fig 3 for the most severe flood event occurred on november 2012 specifically the mcp performance is also evaluated by comparing the percentiles estimated by the processor and the corresponding observed occurrences this comparison is shown in fig 4 a where the cumulated 0 05 5 probability quantiles estimated by the processor are plotted against the corresponding percentages of observed data that falls below each percentile laio and tamea 2007 the comparison is addressed to verify how much the frequency of estimated probabilities matches with corresponding observed frequencies the closer the points along the diagonal the greater the accuracy moreover the 90 uncertainty band provided by mcp is found verified with the percentage of included observed occurrences slightly higher than 90 4 2 stage forecasting at morrano the forecast stage at morrano site is obtained through stafom rcm implemented for ponticelli morrano reach with a lead time of 4 h and taking the backwater effect into account for the confluence with the paglia river 700 m considering the last error on forecast stage eq 5 the input data needed for stafom rcm application are only the stages at the two end sections along with accurate rating curves and topographic surveys as far as the model parameters are concerned the following values estimated considering the available information on the selected reach are considered k 4 h θ 0 5 λ 17 2 δ 2 21 α 1 65 and β 0 0 the choice of the investigated lead time mainly depends on the characteristic of stafom rcm as demonstrated by previous application of the model barbetta et al 2017b it provides better performance for shorter lead times specifically the performance is found accurate up to the mean wave travel time observed along the selected river reach on this basis and taking into consideration the necessity of a compromise between the forecast accuracy and the length of the forecast horizon in this study the lead time equal to 4 h is deeply analyzed the deterministic forecast by stafom rcm is used as predictor for the mcp application and the predictive uncertainty is estimated and analyzed by considering 3 different elaborations 1 using the selected dataset for mcp calibration 2 using 53 of the dataset for calibration and 3 the remaining 47 for validation table 2 summarizes the obtained results stafom rcm model is able to provide accurate forecasts for all the three elaborations with ns values always higher than 0 91 and a mean of the absolute error on stage forecast er h lower than 0 05 m for all the three elaborations when the mcp expected value is considered a general improvement is always observed with a reduction of the mean and standard deviation of er h and an increase of ns values that are found always close to 0 99 fig 4b shows that the frequency of forecast probabilities exceeding a specific threshold matches well with corresponding observed frequencies specifically 93 of observed points is included in the uncertainty 90 band the benefit introduced by mcp application can be also seen in fig 5 where the results of the mcp are compared with those by applying stafom rcm for two selected events specifically the results obtained for the flood occurred on november 2012 fig 5a and january 2014 fig 5b indicate that the pu estimate by using the mcp introduces an important benefit respect to the deterministic model forecast with the expected value very close to the observed stage hydrograph the performance of mcp in terms of hydrometric threshold exceedance forecasting is also quantified through the brier skill score bs appendix a that is estimated for all the three elaborations and for both the alarm and the overtopping hydrometric thresholds specifically the analysis is carried for significant flood events selected in the used dataset the bs quantification is carried out for the floods during which the observed stage was higher than 2 m overall 23 flood events are identified and for each of them the maximum exceedance probability computed by mcp is used for bs computation through eq a1 the bs values are found very satisfactory and always not exceeding 0 008 the results are summarized in table 3 for the alarm and the overtopping thresholds finally the difference between the predicted and occurred cumulative distributions is estimated through the continuous ranked probability score crps the values shown in table 3 indicate the abilities of the probabilistic forecast system with a mean value equal to 0 120 0 118 and 0 103 m for elaboration 1 2 and 3 respectively 4 3 stage forecasting at orvieto site to achieve the forecast stage estimate at orvieto the mcp expected value at morrano and the probabilistic relationship between the stages recorded at the two gauged sections at the same time are used specifically the expected value of the probabilistic forecast at morrano site obtained through the mcp application for a lead time of 4 h is used to apply the probabilistic relationship developed during step 1 of the proposed methodology considering that the observed tl between morrano and orvieto is 0 h the lead time for orvieto is still equal to 4 h the accuracy of the future predictions at orvieto site can be inferred by inspecting table 2 for all the three elaborations the mean and standard deviation of the absolute error on stage forecast are very low while the ns is equal to 0 983 for elaboration 1 and 2 and is found slightly lower for the validation analysis fig 6 shows the probabilistic forecast for the two same flood events reported in fig 5 for morrano section as it can be seen for both the floods the expected value is very good and this can be explained by the high correlation between the stages recorded at morrano and orvieto which determines a really narrow 90 band as well the probabilistic forecast performance is also evaluated for orvieto site through the quantification of bs and crps specifically bs is computed for 29 floods identified considering only the events during which the observed stage was higher than 3 5 m the bs values are found very low demonstrating a high performance of mcp table 3 for both the investigated hydrometric thresholds finally the crps values in table 3 demonstrate the abilities of mcp with a mean value equal to 0 101 0 112 and 0 085 m for elaboration 1 2 and 3 respectively 5 conclusions the issue of real time flood forecasting at river sites located just downstream confluences by using stage forecasting modeling based on a uniformly distributed representation of lateral inflow is investigated in this paper specifically a methodology for stage predictions at gauged sections located downstream river confluences is proposed and tested the procedure is based on the forecast stages provided by stafom rcm model at a site along the tributary used as predictor for the application of a bayesian approach able to provide a probabilistic forecast at the forecast section on the tributary the probabilistic relationship between the stages recorded at this section and at another one located downstream the confluence on the main river assessed through the bayesian approach as well is then used to achieve the future estimates of stage at the site on the main channel the results obtained show that the presented methodology could be conveniently used to address the issue of stage forecast at a section located along a river just downstream confluences provided that at least two gauged sites are operative along the tributary specifically the outcomes for the case study selected in the paglia river basin central italy demonstrate that the methodology could be useful for real time hydraulic risk management in flood prone areas located downstream river confluences provided that gauged sites are operative along the tributary it is worth noting that 4 h is actually a short lead time but for the selected case study it could be useful for alarm and to address the first civil protection activities further investigations on different appropriate natural channels are required and this activity will be the subject of future studies moreover also the use of multiple forecasts from different deterministic forecasting models such as artificial neural network models will be considered for future analysis acknowledgments authors are thankful to the water resources and hydraulic risk service of umbria region for providing the data used for the study the data are available from dr nicola berni upon request centrofunzionale regione umbria it the data are archived at the functional centre of civil protection of umbria region http www cfumbria it thanks to the anonymous reviewers for the constructive comments and helpful suggetsions appendix a a 1 brier skill score the threshold exceedance probability forecasted by mcp is evaluated through the brier score bs computed as follows bier 1950 a1 bs 1 n t 1 n f t o t 2 where n is the number of investigated flood events ft is the forecast maximum threshold exceedance probability ot is the outcome 1 if the threshold is actually exceeded 0 if it is not the best possible bs is 0 for total accuracy the lowest possible score is 1 a 2 continuous ranked probability score crps let x be a random variable and xa the observation value that actually occurred suppose that the probability density function pdf forecast is provided by a probabilistic forecasting procedure and is indicates as p x then the continuous ranked probability score gneiting et al 2005 matheson and winkler 1976 expressing some kind of distance between the probabilistic forecast and truth xa is defined as a2 crps p x a p x p a x 2 d x p and pa are cumulative distributions a3 p x p x d x a4 p a x h x x a where a5 h x 0 for x 0 1 for x 0 is the well known heaviside function the crps measures the difference between the predicted and occurred cumulative distributions its minimal and better value is zero achieved for p pa note that the crps has the dimension of the parameter x which enters via the integration over dx 
7021,accurate forecast stages at river sections is of paramount importance to properly address flood forecasting and warning systems ffwss operating in real time the forecast values can be provided by flood wave routing models to be implemented when gauged sections are operative along the channel different models have been proposed in the literature and the forecast can be approached by neglecting or involving the contribution of lateral inflows among the latter recently stafom rcm stage forecasting model rating curve model has been proposed assuming a lateral contribution uniformly distributed along the reach therefore the model application is not suitable for future stage prediction at hydrometric sections located just downstream river confluences to overcome this issue we propose a methodology that exploits the probabilistic forecast estimated at a gauged site on a tributary through a bayesian approach and the probabilistic relationship between the stages recorded here and the ones at a downstream site located along the main channel where the forecasted stage estimate is of interest the paglia river basin in central italy is selected as case study the results indicate that the procedure can be useful to address real time hydraulic risk management even at river sections located downstream important confluences provided that gauged sites are operative along the tributary keywords flood forecasting river confluences real time lateral inflow predicative uncertainty 1 introduction last decades showed the steady increase of damages due to flooding highlighting the need of developing effective measures to reduce the flood events impacts to this end structural and non structural measures may be used to mitigate the hydraulic risk as regards the latter forecasting models providing future estimates of main hydrological quantities represent one of the fundamental components of real time flood monitoring and warning systems fmwss traditionally flood forecasting is approached through 1 rainfall runoff providing forecasted discharge at the basin outlet with a lead time close to the time of concentration of the basin or longer if quantitative precipitation forecast qpf are used 2 flood routing models providing forecasts at a downstream end of river reaches with a forecast horizon limited by the flood wave travel time vivoni et al 2006 the latter are more appealing for the limited data required and parameters involved for river reaches with negligible intermediate drainage area flood routing models without incorporating lateral inflow can be used moramarco et al 2008 perumal et al 2011 however for long river channels a model capable to quantify the lateral inflow has to be considered and different approaches have been proposed in the literature such as the use of rainfall runoff modelling price 2009 artificial neural networks and fuzzy system tayfur et al 2007 mukerji et al 2009 rezaeianzadeh et al 2014 and simplified methods o donnell 1985 barbetta et al 2011 2017a karahan et al 2014 yadav et al 2015 spada et al 2017 specifically the routing model proposed by barbetta et al 2011 for stage forecast named stafom rcm stage forecasting model rating curve model also incorporates lateral inflow assessment by exploiting a simple approach physically based this forecasting model essentially descends from the combination of a physically based muskingum model and an estimator of lateral inflow specifically stafom rcm assumes a uniform lateral contribution along the reach and assesses the lateral inflow for unit channel length through the continuity equation applied between an upstream and a downstream section moramarco et al 2005 therefore tributaries located immediately upstream the downstream gauged section where the forecast is of interest pose a sub optimal condition because the assumption of uniform lateral inflows does not accurately represent the real inflow distribution making the model application not suitable for stage prediction at hydrometric sections located just downstream river confluences barbetta et al 2017b to overcome this issue we propose a methodology based on the probabilistic forecast estimated at a gauged site on the tributary through the bayesian approach mcp model conditional processor coccia and todini 2011 barbetta et al 2017b and the probabilistic relationship between the stages recorded at tributary site and the ones at a downstream site along the main channel and where the forecast estimate is of interest mcp is a bayesian approach developed for predictive uncertainty pu estimate to support the flood forecasting activities in real time and it is essentially based on the definition of the multi variate conditional distribution i e the density of the predictand water level discharge etc conditional on multiple deterministic model predictions predictors mcp has been applied in previous studies considering both the single model and the multi model configuration coccia and todini 2011 barbetta et al 2016 2017b the results demonstrated that information provided by multiple deterministic forecasts can be useful for improving the performance mainly when deterministic models are characterized by almost homoscedastic error in this study mcp is selected to estimate the predictive uncertainty and the probabilistic relationship between the water levels recorded at two gauged river sites specifically the bayesian approach is applied considering only stafom rcm deterministic model with the main purpose to investigate if the proposed mcp based methodology is able to overcome the limitation of stafom rcm due to lateral inflow along the reach not accurately described as uniformly distributed to this end in this work mcp is also applied for the first time for deriving a probabilistic relationship between stage values recorded at two hydrometric sections based on statistical analysis different approaches are available in the literature for assessing uncertainty in models forecasts such as the hydrological uncertainty processor hup krzysztofowicz 1999 and the quantile regression qr koenker 2005 weerts et al 2011 however the purpose of this work is not the comparison of different approaches for predictive uncertainty assessment discussed in previous works coccia and todini 2011 moreover todini 2013 demonstrated that the results of hup and mcp are identical when predicting one step ahead while the qr does not produce a continuous predictive density but provides a discrete representation based on quantiles and does not guarantee proper results in the normal space koenker 2005 coccia and todini 2011 the paglia river basin in central italy is selected as case study for the presented study the paper is organized as follows section 2 describes the methodology proposed for probabilistic forecast estimate at river sections located just downstream confluences and presents the main characteristics of the deterministic forecasting model and the bayesian approach used in the study section 3 gives details on the selected case study and dataset section 4 presents and discusses the results obtained through the proposed methodology section 5 outlines the conclusions on the potential usefulness of the approach 2 methodology the methodology proposed in this work exploits a the probabilistic relationship between the stages recorded at a site located on the tributary and the ones delayed by the wave travel time tl at a section on the main river downstream the confluence b the probabilistic forecast estimated at the site on the tributary assessed through the model conditional processor mcp using as predictor the forecasts of deterministic models coupling the above information allows to achieve a probabilistic forecast stage at site located on the main river just downstream a concentrate lateral contribution specifically the methodology is based on three main steps 1 the probabilistic relationship between the stages recorded at a gauged site on tributary section b in fig 1 and at a site located on the main river downstream the confluence section c in fig 1 is derived by assigning at each level of tributary the corresponding probability distribution function of expected levels at site on the main channel delayed of tl therefore model conditional processor mcp is applied considering the mean observed travel time 2 the probabilistic forecast at section b is assessed through mcp for a fixed lead time lt the deterministic forecast provided by a forecasting model is used as predictor for the predictive uncertainty estimate by the application of mcp that identifies the probability density of the future stage conditional on the deterministic forecasts coccia and todini 2011 3 the forecast stage at section c is derived by leveraging the mcp expected value at section b and the probabilistic relationship between the stages recorded at the two gauged sections the total forecast horizon is equal to lt tl a brief description of the models used in the study is provided in the following sections 2 1 stage forecasting model stafom rcm stafom rcm staage forecasting model rating curve model provides real time forecast stages by estimating at each time of forecast tf the lateral inflow along the selected reach barbetta et al 2011 specifically stafom rcm approach unlike black box models essentially descends from the combination of a physically based muskingum model and an estimator of lateral inflow and is based on the coupling of two models i e stafom and rcm the final forecast stage is derived through the following main steps 1 stafom is applied providing a preliminary estimate of the forecast stage at the downstream end hd computed as 1 h d t f δ t 1 λ c 1 q u t f q for t f l c 2 h d t f δ 1 δ with hd tf stage observed at the downstream end at tf δt forecast lead time mean observed wave travel time of the reach qu tf observed upstream discharge at tf l river reach length λ and δ parameters of the downstream rating curve qd λ hd δ c1 and c2 refer to the muskingum parameters k and θ respecting the constraint δt 2kθ the lateral inflow contribution for unit channel length qfor is estimated considering the observations at previous time steps as moramarco et al 2005 2 q for t f a d t f a u t f t l t l where au and ad are the upstream and downstream flow areas respectively tl is the flood wave travel time assumed equal to the lead time δt for forecasting purposes the lateral inflow is considered uniformly distributed along the branch and hence the total lateral discharge entering in the reach in the time interval tf tf δt ql is equal to qfor tf l 2 rcm is used improving the preliminary forecast stage the rating curve model rcm is a simple method developed for reconstructing the discharge hydrograph at a river site where only the stage is monitored and the discharge is recorded at another section the model takes account of significant lateral inflow and without using a flood routing procedure permits it to relate the discharge at an upstream section qu with those at a downstream one qd through the following equation moramarco et al 2005 3 q d t t l α a d t t l a u t q u t β where α and β are the rcm model parameters specifically rcm is exploited to refine the preliminary forecast stage hd that is used to assess the downstream flow area ad at time tf δt and hence the quantity ad tf δt au tf qu tf in eq 3 from which the refined forecast stage is derived as 4 h d t f δ t 1 λ α a d t f δ t a u t f q u t f β 1 δ when the downstream section is located close to a river confluence i e section b in fig 1 the backwater effect due to the junction could affect the hydraulic regime at the site and it should be considered to this end the forecast stage assessed through eq 4 at site b is further adjusted by considering the error observed on the forecast stage at time tf 5 h d b a c k t f δ t h d t f δ t d h t f where dh is the forecast error i e h d t f h d t f 2 2 predictive uncertainty estimate the model conditional processor the model conditional processor mcp is the bayesian approach used in this study for estimating the flood predictive uncertainty pu defined as the probability density of a future outcome conditional on all the available information usually provided by model forecasts moreover the application of mcp in this study provides the probabilistic relationship between the water levels recorded at two gauged river sites the main characteristics of mcp are presented in what follows while for additional details the reader is referred to coccia and todini 2011 and barbetta et al 2017b mcp was developed for predictive uncertainty pu estimate to support the flood forecasting activities in real time and it is essentially based on the definition of the multi variate conditional distribution i e the density of the predictand water level discharge etc conditional on multiple deterministic model predictions predictors the analysis can be done by considering a unique forecast horizon single temporal approach or multiple lead times multi temporal approach mcp identifies the multi variate conditional distribution i e the probability density of the predictant conditional on the models predictions this distribution is obtained by dividing the joint predictand prediction distribution by the joint marginal distribution of the predictor s and is estimated by considering an identified calibration data period specifically the calibration consists in identifying the joint and marginal probability distributions required for bayes theorem application the mcp application is based on four steps 1 the observations y and the forecasts y k k 1 m m number of forecasts provided by m different models are converted into the normal space using the normal quantile transform nqt the variables y and y k whose empirical cumulative distribution functions are computed using the weibull plotting position are converted to their transformed values η and η k respectively which are normally distributed with zero mean and unit variance the probability of each element of η and η k is the same as its original corresponding value in y and y k 2 in the normal space the joint probability distribution of observed and predicted variables f η η with η η 1 η 2 η m is assumed to be a normal multivariate distribution 3 the predictive density is obtained applying the following equation that is known in the literature as the bayesian inversion problem which starts from the bayes formula 6 f η η f η η f η where f η η f η η 1 η 2 η m is the joint probability density of predictand and predictors and f η f η 1 η 2 η m the joint probability density of predictors given that both probability densities are multi gaussian the conditional predictive density f η η is a gaussian distribution mardia et al 1979 with mean μ η η and variance σ 2 η η defined as 7 μ η η σ η η σ η η 1 η 1 η 2 η m 8 σ 2 η η 1 σ η η σ η η 1 σ η η t when a single deterministic forecasting model is used m 1 and eq 6 is simplified as 9 f η η 1 f η η 1 f η 1 4 the predictive probability density in the normal space is finally reconverted to the real space through the inverse nqt the described approach is typically applied for flood forecasting purposes providing useful information in the context of probabilistic bayesian decision making in this work mcp is also applied by assuming the observed level at site c as the predictand i e y quantity and the observed level at site b as the predictor y therefore the predictive density is derived in this elaboration through the bayes theorem by considering the joint probability distribution of observed water levels at site b and c and the marginal probability distributions of the level at section b 3 case study and dataset the paglia river basin subtended by the hydrometric section of orvieto is selected as study area the basin shown in fig 2 is located in an inland region of central italy and has a drainage area of 1277 km2 the main tributary is the chiani river 470 km2 two hydrometric sections are located on the main river allerona and orvieto while four gauged stations are operative along the chiani river the forecast stage estimate at orvieto through stafom rcm implemented for allerona orvieto reach is actually not possible for the lack of an upstream rating curve and also the short distance between the two gauged sections moreover the confluence with the chiani river just upstream orvieto site makes the selected case study non optimal for the model application the presence of four gauged sites along the chiani river of which morrano section is immediately upstream the confluence fig 2 allows to verify the methodology here proposed specifically ponticelli station is selected as upstream site and the main properties of the investigated reaches are summarised in table 1 the main flood event periods recorded during the last 13 years 2005 2017 about 25 000 hourly data are selected for the analysis also considering the data reliability at all the three used gauged sections i e ponticelli morrano and orvieto the highest flood occurred on november 2012 caused extensive flooding it is worth noting that as shown in table 1 the lateral inflow between morrano and orvieto section is on average very high 76 due to the contribution flowing along the main channel that makes the estimate of the wave travel time along the selected reach tricky specifically for most floods the rising limb at orvieto is found contemporary or even earlier than the one observed at morrano site 4 results and discussion the proposed methodology is applied for the selected case study in the paglia river basin and shown in fig 2 1 first the probabilistic relationship between the stage data recorded at morrano and orvieto sections is derived through the mcp assuming tl 0 h 2 second the forecast stage at morrano site is obtained through stafom rcm implemented for ponticelli morrano reach with a lead time of 4 h the deterministic forecast is then used as predictor for the mcp application 3 third the forecast stage at orvieto is derived by exploiting the mcp expected value at morrano and the probabilistic relationship assessed during step 1 4 1 stage probabilistic relationship the stage data recorded at morrano and orvieto sections during the selected flood event periods are analyzed and the probabilistic relationship between them is derived through the mcp referring to the mcp expected value the mean and the standard deviation of the absolute error on stage reproduction er h are found equal to 0 0176 m and 0 0469 m respectively and the nash sutcliffe efficiency coefficient nash and sutcliffe 1970 very high and equal to 0 984 these results clearly indicate that the probabilistic relationship identified through mcp is able to accurately estimate the stage at orvieto site starting from the knowledge of the stage recorded or forecasted at morrano section at the same time as shown in fig 3 for the most severe flood event occurred on november 2012 specifically the mcp performance is also evaluated by comparing the percentiles estimated by the processor and the corresponding observed occurrences this comparison is shown in fig 4 a where the cumulated 0 05 5 probability quantiles estimated by the processor are plotted against the corresponding percentages of observed data that falls below each percentile laio and tamea 2007 the comparison is addressed to verify how much the frequency of estimated probabilities matches with corresponding observed frequencies the closer the points along the diagonal the greater the accuracy moreover the 90 uncertainty band provided by mcp is found verified with the percentage of included observed occurrences slightly higher than 90 4 2 stage forecasting at morrano the forecast stage at morrano site is obtained through stafom rcm implemented for ponticelli morrano reach with a lead time of 4 h and taking the backwater effect into account for the confluence with the paglia river 700 m considering the last error on forecast stage eq 5 the input data needed for stafom rcm application are only the stages at the two end sections along with accurate rating curves and topographic surveys as far as the model parameters are concerned the following values estimated considering the available information on the selected reach are considered k 4 h θ 0 5 λ 17 2 δ 2 21 α 1 65 and β 0 0 the choice of the investigated lead time mainly depends on the characteristic of stafom rcm as demonstrated by previous application of the model barbetta et al 2017b it provides better performance for shorter lead times specifically the performance is found accurate up to the mean wave travel time observed along the selected river reach on this basis and taking into consideration the necessity of a compromise between the forecast accuracy and the length of the forecast horizon in this study the lead time equal to 4 h is deeply analyzed the deterministic forecast by stafom rcm is used as predictor for the mcp application and the predictive uncertainty is estimated and analyzed by considering 3 different elaborations 1 using the selected dataset for mcp calibration 2 using 53 of the dataset for calibration and 3 the remaining 47 for validation table 2 summarizes the obtained results stafom rcm model is able to provide accurate forecasts for all the three elaborations with ns values always higher than 0 91 and a mean of the absolute error on stage forecast er h lower than 0 05 m for all the three elaborations when the mcp expected value is considered a general improvement is always observed with a reduction of the mean and standard deviation of er h and an increase of ns values that are found always close to 0 99 fig 4b shows that the frequency of forecast probabilities exceeding a specific threshold matches well with corresponding observed frequencies specifically 93 of observed points is included in the uncertainty 90 band the benefit introduced by mcp application can be also seen in fig 5 where the results of the mcp are compared with those by applying stafom rcm for two selected events specifically the results obtained for the flood occurred on november 2012 fig 5a and january 2014 fig 5b indicate that the pu estimate by using the mcp introduces an important benefit respect to the deterministic model forecast with the expected value very close to the observed stage hydrograph the performance of mcp in terms of hydrometric threshold exceedance forecasting is also quantified through the brier skill score bs appendix a that is estimated for all the three elaborations and for both the alarm and the overtopping hydrometric thresholds specifically the analysis is carried for significant flood events selected in the used dataset the bs quantification is carried out for the floods during which the observed stage was higher than 2 m overall 23 flood events are identified and for each of them the maximum exceedance probability computed by mcp is used for bs computation through eq a1 the bs values are found very satisfactory and always not exceeding 0 008 the results are summarized in table 3 for the alarm and the overtopping thresholds finally the difference between the predicted and occurred cumulative distributions is estimated through the continuous ranked probability score crps the values shown in table 3 indicate the abilities of the probabilistic forecast system with a mean value equal to 0 120 0 118 and 0 103 m for elaboration 1 2 and 3 respectively 4 3 stage forecasting at orvieto site to achieve the forecast stage estimate at orvieto the mcp expected value at morrano and the probabilistic relationship between the stages recorded at the two gauged sections at the same time are used specifically the expected value of the probabilistic forecast at morrano site obtained through the mcp application for a lead time of 4 h is used to apply the probabilistic relationship developed during step 1 of the proposed methodology considering that the observed tl between morrano and orvieto is 0 h the lead time for orvieto is still equal to 4 h the accuracy of the future predictions at orvieto site can be inferred by inspecting table 2 for all the three elaborations the mean and standard deviation of the absolute error on stage forecast are very low while the ns is equal to 0 983 for elaboration 1 and 2 and is found slightly lower for the validation analysis fig 6 shows the probabilistic forecast for the two same flood events reported in fig 5 for morrano section as it can be seen for both the floods the expected value is very good and this can be explained by the high correlation between the stages recorded at morrano and orvieto which determines a really narrow 90 band as well the probabilistic forecast performance is also evaluated for orvieto site through the quantification of bs and crps specifically bs is computed for 29 floods identified considering only the events during which the observed stage was higher than 3 5 m the bs values are found very low demonstrating a high performance of mcp table 3 for both the investigated hydrometric thresholds finally the crps values in table 3 demonstrate the abilities of mcp with a mean value equal to 0 101 0 112 and 0 085 m for elaboration 1 2 and 3 respectively 5 conclusions the issue of real time flood forecasting at river sites located just downstream confluences by using stage forecasting modeling based on a uniformly distributed representation of lateral inflow is investigated in this paper specifically a methodology for stage predictions at gauged sections located downstream river confluences is proposed and tested the procedure is based on the forecast stages provided by stafom rcm model at a site along the tributary used as predictor for the application of a bayesian approach able to provide a probabilistic forecast at the forecast section on the tributary the probabilistic relationship between the stages recorded at this section and at another one located downstream the confluence on the main river assessed through the bayesian approach as well is then used to achieve the future estimates of stage at the site on the main channel the results obtained show that the presented methodology could be conveniently used to address the issue of stage forecast at a section located along a river just downstream confluences provided that at least two gauged sites are operative along the tributary specifically the outcomes for the case study selected in the paglia river basin central italy demonstrate that the methodology could be useful for real time hydraulic risk management in flood prone areas located downstream river confluences provided that gauged sites are operative along the tributary it is worth noting that 4 h is actually a short lead time but for the selected case study it could be useful for alarm and to address the first civil protection activities further investigations on different appropriate natural channels are required and this activity will be the subject of future studies moreover also the use of multiple forecasts from different deterministic forecasting models such as artificial neural network models will be considered for future analysis acknowledgments authors are thankful to the water resources and hydraulic risk service of umbria region for providing the data used for the study the data are available from dr nicola berni upon request centrofunzionale regione umbria it the data are archived at the functional centre of civil protection of umbria region http www cfumbria it thanks to the anonymous reviewers for the constructive comments and helpful suggetsions appendix a a 1 brier skill score the threshold exceedance probability forecasted by mcp is evaluated through the brier score bs computed as follows bier 1950 a1 bs 1 n t 1 n f t o t 2 where n is the number of investigated flood events ft is the forecast maximum threshold exceedance probability ot is the outcome 1 if the threshold is actually exceeded 0 if it is not the best possible bs is 0 for total accuracy the lowest possible score is 1 a 2 continuous ranked probability score crps let x be a random variable and xa the observation value that actually occurred suppose that the probability density function pdf forecast is provided by a probabilistic forecasting procedure and is indicates as p x then the continuous ranked probability score gneiting et al 2005 matheson and winkler 1976 expressing some kind of distance between the probabilistic forecast and truth xa is defined as a2 crps p x a p x p a x 2 d x p and pa are cumulative distributions a3 p x p x d x a4 p a x h x x a where a5 h x 0 for x 0 1 for x 0 is the well known heaviside function the crps measures the difference between the predicted and occurred cumulative distributions its minimal and better value is zero achieved for p pa note that the crps has the dimension of the parameter x which enters via the integration over dx 
7022,decades of logging and slash and burn agriculture have turned vast tracts of land in tropical south east asia into unproductive fire climax grasslands whose hydrological functioning is poorly known to help fill this knowledge gap a 3 2 ha landslide affected imperata grassland micro catchment with perennial flow on leyte island philippines was instrumented and monitored for a year the area was hit by typhoon haiyan on 8 november 2013 one of the largest events on record landslide surfaces covered 3 4 of the catchment prior to typhoon haiyan and contributed to direct runoff q q this basic contributing area increased to 7 7 by activation of old landslides and formation of new ones during typhoon haiyan median storm runoff coefficients q q p based on straight line hydrograph separation were 9 and 23 before 48 events and after the typhoon 43 events respectively but the ratios of period total q q and p were much larger 24 and 47 respectively both storm runoff volumes and peak discharge increased rapidly once a mid slope water storage threshold for the upper 60 cm of soil of 250 mm was exceeded storm runoff contributions above those generated on landslides were most likely in the form of overland flow given the prevailing very low soil hydraulic conductivities post typhoon water use of the heavily disturbed vegetation was reduced initially by nearly 70 recovering to nearly 80 of the pre typhoon value after 3 months the high annual sediment yield 27 t ha 1 was heavily dominated by post haiyan sediment transport 94 bedload contributed 8 of the total sediment yield keywords hillslope hydrology imperata grassland landsliding runoff generation tropical hydrology 1 introduction decades of swidden cultivation also called slash and burn agriculture brady 1996 have created extensive tracts of largely unproductive fire climax grassland across the tropics garrity et al 1997 hooper et al 2005 styger et al 2007 despite their considerable spatial extent an estimated 35 million ha in south and south east asia alone in the 1990s garrity et al 1997 very few hydrological studies have focused on these imperata and saccharum dominated tropical grasslands particularly in terms of runoff processes at the catchment scale waterloo et al 1999 showed that the water use of a seasonally dormant non grazed fire climax grassland in the fiji archipelago followed the seasonal pattern of leaf surface area and was much lower than evapotranspiration from nearby pine plantations suggesting grassland soils may be wetter and thus hydrologically more responsive than forest soils in addition soils of fire climax grasslands can be water repellent because of repeated burning and compacted when grazed jasmin 1976 snelder 2001 starkel and singh 2004 this may lead to enhanced overland flow chandler and walter 1998 and surface erosion concepcion and samar 1995 there is typically an increase in the incidence of shallow 2 3 m landslides on tropical steeplands a few years after deforestation when the extra hillslope strength formerly imparted by the roots of the trees starts to decline o loughlin 1984 cf rabonza et al 2015 particularly in areas characterized by seasonally high rainfall steep slopes a regolith overlying impermeable rock and significant tectonic activity scatena et al 2005 sidle et al 2006 lin et al 2008 wu and chen 2009 thus sediment yields from fire climax grassland catchments subject to landsliding can be much enhanced cf page et al 1994 trustrum et al 1999 even when contributions by surface erosion are modest jasmin 1976 starkel and singh 2004 such findings are especially pertinent in the philippines which are located in one of the world s premier cyclone generating areas garcía herrera et al 2007 and where about 30 of the annual precipitation is received during the passage of tropical cyclones and depressions cinco et al 2016 annual sediment yields from upland catchments in the philippines and similar settings e g taiwan are heavily dominated by sediment generated during such extreme events white 1990 lin et al 2008 therefore in view of i the general lack of catchment scale hydrological and sediment yield studies for tropical fire climax grasslands cf daño 1995 and ii the expected intensification of extreme events in the region due to continued oceanic warming and freshening balaguru et al 2016 we monitored key hydrological variables in a landslide impacted imperata grassland micro catchment 3 2 ha with perennial streamflow at the village of basper near tacloban city north eastern leyte island eastern visayas the philippines for a year measurements included continuous observations of rainfall streamflow soil moisture and shallow groundwater levels with the aim to quantify i the water budget of a cogon grassland ii the grassland s runoff response to rainfall including extreme events and iii the role of landslides with respect to stormflow generation and sediment supply during the study year the catchment was hit by typhoon haiyan one of the largest events on record in the region delivering more than 200 mm of rain within several hours nguyen et al 2014 this provided an opportunity to study the effect of this extreme event and associated landsliding on runoff production and sediment yield zhang et al 2018a reported very low surface and near surface saturated soil hydraulic conductivities for the basper grassland as well as high top soil moisture contents during months with peak rainfall such conditions are conducive to the generation of both infiltration excess iof and saturation excess overland flow sof bonell 2005 specifically we hypothesized that a cogon runoff response to rainfall is flashy due to the prevailing low soil infiltration capacity and high soil water content b landslides constitute a significant source of direct runoff during rainfall events and c extreme events like typhoon haiyan increase the number of landslides thereby enhancing overall catchment runoff response and especially sediment yield 2 study area the south facing 3 2 ha headwater basper micro catchment is located 14 km west of the city of tacloban at 11 15 28 n and 124 57 22 e elevations range from 50 to 135 m a s l the upper slopes are straight to slightly concave while the lower slopes steepen towards the stream the average slope is 23 landslide scars are prominent in the landscape fig 1 the climate is tropical ever wet köppen type af mean annual rainfall at nearby tacloban airport 1977 2011 is 2660 mm range 1435 4790 mm distributed over on average 195 rain days i e 0 5 mm of rain per day per year although there is no clearly defined dry season average rainfall from november to january 350 mm mo 1 is higher than for april may 100 mm mo 1 typhoons and tropical storms occur regularly in the area cinco et al 2016 seasonal variation in monthly temperatures at tacloban airport is small ranging from 25 7 c in january to 28 1 c in may as are seasonal variations in average daily relative humidity 81 86 and average monthly wind speeds 1 5 2 4 m s 1 average daily reference evaporation rates allen et al 1998 computed from basic climatic data for tacloban airport range between 3 0 mm d 1 for december and 4 8 mm d 1 for april the vegetation consisted of cogon grass imperata cylindrica l beauv on the ridges and a few isolated coconut trees fig 1a and upper slope areas with sedges cyperus sp being numerous in less drained parts the mid slopes had mixed grassland and low shrub 1 5 m high mostly melastoma malabathricum l smith and chromolaena odorata l r m king h robinson while shrubs and young trees 2 3 m high mostly neonauclea lanceolata blume merr and leukosyke capitella wedd were common on the lowermost slopes near the streams along with a few remnant planted acacia mangium willd trees fig 1a although regularly burned in the past the basper study site had not experienced any fire since 2003 and young regenerating forest occupied an estimated 4500 m2 in the central portion of the catchment representing 14 of the total area on 8 november 2013 the area was hit severely by typhoon haiyan one of the largest events on record which effectively defoliated all shrubs and saplings fig 1b and buried the foot slope vegetation with landslide material in some places the pre typhoon leaf area index of the riparian vegetation 26 measurements made in august 2013 at 5 m intervals in the riparian zone using a cid bio science ci 110 plant canopy imager was 1 6 1 0 m2 m 2 the underlying mafic rock gabbro belongs to the tacloban ophiolite complex dimantala et al 2006 soils are classified as eutric cambisols with a predominantly clay loam texture upper 0 9 m grading to sandy clay loam at greater depth median values median absolute difference mad of soil organic carbon content declined with depth from 2 3 0 7 at 10 cm to 1 0 0 3 at 20 cm and 0 5 0 1 below 40 cm zhang et al 2018a similarly median soil porosity decreased with depth from 51 7 10 cm to 47 4 20 cm and 42 1 below 60 cm while median bulk density increased from 1 14 0 08 g cm 3 10 cm to 1 33 0 05 g cm 3 40 cm and 1 38 0 07 g cm 3 deeper in the profile 60 100 cm the median value of the final surface infiltration rate as determined with a portable double ring infiltrometer n 13 was 2 1 0 7 mm h 1 while median field saturated soil hydraulic conductivities k sat n 47 determined with a constant head well permeameter amoozegar 1989 were 2 85 1 80 mm h 1 at 20 40 cm depth inter quartile range 0 8 6 6 mm h 1 and 1 mm h 1 iqr 0 1 1 8 mm h 1 below 60 cm see zhang et al 2018a for details 3 methods 3 1 field measurements 3 1 1 hydrological monitoring field measurements were made between june 2013 and 2014 rainfall p was measured using two tipping bucket rain gauges rg3 onset computer corporation usa 0 25 mm per tip confirmed by manual calibration connected to a hobo pendant event data logger one gauge was located in the open below the outlet of the catchment and the other on the upper western ridge fig 2 a standard manual rain gauge 100 cm2 orifice was placed next to the tipping bucket gauges and read every morning as a check daily rainfall totals for the two recording gauges were strongly correlated r2 0 99 n 113 rain days with p 0 5 mm and occasional gaps in the record of either gauge were filled using the data for the other gauge e g during typhoon haiyan and the subsequent 11 day period when only the more sheltered lower gauge was functioning although wind speeds were measured at the site of the upper recording gauge see below between 8 july and 8 november 2013 when the instrument was destroyed during the passage of typhoon haiyan no corrections were made for wind related under estimation of rainfall since wind speeds were generally low and the application of correction methods e g førland et al 1996 for the extreme wind speeds encountered during the haiyan event up to 315 km h 1 rabonza et al 2015 leads to unverifiable and uncertain corrections instead the catch of a recording cylindrical fog gauge located at site s1 with a 100 catch efficiency for near horizontal wind driven rain frumau et al 2011 was used to estimate extra inputs of near horizontal rainfall during the haiyan event because the catch efficiency of live vegetation is smaller than that of the type of fog gauge employed bruijnzeel et al 2005 it is acknowledged that such an estimate will represent a maximum value basic climate variables for the computation of reference evapotranspiration et0 allen et al 1998 for use in the hbv light modeling see below were measured by a dws automatic weather station decagon u s a located at site s1 from 8 july 2013 onwards short wave radiation was measured by a pyranometer temperature and relative humidity by sensors placed within a radiation shield at 2 m from the ground and wind speed by a cup anemometer also at 2 m all data were recorded at 5 min intervals by a decagon em50 data logger the anemometer was destroyed during passage of typhoon haiyan henceforth wind speeds were approximated using corresponding long term averages for the respective months as measured at tacloban airport pagasa weather office tacloban streamflow q was measured using a sharp crested compound weir consisting of a 0 55 m high 90 v notch and a horizontal beam extending 0 5 m to each side from the edge of the v notch supporting fig 1 water pressures were measured at 5 min intervals using a hobo u20 logger atmospheric pressure was measured using a hobo u20 logger in a hut located 100 m from the weir and used to calculate the water levels from the water pressure measurements the standard v notch weir equation bos 1989 was checked through streamflow measurements volumetric measurements below 4 4 l s 1 staff heights 0 3 m and the velocity area method at stages up to 0 55 m using a price type aa current meter water levels exceeded the shoulder of the v notch during 22 storm events in total 48 7 h or 0 4 of the total study time and for these conditions the bergmann compound weir equation as given by usbr 1997 was used to calculate streamflow water level data were incomplete for 52 days 14 of the total time due to equipment malfunctioning amongst others during the 15 day period immediately following typhoon haiyan with the exception of the latter period the calibrated hbv model bergström 1992 1995 as implemented in the hbv light version of seibert and vis 2012 was used for gap filling see streamflow gap filling section below for details suspended sediment concentrations ssc of the stream water were determined for samples collected during the rising stage of 34 events using up to eleven 400 ml water bottles equipped with a siphon shaped air exhaust schick 1967 with their apertures placed at successively greater heights 8 52 5 cm above the lowermost point of the v notch see inset supporting fig 1 bottles that filled during an event were replaced by clean empty ones generally the next day in addition during several large events in the pre haiyan period water samples were also collected manually using 500 ml sampling bottles both during rising and falling stages manual samples were not collected during the post haiyan period in total 275 samples of suspended sediment in streamflow were collected during stormflow conditions 229 using the single stage samplers and 46 manual samples all samples were filtered in the laboratory at visayas state university first through whatman grade 589 2 standard filter paper 4 12 µm and subsequently through millipore 0 45 μm filters the residues were oven dried for 24 h at 105 c and weighed to the nearest 0 001 g to give ssc in mg l 1 ssc values were linked to the streamflow at the time that the bottle filled to derive separate sediment rating curves for pre and post haiyan conditions and to allow estimation of suspended sediment transport from the continuous streamflow record walling 1977 white 1990 it is acknowledged that the use of mostly rising stage samples normally leads to an over estimation of the suspended sediment load because of the generally higher ssc during rising stage conditions walling 1977 however because the values of ssc obtained with the single stage samplers were intermediate between those of manually collected rising and falling stage samples see section on catchment sediment yield below we assume that this over estimation is relatively minor the electrical conductivity ec of the stream water was measured at 5 min intervals using a hobo u24 conductivity logger installed next to the water level sensor cf inset supporting fig 1 the ec data were regularly checked against manual measurements made with a cyberscan pc300 ph conductivity tds meter envco australia bedload accumulation behind the weir was determined volumetrically at irregular intervals n 6 by removing the sediment using a bucket of known volume sediment volumes were converted to oven dry weights using the mean bulk density of the bed material estimated at 1 2 g cm 3 rijsdijk and bruijnzeel 1990 seasonal and annual totals were obtained by summing individually measured values the sediment volume accumulated between 10 february and 2 june 2014 end of observation period was estimated by multiplying the average bedload concentration per mm of stormflow based on constant slope hydrograph separation see section 3 3 1 below during january 2014 n 3 times the total stormflow between the above two dates volumetric soil moisture content θ was monitored at a 5 min interval at two locations within the catchment sites s1 and s2 in fig 2 at site s1 on the western ridge a mixture of cogon grass and sedges decagon ec 5 moisture sensors were installed at depths of 0 15 0 30 and 0 55 m below the surface and connected to a decagon em50 data logger at site s2 cogon grassland at mid slope position simplified time domain reflectometry tdr sensors mp 306 ict international australia were installed at 0 10 0 20 0 40 0 60 0 80 and 1 10 m depth the sensors were connected to an ict international microvolt data logger shallow groundwater levels were measured in four piezometers installed at the soil bedrock interface fig 2 piezometers g1 left bank 0 9 m deep and g2 right bank 2 65 m deep were located in the young regenerating forest area close to the stream about 6 m upstream of the weir while the third site s2 2 6 m deep and fourth s1 1 7 m deep piezometers were located at the mid slope cogon grass and upper ridge cogon plus sedges soil moisture measurement sites respectively groundwater levels were measured manually once per week at piezometers g2 s1 and s2 and at 5 min intervals at piezometer g1 using a hobo u20 water pressure logger 3 1 2 landslide surveys a landslide survey was conducted in august 2013 to map all landslides within the catchment that based on visual evidence during rainfall events likely contributed directly to storm runoff for each landslide the slopes of the slip face and side slopes were measured at regular intervals along the longitudinal profile using a clinometer to determine the projected landslide surface area dunne 1977 the survey was repeated in december 2013 after typhoon haiyan had reactivated some old landslides and created several new ones fig 2 3 2 streamflow gap filling simulated streamflow was used for the 52 days during which water level data were incomplete total rainfall during these days was 193 mm the hbv light model of seibert and vis 2012 was calibrated using 5 min rainfall and streamflow data by maximizing the value of the objective function that gave equal weight to the nash sutcliffe efficiency nse and the nse for the log transformed streamflow to avoid bias towards the more uncertain high streamflow values we used 100 independent model calibration trials each consisting of 3500 model runs to derive the 100 optimum parameter sets using the gap optimization algorithm in the model the model was calibrated separately for the pre and post haiyan period a three week warming up period 3 23 june 2013 was used for the pre haiyan calibration 24 june 5 november 2013 while the period between 3 june and 22 november 2013 was used as the warming up period for the post haiyan calibration 23 november 2013 10 june 2014 to fill gaps in the streamflow record see fig 3 below for all times except during and directly after typhoon haiyan 8 22 november 2013 the 25 best parameter sets for either period were selected having average combined objective function values of 0 82 and 0 81 for the pre and post haiyan period respectively because hbv modeled 5 min streamflows were 7 and 16 lower than observed values on average during the respective periods see supporting fig 2 the gap filled streamflow data were increased proportionately modeled streamflow totals for the gap filling during the pre haiyan period amounted to 9 mm versus 27 28 mm during the wetter post haiyan period representing 2 5 of the streamflow total i e observed plus gap filled in both cases the period during and directly after typhoon haiyan 8 22 november 2013 was not included in the above model calibrations due to the absence of measured streamflow data because the model tended to under estimate the peak streamflow during other very large events we did not use the simulation results for gap filling during this period instead a simplified approach was used to estimate daily streamflow totals first daily stormflow totals q q were estimated from a polynomial relationship linking daily p and q q during the post haiyan period r2 0 99 n 43 corresponding daily baseflow amounts q b were estimated using the master recession curve see description below and the estimated baseflow for 8 november 2013 determined as the difference between total precipitation input and q q for that day as the starting point baseflow for the period 20 22 november was estimated by backward extrapolation of the measured recession for 23 25 november 3 3 data analysis 3 3 1 stormflow separation and recession analysis to separate stormflow also referred to as direct runoff or storm runoff in this paper from baseflow during rainfall events the constant slope method of hewlett and hibbert 1967 was used the following criteria were used to select rainfall events for stormflow analysis i gross p per event 5 mm ii the event was preceded by a rain free period of 6 h and iii complete rainfall and streamflow observations at 5 min intervals were available based on these criteria there were 48 rainfall events prior to typhoon haiyan median event size 14 mm maximum 154 mm and 43 rainfall events after typhoon haiyan median 17 mm maximum 215 mm stormflow amounts determined in this way q q in mm were also expressed in terms of their minimum contributing area equivalent mca expressed in ha dickinson and whiteley 1970 the mca is defined as the minimum area that contributing 100 of the effective rainfall it receives would yield the measured storm runoff as such mca q q p a i e the event storm runoff coefficient times catchment area a in ha and may be interpreted as the fraction of the catchment contributing the observed storm runoff dickinson and whiteley 1970 separate master recession curves were determined before and after catchment disturbance by typhoon haiyan using the matching strip technique of toebes and strang 1964 exponential curves were fitted to these master recession curves while recession constants k for three superimposed reservoirs were derived according to linear reservoir theory de zeeuw 1973 chapman 1999 furthermore using the method outlined by de zeeuw 1973 both master recession curves were examined for downward deviations from the exponential decline in flow for the slowest reservoir no such deviations were observed indicating no detectable catchment leakage see results below 3 3 2 catchment water budget although shallow groundwater levels were measured in the four piezometers see fig 2 for locations changes in effective shallow catchment wide groundwater storage g t were evaluated using the method of chapman 1999 in which g t in mm at time t is approximated by 1 g t q t ln k where q t is the base flow rate at time t and k is the corresponding reservoir constant day 1 eq 1 was used to calculate the changes in shallow groundwater storage δg between the start and end of the pre and post haiyan runoff observation periods from the corresponding initial and final daily baseflow values the associated changes in soil water storage δs mm were derived from the integration of measured values of θ down to 60 cm at sites s1 and s2 together with measured p and q this allowed estimation of catchment wide apparent evapotranspiration et losses using the general water budget equation et p q δg δs 3 3 3 statistical analyses because of the disturbing effect of the typhoon on the catchment s vegetation a distinction was made between pre and post haiyan conditions called periods i and iii respectively period i lasted from 3 june 7 november 2013 n 158 days while period iii lasted from 23 november 2013 to 3 june 2014 n 192 days period ii from 8 22 november 2013 n 15 days describes the period during and directly following typhoon haiyan differences in the median runoff response to rainfall before and after disturbance by typhoon haiyan were tested for significance using the mann whitney wilcoxon test for pairwise comparisons between groups because the data were not normally distributed a significance value of p 0 05 was used for all analyses statgraphic centurion xvii version 17 2 00 software was used for all statistical analyses 4 results 4 1 seasonal rainfall streamflow and stream water ec patterns the daily rainfall inputs and streamflow outputs for the basper micro catchment between 3 june 2013 and 2 june 2014 are shown in fig 3 september and october 2013 as well as february part of april and may 2014 were relatively dry whereas the period between november 2013 and january 2014 was particularly rainy by far the largest event occurred on 7 8 november 2013 when typhoon haiyan passed over the catchment and delivered at least 228 mm of rain catch of lower rain gauge uncorrected for wind losses plus up to 50 mm of wind driven near horizontal rain catch of fog gauge at s1 other very large rainfall events occurred on 28 29 june 2013 154 mm 10 13 january 2014 195 mm and 22 24 march 2014 209 mm periods with prolonged high streamflow were concentrated mostly in june 2013 and november 2013 january 2014 fig 3b stream water ec was greatly reduced during times of rainfall while baseflow ec values varied inversely with the amount of flow fig 3c although the range in average monthly ec values during baseflow conditions was nearly identical for the pre 266 322 μs cm 1 and post haiyan periods 263 330 μs cm 1 post disturbance period iii values of baseflow conductivities were higher throughout p 0 05 regardless of catchment wetness status rainfall and streamflow totals for the entire study period 365 days were 3365 and 1995 mm respectively table 1 expressed on a daily basis post haiyan rainfall period iii 23 november 2013 3 june 2014 average 8 9 mm d 1 was 19 higher on average than before catchment disturbance period i 3 june 7 november 2013 average 7 5 mm d 1 corresponding average daily streamflow values nearly doubled from 2 9 mm to 5 6 mm d 1 the flow duration curves for periods i pre haiyan and iii post haiyan shown in fig 4 confirm the greater streamflow range during the post haiyan period expressing the flashiness of the flow as the ratio between the streamflows that were exceeded for 10 and 90 of the time f 10 90 the post disturbance f 10 90 of 122 was nearly three times larger than the pre disturbance value of 44 fig 4 stormflow q q made up a very large part of total runoff q t 56 for period i versus 68 for period iii table 1 and supporting table 2 total q q for the study year amounted to 1214 mm 61 of q t versus 725 mm of baseflow 39 of q t the apparent evapotranspiration et decreased from a pre disturbance value of 4 7 mm d 1 to 3 6 mm d 1 during period iii table 1 the corresponding value derived for the 15 day period immediately after the haiyan event period ii when trees and shrubs were defoliated and grasses beaten down was much lower 1 5 mm d 1 table 1 although we have to note that the uncertainties in the total precipitation inputs during the haiyan event and in the streamflow data afterwards are considerable 4 2 streamflow recession the streamflow recession rates during the two periods did not differ significantly fig 5 a and b recessions in both cases could be described by three superimposed linear reservoirs with pre haiyan recession constants k values in fig 5 converted to d 1 of 0 024 d 1 for the slowest groundwater reservoir 0 34 d 1 for the intermediate reservoir and 2 88 d 1 for the fastest reservoir corresponding values for post haiyan conditions period ii were 0 062 0 43 and 5 64 d 1 respectively 4 3 runoff response to rainfall before and after passage of typhoon haiyan runoff response to rainfall at basper was rapid with a median pre disturbance rising limb duration amounting to only 25 min 0 42 h the corresponding value for post haiyan conditions period iii was 78 min 1 3 h table 2 although median event rainfall amount p and intensity i as well as the median three day antecedent precipitation index api3 were not significantly different for the pre and post haiyan event data sets post haiyan medians of peak flow q p stormflow depth q q and storm runoff coefficient q q p were significantly larger table 2 the median post haiyan storm runoff coefficient was 2 6 times higher 22 7 versus 8 7 for the pre haiyan period stormflow runoff coefficients q q p increased with rainfall although the spread in the data was fairly large supporting table 1 pre typhoon values ranged from a modest 7 8 sd for small events 5 10 mm of rain to 23 26 for intermediate events 20 40 mm and 55 for a very large rainfall event 154 mm equivalent values for the post haiyan period were slightly larger but the difference was not statistically significant supporting table 1 stormflow amounts q q for individual events also increased rapidly with rainfall amount both before and after haiyan r2 0 89 and 0 99 for period i and iii respectively although the two relationships describing pre and post haiyan conditions were not significantly different post haiyan values of q q for a given rainfall amount tended to be slightly higher fig 6 a overall weighted mean values of q q p for the two periods derived by dividing cumulative q q for all examined events during a period by the corresponding cumulative p were 24 and 47 implying a doubling of q q p during the post typhoon period table 2 converting the pre and post typhoon median q q values to equivalent minimum contributing areas mca suggested median mcas of 0 28 and 0 72 ha respectively peak streamflow q p increased non linearly with event rainfall amount in both periods fig 6b but the correlations were less strong than the corresponding q q p relationships r s 0 78 and 0 86 for period i and iii respectively nevertheless peak flows for a given rainfall were significantly higher for post haiyan conditions compared to the pre disturbance situation fig 6b fig 7 shows the influence of the maximum 15 min rainfall intensity recorded during an event i max 15 expressed as mm h 1 equivalent on the magnitude of the stormflow volume and peak streamflow because the weir overflowed during some larger events leading to some uncertainty in peak flow estimates see methods a distinction was made between regular events no overflow and events with weir overflow conditions for up to 25 of the stormflow duration n 5 during the pre haiyan period n 14 post haiyan neither type of stormflow amount was affected by i max 15 not even for very high values of i max 15 fig 7a there was a clear threshold in the relation between q p and i max 15 with the magnitude of the threshold differing between the two periods before haiyan q p increased more with rainfall intensity after i max 15 exceeded 25 mm h 1 whereas during the post haiyan period the response was both more pronounced 3 4 times larger and earlier for i max 15 15 mm h 1 fig 7b however correlations were generally poor fig 7 using the maximum 5 or 30 min rainfall intensities instead of i max 15 gave very similar results not shown 4 4 effect of antecedent soil moisture conditions on runoff response both during the pre and post typhoon period storm runoff was a threshold function of the integrated antecedent soil water content in the upper 60 cm of the soil profile aswc60 plus precipitation p in that both q q and q p increased rapidly beyond a critical value as shown in fig 8 threshold values differed somewhat between the sites where soil water contents were monitored for the upper slope location station s1 a threshold value of 325 mm for aswc60 p was derived versus 250 mm at the mid slope site s2 fig 8a and c versus fig 8b and d the threshold value for the mid slope site fell between the depth integrated 0 60 cm amounts of soil water at saturation 270 mm andfield capacity 230 mm but nearly coincided withsaturated conditions at the upper site 345 mm cf supporting fig 3 correlations after the threshold values were generally stronger for the relation between stormflow amount and aswc60 p pre haiyan values of r2 0 56 0 96 than for the relation between peak flow and aswc60 p r2 0 44 0 54 there were no significant differences in the relations for pre and post haiyan conditions except for a possible tendency towards a slightly higher threshold value at the upper site during the post haiyan period fig 8a and b the strength of the post haiyan correlations was again much greater for q q r2 0 99 at both measuring sites than for q p r2 0 40 0 43 fig 8 4 5 landslide incidence during typhoon haiyan during the passage of typhoon haiyan on 8 november 2013 very strong winds up to 314 km h 1 rabonza et al 2015 caused defoliation of the regenerating vegetation in the central part of the catchment as well as massive damage to tree stems and branches fig 1b the high rainfall 228 mm of rain was captured during the event by the lower rain gauge plus up to 50 mm of wind driven precipitation by the fog gauge at site s1 caused the reactivation of some existing landslides and the creation of several new ones including a major landslide that partly buried the stream gauging station during the latter phase of the haiyan event cf fig 2 no landsliding was observed during the passage of a tropical storm on 28 29 june 2013 which delivered 154 mm of rain landslide surveys conducted before august 2013 and after december 2013 typhoon haiyan indicated an increase in projected impervious landslip surface area from 1080 to 2450 m2 these areas represent 3 4 and 7 7 of the total catchment area respectively implying a 227 increase in potential mca after the passage of typhoon haiyan 4 6 catchment sediment yield although suspended sediment concentrations ssc for manually collected rising stage samples were generally higher than for corresponding falling stage samples during the pre haiyan period ssc values obtained with the single stage samplers were typically intermediate between either type of manually collected sample fig 9 a the slope of the resulting sediment rating curves for pre and post haiyan conditions i e periods i and iii did not differ much between the two periods but ssc values for a given instantaneous streamflow were much enhanced 2 6 times with an overall average streamflow weighted factor of 3 5 after typhoon passage fig 9b combined with the higher stormflows and generally higher daily streamflow at the height of the wet season november january during the post haiyan period table 2 and fig 3b this suggests strongly enhanced suspended sediment transport during periods ii and iii table 3 while the figure derived for period ii is particularly uncertain because of the estimated daily streamflow totals there can be little doubt that overall suspended sediment export from the landslide impacted basper micro catchment during the study year was both substantial at 25 t ha 1 yr 1 and heavily dominated by post haiyan sediment transport 94 of the estimated annual total suspended load table 3 accumulated bedload volumes roughly mirrored corresponding stormflow totals per collection period with the greatest amount of bedload movement being associated with the extreme haiyan event fig 10 and supporting table 2 overall sediment export in the form of bedload amounted to a modest 2 1 t ha 1 yr 1 or 8 of the total sediment load table 3 5 discussion 5 1 tropical grassland runoff response runoff response to rainfall in the basper fire climax grassland catchment was pronounced with an overall pre haiyan stormflow coefficient q q p of 24 versus 47 for post haiyan conditions period iii table 2 such storm runoff coefficients are high to very high even compared to findings for wet lowland tropical locations with an impeding layer i e low hydraulic conductivity k sat at shallow depth which are known to produce more storm runoff than sites having deeper and or more permeable soils elsenbeer 2001 chappell et al 2007 chappell et al 2012 for the former conditions germer et al 2010 and de moraes et al 2006 reported average wet season values of q q p for micro catchments 0 7 ha each under lightly grazed pasture in rondônia and eastern amazonia of 18 and 21 year with average rainfall respectively while gilmour 1977 obtained an overall value of 30 for a partially converted lowland rain forest catchment in northern queensland subject to extreme precipitation inputs during tropical storms and cyclones although the way in which these q q p values were derived differed somewhat between studies the bulk of the stormflow produced at the three locations consisted of overland flow mostly of the saturation excess type sof due to a rapidly decreasing k sat with depth that resulted in the formation of perched water tables and gradually expanding hillside saturation during times of peak rainfall bonell et al 1981 de moraes et al 2006 germer et al 2010 the very low values of surface k sat at the eastern amazonian site of de moraes et al 2006 suggest that infiltration excess overland flow iof was important as well further q q p values at the respective sites increased with catchment wetness status and rainfall input germer et al 2010 de moraes et al 2006 howard et al 2010 as also found in this study supporting table 1 interestingly storm runoff coefficients per rainfall size class at basper supporting table 1 were very similar to corresponding values derived by howard et al 2010 for forested and grassland catchments during the main monsoon season in northern queensland that are generally regarded as some of the most responsive humid tropical catchments described to date bonell 2005 cf chappell et al 2012 comparative published data for tropical fire climax grassland catchments as opposed to man made grasslands are all but non existent although several studies have reported on overland flow production at the plot scale in imperata grasslands in indonesia coster 1938 and the philippines northern luzon jasmin 1976 southern leyte chandler and walter 1998 observed amounts of overland flow were low to modest in the absence of grazing and burning even during years with high rainfall 5 13 of p coster 1938 jasmin 1976 but an extremely high surface runoff fraction as much as 69 of p was reported for a severely overgrazed grassland by chandler and walter 1998 while overland flow in the latter case consisted entirely of iof chandler and walter 1998 occasional sof cannot be excluded in the luzon grassland investigated by jasmin 1976 considering the reportedly high soil infiltration capacity the ecosystems research and development bureau in the philippines monitored streamflow from a lightly grazed micro catchment 1 6 ha under imperata grassland at angat luzon that was burned annually between 1973 and the early 1990 s daño 1995 limsuan 1995 although the original daily flow data have been largely lost monthly and annual precipitation p total runoff q t and storm runoff q q data for the period 1974 1988 a m daño personal communication allowed computation of the long term average q q p value annual stormflow coefficients were high to very high 29 53 with an overall average value of 43 6 i e very similar to the post haiyan value derived for the basper grassland 47 table 2 the angat catchment s suspended sediment yield 5 6 t ha 1 yr 1 was low by philippine standards daño 1995 cf white 1990 possibly implying low to modest surface erosion stormflow made up 94 of q t on average while apparent et approximated by p q t amounted to 1725 mm yr 1 suggesting considerable leakage losses 5 2 runoff response in the basper fire climax grassland a conceptual model with 64 of its total runoff being supplied by stormflow or 38 of p the basper grassland micro catchment ranks as one of the most responsive humid tropical sites described to date as reviewed by bonell 2005 cf fritsch 1993 godsey et al 2004 howard et al 2010 it also appears more responsive than several forested steepland catchments subject to regular typhoon incidence in taiwan average q q p 12 26 cheng et al 2002 chang et al 2013 yet the basper grassland site lacks the typical characteristics that have been identified as key factors leading to such a pronounced response such as the presence of i a wide valley bottom and gentle foot slopes prone to localized sof fritsch 1993 germer et al 2010 ii an impeding layer at very shallow depth 10 20 cm under high rainfall conditions leading to widespread hillslope sof bonell et al 1981 elsenbeer et al 1992 de moraes et al 2006 or iii near surface pipes feeding rapid return flow to foot slopes and headwater gullies elsenbeer and vertessy 2000 cf chappell 2010 what then makes the basper grassland so responsive arguably two aspects set the study catchment apart i its proneness to landsliding fig 2 and ii the low to very low hillside k sat values throughout the soil profile zhang et al 2018a landslide slip faces at basper were effectively impermeable zhang et al 2018a cf merz and mosley 1998 and iof was commonly seen on these during rain events supporting fig 4a however although the 2 6 fold increase in median pre and post haiyan storm runoff coefficients from 8 7 to 22 7 table 2 was roughly proportional to the corresponding increase in the surface area occupied by landslides 2 3 times from 1080 to 2450 m2 the minimum contributing area equivalents of the median pre and post haiyan stormflow fractions 0 28 and 0 72 ha table 2 were up to three times larger than the contributing areas represented by the landslides nevertheless pre and post typhoon landslide surface areas were ca 2 7 times larger than the respective mca equivalents of the lower 25th percentile stormflow values table 2 indicating landslide surfaces were important as a source area for storm runoff during smaller events additional runoff contributions are needed however to explain the observed high stormflow volumes large macropores in the form of former root channels or animal burrows were rarely observed they appeared to be absent in the upper slope profiles dominated by grasses and sedges but were occasionally seen in the top layer beneath the regenerating forest in the riparian zone quiñones 2014 hence rapid subsurface contributions to stormflow if any would appear to be restricted to a narrow riparian zone this leaves hillside iof and or sof as the chief remaining potential storm runoff contributing processes the soils on the upper slopes and ridges site s1 appeared to be saturated for most of the time at depths below 45 cm but were better drained around 30 cm depth although the top layer approached saturation during the peak rainy months supporting fig 3 manually measured groundwater levels taken shortly after major rainfall events were restricted to the subsoil always 70 cm and not seen to rise to the surface to produce sof cf godsey et al 2004 de moraes et al 2006 similarly at the mid slope site s2 soil water contents always remained below saturation at depths greater than 40 60 cm although occasional saturation during times of peak rainfall may have occurred at 20 cm depth and possibly at 10 cm depth supporting fig 3 nevertheless groundwater levels were also low at this site suggesting sof did not occur on the mid slope segment either however sof cannot be excluded for those parts of the riparian zone that exhibited a shallow layer of soil over fractured weathered rock supporting fig 4b quiñones 2014 indeed groundwater levels at piezometer g1 cf fig 2 occasionally rose to within 5 cm below the surface during times of peak rainfall supporting fig 5 finally the fact that both the median surface infiltrability 2 1 0 4 mm h 1 and median near surface k sat 2 85 mm h 1 at 20 50 cm depth beneath grasses and shrubs were lower than or similar to the median 5 min rainfall intensity 3 2 mm h 1 hourly equivalent may be taken as a strong indicator of the importance of iof as a source of storm runoff at basper zhang et al 2018a values of k sat measured at three locations within the regenerating riparian vegetation were not higher than those beneath imperata grass or shrubs on the hillslopes quiñones 2014 hence hillside iof is not likely to completely re infiltrate on the footslope cf woolhiser et al 1996 chappell et al 1998 although values of surface and near surface k sat may have been underestimated by the use of a relatively small infiltrometer 15 cm inner diameter and because of possible borehole smearing respectively see zhang et al 2018a for fuller discussion there is little doubt that hydraulic conductivities for the majority of the soils at basper are low to very low further while direct observations of iof occurrence away from landslip surfaces supporting fig 4a are lacking cf jasmin 1976 chandler and walter 1998 support for the contention that storm and peakflow generation at basper is dominated by iof comes from the fact that i both q q and q p responded in a linear fashion to rainfall intensity beyond threshold values of 10 15 mm h 1 fig 7 and ii stream water ec values were often low to very low during peak flows indicating major dilution with low conductivity water such as rainfall and by implication overland flow fig 3c cf bruijnzeel 1983b elsenbeer et al 1995 5 3 fire climax grassland water use average apparent evapotranspiration et rates for the imperata grassland plus the young regenerating vegetation of the central part of the catchment derived from the catchment water budget table 1 were 4 7 mm d 1 prior to disturbance by typhoon haiyan period i and 3 6 mm d 1 post haiyan period iii the pre disturbance et might seem rather high at first sight compared to overall average values reported for grazed pastures across the tropics typically 3 4 mm d 1 van der molen et al 2006 and a possible effect of unaccounted leakage losses cannot be entirely excluded given the very small size of the study catchment however leakage losses if any are likely to be very small because not only has the stream incised itself down to fresh bedrock in the lower section where the flow is perennial and the gauging weir is located cf supporting fig 1 but also the recession analysis did not show a detectable deviation from linear reservoir theory for the outflow from the groundwater reservoir fig 5 furthermore the fact that flows did not cease during several extended dry periods fig 3b is remarkable in itself for such a small drainage area also it is pertinent to remember that the water use of young vigorous tropical regrowth making up 14 of the vegetation at basper is enhanced relative to that of grassland hölscher et al 1997 giambelluca et al 2000 lastly with the exception of a dry period in october 2013 when the grass started to fade and in may 2014 at which time the grass did not exhibit any signs of moisture stress despite very low topsoil moisture content in the upper part of the catchment soil water content in the basper grassland at 20 cm depth and below were generally high supporting fig 3 zhang et al 2018a mid slope topsoil moisture values remained well above permanent wilting point as well 28 j zhang unpublished data in contrast at other more seasonal sites grassland water use has been reported to be reduced during the dry season wright et al 1992 wolf et al 2011 or even to come to a complete halt as the grass went dormant waterloo et al 1999 however comparably high evaporation rates have been obtained at most tropical pasture sites during the transition from the wet to the dry season when neither moisture nor energy are limiting evaporation 3 7 4 2 mm d 1 wright et al 1992 van der molen et al 2006 wolf et al 2011 waterloo et al 1999 observed a strong relationship between the monthly water use and leaf area index lai of a fire climax grassland under highly seasonal conditions in fiji at basper the extreme winds encountered during passage of typhoon haiyan 85 m s 1 rabonza et al 2015 effectively defoliated the trees and shrubs and flattened the grasses cf fig 1b thereby likely to greatly reduce et initially cf table 1 overall post haiyan et rates are therefore likely to have been dominated initially by soil evaporation after the passage of typhoon haiyan cf scatena et al 2005 with transpiration gradually increasing again as the grasses recovered in january 2014 followed by the gradual refoliation of shrubs and trees in march 2014 the lai of a nearby forest effectively recovered to pre disturbance values after 3 months zhang et al 2018b the relative magnitude of the average apparent et values derived for periods ii and iii although somewhat uncertain for period ii in particular do reflect this expected trend table 1 5 4 landsliding and catchment sediment yield at 27 t ha 1 of which 25 t ha 1 yr 1 was carried in suspension and 2 t ha 1 yr 1 was transported as bedload table 3 the estimated sediment yield of the basper grassland catchment during the study year was considerable for example the long term average sediment yield for the annually burned grassland at angat in luzon referred to earlier daño 1995 was 5 3 t ha 1 yr 1 although as responsive hydrologically as the basper grassland a m daño unpublished data slope gradients at angat were more modest 30 40 and mass wastage was unimportant however sediment yields of nearly 40 t ha 1 yr 1 were measured elsewhere in luzon magat area for overgrazed headwater catchments subject to regular fire and widespread mass wasting white 1996 by contrast baseline sediment yields for small forested headwater catchments in high rainfall 3000 mm yr 1 areas in south and south east asia without major landsliding nor subject to tropical cyclones are typically less than 4 t ha 1 yr 1 bruijnzeel 1983a malmer 1990 douglas et al 1992 gafur et al 2003 the extreme event of 8 november 2013 passage of typhoon haiyan was decisive in several ways firstly an estimated 25 t of sediment 7 8 t ha 1 were exported during this particular event alone which is equivalent to 29 of the annual total further before haiyan period i 158 days only 0 55 t ha 1 of suspended sediment were transported per 100 mm of stormflow compared to an estimated 3 4 and 2 0 t ha 1 per 100 mm of stormflow during post haiyan periods ii 15 days and iii 192 days respectively table 3 measured suspended sediment transport during period iii 15 t ha 1 was 3 5 times higher than predicted for the same amount of streamflow using the pre haiyan sediment rating curve fig 9b indicating greatly increased sediment availability after haiyan presumably due to the landsliding that occurred during the event cf fig 2 interestingly a previous large rainfall event 28 29 june 2013 that delivered 154 mm of rain but did not generate new landslides caused only 1 5 t of sediment to be transported in suspension 0 5 t ha 1 assuming the pre haiyan sediment rating curve to represent conditions without major sediment contributions by mass wasting and combining it with measured post disturbance streamflow gave a suspended sediment yield of ca 7 t ha 1 yr 1 for the june 2013 may 2014 study period being similar to the 5 3 t ha 1 yr 1 for the angat grassland micro catchment the situation at basper is conducive to landslide generation due to a combination of steep upper slopes a less than cohesive subsoil becoming sandier and stonier with depth quiñones 2014 zhang et al 2018a absence of a deep stabilizing root system cf o loughlin 1984 sidle et al 2006 and high to very high rainfall rabonza et al 2015 as such it is of interest to examine why the haiyan event generated so much sediment while the june 2013 event did not although the two events differed in terms of their total rainfall 258 mm versus 154 mm rainfall amounts in both cases were well above the 70 mm rainfall threshold value identified by nolasco javier et al 2015 as being required for shallow landslides to occur in non forested terrain in the baguio area luzon similarly estimated kinetic energies associated with the two storms were well above the critical threshold value of 2000 j m 2 proposed by lin and chen 2012 for landslide initiation in forested taiwanese steepland although the value associated with typhoon haiyan ca 5500 j m 2 was nearly twice that for the june 28 29 event ca 2800 j m 2 further actual pre storm water storage in the top 60 cm of soil was almost identical on both days as well as during the seven days preceding the respective events cf supporting fig 3 while foot slope groundwater levels measured at piezometer g1 reached a higher value during the june event than during typhoon haiyan supporting fig 5 despite the higher rainfall associated with the latter however a major difference between the two situations relates to the fact that the haiyan event had been preceded by a period of low rainfall from mid august 2013 onwards until rainfall increased again around mid october fig 3 this dry period caused the development of cracks that may have facilitated rapid transfer of the heavier rainfall in late october and early november to deeper layers thereby saturating the soil rock interface to critical levels during the haiyan event with its maximum 60 min intensity of 81 mm cf supporting fig 3 whereas normally much if not most of the rainfall would have run off the hillslope surface due to the very low hydraulic conductivity of the soils at basper the close correlation between landslide incidence and extreme rainfall during typhoon passage observed in the philippines and elsewhere in the region nolasco javier et al 2015 nolasco javier and kumar 2018 lin et al 2008 chen et al 2015 does not bode well for a future in which tropical storms and cyclones are expected to become more forceful due to continued oceanic warming balaguru et al 2016 apart from the corresponding increase in stream sediment load areas prone to landsliding like the basper grassland can be expected to become more hydrologically responsive in the future cf chiang and chang 2011 walsh et al 2013 while the progressive loss of the overburden may cause a gradual loss of soil water storage potential and eventually lead to diminished baseflows rawat et al 2015 cf bruijnzeel 1989 6 conclusions rainfall streamflow and sediment yield were determined for the basper fire climax grassland micro catchment 3 2 ha near tacloban leyte island philippines between 3 june 2013 and 2 june 2014 the catchment had not been burned or grazed for ten years prior to the start of the measurements and the central portion 14 of the catchment surrounding the perennial stream was covered by low but dense regenerating vegetation on 8 november 2013 the area was struck by typhoon haiyan one of the largest events on record runoff response to rainfall was very pronounced with weighted average storm runoff coefficients q q p being 24 and 47 for pre and post haiyan conditions respectively the latter value ranks as one of the highest reported in the literature on humid tropical runoff responses overland flow contributions on landslide slip surfaces occupying 3 4 and 7 7 of the catchment before and after haiyan were important as a source of storm runoff but by far not sufficient to explain the high q q values that were observed macropores were observed only occasionally in the soils beneath the regenerating riparian zone forest suggesting rapid lateral subsurface stormflow was probably limited to a very small part of the catchment at best although near surface soil moisture was high during the wettest months perched groundwater levels were not observed to reach the surface except occasionally near the stream channel hence saturation excess overland flow is likely not a major contributor of storm runoff either rather in view of the low to very low hydraulic conductivities of the soils underlying the imperata grass and shrub as well as the regenerating riparian vegetation infiltration excess overland flow is considered the dominant runoff generating mechanism at basper pre typhoon water use by the combined imperata grassland and young regenerating vegetation as derived from the catchment water budget was rather high 4 7 mm d 1 possibly reflecting a combination of vigorously regenerating riparian vegetation a generally high soil moisture content and breezy conditions post typhoon evapotranspiration of the heavily disturbed vegetation was initially much reduced but recovered somewhat towards the end of the study period 3 6 mm d 1 the annual sediment production was high 27 t ha 1 and greatly exceeded values previously reported for fire climax grasslands in the region that were not subject to widespread mass wasting post typhoon sediment transport over a period of six months was estimated to be 3 5 times higher than would have been the case without the massive landsliding that occurred during the haiyan event indicating increased and possibly prolonged sediment availability in view of continued oceanic warming and the gradual intensification of extreme rainfall events in the region mass wasting and sediment yields are expected to increase in the future acknowledgements financial support for this work from the china scholarship council to jun zhang vu university amsterdam and the australian council for international agricultural research aciar grant no asem 2010 050 to professor j herbohn is gratefully acknowledged we thank the leaders of barangay basper for their permission to work in the basper catchment mr josé june bagay for assistance in the field miss ofelia maranguit and miss jertz escala for help with the laboratory analyses under the supervision of professor angela ferraren visayas state university vsu professor alfredo lagmay and miss maricar rabonza of the university of the philippines kindly provided the dtm files that enabled the preparation of the catchment map we are especially grateful to dr antonio daño ecosystems research and development bureau laguna for sharing the unpublished angat grassland data and marc vis university of zurich for help with the hbv model dr nestor gregorio aciar project and university of the sunshine coast usc and professor arturo pasa vsu are thanked for overall facilitation of the project and professor john herbohn usc for his continuous support the manuscript benefited from the constructive comments of three anonymous reviewers which is gratefully acknowledged appendix a supplementary material supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 08 016 appendix a supplementary material supplementary fig s1 view of the compound sharp crested v notch weir used for measuring streamflow at the outlet of the basper micro catchment inset view of rising stage sample bottle rack and water level and electrical conductivity sensors housed in the two blue pipes and protected by metal caps photographs by j zhang supplementary fig s2 relations between the 5 min observed q obs and median simulated q sim streamflow for the 25 best parameter sets for the a pre and b post haiyan periods using the hbv light model supplementary fig s3 time series of hourly rainfall intensity a and volumetric soil water content at different depths at the basper grassland upper slope site b and the basper mid slope site c estimates of porosity in the ap ab and bw horizons are indicated by horizontal dashed lines supplementary fig s4 infiltration excess overland flow was observed frequently on landslip faces during rain b seepage from the lower left bank soil profile where soil cover was shallow and rock material fractured photographs by j zhang supplementary fig s5 depth to shallow groundwater table cm at piezometer site g1 lower left bank during the study year hourly values hourly rainfall amounts added for comparison supplementary data 1 
7022,decades of logging and slash and burn agriculture have turned vast tracts of land in tropical south east asia into unproductive fire climax grasslands whose hydrological functioning is poorly known to help fill this knowledge gap a 3 2 ha landslide affected imperata grassland micro catchment with perennial flow on leyte island philippines was instrumented and monitored for a year the area was hit by typhoon haiyan on 8 november 2013 one of the largest events on record landslide surfaces covered 3 4 of the catchment prior to typhoon haiyan and contributed to direct runoff q q this basic contributing area increased to 7 7 by activation of old landslides and formation of new ones during typhoon haiyan median storm runoff coefficients q q p based on straight line hydrograph separation were 9 and 23 before 48 events and after the typhoon 43 events respectively but the ratios of period total q q and p were much larger 24 and 47 respectively both storm runoff volumes and peak discharge increased rapidly once a mid slope water storage threshold for the upper 60 cm of soil of 250 mm was exceeded storm runoff contributions above those generated on landslides were most likely in the form of overland flow given the prevailing very low soil hydraulic conductivities post typhoon water use of the heavily disturbed vegetation was reduced initially by nearly 70 recovering to nearly 80 of the pre typhoon value after 3 months the high annual sediment yield 27 t ha 1 was heavily dominated by post haiyan sediment transport 94 bedload contributed 8 of the total sediment yield keywords hillslope hydrology imperata grassland landsliding runoff generation tropical hydrology 1 introduction decades of swidden cultivation also called slash and burn agriculture brady 1996 have created extensive tracts of largely unproductive fire climax grassland across the tropics garrity et al 1997 hooper et al 2005 styger et al 2007 despite their considerable spatial extent an estimated 35 million ha in south and south east asia alone in the 1990s garrity et al 1997 very few hydrological studies have focused on these imperata and saccharum dominated tropical grasslands particularly in terms of runoff processes at the catchment scale waterloo et al 1999 showed that the water use of a seasonally dormant non grazed fire climax grassland in the fiji archipelago followed the seasonal pattern of leaf surface area and was much lower than evapotranspiration from nearby pine plantations suggesting grassland soils may be wetter and thus hydrologically more responsive than forest soils in addition soils of fire climax grasslands can be water repellent because of repeated burning and compacted when grazed jasmin 1976 snelder 2001 starkel and singh 2004 this may lead to enhanced overland flow chandler and walter 1998 and surface erosion concepcion and samar 1995 there is typically an increase in the incidence of shallow 2 3 m landslides on tropical steeplands a few years after deforestation when the extra hillslope strength formerly imparted by the roots of the trees starts to decline o loughlin 1984 cf rabonza et al 2015 particularly in areas characterized by seasonally high rainfall steep slopes a regolith overlying impermeable rock and significant tectonic activity scatena et al 2005 sidle et al 2006 lin et al 2008 wu and chen 2009 thus sediment yields from fire climax grassland catchments subject to landsliding can be much enhanced cf page et al 1994 trustrum et al 1999 even when contributions by surface erosion are modest jasmin 1976 starkel and singh 2004 such findings are especially pertinent in the philippines which are located in one of the world s premier cyclone generating areas garcía herrera et al 2007 and where about 30 of the annual precipitation is received during the passage of tropical cyclones and depressions cinco et al 2016 annual sediment yields from upland catchments in the philippines and similar settings e g taiwan are heavily dominated by sediment generated during such extreme events white 1990 lin et al 2008 therefore in view of i the general lack of catchment scale hydrological and sediment yield studies for tropical fire climax grasslands cf daño 1995 and ii the expected intensification of extreme events in the region due to continued oceanic warming and freshening balaguru et al 2016 we monitored key hydrological variables in a landslide impacted imperata grassland micro catchment 3 2 ha with perennial streamflow at the village of basper near tacloban city north eastern leyte island eastern visayas the philippines for a year measurements included continuous observations of rainfall streamflow soil moisture and shallow groundwater levels with the aim to quantify i the water budget of a cogon grassland ii the grassland s runoff response to rainfall including extreme events and iii the role of landslides with respect to stormflow generation and sediment supply during the study year the catchment was hit by typhoon haiyan one of the largest events on record in the region delivering more than 200 mm of rain within several hours nguyen et al 2014 this provided an opportunity to study the effect of this extreme event and associated landsliding on runoff production and sediment yield zhang et al 2018a reported very low surface and near surface saturated soil hydraulic conductivities for the basper grassland as well as high top soil moisture contents during months with peak rainfall such conditions are conducive to the generation of both infiltration excess iof and saturation excess overland flow sof bonell 2005 specifically we hypothesized that a cogon runoff response to rainfall is flashy due to the prevailing low soil infiltration capacity and high soil water content b landslides constitute a significant source of direct runoff during rainfall events and c extreme events like typhoon haiyan increase the number of landslides thereby enhancing overall catchment runoff response and especially sediment yield 2 study area the south facing 3 2 ha headwater basper micro catchment is located 14 km west of the city of tacloban at 11 15 28 n and 124 57 22 e elevations range from 50 to 135 m a s l the upper slopes are straight to slightly concave while the lower slopes steepen towards the stream the average slope is 23 landslide scars are prominent in the landscape fig 1 the climate is tropical ever wet köppen type af mean annual rainfall at nearby tacloban airport 1977 2011 is 2660 mm range 1435 4790 mm distributed over on average 195 rain days i e 0 5 mm of rain per day per year although there is no clearly defined dry season average rainfall from november to january 350 mm mo 1 is higher than for april may 100 mm mo 1 typhoons and tropical storms occur regularly in the area cinco et al 2016 seasonal variation in monthly temperatures at tacloban airport is small ranging from 25 7 c in january to 28 1 c in may as are seasonal variations in average daily relative humidity 81 86 and average monthly wind speeds 1 5 2 4 m s 1 average daily reference evaporation rates allen et al 1998 computed from basic climatic data for tacloban airport range between 3 0 mm d 1 for december and 4 8 mm d 1 for april the vegetation consisted of cogon grass imperata cylindrica l beauv on the ridges and a few isolated coconut trees fig 1a and upper slope areas with sedges cyperus sp being numerous in less drained parts the mid slopes had mixed grassland and low shrub 1 5 m high mostly melastoma malabathricum l smith and chromolaena odorata l r m king h robinson while shrubs and young trees 2 3 m high mostly neonauclea lanceolata blume merr and leukosyke capitella wedd were common on the lowermost slopes near the streams along with a few remnant planted acacia mangium willd trees fig 1a although regularly burned in the past the basper study site had not experienced any fire since 2003 and young regenerating forest occupied an estimated 4500 m2 in the central portion of the catchment representing 14 of the total area on 8 november 2013 the area was hit severely by typhoon haiyan one of the largest events on record which effectively defoliated all shrubs and saplings fig 1b and buried the foot slope vegetation with landslide material in some places the pre typhoon leaf area index of the riparian vegetation 26 measurements made in august 2013 at 5 m intervals in the riparian zone using a cid bio science ci 110 plant canopy imager was 1 6 1 0 m2 m 2 the underlying mafic rock gabbro belongs to the tacloban ophiolite complex dimantala et al 2006 soils are classified as eutric cambisols with a predominantly clay loam texture upper 0 9 m grading to sandy clay loam at greater depth median values median absolute difference mad of soil organic carbon content declined with depth from 2 3 0 7 at 10 cm to 1 0 0 3 at 20 cm and 0 5 0 1 below 40 cm zhang et al 2018a similarly median soil porosity decreased with depth from 51 7 10 cm to 47 4 20 cm and 42 1 below 60 cm while median bulk density increased from 1 14 0 08 g cm 3 10 cm to 1 33 0 05 g cm 3 40 cm and 1 38 0 07 g cm 3 deeper in the profile 60 100 cm the median value of the final surface infiltration rate as determined with a portable double ring infiltrometer n 13 was 2 1 0 7 mm h 1 while median field saturated soil hydraulic conductivities k sat n 47 determined with a constant head well permeameter amoozegar 1989 were 2 85 1 80 mm h 1 at 20 40 cm depth inter quartile range 0 8 6 6 mm h 1 and 1 mm h 1 iqr 0 1 1 8 mm h 1 below 60 cm see zhang et al 2018a for details 3 methods 3 1 field measurements 3 1 1 hydrological monitoring field measurements were made between june 2013 and 2014 rainfall p was measured using two tipping bucket rain gauges rg3 onset computer corporation usa 0 25 mm per tip confirmed by manual calibration connected to a hobo pendant event data logger one gauge was located in the open below the outlet of the catchment and the other on the upper western ridge fig 2 a standard manual rain gauge 100 cm2 orifice was placed next to the tipping bucket gauges and read every morning as a check daily rainfall totals for the two recording gauges were strongly correlated r2 0 99 n 113 rain days with p 0 5 mm and occasional gaps in the record of either gauge were filled using the data for the other gauge e g during typhoon haiyan and the subsequent 11 day period when only the more sheltered lower gauge was functioning although wind speeds were measured at the site of the upper recording gauge see below between 8 july and 8 november 2013 when the instrument was destroyed during the passage of typhoon haiyan no corrections were made for wind related under estimation of rainfall since wind speeds were generally low and the application of correction methods e g førland et al 1996 for the extreme wind speeds encountered during the haiyan event up to 315 km h 1 rabonza et al 2015 leads to unverifiable and uncertain corrections instead the catch of a recording cylindrical fog gauge located at site s1 with a 100 catch efficiency for near horizontal wind driven rain frumau et al 2011 was used to estimate extra inputs of near horizontal rainfall during the haiyan event because the catch efficiency of live vegetation is smaller than that of the type of fog gauge employed bruijnzeel et al 2005 it is acknowledged that such an estimate will represent a maximum value basic climate variables for the computation of reference evapotranspiration et0 allen et al 1998 for use in the hbv light modeling see below were measured by a dws automatic weather station decagon u s a located at site s1 from 8 july 2013 onwards short wave radiation was measured by a pyranometer temperature and relative humidity by sensors placed within a radiation shield at 2 m from the ground and wind speed by a cup anemometer also at 2 m all data were recorded at 5 min intervals by a decagon em50 data logger the anemometer was destroyed during passage of typhoon haiyan henceforth wind speeds were approximated using corresponding long term averages for the respective months as measured at tacloban airport pagasa weather office tacloban streamflow q was measured using a sharp crested compound weir consisting of a 0 55 m high 90 v notch and a horizontal beam extending 0 5 m to each side from the edge of the v notch supporting fig 1 water pressures were measured at 5 min intervals using a hobo u20 logger atmospheric pressure was measured using a hobo u20 logger in a hut located 100 m from the weir and used to calculate the water levels from the water pressure measurements the standard v notch weir equation bos 1989 was checked through streamflow measurements volumetric measurements below 4 4 l s 1 staff heights 0 3 m and the velocity area method at stages up to 0 55 m using a price type aa current meter water levels exceeded the shoulder of the v notch during 22 storm events in total 48 7 h or 0 4 of the total study time and for these conditions the bergmann compound weir equation as given by usbr 1997 was used to calculate streamflow water level data were incomplete for 52 days 14 of the total time due to equipment malfunctioning amongst others during the 15 day period immediately following typhoon haiyan with the exception of the latter period the calibrated hbv model bergström 1992 1995 as implemented in the hbv light version of seibert and vis 2012 was used for gap filling see streamflow gap filling section below for details suspended sediment concentrations ssc of the stream water were determined for samples collected during the rising stage of 34 events using up to eleven 400 ml water bottles equipped with a siphon shaped air exhaust schick 1967 with their apertures placed at successively greater heights 8 52 5 cm above the lowermost point of the v notch see inset supporting fig 1 bottles that filled during an event were replaced by clean empty ones generally the next day in addition during several large events in the pre haiyan period water samples were also collected manually using 500 ml sampling bottles both during rising and falling stages manual samples were not collected during the post haiyan period in total 275 samples of suspended sediment in streamflow were collected during stormflow conditions 229 using the single stage samplers and 46 manual samples all samples were filtered in the laboratory at visayas state university first through whatman grade 589 2 standard filter paper 4 12 µm and subsequently through millipore 0 45 μm filters the residues were oven dried for 24 h at 105 c and weighed to the nearest 0 001 g to give ssc in mg l 1 ssc values were linked to the streamflow at the time that the bottle filled to derive separate sediment rating curves for pre and post haiyan conditions and to allow estimation of suspended sediment transport from the continuous streamflow record walling 1977 white 1990 it is acknowledged that the use of mostly rising stage samples normally leads to an over estimation of the suspended sediment load because of the generally higher ssc during rising stage conditions walling 1977 however because the values of ssc obtained with the single stage samplers were intermediate between those of manually collected rising and falling stage samples see section on catchment sediment yield below we assume that this over estimation is relatively minor the electrical conductivity ec of the stream water was measured at 5 min intervals using a hobo u24 conductivity logger installed next to the water level sensor cf inset supporting fig 1 the ec data were regularly checked against manual measurements made with a cyberscan pc300 ph conductivity tds meter envco australia bedload accumulation behind the weir was determined volumetrically at irregular intervals n 6 by removing the sediment using a bucket of known volume sediment volumes were converted to oven dry weights using the mean bulk density of the bed material estimated at 1 2 g cm 3 rijsdijk and bruijnzeel 1990 seasonal and annual totals were obtained by summing individually measured values the sediment volume accumulated between 10 february and 2 june 2014 end of observation period was estimated by multiplying the average bedload concentration per mm of stormflow based on constant slope hydrograph separation see section 3 3 1 below during january 2014 n 3 times the total stormflow between the above two dates volumetric soil moisture content θ was monitored at a 5 min interval at two locations within the catchment sites s1 and s2 in fig 2 at site s1 on the western ridge a mixture of cogon grass and sedges decagon ec 5 moisture sensors were installed at depths of 0 15 0 30 and 0 55 m below the surface and connected to a decagon em50 data logger at site s2 cogon grassland at mid slope position simplified time domain reflectometry tdr sensors mp 306 ict international australia were installed at 0 10 0 20 0 40 0 60 0 80 and 1 10 m depth the sensors were connected to an ict international microvolt data logger shallow groundwater levels were measured in four piezometers installed at the soil bedrock interface fig 2 piezometers g1 left bank 0 9 m deep and g2 right bank 2 65 m deep were located in the young regenerating forest area close to the stream about 6 m upstream of the weir while the third site s2 2 6 m deep and fourth s1 1 7 m deep piezometers were located at the mid slope cogon grass and upper ridge cogon plus sedges soil moisture measurement sites respectively groundwater levels were measured manually once per week at piezometers g2 s1 and s2 and at 5 min intervals at piezometer g1 using a hobo u20 water pressure logger 3 1 2 landslide surveys a landslide survey was conducted in august 2013 to map all landslides within the catchment that based on visual evidence during rainfall events likely contributed directly to storm runoff for each landslide the slopes of the slip face and side slopes were measured at regular intervals along the longitudinal profile using a clinometer to determine the projected landslide surface area dunne 1977 the survey was repeated in december 2013 after typhoon haiyan had reactivated some old landslides and created several new ones fig 2 3 2 streamflow gap filling simulated streamflow was used for the 52 days during which water level data were incomplete total rainfall during these days was 193 mm the hbv light model of seibert and vis 2012 was calibrated using 5 min rainfall and streamflow data by maximizing the value of the objective function that gave equal weight to the nash sutcliffe efficiency nse and the nse for the log transformed streamflow to avoid bias towards the more uncertain high streamflow values we used 100 independent model calibration trials each consisting of 3500 model runs to derive the 100 optimum parameter sets using the gap optimization algorithm in the model the model was calibrated separately for the pre and post haiyan period a three week warming up period 3 23 june 2013 was used for the pre haiyan calibration 24 june 5 november 2013 while the period between 3 june and 22 november 2013 was used as the warming up period for the post haiyan calibration 23 november 2013 10 june 2014 to fill gaps in the streamflow record see fig 3 below for all times except during and directly after typhoon haiyan 8 22 november 2013 the 25 best parameter sets for either period were selected having average combined objective function values of 0 82 and 0 81 for the pre and post haiyan period respectively because hbv modeled 5 min streamflows were 7 and 16 lower than observed values on average during the respective periods see supporting fig 2 the gap filled streamflow data were increased proportionately modeled streamflow totals for the gap filling during the pre haiyan period amounted to 9 mm versus 27 28 mm during the wetter post haiyan period representing 2 5 of the streamflow total i e observed plus gap filled in both cases the period during and directly after typhoon haiyan 8 22 november 2013 was not included in the above model calibrations due to the absence of measured streamflow data because the model tended to under estimate the peak streamflow during other very large events we did not use the simulation results for gap filling during this period instead a simplified approach was used to estimate daily streamflow totals first daily stormflow totals q q were estimated from a polynomial relationship linking daily p and q q during the post haiyan period r2 0 99 n 43 corresponding daily baseflow amounts q b were estimated using the master recession curve see description below and the estimated baseflow for 8 november 2013 determined as the difference between total precipitation input and q q for that day as the starting point baseflow for the period 20 22 november was estimated by backward extrapolation of the measured recession for 23 25 november 3 3 data analysis 3 3 1 stormflow separation and recession analysis to separate stormflow also referred to as direct runoff or storm runoff in this paper from baseflow during rainfall events the constant slope method of hewlett and hibbert 1967 was used the following criteria were used to select rainfall events for stormflow analysis i gross p per event 5 mm ii the event was preceded by a rain free period of 6 h and iii complete rainfall and streamflow observations at 5 min intervals were available based on these criteria there were 48 rainfall events prior to typhoon haiyan median event size 14 mm maximum 154 mm and 43 rainfall events after typhoon haiyan median 17 mm maximum 215 mm stormflow amounts determined in this way q q in mm were also expressed in terms of their minimum contributing area equivalent mca expressed in ha dickinson and whiteley 1970 the mca is defined as the minimum area that contributing 100 of the effective rainfall it receives would yield the measured storm runoff as such mca q q p a i e the event storm runoff coefficient times catchment area a in ha and may be interpreted as the fraction of the catchment contributing the observed storm runoff dickinson and whiteley 1970 separate master recession curves were determined before and after catchment disturbance by typhoon haiyan using the matching strip technique of toebes and strang 1964 exponential curves were fitted to these master recession curves while recession constants k for three superimposed reservoirs were derived according to linear reservoir theory de zeeuw 1973 chapman 1999 furthermore using the method outlined by de zeeuw 1973 both master recession curves were examined for downward deviations from the exponential decline in flow for the slowest reservoir no such deviations were observed indicating no detectable catchment leakage see results below 3 3 2 catchment water budget although shallow groundwater levels were measured in the four piezometers see fig 2 for locations changes in effective shallow catchment wide groundwater storage g t were evaluated using the method of chapman 1999 in which g t in mm at time t is approximated by 1 g t q t ln k where q t is the base flow rate at time t and k is the corresponding reservoir constant day 1 eq 1 was used to calculate the changes in shallow groundwater storage δg between the start and end of the pre and post haiyan runoff observation periods from the corresponding initial and final daily baseflow values the associated changes in soil water storage δs mm were derived from the integration of measured values of θ down to 60 cm at sites s1 and s2 together with measured p and q this allowed estimation of catchment wide apparent evapotranspiration et losses using the general water budget equation et p q δg δs 3 3 3 statistical analyses because of the disturbing effect of the typhoon on the catchment s vegetation a distinction was made between pre and post haiyan conditions called periods i and iii respectively period i lasted from 3 june 7 november 2013 n 158 days while period iii lasted from 23 november 2013 to 3 june 2014 n 192 days period ii from 8 22 november 2013 n 15 days describes the period during and directly following typhoon haiyan differences in the median runoff response to rainfall before and after disturbance by typhoon haiyan were tested for significance using the mann whitney wilcoxon test for pairwise comparisons between groups because the data were not normally distributed a significance value of p 0 05 was used for all analyses statgraphic centurion xvii version 17 2 00 software was used for all statistical analyses 4 results 4 1 seasonal rainfall streamflow and stream water ec patterns the daily rainfall inputs and streamflow outputs for the basper micro catchment between 3 june 2013 and 2 june 2014 are shown in fig 3 september and october 2013 as well as february part of april and may 2014 were relatively dry whereas the period between november 2013 and january 2014 was particularly rainy by far the largest event occurred on 7 8 november 2013 when typhoon haiyan passed over the catchment and delivered at least 228 mm of rain catch of lower rain gauge uncorrected for wind losses plus up to 50 mm of wind driven near horizontal rain catch of fog gauge at s1 other very large rainfall events occurred on 28 29 june 2013 154 mm 10 13 january 2014 195 mm and 22 24 march 2014 209 mm periods with prolonged high streamflow were concentrated mostly in june 2013 and november 2013 january 2014 fig 3b stream water ec was greatly reduced during times of rainfall while baseflow ec values varied inversely with the amount of flow fig 3c although the range in average monthly ec values during baseflow conditions was nearly identical for the pre 266 322 μs cm 1 and post haiyan periods 263 330 μs cm 1 post disturbance period iii values of baseflow conductivities were higher throughout p 0 05 regardless of catchment wetness status rainfall and streamflow totals for the entire study period 365 days were 3365 and 1995 mm respectively table 1 expressed on a daily basis post haiyan rainfall period iii 23 november 2013 3 june 2014 average 8 9 mm d 1 was 19 higher on average than before catchment disturbance period i 3 june 7 november 2013 average 7 5 mm d 1 corresponding average daily streamflow values nearly doubled from 2 9 mm to 5 6 mm d 1 the flow duration curves for periods i pre haiyan and iii post haiyan shown in fig 4 confirm the greater streamflow range during the post haiyan period expressing the flashiness of the flow as the ratio between the streamflows that were exceeded for 10 and 90 of the time f 10 90 the post disturbance f 10 90 of 122 was nearly three times larger than the pre disturbance value of 44 fig 4 stormflow q q made up a very large part of total runoff q t 56 for period i versus 68 for period iii table 1 and supporting table 2 total q q for the study year amounted to 1214 mm 61 of q t versus 725 mm of baseflow 39 of q t the apparent evapotranspiration et decreased from a pre disturbance value of 4 7 mm d 1 to 3 6 mm d 1 during period iii table 1 the corresponding value derived for the 15 day period immediately after the haiyan event period ii when trees and shrubs were defoliated and grasses beaten down was much lower 1 5 mm d 1 table 1 although we have to note that the uncertainties in the total precipitation inputs during the haiyan event and in the streamflow data afterwards are considerable 4 2 streamflow recession the streamflow recession rates during the two periods did not differ significantly fig 5 a and b recessions in both cases could be described by three superimposed linear reservoirs with pre haiyan recession constants k values in fig 5 converted to d 1 of 0 024 d 1 for the slowest groundwater reservoir 0 34 d 1 for the intermediate reservoir and 2 88 d 1 for the fastest reservoir corresponding values for post haiyan conditions period ii were 0 062 0 43 and 5 64 d 1 respectively 4 3 runoff response to rainfall before and after passage of typhoon haiyan runoff response to rainfall at basper was rapid with a median pre disturbance rising limb duration amounting to only 25 min 0 42 h the corresponding value for post haiyan conditions period iii was 78 min 1 3 h table 2 although median event rainfall amount p and intensity i as well as the median three day antecedent precipitation index api3 were not significantly different for the pre and post haiyan event data sets post haiyan medians of peak flow q p stormflow depth q q and storm runoff coefficient q q p were significantly larger table 2 the median post haiyan storm runoff coefficient was 2 6 times higher 22 7 versus 8 7 for the pre haiyan period stormflow runoff coefficients q q p increased with rainfall although the spread in the data was fairly large supporting table 1 pre typhoon values ranged from a modest 7 8 sd for small events 5 10 mm of rain to 23 26 for intermediate events 20 40 mm and 55 for a very large rainfall event 154 mm equivalent values for the post haiyan period were slightly larger but the difference was not statistically significant supporting table 1 stormflow amounts q q for individual events also increased rapidly with rainfall amount both before and after haiyan r2 0 89 and 0 99 for period i and iii respectively although the two relationships describing pre and post haiyan conditions were not significantly different post haiyan values of q q for a given rainfall amount tended to be slightly higher fig 6 a overall weighted mean values of q q p for the two periods derived by dividing cumulative q q for all examined events during a period by the corresponding cumulative p were 24 and 47 implying a doubling of q q p during the post typhoon period table 2 converting the pre and post typhoon median q q values to equivalent minimum contributing areas mca suggested median mcas of 0 28 and 0 72 ha respectively peak streamflow q p increased non linearly with event rainfall amount in both periods fig 6b but the correlations were less strong than the corresponding q q p relationships r s 0 78 and 0 86 for period i and iii respectively nevertheless peak flows for a given rainfall were significantly higher for post haiyan conditions compared to the pre disturbance situation fig 6b fig 7 shows the influence of the maximum 15 min rainfall intensity recorded during an event i max 15 expressed as mm h 1 equivalent on the magnitude of the stormflow volume and peak streamflow because the weir overflowed during some larger events leading to some uncertainty in peak flow estimates see methods a distinction was made between regular events no overflow and events with weir overflow conditions for up to 25 of the stormflow duration n 5 during the pre haiyan period n 14 post haiyan neither type of stormflow amount was affected by i max 15 not even for very high values of i max 15 fig 7a there was a clear threshold in the relation between q p and i max 15 with the magnitude of the threshold differing between the two periods before haiyan q p increased more with rainfall intensity after i max 15 exceeded 25 mm h 1 whereas during the post haiyan period the response was both more pronounced 3 4 times larger and earlier for i max 15 15 mm h 1 fig 7b however correlations were generally poor fig 7 using the maximum 5 or 30 min rainfall intensities instead of i max 15 gave very similar results not shown 4 4 effect of antecedent soil moisture conditions on runoff response both during the pre and post typhoon period storm runoff was a threshold function of the integrated antecedent soil water content in the upper 60 cm of the soil profile aswc60 plus precipitation p in that both q q and q p increased rapidly beyond a critical value as shown in fig 8 threshold values differed somewhat between the sites where soil water contents were monitored for the upper slope location station s1 a threshold value of 325 mm for aswc60 p was derived versus 250 mm at the mid slope site s2 fig 8a and c versus fig 8b and d the threshold value for the mid slope site fell between the depth integrated 0 60 cm amounts of soil water at saturation 270 mm andfield capacity 230 mm but nearly coincided withsaturated conditions at the upper site 345 mm cf supporting fig 3 correlations after the threshold values were generally stronger for the relation between stormflow amount and aswc60 p pre haiyan values of r2 0 56 0 96 than for the relation between peak flow and aswc60 p r2 0 44 0 54 there were no significant differences in the relations for pre and post haiyan conditions except for a possible tendency towards a slightly higher threshold value at the upper site during the post haiyan period fig 8a and b the strength of the post haiyan correlations was again much greater for q q r2 0 99 at both measuring sites than for q p r2 0 40 0 43 fig 8 4 5 landslide incidence during typhoon haiyan during the passage of typhoon haiyan on 8 november 2013 very strong winds up to 314 km h 1 rabonza et al 2015 caused defoliation of the regenerating vegetation in the central part of the catchment as well as massive damage to tree stems and branches fig 1b the high rainfall 228 mm of rain was captured during the event by the lower rain gauge plus up to 50 mm of wind driven precipitation by the fog gauge at site s1 caused the reactivation of some existing landslides and the creation of several new ones including a major landslide that partly buried the stream gauging station during the latter phase of the haiyan event cf fig 2 no landsliding was observed during the passage of a tropical storm on 28 29 june 2013 which delivered 154 mm of rain landslide surveys conducted before august 2013 and after december 2013 typhoon haiyan indicated an increase in projected impervious landslip surface area from 1080 to 2450 m2 these areas represent 3 4 and 7 7 of the total catchment area respectively implying a 227 increase in potential mca after the passage of typhoon haiyan 4 6 catchment sediment yield although suspended sediment concentrations ssc for manually collected rising stage samples were generally higher than for corresponding falling stage samples during the pre haiyan period ssc values obtained with the single stage samplers were typically intermediate between either type of manually collected sample fig 9 a the slope of the resulting sediment rating curves for pre and post haiyan conditions i e periods i and iii did not differ much between the two periods but ssc values for a given instantaneous streamflow were much enhanced 2 6 times with an overall average streamflow weighted factor of 3 5 after typhoon passage fig 9b combined with the higher stormflows and generally higher daily streamflow at the height of the wet season november january during the post haiyan period table 2 and fig 3b this suggests strongly enhanced suspended sediment transport during periods ii and iii table 3 while the figure derived for period ii is particularly uncertain because of the estimated daily streamflow totals there can be little doubt that overall suspended sediment export from the landslide impacted basper micro catchment during the study year was both substantial at 25 t ha 1 yr 1 and heavily dominated by post haiyan sediment transport 94 of the estimated annual total suspended load table 3 accumulated bedload volumes roughly mirrored corresponding stormflow totals per collection period with the greatest amount of bedload movement being associated with the extreme haiyan event fig 10 and supporting table 2 overall sediment export in the form of bedload amounted to a modest 2 1 t ha 1 yr 1 or 8 of the total sediment load table 3 5 discussion 5 1 tropical grassland runoff response runoff response to rainfall in the basper fire climax grassland catchment was pronounced with an overall pre haiyan stormflow coefficient q q p of 24 versus 47 for post haiyan conditions period iii table 2 such storm runoff coefficients are high to very high even compared to findings for wet lowland tropical locations with an impeding layer i e low hydraulic conductivity k sat at shallow depth which are known to produce more storm runoff than sites having deeper and or more permeable soils elsenbeer 2001 chappell et al 2007 chappell et al 2012 for the former conditions germer et al 2010 and de moraes et al 2006 reported average wet season values of q q p for micro catchments 0 7 ha each under lightly grazed pasture in rondônia and eastern amazonia of 18 and 21 year with average rainfall respectively while gilmour 1977 obtained an overall value of 30 for a partially converted lowland rain forest catchment in northern queensland subject to extreme precipitation inputs during tropical storms and cyclones although the way in which these q q p values were derived differed somewhat between studies the bulk of the stormflow produced at the three locations consisted of overland flow mostly of the saturation excess type sof due to a rapidly decreasing k sat with depth that resulted in the formation of perched water tables and gradually expanding hillside saturation during times of peak rainfall bonell et al 1981 de moraes et al 2006 germer et al 2010 the very low values of surface k sat at the eastern amazonian site of de moraes et al 2006 suggest that infiltration excess overland flow iof was important as well further q q p values at the respective sites increased with catchment wetness status and rainfall input germer et al 2010 de moraes et al 2006 howard et al 2010 as also found in this study supporting table 1 interestingly storm runoff coefficients per rainfall size class at basper supporting table 1 were very similar to corresponding values derived by howard et al 2010 for forested and grassland catchments during the main monsoon season in northern queensland that are generally regarded as some of the most responsive humid tropical catchments described to date bonell 2005 cf chappell et al 2012 comparative published data for tropical fire climax grassland catchments as opposed to man made grasslands are all but non existent although several studies have reported on overland flow production at the plot scale in imperata grasslands in indonesia coster 1938 and the philippines northern luzon jasmin 1976 southern leyte chandler and walter 1998 observed amounts of overland flow were low to modest in the absence of grazing and burning even during years with high rainfall 5 13 of p coster 1938 jasmin 1976 but an extremely high surface runoff fraction as much as 69 of p was reported for a severely overgrazed grassland by chandler and walter 1998 while overland flow in the latter case consisted entirely of iof chandler and walter 1998 occasional sof cannot be excluded in the luzon grassland investigated by jasmin 1976 considering the reportedly high soil infiltration capacity the ecosystems research and development bureau in the philippines monitored streamflow from a lightly grazed micro catchment 1 6 ha under imperata grassland at angat luzon that was burned annually between 1973 and the early 1990 s daño 1995 limsuan 1995 although the original daily flow data have been largely lost monthly and annual precipitation p total runoff q t and storm runoff q q data for the period 1974 1988 a m daño personal communication allowed computation of the long term average q q p value annual stormflow coefficients were high to very high 29 53 with an overall average value of 43 6 i e very similar to the post haiyan value derived for the basper grassland 47 table 2 the angat catchment s suspended sediment yield 5 6 t ha 1 yr 1 was low by philippine standards daño 1995 cf white 1990 possibly implying low to modest surface erosion stormflow made up 94 of q t on average while apparent et approximated by p q t amounted to 1725 mm yr 1 suggesting considerable leakage losses 5 2 runoff response in the basper fire climax grassland a conceptual model with 64 of its total runoff being supplied by stormflow or 38 of p the basper grassland micro catchment ranks as one of the most responsive humid tropical sites described to date as reviewed by bonell 2005 cf fritsch 1993 godsey et al 2004 howard et al 2010 it also appears more responsive than several forested steepland catchments subject to regular typhoon incidence in taiwan average q q p 12 26 cheng et al 2002 chang et al 2013 yet the basper grassland site lacks the typical characteristics that have been identified as key factors leading to such a pronounced response such as the presence of i a wide valley bottom and gentle foot slopes prone to localized sof fritsch 1993 germer et al 2010 ii an impeding layer at very shallow depth 10 20 cm under high rainfall conditions leading to widespread hillslope sof bonell et al 1981 elsenbeer et al 1992 de moraes et al 2006 or iii near surface pipes feeding rapid return flow to foot slopes and headwater gullies elsenbeer and vertessy 2000 cf chappell 2010 what then makes the basper grassland so responsive arguably two aspects set the study catchment apart i its proneness to landsliding fig 2 and ii the low to very low hillside k sat values throughout the soil profile zhang et al 2018a landslide slip faces at basper were effectively impermeable zhang et al 2018a cf merz and mosley 1998 and iof was commonly seen on these during rain events supporting fig 4a however although the 2 6 fold increase in median pre and post haiyan storm runoff coefficients from 8 7 to 22 7 table 2 was roughly proportional to the corresponding increase in the surface area occupied by landslides 2 3 times from 1080 to 2450 m2 the minimum contributing area equivalents of the median pre and post haiyan stormflow fractions 0 28 and 0 72 ha table 2 were up to three times larger than the contributing areas represented by the landslides nevertheless pre and post typhoon landslide surface areas were ca 2 7 times larger than the respective mca equivalents of the lower 25th percentile stormflow values table 2 indicating landslide surfaces were important as a source area for storm runoff during smaller events additional runoff contributions are needed however to explain the observed high stormflow volumes large macropores in the form of former root channels or animal burrows were rarely observed they appeared to be absent in the upper slope profiles dominated by grasses and sedges but were occasionally seen in the top layer beneath the regenerating forest in the riparian zone quiñones 2014 hence rapid subsurface contributions to stormflow if any would appear to be restricted to a narrow riparian zone this leaves hillside iof and or sof as the chief remaining potential storm runoff contributing processes the soils on the upper slopes and ridges site s1 appeared to be saturated for most of the time at depths below 45 cm but were better drained around 30 cm depth although the top layer approached saturation during the peak rainy months supporting fig 3 manually measured groundwater levels taken shortly after major rainfall events were restricted to the subsoil always 70 cm and not seen to rise to the surface to produce sof cf godsey et al 2004 de moraes et al 2006 similarly at the mid slope site s2 soil water contents always remained below saturation at depths greater than 40 60 cm although occasional saturation during times of peak rainfall may have occurred at 20 cm depth and possibly at 10 cm depth supporting fig 3 nevertheless groundwater levels were also low at this site suggesting sof did not occur on the mid slope segment either however sof cannot be excluded for those parts of the riparian zone that exhibited a shallow layer of soil over fractured weathered rock supporting fig 4b quiñones 2014 indeed groundwater levels at piezometer g1 cf fig 2 occasionally rose to within 5 cm below the surface during times of peak rainfall supporting fig 5 finally the fact that both the median surface infiltrability 2 1 0 4 mm h 1 and median near surface k sat 2 85 mm h 1 at 20 50 cm depth beneath grasses and shrubs were lower than or similar to the median 5 min rainfall intensity 3 2 mm h 1 hourly equivalent may be taken as a strong indicator of the importance of iof as a source of storm runoff at basper zhang et al 2018a values of k sat measured at three locations within the regenerating riparian vegetation were not higher than those beneath imperata grass or shrubs on the hillslopes quiñones 2014 hence hillside iof is not likely to completely re infiltrate on the footslope cf woolhiser et al 1996 chappell et al 1998 although values of surface and near surface k sat may have been underestimated by the use of a relatively small infiltrometer 15 cm inner diameter and because of possible borehole smearing respectively see zhang et al 2018a for fuller discussion there is little doubt that hydraulic conductivities for the majority of the soils at basper are low to very low further while direct observations of iof occurrence away from landslip surfaces supporting fig 4a are lacking cf jasmin 1976 chandler and walter 1998 support for the contention that storm and peakflow generation at basper is dominated by iof comes from the fact that i both q q and q p responded in a linear fashion to rainfall intensity beyond threshold values of 10 15 mm h 1 fig 7 and ii stream water ec values were often low to very low during peak flows indicating major dilution with low conductivity water such as rainfall and by implication overland flow fig 3c cf bruijnzeel 1983b elsenbeer et al 1995 5 3 fire climax grassland water use average apparent evapotranspiration et rates for the imperata grassland plus the young regenerating vegetation of the central part of the catchment derived from the catchment water budget table 1 were 4 7 mm d 1 prior to disturbance by typhoon haiyan period i and 3 6 mm d 1 post haiyan period iii the pre disturbance et might seem rather high at first sight compared to overall average values reported for grazed pastures across the tropics typically 3 4 mm d 1 van der molen et al 2006 and a possible effect of unaccounted leakage losses cannot be entirely excluded given the very small size of the study catchment however leakage losses if any are likely to be very small because not only has the stream incised itself down to fresh bedrock in the lower section where the flow is perennial and the gauging weir is located cf supporting fig 1 but also the recession analysis did not show a detectable deviation from linear reservoir theory for the outflow from the groundwater reservoir fig 5 furthermore the fact that flows did not cease during several extended dry periods fig 3b is remarkable in itself for such a small drainage area also it is pertinent to remember that the water use of young vigorous tropical regrowth making up 14 of the vegetation at basper is enhanced relative to that of grassland hölscher et al 1997 giambelluca et al 2000 lastly with the exception of a dry period in october 2013 when the grass started to fade and in may 2014 at which time the grass did not exhibit any signs of moisture stress despite very low topsoil moisture content in the upper part of the catchment soil water content in the basper grassland at 20 cm depth and below were generally high supporting fig 3 zhang et al 2018a mid slope topsoil moisture values remained well above permanent wilting point as well 28 j zhang unpublished data in contrast at other more seasonal sites grassland water use has been reported to be reduced during the dry season wright et al 1992 wolf et al 2011 or even to come to a complete halt as the grass went dormant waterloo et al 1999 however comparably high evaporation rates have been obtained at most tropical pasture sites during the transition from the wet to the dry season when neither moisture nor energy are limiting evaporation 3 7 4 2 mm d 1 wright et al 1992 van der molen et al 2006 wolf et al 2011 waterloo et al 1999 observed a strong relationship between the monthly water use and leaf area index lai of a fire climax grassland under highly seasonal conditions in fiji at basper the extreme winds encountered during passage of typhoon haiyan 85 m s 1 rabonza et al 2015 effectively defoliated the trees and shrubs and flattened the grasses cf fig 1b thereby likely to greatly reduce et initially cf table 1 overall post haiyan et rates are therefore likely to have been dominated initially by soil evaporation after the passage of typhoon haiyan cf scatena et al 2005 with transpiration gradually increasing again as the grasses recovered in january 2014 followed by the gradual refoliation of shrubs and trees in march 2014 the lai of a nearby forest effectively recovered to pre disturbance values after 3 months zhang et al 2018b the relative magnitude of the average apparent et values derived for periods ii and iii although somewhat uncertain for period ii in particular do reflect this expected trend table 1 5 4 landsliding and catchment sediment yield at 27 t ha 1 of which 25 t ha 1 yr 1 was carried in suspension and 2 t ha 1 yr 1 was transported as bedload table 3 the estimated sediment yield of the basper grassland catchment during the study year was considerable for example the long term average sediment yield for the annually burned grassland at angat in luzon referred to earlier daño 1995 was 5 3 t ha 1 yr 1 although as responsive hydrologically as the basper grassland a m daño unpublished data slope gradients at angat were more modest 30 40 and mass wastage was unimportant however sediment yields of nearly 40 t ha 1 yr 1 were measured elsewhere in luzon magat area for overgrazed headwater catchments subject to regular fire and widespread mass wasting white 1996 by contrast baseline sediment yields for small forested headwater catchments in high rainfall 3000 mm yr 1 areas in south and south east asia without major landsliding nor subject to tropical cyclones are typically less than 4 t ha 1 yr 1 bruijnzeel 1983a malmer 1990 douglas et al 1992 gafur et al 2003 the extreme event of 8 november 2013 passage of typhoon haiyan was decisive in several ways firstly an estimated 25 t of sediment 7 8 t ha 1 were exported during this particular event alone which is equivalent to 29 of the annual total further before haiyan period i 158 days only 0 55 t ha 1 of suspended sediment were transported per 100 mm of stormflow compared to an estimated 3 4 and 2 0 t ha 1 per 100 mm of stormflow during post haiyan periods ii 15 days and iii 192 days respectively table 3 measured suspended sediment transport during period iii 15 t ha 1 was 3 5 times higher than predicted for the same amount of streamflow using the pre haiyan sediment rating curve fig 9b indicating greatly increased sediment availability after haiyan presumably due to the landsliding that occurred during the event cf fig 2 interestingly a previous large rainfall event 28 29 june 2013 that delivered 154 mm of rain but did not generate new landslides caused only 1 5 t of sediment to be transported in suspension 0 5 t ha 1 assuming the pre haiyan sediment rating curve to represent conditions without major sediment contributions by mass wasting and combining it with measured post disturbance streamflow gave a suspended sediment yield of ca 7 t ha 1 yr 1 for the june 2013 may 2014 study period being similar to the 5 3 t ha 1 yr 1 for the angat grassland micro catchment the situation at basper is conducive to landslide generation due to a combination of steep upper slopes a less than cohesive subsoil becoming sandier and stonier with depth quiñones 2014 zhang et al 2018a absence of a deep stabilizing root system cf o loughlin 1984 sidle et al 2006 and high to very high rainfall rabonza et al 2015 as such it is of interest to examine why the haiyan event generated so much sediment while the june 2013 event did not although the two events differed in terms of their total rainfall 258 mm versus 154 mm rainfall amounts in both cases were well above the 70 mm rainfall threshold value identified by nolasco javier et al 2015 as being required for shallow landslides to occur in non forested terrain in the baguio area luzon similarly estimated kinetic energies associated with the two storms were well above the critical threshold value of 2000 j m 2 proposed by lin and chen 2012 for landslide initiation in forested taiwanese steepland although the value associated with typhoon haiyan ca 5500 j m 2 was nearly twice that for the june 28 29 event ca 2800 j m 2 further actual pre storm water storage in the top 60 cm of soil was almost identical on both days as well as during the seven days preceding the respective events cf supporting fig 3 while foot slope groundwater levels measured at piezometer g1 reached a higher value during the june event than during typhoon haiyan supporting fig 5 despite the higher rainfall associated with the latter however a major difference between the two situations relates to the fact that the haiyan event had been preceded by a period of low rainfall from mid august 2013 onwards until rainfall increased again around mid october fig 3 this dry period caused the development of cracks that may have facilitated rapid transfer of the heavier rainfall in late october and early november to deeper layers thereby saturating the soil rock interface to critical levels during the haiyan event with its maximum 60 min intensity of 81 mm cf supporting fig 3 whereas normally much if not most of the rainfall would have run off the hillslope surface due to the very low hydraulic conductivity of the soils at basper the close correlation between landslide incidence and extreme rainfall during typhoon passage observed in the philippines and elsewhere in the region nolasco javier et al 2015 nolasco javier and kumar 2018 lin et al 2008 chen et al 2015 does not bode well for a future in which tropical storms and cyclones are expected to become more forceful due to continued oceanic warming balaguru et al 2016 apart from the corresponding increase in stream sediment load areas prone to landsliding like the basper grassland can be expected to become more hydrologically responsive in the future cf chiang and chang 2011 walsh et al 2013 while the progressive loss of the overburden may cause a gradual loss of soil water storage potential and eventually lead to diminished baseflows rawat et al 2015 cf bruijnzeel 1989 6 conclusions rainfall streamflow and sediment yield were determined for the basper fire climax grassland micro catchment 3 2 ha near tacloban leyte island philippines between 3 june 2013 and 2 june 2014 the catchment had not been burned or grazed for ten years prior to the start of the measurements and the central portion 14 of the catchment surrounding the perennial stream was covered by low but dense regenerating vegetation on 8 november 2013 the area was struck by typhoon haiyan one of the largest events on record runoff response to rainfall was very pronounced with weighted average storm runoff coefficients q q p being 24 and 47 for pre and post haiyan conditions respectively the latter value ranks as one of the highest reported in the literature on humid tropical runoff responses overland flow contributions on landslide slip surfaces occupying 3 4 and 7 7 of the catchment before and after haiyan were important as a source of storm runoff but by far not sufficient to explain the high q q values that were observed macropores were observed only occasionally in the soils beneath the regenerating riparian zone forest suggesting rapid lateral subsurface stormflow was probably limited to a very small part of the catchment at best although near surface soil moisture was high during the wettest months perched groundwater levels were not observed to reach the surface except occasionally near the stream channel hence saturation excess overland flow is likely not a major contributor of storm runoff either rather in view of the low to very low hydraulic conductivities of the soils underlying the imperata grass and shrub as well as the regenerating riparian vegetation infiltration excess overland flow is considered the dominant runoff generating mechanism at basper pre typhoon water use by the combined imperata grassland and young regenerating vegetation as derived from the catchment water budget was rather high 4 7 mm d 1 possibly reflecting a combination of vigorously regenerating riparian vegetation a generally high soil moisture content and breezy conditions post typhoon evapotranspiration of the heavily disturbed vegetation was initially much reduced but recovered somewhat towards the end of the study period 3 6 mm d 1 the annual sediment production was high 27 t ha 1 and greatly exceeded values previously reported for fire climax grasslands in the region that were not subject to widespread mass wasting post typhoon sediment transport over a period of six months was estimated to be 3 5 times higher than would have been the case without the massive landsliding that occurred during the haiyan event indicating increased and possibly prolonged sediment availability in view of continued oceanic warming and the gradual intensification of extreme rainfall events in the region mass wasting and sediment yields are expected to increase in the future acknowledgements financial support for this work from the china scholarship council to jun zhang vu university amsterdam and the australian council for international agricultural research aciar grant no asem 2010 050 to professor j herbohn is gratefully acknowledged we thank the leaders of barangay basper for their permission to work in the basper catchment mr josé june bagay for assistance in the field miss ofelia maranguit and miss jertz escala for help with the laboratory analyses under the supervision of professor angela ferraren visayas state university vsu professor alfredo lagmay and miss maricar rabonza of the university of the philippines kindly provided the dtm files that enabled the preparation of the catchment map we are especially grateful to dr antonio daño ecosystems research and development bureau laguna for sharing the unpublished angat grassland data and marc vis university of zurich for help with the hbv model dr nestor gregorio aciar project and university of the sunshine coast usc and professor arturo pasa vsu are thanked for overall facilitation of the project and professor john herbohn usc for his continuous support the manuscript benefited from the constructive comments of three anonymous reviewers which is gratefully acknowledged appendix a supplementary material supplementary data associated with this article can be found in the online version at https doi org 10 1016 j jhydrol 2018 08 016 appendix a supplementary material supplementary fig s1 view of the compound sharp crested v notch weir used for measuring streamflow at the outlet of the basper micro catchment inset view of rising stage sample bottle rack and water level and electrical conductivity sensors housed in the two blue pipes and protected by metal caps photographs by j zhang supplementary fig s2 relations between the 5 min observed q obs and median simulated q sim streamflow for the 25 best parameter sets for the a pre and b post haiyan periods using the hbv light model supplementary fig s3 time series of hourly rainfall intensity a and volumetric soil water content at different depths at the basper grassland upper slope site b and the basper mid slope site c estimates of porosity in the ap ab and bw horizons are indicated by horizontal dashed lines supplementary fig s4 infiltration excess overland flow was observed frequently on landslip faces during rain b seepage from the lower left bank soil profile where soil cover was shallow and rock material fractured photographs by j zhang supplementary fig s5 depth to shallow groundwater table cm at piezometer site g1 lower left bank during the study year hourly values hourly rainfall amounts added for comparison supplementary data 1 
7023,the artificial intelligence ai models i e artificial neural network ann and least square support vector machine lssvm were used to statistically downscale and project rainfall data from cmip5 general circulation models gcms for tabriz and ardabil synoptic stations in north west iran since one of the important issues in statistical downscaling of gcms is to select dominant variables among plenty of large scale climate data predictors a predictors screening framework which integrates wavelet entropy we and self organizing map som was developed in this study to statistically downscale mean monthly rainfall values the advantage of proposed method is to reduce the noise and dimensionality of data as well as selecting reliable inputs of downscaling model for future rainfall projection to this end five gcms i e can esm2 bnu esm csiro access1 gfdl esm2g and inm cm4 were employed ann lssvm and multiple linear regression mlr models were trained to capture relationship between the predictors and the stations observed rainfall values predictand then ensemble techniques were applied on the outputs of the downscaling models the calibration validation and projection of the proposed downscaling models were performed over the periods jan 1951 to dec 1991 jan 1992 to dec 2005 and jan 2017 to dec 2100 respectively the projection of rainfall for near and distant future i e 2017 2050 and 2050 2100 by the proposed multi gcm ensemble framework yielded to rainfall alteration pattern 40 41 and 35 42 decrease at tabriz station and 6 12 and 5 13 increase at ardabil station under rcps 4 5 and 8 5 respectively keywords general circulation models rainfall projection wavelet entropy we self organizing map som artificial neural networks ann least square support vector machine lssvm nomenclature acronym definition ai the artificial intelligence anfis adaptive network based fuzzy inference systems ann artificial neural network bnu beijing normal university china cc correlation coefficient cccma canadian centre for climate modelling and analysis canada cmip5 fifth assessment report of ipcc csiro bom commonwealth scientific and industrial research organization bureau of meteorology australia dwt discrete wavelet transform ffnn feed forward neural network gcm general circulation model gfdl geophysical fluid dynamics laboratory usa gp genetic programming hfls surface upward latent heat flux hur relative humidity hus specific humidity idw inverse distance weighting inm institute of numerical mathematics russia lm levenberg marquardt lssvm least square support vector machine mlr multiple linear regression mi mutual information pca principal component analysis pdf probability distribution function psl air pressure at sea level rbf radial basis function rcp representative concentration pathway sc silhouette coefficient som self organizing map tansig tangent sigmoid tas air temperature ua eastward wind uas eastward near surface wind va northward wind vas northward near surface wind we wavelet entropy zg geo potential height 1 introduction the skill of general circulation models gcms in reproducing hydrologic parameters such as precipitation is of critical importance although gcms are the tools that provide reliable atmospheric data coarse spatial resolution of gcms may lead to poor outcomes when applied as inputs to the local scale hydrologic models downscaling is an approach to obtain local scale weather data from large scale gcms there are two major techniques to downscale gcm based climate data statistical and dynamical methods dynamical downscaling is the method to derive smaller scale climatic information over a bounded area via high resolution regionalmodel driven from gcms statistical downscaling encompasses statistically relating large scale climate features predictors to local climate data predictand as a black box model wilby and wigley 1997 in spite of high resolution outputs of dynamical downscaling method its application is limited due to intensive computational procedures need to huge volume of data and a high level of expertise to implement and interpret results trzaska and schnarr 2014 instead statistical downscaling has been broadly used in climate change studies because of the convenience in implementing and interpreting of the results e g see sailor and li 1999 harpham and wilby 2005 chen and adams 2006 beecham et al 2014 the main concept of statistical downscaling is to make a relationship between predictors and predictand by means of a statistical method such as i linear regression models e g statistical downscaling model sdsm wilby et al 2002 ii nonlinear regression models of artificial intelligence ai e g artificial neural network ann zorita and von storch 1999 support vector machine svm tripathi et al 2006 relevance vector machines rvm ghosh and mujumdar 2008 gene expression programming gep sachindra and perera 2016 iii weather generators e g long ashton research station weather generator lars wg racsko et al 1991 trzaska and schnarr 2014 prepared a thorough review of downscaling methods for climate change projections which can be referred for more detail about downscaling methods the capability of anns in simulating nonlinear and time varying characteristics of atmospheric variables at different scales and their potential in extracting complex patterns as well as relations between predictors and predictand has led to several successful applications of ann for downscaling purpose in technical literature e g see wilby and wigley 1997 dibike and coulibaly 2006 chadwick et al 2011 okkan and kirdemir 2016 moreover support vector machines svms and least squares support vector machines lssvms as the other nonlinear downscaling methods vapnik 1995 showed remarkable successes in statistical downscaling of climatic parameters e g tripathi et al 2006 chen et al 2010 sachindra et al 2013 focus on consequences of studies with ai based downscaling methods e g ann shows some contradictory results while some state the superiority some others denote the drawback and inefficiency of ann over the multiple linear regression mlr based models e g dibike and coulibaly 2006 khan et al 2006 abdellatif et al 2013 these inconsistent results may depend on the quality and quantity of the applied data huge data redundant information and the involved noise in the data set are the challenging issues about ai based modeling the noise involved in the data set can be magnified nonlinearly over the simulation time while using nonlinear models e g ann and svm models in this case application of input screening as a pre processing scheme can largely enhance the efficiency of the ai based downscaling models in this regard general approaches such as correlation analysis devak and dhanya 2016 principal component analysis pca ahmadi and han 2013 fuzzy and gamma test ahmadi et al 2015 have been employed for input selection of statistical downscaling models the huge data set in downscaling issue is coming from several predictors at multiple grid points over long time intervals and several gcms which are available for the study region although various research centers around the globe prepare gcm based climate data generally they do not offer the same values for a specific variable at a particular region the reason relies on different parameterization schemes variation in boundary layers and different resolutions relying on the output from a single model and finally abrupt spatial variability in climate thus proper selection of gcm and grid points as well as predictors are of prime importance in downscaling approach for a specific region lee and kim in press hence a robust method of dominant input selection among various gcms several grid points and predictors is needed which current study tries to address this important issue one of the effective methods to decrease the dimensionality of input space is clustering and selecting representative member from each cluster bowden et al 2005 although several studies have already used different clustering based methods for dominant input selection of ai based models in hydrological applications e g may et al 2008 markus et al 2010 nourani and parhizkar 2013 li et al 2015 nourani et al 2017 the implementation of such a clustering based input screening is indeed scarce in statistical downscaling of gcms therefore current study proposes a novel predictor screening methodology by coupling self organizing map som as a clustering approach with wavelet entropies wes of predictors to select dominant predictors since climatologic data sets involve non stationary time series entropy as a measure of information content shannon 1948 could be preferred to statistical moments i e mean variance skewness etc in order to represent whole time series in the clustering procedure several studies have already confirmed appropriate performance of entropy based nonlinear metric over linear based statistical moments e g hlinka et al 2014 vu et al 2018 on the other hand underlying multi resolution seasonalities of the climatic process are drawn out by wavelet transform via extracting various features of time series at different time scales johnson et al 2011 nourani et al 2014 rashid et al 2015 the motivation objectives of current study is to develop proper statistical downscaling model using two important approaches first a novel predictor screening model and second ensemble of some models to downscale properly these objectives were achieved by the following steps i developing a robust we som predictor screening methodology ii developing downscaling models by three approaches i e ann lssvm and mlr iii enhancing the downscaling results by ensemble downscaling models to project future rainfall since rainfall is the most important component of the hydrologic cycle and on the other hand statistical downscaling steps including data gathering pre processing downscaling and projection are time consuming processes and require challenges on big data rainfall was considered as the only predictand in this study similar to some other studies which focused on only one variable including chaudhuri and srivastava 2017 nogueira and barros 2015 and chiew et al 2010 2 study area and data 2 1 study area this study deals with two stations namely tabriz latitude 38 07 n longitude 46 14 e and elevation 1364 m and ardabil latitude 38 22 n longitude 48 30 e and elevation 1332 m in the north west of iran as shown in fig 1 these two stations are approximately located at the same latitude but different longitudes the average annual rainfall in the tabriz and ardabil stations are 280 mm and 318 mm respectively both stations are located in cold weather conditions with regular seasons however ardabil has cold semi humid climate and more precipitation because of the proximity to the caspian sea while tabriz generally has cold semi arid climate the dominant wind blows from the east to the west in both stations 2 2 data set the monthly observed rainfall data for both stations were obtained from the iran meteorological office for the period 1951 2005 the mean monthly gcm predictors in the same time interval were used in this study as listed in table 1 the gcm data from the fifth assessment report of ipcc i e cmip5 gcms under the representative concentration pathways i e rcp4 5 and rcp8 5 for future simulation were retrieved from the ipcc data distribution center http cera www dkrz de during 1951 2100 for downscaling purpose the predictors were extracted from can esm2 bnu esm csiro access1 gfdl esm2g and inm cm4 gcms provided by research centers of canada china australia usa and russia respectively table 1 since several studies accounted beneficial aspects of applying data from several grid points around the study location frost et al 2011 guo et al 2012 beecham et al 2014 predictors from four grid points around each study station considered in the modeling fig 1 therefore the total number of grid points which cover two stations is 6 for each gcm or in other words is 30 for all of the five gcms see fig 1 in this way the number of predictors in surface and various layers of atmosphere in bnu esm and inm cm4 gcms is 95 in can esm2 gcm is 120 in csiro access1 and in gfdl esm2g gcms is 85 leading to totally 1920 variables as the potential input candidates of the downscaling models for each station if trial and error procedure is applied to assess the best input set 2 1920 1 2 1240 1 input combinations should be examined which is an exhausting process and not feasible to select the dominant inputs although linear correlation coefficient cc may be used as a criterion to select dominant inputs which used in this study as comparison purpose implementation of a nonlinear input selection method is essential for a nonlinear process as criticized by nourani et al 2015 in this regard a nonlinear input screening method is developed and applied through the current study 3 proposed methodology the proposed statistical downscaling methodology contains three steps as shown by fig 2 the first step is the dominant predictor selection procedure second step is the ai based downscaling model and finding the superior model by ensemble techniques and finally third step is the projection of future rainfall at tabriz and ardabil synoptic stations under rcps 4 5 and 8 5 3 1 first step input screening in order to cover the strengths and weaknesses of various gcms and handle uncertainty of different gcms five gcms which showed good results for the region in some previous studies e g cai et al 2009 namely can esm2 bnu esm csiro access1 gfdl esm2g and inm cm4 and their ensemble were used in this study due to non stationary inherent of climatic phenomena temporal features as well as seasonal attributes are encompassed in time series which can be detected by wavelet transform thereupon discrete wavelet transform dwt is applied to decompose time series of predictors into multi resolution sub series in this way original time series are broken up into approximation and detailed sub series to represent general trend and different levels of periodicity involved in the time series since the wavelet generated sub series manifold the data it is necessary to use the abstract form of each sub series by maintaining the information contained therein in this regard it is suggested to compute and use entropy of each sub series as the substitute entropy shows information content or the degree of order disorder of each wt decomposed sub series as we in this way each sub series is substituted by only one value i e we and so the dimensionality of the data set is greatly reduced for a monthly time series including many samples first wavelet transform at level l decomposes one predictor time series to l 1 sub series one approximation and l detail sub series then l 1 wes are computed to represent whole time series with only l 1 values each representing a specific feature scale of original time series generally all of the features are not informative equally some may include noise some others may have correlation and some with no remarkable relevancy to the output variable therefore a screening process is necessary to select the impressive features as inputs for downscaling models som as a clustering method is used here to screen the features basically the som is an unsupervised ann tool that can capture linear and non linear statistical relations in complex high dimensional dataset and illustrate them via a comprehensible geometric relation map application of wes instead of the whole decomposed sub series in the clustering procedure can lead to an optimized som input layer so can improve the clustering performance by reducing the dimensionality of the data set the som based clustering is implemented over the computed wes with two approaches i single gcm approach in which wes of each five gcms are fed into som individually and five different results for each gcm are obtained ii multi gcm ensemble approach in which the wes obtained from the whole predictors of five gcms are imposed to the som simultaneously due to the complexity of predictors time series poor linear correlation between predictors and predictand may be detected in spite of existing a strong non linear relation thereupon in order to detect the non linear relationships between predictors and predictand at the clusters mutual information mi measure is used to select representatives of each cluster finally the predictors which pass the screening procedure are entered to the second step to downscale gcm rainfall via ann and lssvm models 3 2 second step downscaling models in the second step the ai based downscaling models are developed in this way the single and multi gcm screened predictors are used to train ann and lssvm downscaling models subsequently in order to achieve the strengths of each downscaling model the ensemble of ann lssvm and mlr downscaling models are stablished in fact ensemble modeling is the process of running two or more related but different analytical models i e ann lssvm and mlr here to combine the outputs of various analytical models into a single output with improved accuracy of predictive modeling the final ensemble model is then used to project future rainfall in the third step it should be mentioned that since application of gcm derived data in downscaling process may lead to systematic biases between the downscaled results and observations statistical amendment of gcm data is often essential wilby et al 2004 one of the common procedures to remove the systematic biases in mean and variance is standardization tripathi et al 2006 chen et al 2010 according to sachindra et al 2014 standardization of predictors i e subtracting the mean from data and dividing by the standard deviation scales down the predictor data to a single uniform scale and removes the units of the variables 3 3 third step rainfall projection for future finally step three is performed under rcps 4 5 and 8 5 to simulate future monthly rainfall of tabriz and ardabil synoptic stations for near and distant future in the periods of 2017 2050 and 2051 2100 it is noted that according to various plausible viewpoints about future anthropogenic actions due to different rates of growth in population economic energy and socioeconomic development and their impacts on greenhouse gas emissions each rcp demonstrates distinct radiative forcing pathways by 2100 in this way rcps 4 5 and 8 5 are related to intermediate and high emission scenarios respectively the sections below briefly explain required mathematical tools for the proposed methodology 4 materials 4 1 wavelet entropy the wavelet makes localization of a signal in time and scale domains by comparing the relationship between wavelet function and a signal the discrete form of wt is used and screened as eq 1 mallat 1998 1 g m n t 1 a 0 m g t n b 0 a 0 m a 0 m where is the complex conjugate and g t named mother wavelet m and n denote to the wavelet dilation and translation respectively a0 is a specified fined dilation step greater than 1 and b0 is the location parameter which must be greater than zero the most common and simplest choice for parameters are a0 2 and b0 1 this power of two logarithmic scaling of the dilation and translation is known as the dyadic grid arrangement the dyadic wavelet can be written in more compact notation as mallat 1998 2 g m n t 2 m 2 g 2 m t n for a discrete time series xi the dyadic wt becomes mallat 1998 3 t m n 2 m 2 i 0 n 1 g 2 m i n x i where tm n corresponds to wavelet coefficient of the discrete wavelet at scale a 2 m and location b 2mn eq 3 considers a finite time series xi i 0 1 2 n 1 and n 2q this gives the ranges of m and n as 0 n 2q m 1 and 1 m q respectively entropy is a statistical measure of the randomness or uncertainty in terms of probability distribution presented by shannon 1948 so entropy of each wavelet decomposed sub series tm n which takes values tm n 1 tm n 2 tm n n with probabilities p tm n 1 p tm n 2 p tm n n respectively is defined as shannon 1948 4 e t m n i 1 n s p t m n i l o g p t m n i where e t m n is entropy of tm n also referred to entropy function and ns is the number of intervals or bins to form the histogram and thereinafter probability distribution function pdf entropy can statistically represent the rate of uniformity for a single variable however it is not able to discover the uniformity and relations between two variables thus in order to overcome this shortcoming joint entropy between two variables is defined as gao et al 2008 5 e x y i 1 n s j 1 m s p x i y i l o g p x i y i where variables x and y in this study are predictors x and predictand y p x i y i is the joint probability of xi and yi with bins number of ns and ms respectively mi calculates the mutualdependence between two variables as follow equation yang et al 2000 6 m i x y e x e y e x y while cc can detect linear relation between two variables mi has the capability to detect non linear dependency of variables cover and thomas 1991 4 2 self organizing map som som clusters homogeneous data with similar pattern in a cluster and reduce the dimensionality of data the som structure contains components called nodes with a common arrangement of two dimensional hexagonal grid a weight vector of the same dimension as the input data vectors is assigned to each node in order to detect node with the closest smallest distance metric weight vector w to the n dimensional input vector x euclidean distance is used kohonen 1997 7 x w i 1 n x i w i 2 the weight with the closest match to the input data is the winner node called best matching unit bmu in order to further decrease the distance between the weights and bmu learning continues by changing the weights at each training iteration t kohonen 1997 8 w t 1 w t α t h lm x w t where α corresponds to the learning rate ranging in 0 1 h lm denotes the neighborhood function the most commonly used neighborhood function is the gaussian function kohonen 1997 9 h lm e x p l m 2 2 σ t 2 where l and m correspond to bmu and the position of neighboring nodes at output and σ is the width of the topological neighborhood at iteration t 4 3 artificial neural network ann ann learns according to input and output data while information flows through network the underlying pattern in data affect the structure of ann and leads to generation of the appropriate network according to data the simplest ann includes three layers input hidden and output layers in order to be brief readers are referred to study relevant books in ann field such as haykin 1994 4 4 least square support vector machine lssvm suykens and vandewalle 1999 proposed lssvm which was first originated from the svm method alike the svm lssvm is also considered as a strong technique to assess non linear classification function estimation and density estimation problems the non linear function of the lssvm method can be shown as suykens and vandewalle 1999 10 f x w t φ x u where f indicates the relationship between the predictors and predictand w is the m dimensional weight vector ϕ is the mapping function that maps x into the m dimensional feature vector and u is the bias term considering the complexity of function and fitting error the regression problem can be given according to the structural minimization principle as suykens and vandewalle 1999 11 min j w e 1 2 w t w γ 2 i 1 m e i 2 which has the following constraints 12 y i w t ϕ x i u e i i 1 2 m where γ is the margin parameter and e i is the slack variable for x i in order to solve the optimization problems given in eq 11 the objective function can be obtained by using the lagrange multipliers of αi and the optimal condition can be obtained by taking the partial derivatives from objective function of unconstraint problem with respect to parameters which yields the linear regression of suykens and vandewalle 1999 13 0 y t y z z t i γ u α 0 1 where y y 1 y ym z ϕ x 1 t y i ϕ x m t y m i 1 1 α α 1 α 1 by defining kernel function k x x i ϕ x t ϕ x i i 1 m the lssvm regression becomes 14 f x i 1 m α i k x x i u a commonly used kernel function in regression problems is the radial basis function rbf which represents the normal probability distribution the majority of stochastic hydro climatologic processes follow the normal probability distribution or may have the potency of altering to a normal distribution the rbf kernel is used as the lssvm s main kernel functions in this study with kernel width parameter σ as follow suykens and vandewalle 1999 15 k x x i exp x x i 2 σ 2 2 4 5 evaluation criteria 4 5 1 clustering evaluation criterion in order to measure the validity of som based clustering silhouette coefficient sc is applied to validation consistency within clusters for each datum i two kinds of dissimilarities are defined first the average dissimilarity of i with all other data in the same cluster a i second the average dissimilarity of point i to each of other clusters other than own cluster of i where the minimum value is b i silhouette equation is then computed as amorim and hennig 2015 16 s i b i a i max a i b i s i varies between 1 1 closer to 1 correct low or negative incorrect placement in cluster respectively and near zero means the datum is located on the border of two clusters in order to assess the overall clustering configuration the average s i of the whole data on the all clusters is calculated which shows how appropriately the data have been clustered hsu and li 2010 17 sc 1 n i 1 n s i where n is the total number of arrays in the data space large values of sc denote to appropriate clustering outcome 4 5 2 model evaluation criteria the comparison between calibrated and observed values is the simplest form of model validation several statistical measures are available to evaluate the association between the calibrated and the observed data cc as eq 18 is the most common method evaluates the linear relevancy between two variables ranging between 1 to 1 where values greater and less than zero shows a positive and negative relation respectively while zero states no association between the two variables 18 cc n o c o c n o 2 o 2 n c 2 o 2 moreover in order to evaluate the precision of the prediction in downscaling model the determination coefficient dc is used in this study see eq 19 it measures how well the observed results based on their proportion of the total variation are replicated by the proposed model and ranges from to 1 the greater dc denotes to the better agreement between the observed and calculated values root mean square error rmse is another measure of the accuracy and assesses how effectively the downscaling model predicts rainfall see eq 20 19 dc 1 o c 2 o o 2 20 rmse o c 2 n where n o c and o are the observation data number observed data calculated values and the mean of the observed data respectively it is necessary to mention that legates and mccabe 1999 already stated that any hydro climatological model can be sufficiently evaluate by only dc and rmse criteria however the indicator cc was also used to assess the linear relation between observed and downscaled data in this study 5 results based on the proposed methodology the results are presented in the following sub sections 5 1 results of first step input screening the proposed predictor screening methodology was applied to single and multi gcm predictors for each gcm 15 atmospheric predictors in surface and various levels of atmosphere at four grid points around the synoptic station were considered to determine the dominant predictors through the first step dwt was applied at decomposition level 7 to decompose time series of predictors into one approximation and 7 detail sub series the proper selection of the mother wavelet and decomposition level is the important issue while using dwt based on nourani et al 2014 the structure of the daubechies mother wavelet with four vanishing moments db4 is similar to most of the hydro climatologic time series hence decomposition procedure was established by db4 mother wavelet with regard to the selection of the optimum decomposing level owing to the fact that the aim of the study is to downscale rainfall for future and there is a need to know about different frequencies of the rainfall in the distant horizon the decomposition level 7 was selected as the appropriate decomposition level to capture the large range of the frequencies from the approximately monthly to the seasonal up to the about five year i e 27 months frequencies the entropy of each sub series was calculated so each time series with 8 sub series obtained through was compacted to a vector with 8 values in this way each predictor was defined by an 8 component vector such a vector can represent the important features of an individual time series since the wavelet based representation of the predictor differs according to the frequency state of the process we values of the sub series will also be different in fact the high values of the wes refer to the subseries with high stochastic fluctuations and the low values of the wes are expected for the ordered sub series with the deterministic and smooth fluctuations henceforth the som clustering approach was used to group the feature vectors wes of predictors into the several clusters two important issues should be respected in clustering procedure first determination of the optimum cluster number considering the ai based downscaling model second the use of an appropriate method to select the representatives from all clusters in the first issue of clustering to determine the optimum cluster number the sc values were calculated and plotted against the number of clusters varying between 2 2 t o 10 2 fig 3 the squared numbers of clusters in fig 3 denote the two dimensional structure of som network in this study it is obvious that increasing of cluster number leads to more homogeneous clusters however such increment may not be wise in high dimensional data like current study where the dominant feature from each cluster will be used by ann and lssvm since numerus inputs to ai models can decrease the efficiency of model logical number of inputs obtained from clusters should be considered to do so the mean value of sc for each number of cluster was determined according to fig 3 the sc values increase very smoothly by growing the number of clusters after a considerable drop around 10 clusters since the growth of the sc around 9 to 25 clusters was smooth in comparison to the gradient of sc after and before the specified range depicted by vertical arrows in fig 3 the start of smooth gradient i e 9 cluster was selected as the optimum cluster number in the single and multi gcm cases as the second issue of clustering the dominant features of the clusters were selected based on the maximum mi computed between the predictors in a cluster and the predictand thus a predictor with the most non linear relevancy to the observed rainfall data was designated as the agent of that cluster the dominant predictors selected from the clusters in both single and multi gcm cases are shown in table 2 where most of the representative predictors are related to humidity wind velocity geopotential height and heat flux of the atmosphere accordingly some previous studies more or less pointed out the importance of such atmospheric predictors for rainfall downscaling wilby et al 2004 frost et al 2011 rashid et al 2015 the outcomes of step one were the dominant features of the clusters for single and multi gcm cases which are displayed on different grid points of various gcms in table 2 5 2 results of second step downscaling models in the second step two non linear data driven models i e ann and lssvm as the commonly used ai based methods in the hydro climatology modeling accompanied with linear mlr model to downscale predictand the dominant predictors that passed through the som screening procedure in the first step were standardized over the period 1951 2005 the first 75 percent of the dominant predictors and observed rainfall data were used for the training of downscaling models and the remaining 25 percent used for the validating purpose in ai based and mlr models hence calibration and validation periods were set to 1951 1991 and 1992 2006 periods respectively the three layer feed forward neural network ffnn with the back propagation of errors levenberg marquardt lm optimization algorithm and tangent sigmoid tansig activation function represented nonlinear functional mapping between predictors and predictand in this study in any ffnn based modeling appropriate selection of neurons number in the hidden layers i e second layer and the training iteration epoch number can improve model efficiency in both the calibration and validation steps the optimum architecture i e hidden neuron and epoch number of ann downscaling model in this study was determined via trial error method in order to avoid overfitting problem due to numerous input data and catch the optimum results on ann downscaling model the input layer which supposed to include big data of gcms were considerably decreased in data size by the proposed we som screening methodology i e first step so that only dominant predictors obtained from first step i e only 8 vectors of 600 components were used in ann downscaling model as the input layer data which is not considered as big data anymore in this way the optimum number of hidden neurons and epoch for multi gcm ann downscaling model were reported 6 250 and 4 470 for tabriz and ardabil stations respectively the results of single and multi gcm models are tabulated in tables 3 and 4 for tabriz and ardabil stations respectively the models which displayed the maximum dc in the validation step with multi gcm inputs were selected as the efficient ann models tables 3 and 4 moreover the lssvm model with rbf kernel function mapped the nonlinear predictor predictand relationship in this study the downscaling results of lssvm model in terms of evaluating criteria also confirmed the results of ann model so the multi gcm model performed more effective than models with single gcm inputs tables 3 and 4 therefore in both ann and lssvm downscaling models multi gcm approach showed more reliable performance while the ann showed slightly better performance than lssvm model the performance of a newly proposed downscaling model is usually assessed with regard to some classic models such as sdsm sdsm as a commonly used statistical downscaling model uses the mlr method to establish a statistical relationship between predictors and predictand so mlr model was applied in this study as well for the comparison purpose in order to assess the performance of the ai based models the mlr model was developed based on the predictors which i did not enter screening method and solely selected according maximum cc with predictand and ii multi gcm predictors of screening method see tables 3 and 4 furthermore in order to compare the proposed method with classic screening techniques the spatial correlation and pca methods were applied on 1920 gcm predictors in the spatial correlation method the correlation among all predictors and predictand were computed and values above 0 4 were selected the selected predictors were then fed into statistical models see tables 3 and 4 also for ardabil station pca method was applied on all predictors i e totally 1920 time series to detect outliers of the data projections of the data points onto the new axis led to determination of the 93 principal components owing to the fact that each component is the linear combination of 1920 time series selection of important predictors from each component can be another challenge it seems for input dimension reduction the predictor selection must be done according to maximum variance of each component or iterative trial error procedure however application of pca apart from being time consuming may deteriorate the performance of data based models such as ann and svm due to less dimension reduction and yielding numerous inputs with redundant information here 93 timeseries in this regard some pros and cons of the developed we som screening method with regards to classic methods i e spatial correlation and pca can be listed as below i both correlation and pca methods are linear methods since they have been developed based on variance but developed we som methodology includes nonlinear entropy based core ii application of correlation and pca methods may not lead to dimension reduction properly e g in case of pca 1920 variables led to 93 variables which require another screening method to lessen the potential inputs while dimension reduction via we som methodology led to select 9 dominant predictors iii application of wavelet is the other advantage of the proposed methodology which can handle non stationary of the series and determine prevailing periods and seasonalities of the process iv som clustering tool classified 1920 predictors of 8 component vectors while pca must find relation among 1920 predictors each with about 600 components in order to improve downscaling result the ensemble of the best ai and mlr models were developed three ensemble techniques were applied i the simple averaging method ii the weighted averaging method weights were defined according to dc validation values and iii the neural ensemble model the first two methods linearly combine outcomes of three ann lssvm and mlr models while in the 3rd non linear ensemble method ffnn was used as a kernel in the ensemble model due to more applicability although other ai based models e g lssvm anfis and gp see the acronym table also could be used as the ensemble kernel the neural ensemble model was trained using the outputs of three downscaling models i e ann lssvm and mlr as the inputs of this novel ensemble method alike ann model neural ensemble model was performed based on three layer ffnn model with back propagation of errors optimization algorithm of the lm and tansig activation function the first layer of neural ensemble model includes precipitation data which are obtained from ann lssvm and mlr models individually as the inputs in the second layer the observed precipitation data function as the target data and the last layer is the output layer which leads to computational precipitation data called as neural ensemble model outputs the network architecture i e hidden neuron and epoch number that yields the most reliable result in terms of revaluation criteria on the calibration test and validation steps is determined through trial error process the optimum architecture of model was gained by five hidden neurons and 600 epochs table 5 shows results of the ensemble methods which reveals that neural ensemble model outperforms all other downscaling models fig 4 depicts the observed and downscaled via efficient ann lssvm mlr and ensemble models rainfall time series for tabriz and ardabil stations 5 3 results of third step rainfall projection for future since the projection of faraway future emissions and other human factors that impact atmosphere is troublesome researchers use a scope of situations utilizing different suppositions about future economic social technological and environmental conditions named projection scenarios here rcps rcps indicate greenhouse gas concentration not emissions paths described in four possible future climate conditions among the four rcps including rcp2 6 rcp4 5 rcp6 and rcp8 5 the rcps 4 5 and 8 5 were used in the current study due to data availability for rainfall projection for future future rainfall projection under the rcps 4 5 and 8 5 was conducted for near and distant future over the 2017 2050 and 2051 2100 periods after calibrating the neural ensemble downscaling model the boxplots in fig 5 compare the distribution of rainfall data based on the minimum first quartile median third quartile and maximum for observation calibration and projection values in near and distant future under two rcps according to the simulation results tabriz station rainfall will decrease in future however at ardabil station an increasing trend is observed in future rainfall in this way rainfall projections under rcps 4 5 and 8 in tabriz station for near and distant future will yield to 40 41 and 35 42 decrease however for the ardabil station will lead to 6 12 and 5 13 increase respectively 6 discussion the discussion on the presented results are explained in three steps 6 1 discussion on first step input screening the significant benefit of the proposed predictor screening methodology is the optimal selection of the representative parameters from a huge number of potential inputs for example in case of can esm2 as a single gcm the 3840 wavelet decomposed sub series in length of 50 years of monthly data the number came from 120 predictors multiplied by 8 decomposed sub series at 4 grid points as seen in table 1 were transformed to 120 feature vectors of 8 components which led to selection of only 9 dominant predictors in case of multi gcm again 9 predictors were considered among 15 360 sub series 1920 predictors from 5 gcms multiplied by 8 wavelet decomposed sub series moreover the selected predictors of multi gcm approach from the grid points denote to the morphologic impact of that region on atmospheric variables which consequently affects the stations rainfall so it is necessary to spatially survey the dispersion of dominant predictors from the stations according to table 2 in both tabriz and ardabil stations the predictors for the nearest grid points are not necessarily selected unexpectedly the predictors at the further or relatively distant grid points show the maximum effect on the stations rainfall therefore rainfall generation at the stations are not related to the predictors at the nearmost grid points in spite the simultaneous effect of predictors at the relatively distant grid points around the stations interfered in rainfall creation this outcome is in contrast to the inverse distance weighting idw method which suggests the nearest point to the station has the potential to be the most proper point for downscaling zhou and zhang 2014 owing to the results section the downscaling models which developed by multi gcm approach performed adequately so that discussion on the dominant predictors was prepared for the multi gcm approach of each station investigation on the dominant predictors at tabriz station denotes that the geopotential height i e zg is the dominant parameter almost in all selected grid points at various pressure levels i e zg1000 zg5000 zg7000 zg3000 zg15000 around the study station the geopotential height can be considered as a gravity adjusted height where the geopotential thickness between pressure levels i e the difference between consecutive geopotential heights is proportional to mean virtual temperature in that layer hofmann and moritz 2005 since temperature alteration leads to generation of winds which are principal cause of clouds displacement and rainfall production geopotential heights as the large scale variables can be effective in local rainfall production in this way the input screening methodology could detect nonlinear relationships between the geopotential height predictors and rainfall production at tabriz station dominant predictors of multi gcms at various grid points are depicted in table 2 which indicate that the relative humidity i e hur predictor at high pressure levels is the other dominant predictor the lack of moisture sources i e large water bodies around the study site has caused the hur predictor dominancy in the upper layers of the atmosphere than lower layers since tabriz is located in mountainous region the humidity from the faraway water bodies like the caspian sea can be transferred in high pressure levels hfls is the other predictor which became important according to table 2 the latent heat flux emerges as winds carry moisture of the urmia lake away from the surface and affects tabriz rainfall table 2 indicates that the dominant predictors which affect the ardabil station rainfall are humidity variables i e hur and hus geopotential height wind speed and mean temperature where all the predictors except mean temperature belong to the grid points located over the caspian sea the mean temperature impact on ardabil rainfall from the south east grid point according to table 2 hus is the dominant predictor of the grid points located on caspian sea at all three gcms selected in multi gcm approach for ardabil station it can be inferred that caspian sea as the principal moisture source impacts ardabil station rainfall however the dominant wind variable ua which is located at the east of station transfers the humidity from sea side to the station the proper choice of wind variable by the proposed methodology is compatible with the prevailing wind i e east west direction of the region the impact of zg from two eastern grids on ardabil rainfall implies the significance of temperature fluctuations on the sea thus wind that blows from east to west and transfers moisture to adjacent mountainous area where ardabil station is located 6 2 discussion on second step downscaling models according to tables 3 and 4 for both stations multi gcm approach outperformed single gcm so the combined use of several gcms could cover the uncertainties involved in each gcm and reduce the dependency on a single gcm model therefore multi gcm model could enjoy only effective characteristics of each gcm for future rainfall projection which has been recommended by some other studies as well li et al 2012 miao et al 2014 rashid et al 2015 according to tables 3 and 4 the consistency between selection of gcms for multi gcm approach and high performance single gcms in both stations indicates the ability of screening method in detecting dominant predictors among the most effective gcms in case of tabriz station selected dominant predictors are from csiro access1 gfdl esm2g and bnu esm gcms while the same gcms in the single gcm approach explained the maximum efficiency in terms of evaluation criteria in ann based modeling for the ardabil station the inm cm4 can esm2 and csiro access1gcms showed high performance in the single gcm model which are compatible with the dominant selections of multi gcm model results of tables 3 and 4 demonstrate that the ai based downscaling models outperform both mlr models in terms of evaluating criteria because mlr is not capable of distinguishing nonlinear relations among dominant predictors and the predictand however the remarkable point is that the mlr model with screened inputs outperforms the mlr model with inputs obtained from cc based method this outcome confirms the superiority of nonlinear screening method to the linear method also the comparison of table 5 with tables 3 and 4 reveals that neural ensemble model is the most efficient downscaling method suggested in the current study moreover fig 4 demonstrates that neural ensemble model could show reasonable trend of the observed data than individual ann lssvm and mlr models the reason for such improvement is that the neural ensemble model reinforces the strengths of each model and weakenes the poor forecasting of individual models i e ann lssvm and mlr by assigning proper weights through training phase overall the comparison of downscaling results in tabriz and ardabil stations denotes to poor results for ardabil than tabriz so generalization of the same gcms to the different cases seems not to be a good idea since developed methodology has the ability to handle big data it is suggested to use all available gcms as the inputs of the screening model and let the model to select the dominant gcms for each region 6 3 discussion on third step rainfall projection for future according to fig 5a the mean annual rainfall value of ardabil station is more than tabriz station and baseline calibrated rainfall values at both stations match observed data with smaller difference for the tabriz station which indicates better performance of methodology for that station however the data dispersion is reduced in calibrated neural ensemble model which is an evident fact in any developed model because model generated data in comparison to observed data show less fluctuations and tend to deterministic state than stochastic the comparison of the annual observed and simulated rainfall values at both stations demonstrates that tabriz station rainfall will decrease in future under both the rcps while in the ardabil station it will increase the intensity of rainfall pattern change in both stations at distant future will be slightly severe than near future the comparison of rcps denotes that both greenhouse gas concentration trajectories i e rcps 4 5 and 8 5 show similar performance in the future rainfall projection of the region at tabriz station although the simulated model shows decreasing trend in annual average rainfall seasonal projections paint future rainfall of station from other viewpoint in fig 5b for tabriz station except spring during all other seasons under both rcps rainfall mean and variance will decrease even extreme events of rainfall which are more plausible in autumn and winter will be less than mean observed rainfall during the baseline it means water resource managers should be aware that during the spring it will be more important to preserve water resources and collect surface water in order to benefit from it during the next three dry seasons for the ardabil station the seasonal rainfall pattern in the upcoming years will be incremental during spring and summer subtractive during autumn and almost constant during winter with regard to the bassline fig 6 depicts annual variations of rainfall for the observed and simulated values under both rcps 4 5 and 8 5 the figure indicates that changes in annual rainfall encompass year to year variations with the considerable decreasing and increasing trends in future for tabriz and ardabil stations respectively furthermore in each diagram of fig 6 a break point is considered in the time series between the observation and the projection time series the reason for this break point is two different source of data observation time series with stochastic characteristic is non stationary and shows trend while projected time series generated from gcm based data based on computational out comes is stationary and without trend therefore break points are inevitable in transiting from observation to projection phase it is noted that it s common to see the projected predictand with confidence interval so the uncertainty for future prediction due to the uncertainty involved in the phenomenon should be also considered in addition to the deterministic trace however precise determination of such interval requires knowledge on pdf of involved parameters and its simulation is out of the scope of current study but in fig 6 the upper and lower bonds of confidence interval of the predictand assuming normal pdf for output has been drawn up 7 concluding remarks since rainfall is an important parameter in developing hydrologic impact studies for future rainfall prediction of the two stations namely tabriz and ardabil were assessed by the ai based statistical gcm downscaling models five various gcms with the single and multi gcm input approaches were used in downscaling models under the rcps 4 5 and 8 5 the novel we som predictor screening methodology was used to select the dominant predictors among huge number of input candidates the advantages of the proposed predictor screening method are its ability to handle non stationary effects of predictors diminishing the dimensionality of data and obtaining dominant input by detecting nonlinear relation between predictors and predictand although the proposed screening methodology with different mathematical tools seems to be complicated which may be considered as a limitation of modeling the selection of optimum variables i e 9 variables among 1920 potential variables resulted in the establishment of a robust and suitable downscaling model downscaling via ai based i e ann and lssvm models was performed after predictor screening step the comparison of the linear i e mlr and nonlinear i e ann and lssvm regression models indicated that ai based models could be more efficient than linear method the superior neural ensemble model was then established based on the outputs of the three individual downscaling models i e ann lssvm and mlr which showed 60 and 64 performance improvement in terms of dc at validation step over individual ann model for tabriz and ardabil stations respectively in contrast to some researches which select the predictors from grid points with minimum distance from the study station the present study showed that sometimes the distance cannot be a suitable criterion for choosing an effective grid point and predictor in the last step future rainfall of tabriz and ardabil stations under the rcps 4 5 and 8 5 were projected results of the simulations indicated that according to intermediate and high emission scenarios the tabriz station rainfall will decrease in average i e 41 40 and high emission i e 35 42 scenarios respectively in addition ardabil station rainfall will display increase 6 12 under rcp 4 5 and 5 13 under rcp 8 5 respectively during near and distant future overall the results of this study provide promising evidence for statistical downscaling and more specifically for the proposed we som input screening method to select climate variables the application of we som screening method to downscale other climatologic parameters of the stations e g temperature can be considered as a topic for future studies moreover the proposed downscaling method can be compared with statistical and dynamical downscaling models other than the mlr which was used in this study in this way due to the different abilities of artificial intelligence and machine learning methods it may be suggested to use other kinds of ai models and clustering approaches 
7023,the artificial intelligence ai models i e artificial neural network ann and least square support vector machine lssvm were used to statistically downscale and project rainfall data from cmip5 general circulation models gcms for tabriz and ardabil synoptic stations in north west iran since one of the important issues in statistical downscaling of gcms is to select dominant variables among plenty of large scale climate data predictors a predictors screening framework which integrates wavelet entropy we and self organizing map som was developed in this study to statistically downscale mean monthly rainfall values the advantage of proposed method is to reduce the noise and dimensionality of data as well as selecting reliable inputs of downscaling model for future rainfall projection to this end five gcms i e can esm2 bnu esm csiro access1 gfdl esm2g and inm cm4 were employed ann lssvm and multiple linear regression mlr models were trained to capture relationship between the predictors and the stations observed rainfall values predictand then ensemble techniques were applied on the outputs of the downscaling models the calibration validation and projection of the proposed downscaling models were performed over the periods jan 1951 to dec 1991 jan 1992 to dec 2005 and jan 2017 to dec 2100 respectively the projection of rainfall for near and distant future i e 2017 2050 and 2050 2100 by the proposed multi gcm ensemble framework yielded to rainfall alteration pattern 40 41 and 35 42 decrease at tabriz station and 6 12 and 5 13 increase at ardabil station under rcps 4 5 and 8 5 respectively keywords general circulation models rainfall projection wavelet entropy we self organizing map som artificial neural networks ann least square support vector machine lssvm nomenclature acronym definition ai the artificial intelligence anfis adaptive network based fuzzy inference systems ann artificial neural network bnu beijing normal university china cc correlation coefficient cccma canadian centre for climate modelling and analysis canada cmip5 fifth assessment report of ipcc csiro bom commonwealth scientific and industrial research organization bureau of meteorology australia dwt discrete wavelet transform ffnn feed forward neural network gcm general circulation model gfdl geophysical fluid dynamics laboratory usa gp genetic programming hfls surface upward latent heat flux hur relative humidity hus specific humidity idw inverse distance weighting inm institute of numerical mathematics russia lm levenberg marquardt lssvm least square support vector machine mlr multiple linear regression mi mutual information pca principal component analysis pdf probability distribution function psl air pressure at sea level rbf radial basis function rcp representative concentration pathway sc silhouette coefficient som self organizing map tansig tangent sigmoid tas air temperature ua eastward wind uas eastward near surface wind va northward wind vas northward near surface wind we wavelet entropy zg geo potential height 1 introduction the skill of general circulation models gcms in reproducing hydrologic parameters such as precipitation is of critical importance although gcms are the tools that provide reliable atmospheric data coarse spatial resolution of gcms may lead to poor outcomes when applied as inputs to the local scale hydrologic models downscaling is an approach to obtain local scale weather data from large scale gcms there are two major techniques to downscale gcm based climate data statistical and dynamical methods dynamical downscaling is the method to derive smaller scale climatic information over a bounded area via high resolution regionalmodel driven from gcms statistical downscaling encompasses statistically relating large scale climate features predictors to local climate data predictand as a black box model wilby and wigley 1997 in spite of high resolution outputs of dynamical downscaling method its application is limited due to intensive computational procedures need to huge volume of data and a high level of expertise to implement and interpret results trzaska and schnarr 2014 instead statistical downscaling has been broadly used in climate change studies because of the convenience in implementing and interpreting of the results e g see sailor and li 1999 harpham and wilby 2005 chen and adams 2006 beecham et al 2014 the main concept of statistical downscaling is to make a relationship between predictors and predictand by means of a statistical method such as i linear regression models e g statistical downscaling model sdsm wilby et al 2002 ii nonlinear regression models of artificial intelligence ai e g artificial neural network ann zorita and von storch 1999 support vector machine svm tripathi et al 2006 relevance vector machines rvm ghosh and mujumdar 2008 gene expression programming gep sachindra and perera 2016 iii weather generators e g long ashton research station weather generator lars wg racsko et al 1991 trzaska and schnarr 2014 prepared a thorough review of downscaling methods for climate change projections which can be referred for more detail about downscaling methods the capability of anns in simulating nonlinear and time varying characteristics of atmospheric variables at different scales and their potential in extracting complex patterns as well as relations between predictors and predictand has led to several successful applications of ann for downscaling purpose in technical literature e g see wilby and wigley 1997 dibike and coulibaly 2006 chadwick et al 2011 okkan and kirdemir 2016 moreover support vector machines svms and least squares support vector machines lssvms as the other nonlinear downscaling methods vapnik 1995 showed remarkable successes in statistical downscaling of climatic parameters e g tripathi et al 2006 chen et al 2010 sachindra et al 2013 focus on consequences of studies with ai based downscaling methods e g ann shows some contradictory results while some state the superiority some others denote the drawback and inefficiency of ann over the multiple linear regression mlr based models e g dibike and coulibaly 2006 khan et al 2006 abdellatif et al 2013 these inconsistent results may depend on the quality and quantity of the applied data huge data redundant information and the involved noise in the data set are the challenging issues about ai based modeling the noise involved in the data set can be magnified nonlinearly over the simulation time while using nonlinear models e g ann and svm models in this case application of input screening as a pre processing scheme can largely enhance the efficiency of the ai based downscaling models in this regard general approaches such as correlation analysis devak and dhanya 2016 principal component analysis pca ahmadi and han 2013 fuzzy and gamma test ahmadi et al 2015 have been employed for input selection of statistical downscaling models the huge data set in downscaling issue is coming from several predictors at multiple grid points over long time intervals and several gcms which are available for the study region although various research centers around the globe prepare gcm based climate data generally they do not offer the same values for a specific variable at a particular region the reason relies on different parameterization schemes variation in boundary layers and different resolutions relying on the output from a single model and finally abrupt spatial variability in climate thus proper selection of gcm and grid points as well as predictors are of prime importance in downscaling approach for a specific region lee and kim in press hence a robust method of dominant input selection among various gcms several grid points and predictors is needed which current study tries to address this important issue one of the effective methods to decrease the dimensionality of input space is clustering and selecting representative member from each cluster bowden et al 2005 although several studies have already used different clustering based methods for dominant input selection of ai based models in hydrological applications e g may et al 2008 markus et al 2010 nourani and parhizkar 2013 li et al 2015 nourani et al 2017 the implementation of such a clustering based input screening is indeed scarce in statistical downscaling of gcms therefore current study proposes a novel predictor screening methodology by coupling self organizing map som as a clustering approach with wavelet entropies wes of predictors to select dominant predictors since climatologic data sets involve non stationary time series entropy as a measure of information content shannon 1948 could be preferred to statistical moments i e mean variance skewness etc in order to represent whole time series in the clustering procedure several studies have already confirmed appropriate performance of entropy based nonlinear metric over linear based statistical moments e g hlinka et al 2014 vu et al 2018 on the other hand underlying multi resolution seasonalities of the climatic process are drawn out by wavelet transform via extracting various features of time series at different time scales johnson et al 2011 nourani et al 2014 rashid et al 2015 the motivation objectives of current study is to develop proper statistical downscaling model using two important approaches first a novel predictor screening model and second ensemble of some models to downscale properly these objectives were achieved by the following steps i developing a robust we som predictor screening methodology ii developing downscaling models by three approaches i e ann lssvm and mlr iii enhancing the downscaling results by ensemble downscaling models to project future rainfall since rainfall is the most important component of the hydrologic cycle and on the other hand statistical downscaling steps including data gathering pre processing downscaling and projection are time consuming processes and require challenges on big data rainfall was considered as the only predictand in this study similar to some other studies which focused on only one variable including chaudhuri and srivastava 2017 nogueira and barros 2015 and chiew et al 2010 2 study area and data 2 1 study area this study deals with two stations namely tabriz latitude 38 07 n longitude 46 14 e and elevation 1364 m and ardabil latitude 38 22 n longitude 48 30 e and elevation 1332 m in the north west of iran as shown in fig 1 these two stations are approximately located at the same latitude but different longitudes the average annual rainfall in the tabriz and ardabil stations are 280 mm and 318 mm respectively both stations are located in cold weather conditions with regular seasons however ardabil has cold semi humid climate and more precipitation because of the proximity to the caspian sea while tabriz generally has cold semi arid climate the dominant wind blows from the east to the west in both stations 2 2 data set the monthly observed rainfall data for both stations were obtained from the iran meteorological office for the period 1951 2005 the mean monthly gcm predictors in the same time interval were used in this study as listed in table 1 the gcm data from the fifth assessment report of ipcc i e cmip5 gcms under the representative concentration pathways i e rcp4 5 and rcp8 5 for future simulation were retrieved from the ipcc data distribution center http cera www dkrz de during 1951 2100 for downscaling purpose the predictors were extracted from can esm2 bnu esm csiro access1 gfdl esm2g and inm cm4 gcms provided by research centers of canada china australia usa and russia respectively table 1 since several studies accounted beneficial aspects of applying data from several grid points around the study location frost et al 2011 guo et al 2012 beecham et al 2014 predictors from four grid points around each study station considered in the modeling fig 1 therefore the total number of grid points which cover two stations is 6 for each gcm or in other words is 30 for all of the five gcms see fig 1 in this way the number of predictors in surface and various layers of atmosphere in bnu esm and inm cm4 gcms is 95 in can esm2 gcm is 120 in csiro access1 and in gfdl esm2g gcms is 85 leading to totally 1920 variables as the potential input candidates of the downscaling models for each station if trial and error procedure is applied to assess the best input set 2 1920 1 2 1240 1 input combinations should be examined which is an exhausting process and not feasible to select the dominant inputs although linear correlation coefficient cc may be used as a criterion to select dominant inputs which used in this study as comparison purpose implementation of a nonlinear input selection method is essential for a nonlinear process as criticized by nourani et al 2015 in this regard a nonlinear input screening method is developed and applied through the current study 3 proposed methodology the proposed statistical downscaling methodology contains three steps as shown by fig 2 the first step is the dominant predictor selection procedure second step is the ai based downscaling model and finding the superior model by ensemble techniques and finally third step is the projection of future rainfall at tabriz and ardabil synoptic stations under rcps 4 5 and 8 5 3 1 first step input screening in order to cover the strengths and weaknesses of various gcms and handle uncertainty of different gcms five gcms which showed good results for the region in some previous studies e g cai et al 2009 namely can esm2 bnu esm csiro access1 gfdl esm2g and inm cm4 and their ensemble were used in this study due to non stationary inherent of climatic phenomena temporal features as well as seasonal attributes are encompassed in time series which can be detected by wavelet transform thereupon discrete wavelet transform dwt is applied to decompose time series of predictors into multi resolution sub series in this way original time series are broken up into approximation and detailed sub series to represent general trend and different levels of periodicity involved in the time series since the wavelet generated sub series manifold the data it is necessary to use the abstract form of each sub series by maintaining the information contained therein in this regard it is suggested to compute and use entropy of each sub series as the substitute entropy shows information content or the degree of order disorder of each wt decomposed sub series as we in this way each sub series is substituted by only one value i e we and so the dimensionality of the data set is greatly reduced for a monthly time series including many samples first wavelet transform at level l decomposes one predictor time series to l 1 sub series one approximation and l detail sub series then l 1 wes are computed to represent whole time series with only l 1 values each representing a specific feature scale of original time series generally all of the features are not informative equally some may include noise some others may have correlation and some with no remarkable relevancy to the output variable therefore a screening process is necessary to select the impressive features as inputs for downscaling models som as a clustering method is used here to screen the features basically the som is an unsupervised ann tool that can capture linear and non linear statistical relations in complex high dimensional dataset and illustrate them via a comprehensible geometric relation map application of wes instead of the whole decomposed sub series in the clustering procedure can lead to an optimized som input layer so can improve the clustering performance by reducing the dimensionality of the data set the som based clustering is implemented over the computed wes with two approaches i single gcm approach in which wes of each five gcms are fed into som individually and five different results for each gcm are obtained ii multi gcm ensemble approach in which the wes obtained from the whole predictors of five gcms are imposed to the som simultaneously due to the complexity of predictors time series poor linear correlation between predictors and predictand may be detected in spite of existing a strong non linear relation thereupon in order to detect the non linear relationships between predictors and predictand at the clusters mutual information mi measure is used to select representatives of each cluster finally the predictors which pass the screening procedure are entered to the second step to downscale gcm rainfall via ann and lssvm models 3 2 second step downscaling models in the second step the ai based downscaling models are developed in this way the single and multi gcm screened predictors are used to train ann and lssvm downscaling models subsequently in order to achieve the strengths of each downscaling model the ensemble of ann lssvm and mlr downscaling models are stablished in fact ensemble modeling is the process of running two or more related but different analytical models i e ann lssvm and mlr here to combine the outputs of various analytical models into a single output with improved accuracy of predictive modeling the final ensemble model is then used to project future rainfall in the third step it should be mentioned that since application of gcm derived data in downscaling process may lead to systematic biases between the downscaled results and observations statistical amendment of gcm data is often essential wilby et al 2004 one of the common procedures to remove the systematic biases in mean and variance is standardization tripathi et al 2006 chen et al 2010 according to sachindra et al 2014 standardization of predictors i e subtracting the mean from data and dividing by the standard deviation scales down the predictor data to a single uniform scale and removes the units of the variables 3 3 third step rainfall projection for future finally step three is performed under rcps 4 5 and 8 5 to simulate future monthly rainfall of tabriz and ardabil synoptic stations for near and distant future in the periods of 2017 2050 and 2051 2100 it is noted that according to various plausible viewpoints about future anthropogenic actions due to different rates of growth in population economic energy and socioeconomic development and their impacts on greenhouse gas emissions each rcp demonstrates distinct radiative forcing pathways by 2100 in this way rcps 4 5 and 8 5 are related to intermediate and high emission scenarios respectively the sections below briefly explain required mathematical tools for the proposed methodology 4 materials 4 1 wavelet entropy the wavelet makes localization of a signal in time and scale domains by comparing the relationship between wavelet function and a signal the discrete form of wt is used and screened as eq 1 mallat 1998 1 g m n t 1 a 0 m g t n b 0 a 0 m a 0 m where is the complex conjugate and g t named mother wavelet m and n denote to the wavelet dilation and translation respectively a0 is a specified fined dilation step greater than 1 and b0 is the location parameter which must be greater than zero the most common and simplest choice for parameters are a0 2 and b0 1 this power of two logarithmic scaling of the dilation and translation is known as the dyadic grid arrangement the dyadic wavelet can be written in more compact notation as mallat 1998 2 g m n t 2 m 2 g 2 m t n for a discrete time series xi the dyadic wt becomes mallat 1998 3 t m n 2 m 2 i 0 n 1 g 2 m i n x i where tm n corresponds to wavelet coefficient of the discrete wavelet at scale a 2 m and location b 2mn eq 3 considers a finite time series xi i 0 1 2 n 1 and n 2q this gives the ranges of m and n as 0 n 2q m 1 and 1 m q respectively entropy is a statistical measure of the randomness or uncertainty in terms of probability distribution presented by shannon 1948 so entropy of each wavelet decomposed sub series tm n which takes values tm n 1 tm n 2 tm n n with probabilities p tm n 1 p tm n 2 p tm n n respectively is defined as shannon 1948 4 e t m n i 1 n s p t m n i l o g p t m n i where e t m n is entropy of tm n also referred to entropy function and ns is the number of intervals or bins to form the histogram and thereinafter probability distribution function pdf entropy can statistically represent the rate of uniformity for a single variable however it is not able to discover the uniformity and relations between two variables thus in order to overcome this shortcoming joint entropy between two variables is defined as gao et al 2008 5 e x y i 1 n s j 1 m s p x i y i l o g p x i y i where variables x and y in this study are predictors x and predictand y p x i y i is the joint probability of xi and yi with bins number of ns and ms respectively mi calculates the mutualdependence between two variables as follow equation yang et al 2000 6 m i x y e x e y e x y while cc can detect linear relation between two variables mi has the capability to detect non linear dependency of variables cover and thomas 1991 4 2 self organizing map som som clusters homogeneous data with similar pattern in a cluster and reduce the dimensionality of data the som structure contains components called nodes with a common arrangement of two dimensional hexagonal grid a weight vector of the same dimension as the input data vectors is assigned to each node in order to detect node with the closest smallest distance metric weight vector w to the n dimensional input vector x euclidean distance is used kohonen 1997 7 x w i 1 n x i w i 2 the weight with the closest match to the input data is the winner node called best matching unit bmu in order to further decrease the distance between the weights and bmu learning continues by changing the weights at each training iteration t kohonen 1997 8 w t 1 w t α t h lm x w t where α corresponds to the learning rate ranging in 0 1 h lm denotes the neighborhood function the most commonly used neighborhood function is the gaussian function kohonen 1997 9 h lm e x p l m 2 2 σ t 2 where l and m correspond to bmu and the position of neighboring nodes at output and σ is the width of the topological neighborhood at iteration t 4 3 artificial neural network ann ann learns according to input and output data while information flows through network the underlying pattern in data affect the structure of ann and leads to generation of the appropriate network according to data the simplest ann includes three layers input hidden and output layers in order to be brief readers are referred to study relevant books in ann field such as haykin 1994 4 4 least square support vector machine lssvm suykens and vandewalle 1999 proposed lssvm which was first originated from the svm method alike the svm lssvm is also considered as a strong technique to assess non linear classification function estimation and density estimation problems the non linear function of the lssvm method can be shown as suykens and vandewalle 1999 10 f x w t φ x u where f indicates the relationship between the predictors and predictand w is the m dimensional weight vector ϕ is the mapping function that maps x into the m dimensional feature vector and u is the bias term considering the complexity of function and fitting error the regression problem can be given according to the structural minimization principle as suykens and vandewalle 1999 11 min j w e 1 2 w t w γ 2 i 1 m e i 2 which has the following constraints 12 y i w t ϕ x i u e i i 1 2 m where γ is the margin parameter and e i is the slack variable for x i in order to solve the optimization problems given in eq 11 the objective function can be obtained by using the lagrange multipliers of αi and the optimal condition can be obtained by taking the partial derivatives from objective function of unconstraint problem with respect to parameters which yields the linear regression of suykens and vandewalle 1999 13 0 y t y z z t i γ u α 0 1 where y y 1 y ym z ϕ x 1 t y i ϕ x m t y m i 1 1 α α 1 α 1 by defining kernel function k x x i ϕ x t ϕ x i i 1 m the lssvm regression becomes 14 f x i 1 m α i k x x i u a commonly used kernel function in regression problems is the radial basis function rbf which represents the normal probability distribution the majority of stochastic hydro climatologic processes follow the normal probability distribution or may have the potency of altering to a normal distribution the rbf kernel is used as the lssvm s main kernel functions in this study with kernel width parameter σ as follow suykens and vandewalle 1999 15 k x x i exp x x i 2 σ 2 2 4 5 evaluation criteria 4 5 1 clustering evaluation criterion in order to measure the validity of som based clustering silhouette coefficient sc is applied to validation consistency within clusters for each datum i two kinds of dissimilarities are defined first the average dissimilarity of i with all other data in the same cluster a i second the average dissimilarity of point i to each of other clusters other than own cluster of i where the minimum value is b i silhouette equation is then computed as amorim and hennig 2015 16 s i b i a i max a i b i s i varies between 1 1 closer to 1 correct low or negative incorrect placement in cluster respectively and near zero means the datum is located on the border of two clusters in order to assess the overall clustering configuration the average s i of the whole data on the all clusters is calculated which shows how appropriately the data have been clustered hsu and li 2010 17 sc 1 n i 1 n s i where n is the total number of arrays in the data space large values of sc denote to appropriate clustering outcome 4 5 2 model evaluation criteria the comparison between calibrated and observed values is the simplest form of model validation several statistical measures are available to evaluate the association between the calibrated and the observed data cc as eq 18 is the most common method evaluates the linear relevancy between two variables ranging between 1 to 1 where values greater and less than zero shows a positive and negative relation respectively while zero states no association between the two variables 18 cc n o c o c n o 2 o 2 n c 2 o 2 moreover in order to evaluate the precision of the prediction in downscaling model the determination coefficient dc is used in this study see eq 19 it measures how well the observed results based on their proportion of the total variation are replicated by the proposed model and ranges from to 1 the greater dc denotes to the better agreement between the observed and calculated values root mean square error rmse is another measure of the accuracy and assesses how effectively the downscaling model predicts rainfall see eq 20 19 dc 1 o c 2 o o 2 20 rmse o c 2 n where n o c and o are the observation data number observed data calculated values and the mean of the observed data respectively it is necessary to mention that legates and mccabe 1999 already stated that any hydro climatological model can be sufficiently evaluate by only dc and rmse criteria however the indicator cc was also used to assess the linear relation between observed and downscaled data in this study 5 results based on the proposed methodology the results are presented in the following sub sections 5 1 results of first step input screening the proposed predictor screening methodology was applied to single and multi gcm predictors for each gcm 15 atmospheric predictors in surface and various levels of atmosphere at four grid points around the synoptic station were considered to determine the dominant predictors through the first step dwt was applied at decomposition level 7 to decompose time series of predictors into one approximation and 7 detail sub series the proper selection of the mother wavelet and decomposition level is the important issue while using dwt based on nourani et al 2014 the structure of the daubechies mother wavelet with four vanishing moments db4 is similar to most of the hydro climatologic time series hence decomposition procedure was established by db4 mother wavelet with regard to the selection of the optimum decomposing level owing to the fact that the aim of the study is to downscale rainfall for future and there is a need to know about different frequencies of the rainfall in the distant horizon the decomposition level 7 was selected as the appropriate decomposition level to capture the large range of the frequencies from the approximately monthly to the seasonal up to the about five year i e 27 months frequencies the entropy of each sub series was calculated so each time series with 8 sub series obtained through was compacted to a vector with 8 values in this way each predictor was defined by an 8 component vector such a vector can represent the important features of an individual time series since the wavelet based representation of the predictor differs according to the frequency state of the process we values of the sub series will also be different in fact the high values of the wes refer to the subseries with high stochastic fluctuations and the low values of the wes are expected for the ordered sub series with the deterministic and smooth fluctuations henceforth the som clustering approach was used to group the feature vectors wes of predictors into the several clusters two important issues should be respected in clustering procedure first determination of the optimum cluster number considering the ai based downscaling model second the use of an appropriate method to select the representatives from all clusters in the first issue of clustering to determine the optimum cluster number the sc values were calculated and plotted against the number of clusters varying between 2 2 t o 10 2 fig 3 the squared numbers of clusters in fig 3 denote the two dimensional structure of som network in this study it is obvious that increasing of cluster number leads to more homogeneous clusters however such increment may not be wise in high dimensional data like current study where the dominant feature from each cluster will be used by ann and lssvm since numerus inputs to ai models can decrease the efficiency of model logical number of inputs obtained from clusters should be considered to do so the mean value of sc for each number of cluster was determined according to fig 3 the sc values increase very smoothly by growing the number of clusters after a considerable drop around 10 clusters since the growth of the sc around 9 to 25 clusters was smooth in comparison to the gradient of sc after and before the specified range depicted by vertical arrows in fig 3 the start of smooth gradient i e 9 cluster was selected as the optimum cluster number in the single and multi gcm cases as the second issue of clustering the dominant features of the clusters were selected based on the maximum mi computed between the predictors in a cluster and the predictand thus a predictor with the most non linear relevancy to the observed rainfall data was designated as the agent of that cluster the dominant predictors selected from the clusters in both single and multi gcm cases are shown in table 2 where most of the representative predictors are related to humidity wind velocity geopotential height and heat flux of the atmosphere accordingly some previous studies more or less pointed out the importance of such atmospheric predictors for rainfall downscaling wilby et al 2004 frost et al 2011 rashid et al 2015 the outcomes of step one were the dominant features of the clusters for single and multi gcm cases which are displayed on different grid points of various gcms in table 2 5 2 results of second step downscaling models in the second step two non linear data driven models i e ann and lssvm as the commonly used ai based methods in the hydro climatology modeling accompanied with linear mlr model to downscale predictand the dominant predictors that passed through the som screening procedure in the first step were standardized over the period 1951 2005 the first 75 percent of the dominant predictors and observed rainfall data were used for the training of downscaling models and the remaining 25 percent used for the validating purpose in ai based and mlr models hence calibration and validation periods were set to 1951 1991 and 1992 2006 periods respectively the three layer feed forward neural network ffnn with the back propagation of errors levenberg marquardt lm optimization algorithm and tangent sigmoid tansig activation function represented nonlinear functional mapping between predictors and predictand in this study in any ffnn based modeling appropriate selection of neurons number in the hidden layers i e second layer and the training iteration epoch number can improve model efficiency in both the calibration and validation steps the optimum architecture i e hidden neuron and epoch number of ann downscaling model in this study was determined via trial error method in order to avoid overfitting problem due to numerous input data and catch the optimum results on ann downscaling model the input layer which supposed to include big data of gcms were considerably decreased in data size by the proposed we som screening methodology i e first step so that only dominant predictors obtained from first step i e only 8 vectors of 600 components were used in ann downscaling model as the input layer data which is not considered as big data anymore in this way the optimum number of hidden neurons and epoch for multi gcm ann downscaling model were reported 6 250 and 4 470 for tabriz and ardabil stations respectively the results of single and multi gcm models are tabulated in tables 3 and 4 for tabriz and ardabil stations respectively the models which displayed the maximum dc in the validation step with multi gcm inputs were selected as the efficient ann models tables 3 and 4 moreover the lssvm model with rbf kernel function mapped the nonlinear predictor predictand relationship in this study the downscaling results of lssvm model in terms of evaluating criteria also confirmed the results of ann model so the multi gcm model performed more effective than models with single gcm inputs tables 3 and 4 therefore in both ann and lssvm downscaling models multi gcm approach showed more reliable performance while the ann showed slightly better performance than lssvm model the performance of a newly proposed downscaling model is usually assessed with regard to some classic models such as sdsm sdsm as a commonly used statistical downscaling model uses the mlr method to establish a statistical relationship between predictors and predictand so mlr model was applied in this study as well for the comparison purpose in order to assess the performance of the ai based models the mlr model was developed based on the predictors which i did not enter screening method and solely selected according maximum cc with predictand and ii multi gcm predictors of screening method see tables 3 and 4 furthermore in order to compare the proposed method with classic screening techniques the spatial correlation and pca methods were applied on 1920 gcm predictors in the spatial correlation method the correlation among all predictors and predictand were computed and values above 0 4 were selected the selected predictors were then fed into statistical models see tables 3 and 4 also for ardabil station pca method was applied on all predictors i e totally 1920 time series to detect outliers of the data projections of the data points onto the new axis led to determination of the 93 principal components owing to the fact that each component is the linear combination of 1920 time series selection of important predictors from each component can be another challenge it seems for input dimension reduction the predictor selection must be done according to maximum variance of each component or iterative trial error procedure however application of pca apart from being time consuming may deteriorate the performance of data based models such as ann and svm due to less dimension reduction and yielding numerous inputs with redundant information here 93 timeseries in this regard some pros and cons of the developed we som screening method with regards to classic methods i e spatial correlation and pca can be listed as below i both correlation and pca methods are linear methods since they have been developed based on variance but developed we som methodology includes nonlinear entropy based core ii application of correlation and pca methods may not lead to dimension reduction properly e g in case of pca 1920 variables led to 93 variables which require another screening method to lessen the potential inputs while dimension reduction via we som methodology led to select 9 dominant predictors iii application of wavelet is the other advantage of the proposed methodology which can handle non stationary of the series and determine prevailing periods and seasonalities of the process iv som clustering tool classified 1920 predictors of 8 component vectors while pca must find relation among 1920 predictors each with about 600 components in order to improve downscaling result the ensemble of the best ai and mlr models were developed three ensemble techniques were applied i the simple averaging method ii the weighted averaging method weights were defined according to dc validation values and iii the neural ensemble model the first two methods linearly combine outcomes of three ann lssvm and mlr models while in the 3rd non linear ensemble method ffnn was used as a kernel in the ensemble model due to more applicability although other ai based models e g lssvm anfis and gp see the acronym table also could be used as the ensemble kernel the neural ensemble model was trained using the outputs of three downscaling models i e ann lssvm and mlr as the inputs of this novel ensemble method alike ann model neural ensemble model was performed based on three layer ffnn model with back propagation of errors optimization algorithm of the lm and tansig activation function the first layer of neural ensemble model includes precipitation data which are obtained from ann lssvm and mlr models individually as the inputs in the second layer the observed precipitation data function as the target data and the last layer is the output layer which leads to computational precipitation data called as neural ensemble model outputs the network architecture i e hidden neuron and epoch number that yields the most reliable result in terms of revaluation criteria on the calibration test and validation steps is determined through trial error process the optimum architecture of model was gained by five hidden neurons and 600 epochs table 5 shows results of the ensemble methods which reveals that neural ensemble model outperforms all other downscaling models fig 4 depicts the observed and downscaled via efficient ann lssvm mlr and ensemble models rainfall time series for tabriz and ardabil stations 5 3 results of third step rainfall projection for future since the projection of faraway future emissions and other human factors that impact atmosphere is troublesome researchers use a scope of situations utilizing different suppositions about future economic social technological and environmental conditions named projection scenarios here rcps rcps indicate greenhouse gas concentration not emissions paths described in four possible future climate conditions among the four rcps including rcp2 6 rcp4 5 rcp6 and rcp8 5 the rcps 4 5 and 8 5 were used in the current study due to data availability for rainfall projection for future future rainfall projection under the rcps 4 5 and 8 5 was conducted for near and distant future over the 2017 2050 and 2051 2100 periods after calibrating the neural ensemble downscaling model the boxplots in fig 5 compare the distribution of rainfall data based on the minimum first quartile median third quartile and maximum for observation calibration and projection values in near and distant future under two rcps according to the simulation results tabriz station rainfall will decrease in future however at ardabil station an increasing trend is observed in future rainfall in this way rainfall projections under rcps 4 5 and 8 in tabriz station for near and distant future will yield to 40 41 and 35 42 decrease however for the ardabil station will lead to 6 12 and 5 13 increase respectively 6 discussion the discussion on the presented results are explained in three steps 6 1 discussion on first step input screening the significant benefit of the proposed predictor screening methodology is the optimal selection of the representative parameters from a huge number of potential inputs for example in case of can esm2 as a single gcm the 3840 wavelet decomposed sub series in length of 50 years of monthly data the number came from 120 predictors multiplied by 8 decomposed sub series at 4 grid points as seen in table 1 were transformed to 120 feature vectors of 8 components which led to selection of only 9 dominant predictors in case of multi gcm again 9 predictors were considered among 15 360 sub series 1920 predictors from 5 gcms multiplied by 8 wavelet decomposed sub series moreover the selected predictors of multi gcm approach from the grid points denote to the morphologic impact of that region on atmospheric variables which consequently affects the stations rainfall so it is necessary to spatially survey the dispersion of dominant predictors from the stations according to table 2 in both tabriz and ardabil stations the predictors for the nearest grid points are not necessarily selected unexpectedly the predictors at the further or relatively distant grid points show the maximum effect on the stations rainfall therefore rainfall generation at the stations are not related to the predictors at the nearmost grid points in spite the simultaneous effect of predictors at the relatively distant grid points around the stations interfered in rainfall creation this outcome is in contrast to the inverse distance weighting idw method which suggests the nearest point to the station has the potential to be the most proper point for downscaling zhou and zhang 2014 owing to the results section the downscaling models which developed by multi gcm approach performed adequately so that discussion on the dominant predictors was prepared for the multi gcm approach of each station investigation on the dominant predictors at tabriz station denotes that the geopotential height i e zg is the dominant parameter almost in all selected grid points at various pressure levels i e zg1000 zg5000 zg7000 zg3000 zg15000 around the study station the geopotential height can be considered as a gravity adjusted height where the geopotential thickness between pressure levels i e the difference between consecutive geopotential heights is proportional to mean virtual temperature in that layer hofmann and moritz 2005 since temperature alteration leads to generation of winds which are principal cause of clouds displacement and rainfall production geopotential heights as the large scale variables can be effective in local rainfall production in this way the input screening methodology could detect nonlinear relationships between the geopotential height predictors and rainfall production at tabriz station dominant predictors of multi gcms at various grid points are depicted in table 2 which indicate that the relative humidity i e hur predictor at high pressure levels is the other dominant predictor the lack of moisture sources i e large water bodies around the study site has caused the hur predictor dominancy in the upper layers of the atmosphere than lower layers since tabriz is located in mountainous region the humidity from the faraway water bodies like the caspian sea can be transferred in high pressure levels hfls is the other predictor which became important according to table 2 the latent heat flux emerges as winds carry moisture of the urmia lake away from the surface and affects tabriz rainfall table 2 indicates that the dominant predictors which affect the ardabil station rainfall are humidity variables i e hur and hus geopotential height wind speed and mean temperature where all the predictors except mean temperature belong to the grid points located over the caspian sea the mean temperature impact on ardabil rainfall from the south east grid point according to table 2 hus is the dominant predictor of the grid points located on caspian sea at all three gcms selected in multi gcm approach for ardabil station it can be inferred that caspian sea as the principal moisture source impacts ardabil station rainfall however the dominant wind variable ua which is located at the east of station transfers the humidity from sea side to the station the proper choice of wind variable by the proposed methodology is compatible with the prevailing wind i e east west direction of the region the impact of zg from two eastern grids on ardabil rainfall implies the significance of temperature fluctuations on the sea thus wind that blows from east to west and transfers moisture to adjacent mountainous area where ardabil station is located 6 2 discussion on second step downscaling models according to tables 3 and 4 for both stations multi gcm approach outperformed single gcm so the combined use of several gcms could cover the uncertainties involved in each gcm and reduce the dependency on a single gcm model therefore multi gcm model could enjoy only effective characteristics of each gcm for future rainfall projection which has been recommended by some other studies as well li et al 2012 miao et al 2014 rashid et al 2015 according to tables 3 and 4 the consistency between selection of gcms for multi gcm approach and high performance single gcms in both stations indicates the ability of screening method in detecting dominant predictors among the most effective gcms in case of tabriz station selected dominant predictors are from csiro access1 gfdl esm2g and bnu esm gcms while the same gcms in the single gcm approach explained the maximum efficiency in terms of evaluation criteria in ann based modeling for the ardabil station the inm cm4 can esm2 and csiro access1gcms showed high performance in the single gcm model which are compatible with the dominant selections of multi gcm model results of tables 3 and 4 demonstrate that the ai based downscaling models outperform both mlr models in terms of evaluating criteria because mlr is not capable of distinguishing nonlinear relations among dominant predictors and the predictand however the remarkable point is that the mlr model with screened inputs outperforms the mlr model with inputs obtained from cc based method this outcome confirms the superiority of nonlinear screening method to the linear method also the comparison of table 5 with tables 3 and 4 reveals that neural ensemble model is the most efficient downscaling method suggested in the current study moreover fig 4 demonstrates that neural ensemble model could show reasonable trend of the observed data than individual ann lssvm and mlr models the reason for such improvement is that the neural ensemble model reinforces the strengths of each model and weakenes the poor forecasting of individual models i e ann lssvm and mlr by assigning proper weights through training phase overall the comparison of downscaling results in tabriz and ardabil stations denotes to poor results for ardabil than tabriz so generalization of the same gcms to the different cases seems not to be a good idea since developed methodology has the ability to handle big data it is suggested to use all available gcms as the inputs of the screening model and let the model to select the dominant gcms for each region 6 3 discussion on third step rainfall projection for future according to fig 5a the mean annual rainfall value of ardabil station is more than tabriz station and baseline calibrated rainfall values at both stations match observed data with smaller difference for the tabriz station which indicates better performance of methodology for that station however the data dispersion is reduced in calibrated neural ensemble model which is an evident fact in any developed model because model generated data in comparison to observed data show less fluctuations and tend to deterministic state than stochastic the comparison of the annual observed and simulated rainfall values at both stations demonstrates that tabriz station rainfall will decrease in future under both the rcps while in the ardabil station it will increase the intensity of rainfall pattern change in both stations at distant future will be slightly severe than near future the comparison of rcps denotes that both greenhouse gas concentration trajectories i e rcps 4 5 and 8 5 show similar performance in the future rainfall projection of the region at tabriz station although the simulated model shows decreasing trend in annual average rainfall seasonal projections paint future rainfall of station from other viewpoint in fig 5b for tabriz station except spring during all other seasons under both rcps rainfall mean and variance will decrease even extreme events of rainfall which are more plausible in autumn and winter will be less than mean observed rainfall during the baseline it means water resource managers should be aware that during the spring it will be more important to preserve water resources and collect surface water in order to benefit from it during the next three dry seasons for the ardabil station the seasonal rainfall pattern in the upcoming years will be incremental during spring and summer subtractive during autumn and almost constant during winter with regard to the bassline fig 6 depicts annual variations of rainfall for the observed and simulated values under both rcps 4 5 and 8 5 the figure indicates that changes in annual rainfall encompass year to year variations with the considerable decreasing and increasing trends in future for tabriz and ardabil stations respectively furthermore in each diagram of fig 6 a break point is considered in the time series between the observation and the projection time series the reason for this break point is two different source of data observation time series with stochastic characteristic is non stationary and shows trend while projected time series generated from gcm based data based on computational out comes is stationary and without trend therefore break points are inevitable in transiting from observation to projection phase it is noted that it s common to see the projected predictand with confidence interval so the uncertainty for future prediction due to the uncertainty involved in the phenomenon should be also considered in addition to the deterministic trace however precise determination of such interval requires knowledge on pdf of involved parameters and its simulation is out of the scope of current study but in fig 6 the upper and lower bonds of confidence interval of the predictand assuming normal pdf for output has been drawn up 7 concluding remarks since rainfall is an important parameter in developing hydrologic impact studies for future rainfall prediction of the two stations namely tabriz and ardabil were assessed by the ai based statistical gcm downscaling models five various gcms with the single and multi gcm input approaches were used in downscaling models under the rcps 4 5 and 8 5 the novel we som predictor screening methodology was used to select the dominant predictors among huge number of input candidates the advantages of the proposed predictor screening method are its ability to handle non stationary effects of predictors diminishing the dimensionality of data and obtaining dominant input by detecting nonlinear relation between predictors and predictand although the proposed screening methodology with different mathematical tools seems to be complicated which may be considered as a limitation of modeling the selection of optimum variables i e 9 variables among 1920 potential variables resulted in the establishment of a robust and suitable downscaling model downscaling via ai based i e ann and lssvm models was performed after predictor screening step the comparison of the linear i e mlr and nonlinear i e ann and lssvm regression models indicated that ai based models could be more efficient than linear method the superior neural ensemble model was then established based on the outputs of the three individual downscaling models i e ann lssvm and mlr which showed 60 and 64 performance improvement in terms of dc at validation step over individual ann model for tabriz and ardabil stations respectively in contrast to some researches which select the predictors from grid points with minimum distance from the study station the present study showed that sometimes the distance cannot be a suitable criterion for choosing an effective grid point and predictor in the last step future rainfall of tabriz and ardabil stations under the rcps 4 5 and 8 5 were projected results of the simulations indicated that according to intermediate and high emission scenarios the tabriz station rainfall will decrease in average i e 41 40 and high emission i e 35 42 scenarios respectively in addition ardabil station rainfall will display increase 6 12 under rcp 4 5 and 5 13 under rcp 8 5 respectively during near and distant future overall the results of this study provide promising evidence for statistical downscaling and more specifically for the proposed we som input screening method to select climate variables the application of we som screening method to downscale other climatologic parameters of the stations e g temperature can be considered as a topic for future studies moreover the proposed downscaling method can be compared with statistical and dynamical downscaling models other than the mlr which was used in this study in this way due to the different abilities of artificial intelligence and machine learning methods it may be suggested to use other kinds of ai models and clustering approaches 
7024,radioactive pollutants enter the subsurface hydrology environment commonly because of operation or accidental leakage from nuclear sites in some occasions heterogeneity in the groundwater system controls the fate of water transport in the aquifer it determines how contaminated groundwater change at site boundary assumption of uniform and homogeneous conditions in subsurface hydrology will lead to unpredictable errors in the decision when initiating a protection program for groundwater this study presents a novel process to establish a practical procedure of reliability and risk assessment for a quaternary aquifer relating to hypothetical nuclear facility installed on the ground surface this research performs reliability and risk analysis considering specified limit as resistance and in situ groundwater condition as load it shows a safety state of the studied site regarding the records of radioactivity in the aquifer it demonstrates a novel result of groundwater at different observation locations and natural environment discharge point associated to reliability issue and represents recommendation for the use of groundwater or environmental monitoring as safety protection of the studied site keywords groundwater reliability risk uncertainty radioactive release 1 introduction the entry of chemical pollutants into the natural environment is usually because of accident operations from industrial facility geological heterogeneities commonly control the fate of groundwater moving in the aquifer in order to predict flow and transport in groundwater system under certain circumstances accurately uniform and homogeneous conditions may not be adequate for the some cases it perhaps raises possible uncertainty to the design of decisive program for remediation during the in situ investigation stage ivanov and angelova 2017 represent the investigations of groundwater sources in bulgaria and indicate concentrations of toxic elements or metal ions exceeding the maximum contaminant values the main problems standing before the companies exploiting groundwater sources with chemical pollution were associated with the choice of an economically beneficial alternative guaranteeing the safety of water used for drinking household and industrial purposes ivanov and angelova 2017 moreno and paster 2018 perform the prediction of pollutant remediation in a heterogeneous aquifer in israel risk analysis for the migration of the plume showed that the ability of the current configuration of the remediation wells to control the plume is limited to the top layers of the aquifer there is a significant risk that the plume will migrate downstream towards production wells without being noticed using the present monitoring network shih et al 2002 and shih 2007 derived analytical solutions for the transport of radioactive nuclides in fracture media shih 2004 used first order differential analysis to derive the analytical form of expectation and variance for contaminant transport by regarding uncertainties of both dispersion coefficient and retardation factor shih 2011 studied analytical one dimensional transport considering multiple members of a decay chain in a single rock fracture it used the input sources for constant pulse impulse heaviside and exponential decay to verify the suitability of the solutions and demonstrate an application to a hybrid test site for a preliminary study for the disposal of spent nuclear fuel however the above mentioned studies commonly used for the idealized groundwater system and cannot be applicable for the type of heterogeneous one the great east japan earthquake and tsunami of march 2011 severely damaged three reactors at the fukushima daiichi nuclear power station and led to a major release of radiation into the environment marui and gallardo 2015 groundwater flow through the crippled reactors continues to be one of the main causes of contamination and associated transport of radionuclides into the pacific ocean it presents an overview of the methods that can manage groundwater contamination and mitigate the impact of hydrological pathways in the dispersion of radionuclides at fukushima a common remedial strategy to deal with contaminated groundwater is to extract the contaminated water and treat it at the surface prior to discharge or reinjection the earlier studies provide many application cases usepa 1995 nrmrl 1995 bass et al 2000 kirtland and aelion 2000 khan et al 2004 uncertainty associated with hydrogeological conditions in an aquifer is not fully quantifiable it often lacks enough knowledge like information regarding site data predictable model or process to determine future outcomes precisely in addition to imperfect awareness uncertain factors are usually subject to a certain level of error due to their heterogeneous characteristics the purpose of reliability and risk analysis is to obtain statistical information to identify how to reduce the impact of uncertainty and make the best choices for decisions incorporating reliability and risk analysis into understanding the performance of a system is a way of improving the quality of decision making process the main purpose of this research is to provide a novel approach to measure uncertainty quantifying risks associated with radioactive release in the subsurface water environment of a quaternary aquifer by considering specified limit as resistance and monitored in situ groundwater condition as load it regards the limitation as a designed radioactive capacity or scheduled safety strength of a natural subsurface water system and in situ monitored groundwater condition is a recognized force or contamination load affecting on the natural environment finally it addresses adequate deployment of a groundwater monitoring well accordingly advanced long term remediation can become feasible in no doubt by checking water quality at a suggested location this paper present a useful and achievable assessment including conceptual design probabilistic method and reliability calculation to illustrate the application of the research the process used in the present study is also appropriate to the other risk based studies of surface or subsurface hydrology system 2 background information the studied site designed in 2010 and designated as a studied area with credible protection dedicated to the research and development for the purpose of nuclear safety and technologies in order to explore unseen events related to a spill or leakage associated to radionuclides released in environment or other subsurface contamination in the future a hypothetical and hybrid studied site hhs was built for the planned mission undergoing a long time for nuclear research it may require building standard procedures to evaluate any remedial actions taken in response to the quantity of the spill or leakage therefore it uses the risk based probability calculation and procedure to build any necessary steps for future remediation controls the site hhs is located in the north of taiwan recent alluvium with local thin sediments lateritic terrace gravel with clay and gravel beds constitute geological strata in the quaternary from the surface down to the bedrock the thickness of the gravel bed is about 24 m table 1 water table approximately ranged from 16 m to 17 m below surface the sandstone bed generally distributed nearly on the bottom of gravel layer the groundwater well tapped in unconfined gravel aquifer with a diameter of 4 in and depth of 24 m fig 1 illustrates the conceptual layout of this study the site was located on the top of a double plateau of a gravel formation it presents a slope ranging from 45 to 65 degree from the top plateau to the second and groundwater level is higher than the ground in the second plateau the strike and face of the slope trends to east north and east south respectively there is a natural spring discharging at the junction of the top and second plateau and regards as the outlet of groundwater release from the subsurface of hhs the equipped monitoring devices in a series of groundwater wells in aquifer system along the site boundary label as a to e fig 1 gross beta activity is an indicator of beta emitting isotopes in water the occurring radioactivity in groundwater is to be indicative of radioactive releases from the site the gross beta activity observed at the spring outlet and groundwater wells a to e are the load for a risk assessment for the general purpose of investigation a hypothetical value is used as a resistance or strength that stresses the radioactive release of groundwater into the human environment this study specifies the rule that gross beta activity for groundwater must be less than 1 8 bq l it designates as the limit of resistance lr to address the impact of radioactive release in groundwater at the hhs regarding hydrological environment it is necessary to observe in situ groundwater conditions and assess safety issues by risk based probability calculations however it is cost effective if one monitor groundwater condition in the key position of site boundary the chance of unexceeding or exceeding the specified limit regard as the possibility of system safety or failure respectively it then focuses the probabilistic calculation and risk assessment with uncertainty measures substantially 3 reliability and risk analysis the key to designing in reliability and risk assessment for a system is to identify loads and resistances correctly it refers to force and strength capacity on that system respectively the resistance defines as the ability of system to achieve the determined purposes without failure when it is under loads sometimes the resistance also indicates a rule to follow the defined limit therefore recognizing the load resistance and all factors associated with uncertainty is a necessary step in risk and reliability analysis the earlier studies provided many cases associated with the reliability analysis considering load resistance interference cornell 1969 ang and cornell 1974 tung et al 2005 singh et al 2007 many factors applied to measure the uncertainty of a system one way to measure the degree of uncertainty is to apply statistical moments in various orders useful statistical moments in this case are mean and variance of random variables mean μ x is the first central moment that illustrates the expected value of a variable x while variance σ x 2 is the second order moment of a variable and demonstrates the scatter of a random variable coefficient of variation cv which is defined as the ratio of the standard deviation of variable σ x to its mean indicates to the level of uncertainty it is also used as a normalized measure of uncertainty to be compared in various conditions or factors moreover the systematic measure of uncertainty is the calculated probability density function pdf of desired uncertain variables it suggests that derivation of the statistical moments and probability density function of random variables are the important parts of uncertainty analysis reliability or the probability of non failure define as an ability of system to satisfy their design functions and it is commonly measured by studying the interaction of load and resistance based on probabilistic analysis when a system is reliable the resistance of system r exceeds the load l while if load exceeds resistance the system cannot achieve the defined purposes and it is unreliable analytically the probability of reliability for a system p s defined as tung et al 2005 1 p l r p s 1 p f where p is the probability p s is the probability of non failure or reliability and p f is the probability of failure the safety margin s m is the same as the safety factor it defines as the difference between system resistance and expected loads 2 s m r l thus the reliability of a system in terms of safety margin is written as 3 p s p r l 0 p s m 0 evaluation reliability using eq 3 does not take the time dependent property of the load and resistance into consideration furthermore it applied the procedure generally when system performance is subject to a single and special worst load event the resistance and load are usually functions of several stochastic variables in a system consider resistance and load as 4 r ρ x r ρ x 1 x 2 x i and 5 l λ x l λ x 1 x 2 x i where x 1 x 2 x i are stochastic variables the reliability calculated as 6 p s p λ x l ρ x r if the performance function ζ consider as a function of load and resistance system reliability thus identify as 7 ζ x r x l ρ x r λ x l where ζ x r x l is the performance function for every load and associated resistance reliability index initially was introduced by cornell 1969 and later ang and cornell 1974 formularized it to measure the reliability of an engineering system the reliability index is defined as the ratio of mean to standard deviation of performance function ζ as 8 β μ ζ σ ζ where μ ζ and σ ζ are the mean and standard deviation of ζ since normal distribution frequently used to perform function ζ x in a system tung et al 2005 the reliability p s and risk p f are estimated simply as 9 p s θ β and 10 p f 1 θ β where θ is the standard normal cumulative density function cdf it is the probability that θ will take a value less than or equal to β on this basis the probability of failure is as singh et al 2007 11 p f p ζ 0 replacing safety margin s m in eq 2 by a new variable of ζ for performance function it has 12 ζ r l hence the mean and variance of ζ are 13 μ ζ μ r μ l and 14 σ ζ 2 σ r 2 σ l 2 2 cov r l when variables are independent the reliability index is as 15 β μ ζ σ ζ μ r μ l σ r 2 σ l 2 if resistance and load follow a lognormal distribution for a possible situation such as spatial distribution type dayton 2018 the performance function can consider as 16 ζ x ln r ln l its statistical moments mean and variance can be calculated as 17 μ ζ μ ln r μ ln l and 18 σ ζ 2 σ ln r 2 σ ln l 2 2 cov ln r ln l if r and l considered as independent variables for each other it has 19 σ ζ 2 σ ln r 2 σ ln l 2 reliability index is as singh et al 2007 20 β μ ln r μ ln l σ ln r 2 σ ln l 2 4 result and discussion the term system associated to the reliability calculation of this study defines as the total net outcome of in situ radioactive release of groundwater against a specified limit of resistance regarding the safety assessment in the studied site it selects seven scenarios in this study table 2 the system loads defines as gross beta activity observed at the spring outlet and in groundwater in wells a to e and averaged value in all wells the averaged activity will be calculated using data observed on the same date statistical data for gross beta activity of groundwater sample collected through five years shows in table 2 it is worth noting that mean normalized gross beta activities are less than unity and ranged from 0 08 to 0 47 for all scenarios table 2 fig 2 the positive mean of performance function ζ calculated by eq 12 also indicates that the resistance overcomes the load for all scenarios table 3 it implies that the resistance exceeds the load or namely radioactive release in the groundwater is below the limit of resistance it should also be pointed out that the system presents higher certainty of gross beta activity at spring outlet and groundwater wells a and c due to lower value of standard deviation and variance table 2 fig 2 and on the other hand groundwater at well e presents higher uncertainty of gross beta activity relatively it uses eqs 9 and 10 to calculate the probability of system safety and failure in fact the resistance and load are the defined limit value lr for investigation and in situ observed gross beta activity of groundwater in wells respectively it is reasonable to assume that r and l are independent of each other in the nature of parameter choice the model of hydrodynamic dispersion predicts that the concentration curve will have a gaussian or normal distribution that is described by the mean and variance fetter 1999 if normal distribution applied for gross beta activity in groundwater eqs 12 to 15 can be used to perform a risk calculation under the designed scenarios groundwater at the spring outlet and at wells a and c sequentially represents higher values of the reliability index as well as demonstrating very high probability of reliability which also means having very low probability of failure table 3 clearly groundwater at well e shows the lowest reliability index and the highest probability of failure in comparison with other scenarios fig 3 moreover if it follows a lognormal distribution when using eqs 16 to 20 groundwater at spring outlet and groundwater wells c and a still represent higher reliability indexes with very high probability of reliability table 4 fig 4 it becomes evident that the groundwater at the spring outlet and at wells a and c are more suitable for long term observation locations this study suggests that the studied site presents a safe state based on statistical outcome of gross beta activity such as calculations of mean variance standard deviation performance function and reliability it is worthwhile to note that groundwater at the spring outlet and at wells a and c can verify the qualification of the site with a higher probability of reliability while groundwater at well e presents a limited extent of reliability apparently the spring outlet is at the site boundary it is a watch location when assessing the impact of radioactive release of groundwater to the biosphere environment in safeguarding in addition reliability and probability calculations for radioactivity of groundwater in site and spring outlet can also serve as better indicators to address the safety or failure of the subsurface water environment due to hypothetical operation of total system of hhs by comparing variability of calculated statistical data and the reliability index probabilistically the fate of transport in aquifer perhaps reflects variation to some extent between different locations of well in many cases the property of geological mixtures such as adsorption and retardation capability in the aquifer perhaps play the key role in nature it suggests that the spring outlet and groundwater wells a and c are a more suitable location regarding safety inspection this research develops a practical and easy procedure to qualify the safety or failure of a system regarding in situ radioactive activity of subsurface water environment for the studied site radioactivity in groundwater provides useful clues to improve top down management and responses to instances where the release of radioactive substances may happen for the purpose of demonstration radioactive releases induced by the hypothetical nuclear operation site are required to comply with the specified limit that is supposed to ensure protection of public health and safety reliability calculations with their statistical summary more or less reflect the heterogeneity in properties in existing aquifers consequently it establishes the procedure of reliability and risk analysis on how data utilize in the conceptual design for safety purposes and necessary actions implementing decision making for effective protection of groundwater furthermore objectives specified to quantifiable probability calculations provide a confidence level which can check compliance with specified limit effectively assessing the safety involving subsurface system using the procedure demonstrated by this study becomes feasible in the future 5 conclusion radioactive release in subsurface water environment in a nuclear installation may occur during its operation period the nature of the aquifer commonly dominate accurate prediction of groundwater transport and release to the human habitat however noting cost implications it is unlikely to build numerous monitoring wells at a site this study provides a novel process to establish a practical procedure for reliability and risk assessment of a hypothetical hybrid studied site considering specified limit as resistance and in situ natural groundwater condition as load it uses the limit of radioactive release in groundwater which meets the guide for the general purpose of investigation groundwater wells can be selected for long term monitoring at the locations that have greatest representative reliability if there is a need for early warning the sampling rate requires to enhancing e g increase temporal sampling rate or spatial sampling location once statistical significance reached it can initiate the necessary protection action at an early stage however if it announces a new or amended limit to address groundwater protection for radioactive releases of groundwater in the future the assessment of reliability and risk needs to revisit by update data acknowledgement the author thanks editor in chief dr geoff syme and dr simon norris radioactive waste management uk and anonymous reviewer for their helpful comments to complete the publication 
7024,radioactive pollutants enter the subsurface hydrology environment commonly because of operation or accidental leakage from nuclear sites in some occasions heterogeneity in the groundwater system controls the fate of water transport in the aquifer it determines how contaminated groundwater change at site boundary assumption of uniform and homogeneous conditions in subsurface hydrology will lead to unpredictable errors in the decision when initiating a protection program for groundwater this study presents a novel process to establish a practical procedure of reliability and risk assessment for a quaternary aquifer relating to hypothetical nuclear facility installed on the ground surface this research performs reliability and risk analysis considering specified limit as resistance and in situ groundwater condition as load it shows a safety state of the studied site regarding the records of radioactivity in the aquifer it demonstrates a novel result of groundwater at different observation locations and natural environment discharge point associated to reliability issue and represents recommendation for the use of groundwater or environmental monitoring as safety protection of the studied site keywords groundwater reliability risk uncertainty radioactive release 1 introduction the entry of chemical pollutants into the natural environment is usually because of accident operations from industrial facility geological heterogeneities commonly control the fate of groundwater moving in the aquifer in order to predict flow and transport in groundwater system under certain circumstances accurately uniform and homogeneous conditions may not be adequate for the some cases it perhaps raises possible uncertainty to the design of decisive program for remediation during the in situ investigation stage ivanov and angelova 2017 represent the investigations of groundwater sources in bulgaria and indicate concentrations of toxic elements or metal ions exceeding the maximum contaminant values the main problems standing before the companies exploiting groundwater sources with chemical pollution were associated with the choice of an economically beneficial alternative guaranteeing the safety of water used for drinking household and industrial purposes ivanov and angelova 2017 moreno and paster 2018 perform the prediction of pollutant remediation in a heterogeneous aquifer in israel risk analysis for the migration of the plume showed that the ability of the current configuration of the remediation wells to control the plume is limited to the top layers of the aquifer there is a significant risk that the plume will migrate downstream towards production wells without being noticed using the present monitoring network shih et al 2002 and shih 2007 derived analytical solutions for the transport of radioactive nuclides in fracture media shih 2004 used first order differential analysis to derive the analytical form of expectation and variance for contaminant transport by regarding uncertainties of both dispersion coefficient and retardation factor shih 2011 studied analytical one dimensional transport considering multiple members of a decay chain in a single rock fracture it used the input sources for constant pulse impulse heaviside and exponential decay to verify the suitability of the solutions and demonstrate an application to a hybrid test site for a preliminary study for the disposal of spent nuclear fuel however the above mentioned studies commonly used for the idealized groundwater system and cannot be applicable for the type of heterogeneous one the great east japan earthquake and tsunami of march 2011 severely damaged three reactors at the fukushima daiichi nuclear power station and led to a major release of radiation into the environment marui and gallardo 2015 groundwater flow through the crippled reactors continues to be one of the main causes of contamination and associated transport of radionuclides into the pacific ocean it presents an overview of the methods that can manage groundwater contamination and mitigate the impact of hydrological pathways in the dispersion of radionuclides at fukushima a common remedial strategy to deal with contaminated groundwater is to extract the contaminated water and treat it at the surface prior to discharge or reinjection the earlier studies provide many application cases usepa 1995 nrmrl 1995 bass et al 2000 kirtland and aelion 2000 khan et al 2004 uncertainty associated with hydrogeological conditions in an aquifer is not fully quantifiable it often lacks enough knowledge like information regarding site data predictable model or process to determine future outcomes precisely in addition to imperfect awareness uncertain factors are usually subject to a certain level of error due to their heterogeneous characteristics the purpose of reliability and risk analysis is to obtain statistical information to identify how to reduce the impact of uncertainty and make the best choices for decisions incorporating reliability and risk analysis into understanding the performance of a system is a way of improving the quality of decision making process the main purpose of this research is to provide a novel approach to measure uncertainty quantifying risks associated with radioactive release in the subsurface water environment of a quaternary aquifer by considering specified limit as resistance and monitored in situ groundwater condition as load it regards the limitation as a designed radioactive capacity or scheduled safety strength of a natural subsurface water system and in situ monitored groundwater condition is a recognized force or contamination load affecting on the natural environment finally it addresses adequate deployment of a groundwater monitoring well accordingly advanced long term remediation can become feasible in no doubt by checking water quality at a suggested location this paper present a useful and achievable assessment including conceptual design probabilistic method and reliability calculation to illustrate the application of the research the process used in the present study is also appropriate to the other risk based studies of surface or subsurface hydrology system 2 background information the studied site designed in 2010 and designated as a studied area with credible protection dedicated to the research and development for the purpose of nuclear safety and technologies in order to explore unseen events related to a spill or leakage associated to radionuclides released in environment or other subsurface contamination in the future a hypothetical and hybrid studied site hhs was built for the planned mission undergoing a long time for nuclear research it may require building standard procedures to evaluate any remedial actions taken in response to the quantity of the spill or leakage therefore it uses the risk based probability calculation and procedure to build any necessary steps for future remediation controls the site hhs is located in the north of taiwan recent alluvium with local thin sediments lateritic terrace gravel with clay and gravel beds constitute geological strata in the quaternary from the surface down to the bedrock the thickness of the gravel bed is about 24 m table 1 water table approximately ranged from 16 m to 17 m below surface the sandstone bed generally distributed nearly on the bottom of gravel layer the groundwater well tapped in unconfined gravel aquifer with a diameter of 4 in and depth of 24 m fig 1 illustrates the conceptual layout of this study the site was located on the top of a double plateau of a gravel formation it presents a slope ranging from 45 to 65 degree from the top plateau to the second and groundwater level is higher than the ground in the second plateau the strike and face of the slope trends to east north and east south respectively there is a natural spring discharging at the junction of the top and second plateau and regards as the outlet of groundwater release from the subsurface of hhs the equipped monitoring devices in a series of groundwater wells in aquifer system along the site boundary label as a to e fig 1 gross beta activity is an indicator of beta emitting isotopes in water the occurring radioactivity in groundwater is to be indicative of radioactive releases from the site the gross beta activity observed at the spring outlet and groundwater wells a to e are the load for a risk assessment for the general purpose of investigation a hypothetical value is used as a resistance or strength that stresses the radioactive release of groundwater into the human environment this study specifies the rule that gross beta activity for groundwater must be less than 1 8 bq l it designates as the limit of resistance lr to address the impact of radioactive release in groundwater at the hhs regarding hydrological environment it is necessary to observe in situ groundwater conditions and assess safety issues by risk based probability calculations however it is cost effective if one monitor groundwater condition in the key position of site boundary the chance of unexceeding or exceeding the specified limit regard as the possibility of system safety or failure respectively it then focuses the probabilistic calculation and risk assessment with uncertainty measures substantially 3 reliability and risk analysis the key to designing in reliability and risk assessment for a system is to identify loads and resistances correctly it refers to force and strength capacity on that system respectively the resistance defines as the ability of system to achieve the determined purposes without failure when it is under loads sometimes the resistance also indicates a rule to follow the defined limit therefore recognizing the load resistance and all factors associated with uncertainty is a necessary step in risk and reliability analysis the earlier studies provided many cases associated with the reliability analysis considering load resistance interference cornell 1969 ang and cornell 1974 tung et al 2005 singh et al 2007 many factors applied to measure the uncertainty of a system one way to measure the degree of uncertainty is to apply statistical moments in various orders useful statistical moments in this case are mean and variance of random variables mean μ x is the first central moment that illustrates the expected value of a variable x while variance σ x 2 is the second order moment of a variable and demonstrates the scatter of a random variable coefficient of variation cv which is defined as the ratio of the standard deviation of variable σ x to its mean indicates to the level of uncertainty it is also used as a normalized measure of uncertainty to be compared in various conditions or factors moreover the systematic measure of uncertainty is the calculated probability density function pdf of desired uncertain variables it suggests that derivation of the statistical moments and probability density function of random variables are the important parts of uncertainty analysis reliability or the probability of non failure define as an ability of system to satisfy their design functions and it is commonly measured by studying the interaction of load and resistance based on probabilistic analysis when a system is reliable the resistance of system r exceeds the load l while if load exceeds resistance the system cannot achieve the defined purposes and it is unreliable analytically the probability of reliability for a system p s defined as tung et al 2005 1 p l r p s 1 p f where p is the probability p s is the probability of non failure or reliability and p f is the probability of failure the safety margin s m is the same as the safety factor it defines as the difference between system resistance and expected loads 2 s m r l thus the reliability of a system in terms of safety margin is written as 3 p s p r l 0 p s m 0 evaluation reliability using eq 3 does not take the time dependent property of the load and resistance into consideration furthermore it applied the procedure generally when system performance is subject to a single and special worst load event the resistance and load are usually functions of several stochastic variables in a system consider resistance and load as 4 r ρ x r ρ x 1 x 2 x i and 5 l λ x l λ x 1 x 2 x i where x 1 x 2 x i are stochastic variables the reliability calculated as 6 p s p λ x l ρ x r if the performance function ζ consider as a function of load and resistance system reliability thus identify as 7 ζ x r x l ρ x r λ x l where ζ x r x l is the performance function for every load and associated resistance reliability index initially was introduced by cornell 1969 and later ang and cornell 1974 formularized it to measure the reliability of an engineering system the reliability index is defined as the ratio of mean to standard deviation of performance function ζ as 8 β μ ζ σ ζ where μ ζ and σ ζ are the mean and standard deviation of ζ since normal distribution frequently used to perform function ζ x in a system tung et al 2005 the reliability p s and risk p f are estimated simply as 9 p s θ β and 10 p f 1 θ β where θ is the standard normal cumulative density function cdf it is the probability that θ will take a value less than or equal to β on this basis the probability of failure is as singh et al 2007 11 p f p ζ 0 replacing safety margin s m in eq 2 by a new variable of ζ for performance function it has 12 ζ r l hence the mean and variance of ζ are 13 μ ζ μ r μ l and 14 σ ζ 2 σ r 2 σ l 2 2 cov r l when variables are independent the reliability index is as 15 β μ ζ σ ζ μ r μ l σ r 2 σ l 2 if resistance and load follow a lognormal distribution for a possible situation such as spatial distribution type dayton 2018 the performance function can consider as 16 ζ x ln r ln l its statistical moments mean and variance can be calculated as 17 μ ζ μ ln r μ ln l and 18 σ ζ 2 σ ln r 2 σ ln l 2 2 cov ln r ln l if r and l considered as independent variables for each other it has 19 σ ζ 2 σ ln r 2 σ ln l 2 reliability index is as singh et al 2007 20 β μ ln r μ ln l σ ln r 2 σ ln l 2 4 result and discussion the term system associated to the reliability calculation of this study defines as the total net outcome of in situ radioactive release of groundwater against a specified limit of resistance regarding the safety assessment in the studied site it selects seven scenarios in this study table 2 the system loads defines as gross beta activity observed at the spring outlet and in groundwater in wells a to e and averaged value in all wells the averaged activity will be calculated using data observed on the same date statistical data for gross beta activity of groundwater sample collected through five years shows in table 2 it is worth noting that mean normalized gross beta activities are less than unity and ranged from 0 08 to 0 47 for all scenarios table 2 fig 2 the positive mean of performance function ζ calculated by eq 12 also indicates that the resistance overcomes the load for all scenarios table 3 it implies that the resistance exceeds the load or namely radioactive release in the groundwater is below the limit of resistance it should also be pointed out that the system presents higher certainty of gross beta activity at spring outlet and groundwater wells a and c due to lower value of standard deviation and variance table 2 fig 2 and on the other hand groundwater at well e presents higher uncertainty of gross beta activity relatively it uses eqs 9 and 10 to calculate the probability of system safety and failure in fact the resistance and load are the defined limit value lr for investigation and in situ observed gross beta activity of groundwater in wells respectively it is reasonable to assume that r and l are independent of each other in the nature of parameter choice the model of hydrodynamic dispersion predicts that the concentration curve will have a gaussian or normal distribution that is described by the mean and variance fetter 1999 if normal distribution applied for gross beta activity in groundwater eqs 12 to 15 can be used to perform a risk calculation under the designed scenarios groundwater at the spring outlet and at wells a and c sequentially represents higher values of the reliability index as well as demonstrating very high probability of reliability which also means having very low probability of failure table 3 clearly groundwater at well e shows the lowest reliability index and the highest probability of failure in comparison with other scenarios fig 3 moreover if it follows a lognormal distribution when using eqs 16 to 20 groundwater at spring outlet and groundwater wells c and a still represent higher reliability indexes with very high probability of reliability table 4 fig 4 it becomes evident that the groundwater at the spring outlet and at wells a and c are more suitable for long term observation locations this study suggests that the studied site presents a safe state based on statistical outcome of gross beta activity such as calculations of mean variance standard deviation performance function and reliability it is worthwhile to note that groundwater at the spring outlet and at wells a and c can verify the qualification of the site with a higher probability of reliability while groundwater at well e presents a limited extent of reliability apparently the spring outlet is at the site boundary it is a watch location when assessing the impact of radioactive release of groundwater to the biosphere environment in safeguarding in addition reliability and probability calculations for radioactivity of groundwater in site and spring outlet can also serve as better indicators to address the safety or failure of the subsurface water environment due to hypothetical operation of total system of hhs by comparing variability of calculated statistical data and the reliability index probabilistically the fate of transport in aquifer perhaps reflects variation to some extent between different locations of well in many cases the property of geological mixtures such as adsorption and retardation capability in the aquifer perhaps play the key role in nature it suggests that the spring outlet and groundwater wells a and c are a more suitable location regarding safety inspection this research develops a practical and easy procedure to qualify the safety or failure of a system regarding in situ radioactive activity of subsurface water environment for the studied site radioactivity in groundwater provides useful clues to improve top down management and responses to instances where the release of radioactive substances may happen for the purpose of demonstration radioactive releases induced by the hypothetical nuclear operation site are required to comply with the specified limit that is supposed to ensure protection of public health and safety reliability calculations with their statistical summary more or less reflect the heterogeneity in properties in existing aquifers consequently it establishes the procedure of reliability and risk analysis on how data utilize in the conceptual design for safety purposes and necessary actions implementing decision making for effective protection of groundwater furthermore objectives specified to quantifiable probability calculations provide a confidence level which can check compliance with specified limit effectively assessing the safety involving subsurface system using the procedure demonstrated by this study becomes feasible in the future 5 conclusion radioactive release in subsurface water environment in a nuclear installation may occur during its operation period the nature of the aquifer commonly dominate accurate prediction of groundwater transport and release to the human habitat however noting cost implications it is unlikely to build numerous monitoring wells at a site this study provides a novel process to establish a practical procedure for reliability and risk assessment of a hypothetical hybrid studied site considering specified limit as resistance and in situ natural groundwater condition as load it uses the limit of radioactive release in groundwater which meets the guide for the general purpose of investigation groundwater wells can be selected for long term monitoring at the locations that have greatest representative reliability if there is a need for early warning the sampling rate requires to enhancing e g increase temporal sampling rate or spatial sampling location once statistical significance reached it can initiate the necessary protection action at an early stage however if it announces a new or amended limit to address groundwater protection for radioactive releases of groundwater in the future the assessment of reliability and risk needs to revisit by update data acknowledgement the author thanks editor in chief dr geoff syme and dr simon norris radioactive waste management uk and anonymous reviewer for their helpful comments to complete the publication 
