index,text
20995,marine icing phenomenon depends on multiple variables like vessel characteristics and uncertain factors like environmental parameters developing an accurate model for its forecasting evaluation and estimation is very challenging commonly most severe ice accretion is caused due to sea spray the past attempts to measure impinging sea spray flux were carried out on specific parts of the spray cloud and most of the empirical spray flux expressions presented only work in specific conditions this necessitates further real time and accurate field measurements of the entire impinging spray flux carried out in multiple scenarios in order to develop more practical correlation high temporal and spatial resolution measurements and scanning ability of the lidar technique has proven to be useful in the agricultural domain for studying pesticide spray drift this work reviews the past studies carried out using lidar technique for measuring the evolution of the pesticide spray cloud asserting the potential of using a shipborne lidar for analysing sea spray in the study of marine icing phenomenon the lidar system is capable to visualise the evolution of the sea spray drift with a high spatial and temporal resolution which can enable comprehensive real time measurement of spray flux for the entire sea spray cloud keywords lidar sea spray marine icing cold conditions ship stability 1 introduction earlier industries have not shown much interest in the colder regions of our planet due to their focus on exploiting resources in easily accessible warmer regions however with the increase in competition in warmer regions and the promising presence of natural resources shorter transport distances and tourism opportunities interest has grown to exploit these opportunities in marine cold climate regions shipping plays an integral part to utilise these opportunities as they are the preferred means for transportation carrying out surveying operations and also used as base stations the growth of interest is evident from the significant surge in maritime traffic in the last few years the total distance sailed by ships in the arctic polar code area grew by 75 in 2019 compared to 2013 and predicted to increase substantially in the coming years pame 2020 nevertheless colder regions bring their challenges due to its remoteness and harsh weather icing is regarded as the most significant risk associated with colder regions multiple vessels became disabled or sank after ice accretion leading to loss of life damaging environment and property aksyutin 1979 deangelis 1974 guest and luke 2005 hay 1956 lundqvist and udin 1977 ntsb 2018 ryerson 2013 shekhtman 1968 shellard 1974 even after many years of research advancement in analytical and numerical models marine icing still possess a serious operational hazard for ships operating in cold climate regions cammaert 2013 hence it is crucial prior entering these regions to winterize a vessel effectively which incorporates structural designs and techniques by adequate anti or de icing insulation and drainage system to decrease the adverse effects of icing and exposure to cold temperature dnvgl 2019 past analysis of icing observations on ships depending on the geographical location indicated typically sea spray alone contributed 50 97 spray along with atmospheric icing 41 1 4 and atmospheric icing alone 4 1 towards accumulation of marine icing over the vessels aksyutin 1979 brown and roebber 1985 kato 2012 makkonen 1984 1984 1984 panov 1976 shekhtman 1968 shellard 1974 zakrzewski 1987 sea spray ice accretion possess a substantial hazard to a vessel s seaworthiness as navigation communication safety and other essential or critical equipment may become impaired deck operation severely impacted and evacuation routes obstructed makkonen 1984 ryerson 2013 the most imminent danger associated due to ice accretion for a vessel is the loss of stability which may ultimately lead to capsizing guest and luke 2005 this paper focuses on the need for accurate real time measurement of impinging sea spray as the past researchers were only able to measure parts of a spray cloud and approximations were made based on the localised measured data hence there is a need for a different setup or a measuring technique which can measure the entire spray cloud in a comprehensive manner the lidar light detection and ranging technique has proven to be useful in the agricultural domain for studying pesticide spray drift measurement because of its measurement ability with high temporal and spatial resolution and scanning ability allard et al 2007 gregorio et al 2016b richardson et al 2017 torrent et al 2020 this shows the potential of using this technique in the field of marine icing for studying sea spray 2 sea spray icing and ship stability the loss of stability is primarily threatening for smaller ships like fishing vessels orimolade et al 2017 and almost 41 of ships entering the arctic polar code area are fishing vessels pame 2020 fishing vessels relatively have a lower freeboard and have a higher pitch angle and frequency hence spray generation is more frequent and likely to cover the whole ship the superstructure surface area is also large compared to its displacement making them more exposed to sea spray in the presence of low temperature the spray freezes across the vessel and a comparatively lesser weight of accreted ice can destabilize and capsize the fishing vessel guest and luke 2005 when the vessel is propelling into the wind and waves maximum ice accretion is on the forepart consequently trimming the vessel by head further intensifying incoming spray and green seas symmetric ice accretion transverse on the deck fig 1 accommodation tops and other higher parts shift the centre of gravity g upward and forward trim by head along the centre line which reduces the metacentric height gmt this affects the dynamic performance by weakening righting lever gz the ship s ability to upright when heeled by external forces which is readily evident from the increase in the natural rolling period also increase in heave and pitch period in a lesser extent wold 2014 also the deck edge immersion angle is reduced due to reduced freeboard extra weight of the ice causing water ingression at a smaller angle of heel than initial the vanishing angle of stability is reduced which is an indicator of the overall range of stability chung 1995 due to ice accretion the wind drag and sail area of the vessel increases leading to an increase in the wind induced heeling moment gradually with the increase in ice load the metacentric height keeps decreasing to negative eventually unable to upright leading to its capsizing depending on the relative direction of wind and waves an asymmetrical sea spray ice accretion can cause the centre of gravity to shift upward and away from centre line causing the vessel to list further increasing its tendency to capsize chung 1995 the international code on intact stability 2008 is code imo 2020 and the polar code imo 2016 includes allowance for ice accretion 30 kg m 2 on exposed weather decks and gangways and 7 5 kg m 2 for the projected lateral area of each side of the ship above the water plane which should be incorporated in the stability calculation for ships at risk of icing ensuring its adequate stability 3 sea spray ice accretion typically sea spray ice accretion can be divided into three parts 3 1 sea spray cloud generation the high energy impact of wave and ship results in the formation of water sheet along its hull as the water sheet upsurges above the water level air enters and the sheet break into drops and gradually forms a cloud of droplets dehghani et al 2016a these generated droplets reach variable heights and velocities depending on the kinetic energy of the collision and diameters ranging from 10 μm to 3 mm close to the bow bodaghkhani et al 2016 rashid et al 2016 ryerson 2013 zakrzewski 1986 the wave generated spray is a significant source of water flux which is the main contributor for marine ice accretion and often formed close to the vessel s bow depending on relative motion and likely have a short and periodical frequency hansen 2012 sea spray may also be generated by strong wind shearing droplets off wave crest and by bubbles bursting in breaking waves creating atomized droplets ranging 1 μm to 25 μm fuentes et al 2010 wind generated droplets usually have a relatively much lesser but continuous contribution to the icing phenomena dehghani sanij et al 2015 3 2 sea spray cloud drift and impinging upon the ship s structure the sea spray cloud generated is then carried by the airflow across the vessel until finally impacting components or structures on the vessel the droplets in the cloud of different initial velocities sizes and shapes are influenced differently by wind and gravitational force and their paths and trajectories are specified through drag force body forces and added mass force acting on it dehghani et al 2016a kulyakhtin and tsarau 2014 makkonen 2000 the wind carries the small droplets with their velocities nearly become similar to the velocity of the wind but the large droplets being affected more by the gravitational force shortly drops on the deck or back to the sea the larger and smaller droplets are not able to reach the highest elevation of the spray while the trajectory of the medium sized droplets makes it dehghani et al 2016b the characteristics of the spray droplets may change anytime along their path may reduce in size due to evaporation or aerodynamic breakup or increase when combining with another droplet lozowski et al 2000 lwc liquid water content which is the total mass of the water droplets in a unit volume of dry air is an important parameter of incoming spray flux along with velocity and distribution of the droplets for icing calculation dehghani sanij et al 2017a the heat transfer vaporization and temperature change during the drift of the droplets are determined by the characteristics of the droplet like velocity and size dehghani sanij et al 2017a 2017b kulyakhtin and tsarau 2014 sultana et al 2018 the droplets undergo convective evaporative and radiative heat transfer cooling the droplets within the airflow during the drift and eventually supercooled when the supercooled droplets impact and splash on the substrate creates ice followed by running off brine water due to gravity and tensile stresses from the air forms a layer or film and at the same time losing heat via conduction convection and radiation kulyakhtin and tsarau 2014 ryerson 2013 the state of freezing droplets is reliant on properties like its size salt content and also the thermal behaviour of the substrate saha et al 2016 3 3 wet growth of ice from the brine water film the majority of the brine water film drains off from the ice surface entrapping a small amount leading to the growth of ice or wet growth makkonen 1987 the rate at which the brine film freezes and the consequent wet growth is dependent on the incoming water flux transported at different areas on the vessel and the rates at which latent and sensible heat extracted from these areas ryerson 1995 the sea salt precipitates with growth in ice thickness forming pure ice and pockets of brine rashid et al 2016 the primary heat fluxes at the air water interface contributing to the freezing of sea spray impinging at the accreted ice surface are convective or sensible heat flux from the air q c evaporative or latent heat flux from the air q e heating or cooling from impinging spray q d and heating or cooling from radiation q r kulyakhtin and tsarau 2014 samuelsen et al 2017 equation 1 latent heat released during freezing q f q c q e q d q r 4 need for real time data we had discussed how the spray cloud generated from wave and wind spray is the primary cause of icing on the vessel dehghani et al 2016b describes the process of spray cloud generation and its movement into several sub stages including wave impact water sheet breakup droplet breakup spray cloud generation its acceleration and deceleration and spray cloud fall and finally impingement however the physical behaviours of these stages are still inadequately understood characteristics of spray clouds such as its duration and movement in the airflow determining incoming water flux are an essential aspect to model the marine icing phenomenon kulyakhtin and tsarau 2014 the accurate prediction of marine icing and the quantity of ice accretion on the vessel structure is challenging mainly because of the variable quantity of incoming flux at different parts of the vessel which is affected by multiple parameters fig 2 at the same time past studies dehghani sanij et al 2015 horjen 2015 2013 kulyakhtin and tsarau 2014 lozowski et al 2000 shipilova et al 2012 did not consider the distribution and variation of droplet size and velocity in a spray cloud for their icing models dehghani et al 2016b the empirical models and nomograms for predicting icing severity comiskey et al 1984 itagaki 1977 kachurin et al 1974 makkonen 1984 mertins 1968 overland et al 1986 overland 1990 stallabrass 1980 sawada 1962 wise and comiskey 1980 were mostly built on data obtained from small to medium sized vessels and based on input parameters of atmospheric conditions which makes their applications confined to particular regions sultana et al 2018 also by investigating present analytical models it was found in order to make them more effective further research and precise measurements are required for calculating the thermo physical properties and heat transfer phenomena sultana et al 2018 the efficiency of the predicted icing rates even from the present advanced models of sea spray icing even with increased accuracy of the numerical prediction models depends on the correctness to which the complex and uncertain quantities like spray flux turbulent heat transfer and the freezing temperature are predicted samuelsen and graversen 2019 the significant difficulties in modelling spray cloud generation propagation and finally impingement are 1 the wave wind and environmental parameters are highly dynamic irregular interdependent and may have varied scenarios in the cold regions 2 the spray flux its liquid content the spray duration and frequency depend on the ship design its speed over water and heading with respect to the wind and waves and its dynamic behaviour ships of different geometry dimension and loading condition interact differently with sea conditions 3 there is a lack of understanding in the behaviour of the droplet during its propagation within the turbulent flow around different types of ship s structure and the near field biases caused by airflow alterations over the vessel this ultimately decides the distribution and quantity of incoming water flux at different locations on the vessel hence questions the reliability and versatility for predicting marine icing from the cfd models which is also restricted by uncertainties like spray generation method moreover all these models are lacking validation against field observations mintu et al 2016 this necessitates direct measurements to gather real time data of the concentration or spatial distribution of the entire impinging spray to remove errors from each step in order to develop more practical and functional equations the formulae used to calculate lwc in a spray cloud only presents an estimation dehghani sanij et al 2017a the different empirical correlations table 1 are obtained from observation for a distinct set of conditions and do not take into account different vessel parameters so they may provide incorrect results if generalised rashid et al 2016 wmo 1994 bodaghkhani et al 2016 dehghani et al 2016b reviewing past sea spray icing models mention that the lack of recording the distribution of size and velocity in a spray cloud led the researchers to use mono size and mono velocity models there is a lack of empirical observations consequently the analytical and numerical formulations are based only on a few actual field observations and not comprehensive data dehghani sanij et al 2017a hence there is a need for more accurate field measurement considering more parameters and scenarios 5 past sea spray field measurements some researchers carried out measurements in the past attempting to measure real time incoming sea spray on vessels to formulate or validate incoming spray flux or liquid water content correlation and model its distribution to estimate sea spray icing accurately tabata et al 1963 reported field measurements on a few japanese ships during which both ice accretion rate and the sea spray intensity were measured zakrzewski 1986 specially designed icing gauges consisting of a rod suspended in a weight gauge were placed over the ship to measure the icing rate and entrap the sea spray lundqvist and udin 1977 later tabata 1969 measured the spray amount and distribution on deck aboard a 350 metric ton patrol vessel with his instrument consisting of water absorption sheet toilet tissue in circular cylinder distributed across the forecastle which was replaced every 5 6 min interval then measured the added mass from spray events fluxes fluctuated from 0 06 to 0 98 kg m2 h depending upon the cylinder s location on the bow area and relative wind speed and wave direction ryerson 1995 brown and roebber 1985 used the above data sets to present a relation of the change of time averaged spray flux as a function of the ship s speed and heading zakrzewski 1986 ono 1964 measured ice growth rates and the sea spray intensity on patrol boats from the accreted amount of spray on an icing rod and collecting the excess runoff brine in a calibrated jar ozeki et al 2016 itagaki 1984 used this data as a function of air temperature and wind speed to estimate the ice accumulation rate on stationary structures sharapov 1971 study provided a data set from a medium fishing vessel mfv recording the spraying zone extent for wind speed from 5 to 11 beaufort later zakrzewski et al 1988 used this data for validating the model performance for his correlation for calculating the highest extent spray droplets from wave hull interaction which was based on field icing data from kuzniecov et al 1971 gashin s study mentioned in borisenkov panov 1972 provided the first direct measurement data for bow generated spray characteristics from the analysis conducted on a mfv of 35 m long soviet fishing trawler in his data the spray droplet diameters ranged between 1000 μm and 3500 μm with a mean of 2400 μm but his measurement methods environmental and sea conditions during his field trial and variations of his result with different vessel size are not known ryerson 1995 kachurin et al 1974 formulated the first lwc correlation as a function of wave height only based on measurement from a mfv but stated no information about the measurement technique borisenkov et al 1975 published data of spray cloud field measurement made on a mfv in the sea of japan reported ship and environmental parameters though information about droplet size and velocity distribution were are not stated the data was also used for producing empirical lwc formulation and succeedingly used by zakrzewski 1986 and brown and roebber 1985 for extending the formulation and later showed by samuelsen et al 2015 the variation in the empirical constant value varies from the previous study method of directly measuring spray flux was carried out in the 1980s on an artificial island tarsiut island to develop the rigice model the spray data collected from measuring the water level at hourly intervals in 45 gallon drums muzik and kirby 1992 as a part of the study program offshore icing horjen et al 1986 jørgensen et al 1986 measurement of spray flux was carried out on supply vessels stand by boats and offshore structures for calibrating the norwegian marine icing model icemod horjen 1990 the data is also utilized by the later developed icing models marice and numis spray measurements were carried out with absorption panels consisting of absorbent paper paper diapers and bent pipes collecting the impinging spray into a graduated container teigen et al 2019 but no information related to spray droplets were provided bodaghkhani et al 2016 ryerson 1995 was the first to carry out the real time measurement of sea spray on a larger ship cgc midgett 115 m length his experimental setup consisted of vertical and horizontal oriented funnel shaped spray collectors ultrasonic range finding ice detectors video recording systems and stroboscopic droplet camera characteristics of the spray cloud generation frequency duration height and distribution size were recorded also parameters such as sea and environmental conditions ship position speed and heading were logged for every hour the spray flux was measured at six different locations but the result presented was only for one location the reported incoming droplet size varied from 14 to 7700 μm and median of 234 μm the mean droplet concentration about 4χ105 droplets m3 the average cloud droplet concentration of 1 05 107 droplets m3 and average spray event duration 2 37 s was recorded dehghani et al 2016b he also attempted to form the lwc correlation but the comparison among his measurements and past lwc correlations were not satisfying though his result provided crucial data set however it was based on specimens from the spray cloud and not based on accounting for the entire distribution data set of the entire spray cloud and also the model did not include the droplet velocity data bodaghkhani et al 2016 dehghani et al 2016a jones and andreas 2013 collected sea spray at mt desert rock lighthouse catwalk at 20 m above sea level to inspect spray generated over the ocean instead from wave and shore impact and was observed under microscopic slides this project s long term goal is to estimate the sea spray concentration across the open ocean and sea spray icing on offshore constructions ozeki and sagawa 2013 modified a snow particle counter into seawater particle counter spc it consisted superluminescent diode light as a parallel ray measuring light attenuation by particles passing through the sensing area 25 mm wide 3 mm high and 0 5 mm deep the spc was able to measure the droplet size distribution impinging the sensing area every second and was placed on the upper deck of an ice breaker and the measuring range was set from 100 to 1000 μm in diameter by using the result the flux distribution and the transport rate could be approximated as a function of particle size johansen et al 2015 proposed a study of using a high speed camera for imaging sea spray and using image analysis hough transform for measuring the sea spray flux however the study could not be deployed for field test because other than the setup being too expensive most critically it required very sensitive lightning setup which is very difficult to control in the harsh marine climate ozeki et al 2016 modified a marine rain gauge to measure seawater spray in large ships and found a correlation in measurement with their previously developed seawater particle counter spc measurement of seawater spray was performed on the compass deck and the bow deck of an icebreaker teigen et al 2019 describes the real time autonomous measurement system designed by modifying a tipping bucket to collect sea spray to measure and record continuous flux on offshore facilities as part of the joint industry project rigspray the system fig 3 consists of flux meters consisting of a collector plate dimensions 0 5 m 0 5 m funnelling the impinging spray to a tipping bucket via a small hose the tipping bucket s water level is continuously measured with a wireless gauge pressure and the water empties automatically after reaching a certain level the system also includes a video recording system and can transmit the data wirelessly and has been in operation on the ship shaped fpso unit norne in the norwegian sea the project provides spray measurements data along with corresponding vessel motion and environmental dataset important for calibrating spray models on large ship shaped offshore structures the rigspray icing model bøckmann et al 2019 the measurement techniques and data collection and analysing procedures have improved over time and have proven to be helpful because of its simplicity and robustness in the harsh climates however the past studies were only able to measure samples of spray flux from some specific parts of a spray cloud and approximations were made on the basis of the localised measured data so for other conditions the droplet size and concentration need to be assessed for the entire spray cloud from the approximated proposed distribution also the prevailing micrometeorological conditions substantially affect the results during the field trials varyingly at different locations on the ship hence they fail to provide a factual comprehensive time resolved distribution data set for the entire spray cloud information the past studies could not provide about the entire impinging spray cloud such as its complete droplets distribution velocity and concentration which is inherent for the formulation of accurate correlation of spray flux vertical distribution and the spray cloud s maximum height therefore it is necessary to adopt different setups or measuring techniques which can carry out real time monitoring in spatial and temporal resolution to measure incoming sea spray flux for the complete spray cloud with higher efficiency and accuracy lidar light detection and ranging also known as laser radar is an optical sensing technique that has the potential to breaks through the shortcomings mentioned above as it is possible to use this technology for carrying out real time active measurement of entire spray cloud with high temporal and spatial resolution 6 lidar lidar is a long existing active range resolving optical measurement technique and commonly used for remote sensing and analysing of aerosols and clouds in atmospheric studies and presently has broad application throughout almost every field gregorio lópez 2012 hulburt 1937 mcmanamon 2019 lidar is a popular choice in atmospheric studies as it can provide high temporal and distance resolution due to the substantial interaction between the emitted electromagnetic radiation at optical wavelengths ranging from ultraviolet to near infrared and aerosols or molecular components in the atmosphere measures 1992 elastic lidar technique fig 4 is the most commonly used technique operating by the emitting pulsed lasers and detecting backscattered radiation at the same wavelength and the delay in receiving signal computes time of flight the distance equation 3 pulsed elastic lidars provide a range resolved intensity profile of the received signal following the principle of simple scattering this intensity profile follows the lidar equation expressed as received power component equation 2 collis and russell 1976 gregorio lópez 2012 other lidar techniques such as raman lidar inelastic differential absorption lidar dial and doppler lidar are also used in atmospheric studies receiver power equation 2 p λ r p o c τ l 2 β λ r a r r 2 e x p 2 0 r α λ r d r ξ λ ξ r p λ r receiver power w λ wave length nm r distance m p o peak transmitted power w c speed of light m s τ l emitted laser pulse duration s τ d temporal detection window s β λ r volumetric backscattering coefficient m sr a r e ffective area of the receiver telescope m 2 spatial resolution equation 3 δ r c τ l τ d 2 c τ d 2 τ l τ d α λ r volume extinction coefficient m ξ λ spectral transmissivity factor of the emission reception optical system ξ r overlap factor between the emitted laser beam and the receiver field view 7 past spray drift studies using lidar technology due to the high temporal and spatial resolution and latterly scanning ability lidar systems had been fairly utilized as a method for monitoring pesticide spray drift and particulate matters in the agricultural application some of the promising studies used for monitoring spray drift are mentioned which shows its potential to be used in the field of marine icing for analysing sea spray cloud the first research carried out by the u s forest service stanford research institute group in 1966 1967 investigating the use of lidar to monitor the dispersal of insecticide spray in the forests of idaho air motions were observed by tracking spray and smoke clouds and also displayed how turbulent and other diffusive processes can be analysed collis 1968 atmospheric environment service aes of canada constructed an elastic backscatter lidar system aral capable of fast attainment to analyse spray geometry and deposition of pesticides from an aerial application by scanning the cross section of the spray hoff et al 1989 later aral was used by mickle 1994 1996 to analyse the dynamics of the pesticide spray when aerially released lidar technology also had been used and proven to be an ideal tool to validate theoretical spray movement models and was able to expose the discrepancies in the models mickle 1999 stoughton et al 1997 tsai 2007 another elastic backscatter lidar was used to monitor aerially applied biological pesticide spray to support the hypothesis that a widespread dispersal of a small pesticide quantity is unavoidable even if the operation is adequately handled miller and stoughton 2000 miller et al 2003 used lidar ground spray measurements to create 3d images of the spray drift cloud above an orange farm hiscox et al 2006 introduced a methodology to estimate the spray cloud absolute concentration obtained from the lidar return signal from the spray application rate and the initial droplet size distribution theoretical models of evaporation and deposition were used to simulate droplet quantity s temporal evolution which remains in the air from aerial spray application they detected a satisfying correlation in the concentrations estimated from the derived model and the lidar return institute national d optique ino canada specially developed an eye safe close range 100 m lidar for the purpose of monitoring pesticide spray drift allard et al 2007 cantin et al 2007 prior this most studies used lidar systems whose design was architected for far range atmospheric studies the ino lidar prototype was tested to validate its performance in the applications of pesticide and dust cloud monitoring the digitized waveform fig 5 of the backscattered signals demonstrated that the equipment was able to monitor low signal levels from the water spray drifting cloud tested with water instead of real pesticide as well as high signal levels from solid targets like dust the result also showed the ability of lidar to present important measurement data regarding the relative concentration of airborne aerosols of diverse nature also at a shorter range allard et al 2007 khot et al 2011 describes the methodology used to report the application of calibrated lidar to quantify spray distribution across space and time the results exhibited a linear relationship r 2 0 77 between lidar backscatter signal of the spray plume and passive spray collection on samplers miller et al 2012 applied lidar to analyse spray drift from near ground aerosol fogs in several stability conditions concluding that spray coverage is more extensive under strong wind a commercial ultraviolet lidar system als 300 leosphere orsay france was used to monitor spray drift fig 6 for comparing with the measurements obtained from the passive collectors which is conventionally used for measuring pesticide spray drift the result of the analysis showed a strong linear correlation r 2 0 90 proving lidar to be a better alternative for monitoring pesticide spray drift with lesser time and resources gregorio et al 2014 an eye safe lidar system was explicitly designed for the purpose of spray drift monitoring gregorio et al 2015 with a scanning ability via pan and tilt unit up to 25 s and 12 s in azimuth and elevation gregorio et al 2016b the instrument has a laser emitter er glass laser of 1534 nm wavelength emitting pulses of 3 mj energy and 6ns duration a telescope with 80 mm aperture captures the backscattered light and it is directed on the photodetector surface of an avalanche photodiode apd module which converts the received light to electrical signal gregorio et al 2016b the temporal and spatial resolution and scanning capability of the lidar equipment were tested to observe real time behaviour of the drift cloud fig 7 and 8 under different spray conditions and the author claimed lidar to be an appropriate method to carry out drift measurement with much lesser time cost and labour compared to using passive collectors gregorio et al 2016a 2016b the past spray studies carried out in the agricultural domain provide evidence for lidar s temporal and spatial resolution capabilities to monitor the entire spray cloud s real time behaviour which the past sea spray studies failed to provide moreover the lidar system enables evaluation of the spray drift speed its concentration and evolution with time and ultimately providing a broader view these results are encouraging to propose this technique which can be valuable in the field of marine icing due to the similarities of pesticide spray with sea spray for studying the complex sea spray behaviour under different circumstances 8 shipborne lidar for sea spray measurement application of a lidar system suitable for shipborne use for the analysis of sea spray will encounter certain technical challenges that need to be incorporated during the selection of the equipment or during its design phase the ability for near range measurement with a high spatial and temporal resolution is essential besides the equipment being compact have low power consumption eye safe and able to withstand the harsh marine environment is also important 8 1 near range measurement using lidar conventional lidar systems were mainly designed for analysing and measuring tropospheric atmospheres hence they transmitted high power pulsed laser used ruby yag and ylf lasers till the mid 90s and had large aperture receiver telescopes in order to carry out far range measurements gregorio lópez 2012 the system used were complicated heavy high power consumption requiring highly skilled operators and costly ansmann et al 1997 fiocco and smullin 1963 sassen 1975 technological improvements in the last years concerning efficient low energy and high prf lasers and affordable photodetectors in the eye safe region let to rise in its application in near range observations such as aerosol flow imaging monitoring industrial emission gas leak detection etc edner et al 1995 fukuchi and shiina 2012 miya et al 2009 song et al 2020 micro pulse lidars mpl spinhirne 1993 1994 and modern commercial ceilometers madonna et al 2014 muenkel et al 2004 song et al 2017 paved the way for economical compact and convenient lidar systems development in laser technology with laser diodes ld and diode pumped solid state dpss further made lidar more compact and have found a widespread application kong et al 2018 s lolli et al 2011 a lidar deployed on ships for sea spray measurement should have the capability for short range measurement with a comparatively smaller field of view along with being compact with lesser power consumption and have to be reliable in the marine environment with state of the art advancements light emitting diode led based light source has become popular for short range measurements shiina and koyama 2010a from chiba university japan developed compact lightweight mini lidar with a light emitting diode led based light source for near range measurements around 0 100 m since then it had been utilized in widespread short range application from mars rover to atmospheric study among others koyama and shiina 2011 ong et al 2018 shiina 2010b 2013 2019a 2019b 2020 shiina et al 2015 2016 the led lamp module has a larger divergence compared to laser beams does not require a heat sink or fan and claims to be cheaper provide a wide range of wavelength choice lesser power consumption resilient against static electricity and has extended duration of use with consistent intensity shiina 2019a hence has a potential for onboard use for analysing sea spray 8 2 motion compensation a lidar mounted on a ship for sea spray analysis is going to experience six degree translation and rotational motion induced by the floating vessel due to action of wind and waves which will introduce distortions in the lidar measurement this motion needs to be compensated for getting an efficient assessment from the measured data generally two ways for compensating this motion are 1 the mechanical method by placing on top of a motion stabilizing platform gimbal which require additional hardware or 2 software based motion correction algorithm mitigates the distortion incorporating motion input from imu inertial measuring unit achtert et al 2015 tiana alsina et al 2015 integrating an inertial measurement unit with the lidar can enable continuous autonomous long term high resolution shipborne measurements in different sea states 8 3 electrical safety a ship is considered potentially a hazardous environment due to the presence of fuel oxygen and ignition source which may lead to fire and explosion therefore while designing any electrical system for onboard use it is a crucial factor which needs to be considered as it may provide a source of ignition either the equipment is required to have an intrinsic design or deployed away from the proximity of any hazard in accordance with solas ch ii 1 part d imo 2014 the equipment needs to satisfy iecex directives that are accepted globally or atex is accepted in eu prior being installed in potentially explosive atmospheres such as on ships or offshore installations 8 4 weather protection lidar equipment needs to provide high quality measurement in order to fulfil the purpose of analysing sea spray accurately the harsh marine climate can possess a significant challenge for such a study especially if deployed for a longer time apart from waterproofing the lidar housing and corrosion protection should have the arrangement to keep the optical module clean or installed in a location where the module is not obscured by saline water dust or ice commercial lidars are generally designed to handle harsh climates of low temperature and devised inside a dustproof and waterproof casing the als 300 leosphere 2009 which was used for pesticide spray study gregorio et al 2014 the optical head has a waterproof and dustproof rating of ip 65 and operating temperature range of 15 c to 35 c the control unit can either be shielded in a casing or stored in a protected location such as inside the ship s bridge 9 conclusion marine icing is a very complicated phenomenon and involves many uncertainties even with the present technological advancements and attempt of many researchers we do not have all the answers however from the reviews of past studies carried out in agricultural domain shows lidar has the potential to answer some important questions in the marine icing phenomenon by providing an approach to analyse the sea spray flux from a comprehensive perspective lidar technology can provide spray cloud time resolved information thus has the ability to quantify droplet concentration in an entire sea spray cloud and total incoming water flux surface 2 d or volume 3 d range resolved imaging of the sea spray cloud be possible with its scanning ability whereas past methods used to study sea spray only could display data from specific parts of a spray cloud this technique is also suitable for carrying out observations to validate present theoretical and analytical models e g cfd of sea spray propagation a shipborne lidar suited for analysing incoming sea spray is possible to set up for carrying out autonomous measurements thus can be deployed in multiple vessels increasing the number of observations and data collection field measurements with the lidar system will allow us to produce more realistic data under several different conditions this review study proposes the use of lidar in the field of marine icing however further research and work remain to be done to recognize the full potential of the proposed method in addition short range measurement can open the possibility to carry out other studies such as measurement of spray generated from wave impact in different parts of the ship other than bow like during beam winds and waves the contribution of flux from ship s propeller wash the variation of spray flux during synoptic scale weather phenomena the contribution of atmospheric icing and also can be utilized in the offshore and coastal facilities declaration of competing interest the authors declare no conflict of interest 
20995,marine icing phenomenon depends on multiple variables like vessel characteristics and uncertain factors like environmental parameters developing an accurate model for its forecasting evaluation and estimation is very challenging commonly most severe ice accretion is caused due to sea spray the past attempts to measure impinging sea spray flux were carried out on specific parts of the spray cloud and most of the empirical spray flux expressions presented only work in specific conditions this necessitates further real time and accurate field measurements of the entire impinging spray flux carried out in multiple scenarios in order to develop more practical correlation high temporal and spatial resolution measurements and scanning ability of the lidar technique has proven to be useful in the agricultural domain for studying pesticide spray drift this work reviews the past studies carried out using lidar technique for measuring the evolution of the pesticide spray cloud asserting the potential of using a shipborne lidar for analysing sea spray in the study of marine icing phenomenon the lidar system is capable to visualise the evolution of the sea spray drift with a high spatial and temporal resolution which can enable comprehensive real time measurement of spray flux for the entire sea spray cloud keywords lidar sea spray marine icing cold conditions ship stability 1 introduction earlier industries have not shown much interest in the colder regions of our planet due to their focus on exploiting resources in easily accessible warmer regions however with the increase in competition in warmer regions and the promising presence of natural resources shorter transport distances and tourism opportunities interest has grown to exploit these opportunities in marine cold climate regions shipping plays an integral part to utilise these opportunities as they are the preferred means for transportation carrying out surveying operations and also used as base stations the growth of interest is evident from the significant surge in maritime traffic in the last few years the total distance sailed by ships in the arctic polar code area grew by 75 in 2019 compared to 2013 and predicted to increase substantially in the coming years pame 2020 nevertheless colder regions bring their challenges due to its remoteness and harsh weather icing is regarded as the most significant risk associated with colder regions multiple vessels became disabled or sank after ice accretion leading to loss of life damaging environment and property aksyutin 1979 deangelis 1974 guest and luke 2005 hay 1956 lundqvist and udin 1977 ntsb 2018 ryerson 2013 shekhtman 1968 shellard 1974 even after many years of research advancement in analytical and numerical models marine icing still possess a serious operational hazard for ships operating in cold climate regions cammaert 2013 hence it is crucial prior entering these regions to winterize a vessel effectively which incorporates structural designs and techniques by adequate anti or de icing insulation and drainage system to decrease the adverse effects of icing and exposure to cold temperature dnvgl 2019 past analysis of icing observations on ships depending on the geographical location indicated typically sea spray alone contributed 50 97 spray along with atmospheric icing 41 1 4 and atmospheric icing alone 4 1 towards accumulation of marine icing over the vessels aksyutin 1979 brown and roebber 1985 kato 2012 makkonen 1984 1984 1984 panov 1976 shekhtman 1968 shellard 1974 zakrzewski 1987 sea spray ice accretion possess a substantial hazard to a vessel s seaworthiness as navigation communication safety and other essential or critical equipment may become impaired deck operation severely impacted and evacuation routes obstructed makkonen 1984 ryerson 2013 the most imminent danger associated due to ice accretion for a vessel is the loss of stability which may ultimately lead to capsizing guest and luke 2005 this paper focuses on the need for accurate real time measurement of impinging sea spray as the past researchers were only able to measure parts of a spray cloud and approximations were made based on the localised measured data hence there is a need for a different setup or a measuring technique which can measure the entire spray cloud in a comprehensive manner the lidar light detection and ranging technique has proven to be useful in the agricultural domain for studying pesticide spray drift measurement because of its measurement ability with high temporal and spatial resolution and scanning ability allard et al 2007 gregorio et al 2016b richardson et al 2017 torrent et al 2020 this shows the potential of using this technique in the field of marine icing for studying sea spray 2 sea spray icing and ship stability the loss of stability is primarily threatening for smaller ships like fishing vessels orimolade et al 2017 and almost 41 of ships entering the arctic polar code area are fishing vessels pame 2020 fishing vessels relatively have a lower freeboard and have a higher pitch angle and frequency hence spray generation is more frequent and likely to cover the whole ship the superstructure surface area is also large compared to its displacement making them more exposed to sea spray in the presence of low temperature the spray freezes across the vessel and a comparatively lesser weight of accreted ice can destabilize and capsize the fishing vessel guest and luke 2005 when the vessel is propelling into the wind and waves maximum ice accretion is on the forepart consequently trimming the vessel by head further intensifying incoming spray and green seas symmetric ice accretion transverse on the deck fig 1 accommodation tops and other higher parts shift the centre of gravity g upward and forward trim by head along the centre line which reduces the metacentric height gmt this affects the dynamic performance by weakening righting lever gz the ship s ability to upright when heeled by external forces which is readily evident from the increase in the natural rolling period also increase in heave and pitch period in a lesser extent wold 2014 also the deck edge immersion angle is reduced due to reduced freeboard extra weight of the ice causing water ingression at a smaller angle of heel than initial the vanishing angle of stability is reduced which is an indicator of the overall range of stability chung 1995 due to ice accretion the wind drag and sail area of the vessel increases leading to an increase in the wind induced heeling moment gradually with the increase in ice load the metacentric height keeps decreasing to negative eventually unable to upright leading to its capsizing depending on the relative direction of wind and waves an asymmetrical sea spray ice accretion can cause the centre of gravity to shift upward and away from centre line causing the vessel to list further increasing its tendency to capsize chung 1995 the international code on intact stability 2008 is code imo 2020 and the polar code imo 2016 includes allowance for ice accretion 30 kg m 2 on exposed weather decks and gangways and 7 5 kg m 2 for the projected lateral area of each side of the ship above the water plane which should be incorporated in the stability calculation for ships at risk of icing ensuring its adequate stability 3 sea spray ice accretion typically sea spray ice accretion can be divided into three parts 3 1 sea spray cloud generation the high energy impact of wave and ship results in the formation of water sheet along its hull as the water sheet upsurges above the water level air enters and the sheet break into drops and gradually forms a cloud of droplets dehghani et al 2016a these generated droplets reach variable heights and velocities depending on the kinetic energy of the collision and diameters ranging from 10 μm to 3 mm close to the bow bodaghkhani et al 2016 rashid et al 2016 ryerson 2013 zakrzewski 1986 the wave generated spray is a significant source of water flux which is the main contributor for marine ice accretion and often formed close to the vessel s bow depending on relative motion and likely have a short and periodical frequency hansen 2012 sea spray may also be generated by strong wind shearing droplets off wave crest and by bubbles bursting in breaking waves creating atomized droplets ranging 1 μm to 25 μm fuentes et al 2010 wind generated droplets usually have a relatively much lesser but continuous contribution to the icing phenomena dehghani sanij et al 2015 3 2 sea spray cloud drift and impinging upon the ship s structure the sea spray cloud generated is then carried by the airflow across the vessel until finally impacting components or structures on the vessel the droplets in the cloud of different initial velocities sizes and shapes are influenced differently by wind and gravitational force and their paths and trajectories are specified through drag force body forces and added mass force acting on it dehghani et al 2016a kulyakhtin and tsarau 2014 makkonen 2000 the wind carries the small droplets with their velocities nearly become similar to the velocity of the wind but the large droplets being affected more by the gravitational force shortly drops on the deck or back to the sea the larger and smaller droplets are not able to reach the highest elevation of the spray while the trajectory of the medium sized droplets makes it dehghani et al 2016b the characteristics of the spray droplets may change anytime along their path may reduce in size due to evaporation or aerodynamic breakup or increase when combining with another droplet lozowski et al 2000 lwc liquid water content which is the total mass of the water droplets in a unit volume of dry air is an important parameter of incoming spray flux along with velocity and distribution of the droplets for icing calculation dehghani sanij et al 2017a the heat transfer vaporization and temperature change during the drift of the droplets are determined by the characteristics of the droplet like velocity and size dehghani sanij et al 2017a 2017b kulyakhtin and tsarau 2014 sultana et al 2018 the droplets undergo convective evaporative and radiative heat transfer cooling the droplets within the airflow during the drift and eventually supercooled when the supercooled droplets impact and splash on the substrate creates ice followed by running off brine water due to gravity and tensile stresses from the air forms a layer or film and at the same time losing heat via conduction convection and radiation kulyakhtin and tsarau 2014 ryerson 2013 the state of freezing droplets is reliant on properties like its size salt content and also the thermal behaviour of the substrate saha et al 2016 3 3 wet growth of ice from the brine water film the majority of the brine water film drains off from the ice surface entrapping a small amount leading to the growth of ice or wet growth makkonen 1987 the rate at which the brine film freezes and the consequent wet growth is dependent on the incoming water flux transported at different areas on the vessel and the rates at which latent and sensible heat extracted from these areas ryerson 1995 the sea salt precipitates with growth in ice thickness forming pure ice and pockets of brine rashid et al 2016 the primary heat fluxes at the air water interface contributing to the freezing of sea spray impinging at the accreted ice surface are convective or sensible heat flux from the air q c evaporative or latent heat flux from the air q e heating or cooling from impinging spray q d and heating or cooling from radiation q r kulyakhtin and tsarau 2014 samuelsen et al 2017 equation 1 latent heat released during freezing q f q c q e q d q r 4 need for real time data we had discussed how the spray cloud generated from wave and wind spray is the primary cause of icing on the vessel dehghani et al 2016b describes the process of spray cloud generation and its movement into several sub stages including wave impact water sheet breakup droplet breakup spray cloud generation its acceleration and deceleration and spray cloud fall and finally impingement however the physical behaviours of these stages are still inadequately understood characteristics of spray clouds such as its duration and movement in the airflow determining incoming water flux are an essential aspect to model the marine icing phenomenon kulyakhtin and tsarau 2014 the accurate prediction of marine icing and the quantity of ice accretion on the vessel structure is challenging mainly because of the variable quantity of incoming flux at different parts of the vessel which is affected by multiple parameters fig 2 at the same time past studies dehghani sanij et al 2015 horjen 2015 2013 kulyakhtin and tsarau 2014 lozowski et al 2000 shipilova et al 2012 did not consider the distribution and variation of droplet size and velocity in a spray cloud for their icing models dehghani et al 2016b the empirical models and nomograms for predicting icing severity comiskey et al 1984 itagaki 1977 kachurin et al 1974 makkonen 1984 mertins 1968 overland et al 1986 overland 1990 stallabrass 1980 sawada 1962 wise and comiskey 1980 were mostly built on data obtained from small to medium sized vessels and based on input parameters of atmospheric conditions which makes their applications confined to particular regions sultana et al 2018 also by investigating present analytical models it was found in order to make them more effective further research and precise measurements are required for calculating the thermo physical properties and heat transfer phenomena sultana et al 2018 the efficiency of the predicted icing rates even from the present advanced models of sea spray icing even with increased accuracy of the numerical prediction models depends on the correctness to which the complex and uncertain quantities like spray flux turbulent heat transfer and the freezing temperature are predicted samuelsen and graversen 2019 the significant difficulties in modelling spray cloud generation propagation and finally impingement are 1 the wave wind and environmental parameters are highly dynamic irregular interdependent and may have varied scenarios in the cold regions 2 the spray flux its liquid content the spray duration and frequency depend on the ship design its speed over water and heading with respect to the wind and waves and its dynamic behaviour ships of different geometry dimension and loading condition interact differently with sea conditions 3 there is a lack of understanding in the behaviour of the droplet during its propagation within the turbulent flow around different types of ship s structure and the near field biases caused by airflow alterations over the vessel this ultimately decides the distribution and quantity of incoming water flux at different locations on the vessel hence questions the reliability and versatility for predicting marine icing from the cfd models which is also restricted by uncertainties like spray generation method moreover all these models are lacking validation against field observations mintu et al 2016 this necessitates direct measurements to gather real time data of the concentration or spatial distribution of the entire impinging spray to remove errors from each step in order to develop more practical and functional equations the formulae used to calculate lwc in a spray cloud only presents an estimation dehghani sanij et al 2017a the different empirical correlations table 1 are obtained from observation for a distinct set of conditions and do not take into account different vessel parameters so they may provide incorrect results if generalised rashid et al 2016 wmo 1994 bodaghkhani et al 2016 dehghani et al 2016b reviewing past sea spray icing models mention that the lack of recording the distribution of size and velocity in a spray cloud led the researchers to use mono size and mono velocity models there is a lack of empirical observations consequently the analytical and numerical formulations are based only on a few actual field observations and not comprehensive data dehghani sanij et al 2017a hence there is a need for more accurate field measurement considering more parameters and scenarios 5 past sea spray field measurements some researchers carried out measurements in the past attempting to measure real time incoming sea spray on vessels to formulate or validate incoming spray flux or liquid water content correlation and model its distribution to estimate sea spray icing accurately tabata et al 1963 reported field measurements on a few japanese ships during which both ice accretion rate and the sea spray intensity were measured zakrzewski 1986 specially designed icing gauges consisting of a rod suspended in a weight gauge were placed over the ship to measure the icing rate and entrap the sea spray lundqvist and udin 1977 later tabata 1969 measured the spray amount and distribution on deck aboard a 350 metric ton patrol vessel with his instrument consisting of water absorption sheet toilet tissue in circular cylinder distributed across the forecastle which was replaced every 5 6 min interval then measured the added mass from spray events fluxes fluctuated from 0 06 to 0 98 kg m2 h depending upon the cylinder s location on the bow area and relative wind speed and wave direction ryerson 1995 brown and roebber 1985 used the above data sets to present a relation of the change of time averaged spray flux as a function of the ship s speed and heading zakrzewski 1986 ono 1964 measured ice growth rates and the sea spray intensity on patrol boats from the accreted amount of spray on an icing rod and collecting the excess runoff brine in a calibrated jar ozeki et al 2016 itagaki 1984 used this data as a function of air temperature and wind speed to estimate the ice accumulation rate on stationary structures sharapov 1971 study provided a data set from a medium fishing vessel mfv recording the spraying zone extent for wind speed from 5 to 11 beaufort later zakrzewski et al 1988 used this data for validating the model performance for his correlation for calculating the highest extent spray droplets from wave hull interaction which was based on field icing data from kuzniecov et al 1971 gashin s study mentioned in borisenkov panov 1972 provided the first direct measurement data for bow generated spray characteristics from the analysis conducted on a mfv of 35 m long soviet fishing trawler in his data the spray droplet diameters ranged between 1000 μm and 3500 μm with a mean of 2400 μm but his measurement methods environmental and sea conditions during his field trial and variations of his result with different vessel size are not known ryerson 1995 kachurin et al 1974 formulated the first lwc correlation as a function of wave height only based on measurement from a mfv but stated no information about the measurement technique borisenkov et al 1975 published data of spray cloud field measurement made on a mfv in the sea of japan reported ship and environmental parameters though information about droplet size and velocity distribution were are not stated the data was also used for producing empirical lwc formulation and succeedingly used by zakrzewski 1986 and brown and roebber 1985 for extending the formulation and later showed by samuelsen et al 2015 the variation in the empirical constant value varies from the previous study method of directly measuring spray flux was carried out in the 1980s on an artificial island tarsiut island to develop the rigice model the spray data collected from measuring the water level at hourly intervals in 45 gallon drums muzik and kirby 1992 as a part of the study program offshore icing horjen et al 1986 jørgensen et al 1986 measurement of spray flux was carried out on supply vessels stand by boats and offshore structures for calibrating the norwegian marine icing model icemod horjen 1990 the data is also utilized by the later developed icing models marice and numis spray measurements were carried out with absorption panels consisting of absorbent paper paper diapers and bent pipes collecting the impinging spray into a graduated container teigen et al 2019 but no information related to spray droplets were provided bodaghkhani et al 2016 ryerson 1995 was the first to carry out the real time measurement of sea spray on a larger ship cgc midgett 115 m length his experimental setup consisted of vertical and horizontal oriented funnel shaped spray collectors ultrasonic range finding ice detectors video recording systems and stroboscopic droplet camera characteristics of the spray cloud generation frequency duration height and distribution size were recorded also parameters such as sea and environmental conditions ship position speed and heading were logged for every hour the spray flux was measured at six different locations but the result presented was only for one location the reported incoming droplet size varied from 14 to 7700 μm and median of 234 μm the mean droplet concentration about 4χ105 droplets m3 the average cloud droplet concentration of 1 05 107 droplets m3 and average spray event duration 2 37 s was recorded dehghani et al 2016b he also attempted to form the lwc correlation but the comparison among his measurements and past lwc correlations were not satisfying though his result provided crucial data set however it was based on specimens from the spray cloud and not based on accounting for the entire distribution data set of the entire spray cloud and also the model did not include the droplet velocity data bodaghkhani et al 2016 dehghani et al 2016a jones and andreas 2013 collected sea spray at mt desert rock lighthouse catwalk at 20 m above sea level to inspect spray generated over the ocean instead from wave and shore impact and was observed under microscopic slides this project s long term goal is to estimate the sea spray concentration across the open ocean and sea spray icing on offshore constructions ozeki and sagawa 2013 modified a snow particle counter into seawater particle counter spc it consisted superluminescent diode light as a parallel ray measuring light attenuation by particles passing through the sensing area 25 mm wide 3 mm high and 0 5 mm deep the spc was able to measure the droplet size distribution impinging the sensing area every second and was placed on the upper deck of an ice breaker and the measuring range was set from 100 to 1000 μm in diameter by using the result the flux distribution and the transport rate could be approximated as a function of particle size johansen et al 2015 proposed a study of using a high speed camera for imaging sea spray and using image analysis hough transform for measuring the sea spray flux however the study could not be deployed for field test because other than the setup being too expensive most critically it required very sensitive lightning setup which is very difficult to control in the harsh marine climate ozeki et al 2016 modified a marine rain gauge to measure seawater spray in large ships and found a correlation in measurement with their previously developed seawater particle counter spc measurement of seawater spray was performed on the compass deck and the bow deck of an icebreaker teigen et al 2019 describes the real time autonomous measurement system designed by modifying a tipping bucket to collect sea spray to measure and record continuous flux on offshore facilities as part of the joint industry project rigspray the system fig 3 consists of flux meters consisting of a collector plate dimensions 0 5 m 0 5 m funnelling the impinging spray to a tipping bucket via a small hose the tipping bucket s water level is continuously measured with a wireless gauge pressure and the water empties automatically after reaching a certain level the system also includes a video recording system and can transmit the data wirelessly and has been in operation on the ship shaped fpso unit norne in the norwegian sea the project provides spray measurements data along with corresponding vessel motion and environmental dataset important for calibrating spray models on large ship shaped offshore structures the rigspray icing model bøckmann et al 2019 the measurement techniques and data collection and analysing procedures have improved over time and have proven to be helpful because of its simplicity and robustness in the harsh climates however the past studies were only able to measure samples of spray flux from some specific parts of a spray cloud and approximations were made on the basis of the localised measured data so for other conditions the droplet size and concentration need to be assessed for the entire spray cloud from the approximated proposed distribution also the prevailing micrometeorological conditions substantially affect the results during the field trials varyingly at different locations on the ship hence they fail to provide a factual comprehensive time resolved distribution data set for the entire spray cloud information the past studies could not provide about the entire impinging spray cloud such as its complete droplets distribution velocity and concentration which is inherent for the formulation of accurate correlation of spray flux vertical distribution and the spray cloud s maximum height therefore it is necessary to adopt different setups or measuring techniques which can carry out real time monitoring in spatial and temporal resolution to measure incoming sea spray flux for the complete spray cloud with higher efficiency and accuracy lidar light detection and ranging also known as laser radar is an optical sensing technique that has the potential to breaks through the shortcomings mentioned above as it is possible to use this technology for carrying out real time active measurement of entire spray cloud with high temporal and spatial resolution 6 lidar lidar is a long existing active range resolving optical measurement technique and commonly used for remote sensing and analysing of aerosols and clouds in atmospheric studies and presently has broad application throughout almost every field gregorio lópez 2012 hulburt 1937 mcmanamon 2019 lidar is a popular choice in atmospheric studies as it can provide high temporal and distance resolution due to the substantial interaction between the emitted electromagnetic radiation at optical wavelengths ranging from ultraviolet to near infrared and aerosols or molecular components in the atmosphere measures 1992 elastic lidar technique fig 4 is the most commonly used technique operating by the emitting pulsed lasers and detecting backscattered radiation at the same wavelength and the delay in receiving signal computes time of flight the distance equation 3 pulsed elastic lidars provide a range resolved intensity profile of the received signal following the principle of simple scattering this intensity profile follows the lidar equation expressed as received power component equation 2 collis and russell 1976 gregorio lópez 2012 other lidar techniques such as raman lidar inelastic differential absorption lidar dial and doppler lidar are also used in atmospheric studies receiver power equation 2 p λ r p o c τ l 2 β λ r a r r 2 e x p 2 0 r α λ r d r ξ λ ξ r p λ r receiver power w λ wave length nm r distance m p o peak transmitted power w c speed of light m s τ l emitted laser pulse duration s τ d temporal detection window s β λ r volumetric backscattering coefficient m sr a r e ffective area of the receiver telescope m 2 spatial resolution equation 3 δ r c τ l τ d 2 c τ d 2 τ l τ d α λ r volume extinction coefficient m ξ λ spectral transmissivity factor of the emission reception optical system ξ r overlap factor between the emitted laser beam and the receiver field view 7 past spray drift studies using lidar technology due to the high temporal and spatial resolution and latterly scanning ability lidar systems had been fairly utilized as a method for monitoring pesticide spray drift and particulate matters in the agricultural application some of the promising studies used for monitoring spray drift are mentioned which shows its potential to be used in the field of marine icing for analysing sea spray cloud the first research carried out by the u s forest service stanford research institute group in 1966 1967 investigating the use of lidar to monitor the dispersal of insecticide spray in the forests of idaho air motions were observed by tracking spray and smoke clouds and also displayed how turbulent and other diffusive processes can be analysed collis 1968 atmospheric environment service aes of canada constructed an elastic backscatter lidar system aral capable of fast attainment to analyse spray geometry and deposition of pesticides from an aerial application by scanning the cross section of the spray hoff et al 1989 later aral was used by mickle 1994 1996 to analyse the dynamics of the pesticide spray when aerially released lidar technology also had been used and proven to be an ideal tool to validate theoretical spray movement models and was able to expose the discrepancies in the models mickle 1999 stoughton et al 1997 tsai 2007 another elastic backscatter lidar was used to monitor aerially applied biological pesticide spray to support the hypothesis that a widespread dispersal of a small pesticide quantity is unavoidable even if the operation is adequately handled miller and stoughton 2000 miller et al 2003 used lidar ground spray measurements to create 3d images of the spray drift cloud above an orange farm hiscox et al 2006 introduced a methodology to estimate the spray cloud absolute concentration obtained from the lidar return signal from the spray application rate and the initial droplet size distribution theoretical models of evaporation and deposition were used to simulate droplet quantity s temporal evolution which remains in the air from aerial spray application they detected a satisfying correlation in the concentrations estimated from the derived model and the lidar return institute national d optique ino canada specially developed an eye safe close range 100 m lidar for the purpose of monitoring pesticide spray drift allard et al 2007 cantin et al 2007 prior this most studies used lidar systems whose design was architected for far range atmospheric studies the ino lidar prototype was tested to validate its performance in the applications of pesticide and dust cloud monitoring the digitized waveform fig 5 of the backscattered signals demonstrated that the equipment was able to monitor low signal levels from the water spray drifting cloud tested with water instead of real pesticide as well as high signal levels from solid targets like dust the result also showed the ability of lidar to present important measurement data regarding the relative concentration of airborne aerosols of diverse nature also at a shorter range allard et al 2007 khot et al 2011 describes the methodology used to report the application of calibrated lidar to quantify spray distribution across space and time the results exhibited a linear relationship r 2 0 77 between lidar backscatter signal of the spray plume and passive spray collection on samplers miller et al 2012 applied lidar to analyse spray drift from near ground aerosol fogs in several stability conditions concluding that spray coverage is more extensive under strong wind a commercial ultraviolet lidar system als 300 leosphere orsay france was used to monitor spray drift fig 6 for comparing with the measurements obtained from the passive collectors which is conventionally used for measuring pesticide spray drift the result of the analysis showed a strong linear correlation r 2 0 90 proving lidar to be a better alternative for monitoring pesticide spray drift with lesser time and resources gregorio et al 2014 an eye safe lidar system was explicitly designed for the purpose of spray drift monitoring gregorio et al 2015 with a scanning ability via pan and tilt unit up to 25 s and 12 s in azimuth and elevation gregorio et al 2016b the instrument has a laser emitter er glass laser of 1534 nm wavelength emitting pulses of 3 mj energy and 6ns duration a telescope with 80 mm aperture captures the backscattered light and it is directed on the photodetector surface of an avalanche photodiode apd module which converts the received light to electrical signal gregorio et al 2016b the temporal and spatial resolution and scanning capability of the lidar equipment were tested to observe real time behaviour of the drift cloud fig 7 and 8 under different spray conditions and the author claimed lidar to be an appropriate method to carry out drift measurement with much lesser time cost and labour compared to using passive collectors gregorio et al 2016a 2016b the past spray studies carried out in the agricultural domain provide evidence for lidar s temporal and spatial resolution capabilities to monitor the entire spray cloud s real time behaviour which the past sea spray studies failed to provide moreover the lidar system enables evaluation of the spray drift speed its concentration and evolution with time and ultimately providing a broader view these results are encouraging to propose this technique which can be valuable in the field of marine icing due to the similarities of pesticide spray with sea spray for studying the complex sea spray behaviour under different circumstances 8 shipborne lidar for sea spray measurement application of a lidar system suitable for shipborne use for the analysis of sea spray will encounter certain technical challenges that need to be incorporated during the selection of the equipment or during its design phase the ability for near range measurement with a high spatial and temporal resolution is essential besides the equipment being compact have low power consumption eye safe and able to withstand the harsh marine environment is also important 8 1 near range measurement using lidar conventional lidar systems were mainly designed for analysing and measuring tropospheric atmospheres hence they transmitted high power pulsed laser used ruby yag and ylf lasers till the mid 90s and had large aperture receiver telescopes in order to carry out far range measurements gregorio lópez 2012 the system used were complicated heavy high power consumption requiring highly skilled operators and costly ansmann et al 1997 fiocco and smullin 1963 sassen 1975 technological improvements in the last years concerning efficient low energy and high prf lasers and affordable photodetectors in the eye safe region let to rise in its application in near range observations such as aerosol flow imaging monitoring industrial emission gas leak detection etc edner et al 1995 fukuchi and shiina 2012 miya et al 2009 song et al 2020 micro pulse lidars mpl spinhirne 1993 1994 and modern commercial ceilometers madonna et al 2014 muenkel et al 2004 song et al 2017 paved the way for economical compact and convenient lidar systems development in laser technology with laser diodes ld and diode pumped solid state dpss further made lidar more compact and have found a widespread application kong et al 2018 s lolli et al 2011 a lidar deployed on ships for sea spray measurement should have the capability for short range measurement with a comparatively smaller field of view along with being compact with lesser power consumption and have to be reliable in the marine environment with state of the art advancements light emitting diode led based light source has become popular for short range measurements shiina and koyama 2010a from chiba university japan developed compact lightweight mini lidar with a light emitting diode led based light source for near range measurements around 0 100 m since then it had been utilized in widespread short range application from mars rover to atmospheric study among others koyama and shiina 2011 ong et al 2018 shiina 2010b 2013 2019a 2019b 2020 shiina et al 2015 2016 the led lamp module has a larger divergence compared to laser beams does not require a heat sink or fan and claims to be cheaper provide a wide range of wavelength choice lesser power consumption resilient against static electricity and has extended duration of use with consistent intensity shiina 2019a hence has a potential for onboard use for analysing sea spray 8 2 motion compensation a lidar mounted on a ship for sea spray analysis is going to experience six degree translation and rotational motion induced by the floating vessel due to action of wind and waves which will introduce distortions in the lidar measurement this motion needs to be compensated for getting an efficient assessment from the measured data generally two ways for compensating this motion are 1 the mechanical method by placing on top of a motion stabilizing platform gimbal which require additional hardware or 2 software based motion correction algorithm mitigates the distortion incorporating motion input from imu inertial measuring unit achtert et al 2015 tiana alsina et al 2015 integrating an inertial measurement unit with the lidar can enable continuous autonomous long term high resolution shipborne measurements in different sea states 8 3 electrical safety a ship is considered potentially a hazardous environment due to the presence of fuel oxygen and ignition source which may lead to fire and explosion therefore while designing any electrical system for onboard use it is a crucial factor which needs to be considered as it may provide a source of ignition either the equipment is required to have an intrinsic design or deployed away from the proximity of any hazard in accordance with solas ch ii 1 part d imo 2014 the equipment needs to satisfy iecex directives that are accepted globally or atex is accepted in eu prior being installed in potentially explosive atmospheres such as on ships or offshore installations 8 4 weather protection lidar equipment needs to provide high quality measurement in order to fulfil the purpose of analysing sea spray accurately the harsh marine climate can possess a significant challenge for such a study especially if deployed for a longer time apart from waterproofing the lidar housing and corrosion protection should have the arrangement to keep the optical module clean or installed in a location where the module is not obscured by saline water dust or ice commercial lidars are generally designed to handle harsh climates of low temperature and devised inside a dustproof and waterproof casing the als 300 leosphere 2009 which was used for pesticide spray study gregorio et al 2014 the optical head has a waterproof and dustproof rating of ip 65 and operating temperature range of 15 c to 35 c the control unit can either be shielded in a casing or stored in a protected location such as inside the ship s bridge 9 conclusion marine icing is a very complicated phenomenon and involves many uncertainties even with the present technological advancements and attempt of many researchers we do not have all the answers however from the reviews of past studies carried out in agricultural domain shows lidar has the potential to answer some important questions in the marine icing phenomenon by providing an approach to analyse the sea spray flux from a comprehensive perspective lidar technology can provide spray cloud time resolved information thus has the ability to quantify droplet concentration in an entire sea spray cloud and total incoming water flux surface 2 d or volume 3 d range resolved imaging of the sea spray cloud be possible with its scanning ability whereas past methods used to study sea spray only could display data from specific parts of a spray cloud this technique is also suitable for carrying out observations to validate present theoretical and analytical models e g cfd of sea spray propagation a shipborne lidar suited for analysing incoming sea spray is possible to set up for carrying out autonomous measurements thus can be deployed in multiple vessels increasing the number of observations and data collection field measurements with the lidar system will allow us to produce more realistic data under several different conditions this review study proposes the use of lidar in the field of marine icing however further research and work remain to be done to recognize the full potential of the proposed method in addition short range measurement can open the possibility to carry out other studies such as measurement of spray generated from wave impact in different parts of the ship other than bow like during beam winds and waves the contribution of flux from ship s propeller wash the variation of spray flux during synoptic scale weather phenomena the contribution of atmospheric icing and also can be utilized in the offshore and coastal facilities declaration of competing interest the authors declare no conflict of interest 
20996,the effectiveness of vertical baffles of different configurations in suppressing violent transient sloshing was numerically investigated with the lattice boltzmann method lbm volume of fluid vof and large eddy simulation les models were employed to simulate a violent wave breaking phenomenon at finite water depths under resonance conditions the liquid elevation total impact pressure and energy dissipation were measured to evaluate the damping effect with regard to the installation of single or double vertical baffles of different heights and separation distances the results indicate that the interaction between the free surface and the vortex caused by the shearing effect at the tip of vertical baffles constitutes the essential mechanism responsible for damping the sloshing wave a quantitative method is first proposed to distinctively quantify the viscous dissipation that occurred on the interface and interior of the fluid and the results demonstrate that strong internal dissipation is most important for suppressing the sloshing wave the spacing distance is important for the damping effect on the sloshing pressure and the proper distribution of two vertical baffles can inhibit the peak impact pressure to more than about three times lower than that when double baffles with a poor arrangement are used keywords sloshing baffles wave breaking lattice boltzmann method 1 introduction the sloshing of liquid induced by large amplitude oscillation in a partially filled tank represents a strongly nonlinear phenomenon characterized by large instantaneous wave impacts and violent wave breaking of the liquid free surface such sloshing flows are prototypes for phenomena that occur in many engineering containers such as the fuel tanks of aerospace vehicles road tankers and liquefied natural gas lng carriers the localized impact pressure caused by transient and violent sloshing waves could result in structural damage to containers especially under resonance conditions when the external frequency of enforced motion is close to the natural frequency of the liquid filled in the tank faltinsen et al 2006 wu et al 2013 wang et al 2016c the sloshing wave and impact pressure can be effectively diminished by increasing the damping of the large amplitude sloshing motion through baffles whose appropriate application requires detailed understanding of suppression mechanisms associated with the baffle configurations and external sloshing parameters xue et al 2017a akyildiz 2012 the effect of baffles on reducing sloshing has been extensively investigated analytically experimentally and numerically faltinsen and timokha 2009 ibrahim 2005 and the recent progress in this field was comprehensively reviewed by xue et al 2017b and yu et al 2020 the design of baffle configuration mainly requires consideration of the horizontal and vertical types as well as the associated location size number stiffness and perforations all of which contribute to the complexity of the problem therefore the study of the damping mechanism and effectiveness of baffles on the sloshing of liquid is still a popular research topic as a pioneer in this field buzhinskii 1998 considered the baffle induced damping on sloshing to be primarily associated with viscous dissipation caused by formation of vortices at the tips of the sharp edged baffles which transfer the energy from the irrotational motion to vortical motion in addition the presence of baffles was found to result in attenuation of the natural frequency of sloshing which alters the resonance condition xue and lin 2011 however the suppression of violent transient sloshing accompanied by a significant wave breaking phenomenon has seldom been investigated systematically due to strongly nonlinear and discontinuous behaviour encountered in numerical and analytical difficulties most of the theoretical solutions were derived from potential flow theory or quasi viscous rayleigh damping equations faltinsen 1974 faitinsen 1978 nakayama and washizu 1980 warnitchai and pinkaew 1998 abramson 1966 first applied the potential flow theory to analyse the linear and nonlinear behaviour of sloshing motions and to predict the dynamic pressure in cylindrical tanks and he subsequently investigated the effects of baffles on the damping of the sloshing amplitude and energy dissipation rate buzhinskii 1998 analytically investigated the vortex damping of sloshing in tanks with vertical or horizontal baffles by assuming the localized vortex motion to be near the sharp edges of the baffles which indicates that nonlinear vortex damping is caused by energy dissipation in a boundary layer close to a wall faltinsen and timokha 2009 developed the multimodal method and asymptotic modal approximations which have been employed to study the damping effect of the wall and horizontal and vertical baffles in terms of their energy dissipation however it is difficult for the analytical models to accurately estimate the viscosity effect which is especially crucial for large amplitude sloshing experimental studies are considered to be the most reliable source for descriptions of the violent sloshing phenomena akyildiz and ünal 2005 conducted experimental investigations on the influence of baffle configurations on the nonlinear behaviour and damping characteristics under large amplitude sloshing with different filling levels four types of waves were classified namely the standing wave traveling wave hydraulic jump and their combination they found that the energy dissipation can be enhanced by the occurrence of a hydraulic jump and breaking wave induced by baffles in addition the maximum pressure reduction on the tank wall was concluded to be achieved by the vertical baffle mounted at the centre of the tank bottom panigrahy et al 2009 experimentally studied the suppression effect on sloshing by comparing the wall pressure and fluid elevation of rectangular tanks with a horizontal or perforated vertical baffle attached to two side walls and a ring type baffle attached to all walls the vertical baffle was found to suppress the horizontal motion of the liquid while horizontal and ring baffles were found to decrease the transverse motion the results show a considerable amount of reduction in the impact pressure and free surface displacement due to the introduction of baffles especially the ring baffles which affect all walls younes 2015 investigated the damping effect of three types of vertical baffles of different heights lower mounted upper mounted or perforated with a central hole the results indicated that the optimal size and position of the vertical baffles for the highest damping of wall impact pressure are dependent on the filling ratios of the tank as a result a single holed baffle is relatively suitable for achieving an acceptable damping effect for a wide range of filling ratios xue et al 2017a conducted a comprehensive experimental study on the effectiveness of four types of vertical baffles on suppressing violent sloshing of a rectangular tank under enforced horizontal oscillation of a wide range of frequencies they determined that the damping effect is closely related to the modulation of the first mode natural frequency of sloshing which is shifted to a lower value for the immersed and free surface flushing baffles and to a higher value for the surface piercing and perforated baffles the observations of free surface profiles demonstrated that the fluctuation in free surface waves is suppressed by damping or trapping partial mechanical energy of the sloshing wave near the baffle contributing to the effective reduction in impact pressure on the tank walls yu et al 2020 emphasized the importance of high modes for the liquid sloshing by investigating the damping of vertical baffles with different numbers and positions they found that the closer the position of the baffles is to the nodes of sloshing modes the more powerful the damping effect a number of numerical techniques have been developed to investigate the problem of baffled or unbaffled sloshing including the boundary element method bem liu and huang 1994 nakayama and washizu 1981 faltinsen 1974 gedikli and ergüven 2003 finite element method fem wu et al 1998 cho and lee 2004 wang and khoo 2005 cho et al 2005 finite difference method fdm armenio and rocca 1996 chen et al 1996 chen and nokes 2005 and finite volume method fvm liu and lin 2008 gómez goñi et al 2013 ansari et al 2011 zhao and chen 2015 liu and lin 2008 developed a three dimensional 3d numerical model employing the large eddy simulation les approach the volume of fluid vof method and the virtual boundary force vbf method to model the turbulent flow free surface boundary and fluid structure interaction of liquid sloshing respectively the results obtained by this model suggested that vertical baffles are more effective than horizontal baffles at reducing the sloshing amplitude it has also been successfully adopted to model liquid sloshing in tanks with complex baffles xue and lin 2011 used the same method to analyse ring baffles in a rectangular liquid tank the results show that the mechanisms of the ring baffles reduce the vertical velocity of violent fluid motion near the ring baffles while creating a vortex at the edge of the baffles and further enhancing the dissipation rate of fluid energy lu et al 2015 compared the numerical results of liquid sloshing in a baffled or unbaffled tank obtained by the viscous fluid model and potential flow models and demonstrated that the dissipative effects of viscosity account for the significant over predictions of sloshing amplitudes by the potential flow models especially in a baffled tank with stronger vortex flow chu et al 2018 employed the les model to investigate the damping effect of multiple baffles on the hydrodynamic force in a rectangular sloshing tank in addition different configurations of baffles and tanks have been extensively studied to suppress the effect of sloshing hasheminejad and aghabeigi 2012 panigrahy et al 2009 ünal et al 2019 regarding different container forms many scholars have investigated the effect of multiple rigid annular baffles on cylindrical containers and they found that the position and spacing of the baffles have an impact on the sloshing force akyıldız et al 2013 wang et al 2016b 2019 wang et al 2016a investigated the effects of the liquid fill level a t shaped baffle arrangement and baffle length on the sloshing frequencies the associated sloshing mode shapes and sloshing wave height in elliptical tanks wang et al 2017 simulated the effect of baffles on toroidal vessels demonstrating that the appropriate placement of baffles can be effective at suppressing the sloshing force hasheminejad and aghabeigi 2012 and kolaei et al 2015 analysed a horizontal cylindrical container with different designs of longitudinal baffles and surface touching side baffles were found to be most effective in terms of suppressing the total induced force amplitudes the worst performance was associated with the bottom mounted vertical baffle and the surface piercing vertical baffle was of intermediate value regarding different baffle forms cho and kim 2016 and cho et al 2017 studied the damping effect of vertical and horizontal porous baffles with different arrangements showing that dual vertical porous baffles can significantly suppress sloshing motions and that horizontal porous baffles installed on both tank walls could significantly restrain violent resonant sloshing responses compared to one baffle installed at the tank centre koh et al 2013 simulated the movement of a floating baffle in a liquid tank and the results showed that the floating baffle can effectively suppress the sloshing pressure degroote et al 2010 and paik and carrica 2014 numerically investigated the dynamic interaction that exists between the liquid and elastic tank baffle system hwang et al 2016 used a modified particle based fluid structure interaction fsi solver to investigate the effect of elastic baffles with different moduli compared with rigid baffles concluding that as the elastic modulus increases the damping effect of an elastic baffle is closer to that of a rigid baffle the ability of meshless methods and the lattice boltzmann method lbm to model violent transient sloshing featured by prominent wave breaking phenomena has recently been recognized by researchers as the highly discontinuous gas liquid interface cannot be properly captured by the aforementioned traditional numerical methods based on continuum mechanics shao et al 2012 cao et al 2014 janβen et al 2013 kabiri et al 2019 delorme et al 2009 investigated impact pressure in the case of shallow water sloshing for a forced rolling motion using the smoothed particle hydrodynamics sph method which effectively simulated nonlinear behaviours such as a hydraulic jump and plunging wave in shallow water and verified that the maximum value of hydrodynamic pressure usually occurs at a frequency lower than the first natural frequency cao et al 2014 employed the sph method to demonstrate that a vertical baffle can effectively reduce the height of a sloshing wave by up to 90 and its damping effect is most significant on the lowest natural frequency of the sloshing system at a filling ratio h b h w larger than 0 5 meanwhile lbm has been proven to be an effective tool for simulating the problem of free surface and gas liquid two phase flow chen et al 2018a 2019a 2019b wang et al 2015 janssen et al 2016 adopted the lbm and vof model to simulate impact waves and the breaking free surface phenomena in lng ships such as the collision of jet flows and collapse of entrained air bubbles the results proved the applicability in predicting the nonlinear behaviour and impact pressure in violent tank sloshing the present study integrates the free surface model and les model into the lbm framework to investigate the transient flow behaviours in a horizontal sloshing tank with single and double vertical baffles and the mechanisms responsible for kinetic dissipation to suppress the impact wave onto tank walls in most violent sloshing cycles the remainder of this paper is organized as follows the methodology is described in section 2 and the parameter set ups are introduced in section 3 the results and analysis are presented in section 4 finally concluding remarks are given in section 5 in addition detailed validations and mesh sensitivity studies of numerical models are presented in the appendix 2 numerical methodology 2 1 the concept of the lbm and les model the horizontal sloshing of a homogenous isotopic and viscous newtonian fluid is described in a fixed cartesian coordinate system with reference to an oscillating rectangular tank the present numerical model inherits the spatial and temporal discretion scheme of the lbm krüger et al 2017 and the smagorinsky eddy viscosity by using the filtered particle distribution function f i x t where the straight overbar represents a filtering operator x signifies the particle position coordinate t is the time step and i is the velocity direction the temporal iteration follows the forced bhatnagar gross krook bgk model hou et al 1994 which consists of the collision step and the streaming step 1 f i x t f i x t δ t τ f i x t f i e q x t f i δ t 2 f i x c i δ t t δ t f i x t where f i represents the distribution function after collision and τ is the relaxation time corresponding to the total viscosity ν the external force term f i is caused by the non inertial reference frame fixed on the oscillating tank the equilibrium distribution function f i e q is given by 3 f i e q x t ω i ρ 1 u c i c s 2 u c i 2 2 c s 4 u u 2 c s 2 where ρ and u are the macroscopic density and velocity of the fluid respectively and c s 2 1 3 is the speed of sound in the lattice ρ and u can be calculated from the distribution function as follows 4 ρ i 0 18 f i u 1 ρ i 0 18 f i c i f δ t 2 the force term f i is expressed using the form proposed by guo et al 2002 as follows 5 f i ω i 1 1 2 τ c i u c s 2 c i c i u c s 4 f the weighting factors related to the lattice velocities ω i are determined by the d3q19 model krüger et al 2017 the density and pressure can be expressed as ρ x t ρ 0 ρ x t where ρ 0 is the constant state density and ρ is the fluctuation in the density which is a small quantity compared to ρ 0 krüger et al 2017 the relaxation time is determined according to the total viscosity ν and time step δ t 6 2 τ 1 6 δ t ν the les model is integrated in the lbm framework by introducing the standard smagorinsky subgrid viscosity ν t into the total viscosity by ν ν ν t wang et al 2014 whose value can be evaluated by 7 ν t c δ 2 s where c is the smagorinsky constant δ is the filter length scale of a large eddy and s is the absolute value of the strain tensor 2 2 boundary conditions the no slip boundary condition is imposed on the rigid walls of the tank and baffles and the implementation of this boundary condition follows the standard bounce back scheme in the lbm 8 f i ˆ x b t δ t f i x f t where f i ˆ and f i denote the particle velocity distributions in opposite directions and x b and x f indicate the lattice on the rigid wall and the corresponding neighbouring fluid lattice respectively x f x b c i δ t as sketched in fig 1 the mass tracking algorithm körner et al 2005 thürey et al 2006 was adopted to track the free surface boundary and its implementation is similar to that of the volume of fluid vof method which has been extensively employed in traditional computational fluid dynamics cfd methods gopala and wachem 2008 the lattices are divided into three types namely liquid interface and gas lattices the volume fraction of fluid v x t ranges between 0 and 1 on the interface lattice and is fixed at 1 and 0 on the liquid and gas lattices respectively the macroscopic variable of mass in each node is correlated to the volume fraction according to m x t v x t ρ x t additionally mass exchange is permitted only through the interface lattice whose mass distribution is updated as follows 9 m x t δ t m x t n 0 18 a i f i ˆ x c i δ t t f i x t where a i depends on the types of the two neighbouring lattices in the i direction and can be expressed as follows 10 a i 1 2 v x c i δ t t v x t interface interface liquid gas 1 liquid liquid 0 gas gas the distribution function of the gas lattice can be reconstructed from the distribution function of the interface lattice by assuming that the gas lattice has the same reference pressure and velocity as those of the neighbouring interface lattice and thus it can be expressed as follows 11 f i ˆ x t δ t f i e q ρ g u f i ˆ e q ρ g u f i x t where ρ g represents the reference density equals to 1 in this paper and u represents the velocities of the interface and gas lattices a schematic diagram illustrating the steps for executing the temporal evolution of flow through the interface lattice is shown in fig 1 3 parameter settings fig 2 illustrates the dimensions of the rectangular tank namely l length b breadth and h height sloshing is excited by the harmonic oscillation of the tank in the x direction the oscillation velocity u x and the inertial force f x induced by the moving reference frame fixed on the tank are expressed by 12 u x t a σ sin σ t f x m a m u m a σ 2 cos σ t where a a and σ are the external horizontal amplitude acceleration amplitude and angular frequency respectively therefore the external force vector f employed by equation 5 is expressed by 13 f t f x f y ρ v a σ 2 cos σ t ρ v g the non baffled sloshing in a rectangle tank can be characterized by five dimensionless parameters ji et al 2012 namely the froude number f r u 0 g l the reynolds number r e u 0 l ν the aspect ratio of static fluid depth and length of the tank a r h w l the normalized amplitude of oscillation η 2 a l and the frequency ratio between the external forcing and the first natural mode α σ σ 0 the reference velocity u 0 is defined by u 0 σ l 2 π and the first natural frequency of sloshing in a rectangular tank can be estimated as follows liu and lin 2008 14 σ 0 g π l tanh π h w l furthermore the viscous boundary layer should be excessively considered for the analysis of the energy dissipation the boundary layer thickness d can be calculated first using the formula below jin and lin 2019 15 d o 2 π ν σ 0 the corresponding boundary layer is 1 43 mm therefore the influence of the boundary layer can be ignored for a small viscous fluid as shown in fig 2 three additional parameters are specified to describe the present problem due to the influence of baffle configuration and the top wall including the normalized baffle height h b h w the normalized distance between the baffle and side wall l b l and the normalized tank height h l meanwhile the thickness of the baffle is negligible the instantaneous free surface elevation is recorded at x 1 1 10 l and the transient impact pressure at y 1 3 4 h and y 2 h on the left side wall is also traced for further analysis for the numerical simulations presented in the study the fluid density ρ and kinematic viscosity ν of water are taken as 1 0 10 3 kg m3 and 1 0 10 6 m2 s receptively the value of gravity acceleration g is 9 81 m s2 the dimensions of the tank are l 3 0 m b 1 2 m and h 2 0 m the amplitude and angular frequency of tank oscillation are a 0 2 m and σ 3 14 rad s respectively the fluid depth is fixed at h w 1 5 m following the aforementioned definitions the dimensionless parameters are determined as f r 0 28 r e 4 50 10 6 a r 0 50 η 0 13 and α 1 02 according to faltinsen and timokha 2009 and jung et al 2012 the unbaffled sloshing with such parameters will be under resonance and finite depth conditions and it features a large amplitude impact wave the different baffle configurations for tests 1 17 are summarized in table 1 we note that the influence of surface tension and capillary forces were not considered in the present study as they are negligible for the large scale and high reynolds number conditions the homogeneous spatial resolution is δ x 0 01 m and the temporal iteration step is δ t 1 0 10 4 these values were adopted after the sensitivity analysis the smagorinsky constant and the large eddy filter length were determined as c 0 14 and δ δ x respectively the accuracy and efficiency of the present numerical have been validated by comparisons against previous experimental and numerical results as detailed in the appendix readers may refer to krüger 2011 and chen et al 2018b for the conversion between the physical and lattice units 4 results and analysis 4 1 transient sloshing states without a baffle as shown in fig 3 the transient sloshing states for unbaffled sloshing under resonant condition were introduced first to facilitate the subsequent qualitative analysis of the damping effect in the baffled cases these transient flow states include the excitation top slamming and wave breaking states which were classified based on the characteristics of corresponding free surface waveforms observed in previous experimental studies faltinsen et al 2005 2006 royon lebeaud et al 2007 faltinsen and timokha 2009 colagrossi et al 2006 the excitation state usually appears first during the first half period when the free surface moves in the form of planar waves with low surface velocity while the amplitude of sloshing wave increases from zero but is still far less than under the saturated condition fig 3a as the sloshing wave accumulates mechanical energy from the large amplitude oscillatory motion of the tank the wave crest moves upward fast along the side like a jet flow until slamming on the top wall and induces a considerable impact pressure which is referred to as the top slamming state fig 3b however the free surface is still relatively continuous and no significant wave breaking behaviour was observed in the top slamming state on the other hand the wave breaking state features a splashing wave or plunging wave the splashing wave forms when the wave crest impacts the top wall with a higher kinetic energy than that of the jet wave such that the tongue of the wave crest breaks into small droplets which are ejected from the impact zone and then fall down like a parabolic motion fig 3c the plunging wave forms due to the slowing down of the wave base meanwhile the wave crest still moves upward such that the wave front becomes concave until the collapse of the wave crest fig 3d notably the plunging wave does not lead to as large a wall pressure as that by the jet splashing wave but the occurrence of wave breaking in the internal tank induces significant dissipation of mechanical energy generally the sloshing state alternates mainly between the top slamming state and two wave breaking states under large amplitude resonance conditions after the first period of oscillatory motion in the following sections we focus on the influence of baffle configurations on the sloshing states from the perspectives of waveform free surface elevation wall pressure and energy balance 4 2 influence of the baffle height in this section we investigate the damping effect of a single vertical baffle mounted at the centre of the tank bottom l b l 0 5 with different heights by comparison with the numerical results of tests 1 6 according to faltinsen and timokha 2009 the first natural frequency of 2 d sloshing can be modulated by the immersed baffle under such a configuration and it can be estimated by 16 σ 0 2 σ 0 2 1 2 π 2 sin 2 π 2 sinh 2 π h w l h b l 2 therefore the modulated dimensionless frequent ratios for tests 1 4 are α 1 02 1 04 1 08 and 1 17 respectively as shown in table 1 as for tests 5 and 6 two sections were separated by a central baffle in the tank for h b h w yielding the equivalent baffle length l 0 5 l and the corresponding frequent ratio α 0 69 similarly the modulated dimensionless frequent ratios for tests 7 11 are α 1 02 which shows that the tests are in resonance condition 4 2 1 free surface elevation fig 4 depicts the transient trace of the free surface elevation e h of tests 1 6 during the first five periods where e y h w is the instantaneous free surface height relative to the fluid depth at stillness detected at x 1 the maximum elevation limited by the top wall was reached for tests 1 3 just within the second half cycle in the first period as indicated by fig 5 the splashing wave was observed for tests 1 3 at t t 1 while the spilling distance of the breaking droplets decreases with the increase in baffle height an obvious shearing effect and vortex generation at the tip of the baffle which is similar to wu et al 2012 can be observed in fig 5 for tests 2 and 3 however the splashing wave still impacts the left top and right top walls alternatively and only results in the general decrease in the duration and amplitude of the wave impact during the sloshing period with the increase in baffle height the top slamming state was only transiently reached for test 6 in the first two periods leading to a peak of e h at t t 1 4 but the large deviation from the resonance frequency due to the high baffle finally led to a more stabilized sloshing state in the subsequent periods the damping effect of a single vertical baffle was the most significant when 0 75 h b h w 1 as the top slamming state and the splashing wave breaking state completely disappeared for tests 4 and 5 as shown in fig 5 the wave breaking state with plunging waves with air bubble entrapment is a predominant phenomenon when the tip of baffle is close to the free surface at stillness which has also been demonstrated by the experimental results in xue et al 2017b such a baffle configuration is favourable for the formation of plunging waves because the wave crest can jump over the baffle while the wave base is blocked by the baffle the most intensive shearing effect was observed for test 5 because the flow velocity increases with the proximity to the free surface such that the interaction between the near surface fluid and baffle leads to the strong viscous dissipation this will be quantitatively discussed in detail in addition to the viscous dissipation we note that the significant modulation of the natural frequency is the other major factor contributing to the overall damping effect of the vertical baffle and the natural frequency is mostly deviated from the resonance frequency for test 5 according to equation 16 therefore the amplitude of the free surface elevation is approximately at the same level for tests 4 and 5 under the coupling influence of the aforementioned factors while the obvious phase difference in peaks was due to the different frequency modulations 4 2 2 vortical flow and energy dissipation in this section we mainly study the effect of the baffle on the dissipation of energy constituted by the free surface dissipation and internal dissipation the energy balance relationship of the fluid in the tank with respect to the non inertial system is worth noting according to the chapman enskog analysis the bgk equation is equivalent to the navier stokes equation from which iafrati 2009 derived the following energy balance equation 17 d e t d t ω ρ u 2 2 u n d s ω p u n d s ω μ u ω n d s ω μ ω 2 d ω ω ρ a u d ω 18 e t e k e p ω 1 2 ρ u 2 d ω ω ρ g e d ω where e t is the total mechanical energy that includes the kinetic energy e k and potential energy e p of the fluid the first three terms on the right side of equation 17 represent the kinetic energy flux work by pressure and work by tangential stresses which are homogeneously zero for the present problem because of the non slip boundary velocity condition u 0 on the walls with respect to the non inertial reference frame the two remaining terms of equation 17 denote the viscous dissipation and work by inertial force whose instantaneous values determine the rate of change of the total mechanical energy the viscous dissipation is also known as entropy which is dependent on the sum of squares of the vorticity components ω x ω y and ω z despite ω z playing the most dominant role in such a problem featured by planar sloshing lu et al 2015 fig 6 depicts the contour of the instantaneous vorticity amplitude as counterparts of fig 5 during the second period while the snapshots of the 3d surface profiles shown in fig 7 demonstrate the breaking waveforms of tests 1 6 at the instant when the corresponding kinetic energy e k reaches the peak value for the unbaffled case of test 1 the vorticity is mainly generated by the splashing wave after impacting the top wall every half cycle as shown in fig 7 the breaking droplets form a significant splashing zone in tests 1 and 2 and fig 6 indicates that the falling droplets manifest strong vorticity for their rotation and deformation from tests 2 to 4 the internal vorticity field intensifies with the increase in baffle height fig 6 meanwhile the strength of the splashing wave decreases and almost vanishes in test 4 where the free surface is similar to the plunging wave fig 7 the intensity and distribution of vorticity of test 4 at t t 2 00 is significantly superior to that of other tests at any instant displayed in fig 6 due to the strong shearing interaction between the shedding vortex and the fluid near the wave surface however a higher baffle with h b h w 1 in tests 5 and 6 weakened the shearing effect at the baffle tip and part of the interior vortex is caused by the entrapped fluid due to plunging wave breaking similar to the experimental observation in xue et al 2017a the vorticity amplitude of test 6 was relatively small compared to the other cases as the baffle almost separates the tank into two smaller ones where the top slamming state is the dominant phenomenon figs 6 and 7 in the present study the energy dissipation that occurred on the interface and interior of the fluid was distinctively quantified to evaluate the contribution of wave breaking and vortex generation to damping 19 ψ f ω μ ω 2 v δ v 1 d ω 20 ψ i ω μ ω 2 δ v 1 d ω where the dirac function δ v 1 equals 1 for an interior fluid whose volume of fraction v 1 otherwise it equals 0 at the interface the transient traces of the surface and internal energy dissipation rates of tests 1 6 are shown in fig 8 by employing equations 19 and 20 in general the internal dissipation is always larger than the surface dissipation rate for each test we note that the surface dissipation is basically induced by wave breaking but not vice versa as no vortex was generated by the baffle in test 1 but ψ i still surpasses ψ f for the occurrence of wave breaking the internal dissipation experiences a rapid increase until reaching a saturated state which takes approximately 2 3 cycles and is dependent on the height of the baffle but apart from tests 1 and 5 no obvious cycle to cycle periodicity can be observed from the transient traces of the energy dissipation rate the free surface dissipation was even more irregular than the internal dissipation since the wave breaking behaviour is highly nonlinear similar to the qualitative observation according to fig 6 the amplitude of internal dissipation increases with the increase in baffle height for h b h w 1 despite the ψ i of test 3 being higher than that of test 4 at certain phases due to the frequency shift in contrast the increase in baffle height for h b h w 1 led to an abrupt reduction in ψ i the internal dissipation was mainly caused by the wave breaking and the vortex shedding from the tip of the baffle and both phenomena were weakened by the bottom mounted baffle piercing the free surface of the fluid at rest in general we conclude that the vertical baffle with a height slightly below the fluid depth is most favourable for the damping of sloshing through energy dissipation in addition the energy dissipation was studied with a single baffle at the bottom of the tank under resonance conditions fig 9 shows the transient traces of the total energy dissipation rate of test 1 and tests 7 11 under resonance conditions the energy dissipation rate of the system will gradually increase and fluctuate around a larger value compared with test 1 the energy dissipation of tests 7 11 was significantly enhanced when h b h w 1 the dissipation of the system will increase as the baffle increases meanwhile until h b h w increases to 0 5 the increase in energy dissipation is no longer obvious when h b h w 1 compared with the baffle below the liquid level the energy consumption effect weakens obviously fig 10 shows the velocity contour of test 1 and tests 7 11 at peak kinetic energy which shows that all tests had the process of the top slamming state and the violent wave breaking state under the resonance condition for tests 7 9 the vortex generated at the top of the baffle was more conducive to energy dissipation under resonance conditions as shown in figs 9 and 10 furthermore the resonance effect of test 11 was more intense than that of test 10 because the breaking wave splashes on the liquid surface on the other side of the baffle changing the natural frequency of the system on the other hand compared with the tests of non resonance the movement of the free surface was more intense under resonance conditions therefore the influence of relationship between external excitation frequency and natural frequency on sloshing is very important 4 3 influence of the spacing of two baffles multiple baffles are already commonly installed in lng carriers to damp the sloshing movement intensity of liquid fuel however the existing laboratory experiments and or numerical studies have seldomly specified the influence of baffle spacing on the coupled interaction of multiple baffles by comparing the free surface elevation wave amplitude and impact pressure on the wall for tests 12 17 we investigated the damping effect of two symmetrically installed baffles with a fixed optimal height h b h 0 75 but different spacing distances away from the side wall l b l 0 13 0 47 similar to fig 4 the transient traces of the free surface elevation of tests 12 17 at x 1 is plotted in fig 11 the variation in elevation of test 12 is similar to that of test 1 as the baffles became invalid in damping the sloshing when they were in proximity to the side wall as l b l 0 likewise the variation in the elevation of test 17 was similar to that of test 4 for the two baffles which acted like a single baffle while getting closer to each other towards the limit l b l 0 5 the amplitude of elevation was best suppressed for test 15 whose spacing distance was l b l 0 33 as e h is less than 0 2 after the first transient cycle therefore the relatively uniform distribution of multiple baffles in the tank is more effective at suppressing the amplitude of the sloshing wave the instantaneous velocity contours of tests 12 17 during the second period are also displayed in fig 12 for comparison against fig 5 the free surface profile of test 12 is similar to the unbaffled case of test 1 which also manifested the features of a splashing wave despite the interaction between the wave and baffles giving rise to tip vortices near the side wall the wave breaking phenomena that occurred in test 4 were generally reproduced in test 17 where the two baffles with a narrow gap can be regarded as a thicker one the mitigating effect of multiple baffles can be observed in tests 13 16 and the vortices were generated and shed on the tip of both baffles making the velocity field more complicated due to the stronger nonlinear effect on the other hand the velocity gradient became weaker with increasing baffle number which was also noted by chu et al 2018 in addition multiple plunging waves can be generated in half a cycle with the presence of multiple baffles as they block the horizontal motion of the wave base which is favourable for the wave crest curl down to form the plunging wave for a more intuitive description of the suppression of wave breaking by baffles fig 13 shows a three dimensional velocity snapshot of the maximum kinetic energy in the second period suggesting that the degree of wave breaking for tests 14 16 was greatly reduced fig 14 shows the transient wall pressure at two measuring points y 1 and y 2 which are flush with the free surface at rest and on the corner of the left wall respectively as indicated in the schematic diagram in figs 2 and fig 15 shows the contour of the peak pressure in the second period from a to i in fig 14 for tests 12 and 13 the periodic peak pressure resulted from top slamming of the wave onto the side wall y 1 in fig 14 a and top wall y 2 in fig 14 b for a violent top slamming case such as test 12 the amplitude of peak load at the free surface is several times larger than that in other cases at the same position the impact pressure on the side wall at y 1 mainly resulted from the impact of the leftward horizontal motion of the wave crest as shown in fig 15 but the kinetic energy can be transformed into gravitational potential energy and the primary direction of momentum is converted from horizontal to vertical afterwards the upwelling motion of wave crest is immediately restricted by the tank roof such that it strikes the top wall like a water hammer as l b l increases the horizontal motion is effectively suppressed by both baffles and the damping effect becomes stronger no obvious peak pressure was detected for 0 27 l b l 0 40 until l b l 0 47 the pressure measured at y 2 reappears and its value is smaller than that in test 12 therefore the spacing distance is critical for the damping effect on the sloshing amplitude such that multiple baffles with a poor arrangement will have a less significant mitigating effect than a baffle or double baffles with the proper distribution 5 conclusion this study employed a les vof model in the framework of lbm to investigate the problem of liquid sloshing with wave breaking in a partially filled rectangular tank under resonance conditions the damping effects subject to single and double vertical baffles of different heights or spacing distances were analysed with respect to the liquid elevation free surface profile energy dissipation and impact pressure the main conclusions of this work can be summarized as follows for the sloshing phenomenon when the excitation frequency is close to the natural frequency of the tank the damping of vertical baffles is essentially induced by two factors namely the modulation of resonance frequency and the viscous dissipation caused by strong shearing interaction the optimal height for damping the sloshing amplitude by a single vertical baffle is reached for 0 75 h b h w 1 where the top slamming state and the splashing wave breaking state can be completely eliminated and the stronger plunging wave breaking can be observed a quantitative method is first proposed to distinctively quantify the viscous dissipation that occurred on the interface and interior of the fluid it was employed to evaluate the contribution to damping of wave breaking and vortex generation internal dissipation was far higher than interface dissipation the intensity of internal dissipation increases with the proximity of the baffle tip to the free surface as the interaction between the near surface fluid and baffle leads to the onset of strong vorticity for the cases with two vertical baffles they became invalid in damping the sloshing when they were in proximity to the side wall and acted like a single baffle when they were close to each other the relatively uniform distribution of multiple baffles in the tank was more effective at suppressing the amplitude of the sloshing wave the spacing distance is important for achieving a damping effect on the sloshing pressure and the proper distribution of two vertical baffles can reduce the peak impact pressure to more than about three times lower than that when double baffles with a poor arrangement are used credit authorship contribution statement chunlei ma conceptualization methodology software data curation writing original draft visualization investigation chengwang xiong supervision software validation data curation writing review editing guowei ma supervision writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors would like to acknowledge the financial support from the national natural science foundation of china no 51909055 china postdoctoral science foundation no 2019m652480 natural science foundation of hebei province no e2019202471 the corresponding author c x would like to acknowledge the support from shandong provincial key laboratory of ocean engineering no kloe201904 and state key laboratory of coastal and offshore engineering no lp1921 appendix numerical validation comparison with experimental results the numerical simulation performed using the lbm method was compared with the experiment from faltinsen and timokha 2002 which has been widely verified by ji et al 2012 the parameters in table 2 test 18 are exactly the same as in faltinsen s experiment and the numerical results can be found in fig 16 the time history curves of the liquid elevation show good agreement between the two experiments furthermore we compared the wall pressure and the photo of the free surface height with baffles obtained from the experimental results of xue et al 2017b the parameters are show in results are shown in table 2 tests 19 and 20 the results are shown in figs 17 and 18 the lbm calculation results in the present study achieved a reliable numerical accuracy table 2 the experimental and numerical comparison parameters of tests 18 21 in this paper table 2 test l m b l h l h l a l ω rad s h b h l b l 18 1 73 0 115 0 607 0 173 0 028 3 696 19 0 57 0 544 0 316 0 035 5 442 20 0 57 0 544 0 316 0 018 6 019 0 186 0 5 21 1 00 1 000 0 500 0 200 3 140 fig 16 comparison of the transient wave elevation at a position x 0 0 05 m between the present numerical result and the experimental data in fig 7 of faltinsen and timokha 2002 and fig 2 of ji et al 2012 fig 16 fig 17 comparison of the pressure at p1 a a p2 b b and p3 c c between the present numerical result and the experimental data in fig 3 of xue et al 2017b fig 17 fig 18 comparison of photos of transient wave elevation between the present numerical result and the experimental data in fig 10 of xue et al 2017b fig 18 efficiency comparison with fvm the computational efficiency and time step sensitivity of lbm were compared with those of the fvm by conducting the same test the commercial software fluent3d which is based on the fvm with the vof model is widely used to simulate fluid dynamics problems with free surface problems armenio and rocca 1996 liu and lin 2008 the lbm and fvm tests applied parameter settings described in table 2 test 21 and the mesh precision described in table 3 assuming that the tank is secured on a shaker and subjected to a sinusoidal horizontal excitation with a velocity function the employed mesh system has 100 100 uniform and vertical meshes in fluent3d using the vof model while the resolution n x is 100 in the lbm using the les bgk d3q19 model to neglect the effect in the z direction we set the boundaries of the front and back walls to be fluid which ensures the same settings for both methods table 3 comparison of calculation time memory and stability between lbm and fvm where d represents the variance of tests table 3 n t s cpu time h ram d fvm 1 0 10 2 1 583 16 gb 0 0196 5 0 10 3 3 5 1 0 10 3 7 5 lbm 5 0 10 4 0 533 8 gb 0 0131 1 0 10 4 1 2 5 0 10 5 2 75 convergence test of time step fig 19 the sensitivity of time step in test 21 between fvm method and lbm method where h 0 5 m fig 19 three tests were performed to analyse the sensitivity to the time step the results shown in fig 19 indicate that the fvm exhibits a large computational deviation in the final period while the lbm remains fairly stable at the same time in addition the computation time and variance analysis are summarized in table 3 which shows the advantages of the lbm namely its high computational efficiency and insensitivity to the time step convergence test of mesh resolution four different mesh systems were considered for h w h 50 and 75 to test the grid dependence of the resolution under the resonance conditions the parameters are listed in table 2 test 21 the results in fig 20 and table 4 indicate that the good computational convergence achieved with the lbm shows little dependence on the mesh in addition the lbm exhibits better stability for the calculation of large amplitude sloshing considering the computation time and accuracy a resolution of n x 100 was adopted for the analysis in this paper fig 20 the sensitivity of mesh in test 21 with lbm method where h 0 5 m in a and h 0 75 m in b fig 20 table 4 comparison of free surface elevation with different resolution in 50 and 75 depth using lbm where e m a x and e r e indicate the elevation of the extremum and relative error table 4 h w h n x x 0 1 x 0 5 d e m a x e r e d e m a x e r e 50 180 120 72 0 0414 0 4885 4 14 0 0192 0 1112 1 92 240 160 96 0 0329 0 4813 3 29 0 0134 0 1340 1 34 300 200 120 0 0386 0 3569 3 86 0 0207 0 1052 2 07 360 240 144 0 0389 0 4390 3 89 0 0161 0 0813 1 61 75 180 120 72 0 0442 0 4511 2 71 0 0161 0 0591 1 07 240 160 96 0 0453 0 4554 2 80 0 0127 0 0762 0 85 300 200 120 0 0332 0 2042 2 02 0 0131 0 0981 0 88 360 240 144 0 0380 0 3400 2 36 0 0142 0 0729 0 95 
20996,the effectiveness of vertical baffles of different configurations in suppressing violent transient sloshing was numerically investigated with the lattice boltzmann method lbm volume of fluid vof and large eddy simulation les models were employed to simulate a violent wave breaking phenomenon at finite water depths under resonance conditions the liquid elevation total impact pressure and energy dissipation were measured to evaluate the damping effect with regard to the installation of single or double vertical baffles of different heights and separation distances the results indicate that the interaction between the free surface and the vortex caused by the shearing effect at the tip of vertical baffles constitutes the essential mechanism responsible for damping the sloshing wave a quantitative method is first proposed to distinctively quantify the viscous dissipation that occurred on the interface and interior of the fluid and the results demonstrate that strong internal dissipation is most important for suppressing the sloshing wave the spacing distance is important for the damping effect on the sloshing pressure and the proper distribution of two vertical baffles can inhibit the peak impact pressure to more than about three times lower than that when double baffles with a poor arrangement are used keywords sloshing baffles wave breaking lattice boltzmann method 1 introduction the sloshing of liquid induced by large amplitude oscillation in a partially filled tank represents a strongly nonlinear phenomenon characterized by large instantaneous wave impacts and violent wave breaking of the liquid free surface such sloshing flows are prototypes for phenomena that occur in many engineering containers such as the fuel tanks of aerospace vehicles road tankers and liquefied natural gas lng carriers the localized impact pressure caused by transient and violent sloshing waves could result in structural damage to containers especially under resonance conditions when the external frequency of enforced motion is close to the natural frequency of the liquid filled in the tank faltinsen et al 2006 wu et al 2013 wang et al 2016c the sloshing wave and impact pressure can be effectively diminished by increasing the damping of the large amplitude sloshing motion through baffles whose appropriate application requires detailed understanding of suppression mechanisms associated with the baffle configurations and external sloshing parameters xue et al 2017a akyildiz 2012 the effect of baffles on reducing sloshing has been extensively investigated analytically experimentally and numerically faltinsen and timokha 2009 ibrahim 2005 and the recent progress in this field was comprehensively reviewed by xue et al 2017b and yu et al 2020 the design of baffle configuration mainly requires consideration of the horizontal and vertical types as well as the associated location size number stiffness and perforations all of which contribute to the complexity of the problem therefore the study of the damping mechanism and effectiveness of baffles on the sloshing of liquid is still a popular research topic as a pioneer in this field buzhinskii 1998 considered the baffle induced damping on sloshing to be primarily associated with viscous dissipation caused by formation of vortices at the tips of the sharp edged baffles which transfer the energy from the irrotational motion to vortical motion in addition the presence of baffles was found to result in attenuation of the natural frequency of sloshing which alters the resonance condition xue and lin 2011 however the suppression of violent transient sloshing accompanied by a significant wave breaking phenomenon has seldom been investigated systematically due to strongly nonlinear and discontinuous behaviour encountered in numerical and analytical difficulties most of the theoretical solutions were derived from potential flow theory or quasi viscous rayleigh damping equations faltinsen 1974 faitinsen 1978 nakayama and washizu 1980 warnitchai and pinkaew 1998 abramson 1966 first applied the potential flow theory to analyse the linear and nonlinear behaviour of sloshing motions and to predict the dynamic pressure in cylindrical tanks and he subsequently investigated the effects of baffles on the damping of the sloshing amplitude and energy dissipation rate buzhinskii 1998 analytically investigated the vortex damping of sloshing in tanks with vertical or horizontal baffles by assuming the localized vortex motion to be near the sharp edges of the baffles which indicates that nonlinear vortex damping is caused by energy dissipation in a boundary layer close to a wall faltinsen and timokha 2009 developed the multimodal method and asymptotic modal approximations which have been employed to study the damping effect of the wall and horizontal and vertical baffles in terms of their energy dissipation however it is difficult for the analytical models to accurately estimate the viscosity effect which is especially crucial for large amplitude sloshing experimental studies are considered to be the most reliable source for descriptions of the violent sloshing phenomena akyildiz and ünal 2005 conducted experimental investigations on the influence of baffle configurations on the nonlinear behaviour and damping characteristics under large amplitude sloshing with different filling levels four types of waves were classified namely the standing wave traveling wave hydraulic jump and their combination they found that the energy dissipation can be enhanced by the occurrence of a hydraulic jump and breaking wave induced by baffles in addition the maximum pressure reduction on the tank wall was concluded to be achieved by the vertical baffle mounted at the centre of the tank bottom panigrahy et al 2009 experimentally studied the suppression effect on sloshing by comparing the wall pressure and fluid elevation of rectangular tanks with a horizontal or perforated vertical baffle attached to two side walls and a ring type baffle attached to all walls the vertical baffle was found to suppress the horizontal motion of the liquid while horizontal and ring baffles were found to decrease the transverse motion the results show a considerable amount of reduction in the impact pressure and free surface displacement due to the introduction of baffles especially the ring baffles which affect all walls younes 2015 investigated the damping effect of three types of vertical baffles of different heights lower mounted upper mounted or perforated with a central hole the results indicated that the optimal size and position of the vertical baffles for the highest damping of wall impact pressure are dependent on the filling ratios of the tank as a result a single holed baffle is relatively suitable for achieving an acceptable damping effect for a wide range of filling ratios xue et al 2017a conducted a comprehensive experimental study on the effectiveness of four types of vertical baffles on suppressing violent sloshing of a rectangular tank under enforced horizontal oscillation of a wide range of frequencies they determined that the damping effect is closely related to the modulation of the first mode natural frequency of sloshing which is shifted to a lower value for the immersed and free surface flushing baffles and to a higher value for the surface piercing and perforated baffles the observations of free surface profiles demonstrated that the fluctuation in free surface waves is suppressed by damping or trapping partial mechanical energy of the sloshing wave near the baffle contributing to the effective reduction in impact pressure on the tank walls yu et al 2020 emphasized the importance of high modes for the liquid sloshing by investigating the damping of vertical baffles with different numbers and positions they found that the closer the position of the baffles is to the nodes of sloshing modes the more powerful the damping effect a number of numerical techniques have been developed to investigate the problem of baffled or unbaffled sloshing including the boundary element method bem liu and huang 1994 nakayama and washizu 1981 faltinsen 1974 gedikli and ergüven 2003 finite element method fem wu et al 1998 cho and lee 2004 wang and khoo 2005 cho et al 2005 finite difference method fdm armenio and rocca 1996 chen et al 1996 chen and nokes 2005 and finite volume method fvm liu and lin 2008 gómez goñi et al 2013 ansari et al 2011 zhao and chen 2015 liu and lin 2008 developed a three dimensional 3d numerical model employing the large eddy simulation les approach the volume of fluid vof method and the virtual boundary force vbf method to model the turbulent flow free surface boundary and fluid structure interaction of liquid sloshing respectively the results obtained by this model suggested that vertical baffles are more effective than horizontal baffles at reducing the sloshing amplitude it has also been successfully adopted to model liquid sloshing in tanks with complex baffles xue and lin 2011 used the same method to analyse ring baffles in a rectangular liquid tank the results show that the mechanisms of the ring baffles reduce the vertical velocity of violent fluid motion near the ring baffles while creating a vortex at the edge of the baffles and further enhancing the dissipation rate of fluid energy lu et al 2015 compared the numerical results of liquid sloshing in a baffled or unbaffled tank obtained by the viscous fluid model and potential flow models and demonstrated that the dissipative effects of viscosity account for the significant over predictions of sloshing amplitudes by the potential flow models especially in a baffled tank with stronger vortex flow chu et al 2018 employed the les model to investigate the damping effect of multiple baffles on the hydrodynamic force in a rectangular sloshing tank in addition different configurations of baffles and tanks have been extensively studied to suppress the effect of sloshing hasheminejad and aghabeigi 2012 panigrahy et al 2009 ünal et al 2019 regarding different container forms many scholars have investigated the effect of multiple rigid annular baffles on cylindrical containers and they found that the position and spacing of the baffles have an impact on the sloshing force akyıldız et al 2013 wang et al 2016b 2019 wang et al 2016a investigated the effects of the liquid fill level a t shaped baffle arrangement and baffle length on the sloshing frequencies the associated sloshing mode shapes and sloshing wave height in elliptical tanks wang et al 2017 simulated the effect of baffles on toroidal vessels demonstrating that the appropriate placement of baffles can be effective at suppressing the sloshing force hasheminejad and aghabeigi 2012 and kolaei et al 2015 analysed a horizontal cylindrical container with different designs of longitudinal baffles and surface touching side baffles were found to be most effective in terms of suppressing the total induced force amplitudes the worst performance was associated with the bottom mounted vertical baffle and the surface piercing vertical baffle was of intermediate value regarding different baffle forms cho and kim 2016 and cho et al 2017 studied the damping effect of vertical and horizontal porous baffles with different arrangements showing that dual vertical porous baffles can significantly suppress sloshing motions and that horizontal porous baffles installed on both tank walls could significantly restrain violent resonant sloshing responses compared to one baffle installed at the tank centre koh et al 2013 simulated the movement of a floating baffle in a liquid tank and the results showed that the floating baffle can effectively suppress the sloshing pressure degroote et al 2010 and paik and carrica 2014 numerically investigated the dynamic interaction that exists between the liquid and elastic tank baffle system hwang et al 2016 used a modified particle based fluid structure interaction fsi solver to investigate the effect of elastic baffles with different moduli compared with rigid baffles concluding that as the elastic modulus increases the damping effect of an elastic baffle is closer to that of a rigid baffle the ability of meshless methods and the lattice boltzmann method lbm to model violent transient sloshing featured by prominent wave breaking phenomena has recently been recognized by researchers as the highly discontinuous gas liquid interface cannot be properly captured by the aforementioned traditional numerical methods based on continuum mechanics shao et al 2012 cao et al 2014 janβen et al 2013 kabiri et al 2019 delorme et al 2009 investigated impact pressure in the case of shallow water sloshing for a forced rolling motion using the smoothed particle hydrodynamics sph method which effectively simulated nonlinear behaviours such as a hydraulic jump and plunging wave in shallow water and verified that the maximum value of hydrodynamic pressure usually occurs at a frequency lower than the first natural frequency cao et al 2014 employed the sph method to demonstrate that a vertical baffle can effectively reduce the height of a sloshing wave by up to 90 and its damping effect is most significant on the lowest natural frequency of the sloshing system at a filling ratio h b h w larger than 0 5 meanwhile lbm has been proven to be an effective tool for simulating the problem of free surface and gas liquid two phase flow chen et al 2018a 2019a 2019b wang et al 2015 janssen et al 2016 adopted the lbm and vof model to simulate impact waves and the breaking free surface phenomena in lng ships such as the collision of jet flows and collapse of entrained air bubbles the results proved the applicability in predicting the nonlinear behaviour and impact pressure in violent tank sloshing the present study integrates the free surface model and les model into the lbm framework to investigate the transient flow behaviours in a horizontal sloshing tank with single and double vertical baffles and the mechanisms responsible for kinetic dissipation to suppress the impact wave onto tank walls in most violent sloshing cycles the remainder of this paper is organized as follows the methodology is described in section 2 and the parameter set ups are introduced in section 3 the results and analysis are presented in section 4 finally concluding remarks are given in section 5 in addition detailed validations and mesh sensitivity studies of numerical models are presented in the appendix 2 numerical methodology 2 1 the concept of the lbm and les model the horizontal sloshing of a homogenous isotopic and viscous newtonian fluid is described in a fixed cartesian coordinate system with reference to an oscillating rectangular tank the present numerical model inherits the spatial and temporal discretion scheme of the lbm krüger et al 2017 and the smagorinsky eddy viscosity by using the filtered particle distribution function f i x t where the straight overbar represents a filtering operator x signifies the particle position coordinate t is the time step and i is the velocity direction the temporal iteration follows the forced bhatnagar gross krook bgk model hou et al 1994 which consists of the collision step and the streaming step 1 f i x t f i x t δ t τ f i x t f i e q x t f i δ t 2 f i x c i δ t t δ t f i x t where f i represents the distribution function after collision and τ is the relaxation time corresponding to the total viscosity ν the external force term f i is caused by the non inertial reference frame fixed on the oscillating tank the equilibrium distribution function f i e q is given by 3 f i e q x t ω i ρ 1 u c i c s 2 u c i 2 2 c s 4 u u 2 c s 2 where ρ and u are the macroscopic density and velocity of the fluid respectively and c s 2 1 3 is the speed of sound in the lattice ρ and u can be calculated from the distribution function as follows 4 ρ i 0 18 f i u 1 ρ i 0 18 f i c i f δ t 2 the force term f i is expressed using the form proposed by guo et al 2002 as follows 5 f i ω i 1 1 2 τ c i u c s 2 c i c i u c s 4 f the weighting factors related to the lattice velocities ω i are determined by the d3q19 model krüger et al 2017 the density and pressure can be expressed as ρ x t ρ 0 ρ x t where ρ 0 is the constant state density and ρ is the fluctuation in the density which is a small quantity compared to ρ 0 krüger et al 2017 the relaxation time is determined according to the total viscosity ν and time step δ t 6 2 τ 1 6 δ t ν the les model is integrated in the lbm framework by introducing the standard smagorinsky subgrid viscosity ν t into the total viscosity by ν ν ν t wang et al 2014 whose value can be evaluated by 7 ν t c δ 2 s where c is the smagorinsky constant δ is the filter length scale of a large eddy and s is the absolute value of the strain tensor 2 2 boundary conditions the no slip boundary condition is imposed on the rigid walls of the tank and baffles and the implementation of this boundary condition follows the standard bounce back scheme in the lbm 8 f i ˆ x b t δ t f i x f t where f i ˆ and f i denote the particle velocity distributions in opposite directions and x b and x f indicate the lattice on the rigid wall and the corresponding neighbouring fluid lattice respectively x f x b c i δ t as sketched in fig 1 the mass tracking algorithm körner et al 2005 thürey et al 2006 was adopted to track the free surface boundary and its implementation is similar to that of the volume of fluid vof method which has been extensively employed in traditional computational fluid dynamics cfd methods gopala and wachem 2008 the lattices are divided into three types namely liquid interface and gas lattices the volume fraction of fluid v x t ranges between 0 and 1 on the interface lattice and is fixed at 1 and 0 on the liquid and gas lattices respectively the macroscopic variable of mass in each node is correlated to the volume fraction according to m x t v x t ρ x t additionally mass exchange is permitted only through the interface lattice whose mass distribution is updated as follows 9 m x t δ t m x t n 0 18 a i f i ˆ x c i δ t t f i x t where a i depends on the types of the two neighbouring lattices in the i direction and can be expressed as follows 10 a i 1 2 v x c i δ t t v x t interface interface liquid gas 1 liquid liquid 0 gas gas the distribution function of the gas lattice can be reconstructed from the distribution function of the interface lattice by assuming that the gas lattice has the same reference pressure and velocity as those of the neighbouring interface lattice and thus it can be expressed as follows 11 f i ˆ x t δ t f i e q ρ g u f i ˆ e q ρ g u f i x t where ρ g represents the reference density equals to 1 in this paper and u represents the velocities of the interface and gas lattices a schematic diagram illustrating the steps for executing the temporal evolution of flow through the interface lattice is shown in fig 1 3 parameter settings fig 2 illustrates the dimensions of the rectangular tank namely l length b breadth and h height sloshing is excited by the harmonic oscillation of the tank in the x direction the oscillation velocity u x and the inertial force f x induced by the moving reference frame fixed on the tank are expressed by 12 u x t a σ sin σ t f x m a m u m a σ 2 cos σ t where a a and σ are the external horizontal amplitude acceleration amplitude and angular frequency respectively therefore the external force vector f employed by equation 5 is expressed by 13 f t f x f y ρ v a σ 2 cos σ t ρ v g the non baffled sloshing in a rectangle tank can be characterized by five dimensionless parameters ji et al 2012 namely the froude number f r u 0 g l the reynolds number r e u 0 l ν the aspect ratio of static fluid depth and length of the tank a r h w l the normalized amplitude of oscillation η 2 a l and the frequency ratio between the external forcing and the first natural mode α σ σ 0 the reference velocity u 0 is defined by u 0 σ l 2 π and the first natural frequency of sloshing in a rectangular tank can be estimated as follows liu and lin 2008 14 σ 0 g π l tanh π h w l furthermore the viscous boundary layer should be excessively considered for the analysis of the energy dissipation the boundary layer thickness d can be calculated first using the formula below jin and lin 2019 15 d o 2 π ν σ 0 the corresponding boundary layer is 1 43 mm therefore the influence of the boundary layer can be ignored for a small viscous fluid as shown in fig 2 three additional parameters are specified to describe the present problem due to the influence of baffle configuration and the top wall including the normalized baffle height h b h w the normalized distance between the baffle and side wall l b l and the normalized tank height h l meanwhile the thickness of the baffle is negligible the instantaneous free surface elevation is recorded at x 1 1 10 l and the transient impact pressure at y 1 3 4 h and y 2 h on the left side wall is also traced for further analysis for the numerical simulations presented in the study the fluid density ρ and kinematic viscosity ν of water are taken as 1 0 10 3 kg m3 and 1 0 10 6 m2 s receptively the value of gravity acceleration g is 9 81 m s2 the dimensions of the tank are l 3 0 m b 1 2 m and h 2 0 m the amplitude and angular frequency of tank oscillation are a 0 2 m and σ 3 14 rad s respectively the fluid depth is fixed at h w 1 5 m following the aforementioned definitions the dimensionless parameters are determined as f r 0 28 r e 4 50 10 6 a r 0 50 η 0 13 and α 1 02 according to faltinsen and timokha 2009 and jung et al 2012 the unbaffled sloshing with such parameters will be under resonance and finite depth conditions and it features a large amplitude impact wave the different baffle configurations for tests 1 17 are summarized in table 1 we note that the influence of surface tension and capillary forces were not considered in the present study as they are negligible for the large scale and high reynolds number conditions the homogeneous spatial resolution is δ x 0 01 m and the temporal iteration step is δ t 1 0 10 4 these values were adopted after the sensitivity analysis the smagorinsky constant and the large eddy filter length were determined as c 0 14 and δ δ x respectively the accuracy and efficiency of the present numerical have been validated by comparisons against previous experimental and numerical results as detailed in the appendix readers may refer to krüger 2011 and chen et al 2018b for the conversion between the physical and lattice units 4 results and analysis 4 1 transient sloshing states without a baffle as shown in fig 3 the transient sloshing states for unbaffled sloshing under resonant condition were introduced first to facilitate the subsequent qualitative analysis of the damping effect in the baffled cases these transient flow states include the excitation top slamming and wave breaking states which were classified based on the characteristics of corresponding free surface waveforms observed in previous experimental studies faltinsen et al 2005 2006 royon lebeaud et al 2007 faltinsen and timokha 2009 colagrossi et al 2006 the excitation state usually appears first during the first half period when the free surface moves in the form of planar waves with low surface velocity while the amplitude of sloshing wave increases from zero but is still far less than under the saturated condition fig 3a as the sloshing wave accumulates mechanical energy from the large amplitude oscillatory motion of the tank the wave crest moves upward fast along the side like a jet flow until slamming on the top wall and induces a considerable impact pressure which is referred to as the top slamming state fig 3b however the free surface is still relatively continuous and no significant wave breaking behaviour was observed in the top slamming state on the other hand the wave breaking state features a splashing wave or plunging wave the splashing wave forms when the wave crest impacts the top wall with a higher kinetic energy than that of the jet wave such that the tongue of the wave crest breaks into small droplets which are ejected from the impact zone and then fall down like a parabolic motion fig 3c the plunging wave forms due to the slowing down of the wave base meanwhile the wave crest still moves upward such that the wave front becomes concave until the collapse of the wave crest fig 3d notably the plunging wave does not lead to as large a wall pressure as that by the jet splashing wave but the occurrence of wave breaking in the internal tank induces significant dissipation of mechanical energy generally the sloshing state alternates mainly between the top slamming state and two wave breaking states under large amplitude resonance conditions after the first period of oscillatory motion in the following sections we focus on the influence of baffle configurations on the sloshing states from the perspectives of waveform free surface elevation wall pressure and energy balance 4 2 influence of the baffle height in this section we investigate the damping effect of a single vertical baffle mounted at the centre of the tank bottom l b l 0 5 with different heights by comparison with the numerical results of tests 1 6 according to faltinsen and timokha 2009 the first natural frequency of 2 d sloshing can be modulated by the immersed baffle under such a configuration and it can be estimated by 16 σ 0 2 σ 0 2 1 2 π 2 sin 2 π 2 sinh 2 π h w l h b l 2 therefore the modulated dimensionless frequent ratios for tests 1 4 are α 1 02 1 04 1 08 and 1 17 respectively as shown in table 1 as for tests 5 and 6 two sections were separated by a central baffle in the tank for h b h w yielding the equivalent baffle length l 0 5 l and the corresponding frequent ratio α 0 69 similarly the modulated dimensionless frequent ratios for tests 7 11 are α 1 02 which shows that the tests are in resonance condition 4 2 1 free surface elevation fig 4 depicts the transient trace of the free surface elevation e h of tests 1 6 during the first five periods where e y h w is the instantaneous free surface height relative to the fluid depth at stillness detected at x 1 the maximum elevation limited by the top wall was reached for tests 1 3 just within the second half cycle in the first period as indicated by fig 5 the splashing wave was observed for tests 1 3 at t t 1 while the spilling distance of the breaking droplets decreases with the increase in baffle height an obvious shearing effect and vortex generation at the tip of the baffle which is similar to wu et al 2012 can be observed in fig 5 for tests 2 and 3 however the splashing wave still impacts the left top and right top walls alternatively and only results in the general decrease in the duration and amplitude of the wave impact during the sloshing period with the increase in baffle height the top slamming state was only transiently reached for test 6 in the first two periods leading to a peak of e h at t t 1 4 but the large deviation from the resonance frequency due to the high baffle finally led to a more stabilized sloshing state in the subsequent periods the damping effect of a single vertical baffle was the most significant when 0 75 h b h w 1 as the top slamming state and the splashing wave breaking state completely disappeared for tests 4 and 5 as shown in fig 5 the wave breaking state with plunging waves with air bubble entrapment is a predominant phenomenon when the tip of baffle is close to the free surface at stillness which has also been demonstrated by the experimental results in xue et al 2017b such a baffle configuration is favourable for the formation of plunging waves because the wave crest can jump over the baffle while the wave base is blocked by the baffle the most intensive shearing effect was observed for test 5 because the flow velocity increases with the proximity to the free surface such that the interaction between the near surface fluid and baffle leads to the strong viscous dissipation this will be quantitatively discussed in detail in addition to the viscous dissipation we note that the significant modulation of the natural frequency is the other major factor contributing to the overall damping effect of the vertical baffle and the natural frequency is mostly deviated from the resonance frequency for test 5 according to equation 16 therefore the amplitude of the free surface elevation is approximately at the same level for tests 4 and 5 under the coupling influence of the aforementioned factors while the obvious phase difference in peaks was due to the different frequency modulations 4 2 2 vortical flow and energy dissipation in this section we mainly study the effect of the baffle on the dissipation of energy constituted by the free surface dissipation and internal dissipation the energy balance relationship of the fluid in the tank with respect to the non inertial system is worth noting according to the chapman enskog analysis the bgk equation is equivalent to the navier stokes equation from which iafrati 2009 derived the following energy balance equation 17 d e t d t ω ρ u 2 2 u n d s ω p u n d s ω μ u ω n d s ω μ ω 2 d ω ω ρ a u d ω 18 e t e k e p ω 1 2 ρ u 2 d ω ω ρ g e d ω where e t is the total mechanical energy that includes the kinetic energy e k and potential energy e p of the fluid the first three terms on the right side of equation 17 represent the kinetic energy flux work by pressure and work by tangential stresses which are homogeneously zero for the present problem because of the non slip boundary velocity condition u 0 on the walls with respect to the non inertial reference frame the two remaining terms of equation 17 denote the viscous dissipation and work by inertial force whose instantaneous values determine the rate of change of the total mechanical energy the viscous dissipation is also known as entropy which is dependent on the sum of squares of the vorticity components ω x ω y and ω z despite ω z playing the most dominant role in such a problem featured by planar sloshing lu et al 2015 fig 6 depicts the contour of the instantaneous vorticity amplitude as counterparts of fig 5 during the second period while the snapshots of the 3d surface profiles shown in fig 7 demonstrate the breaking waveforms of tests 1 6 at the instant when the corresponding kinetic energy e k reaches the peak value for the unbaffled case of test 1 the vorticity is mainly generated by the splashing wave after impacting the top wall every half cycle as shown in fig 7 the breaking droplets form a significant splashing zone in tests 1 and 2 and fig 6 indicates that the falling droplets manifest strong vorticity for their rotation and deformation from tests 2 to 4 the internal vorticity field intensifies with the increase in baffle height fig 6 meanwhile the strength of the splashing wave decreases and almost vanishes in test 4 where the free surface is similar to the plunging wave fig 7 the intensity and distribution of vorticity of test 4 at t t 2 00 is significantly superior to that of other tests at any instant displayed in fig 6 due to the strong shearing interaction between the shedding vortex and the fluid near the wave surface however a higher baffle with h b h w 1 in tests 5 and 6 weakened the shearing effect at the baffle tip and part of the interior vortex is caused by the entrapped fluid due to plunging wave breaking similar to the experimental observation in xue et al 2017a the vorticity amplitude of test 6 was relatively small compared to the other cases as the baffle almost separates the tank into two smaller ones where the top slamming state is the dominant phenomenon figs 6 and 7 in the present study the energy dissipation that occurred on the interface and interior of the fluid was distinctively quantified to evaluate the contribution of wave breaking and vortex generation to damping 19 ψ f ω μ ω 2 v δ v 1 d ω 20 ψ i ω μ ω 2 δ v 1 d ω where the dirac function δ v 1 equals 1 for an interior fluid whose volume of fraction v 1 otherwise it equals 0 at the interface the transient traces of the surface and internal energy dissipation rates of tests 1 6 are shown in fig 8 by employing equations 19 and 20 in general the internal dissipation is always larger than the surface dissipation rate for each test we note that the surface dissipation is basically induced by wave breaking but not vice versa as no vortex was generated by the baffle in test 1 but ψ i still surpasses ψ f for the occurrence of wave breaking the internal dissipation experiences a rapid increase until reaching a saturated state which takes approximately 2 3 cycles and is dependent on the height of the baffle but apart from tests 1 and 5 no obvious cycle to cycle periodicity can be observed from the transient traces of the energy dissipation rate the free surface dissipation was even more irregular than the internal dissipation since the wave breaking behaviour is highly nonlinear similar to the qualitative observation according to fig 6 the amplitude of internal dissipation increases with the increase in baffle height for h b h w 1 despite the ψ i of test 3 being higher than that of test 4 at certain phases due to the frequency shift in contrast the increase in baffle height for h b h w 1 led to an abrupt reduction in ψ i the internal dissipation was mainly caused by the wave breaking and the vortex shedding from the tip of the baffle and both phenomena were weakened by the bottom mounted baffle piercing the free surface of the fluid at rest in general we conclude that the vertical baffle with a height slightly below the fluid depth is most favourable for the damping of sloshing through energy dissipation in addition the energy dissipation was studied with a single baffle at the bottom of the tank under resonance conditions fig 9 shows the transient traces of the total energy dissipation rate of test 1 and tests 7 11 under resonance conditions the energy dissipation rate of the system will gradually increase and fluctuate around a larger value compared with test 1 the energy dissipation of tests 7 11 was significantly enhanced when h b h w 1 the dissipation of the system will increase as the baffle increases meanwhile until h b h w increases to 0 5 the increase in energy dissipation is no longer obvious when h b h w 1 compared with the baffle below the liquid level the energy consumption effect weakens obviously fig 10 shows the velocity contour of test 1 and tests 7 11 at peak kinetic energy which shows that all tests had the process of the top slamming state and the violent wave breaking state under the resonance condition for tests 7 9 the vortex generated at the top of the baffle was more conducive to energy dissipation under resonance conditions as shown in figs 9 and 10 furthermore the resonance effect of test 11 was more intense than that of test 10 because the breaking wave splashes on the liquid surface on the other side of the baffle changing the natural frequency of the system on the other hand compared with the tests of non resonance the movement of the free surface was more intense under resonance conditions therefore the influence of relationship between external excitation frequency and natural frequency on sloshing is very important 4 3 influence of the spacing of two baffles multiple baffles are already commonly installed in lng carriers to damp the sloshing movement intensity of liquid fuel however the existing laboratory experiments and or numerical studies have seldomly specified the influence of baffle spacing on the coupled interaction of multiple baffles by comparing the free surface elevation wave amplitude and impact pressure on the wall for tests 12 17 we investigated the damping effect of two symmetrically installed baffles with a fixed optimal height h b h 0 75 but different spacing distances away from the side wall l b l 0 13 0 47 similar to fig 4 the transient traces of the free surface elevation of tests 12 17 at x 1 is plotted in fig 11 the variation in elevation of test 12 is similar to that of test 1 as the baffles became invalid in damping the sloshing when they were in proximity to the side wall as l b l 0 likewise the variation in the elevation of test 17 was similar to that of test 4 for the two baffles which acted like a single baffle while getting closer to each other towards the limit l b l 0 5 the amplitude of elevation was best suppressed for test 15 whose spacing distance was l b l 0 33 as e h is less than 0 2 after the first transient cycle therefore the relatively uniform distribution of multiple baffles in the tank is more effective at suppressing the amplitude of the sloshing wave the instantaneous velocity contours of tests 12 17 during the second period are also displayed in fig 12 for comparison against fig 5 the free surface profile of test 12 is similar to the unbaffled case of test 1 which also manifested the features of a splashing wave despite the interaction between the wave and baffles giving rise to tip vortices near the side wall the wave breaking phenomena that occurred in test 4 were generally reproduced in test 17 where the two baffles with a narrow gap can be regarded as a thicker one the mitigating effect of multiple baffles can be observed in tests 13 16 and the vortices were generated and shed on the tip of both baffles making the velocity field more complicated due to the stronger nonlinear effect on the other hand the velocity gradient became weaker with increasing baffle number which was also noted by chu et al 2018 in addition multiple plunging waves can be generated in half a cycle with the presence of multiple baffles as they block the horizontal motion of the wave base which is favourable for the wave crest curl down to form the plunging wave for a more intuitive description of the suppression of wave breaking by baffles fig 13 shows a three dimensional velocity snapshot of the maximum kinetic energy in the second period suggesting that the degree of wave breaking for tests 14 16 was greatly reduced fig 14 shows the transient wall pressure at two measuring points y 1 and y 2 which are flush with the free surface at rest and on the corner of the left wall respectively as indicated in the schematic diagram in figs 2 and fig 15 shows the contour of the peak pressure in the second period from a to i in fig 14 for tests 12 and 13 the periodic peak pressure resulted from top slamming of the wave onto the side wall y 1 in fig 14 a and top wall y 2 in fig 14 b for a violent top slamming case such as test 12 the amplitude of peak load at the free surface is several times larger than that in other cases at the same position the impact pressure on the side wall at y 1 mainly resulted from the impact of the leftward horizontal motion of the wave crest as shown in fig 15 but the kinetic energy can be transformed into gravitational potential energy and the primary direction of momentum is converted from horizontal to vertical afterwards the upwelling motion of wave crest is immediately restricted by the tank roof such that it strikes the top wall like a water hammer as l b l increases the horizontal motion is effectively suppressed by both baffles and the damping effect becomes stronger no obvious peak pressure was detected for 0 27 l b l 0 40 until l b l 0 47 the pressure measured at y 2 reappears and its value is smaller than that in test 12 therefore the spacing distance is critical for the damping effect on the sloshing amplitude such that multiple baffles with a poor arrangement will have a less significant mitigating effect than a baffle or double baffles with the proper distribution 5 conclusion this study employed a les vof model in the framework of lbm to investigate the problem of liquid sloshing with wave breaking in a partially filled rectangular tank under resonance conditions the damping effects subject to single and double vertical baffles of different heights or spacing distances were analysed with respect to the liquid elevation free surface profile energy dissipation and impact pressure the main conclusions of this work can be summarized as follows for the sloshing phenomenon when the excitation frequency is close to the natural frequency of the tank the damping of vertical baffles is essentially induced by two factors namely the modulation of resonance frequency and the viscous dissipation caused by strong shearing interaction the optimal height for damping the sloshing amplitude by a single vertical baffle is reached for 0 75 h b h w 1 where the top slamming state and the splashing wave breaking state can be completely eliminated and the stronger plunging wave breaking can be observed a quantitative method is first proposed to distinctively quantify the viscous dissipation that occurred on the interface and interior of the fluid it was employed to evaluate the contribution to damping of wave breaking and vortex generation internal dissipation was far higher than interface dissipation the intensity of internal dissipation increases with the proximity of the baffle tip to the free surface as the interaction between the near surface fluid and baffle leads to the onset of strong vorticity for the cases with two vertical baffles they became invalid in damping the sloshing when they were in proximity to the side wall and acted like a single baffle when they were close to each other the relatively uniform distribution of multiple baffles in the tank was more effective at suppressing the amplitude of the sloshing wave the spacing distance is important for achieving a damping effect on the sloshing pressure and the proper distribution of two vertical baffles can reduce the peak impact pressure to more than about three times lower than that when double baffles with a poor arrangement are used credit authorship contribution statement chunlei ma conceptualization methodology software data curation writing original draft visualization investigation chengwang xiong supervision software validation data curation writing review editing guowei ma supervision writing original draft declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors would like to acknowledge the financial support from the national natural science foundation of china no 51909055 china postdoctoral science foundation no 2019m652480 natural science foundation of hebei province no e2019202471 the corresponding author c x would like to acknowledge the support from shandong provincial key laboratory of ocean engineering no kloe201904 and state key laboratory of coastal and offshore engineering no lp1921 appendix numerical validation comparison with experimental results the numerical simulation performed using the lbm method was compared with the experiment from faltinsen and timokha 2002 which has been widely verified by ji et al 2012 the parameters in table 2 test 18 are exactly the same as in faltinsen s experiment and the numerical results can be found in fig 16 the time history curves of the liquid elevation show good agreement between the two experiments furthermore we compared the wall pressure and the photo of the free surface height with baffles obtained from the experimental results of xue et al 2017b the parameters are show in results are shown in table 2 tests 19 and 20 the results are shown in figs 17 and 18 the lbm calculation results in the present study achieved a reliable numerical accuracy table 2 the experimental and numerical comparison parameters of tests 18 21 in this paper table 2 test l m b l h l h l a l ω rad s h b h l b l 18 1 73 0 115 0 607 0 173 0 028 3 696 19 0 57 0 544 0 316 0 035 5 442 20 0 57 0 544 0 316 0 018 6 019 0 186 0 5 21 1 00 1 000 0 500 0 200 3 140 fig 16 comparison of the transient wave elevation at a position x 0 0 05 m between the present numerical result and the experimental data in fig 7 of faltinsen and timokha 2002 and fig 2 of ji et al 2012 fig 16 fig 17 comparison of the pressure at p1 a a p2 b b and p3 c c between the present numerical result and the experimental data in fig 3 of xue et al 2017b fig 17 fig 18 comparison of photos of transient wave elevation between the present numerical result and the experimental data in fig 10 of xue et al 2017b fig 18 efficiency comparison with fvm the computational efficiency and time step sensitivity of lbm were compared with those of the fvm by conducting the same test the commercial software fluent3d which is based on the fvm with the vof model is widely used to simulate fluid dynamics problems with free surface problems armenio and rocca 1996 liu and lin 2008 the lbm and fvm tests applied parameter settings described in table 2 test 21 and the mesh precision described in table 3 assuming that the tank is secured on a shaker and subjected to a sinusoidal horizontal excitation with a velocity function the employed mesh system has 100 100 uniform and vertical meshes in fluent3d using the vof model while the resolution n x is 100 in the lbm using the les bgk d3q19 model to neglect the effect in the z direction we set the boundaries of the front and back walls to be fluid which ensures the same settings for both methods table 3 comparison of calculation time memory and stability between lbm and fvm where d represents the variance of tests table 3 n t s cpu time h ram d fvm 1 0 10 2 1 583 16 gb 0 0196 5 0 10 3 3 5 1 0 10 3 7 5 lbm 5 0 10 4 0 533 8 gb 0 0131 1 0 10 4 1 2 5 0 10 5 2 75 convergence test of time step fig 19 the sensitivity of time step in test 21 between fvm method and lbm method where h 0 5 m fig 19 three tests were performed to analyse the sensitivity to the time step the results shown in fig 19 indicate that the fvm exhibits a large computational deviation in the final period while the lbm remains fairly stable at the same time in addition the computation time and variance analysis are summarized in table 3 which shows the advantages of the lbm namely its high computational efficiency and insensitivity to the time step convergence test of mesh resolution four different mesh systems were considered for h w h 50 and 75 to test the grid dependence of the resolution under the resonance conditions the parameters are listed in table 2 test 21 the results in fig 20 and table 4 indicate that the good computational convergence achieved with the lbm shows little dependence on the mesh in addition the lbm exhibits better stability for the calculation of large amplitude sloshing considering the computation time and accuracy a resolution of n x 100 was adopted for the analysis in this paper fig 20 the sensitivity of mesh in test 21 with lbm method where h 0 5 m in a and h 0 75 m in b fig 20 table 4 comparison of free surface elevation with different resolution in 50 and 75 depth using lbm where e m a x and e r e indicate the elevation of the extremum and relative error table 4 h w h n x x 0 1 x 0 5 d e m a x e r e d e m a x e r e 50 180 120 72 0 0414 0 4885 4 14 0 0192 0 1112 1 92 240 160 96 0 0329 0 4813 3 29 0 0134 0 1340 1 34 300 200 120 0 0386 0 3569 3 86 0 0207 0 1052 2 07 360 240 144 0 0389 0 4390 3 89 0 0161 0 0813 1 61 75 180 120 72 0 0442 0 4511 2 71 0 0161 0 0591 1 07 240 160 96 0 0453 0 4554 2 80 0 0127 0 0762 0 85 300 200 120 0 0332 0 2042 2 02 0 0131 0 0981 0 88 360 240 144 0 0380 0 3400 2 36 0 0142 0 0729 0 95 
20997,this paper summarized a study that aims to investigate the applicability of a fracture mechanics fm based approach for calculating the fatigue lives of the mooring lines of a spar based floating offshore wind turbine fowt in time domain tension ranges of mooring lines are calculated from a time domain hydrodynamic analysis taking into account the effects of wind wave and current mooring tension cycles with corresponding ranges are counted by a rain flow counting method a comparison between fatigue lives of mooring system predicted by s n curves t n curves and the fm based approaches is made and the results show that the fm based approach generally provides reasonable estimate of fatigue lives of the mooring lines of the fowt parametric studies were further performed to investigate the effects of loading sequence stress concentration factor initial crack shape initial crack size and critical crack depth on fatigue life prediction of the fm based approach it was observed that the predicted fatigue life is sensitive to stress concentration factor and initial crack size a comparative study on three kinds of mooring design with different chain diameters is also made and the applicability of each design is discussed keywords floating offshore wind turbine fowt mooring line fatigue fracture mechanics time domain 1 introduction in the past few decades tremendous progress has been made in the advancement of offshore wind turbines a large amount of commercial bottom fixed offshore wind turbines have been in service though most of them are economically limited to shallow waters campanile et al 2018 to install offshore wind turbines at water depth greater than 35 40 m and to enable stronger and more constant offshore wind the development of floating offshore wind turbines fowt has become one of the primary trends in 2009 the world s first experimental full scale spar based fowt hywind demo was installed by statoil in the north sea driscoll et al 2016 after that a semi submersible type fowt windfloat was successfully installed in 2011 valverde 2015 in 2017 the world s first commercial floating wind farm equinor 2018 30 mw hywind scotland pilot park which consists of five 6 mw spar based fowts was constructed and put into service unlike bottom fixed offshore wind turbines station keeping for a fowt is primarily dependent on its mooring system mooring safety is thus crucially important to a fowt traditionally mooring fatigue analysis for offshore structures is mainly conducted based on the palmgren miner s rule with use of s n curves or t n curves api rp 2sk 2008 dnvgl os e301 2015 cheng et al 2017 made a comparison on mooring fatigue damage of floating horizontal axis wind turbines hawts and vertical axis wind turbines vawts using a s n curves based approach campanile et al 2018 applied s n curves to fatigue limit state design of mooring systems of fowts installed at intermediate and deep water depths li et al 2019 applied s n curves to investigate the influence of wind and wave on the mooring fatigue of a spar based fowt xu et al 2019 conducted a time domain mooring fatigue analysis for a semi submersible fowt with use of t n curves where the effect of wave nonlinearity is considered barrera et al 2019 proposed a life cycle methodology for mooring fatigue assessment of a fowt and a comparison on fatigue damage achieved from the new method and the standard methods using s n curves and t n curves was made over the past few decades mooring accidents of offshore floating structures occurred at a high rate in the report of d souza and majhi 2013 there were 23 mooring failure incidents on floating production systems and at least 150 mooring lines were replaced or repaired during 2000 2011 drori 2015 analysed an industry survey of 107 offshore mooring failures and estimated that the failure rate of single mooring line is 2 5 10 2 per asset per year this high failure rate is also mentioned in fontaine et al 2014 which indicated that fatigue is one of the most prevalent causes of failure and at least 24 of mooring failures are due to fatigue therefore in addition to the s n t n curves based approaches there might be a need to develop other rational methods for mooring system fatigue analysis during the design phase of offshore floating structures as another effective approach for fatigue analysis the fracture mechanics fm based mooring system fatigue analysis is being received more attention mathisen and larsen 2004 applied a fm based approach to crack growth prediction for risk based inspection planning of mooring chains palin luc et al 2010 and pérez mora et al 2015 conducted a series of experiments to investigate the crack growth behaviour of mooring chains in corrosive environments fatigue lives of mooring chains predicted by a fm based approach were compared with the experiment results xue and chen 2018 performed a fm based mooring fatigue analysis for a semi submersible subjected to low frequency and wave frequency loading processes considering various load combination methods xue et al 2018 presented a fm based mooring fatigue analysis for a semi submersible in frequency domain and a parametric study was conducted to investigate the impact of relevant parameters on fatigue life prediction of the fm based approach arredondo et al 2018 conducted a finite element analysis to measure stress intensity factors on mooring chains considering a variety of crack and load combination ibekwe et al 2018 investigated the remaining strength and fatigue damage of the degraded top mooring chains of the bonga fpso and single point mooring spm loading buoy with use of a fm based approach lee and kim 2019 performed a fm based probabilistic flaw assessment for a surface crack in a mooring chain recently xue et al 2020a conducted a fm based investigation on the mechanism of out of plane bending opb between mooring chain links and its effects on fatigue lives of mooring chain links xue et al 2020b carried out a mooring fatigue assessment for mooring chain links of a semi submersible operated in offshore west africa owa and three cases that mooring chain links are subjected to pure tension out of plane bending opb and torque are considered in the assessment nevertheless at the current stage the fm based fatigue assessment for offshore mooring system is generally not well established due to the complexity of the application such as how to select the initial crack shape how to define the critical crack size how much ctod should be chosen how to apply the fatigue loading etc most of offshore design codes only provide conceptual guidance but no detailed guidance about how to apply the fm based approach for mooring system fatigue analysis as a type of emerging offshore floating structures there is even less engineering practice on the mooring system analysis for fowts therefore as an extension of the work of xue et al 2018 this paper aims to investigate the applicability of a time domain fm based mooring system fatigue analysis for a spar fowt through a comparison between t n and s n curves based fatigue analyses a parametric study is further conducted to investigate the effects of loading sequence stress concentration factor initial crack shape initial crack size and critical crack depth on the time domain fatigue life prediction of the fm based approach in addition a comparative study on three kinds of mooring design with different chain diameters is also performed and the applicability of each design is discussed 2 spar based fowt and mooring system an oc3 hywind spar based fowt with a catenary mooring system assumed to be operated at south china sea is considered in this paper the mooring system consists of three mooring lines distributed at an angle of 120 three kinds of studless chains with different diameters 2 5 inch 4 inch 5 inch are taken into account for mooring design of the fowt to investigate the applicability of each design 2 1 spar based fowt the spar based fowt considered in this paper is defined in the phase iv of oc3 project by nrel jonkman et al 2009 jonkman 2010 which consists of an nrel 5 mw wind turbine and a spar based platform the principal parameters of wind turbine and platform are listed in table 1 and the geometry sketch of the spar based fowt is shown in fig 1 2 2 mooring system the catenary mooring system is composed of three mooring lines as shown in fig 2 adjacent lines are 120 separated attaches to the platform via a delta connection which is to provide the yaw restoring moment three kinds of mooring chains with different diameters 2 5 inch 4 inch 5 inch are considered for the mooring system and the design life of mooring system is assumed to be 25 years as recommended by dnvgl os e301 2015 the transverse and longitudinal drag coefficients are set as 2 40 and 1 15 respectively the friction coefficient at seafloor is assumed to be 1 0 wu et al 2015 the principal parameters of the mooring chains are listed in table 2 3 environmental conditions the spar fowt is assumed to be installed and operated at south china sea the sea states are listed in table 3 huang et al 2011 where h s is the significant wave height t p the peak period v w the mean wind velocity v c the mean current velocity and p the occurrence probability of each sea state the wave wind and current in collinear direction aligned with the rotor of fowt is shown in fig 2 3 1 wave load interaction between wave and a fowt normally generates three components of mooring line tension including mean mooring line tension induced by the mean wave drift load wave frequency mooring line tension induced by the first order wave and low frequency mooring line tension induced by the second order wave load the wave induced load acting on the fowt is achieved in terms of the morison equation and the jonswap spectrum in which the morison equation for floating structure is given as morison et al 1950 sumer and fredsøe 2006 1 f m ρ w v u w ρ w c a v u w v p 1 2 ρ w c d a u w v p u w v p where f m is the fluid force per unit length ρ w the density of water v the volume of the platform u w the fluid velocity u w the fluid acceleration c a the added mass coefficient v p the velocity of platform v p the acceleration of platform c d the drag coefficient a the drag area in the hydrodynamic analysis the jonswap spectrum s ω is used for the wave simulation isherwood 1987 2 s ω α g 2 ω 5 e x p 5 4 ω p ω 4 γ e x p ω ω p 2 2 σ s 2 ω p 2 where g is the acceleration due to gravity ω the wave frequency ω p the peak wave frequency γ the peakedness parameter α and σ s are spectrum parameters which can be referred to marintek 2012 3 α h s ω p 2 4 g 2 0 065 γ 0 803 0 135 4 σ s 0 07 f o r ω ω p 0 09 f o r ω ω p where h s is the significant wave height 3 2 wind load mean wind forces based on 1 h average velocity above mean water level and time varying wind forces due to wind gusts are considered herein the wind force is considered as drag force and it is given by 5 f w 1 2 c w ρ a a w u d z v p u d z v p where c w is the drag coefficient ρ a the density of the air a w the projected area of the surface perpendicular to wind u d z is the 1 h average wind velocity at elevation z above sea level which is considered as a statistical value that is generated from the api wind spectrum api rp 2a wsd 1993 6 s a p i f i z u d z 2 f p 1 1 5 f f p 5 3 where s api f is the spectral energy density at the wind frequency f f p can be calculated by 7 f p 0 025 u d z z u d z can be calculated by 8 u d z u 0 z z r 0 125 where u 0 is the 1 h mean wind speed at elevation of 10m above sea level z r 10 m i z is the turbulence intensity and it is expressed as 9 i z 0 15 z z s 0 125 f o r z z s 0 15 z z s 0 275 f o r z z s z s 20 m 3 3 current load current is considered as a steady flow in the mooring analysis the current load is given by 10 f c 1 2 c c ρ w a c u c v p u c v p where c c is the drag coefficient a c the projected area of the surface perpendicular to current u c the velocity of the current 4 mooring line tension 4 1 time domain dynamic analysis the dynamic mooring analysis can be performed in time domain or frequency domain in general a time domain analysis is considered more accurate than a frequency domain analysis as time domain analysis takes into account the nonlinear and coupling effects between environmental loads and structural responses in this section mooring tension ranges are from a time domain dynamic analysis where mass damping stiffness loading etc are calculated at each time step with considering the instantaneous and time varying geometry mooring lines are modelled through a finite element analysis and they are discretized into individual nodes which carries six degrees of freedom the governing function is given by orcina ltd 2019 11 m p a c p v k p f p v t where m p a c p v and k p are matrices of inertia damping and stiffness respectively f p v t represents the external force p the position vector v the corresponding velocity vector and a the corresponding acceleration vector t the simulation time fig 3 shows the tension responses of the three mooring lines with the 4 inch chain under the sea state where h s 1 55 m t p 6 s v w 9 4 m s v c 0 282 m s 4 2 rain flow counting tension cycles with the corresponding ranges are counted by the rain flow counting method proposed by matsuishi and endo 1968 which is widely accepted for time domain fatigue analysis the algorithm procedure of the method is shown in fig 4 and the details can be referred to astm 2005 5 s n and t n curves based fatigue analysis traditionally mooring fatigue analysis for offshore structures is mainly conducted based on the palmgren miner s rule miner 1945 with use of t n or s n curves api rp 2sk 2008 dnvgl os e301 2015 5 1 s n curves based approach in this approach in terms of the palmgren miner rule the fatigue damage d is calculated as 12 d n i n i where n i is the number of cycles of a constant stress range s i acting on the structure n i represents the number of cycles to failure under the constant stress range s i n i can be determined from a s n curve as shown in fig 5 as 13 n i k s s i m s where m s is the slope of the s n curve k s the intercept parameter as shown in table 4 the reference values of the parameters m s and k s suggested by dnvgl os e301 2015 are utilized herein for the s n curves based fatigue damage calculation 5 2 t n curves based approach similar to the s n curves based approach the fatigue damage d in the t n curves based approach is also calculated in accordance with the eq 12 but the n i in the t n curves based approach is the number of cycles of r i that is the ratio of a constant tension range to reference breaking strength rbs of the mooring line n i represents the number of cycles to failure under the r i and it can be achieved from a t n curve as shown in fig 6 as 14 n i k t r i m t where m t is the slope of the t n curve and k t the intercept parameter according to api rp 2sk 2008 if rbs is not available it can be approximately estimated by the following equation 15 r b s 0 0211 d 2 44 0 08 d where d is the chain diameter as shown in table 5 the reference values of the parameters m t and k t suggested by api rp 2sk 2008 for studlink and studless chains are used in the t n curves based fatigue damage calculation 6 fracture mechanics analysis this section is to perform the fracture mechanics fm based mooring system fatigue analysis firstly the mooring chain is treated as a round bar and an initial surface crack is assumed to propagate at the surface of the chain link secondly a finite element fe analysis is performed to predict the tension induced membrane and bending stresses acting on cross sections of mooring chains then the stress intensity factors are calculated according to the bs 7910 2013 the crack propagation is finally estimated by the paris law paris and erdogan 1963 a flowchart summarizing the main steps of the fm based approach is shown in fig 7 due to the manufacture or installation process such as welding process proof loading test the overload during the installation etc defects are often initiated in the mooring chain links and these defects are normally regarded as initial cracks in the fm analysis at present there is still no existing industry codes developed on how to select initial crack size initial crack shape and also critical crack size for offshore mooring chain links according to the abs guide for fatigue assessment of offshore structures abs 2018 and the work of chen et al 2011 for surface cracks starting from the transition between weld base materials a crack depth of 0 5 mm may be assumed if no data on crack depth are available as a result the initial crack depth of 0 5 mm is chosen in the fm analysis semi elliptical and semi circle surface cracks are two common types of the initial crack shapes recommended by bs 7910 2013 in engineering practices therefore an initial semi elliptical or semi circle surface crack with the initial crack depth 0 5 mm is assumed at the surface of the mooring chain link the choice of critical crack depth is made based on the work of mathisen and larsen 2004 where the critical crack depth is suggested to be 12 of the chain diameter in addition the welding quality that normally determines the value of scf at the weld section of a mooring chain link is also taken into account in the fm analysis as suggested by chen et al 2011 a calibrated scf around 2 0 for weld section of a mooring chain link is applied in the fm analysis 6 1 paris law and stress intensity factor based upon the paris erdogan equation paris and erdogan 1963 the crack depth a d can be estimated by 16 d a d d n c k δ k f m where a d is the crack depth n the number of stress cycles c k and m are the material constants δk f is the stress intensity factor range the stress intensity factor k f can be calculated as bs 7910 2013 17 k f y σ π a d where y is the stress intensity correction factor σ the stress acting on the mooring chain yσ is defined as 18 y σ m f f w m m k t m m k m σ m m b k t b m k b σ b where m f is the bulging correction factor f w the finite width correction factors k tm and k tb are stress concentration factors m m m b m km and m kb are stress intensity magnification factors for the semi elliptical surface crack in round bars as shown in fig 8 a m f f w m km m kb 1 the expressions for m m and m b are a little complicated in order to keep the article concise the detailed expressions of m m and m b are omitted herein but they can be found in bs 7910 2013 for the semi circle surface crack in round bars as shown in fig 8 b m f f w m km m kb 1 m m and m b are given by 19 m m g 0 752 2 02 a d 2 r 0 37 1 sin π a d 4 r 3 where 21 g 1 84 π tan π a d 4 r π a d 4 r 0 5 cos π a d 4 r where r is as shown in fig 8 b σ m and σ b are membrane stresses and bending stresses acting on the mooring chains which can be obtained from the finite element analysis according to equation 15 20 the fatigue life n f can be estimated by 22 n f a 0 a c d a d c k δ k f m where a 0 is the initial crack depth a c the critical crack depth 6 2 finite element analysis in order to diminish the effects of boundary conditions on the numerical accuracy of fe analysis three full mooring chain links and two half links are modelled as shown in fig 9 three types of chain diameters are considered namely 2 5 inch 4 inch and 5 inch and all of chain links are considered with the corrosion and wear allowance of 0 5 mm year for 25 years end faces a and b are fixed support and mooring tensions are applied at the other side end faces c and d by pressure according to dnvgl os e302 2015 the length l and breadth b of mooring chains are given as multiples of the nominal diameter 23 l 6 d b 3 35 d where d is the nominal diameter of mooring chain mooring chains are meshed with quadratic hexahedron elements and the contact areas are meshed with quadratic quadrilateral contact target elements as shown in fig 10 following the suggestion of lassen et al 2005 three potential locations prone to fatigue for mooring chains are considered the inner surface of weld sections a a the inner surface of bend sections b b and the outside of crown sections c c as shown in fig 11 after the normal stresses of the weld bend and crown sections are obtained the membrane stresses σ m and bending stresses σ b are calculated by linearizing the normal stresses of the cross sections membrane stress is the mean stress through the section thickness and bending stress is the component of stresses due to imposed loading that varies linearly across the section thickness the membrane stresses σ m and bending stresses σ b are thus given by 24 σ m 1 t 0 t σ n u d u 25 σ b 6 t 2 0 t σ n u t 2 u d u where σ n is the normal stress t the thickness along the chain diameter direction u the local coordinate along the thickness direction typical distributions of normal stresses at the weld sections of three kinds of mooring chains are shown in fig 12 and the corresponding linearization results of stresses are shown in fig 13 7 comparative study a comparative study of mooring system fatigue analysis with use of s n curves t n curves and the fm based approaches is conducted to investigate the applicability of the fm based approach for time domain mooring system fatigue analysis of the fowt fatigue lives of three kinds of chains 2 5 inch 4 inch 5 inch predicted by the s n and t n curves based approaches with without considering the safety factors sf are shown in fig 14 in the fm based approach the chain link is treated as a round bar and a semi elliptical shape surface crack with initial crack sizes of 0 5 mm 0 5 mm is assumed to propagate at the surface of a chain link the critical crack depth is set as 12 of the chain diameter fatigue lives predicted by the fm based approach for weld sections with consideration of the stress concentration factor scf of 2 0 bend sections and crown sections of mooring chains are plotted in fig 15 the ratios of fatigue lives predicted by the fm based approach to those predicted by the t n curves based approach with sf of 3 0 and those predicted by the s n curves based approach with sf of 5 0 are shown in fig 16 and fig 17 respectively as shown in fig 14 if the safety factors are not considered in s n and t n curves based approaches fatigue lives predicted by the s n curves based approach are significant different from those predicted by the t n curves based approach fatigue lives of 2 5 inch 4 inch and 5 inch mooring chains predicted by the s n curves based approach are 28 63 and 93 longer than those predicted by the t n curves based approach respectively the larger the chain link diameter is the more conservative the fatigue life predicted by the s n curves based approach is the reason is that t n curves take into account the ratio of tension range to rbs instead of the nominal stress range where the ratio is related to the chain diameters therefore compared with the s n curves based approach larger diameter will lead to more fatigue damage predicted by the t n curves based approach these results are consistent with those in the work of xue et al 2018 where 6 inch chains are considered and fatigue lives calculated by the s n curves based approach are 130 longer than those predicted by the t n curves based approach fig 14 also shows that if the safety factors of 5 0 suggested by dnvgl os e301 2015 for the s n curves based approach and 3 0 suggested by api rp 2sk 2008 for the t n curves based approach are applied the difference in fatigue lives predicted by two approaches is subtle fatigue lives of mooring lines with the 5 inch chain predicted by the s n curves based approach are only 16 longer than those calculated by the t n curves based approach particularly fatigue lives of 4 inch chains predicted by the two approaches are almost the same mooring fatigue lives predicted by the fm based approach for weld sections with consideration of a scf of 2 0 crown sections and bend sections of three kinds of chains are shown in fig 15 fig 15 shows that if the scf of 2 0 is considered at weld sections the fatigue lives of weld sections are 60 of those of crown sections and only 40 of those of bend sections it can be seen from fig 15 that bend section is relatively not prone to fatigue damage compared with crown section and weld section with consideration of a scf of 2 0 both figs 14 and 15 show that the fatigue lives of mooring lines with 2 5 inch chain predicted by s n curves t n curves and the fm based approaches are quite shorter than the design life of the fowt which indicates that the design with 2 5 inch chain does not meet the fatigue requirements while for the 5 inch chain the fatigue lives exceed 200 years even the sf and the scf are considered in s n curves t n curves and the fm based approaches it means that the design with 5 inch chain is relatively conservative for the fowt for the 4 inch chain the fatigue lives are in a reasonable range which not only meet the fatigue requirements but also are not too conservative thus the design with 4 inch chain is the best mooring design for the fowt compared with the designs with 2 5 inch and 5 inch chain furthermore as shown in fig 16 fatigue lives of bend section of the 2 5 inch chains estimated by the fm based approach are quite close to those predicted by the t n curves based approach with a sf of 3 0 suggested by api figs 16 and 17 show fatigue lives of crown sections of the 4 inch and 5 inch chains predicted by the fm based approach are comparable with those predicted by the t n curves and s n curves based approaches where a sf of 3 0 suggested by api and a sf of 5 0 suggested by dnvgl are considered in the two approaches respectively these results demonstrate that there is no significant difference in the fatigue life prediction between s n curves t n curves and the fm based approaches if the safety factors suggested by dnvgl and api are considered in the s n and t n curves based approaches which means that the fm based approach generally provides reasonable time domain mooring fatigue prediction for the fowt 8 parametric study in general the fatigue damage predicted by the time domain fm based approach varies with the assumptions made in the analysis such as loading sequence stress concentration factor initial crack shape initial crack size and critical crack depth in order to investigate the impact of these factors on the fatigue life prediction of the time domain fm based approach a parametric study is conducted for the mooring system with 4 inch chain 8 1 loading sequence three types of loading sequences namely stress ranges sorted descending stress ranges sorted ascending and random stress ranges in which random numbers are generated from a gaussian distribution are considered the predicted fatigue lives of mooring chains and the corresponding crack depth in the final year before failure are tabulated in table 6 and table 7 respectively tables 6 and 7 show that there is almost no difference between the predicted fatigue lives and final crack depths when the three types of loading sequences are considered which indicates that the fatigue life prediction of the fm based approach may be insensitive to the loading sequence in this specific case study 8 2 stress concentration factor the effect of scf due to welding quality at weld section on fatigue life prediction of the fm based approach is investigated ratios of fatigue lives of weld sections of mooring chains with different scfs to those without considering the scf namely the scf 1 0 is shown in fig 18 the results show that the fatigue lives of weld sections of mooring chains with a scf of 1 6 and 2 2 are about 25 and 10 of those without considering the scf respectively it indicates that welding quality that normally determines the value of scf at weld section has a significant impact on the predicted fatigue lives of mooring chains thus the selection of an appropriate scf is one of key issues during the fm based mooring system fatigue analysis 8 3 initial crack shape two types of initial crack shape namely semi elliptical and semi circle surface cracks are considered in this parametric study the comparison of fatigue lives of crown sections of mooring chains with initial semi elliptical and semi circle surface cracks is performed and the results are plotted in fig 19 fig 19 shows that the fatigue life of chain links in mooring line 1 calculated with an initial semi elliptical surface crack is 14 longer than that calculated with an initial semi circle surface crack the same trends can be found in other two mooring lines the predicted fatigue lives of the mooring lines 2 and 3 with initial semi elliptical surface cracks are about 16 longer than those with initial semi circle surface cracks the results indicate that the fatigue life of a mooring chain calculated based on the initial semi circle surface crack may be shorter than that calculated based on the initial semi elliptical surface crack 8 4 initial crack size the ratios of fatigue lives of mooring chains with different initial crack sizes to those with an initial crack depth of 0 5 mm are plotted in fig 20 the results show that the predicted fatigue lives with initial crack sizes as 0 7 mm 0 7 mm are about 80 of those estimated with initial crack sizes as 0 5 mm 0 5 mm which indicates that the fatigue life of a mooring chain is generally sensitive to the assumed initial crack sizes and proper choice of the initial crack sizes is important in the fm based mooring system fatigue analysis 8 5 critical crack depth the ratios of fatigue lives of mooring chains with critical crack depths chosen as 25 37 and 50 of chain diameter to those with the critical crack depth set as 12 of chain diameter are plotted in fig 21 as seen from the fig 21 there is no significant difference between the fatigue lives of chain links when the three different critical crack depths are set it demonstrates that fatigue life of a mooring chain predicted by the fm based approach may be insensitive to the critical crack depth 9 conclusions the intent of this study was to investigate the applicability of the fm based approach for time domain mooring system fatigue analysis of the fowt mooring tension responses were predicted by a time domain analysis accounting for the coupled effects of wind wave and current and the corresponding tension cycles were counted by a rain flow counting method both s n and t n curves based approaches with without considering the safety factors suggested by the api and dnvgl were performed for the comparative study for the fm based fatigue analysis initial cracks were assumed to propagate at the surface of mooring chains and three potential locations prone to fatigue were taken into account the comparison of fatigue lives of mooring chains predicted by s n curves t n curves and the fm based approaches was made and the results show there is no significant difference on fatigue lives predicted by the three approaches when the safety factors suggested by api and dnvgl are applied in s n curves and t n curves based approaches it indicates that the fm based approach generally provides reasonable time domain mooring fatigue prediction for the fowt a parametric study was further conducted to investigate the effects of loading sequence stress concentration factor initial crack shape initial crack size and critical crack depth on the mooring fatigue life prediction of the fm based approach and the results show the predicted fatigue life of a mooring chain is generally sensitive to stress concentration factor and initial crack size the predicted fatigue life of a mooring chain is relatively less sensitive to the initial crack shape the predicted fatigue life of a mooring chain is insensitive to the critical crack depth and the loading sequence a comparative study on the studless mooring chains with three kinds of diameters 2 5 inch 4 inch 5 inch was also carried out and the results show that the mooring design with 4 inch chain is the best design which not only well meets the fatigue requirements of the fowt but also the predicted fatigue life of mooring system is not too conservative credit authorship contribution statement xifeng gao writing original draft investigation supervision xiaoyong liu writing original draft investigation xutian xue formal analysis software investigation writing review editing nian zhong chen conceptualization methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
20997,this paper summarized a study that aims to investigate the applicability of a fracture mechanics fm based approach for calculating the fatigue lives of the mooring lines of a spar based floating offshore wind turbine fowt in time domain tension ranges of mooring lines are calculated from a time domain hydrodynamic analysis taking into account the effects of wind wave and current mooring tension cycles with corresponding ranges are counted by a rain flow counting method a comparison between fatigue lives of mooring system predicted by s n curves t n curves and the fm based approaches is made and the results show that the fm based approach generally provides reasonable estimate of fatigue lives of the mooring lines of the fowt parametric studies were further performed to investigate the effects of loading sequence stress concentration factor initial crack shape initial crack size and critical crack depth on fatigue life prediction of the fm based approach it was observed that the predicted fatigue life is sensitive to stress concentration factor and initial crack size a comparative study on three kinds of mooring design with different chain diameters is also made and the applicability of each design is discussed keywords floating offshore wind turbine fowt mooring line fatigue fracture mechanics time domain 1 introduction in the past few decades tremendous progress has been made in the advancement of offshore wind turbines a large amount of commercial bottom fixed offshore wind turbines have been in service though most of them are economically limited to shallow waters campanile et al 2018 to install offshore wind turbines at water depth greater than 35 40 m and to enable stronger and more constant offshore wind the development of floating offshore wind turbines fowt has become one of the primary trends in 2009 the world s first experimental full scale spar based fowt hywind demo was installed by statoil in the north sea driscoll et al 2016 after that a semi submersible type fowt windfloat was successfully installed in 2011 valverde 2015 in 2017 the world s first commercial floating wind farm equinor 2018 30 mw hywind scotland pilot park which consists of five 6 mw spar based fowts was constructed and put into service unlike bottom fixed offshore wind turbines station keeping for a fowt is primarily dependent on its mooring system mooring safety is thus crucially important to a fowt traditionally mooring fatigue analysis for offshore structures is mainly conducted based on the palmgren miner s rule with use of s n curves or t n curves api rp 2sk 2008 dnvgl os e301 2015 cheng et al 2017 made a comparison on mooring fatigue damage of floating horizontal axis wind turbines hawts and vertical axis wind turbines vawts using a s n curves based approach campanile et al 2018 applied s n curves to fatigue limit state design of mooring systems of fowts installed at intermediate and deep water depths li et al 2019 applied s n curves to investigate the influence of wind and wave on the mooring fatigue of a spar based fowt xu et al 2019 conducted a time domain mooring fatigue analysis for a semi submersible fowt with use of t n curves where the effect of wave nonlinearity is considered barrera et al 2019 proposed a life cycle methodology for mooring fatigue assessment of a fowt and a comparison on fatigue damage achieved from the new method and the standard methods using s n curves and t n curves was made over the past few decades mooring accidents of offshore floating structures occurred at a high rate in the report of d souza and majhi 2013 there were 23 mooring failure incidents on floating production systems and at least 150 mooring lines were replaced or repaired during 2000 2011 drori 2015 analysed an industry survey of 107 offshore mooring failures and estimated that the failure rate of single mooring line is 2 5 10 2 per asset per year this high failure rate is also mentioned in fontaine et al 2014 which indicated that fatigue is one of the most prevalent causes of failure and at least 24 of mooring failures are due to fatigue therefore in addition to the s n t n curves based approaches there might be a need to develop other rational methods for mooring system fatigue analysis during the design phase of offshore floating structures as another effective approach for fatigue analysis the fracture mechanics fm based mooring system fatigue analysis is being received more attention mathisen and larsen 2004 applied a fm based approach to crack growth prediction for risk based inspection planning of mooring chains palin luc et al 2010 and pérez mora et al 2015 conducted a series of experiments to investigate the crack growth behaviour of mooring chains in corrosive environments fatigue lives of mooring chains predicted by a fm based approach were compared with the experiment results xue and chen 2018 performed a fm based mooring fatigue analysis for a semi submersible subjected to low frequency and wave frequency loading processes considering various load combination methods xue et al 2018 presented a fm based mooring fatigue analysis for a semi submersible in frequency domain and a parametric study was conducted to investigate the impact of relevant parameters on fatigue life prediction of the fm based approach arredondo et al 2018 conducted a finite element analysis to measure stress intensity factors on mooring chains considering a variety of crack and load combination ibekwe et al 2018 investigated the remaining strength and fatigue damage of the degraded top mooring chains of the bonga fpso and single point mooring spm loading buoy with use of a fm based approach lee and kim 2019 performed a fm based probabilistic flaw assessment for a surface crack in a mooring chain recently xue et al 2020a conducted a fm based investigation on the mechanism of out of plane bending opb between mooring chain links and its effects on fatigue lives of mooring chain links xue et al 2020b carried out a mooring fatigue assessment for mooring chain links of a semi submersible operated in offshore west africa owa and three cases that mooring chain links are subjected to pure tension out of plane bending opb and torque are considered in the assessment nevertheless at the current stage the fm based fatigue assessment for offshore mooring system is generally not well established due to the complexity of the application such as how to select the initial crack shape how to define the critical crack size how much ctod should be chosen how to apply the fatigue loading etc most of offshore design codes only provide conceptual guidance but no detailed guidance about how to apply the fm based approach for mooring system fatigue analysis as a type of emerging offshore floating structures there is even less engineering practice on the mooring system analysis for fowts therefore as an extension of the work of xue et al 2018 this paper aims to investigate the applicability of a time domain fm based mooring system fatigue analysis for a spar fowt through a comparison between t n and s n curves based fatigue analyses a parametric study is further conducted to investigate the effects of loading sequence stress concentration factor initial crack shape initial crack size and critical crack depth on the time domain fatigue life prediction of the fm based approach in addition a comparative study on three kinds of mooring design with different chain diameters is also performed and the applicability of each design is discussed 2 spar based fowt and mooring system an oc3 hywind spar based fowt with a catenary mooring system assumed to be operated at south china sea is considered in this paper the mooring system consists of three mooring lines distributed at an angle of 120 three kinds of studless chains with different diameters 2 5 inch 4 inch 5 inch are taken into account for mooring design of the fowt to investigate the applicability of each design 2 1 spar based fowt the spar based fowt considered in this paper is defined in the phase iv of oc3 project by nrel jonkman et al 2009 jonkman 2010 which consists of an nrel 5 mw wind turbine and a spar based platform the principal parameters of wind turbine and platform are listed in table 1 and the geometry sketch of the spar based fowt is shown in fig 1 2 2 mooring system the catenary mooring system is composed of three mooring lines as shown in fig 2 adjacent lines are 120 separated attaches to the platform via a delta connection which is to provide the yaw restoring moment three kinds of mooring chains with different diameters 2 5 inch 4 inch 5 inch are considered for the mooring system and the design life of mooring system is assumed to be 25 years as recommended by dnvgl os e301 2015 the transverse and longitudinal drag coefficients are set as 2 40 and 1 15 respectively the friction coefficient at seafloor is assumed to be 1 0 wu et al 2015 the principal parameters of the mooring chains are listed in table 2 3 environmental conditions the spar fowt is assumed to be installed and operated at south china sea the sea states are listed in table 3 huang et al 2011 where h s is the significant wave height t p the peak period v w the mean wind velocity v c the mean current velocity and p the occurrence probability of each sea state the wave wind and current in collinear direction aligned with the rotor of fowt is shown in fig 2 3 1 wave load interaction between wave and a fowt normally generates three components of mooring line tension including mean mooring line tension induced by the mean wave drift load wave frequency mooring line tension induced by the first order wave and low frequency mooring line tension induced by the second order wave load the wave induced load acting on the fowt is achieved in terms of the morison equation and the jonswap spectrum in which the morison equation for floating structure is given as morison et al 1950 sumer and fredsøe 2006 1 f m ρ w v u w ρ w c a v u w v p 1 2 ρ w c d a u w v p u w v p where f m is the fluid force per unit length ρ w the density of water v the volume of the platform u w the fluid velocity u w the fluid acceleration c a the added mass coefficient v p the velocity of platform v p the acceleration of platform c d the drag coefficient a the drag area in the hydrodynamic analysis the jonswap spectrum s ω is used for the wave simulation isherwood 1987 2 s ω α g 2 ω 5 e x p 5 4 ω p ω 4 γ e x p ω ω p 2 2 σ s 2 ω p 2 where g is the acceleration due to gravity ω the wave frequency ω p the peak wave frequency γ the peakedness parameter α and σ s are spectrum parameters which can be referred to marintek 2012 3 α h s ω p 2 4 g 2 0 065 γ 0 803 0 135 4 σ s 0 07 f o r ω ω p 0 09 f o r ω ω p where h s is the significant wave height 3 2 wind load mean wind forces based on 1 h average velocity above mean water level and time varying wind forces due to wind gusts are considered herein the wind force is considered as drag force and it is given by 5 f w 1 2 c w ρ a a w u d z v p u d z v p where c w is the drag coefficient ρ a the density of the air a w the projected area of the surface perpendicular to wind u d z is the 1 h average wind velocity at elevation z above sea level which is considered as a statistical value that is generated from the api wind spectrum api rp 2a wsd 1993 6 s a p i f i z u d z 2 f p 1 1 5 f f p 5 3 where s api f is the spectral energy density at the wind frequency f f p can be calculated by 7 f p 0 025 u d z z u d z can be calculated by 8 u d z u 0 z z r 0 125 where u 0 is the 1 h mean wind speed at elevation of 10m above sea level z r 10 m i z is the turbulence intensity and it is expressed as 9 i z 0 15 z z s 0 125 f o r z z s 0 15 z z s 0 275 f o r z z s z s 20 m 3 3 current load current is considered as a steady flow in the mooring analysis the current load is given by 10 f c 1 2 c c ρ w a c u c v p u c v p where c c is the drag coefficient a c the projected area of the surface perpendicular to current u c the velocity of the current 4 mooring line tension 4 1 time domain dynamic analysis the dynamic mooring analysis can be performed in time domain or frequency domain in general a time domain analysis is considered more accurate than a frequency domain analysis as time domain analysis takes into account the nonlinear and coupling effects between environmental loads and structural responses in this section mooring tension ranges are from a time domain dynamic analysis where mass damping stiffness loading etc are calculated at each time step with considering the instantaneous and time varying geometry mooring lines are modelled through a finite element analysis and they are discretized into individual nodes which carries six degrees of freedom the governing function is given by orcina ltd 2019 11 m p a c p v k p f p v t where m p a c p v and k p are matrices of inertia damping and stiffness respectively f p v t represents the external force p the position vector v the corresponding velocity vector and a the corresponding acceleration vector t the simulation time fig 3 shows the tension responses of the three mooring lines with the 4 inch chain under the sea state where h s 1 55 m t p 6 s v w 9 4 m s v c 0 282 m s 4 2 rain flow counting tension cycles with the corresponding ranges are counted by the rain flow counting method proposed by matsuishi and endo 1968 which is widely accepted for time domain fatigue analysis the algorithm procedure of the method is shown in fig 4 and the details can be referred to astm 2005 5 s n and t n curves based fatigue analysis traditionally mooring fatigue analysis for offshore structures is mainly conducted based on the palmgren miner s rule miner 1945 with use of t n or s n curves api rp 2sk 2008 dnvgl os e301 2015 5 1 s n curves based approach in this approach in terms of the palmgren miner rule the fatigue damage d is calculated as 12 d n i n i where n i is the number of cycles of a constant stress range s i acting on the structure n i represents the number of cycles to failure under the constant stress range s i n i can be determined from a s n curve as shown in fig 5 as 13 n i k s s i m s where m s is the slope of the s n curve k s the intercept parameter as shown in table 4 the reference values of the parameters m s and k s suggested by dnvgl os e301 2015 are utilized herein for the s n curves based fatigue damage calculation 5 2 t n curves based approach similar to the s n curves based approach the fatigue damage d in the t n curves based approach is also calculated in accordance with the eq 12 but the n i in the t n curves based approach is the number of cycles of r i that is the ratio of a constant tension range to reference breaking strength rbs of the mooring line n i represents the number of cycles to failure under the r i and it can be achieved from a t n curve as shown in fig 6 as 14 n i k t r i m t where m t is the slope of the t n curve and k t the intercept parameter according to api rp 2sk 2008 if rbs is not available it can be approximately estimated by the following equation 15 r b s 0 0211 d 2 44 0 08 d where d is the chain diameter as shown in table 5 the reference values of the parameters m t and k t suggested by api rp 2sk 2008 for studlink and studless chains are used in the t n curves based fatigue damage calculation 6 fracture mechanics analysis this section is to perform the fracture mechanics fm based mooring system fatigue analysis firstly the mooring chain is treated as a round bar and an initial surface crack is assumed to propagate at the surface of the chain link secondly a finite element fe analysis is performed to predict the tension induced membrane and bending stresses acting on cross sections of mooring chains then the stress intensity factors are calculated according to the bs 7910 2013 the crack propagation is finally estimated by the paris law paris and erdogan 1963 a flowchart summarizing the main steps of the fm based approach is shown in fig 7 due to the manufacture or installation process such as welding process proof loading test the overload during the installation etc defects are often initiated in the mooring chain links and these defects are normally regarded as initial cracks in the fm analysis at present there is still no existing industry codes developed on how to select initial crack size initial crack shape and also critical crack size for offshore mooring chain links according to the abs guide for fatigue assessment of offshore structures abs 2018 and the work of chen et al 2011 for surface cracks starting from the transition between weld base materials a crack depth of 0 5 mm may be assumed if no data on crack depth are available as a result the initial crack depth of 0 5 mm is chosen in the fm analysis semi elliptical and semi circle surface cracks are two common types of the initial crack shapes recommended by bs 7910 2013 in engineering practices therefore an initial semi elliptical or semi circle surface crack with the initial crack depth 0 5 mm is assumed at the surface of the mooring chain link the choice of critical crack depth is made based on the work of mathisen and larsen 2004 where the critical crack depth is suggested to be 12 of the chain diameter in addition the welding quality that normally determines the value of scf at the weld section of a mooring chain link is also taken into account in the fm analysis as suggested by chen et al 2011 a calibrated scf around 2 0 for weld section of a mooring chain link is applied in the fm analysis 6 1 paris law and stress intensity factor based upon the paris erdogan equation paris and erdogan 1963 the crack depth a d can be estimated by 16 d a d d n c k δ k f m where a d is the crack depth n the number of stress cycles c k and m are the material constants δk f is the stress intensity factor range the stress intensity factor k f can be calculated as bs 7910 2013 17 k f y σ π a d where y is the stress intensity correction factor σ the stress acting on the mooring chain yσ is defined as 18 y σ m f f w m m k t m m k m σ m m b k t b m k b σ b where m f is the bulging correction factor f w the finite width correction factors k tm and k tb are stress concentration factors m m m b m km and m kb are stress intensity magnification factors for the semi elliptical surface crack in round bars as shown in fig 8 a m f f w m km m kb 1 the expressions for m m and m b are a little complicated in order to keep the article concise the detailed expressions of m m and m b are omitted herein but they can be found in bs 7910 2013 for the semi circle surface crack in round bars as shown in fig 8 b m f f w m km m kb 1 m m and m b are given by 19 m m g 0 752 2 02 a d 2 r 0 37 1 sin π a d 4 r 3 where 21 g 1 84 π tan π a d 4 r π a d 4 r 0 5 cos π a d 4 r where r is as shown in fig 8 b σ m and σ b are membrane stresses and bending stresses acting on the mooring chains which can be obtained from the finite element analysis according to equation 15 20 the fatigue life n f can be estimated by 22 n f a 0 a c d a d c k δ k f m where a 0 is the initial crack depth a c the critical crack depth 6 2 finite element analysis in order to diminish the effects of boundary conditions on the numerical accuracy of fe analysis three full mooring chain links and two half links are modelled as shown in fig 9 three types of chain diameters are considered namely 2 5 inch 4 inch and 5 inch and all of chain links are considered with the corrosion and wear allowance of 0 5 mm year for 25 years end faces a and b are fixed support and mooring tensions are applied at the other side end faces c and d by pressure according to dnvgl os e302 2015 the length l and breadth b of mooring chains are given as multiples of the nominal diameter 23 l 6 d b 3 35 d where d is the nominal diameter of mooring chain mooring chains are meshed with quadratic hexahedron elements and the contact areas are meshed with quadratic quadrilateral contact target elements as shown in fig 10 following the suggestion of lassen et al 2005 three potential locations prone to fatigue for mooring chains are considered the inner surface of weld sections a a the inner surface of bend sections b b and the outside of crown sections c c as shown in fig 11 after the normal stresses of the weld bend and crown sections are obtained the membrane stresses σ m and bending stresses σ b are calculated by linearizing the normal stresses of the cross sections membrane stress is the mean stress through the section thickness and bending stress is the component of stresses due to imposed loading that varies linearly across the section thickness the membrane stresses σ m and bending stresses σ b are thus given by 24 σ m 1 t 0 t σ n u d u 25 σ b 6 t 2 0 t σ n u t 2 u d u where σ n is the normal stress t the thickness along the chain diameter direction u the local coordinate along the thickness direction typical distributions of normal stresses at the weld sections of three kinds of mooring chains are shown in fig 12 and the corresponding linearization results of stresses are shown in fig 13 7 comparative study a comparative study of mooring system fatigue analysis with use of s n curves t n curves and the fm based approaches is conducted to investigate the applicability of the fm based approach for time domain mooring system fatigue analysis of the fowt fatigue lives of three kinds of chains 2 5 inch 4 inch 5 inch predicted by the s n and t n curves based approaches with without considering the safety factors sf are shown in fig 14 in the fm based approach the chain link is treated as a round bar and a semi elliptical shape surface crack with initial crack sizes of 0 5 mm 0 5 mm is assumed to propagate at the surface of a chain link the critical crack depth is set as 12 of the chain diameter fatigue lives predicted by the fm based approach for weld sections with consideration of the stress concentration factor scf of 2 0 bend sections and crown sections of mooring chains are plotted in fig 15 the ratios of fatigue lives predicted by the fm based approach to those predicted by the t n curves based approach with sf of 3 0 and those predicted by the s n curves based approach with sf of 5 0 are shown in fig 16 and fig 17 respectively as shown in fig 14 if the safety factors are not considered in s n and t n curves based approaches fatigue lives predicted by the s n curves based approach are significant different from those predicted by the t n curves based approach fatigue lives of 2 5 inch 4 inch and 5 inch mooring chains predicted by the s n curves based approach are 28 63 and 93 longer than those predicted by the t n curves based approach respectively the larger the chain link diameter is the more conservative the fatigue life predicted by the s n curves based approach is the reason is that t n curves take into account the ratio of tension range to rbs instead of the nominal stress range where the ratio is related to the chain diameters therefore compared with the s n curves based approach larger diameter will lead to more fatigue damage predicted by the t n curves based approach these results are consistent with those in the work of xue et al 2018 where 6 inch chains are considered and fatigue lives calculated by the s n curves based approach are 130 longer than those predicted by the t n curves based approach fig 14 also shows that if the safety factors of 5 0 suggested by dnvgl os e301 2015 for the s n curves based approach and 3 0 suggested by api rp 2sk 2008 for the t n curves based approach are applied the difference in fatigue lives predicted by two approaches is subtle fatigue lives of mooring lines with the 5 inch chain predicted by the s n curves based approach are only 16 longer than those calculated by the t n curves based approach particularly fatigue lives of 4 inch chains predicted by the two approaches are almost the same mooring fatigue lives predicted by the fm based approach for weld sections with consideration of a scf of 2 0 crown sections and bend sections of three kinds of chains are shown in fig 15 fig 15 shows that if the scf of 2 0 is considered at weld sections the fatigue lives of weld sections are 60 of those of crown sections and only 40 of those of bend sections it can be seen from fig 15 that bend section is relatively not prone to fatigue damage compared with crown section and weld section with consideration of a scf of 2 0 both figs 14 and 15 show that the fatigue lives of mooring lines with 2 5 inch chain predicted by s n curves t n curves and the fm based approaches are quite shorter than the design life of the fowt which indicates that the design with 2 5 inch chain does not meet the fatigue requirements while for the 5 inch chain the fatigue lives exceed 200 years even the sf and the scf are considered in s n curves t n curves and the fm based approaches it means that the design with 5 inch chain is relatively conservative for the fowt for the 4 inch chain the fatigue lives are in a reasonable range which not only meet the fatigue requirements but also are not too conservative thus the design with 4 inch chain is the best mooring design for the fowt compared with the designs with 2 5 inch and 5 inch chain furthermore as shown in fig 16 fatigue lives of bend section of the 2 5 inch chains estimated by the fm based approach are quite close to those predicted by the t n curves based approach with a sf of 3 0 suggested by api figs 16 and 17 show fatigue lives of crown sections of the 4 inch and 5 inch chains predicted by the fm based approach are comparable with those predicted by the t n curves and s n curves based approaches where a sf of 3 0 suggested by api and a sf of 5 0 suggested by dnvgl are considered in the two approaches respectively these results demonstrate that there is no significant difference in the fatigue life prediction between s n curves t n curves and the fm based approaches if the safety factors suggested by dnvgl and api are considered in the s n and t n curves based approaches which means that the fm based approach generally provides reasonable time domain mooring fatigue prediction for the fowt 8 parametric study in general the fatigue damage predicted by the time domain fm based approach varies with the assumptions made in the analysis such as loading sequence stress concentration factor initial crack shape initial crack size and critical crack depth in order to investigate the impact of these factors on the fatigue life prediction of the time domain fm based approach a parametric study is conducted for the mooring system with 4 inch chain 8 1 loading sequence three types of loading sequences namely stress ranges sorted descending stress ranges sorted ascending and random stress ranges in which random numbers are generated from a gaussian distribution are considered the predicted fatigue lives of mooring chains and the corresponding crack depth in the final year before failure are tabulated in table 6 and table 7 respectively tables 6 and 7 show that there is almost no difference between the predicted fatigue lives and final crack depths when the three types of loading sequences are considered which indicates that the fatigue life prediction of the fm based approach may be insensitive to the loading sequence in this specific case study 8 2 stress concentration factor the effect of scf due to welding quality at weld section on fatigue life prediction of the fm based approach is investigated ratios of fatigue lives of weld sections of mooring chains with different scfs to those without considering the scf namely the scf 1 0 is shown in fig 18 the results show that the fatigue lives of weld sections of mooring chains with a scf of 1 6 and 2 2 are about 25 and 10 of those without considering the scf respectively it indicates that welding quality that normally determines the value of scf at weld section has a significant impact on the predicted fatigue lives of mooring chains thus the selection of an appropriate scf is one of key issues during the fm based mooring system fatigue analysis 8 3 initial crack shape two types of initial crack shape namely semi elliptical and semi circle surface cracks are considered in this parametric study the comparison of fatigue lives of crown sections of mooring chains with initial semi elliptical and semi circle surface cracks is performed and the results are plotted in fig 19 fig 19 shows that the fatigue life of chain links in mooring line 1 calculated with an initial semi elliptical surface crack is 14 longer than that calculated with an initial semi circle surface crack the same trends can be found in other two mooring lines the predicted fatigue lives of the mooring lines 2 and 3 with initial semi elliptical surface cracks are about 16 longer than those with initial semi circle surface cracks the results indicate that the fatigue life of a mooring chain calculated based on the initial semi circle surface crack may be shorter than that calculated based on the initial semi elliptical surface crack 8 4 initial crack size the ratios of fatigue lives of mooring chains with different initial crack sizes to those with an initial crack depth of 0 5 mm are plotted in fig 20 the results show that the predicted fatigue lives with initial crack sizes as 0 7 mm 0 7 mm are about 80 of those estimated with initial crack sizes as 0 5 mm 0 5 mm which indicates that the fatigue life of a mooring chain is generally sensitive to the assumed initial crack sizes and proper choice of the initial crack sizes is important in the fm based mooring system fatigue analysis 8 5 critical crack depth the ratios of fatigue lives of mooring chains with critical crack depths chosen as 25 37 and 50 of chain diameter to those with the critical crack depth set as 12 of chain diameter are plotted in fig 21 as seen from the fig 21 there is no significant difference between the fatigue lives of chain links when the three different critical crack depths are set it demonstrates that fatigue life of a mooring chain predicted by the fm based approach may be insensitive to the critical crack depth 9 conclusions the intent of this study was to investigate the applicability of the fm based approach for time domain mooring system fatigue analysis of the fowt mooring tension responses were predicted by a time domain analysis accounting for the coupled effects of wind wave and current and the corresponding tension cycles were counted by a rain flow counting method both s n and t n curves based approaches with without considering the safety factors suggested by the api and dnvgl were performed for the comparative study for the fm based fatigue analysis initial cracks were assumed to propagate at the surface of mooring chains and three potential locations prone to fatigue were taken into account the comparison of fatigue lives of mooring chains predicted by s n curves t n curves and the fm based approaches was made and the results show there is no significant difference on fatigue lives predicted by the three approaches when the safety factors suggested by api and dnvgl are applied in s n curves and t n curves based approaches it indicates that the fm based approach generally provides reasonable time domain mooring fatigue prediction for the fowt a parametric study was further conducted to investigate the effects of loading sequence stress concentration factor initial crack shape initial crack size and critical crack depth on the mooring fatigue life prediction of the fm based approach and the results show the predicted fatigue life of a mooring chain is generally sensitive to stress concentration factor and initial crack size the predicted fatigue life of a mooring chain is relatively less sensitive to the initial crack shape the predicted fatigue life of a mooring chain is insensitive to the critical crack depth and the loading sequence a comparative study on the studless mooring chains with three kinds of diameters 2 5 inch 4 inch 5 inch was also carried out and the results show that the mooring design with 4 inch chain is the best design which not only well meets the fatigue requirements of the fowt but also the predicted fatigue life of mooring system is not too conservative credit authorship contribution statement xifeng gao writing original draft investigation supervision xiaoyong liu writing original draft investigation xutian xue formal analysis software investigation writing review editing nian zhong chen conceptualization methodology supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper 
20998,very large floating structures vlfss are novel offshore structures without direct reliability design criteria available currently target reliability as a critical safety indicator could be used to evaluate the ultimate strength reliability of vlfss therefore it is necessary to establish acceptable risk criteria to determine the structural design target reliability of vlfss and to calculate partial safety factors psfs for use as ultimate strength design criteria this paper developed a reliability assessment process in order to achieve the ultimate strength design criteria of vlfs a reasonable target reliability range for vlfs was determined by risk assessment methods and principles considering the structure failure probability and consequences the longitudinal ultimate strength for the typical sections of vlfs was calculated by applying the simplified progressive failure method the vertical extreme wave bending moments and their uncertainties for the corresponding typical sections of vlfs were analysed based on wave scatter diagram of the south china sea finally the ultimate strength reliability was assessed based on the reasonable target reliability range established within this paper results have shown that the reasonable target reliability range is found to be applicable for identifying the weak structural components of vlfs and some typical sections of vlfs should be redesigned to satisfy the criteria this paper can provide a reference for the safe design and compilation of relevant guidelines for vlfs keywords very large floating structures ultimate strength target reliability risk analysis structural reliability 1 introduction in recent years the development of coastal land has expanded lamas pardo et al 2015 therefore some conceptual designs involving floating bodies have occurred such as floating airports and ports suzuki et al 2007 floating ecopolises lamas pardo et al 2015 floating farms wang and tay 2011 and the floating tourism platforms xie et al 2020 among those conceptual designs floating airports ports have some distinguishing features a large size complex systems and large numbers of passengers and staff hence very large floating structures vlfss provide a solution for this novel architecture and have attracted the attention of architects and engineers wang and tay 2011 lamas pardo et al 2015 presented a definition of vlfss with the following characteristics a range of unprecedented parameters a long design life low maintenance costs and durability and resistance to fatigue vlfss are characterized by a range of unprecedented parameters and consist of several single modules the length of a single module can reach 300 400 m wang and tay 2011 vlfss can function as airports at sea harbours and comprehensive support bases and they can be an important components for the development of marine resources lamas pardo et al 2015 suzuki et al 2007 two types of vlfss pontoon type and semisubmersible type vlfss were studied in the 1990s by japan and the us respectively mcallister 1997 suzuki et al 2017 in 2013 china began a new project on the complex environmental responses of vlfs and performed corresponding structural safety assessments wu et al 2017 in this project a large number of theoretical and experimental studies on semisubmersible type vlfss were performed including studies of wave monitoring and simulation near islands and reefs liu et al 2019 yang et al 2013 fluid structure coupling responses ding et al 2017 2019 wu et al 2018 mooring systems cheng and wu 2018 ni et al 2018 connectors zhang et al 2017 and structural ultimate strength analysis zhao et al 2019 risk assessments reliability analyses and structure safety design criteria are key factors in the design and construction of vlfss for use as airports suzuki et al 2007 a basic principle of vlfs airport design and construction is that the safety level should be equivalent to that established by the international aviation industry the safety level can be evaluated by performing risk assessments and expressed by risk values zhang et al 2018 the risk value is an indicator of the safety margin as suddle 2009 noted a maximum safety level corresponds to no risk and a minimum safety level corresponds roughly to a high risk thus reflecting the linkage between safety and risk additionally a challenge faced by designers is determining how to set the target safety level at a sub system that is in line with the total risk acceptance criteria of a ship skjong and guedes soares 2008 ruud and mikkelsen 2008 performed work to determine target safety levels for crane systems using the formal safety assessment fsa approach for vlfs airports designers are mainly concerned with the longitudinal ultimate strength design criteria under extreme wave loads in regard to catastrophic failure scenarios design criteria for the ultimate strength limit state are needed to obtain the ultimate strength design criteria criteria related to reliability e g target reliability which represents the maximum allowable structural failure probability must be established target reliability can be applied to check whether the structural safety level meets the relevant requirements and can also be used to determine partial safety factors psfs in the load and resistance factor design lrfd method another challenge involves determining the relationship between risk and reliability and illustrating the risk level of the reliability indicator by considering the consequences of structure failure first this paper applies the risk acceptance criterion and corresponding design principles to determine a reasonable range of structural target reliability for vlfs second a simplified progressive failure method is applied to calculate the ultimate strength of typical vlfs sections the vertical extreme wave bending moments and their uncertainties for the corresponding typical sections of vlfs were analysed based on wave scatter diagram of the south china sea finally the longitudinal ultimate strength reliability of typical vlfs sections is assessed considering the selected target reliabilities the safety margin equation is established and the corresponding psfs are calculated based on these psfs the design requirements for the ultimate strength of vlfss under different working conditions are obtained 2 literature review 2 1 risk assessment applications involving marine structures the piper alpha disaster in 1988 was a wake up call for offshore industry practitioners since then some changes in offshore platforms have been made to avoid such accidents notably the offshore safety case regulations were published by the uk health and safety executive in 1992 these regulations require quantitative risk assessments qras for preparing offshore installation safety cases flin et al 2005 based on offshore safety case practices the international maritime organization imo accepted its member states suggestions for adopting risk analysis during the imo rule making process and established the formal safety assessment fsa methodology imo 2013 currently risk of ships and marine structures is assessed under the framework of fsa methodology in the marine safety domain montewka et al 2014 fsa involves five steps identification of hazards risk analysis risk control options cost benefit assessment and recommendations for decision making imo 2013 some fsa applications involving ships and their subsystems such as bulk carrier safety germany 2016 uk 2002 container vessels denmark 2007a liquefied natural gas carriers denmark 2007b korea 2016 cruise ships denmark 2008a denmark and uk 2012 european commission 2015 ropax ships brazil 2007 denmark 2008b and crude oil tankers denmark 2008a have been explored by imo member states the research scope of these fsa studies ranged from operational risk assessments to ship performance risk assessments although the fsa methodology has been adopted for various ship types little work has been done on overall safety evaluations of vlfs 2 2 target reliability for vlfss generally target reliability in traditional structural reliability assessment is based on the relevant code requirements dnv 1992 suggested different target failure probability requirements for different types of failure modes and consequences based on the damage to human life and the environment the canadian standards association 1992 provided values of 10 3 and 10 5 as safety levels for offshore structures in this case the target failure probability is established based on a qualitative description of the failure consequences and the severity of the failure consequences is not quantitatively assessed some empirical formulas have been suggested for calculating target reliability considering the structural lifetime redundancy and failure consequences bea 1990 these empirical formulas can provide guidance for determining the safety margin of structures of the same kind however there is no direct reference available that provides reliability design criteria for vlfss as novel marine structures notably empirical formulas may not be applicable to vlfs airports where many passengers crews and ground service personnel stay therefore it is necessary to rationally assess the severity of structural failure consequences and propose reasonable and practicable target reliability some researchers bhattacharya et al 2001 suzuki 2001 have considered using risk analysis methods to select vlfs target reliability ranges based on qualitative or quantitative analyses of the structural failure consequences according to risk assessment results suzuki 2001 analysed vlfs failure scenarios and calibrated the target failure probability using the fatal accidental rate far for japanese railway the target failure probability was used by fujikubo et al 2003 to assess vlfs structural reliability in their research fujikubo et al 2003 compared the calculated failure probability with a specified target safety level and found that the safety target was not satisfactory under breakwater damage conditions bhattacharya et al 2001 tentatively applied a risk method and theory for the selection of target reliability and proposed a risk analysis method to determine the target reliability of mobile offshore bases mob although the papers above attempted to estimate vlfs target reliability using risk analysis methods the proportion of structural failure risk to overall accident risk was not taken into account additionally structural reliability criteria should explicitly consider potential influence on human lives as suggested by trbojevic 2009 who compared societal risk criteria and several structural reliability criteria and found that the safety level provided by structure codes may be intolerable from a safety risk perspective 2 3 ultimate strength of vlfs when assessing the load carrying capacity of ships or platforms wave induced loads and the capacity of hull girders must be determined yao 2003 several methods have been used by researchers to calculate the ultimate strength and most are based on progressive collapse analysis the related calculation methods include caldwell s method caldwell 1965 smith s method smith 1977 the finite element method fem chen 1983 and the ideal structural unit method isum ueda and rashed 1984 caldwell s method assumes that the average stress strain relationships are characterized by yielding buckling behaviour without strength reduction beyond the ultimate strength however smith s method assumes that the strength is reduced after the yielding buckling point is reached smith s method describes the actual behaviour of the material yao 2003 this method divides each hull girder into elements composed of plates and stiffeners the elements collapse one by one with increasing curvature then the maximum bending moment occurs when there is no incremental longitudinal bending moment mohammed et al 2016 paik et al 2008 the fem and isum methods are two effective methods of developing specific elements to conduct progressive collapse analysis however considerable computational efforts are needed because of the large numbers of nodes and elements for large girders yao 2003 fujikubo et al 2003 calculated the ultimate bending strengths of pontoon type vlfss based on the isum and nonlinear fem methods zhao et al 2019 studied the ultimate strength of brace struts for semi submersible type vlfs under compressive loads and torsion moments numerical simulations and model tests were conducted to verify the failure mechanism of the brace struts of the vlfs 3 the proposed methodology in this section a research flow diagram illustrating how to obtain the ultimate strength of a vlfs is provided fig 1 shows the analysis steps in this paper step 1 analyse the possible accident scenarios for vlfs this step aims to identify the major hazards of vlfs airports and establish an event tree model to obtain the structural failure risk value step 2 determine target reliability of vlfs the scope of this step includes analysing the ratio of structural risk to total risk assessing the severity of accident consequences and estimating target reliability based on the accident consequences step 3 calculate the vlfs ultimate strength and extreme wave loads this step utilizes a simplified progressive failure method and three dimensional potential flow theory to calculate the ultimate strength and extreme wave loads hence the characteristics of resistance and loads are obtained step 4 calibrate the ultimate strength structural reliability of vlfs based on the target reliability determined in step 2 in this step the ultimate strength reliability of vlfs is assessed by using the reasonable and practicable range of target reliability set in this paper the psfs in the safety margin equation are determined the ultimate strength design criteria for typical vlfs sections are obtained 4 determination of structural target reliability 4 1 introduction to risk theory risk can be expressed as a combination of the frequency and severity of a consequence imo 2013 with the following formula 1 r l c where r represents risk l is the probability of the hazard and c is the severity of the structural failure consequence thus risk is the product of the frequency and consequences of an event in marine engineering reliability is the complementary failure probability 2 r r e l i a b i l i t y 1 p f where r r e l i a b i l i t y is reliability and p f is the failure probability structural failure probability can be regarded as the hazard frequency associated with risk structural failure probability can also be expressed through the following reliability index fang and das 2005 3 β φ 1 1 p f individual risk can be expressed by the fatal accidental rate far imo 2013 the far represents the number of fatalities per 108 working hours 4 f a r p l l 10 8 p o b a v 8760 where pll is a potential loss of lives p o b a v is the average number of personnel on a floating structure societal risk can be expressed by f n diagrams f n diagrams are plots of the frequency f of n or more fatalities imo 2013 societal risk acceptance criteria can be used to limit the risks of catastrophes that affect many people 5 p l l a r e v f 1 1 n 1 n u 1 1 n 1 f 1 n 1 n u 1 n where p l l a represents the acceptable potential loss of lives r is the number of fatalities per generated economic value e v is the generated economic value f 1 represents the frequency of 1 or more fatalities and n represents the number of fatalities 4 2 structural failure risk to obtain the risk value ratio for floating body structural damage due to bad weather based on the total risk the following accidents were selected as the total accident set collisions cns fires explosions fxs grounding gr and floating body damage due to bad weather hd the pll caused by typical accidents can be expressed as 6 p l l i p o b c i p f i where i represents the typical accidents p f i is the initial accident frequency and c i is a coefficient related to the sequence of accident scenarios which represents the probability associated with event tree nodes 7 c i n 1 n u n f n p o b p f i the pll caused by typical accidents is as follows 8 p l l c n p o b c c n p f c n p l l f x p o b c f x p f f x p l l g r p o b c g r p f g r p l l h d p o b c h d p f h d the four types of accident plls are added to obtain the total pll 9 p l l t p l l c n p l l f x p l l g r p l l h d p o b i c i p f i in this paper a preliminary risk analysis of vlfss is performed and event tree models for collisions fires explosions grounding and floating body damage due to bad weather are established because a vlfs is considered a novel structure in the conceptual design process the accident data directly related to vlfss are limited the initial frequency is based on information from other platforms and ships the initial frequency data for collisions were chosen from the historical occurrence frequency of collisions from the uk marine platform brazil 2007 the fire explosion grounding and hull damage initial frequency data were obtained from global ro pax ships european maritime safety agency 2015 the similar characteristics of ro pax ships and vlfss such as spacious vehicle decks and large numbers of persons on board were the reason for selecting that data source the event tree for floating body damage due to bad weather is shown in fig 2 several accident scenarios from initial frequencies to final consequences were developed based on high level event sequences the high level event sequences for accident floating body damage due to bad weather included structure damage yes no the area of structure damage progressive damage yes no water ingress yes no collapse yes no sinking yes no and fast or slow sinking each node in the event sequence was assigned an occurrence probability consequences in the accident chains were also assessed finally the risk for each accident chain was calculated based on the product of the frequency and consequence the other event tree models such as collisions cns fire explosions fxs and grounding gr have been listed in appendix i the frequencies and fatalities for each scenario were assessed by the participants involved in the risk analysis process hypotheses for different accident sequence consequences were established and typical accident pll values were calculated from the event tree models the results are shown in table 1 the proportion of the structural damage risk value accounting for total risk was determined to be 14 5 which can be used to calculate the acceptable accident probability as follows 10 p f i a c p l l i p l l t p l l a c p o b where p l l a c is the acceptable pll and p f i a c is the acceptable accident probability associated with fatalities 4 3 developing target reliability target reliability can be estimated through a risk analysis method to determine the risk acceptance level identify the structural failure mode analyse the proportion of structural risk accounting for total risk assess the severity of accident consequences casualties or property damage and select target reliability based on these accident consequences according to the statistics of the civil aviation administration of china caac 2016 the daily average throughput of civil airports in china in 2016 was approximately 13000 passengers therefore the average throughput of a vlfs airport is assumed to be 13000 passengers per day the average time spent by each departing passenger and arriving passenger at an airport is assumed to be 3 h and 2 h respectively suzuki 2001 and the annual total exposure to activity is 1 19 million h which is 1354 passenger years it is assumed that there are 1000 airport service personnel who stay at the airport for 24 h which is 1000 staff years far and f n curves were plotted to determine the target reliability the fatal accident rate far 2 recommended by suzuki 2001 was selected and the structural failure pll was found to account for 14 5 of the total pll moreover the permissible annual structural failure probability was calculated as 7 48e 06 β 4 33 11 p l l f a r p o b a v 8760 10 8 n t p f where p o b a v represents the average number of personnel on the floating structure which is the sum of 1354 passenger years and 1000 staff years n t is maximum detention which is equal to 8000 persons aviation transportation industry fatality was selected as the criterion for calculating the f n curve acceptance criteria the generic benchmark for passenger fatality risk per unit gnp contribution was 0 73 fatalities per billion u s dollars of revenue this value was based on the 414 fatalities that occurred during aircraft accidents worldwide in 2012 compared to the total airline revenue of 638 billion u s dollars european maritime safety agency 2015 based on the statistics from an annual report of the civil aviation company of china china southern airlines 2016 the annual revenue per passenger year was calculated as 0 23 million u s dollars and the total revenue was calculated based on the total passenger years and staff years then the average acceptable plla was obtained according to eq 5 and the frequency of 1 or more fatalities f 1 occurring was calculated with eq 12 12 f 1 p l l a 14 5 n 1 8000 1 n 5 99 10 3 the upper and lower borders of a frequency of 1 or more fatalities are 5 99e 02 and 5 99e 04 respectively the f n curve acceptance criteria are presented in fig 3 according to the assumption in the event tree model that 66 of fatalities are caused by floating body damage due to bad weather a reasonable and practicable range for target failure probability is 1 13e 05 1 13e 07 β 4 24 5 18 the target reliability of vlfs varies with the service life and the reliability of the target for different years of service can be calculated from the following formula fujikubo et al 2003 13 p f n 1 1 p f 1 n where n is the number of service years p f 1 is the annual failure probability and p f n is the failure probability in year n the target reliability of the longitudinal ultimate strength of vlfs is calculated for different service periods the results of target reliability at 25 50 75 and 100 years are shown in table 2 as the service period increases the target reliability gradually decreases as shown in fig 4 dnv 1992 suggested an annual target failure probability of 1e 03 1e 04 β 3 09 3 71 for redundant structures the target failure probability calculated in this paper lies between 1e 05 and 1e 07 which is higher than the suggestion of dnv the structural target reliability calculated based on the f n curve acceptance criteria is a reasonable and practicable range that can provide guidance for structural design therefore this range is used to assess the strength reliability of a typical section and calculate the psfs as the number of fatalities decreases the target reliability will decrease however the structural target reliability will not decrease without limitation a minimum target reliability is required for vlfs therefore based on consultations with relevant experts a value of 3 09 1e 03 is established as proposed by dnv as the minimum target reliability requirement for the acceptable region border the alarp region requires the upper and lower border scope to cover two orders of magnitude therefore the lower border can be set as 1e 01 which represents a reliability value of 1 28 based on eq 3 setting a minimum target reliability value that meets the requirements of the acceptable risk level keeps the target reliability from becoming too low under small failure consequence conditions the target reliabilities of different failure consequences for 50 and 100 service years are shown in fig 5 and fig 6 respectively the whole area is divided into three regions when structural reliability plots in an intolerable region the structural reliability is unacceptable and measures should be taken to improve reliability when structural reliability plots in the alarp region the reliability of the structure is reasonable and practicable and cost effective measures should be taken to meet the reliability requirements 5 vlfs ultimate strength and wave loads 5 1 main design parameters a single vlfs module 300 m in length and 100 m in breath is composed of a superstructure deck column floating box and brace strut structure the floating box is transverse the main design parameters and component scales are shown in table 3 the segments of the module are shown in fig 7 5 2 ultimate strength simplified progressive collapse analysis is also called smith s method which is applied to calculate the longitudinal ultimate strength of typical sections of vlfs a step by step collapse analysis is carried out on the cross sections of vlfs subjected to ultimate bearing capacity and divide the cross section into stiffened plate elements and hard corner elements the average stress strain relationship for each type of element is achieved the planar cross section assumption is applied and curvature is progressively added to the cross section the maximum bending moment in the collapse process can be regarded as the ultimate strength of the structure yao 2003 because the segments of the vlfs contain different types of cross section the simplified progressive failure analysis method is used to calculate the ultimate strength of the midship section and no 6 cross section the cross sectional forms are shown in fig 8 and fig 9 the bending moment to curvature relationships of the vlfs midship section and no 6 cross section are shown in fig 10 and fig 11 the ultimate strength of the midship section under hogging conditions is 2 06e 10 nm and under sagging conditions is 2 67e 10 nm for the no 6 cross section the ultimate strength under hogging conditions is 6 97e 09 nm and that under sagging conditions is 8 37e 09 nm considering the uncertainty of the yield strength and plate thickness the actual value of the structural strength of the floating body is different from the characteristic value according to the statistical analysis of the yield strength and plate thickness the yield stress coefficient of variation cov equals 0 06 which indicates a lognormal distribution the plate thickness cov equals 0 01 which obeys a normal distribution the improved rosenbluthe method is used to calculate the ultimate strength and the cov of the vlfs cui et al 1998 the results are shown in table 4 the ultimate strength of the vlfs obeys a logarithmic normal distribution and the corresponding cov is between 0 05 and 0 06 5 3 vertical bending moment based on three dimensional potential flow theory the vertical bending moment rao of the midship section and no 6 cross section were calculated the jonswap spectrum was selected for the calculation of wave induced responses as shown in fig 12 a wave scatter diagram of the south china sea was applied to calculate the long term wave induced bending moment the long term prediction of wave induced responses approximately follows a weibull distribution f x given by 14 f x 1 exp x k r where k and r are the scale and shape parameters respectively the long term prediction of the vertical wave moment for different exceedance probabilities is shown in fig 13 the distribution of the long term extreme wave induced bending moment can be described by the gumbel distribution and the gumbel distribution can be expressed as follows 15 g y n exp exp c y n u where u and c are parameters of the gumbel distribution and can be estimated based on the initial weibull distribution as follows teixeira and guedes soares 2005 16 u k ln n 1 r 17 c r k u k r 1 where k and r are the parameters of weibull distribution and n is the return period related to the number of vlfs service years the extreme value of the vertical wave bending moment in a hundred year return period is calculated as 8 18e 09 nm for the midship section and 7 12e 09 nm for the no 6 cross section the coefficient of variation associated with the uncertainty of the wave load is approximately 0 08 the probability density functions of the weibull distribution and gumbel distribution are shown in fig 14 6 structural strength design criteria 6 1 structural reliability assessment the ultimate strength reliability of the vlfs midship section and no 6 cross section was assessed by using the reasonable and practicable range of target reliability set in this paper and the limit state equation for hull girder collapse was established as follows 18 z x m u m s m w where m u is the ultimate bearing capacity m s is the static bearing moment and m w is the wave bending moment the random variable z is a performance function related to the ultimate bearing capacity static bearing moment and wave bending moment the safety state for the performance function can be assessed based on z 0 notably z 0 represents the failure state and z 0 lies in the critical state the ultimate bearing capacity and wave bending moment follow a non normal distribution therefore it is necessary to transform the non normal distribution into a normal distribution at certain points the jc method proposed by rackwitz and flessler 1978 can be used to mitigate situations in which the limit state equation contains random variables with arbitrary distributions the jc method transforms the arbitrary distributions of random variables into normal distributions at design points by equivalent normalization zhao et al 2020 the calculation principle of equivalent normalization can be described as follows x i denotes a non normally distributed random variable with mean value μ x i and standard deviation σ x i the probability density and cumulative distribution function are f x i x i and f x i x i respectively the corresponding equivalent normalized random variable is x i with mean value μ x i and standard deviation σ x i the probability density and cumulative distribution function are f x i x i and f x i x respectively the equivalent normalization process in the jc method requires the probability density and cumulative distribution function of x i and x i to be equal at design point x this relation can be expressed as follows zhao et al 2020 19 f x i x i φ x i μ x i σ x i f x i x i 20 f x i x i 1 σ x i ϕ x i μ x i σ x i f x i x i the equivalent normalized mean value μ x i and standard deviation σ x i can be calculated by an inverse function 21 μ x i x i φ 1 f x i x i σ x i 22 σ x i ϕ φ 1 f x i x i f x i x i based on the equivalent normalized mean values and standard deviations the reliability index can be calculated through an iterative procedure as follows li et al 2020 1 for equation z g x i the initial check point value x μ x was chosen as the starting design point 2 for the non normally distributed random variable x i the equivalent normalized mean value μ x i and standard deviation σ x i were calculated by eqs 21 and 22 respectively the sensitivity factor α x i was calculated by substituting μ x i for μ x i and σ x i for σ x i 23 α x i g x x i σ x i i 1 n g x x i 2 σ x i 2 3 the reliability index β can be calculated from the following equation 24 β μ z σ z g x i 1 n g x x i μ x i x i i 1 n g x x i 2 σ x i 2 4 the new checkpoint x can be calculated with eq 25 25 x μ x i β α x i σ x i 5 steps 2 to 4 are repeated by updating at new checkpoints until two adjacent x values satisfy the relevant accuracy requirements the statistical parameters for the strength and load of a floating body are shown in table 5 the ultimate strength reliability values of typical sections for a hundred year return period extreme wave bending moment are calculated by the jc method as shown in table 6 compared to the target reliability set in this paper as shown in fig 15 the ultimate strength reliability of the midship section lies in the negligible region whereas the ultimate strength reliability of the no 6 cross section lies in the intolerable region the longitudinal ultimate strength of cross section no 6 is insufficient for a hundred year return period extreme wave bending moment 6 2 partial safety factors the psfs of the limit state equation in the lrfd method can ensure that the corresponding target reliability is satisfied in the limit state condition the reasonable and practicable range of the target reliability set in this paper can also be used to calibrate psfs and ensure that the structural safety level is adequate the limit state equation with psfs is established as 26 m u γ u γ s m s γ w m w where m u is the ultimate bearing capacity m s is the static bearing moment and m w is the wave bending moment γ u γ s and γ w are the model uncertainties associated with the ultimate capacity still water and wave bending moment respectively the target reliability range of 3 05 4 24 failure probability of 1 13e 03 1 13e 05 which corresponds to the alarp region of target reliability over 100 service years is selected to calculate the psfs for the midship section the psf applied to the capacity is approximately 1 05 1 07 the psf applied to the still water bending moment is 1 00 and the psf applied to the wave bending moment is 1 30 1 59 for the no 6 cross section the psf applied to the capacity is approximately 1 06 1 07 the psf applied to the still water bending moment is 1 00 and the psf applied to the wave bending moment is 1 32 1 59 6 3 ultimate strength design requirements based on the psfs and the still water and wave bending moments the ultimate strength design requirements can be calculated to guide structural design as shown in table 7 when the target reliability changes from 3 05 to 4 24 the ultimate strength for the midship section ranges from 1 13e 10 to 1 40e 10 nm and the ultimate strength for the no 6 cross section ranges from 1 00e 10 to 1 23e 10 nm compared to the design requirements the longitudinal ultimate strength of the midship section is larger than the design requirement and the ultimate longitudinal strength of the no 6 cross section is lower than the design requirement 7 conclusions in this paper a tentative analysis of the safety and reliability of vlfss was performed through a risk analysis approach a case study of the longitudinal ultimate strength of vlfss was conducted the psfs of the safety margin equation were calculated and the ultimate strength design requirements for typical sections were determined the reasonable and practicable scope of the structural target reliability of vlfss set in this paper can be used as a criterion to evaluate structural reliability and this metric is analogous to the risk level in other industries the event tree models developed in this paper provide a basis for assessing the risk of vlfss further research is needed to directly measure and calculate the connections among accident chains or accident categories the model established in this paper will become more robust as data become more available and reliable the reliability assessment results indicate that the ultimate strength reliability of the midship section is within the acceptable region for a hundred year return period extreme wave bending moment but that of the no 6 cross section lies in an unacceptable region thus ultimate strength design requirements are proposed for typical sections the ultimate strength criteria established in this paper provide guidance for engineering design credit authorship contribution statement xizhao wang conceptualization methodology formal analysis visualization writing original draft xuekang gu writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study is one of the research results of the project complex environment response and structural safety assessment for vlfs which has been funded by the ministry of science and technology of china under grant no 2013cb036105 this study is also supported by the ministry of industry and information technology of china under project no 2016 22 2019 357 and jiangsu province science foundation for youths under grant no 351510008k0708la00 appendix i event tree models and data for collision fire explosion and grounding accidents image 1 
20998,very large floating structures vlfss are novel offshore structures without direct reliability design criteria available currently target reliability as a critical safety indicator could be used to evaluate the ultimate strength reliability of vlfss therefore it is necessary to establish acceptable risk criteria to determine the structural design target reliability of vlfss and to calculate partial safety factors psfs for use as ultimate strength design criteria this paper developed a reliability assessment process in order to achieve the ultimate strength design criteria of vlfs a reasonable target reliability range for vlfs was determined by risk assessment methods and principles considering the structure failure probability and consequences the longitudinal ultimate strength for the typical sections of vlfs was calculated by applying the simplified progressive failure method the vertical extreme wave bending moments and their uncertainties for the corresponding typical sections of vlfs were analysed based on wave scatter diagram of the south china sea finally the ultimate strength reliability was assessed based on the reasonable target reliability range established within this paper results have shown that the reasonable target reliability range is found to be applicable for identifying the weak structural components of vlfs and some typical sections of vlfs should be redesigned to satisfy the criteria this paper can provide a reference for the safe design and compilation of relevant guidelines for vlfs keywords very large floating structures ultimate strength target reliability risk analysis structural reliability 1 introduction in recent years the development of coastal land has expanded lamas pardo et al 2015 therefore some conceptual designs involving floating bodies have occurred such as floating airports and ports suzuki et al 2007 floating ecopolises lamas pardo et al 2015 floating farms wang and tay 2011 and the floating tourism platforms xie et al 2020 among those conceptual designs floating airports ports have some distinguishing features a large size complex systems and large numbers of passengers and staff hence very large floating structures vlfss provide a solution for this novel architecture and have attracted the attention of architects and engineers wang and tay 2011 lamas pardo et al 2015 presented a definition of vlfss with the following characteristics a range of unprecedented parameters a long design life low maintenance costs and durability and resistance to fatigue vlfss are characterized by a range of unprecedented parameters and consist of several single modules the length of a single module can reach 300 400 m wang and tay 2011 vlfss can function as airports at sea harbours and comprehensive support bases and they can be an important components for the development of marine resources lamas pardo et al 2015 suzuki et al 2007 two types of vlfss pontoon type and semisubmersible type vlfss were studied in the 1990s by japan and the us respectively mcallister 1997 suzuki et al 2017 in 2013 china began a new project on the complex environmental responses of vlfs and performed corresponding structural safety assessments wu et al 2017 in this project a large number of theoretical and experimental studies on semisubmersible type vlfss were performed including studies of wave monitoring and simulation near islands and reefs liu et al 2019 yang et al 2013 fluid structure coupling responses ding et al 2017 2019 wu et al 2018 mooring systems cheng and wu 2018 ni et al 2018 connectors zhang et al 2017 and structural ultimate strength analysis zhao et al 2019 risk assessments reliability analyses and structure safety design criteria are key factors in the design and construction of vlfss for use as airports suzuki et al 2007 a basic principle of vlfs airport design and construction is that the safety level should be equivalent to that established by the international aviation industry the safety level can be evaluated by performing risk assessments and expressed by risk values zhang et al 2018 the risk value is an indicator of the safety margin as suddle 2009 noted a maximum safety level corresponds to no risk and a minimum safety level corresponds roughly to a high risk thus reflecting the linkage between safety and risk additionally a challenge faced by designers is determining how to set the target safety level at a sub system that is in line with the total risk acceptance criteria of a ship skjong and guedes soares 2008 ruud and mikkelsen 2008 performed work to determine target safety levels for crane systems using the formal safety assessment fsa approach for vlfs airports designers are mainly concerned with the longitudinal ultimate strength design criteria under extreme wave loads in regard to catastrophic failure scenarios design criteria for the ultimate strength limit state are needed to obtain the ultimate strength design criteria criteria related to reliability e g target reliability which represents the maximum allowable structural failure probability must be established target reliability can be applied to check whether the structural safety level meets the relevant requirements and can also be used to determine partial safety factors psfs in the load and resistance factor design lrfd method another challenge involves determining the relationship between risk and reliability and illustrating the risk level of the reliability indicator by considering the consequences of structure failure first this paper applies the risk acceptance criterion and corresponding design principles to determine a reasonable range of structural target reliability for vlfs second a simplified progressive failure method is applied to calculate the ultimate strength of typical vlfs sections the vertical extreme wave bending moments and their uncertainties for the corresponding typical sections of vlfs were analysed based on wave scatter diagram of the south china sea finally the longitudinal ultimate strength reliability of typical vlfs sections is assessed considering the selected target reliabilities the safety margin equation is established and the corresponding psfs are calculated based on these psfs the design requirements for the ultimate strength of vlfss under different working conditions are obtained 2 literature review 2 1 risk assessment applications involving marine structures the piper alpha disaster in 1988 was a wake up call for offshore industry practitioners since then some changes in offshore platforms have been made to avoid such accidents notably the offshore safety case regulations were published by the uk health and safety executive in 1992 these regulations require quantitative risk assessments qras for preparing offshore installation safety cases flin et al 2005 based on offshore safety case practices the international maritime organization imo accepted its member states suggestions for adopting risk analysis during the imo rule making process and established the formal safety assessment fsa methodology imo 2013 currently risk of ships and marine structures is assessed under the framework of fsa methodology in the marine safety domain montewka et al 2014 fsa involves five steps identification of hazards risk analysis risk control options cost benefit assessment and recommendations for decision making imo 2013 some fsa applications involving ships and their subsystems such as bulk carrier safety germany 2016 uk 2002 container vessels denmark 2007a liquefied natural gas carriers denmark 2007b korea 2016 cruise ships denmark 2008a denmark and uk 2012 european commission 2015 ropax ships brazil 2007 denmark 2008b and crude oil tankers denmark 2008a have been explored by imo member states the research scope of these fsa studies ranged from operational risk assessments to ship performance risk assessments although the fsa methodology has been adopted for various ship types little work has been done on overall safety evaluations of vlfs 2 2 target reliability for vlfss generally target reliability in traditional structural reliability assessment is based on the relevant code requirements dnv 1992 suggested different target failure probability requirements for different types of failure modes and consequences based on the damage to human life and the environment the canadian standards association 1992 provided values of 10 3 and 10 5 as safety levels for offshore structures in this case the target failure probability is established based on a qualitative description of the failure consequences and the severity of the failure consequences is not quantitatively assessed some empirical formulas have been suggested for calculating target reliability considering the structural lifetime redundancy and failure consequences bea 1990 these empirical formulas can provide guidance for determining the safety margin of structures of the same kind however there is no direct reference available that provides reliability design criteria for vlfss as novel marine structures notably empirical formulas may not be applicable to vlfs airports where many passengers crews and ground service personnel stay therefore it is necessary to rationally assess the severity of structural failure consequences and propose reasonable and practicable target reliability some researchers bhattacharya et al 2001 suzuki 2001 have considered using risk analysis methods to select vlfs target reliability ranges based on qualitative or quantitative analyses of the structural failure consequences according to risk assessment results suzuki 2001 analysed vlfs failure scenarios and calibrated the target failure probability using the fatal accidental rate far for japanese railway the target failure probability was used by fujikubo et al 2003 to assess vlfs structural reliability in their research fujikubo et al 2003 compared the calculated failure probability with a specified target safety level and found that the safety target was not satisfactory under breakwater damage conditions bhattacharya et al 2001 tentatively applied a risk method and theory for the selection of target reliability and proposed a risk analysis method to determine the target reliability of mobile offshore bases mob although the papers above attempted to estimate vlfs target reliability using risk analysis methods the proportion of structural failure risk to overall accident risk was not taken into account additionally structural reliability criteria should explicitly consider potential influence on human lives as suggested by trbojevic 2009 who compared societal risk criteria and several structural reliability criteria and found that the safety level provided by structure codes may be intolerable from a safety risk perspective 2 3 ultimate strength of vlfs when assessing the load carrying capacity of ships or platforms wave induced loads and the capacity of hull girders must be determined yao 2003 several methods have been used by researchers to calculate the ultimate strength and most are based on progressive collapse analysis the related calculation methods include caldwell s method caldwell 1965 smith s method smith 1977 the finite element method fem chen 1983 and the ideal structural unit method isum ueda and rashed 1984 caldwell s method assumes that the average stress strain relationships are characterized by yielding buckling behaviour without strength reduction beyond the ultimate strength however smith s method assumes that the strength is reduced after the yielding buckling point is reached smith s method describes the actual behaviour of the material yao 2003 this method divides each hull girder into elements composed of plates and stiffeners the elements collapse one by one with increasing curvature then the maximum bending moment occurs when there is no incremental longitudinal bending moment mohammed et al 2016 paik et al 2008 the fem and isum methods are two effective methods of developing specific elements to conduct progressive collapse analysis however considerable computational efforts are needed because of the large numbers of nodes and elements for large girders yao 2003 fujikubo et al 2003 calculated the ultimate bending strengths of pontoon type vlfss based on the isum and nonlinear fem methods zhao et al 2019 studied the ultimate strength of brace struts for semi submersible type vlfs under compressive loads and torsion moments numerical simulations and model tests were conducted to verify the failure mechanism of the brace struts of the vlfs 3 the proposed methodology in this section a research flow diagram illustrating how to obtain the ultimate strength of a vlfs is provided fig 1 shows the analysis steps in this paper step 1 analyse the possible accident scenarios for vlfs this step aims to identify the major hazards of vlfs airports and establish an event tree model to obtain the structural failure risk value step 2 determine target reliability of vlfs the scope of this step includes analysing the ratio of structural risk to total risk assessing the severity of accident consequences and estimating target reliability based on the accident consequences step 3 calculate the vlfs ultimate strength and extreme wave loads this step utilizes a simplified progressive failure method and three dimensional potential flow theory to calculate the ultimate strength and extreme wave loads hence the characteristics of resistance and loads are obtained step 4 calibrate the ultimate strength structural reliability of vlfs based on the target reliability determined in step 2 in this step the ultimate strength reliability of vlfs is assessed by using the reasonable and practicable range of target reliability set in this paper the psfs in the safety margin equation are determined the ultimate strength design criteria for typical vlfs sections are obtained 4 determination of structural target reliability 4 1 introduction to risk theory risk can be expressed as a combination of the frequency and severity of a consequence imo 2013 with the following formula 1 r l c where r represents risk l is the probability of the hazard and c is the severity of the structural failure consequence thus risk is the product of the frequency and consequences of an event in marine engineering reliability is the complementary failure probability 2 r r e l i a b i l i t y 1 p f where r r e l i a b i l i t y is reliability and p f is the failure probability structural failure probability can be regarded as the hazard frequency associated with risk structural failure probability can also be expressed through the following reliability index fang and das 2005 3 β φ 1 1 p f individual risk can be expressed by the fatal accidental rate far imo 2013 the far represents the number of fatalities per 108 working hours 4 f a r p l l 10 8 p o b a v 8760 where pll is a potential loss of lives p o b a v is the average number of personnel on a floating structure societal risk can be expressed by f n diagrams f n diagrams are plots of the frequency f of n or more fatalities imo 2013 societal risk acceptance criteria can be used to limit the risks of catastrophes that affect many people 5 p l l a r e v f 1 1 n 1 n u 1 1 n 1 f 1 n 1 n u 1 n where p l l a represents the acceptable potential loss of lives r is the number of fatalities per generated economic value e v is the generated economic value f 1 represents the frequency of 1 or more fatalities and n represents the number of fatalities 4 2 structural failure risk to obtain the risk value ratio for floating body structural damage due to bad weather based on the total risk the following accidents were selected as the total accident set collisions cns fires explosions fxs grounding gr and floating body damage due to bad weather hd the pll caused by typical accidents can be expressed as 6 p l l i p o b c i p f i where i represents the typical accidents p f i is the initial accident frequency and c i is a coefficient related to the sequence of accident scenarios which represents the probability associated with event tree nodes 7 c i n 1 n u n f n p o b p f i the pll caused by typical accidents is as follows 8 p l l c n p o b c c n p f c n p l l f x p o b c f x p f f x p l l g r p o b c g r p f g r p l l h d p o b c h d p f h d the four types of accident plls are added to obtain the total pll 9 p l l t p l l c n p l l f x p l l g r p l l h d p o b i c i p f i in this paper a preliminary risk analysis of vlfss is performed and event tree models for collisions fires explosions grounding and floating body damage due to bad weather are established because a vlfs is considered a novel structure in the conceptual design process the accident data directly related to vlfss are limited the initial frequency is based on information from other platforms and ships the initial frequency data for collisions were chosen from the historical occurrence frequency of collisions from the uk marine platform brazil 2007 the fire explosion grounding and hull damage initial frequency data were obtained from global ro pax ships european maritime safety agency 2015 the similar characteristics of ro pax ships and vlfss such as spacious vehicle decks and large numbers of persons on board were the reason for selecting that data source the event tree for floating body damage due to bad weather is shown in fig 2 several accident scenarios from initial frequencies to final consequences were developed based on high level event sequences the high level event sequences for accident floating body damage due to bad weather included structure damage yes no the area of structure damage progressive damage yes no water ingress yes no collapse yes no sinking yes no and fast or slow sinking each node in the event sequence was assigned an occurrence probability consequences in the accident chains were also assessed finally the risk for each accident chain was calculated based on the product of the frequency and consequence the other event tree models such as collisions cns fire explosions fxs and grounding gr have been listed in appendix i the frequencies and fatalities for each scenario were assessed by the participants involved in the risk analysis process hypotheses for different accident sequence consequences were established and typical accident pll values were calculated from the event tree models the results are shown in table 1 the proportion of the structural damage risk value accounting for total risk was determined to be 14 5 which can be used to calculate the acceptable accident probability as follows 10 p f i a c p l l i p l l t p l l a c p o b where p l l a c is the acceptable pll and p f i a c is the acceptable accident probability associated with fatalities 4 3 developing target reliability target reliability can be estimated through a risk analysis method to determine the risk acceptance level identify the structural failure mode analyse the proportion of structural risk accounting for total risk assess the severity of accident consequences casualties or property damage and select target reliability based on these accident consequences according to the statistics of the civil aviation administration of china caac 2016 the daily average throughput of civil airports in china in 2016 was approximately 13000 passengers therefore the average throughput of a vlfs airport is assumed to be 13000 passengers per day the average time spent by each departing passenger and arriving passenger at an airport is assumed to be 3 h and 2 h respectively suzuki 2001 and the annual total exposure to activity is 1 19 million h which is 1354 passenger years it is assumed that there are 1000 airport service personnel who stay at the airport for 24 h which is 1000 staff years far and f n curves were plotted to determine the target reliability the fatal accident rate far 2 recommended by suzuki 2001 was selected and the structural failure pll was found to account for 14 5 of the total pll moreover the permissible annual structural failure probability was calculated as 7 48e 06 β 4 33 11 p l l f a r p o b a v 8760 10 8 n t p f where p o b a v represents the average number of personnel on the floating structure which is the sum of 1354 passenger years and 1000 staff years n t is maximum detention which is equal to 8000 persons aviation transportation industry fatality was selected as the criterion for calculating the f n curve acceptance criteria the generic benchmark for passenger fatality risk per unit gnp contribution was 0 73 fatalities per billion u s dollars of revenue this value was based on the 414 fatalities that occurred during aircraft accidents worldwide in 2012 compared to the total airline revenue of 638 billion u s dollars european maritime safety agency 2015 based on the statistics from an annual report of the civil aviation company of china china southern airlines 2016 the annual revenue per passenger year was calculated as 0 23 million u s dollars and the total revenue was calculated based on the total passenger years and staff years then the average acceptable plla was obtained according to eq 5 and the frequency of 1 or more fatalities f 1 occurring was calculated with eq 12 12 f 1 p l l a 14 5 n 1 8000 1 n 5 99 10 3 the upper and lower borders of a frequency of 1 or more fatalities are 5 99e 02 and 5 99e 04 respectively the f n curve acceptance criteria are presented in fig 3 according to the assumption in the event tree model that 66 of fatalities are caused by floating body damage due to bad weather a reasonable and practicable range for target failure probability is 1 13e 05 1 13e 07 β 4 24 5 18 the target reliability of vlfs varies with the service life and the reliability of the target for different years of service can be calculated from the following formula fujikubo et al 2003 13 p f n 1 1 p f 1 n where n is the number of service years p f 1 is the annual failure probability and p f n is the failure probability in year n the target reliability of the longitudinal ultimate strength of vlfs is calculated for different service periods the results of target reliability at 25 50 75 and 100 years are shown in table 2 as the service period increases the target reliability gradually decreases as shown in fig 4 dnv 1992 suggested an annual target failure probability of 1e 03 1e 04 β 3 09 3 71 for redundant structures the target failure probability calculated in this paper lies between 1e 05 and 1e 07 which is higher than the suggestion of dnv the structural target reliability calculated based on the f n curve acceptance criteria is a reasonable and practicable range that can provide guidance for structural design therefore this range is used to assess the strength reliability of a typical section and calculate the psfs as the number of fatalities decreases the target reliability will decrease however the structural target reliability will not decrease without limitation a minimum target reliability is required for vlfs therefore based on consultations with relevant experts a value of 3 09 1e 03 is established as proposed by dnv as the minimum target reliability requirement for the acceptable region border the alarp region requires the upper and lower border scope to cover two orders of magnitude therefore the lower border can be set as 1e 01 which represents a reliability value of 1 28 based on eq 3 setting a minimum target reliability value that meets the requirements of the acceptable risk level keeps the target reliability from becoming too low under small failure consequence conditions the target reliabilities of different failure consequences for 50 and 100 service years are shown in fig 5 and fig 6 respectively the whole area is divided into three regions when structural reliability plots in an intolerable region the structural reliability is unacceptable and measures should be taken to improve reliability when structural reliability plots in the alarp region the reliability of the structure is reasonable and practicable and cost effective measures should be taken to meet the reliability requirements 5 vlfs ultimate strength and wave loads 5 1 main design parameters a single vlfs module 300 m in length and 100 m in breath is composed of a superstructure deck column floating box and brace strut structure the floating box is transverse the main design parameters and component scales are shown in table 3 the segments of the module are shown in fig 7 5 2 ultimate strength simplified progressive collapse analysis is also called smith s method which is applied to calculate the longitudinal ultimate strength of typical sections of vlfs a step by step collapse analysis is carried out on the cross sections of vlfs subjected to ultimate bearing capacity and divide the cross section into stiffened plate elements and hard corner elements the average stress strain relationship for each type of element is achieved the planar cross section assumption is applied and curvature is progressively added to the cross section the maximum bending moment in the collapse process can be regarded as the ultimate strength of the structure yao 2003 because the segments of the vlfs contain different types of cross section the simplified progressive failure analysis method is used to calculate the ultimate strength of the midship section and no 6 cross section the cross sectional forms are shown in fig 8 and fig 9 the bending moment to curvature relationships of the vlfs midship section and no 6 cross section are shown in fig 10 and fig 11 the ultimate strength of the midship section under hogging conditions is 2 06e 10 nm and under sagging conditions is 2 67e 10 nm for the no 6 cross section the ultimate strength under hogging conditions is 6 97e 09 nm and that under sagging conditions is 8 37e 09 nm considering the uncertainty of the yield strength and plate thickness the actual value of the structural strength of the floating body is different from the characteristic value according to the statistical analysis of the yield strength and plate thickness the yield stress coefficient of variation cov equals 0 06 which indicates a lognormal distribution the plate thickness cov equals 0 01 which obeys a normal distribution the improved rosenbluthe method is used to calculate the ultimate strength and the cov of the vlfs cui et al 1998 the results are shown in table 4 the ultimate strength of the vlfs obeys a logarithmic normal distribution and the corresponding cov is between 0 05 and 0 06 5 3 vertical bending moment based on three dimensional potential flow theory the vertical bending moment rao of the midship section and no 6 cross section were calculated the jonswap spectrum was selected for the calculation of wave induced responses as shown in fig 12 a wave scatter diagram of the south china sea was applied to calculate the long term wave induced bending moment the long term prediction of wave induced responses approximately follows a weibull distribution f x given by 14 f x 1 exp x k r where k and r are the scale and shape parameters respectively the long term prediction of the vertical wave moment for different exceedance probabilities is shown in fig 13 the distribution of the long term extreme wave induced bending moment can be described by the gumbel distribution and the gumbel distribution can be expressed as follows 15 g y n exp exp c y n u where u and c are parameters of the gumbel distribution and can be estimated based on the initial weibull distribution as follows teixeira and guedes soares 2005 16 u k ln n 1 r 17 c r k u k r 1 where k and r are the parameters of weibull distribution and n is the return period related to the number of vlfs service years the extreme value of the vertical wave bending moment in a hundred year return period is calculated as 8 18e 09 nm for the midship section and 7 12e 09 nm for the no 6 cross section the coefficient of variation associated with the uncertainty of the wave load is approximately 0 08 the probability density functions of the weibull distribution and gumbel distribution are shown in fig 14 6 structural strength design criteria 6 1 structural reliability assessment the ultimate strength reliability of the vlfs midship section and no 6 cross section was assessed by using the reasonable and practicable range of target reliability set in this paper and the limit state equation for hull girder collapse was established as follows 18 z x m u m s m w where m u is the ultimate bearing capacity m s is the static bearing moment and m w is the wave bending moment the random variable z is a performance function related to the ultimate bearing capacity static bearing moment and wave bending moment the safety state for the performance function can be assessed based on z 0 notably z 0 represents the failure state and z 0 lies in the critical state the ultimate bearing capacity and wave bending moment follow a non normal distribution therefore it is necessary to transform the non normal distribution into a normal distribution at certain points the jc method proposed by rackwitz and flessler 1978 can be used to mitigate situations in which the limit state equation contains random variables with arbitrary distributions the jc method transforms the arbitrary distributions of random variables into normal distributions at design points by equivalent normalization zhao et al 2020 the calculation principle of equivalent normalization can be described as follows x i denotes a non normally distributed random variable with mean value μ x i and standard deviation σ x i the probability density and cumulative distribution function are f x i x i and f x i x i respectively the corresponding equivalent normalized random variable is x i with mean value μ x i and standard deviation σ x i the probability density and cumulative distribution function are f x i x i and f x i x respectively the equivalent normalization process in the jc method requires the probability density and cumulative distribution function of x i and x i to be equal at design point x this relation can be expressed as follows zhao et al 2020 19 f x i x i φ x i μ x i σ x i f x i x i 20 f x i x i 1 σ x i ϕ x i μ x i σ x i f x i x i the equivalent normalized mean value μ x i and standard deviation σ x i can be calculated by an inverse function 21 μ x i x i φ 1 f x i x i σ x i 22 σ x i ϕ φ 1 f x i x i f x i x i based on the equivalent normalized mean values and standard deviations the reliability index can be calculated through an iterative procedure as follows li et al 2020 1 for equation z g x i the initial check point value x μ x was chosen as the starting design point 2 for the non normally distributed random variable x i the equivalent normalized mean value μ x i and standard deviation σ x i were calculated by eqs 21 and 22 respectively the sensitivity factor α x i was calculated by substituting μ x i for μ x i and σ x i for σ x i 23 α x i g x x i σ x i i 1 n g x x i 2 σ x i 2 3 the reliability index β can be calculated from the following equation 24 β μ z σ z g x i 1 n g x x i μ x i x i i 1 n g x x i 2 σ x i 2 4 the new checkpoint x can be calculated with eq 25 25 x μ x i β α x i σ x i 5 steps 2 to 4 are repeated by updating at new checkpoints until two adjacent x values satisfy the relevant accuracy requirements the statistical parameters for the strength and load of a floating body are shown in table 5 the ultimate strength reliability values of typical sections for a hundred year return period extreme wave bending moment are calculated by the jc method as shown in table 6 compared to the target reliability set in this paper as shown in fig 15 the ultimate strength reliability of the midship section lies in the negligible region whereas the ultimate strength reliability of the no 6 cross section lies in the intolerable region the longitudinal ultimate strength of cross section no 6 is insufficient for a hundred year return period extreme wave bending moment 6 2 partial safety factors the psfs of the limit state equation in the lrfd method can ensure that the corresponding target reliability is satisfied in the limit state condition the reasonable and practicable range of the target reliability set in this paper can also be used to calibrate psfs and ensure that the structural safety level is adequate the limit state equation with psfs is established as 26 m u γ u γ s m s γ w m w where m u is the ultimate bearing capacity m s is the static bearing moment and m w is the wave bending moment γ u γ s and γ w are the model uncertainties associated with the ultimate capacity still water and wave bending moment respectively the target reliability range of 3 05 4 24 failure probability of 1 13e 03 1 13e 05 which corresponds to the alarp region of target reliability over 100 service years is selected to calculate the psfs for the midship section the psf applied to the capacity is approximately 1 05 1 07 the psf applied to the still water bending moment is 1 00 and the psf applied to the wave bending moment is 1 30 1 59 for the no 6 cross section the psf applied to the capacity is approximately 1 06 1 07 the psf applied to the still water bending moment is 1 00 and the psf applied to the wave bending moment is 1 32 1 59 6 3 ultimate strength design requirements based on the psfs and the still water and wave bending moments the ultimate strength design requirements can be calculated to guide structural design as shown in table 7 when the target reliability changes from 3 05 to 4 24 the ultimate strength for the midship section ranges from 1 13e 10 to 1 40e 10 nm and the ultimate strength for the no 6 cross section ranges from 1 00e 10 to 1 23e 10 nm compared to the design requirements the longitudinal ultimate strength of the midship section is larger than the design requirement and the ultimate longitudinal strength of the no 6 cross section is lower than the design requirement 7 conclusions in this paper a tentative analysis of the safety and reliability of vlfss was performed through a risk analysis approach a case study of the longitudinal ultimate strength of vlfss was conducted the psfs of the safety margin equation were calculated and the ultimate strength design requirements for typical sections were determined the reasonable and practicable scope of the structural target reliability of vlfss set in this paper can be used as a criterion to evaluate structural reliability and this metric is analogous to the risk level in other industries the event tree models developed in this paper provide a basis for assessing the risk of vlfss further research is needed to directly measure and calculate the connections among accident chains or accident categories the model established in this paper will become more robust as data become more available and reliable the reliability assessment results indicate that the ultimate strength reliability of the midship section is within the acceptable region for a hundred year return period extreme wave bending moment but that of the no 6 cross section lies in an unacceptable region thus ultimate strength design requirements are proposed for typical sections the ultimate strength criteria established in this paper provide guidance for engineering design credit authorship contribution statement xizhao wang conceptualization methodology formal analysis visualization writing original draft xuekang gu writing review editing supervision declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgements this study is one of the research results of the project complex environment response and structural safety assessment for vlfs which has been funded by the ministry of science and technology of china under grant no 2013cb036105 this study is also supported by the ministry of industry and information technology of china under project no 2016 22 2019 357 and jiangsu province science foundation for youths under grant no 351510008k0708la00 appendix i event tree models and data for collision fire explosion and grounding accidents image 1 
20999,digital twins are virtual representations of subsystems within a system of systems they can be utilized to model and predict performance and condition degradation throughout a system s life cycle condition based maintenance or the performance of system maintenance based on the subsystem states is often facilitated by the implementation of digital twins an open challenge is selecting the subsystems that require digital twins we establish a generic process for determining a set of priority based system components requiring digital twin development for condition based maintenance purposes the priority set which we term the triage set represents the set of components that when monitored through a digital twin lead to the greatest increase in total system reliability and simultaneously represent the minimal cost set of components for implementing a digital twin while we focus our process on an unmanned underwater vehicle uuv where we frame the design problem as a multiobjective optimization problem utilizing experimentally determined data and metrics from the model of a real uuv system the process is generic enough that it could be utilized by any system looking at cost and reliability estimates for leveraging digital twin technology keywords digital twin multiobjective optimization pareto optimization reliability nomenclature cbm condition based maintenance dt digital twin ganbi genetic algorithm based normal boundary intersection mbse model based systems engineering moop multiobjective optimization problem sos system of systems tdt triage digital twin uuv unmanned underwater vehicle f min convex hull of individual minima for moop δ r r reliability improvement function c set of known design and development costs for digital twins of subsystems r set of known reliabilities of subsystem components r known reliabilities for components with corresponding digital twin c tot total digital twin implementation cost n gen number of generations in evolutionary algorithm n pop size of population in evolutionary algorithm n pts number of points segmenting line connecting individual minima l vector of component layer information n total number of system components r pareto optimal subset of component reliabilities s triage digital twin components 1 introduction we explore the interplay between total system reliability and the development cost for building a digital twin for an sos industries that depend on complex sos for accomplishing hazardous or laborious tasks that would otherwise place humans in harm require reliable and robust sos that function expectedly medical robotics the airline and automotive industries and smart manufacturing facilities are a few examples of sos that perform tasks to mitigate the risk to the human often digital twins a term first coined by michael grieves facilitate this reliability and enhance the robustness by providing sos operators and maintainers with additional system awareness grieves 2005 daneshmand et al 2017 kousi et al 2019 tao et al 2019a digital twins are virtual representations that mimic the subsystems and dynamics of their real time counterparts digital twins have proliferated in use because of their predictive capacity for the degradation of their real time systems and are now a central part of product life cycle management grieves and vickers 2017 however many legacy sos still rely on traditional methods of reliability management to mitigate risks through a variety of maintenance strategies including preventative reactive and condition based maintenance preventative maintenance entails performing routine maintenance tasks on a fixed schedule swanson 2001 this can lead to significant waste of labor since component failures typically occur as a result of the condition of parts endrenyi et al 2001 if the condition of the part to be replaced has not yet degraded to the point of failure then the replacement part is wasted as is the labor to replace the part reactive maintenance means performing maintenance based on events such as the failure or degradation of a mechanical part to the extent that it is non functional karuppuswamy et al 2006 while the typical maintenance schedule of an sos includes a combination of both preventative and reactive maintenance alternative methods are used throughout the airline automotive and other commercial industries that observe the condition of components to trigger maintenance tasks li and nilkitsaranont 2009 prajapati et al 2012 zou et al 2019 this condition based maintenance provides an opportunity to reduce labor and parts costs since fewer parts are wasted and labor is optimized on an as needed basis visual inspection can provide some degree of accuracy in assessing the condition of certain external components for example the tread on a tire of an automobile horner et al 1997 a newer approach offers more disciplined and less ambiguous condition assessments this is condition based maintenance through the use of a digital twin to minimize the need for visual inspection digital twins are utilized to monitor the condition of components in critical systems like jet engines fuel pumps and robotics for example digital twins have taken a leading role in advancing manufacturing and complex sos throughout the industry 4 0 movement and the proliferation of the internet of things kusiak 2017 fuller et al 2020 koulamas and kalogeras 2018 given the widespread adaptation and integration of multiple data sources throughout a system s lifecycle including sensor performance testing and evaluation and maintenance data for example numerous technologies among which the digital twin belongs integrate and aggregate these data sources into a uniform picture of a system s state qi and tao 2018 tao et al provide a detailed account and survey of digital twin technology including numerous examples from industry that illuminate the utility of digital twins for predicting condition degradation within a sos tao et al 2019b notably tao et al outline how general electric ge has implemented digital twins for their wind turbine systems lund et al 2018a 2018b the total digital twin system constitutes the sensor network by which the physical wind turbines are connected and the network connection to the cloud based turbine model the cloud models are constantly updated with performance data collected across the physical system network the feedback from the cloud model can then be utilized in turn as an optimized controller for the wind turbines creating an optimized feedback loop facilitated by the so called smart connectivity ge s digital twin model emphasizes a general standard that defines a digital twin system there is a physical system a virtual system and connection between the virtual and physical system glaessgen and stargel 2012 another interesting example is the development of a digital twin for a robotic surgery system laaki et al 2019 while laaki et al utilize a robotic arm as a substitute for a real time system they mention the da vinci surgical system manufactured by intuitive surgical inc as a suitable candidate that would benefit from the digital twin boeing has begun utilizing its in house developed discrete event simulation model which incorporates material procurement data and manufacturing automation performance data by using this data and the simulation tool boeing has an end to end supply chain model for its manufacturing businesses together these represent the digital twin hilton and needham 2019 siemens the german manufacturer utilizes numerous digital twin models for its production processes this underscores the key idea behind digital twins there is not one digital twin that governs or represents an entire system rather a digital twin comprises numerous distinct and potentially different models based on the function of the individual subsystems in siemens case they utilize finite element models for stress and strain digital twins in their production line tao and qi 2019 for further examples taken from industry see liu et al 2020 for this paper we choose the unmanned underwater vehicle for a case study since there is a growing dependence on these systems from a variety of industries that directly remove humans from harm as a result of leveraging uuv technology uuvs or autonomous underwater vehicles auvs have witnessed significant growth in their utility for a variety of industries including sea floor and oceanographic surveys deep water drilling platform inspections ship hull inspections bridge maintenance and surveys and various academic uses hylton 2020 whitcomb 2000 fletcher 2000 mcfarlane 2008 fletcher and wernli 2003 miller 1996 kukulya et al 2010 the wide adaptation and continued use of uuvs indicates a high level of dependence on these platforms for critical tasking tasking which would otherwise place humans in direct risk of harm thieme and utne 2017 this dependence largely requires reliable and available systems that can be expected to function according to specifications runtime mission failures present potentially catastrophic consequences for the operators while presenting a challenging task to mitigate these risks for the uuv maintainers a uuv presents a very challenging task for traditional maintenance strategies and cbm through visual inspection since access to internal components is limited or requires significant effort to inspect the internal components are housed inside either a free flooded the hull floods with water for buoyancy control or a hermetically sealed hull the hull is both air and water tight to access the components housed inside the sealed hull requires breaking the seal and accessing the components in a confined space external components can be inspected for wear and condition degradation but these are also challenging since functionality can be degraded without visual cues these challenges can largely be subverted by the use of digital twins for cbm purposes the twin is a digital replica that maintains data and dynamics information in parallel with the real time system building a twin typically involves selecting a data or dynamics driven model for every individual component liu et al 2012 coraddu et al 2019 kim et al 2020 data driven models rely on historical system data for training machine learning models dynamics driven models utilize first principles and physics based modeling for creating models that are data independent the particular methodology depends on the intended use for example a data driven model which utilizes a machine learning process is particularly suited for predicting component degradation hong et al demonstrate the use of one such technique a special ordered map which through unsupervised machine learning they train to extract degradation of ball bearings hong et al 2014 alternative methods have been used which provide performance estimations under unknown conditions these dynamics driven approaches offer higher degrees of predictability than their data driven counterparts since they model time based dynamics these too update model parameters from the real time system but do not depend on historical performance data for their predictive capacity hanachi et al derive a physics based model for capturing the performance of gas turbine engines with applications in the airline industry hanachi et al 2015 their work demonstrates one instance of the applicability of a model based approach for predictive capacity others have developed novel techniques that give hybrid performance lei et al use a model based approach for remaining useful life rul predictions for which they provide experimental evidence demonstrating the method s efficacy on ball bearings the challenge with leveraging data driven models is the necessity for copious amounts of high quality data for the airline and automotive industries which typically have experimental apparatus in place it is decidedly easier to produce the data for predictive maintenance models however for systems like uuvs the presence of high quality data is generally lacking since it is challenging to extract failure mode data from these systems when failures occur at run time and below the sea surface there are two primary mechanisms for handling this case machine learning algorithms that handle limited training data and better experimental apparatus alternative machine learning models exist to leverage digital twin technology without the use of high quality or properly labeled data the work of tan et al demonstrates the use of one such technique to predict condition degradation of a ship s propulsion system without properly labeled data sets tan et al 2019 2020 alternative test setups can be fashioned to run repeated experimental tests to extract relevant performance data under typical operational mission profiles see fig 1 for an example experimental setup in the figure an oscilloscope is connected to the uuv while the uuv s autonomy computer is running in order to collect sensory signal data on the workbench user interface components are connected directly to the autonomy computer to manipulate simulation characteristics on the bench the uuv shown in the figure is the system we consider for the case study in this paper section 3 provides a detailed overview of the system even these setups lack in realistic simulation since external failures can occur from the uuv hitting something in the water or during docking and deploying the uuv from a ship the repeated insertion and extraction deploying and docking of the uuv can create significant wear on the system because many of the external components are very sensitive such as the fins and propeller to accurately represent these mechanical failures is challenging in a benchtop environment the apparatus shown in fig 1 is only capable of testing the electronic components and as such falls short at capturing the entirety of the potential failure modes here we are not considering the particular model type only that some model will be selected to serve as the twin we do make the distinction that the digital twin for an entire system comprises any number of individual digital twins for the subsystems being monitored each subsystem has its own model requirements data or dynamics driven and has its own requirements for data acquisition and physical interfaces data acquisition establishes the means by which the twin acquires data from the real time subsystem this could be through client server style resources as in the robot operating system ros or exchanging data through some other means via ethernet for example stanford artificial intelligence laboratory et al physical interfaces indicate the required ports to facilitate the data acquisition process these could be any physical connection such as universal serial bus usb ethernet or other serial port connections there are two pathways to leveraging digital twin technology for cbm purposes first the system designer can build a twin for each component incorporating the necessary data and physical interfaces into the system design second the system can be retrofitted with the information acquisition resources data and physical interfaces to extract the relevant information to support the twin the former requires a significant amount of design effort since the system designer must meet the standard system specifications and requirements as well as incorporate the acquisition resources for the digital twin for the relevant components the second pathway provides a means for retrofitting the system with digital twins it also provides attachability meaning legacy systems that are critical for removing humans from direct harm can still benefit from digital twin technology the second also has the advantage of an established perhaps inefficient maintenance schedule that can be optimized from the incorporation of digital twins for cbm purposes however the questions unanswered from the perspective of decision makers and developers alike remain what components should have digital twins how should the system be retrofitted with the data acquisition resources for the digital twins we address the cost issue associated with incorporating a digital twin by developing a novel approach that incorporates both mbse and multiobjective optimization to enable the selection of appropriate components for digital twin representation these triage components produce the largest increase in total system reliability and minimize the cost entrance hurdle for leveraging digital twin technology we utilize the term triage to reflect the fact that some components are prioritized over others much like the triage process utilized during disaster relief by first responders prioritization of limited medical treatment resources optimizes the care given ensuring that those who qualify and meet the selection criteria receive treatment first koenig and schultz 2010 though the criteria change based on the triage system used the idea remains the same those who benefit most from treatment receive priority over those who would benefit the least such as someone with significant blood loss over someone with a minor cut likewise certain subsystems yield larger and more significant benefits to total system reliability than other subsystems the paper is organized as follows in section 2 we explore established research for reliability predictions redundancy allocation and reliability optimization in section 3 we introduce the platform used for modeling a minimalist uuv system as well as a basic description of the vehicle and additional reference data in section 4 we introduce our mbse approach including the language and modeling used to develop the model for the uuv system as well as challenges in implementing mbse retroactively in section 5 we explain in detail the reliability analysis and demonstrate results from applying our process to the uuv under test we conclude the case study in section 6 by commenting on the implications of the case study for the field of uuvs and how the work can be used to inform the tdt design process we address the implications on the work for the field of reliability studies and how the process generalizes for arbitrary sos looking at implementing a tdt 2 related work much of the existing literature in the fields of redundancy allocation and reliability predictions offer technically rigorous mechanisms for improving sos reliabilities through the introduction of redundant components and sophisticated methods for predicting and optimizing sos reliability as a result these methods provide a breadth of established research that can be used for a variety of sos our contribution is a coupling of an mbse approach and an moop providing a simplified process that incorporates data from a variety of stakeholders system maintainers and operators to guide the reliability improvement analysis and frame the discussion with decision makers by providing candidate subsets for tdt implementation our specific contributions are as follows a novel methodology to prioritize and select a triage set of subsystems that comprise the digital twin of the total system an mbse approach that elucidates the necessary data acquisition and physical interfaces that must be established for future digital twin development a reliability analysis based on the application of our methodology to a case study on a uuv qualitative analysis of the implications of our methodology on the development of next generation unmanned systems on the tdt design process we will now discuss the state of the art in digital twin development and reliability improvements for sos and how they are augmented by our methodology biggs et al introduce the contemporary challenges in utilizing sysml as the primary mbse language to include reliability considerations in an mbse effort early in a project s life cycle biggs et al 2018 they advocate for the inclusion of new language concepts that extend sysml to better model reliability requirements than are currently possible at the time of this authorship we are not aware of the inclusion of these concepts in the sysml standard their work is notable because they address several issues that we have encountered including the tracking of reliability and safety data across different documents and spreadsheets these are challenging to maintain and often the critical information is lost to mitigate this challenge we capture reliability data directly in the mbse model as we conduct discussions with the system maintainers and architects this information is tracked and can be updated as the model is updated throughout its life cycle additional techniques are utilizing the central structure that mbse provides for conducting failure modes and effects analysis fmea huang et al 2017 our choice in using mbse for modeling complex sos is supported by the use and acceptance of several organizations d ambrosio and soremekun 2017 mitchell 2010 given the complexity of many sos mbse is gaining traction across organizations that would like to simplify system life cycle maintenance since it unifies many traditionally disparate data sources and documents into one accessible and traceable location several strategies are used to improve system reliability one such strategy is the introduction of redundant components by introducing redundant components or backups the failure of the component is mitigated by these alternates indeed this is an integral part of robust system design and the topic of numerous papers on designing for reliability rochlin et al 1987 kim and kim 2017 muhuri et al 2018 an example is the electronic flight data recorder or black box used in commercial airplanes the electronic flight data recorder tracks and records flight data and system diagnostics it is recovered after airplane crashes and used to provide investigators with vital system information leading to the failure and crash the data recorder is often installed with a redundant data recorder to improve the chances of finding the device in a crash and to improve the reliability downer 2011 a challenging problem is determining how many redundant components should be used to achieve a desired level of reliability this is the redundancy allocation problem for parallel subsystems coit and smith introduce a genetic algorithm for the redundancy allocation problem in parallel subsystems coit and smith 1996 the genetic algorithm of coit and smith scales well for large systems and offers a unique formulation for determining redundancy levels and searching the component trade space as a consequence they can quickly identify the level of redundancy required to achieve a stated level of reliability within cost constraints our work seeks a similar calculation except that we are not considering parallel subsystems exclusively and we do not have reliability requirements muhuri et al provide a detailed approach to the redundancy allocation problem they go beyond the work of coit and smith by accommodating traditionally challenging trade space parameters such as physical dimensions and weight of redundant components through fuzzy parameters in their optimization routine the challenge with such an approach is utilizing this retroactively while this is an excellent approach when utilized early in the design phase of a system existing components are largely fixed and the system has been optimized to accommodate those components fundamentally the reliability can only be changed through a more intelligent maintenance routine such as a cbm approach yeh and fiondella expound in great detail on a redundancy allocation application in computer networks yeh and fiondella 2017 they utilize a simulated annealing algorithm to solve the allocation problem garg and sharma perform a strikingly similar analysis as our work they utilize a particle swarm optimization algorithm to solve their moop which is a bi objective problem maximizing reliability improvement from the introduction of redundant components they also minimize system design cost garg and sharma 2013 we also optimize for a reliability difference which is the difference between the base system and the new proposed system with digital twins for cbm purposes the work is distinct in that they minimize the cost for adding the redundant components whereas our work considers selecting candidate subsets that minimize tdt implementation costs there have been significant advances in reliability predictions for complex systems in recent years as of 2018 yuan et al introduced a statistical mechanism for reliability evaluation yuan et al 2018 using bayesian networks bn they construct object oriented representations of subsystems which they utilize to construct a bn for propagating uncertainties about component conditions these dynamic object oriented bayesian networks doobns facilitate ease of modeling since the connections between subsystems are concise and built from conversations between the modelers and the domain experts kumar et al show using fuzzy set logic a method for computing reliability of series parallel systems kumar et al 2020 in their survey pérez rosés outlines numerous other mechanisms that exist for reliability optimization and redundancy allocations on complex systems and over series parallel networks pérez rosés 2018 3 unmanned underwater vehicle for case study in fig 2 we show the low cost vehicle with subsystem labels and components we have chosen this vehicle as our case study system for two reasons first we have direct access to design specifications bill of materials and the system architects second the system provides a baseline representation of a uuv without the added components and complexity of legacy commercial off the shelf systems the experimental vehicle offers the minimal set of functioning components as a result the systems engineering process is simplified to complete retroactively we acknowledge that for a more complex system this process would not be as straightforward particularly since access to the original architects or maintainers may be severely limited we argue those who perform routine maintenance can provide insight into the design and the components that are the most challenging to maintain the system operators are also an excellent resource since they have a better idea of how the system functions under normal or expected operating conditions which helps inform the triage component selection process the output of the process in this paper guarantees subsets of components maximizing reliability and minimizing digital twin development cost but it does not say whether these components are the most challenging to maintain cost does not necessarily imply difficulty of maintenance if the component is challenging to reach such as an electronics component in the interior of the hull but is low cost like a resistor this would be a component that is hard to maintain but low unit cost while we concede that there is generally a labor cost associated with performing maintenance here we do not consider this we do not address maintainability directly in this work but it should be considered during the discussion phase with decision makers future work will address maintainability in a more rigorous fashion by including a maintainability metric in the objective set in section 6 we discuss the use of this and other higher level information which can be used to scale the optimal subsets of components provided by the moop in our process the vehicle comprises 17 main subsystems here we do not make a distinction between a subsystem and a component for a minimalist system like the vehicle these can be used interchangeably the components listed in fig 2 represent subsystems supporting communication between the vehicle and the operators navigation and intelligence the communication subsystems are the acoustic modem transducer acoustic modem electronics and comms antenna contained in the handle the navigation components are the passive sonar array inertial measurement unit satellite navigation velocity sensor and depth sensor the intelligence subsystems support the higher level vehicle control including path planning ascending descending and waypoint navigation the primary intelligence is provided by the vehicle computer and electronics all of these subsystems depend on the energy source provided by the batteries the components are assembled in the external housing which is composed of the nose cone front bulkhead mid section rear bulkhead o rings and tail cone the propeller and fins provide propulsion and control respectively the only subsystem we refer to that is not shown in fig 2 is the propeller shroud which is concentric with the propeller and shields the propeller from any damage together these subsystems constitute a minimalist uuv and provide the ideal experimental apparatus to test our decision process on selecting triage component sets for implementing digital twins however to understand the process for determining the triage components we must first understand the connections of the subsystems we utilize an mbse process to facilitate this understanding 4 model based systems engineering approach ideally mbse models associated with physical systems are designed in the early stages of a project life cycle this method captures full and accurate physical system information capabilities and design decisions in the model as the project evolves it also permits mbse modeling products to influence the evolving project retrofitting an mbse model to a system that has already been designed and manufactured can be challenging one of the challenges is collecting accurate data about the system requirements and physical components from documented resources those documents may be out of date or located in various locations that may be difficult to access another challenge is attempting to develop an understanding of how and why the system s components interact with each other based on analyzing the final design to counteract these challenges we initiated routine meetings with the vehicle engineers to collect the most current system information to help develop a vehicle cbm based mbse model these discussions are an integral part in the overall process demonstrated in fig 3 indeed they permit the collection and organization of relevant reliability and cost estimating data required for implementing the triage component selection algorithms regardless of whether an mbse model is generated at the start or the finish of its associated physical system s creation the design of an mbse model mainly depends on the nature of the project what the project is trying to achieve what are the expected outputs of the project and the resources available to the project during its life cycle another key aspect of an mbse methodology is ensuring that the method provides a framework for specifying both the structure and operation of the project system and for analyzing its performance additionally the steps taken in designing an mbse model are often written in sequence but many of them are executed in parallel the same is true for the mbse methodology of this project the mbse method chosen for the vehicle digital twin project is a modified version of the methodology described throughout friedenthal et al s well known text on mbse in sysml friedenthal et al 2015 the first step in retroactively applying an mbse methodology is the identification of the core components of the system as a result the core components also constitute the core components of a digital twin if one is implemented enterprise architect e a is the mbse software tool utilized to develop the model sparx systems we chose e a after a detailed trade study on the utility of various sysml implementations we selected e a after determining that it aligns with industry use and supports the infrastructure for mbse model life cycle maintenance an additional feature that assists the automation of our proposed process is e a s support for the xml metadata interchange xmi format this allows us to exchange the model with different mbse software tools it also allows us to easily parse the xmi formatted output for connectivity of the subsystems which for a very large system proves formidable if undertaken by hand the model s package structure defines the organization hierarchy in fig 4 we show this hierarchy the packages in the model are organized based on the artifacts and elements they contain since we are informing the development of a digital twin for a uuv our first step is to develop the requirements for the digital twin these requirements closely track those of the actual system since the twin is a virtual representation of the vehicle real time system according to friedenthal et al the initial phase of establishing requirements is implemented by generating requirements from a project s mission statement or original problem concept that the project is trying to solve or answer the modeling team facilitated the following efforts to obtain the most relevant current requirements communicated with the vehicle s initial designers and stakeholders to retrieve initial project requirements met with the vehicle engineering team to refine the requirements to their current status and generated requirement elements in the vehicle digital twin mbse model in requirements diagrams table 1 shows the requirements gathered retroactively these are shown here as tabular data but are extracted directly from the mbse requirements diagram we do not show the diagram for the sake of clarity by including a requirements diagram in the mbse model we can trace the functionality of the subsystems to the original project requirements and also establish a working set of initial requirements for future dt development the dts constructed will have requirements that closely track those of the original subsystems since for cbm purposes any subsystem that stops functioning as expected will manifest the failure in the requirement an example is a depth sensor shown in fig 5 the depth sensor participates in localization and waypoint navigation if the depth sensor malfunctions then requirements 6 and 11 are no longer met consequently the sensor will no longer deliver depth data to the main vehicle computer which is responsible for higher level planning and waypoint navigation this depth data shown as a red dotted item flow in fig 5 defines an interface that would be monitored through the data driven dt updating the dt s learning model based on expected and actual functionality the structural vehicle block elements in the mbse model represent the physical components of the vehicle we show the entire system composition from the mbse process in fig 5 block definition diagrams bdds represent the physical components of the system next the digital twin cbm physical components are specified in the model this step involved two main phases generating block element representations of the physical components based on vehicle design documentation and adding data and energy flow connectors between appropriate components for both phases the uuv digital twin mbse modeling team communicated with the vehicle engineers to verify and update designated cbm components and connections according to friedenthal et al a key effort in designing systems involves performing various engineering analyses such as trade studies sensitivity analysis and design optimization friedenthal et al 2015 it may include the analysis of performance reliability cost and physical properties of the project system mbse modeling supports these types of analyses via sysml parametric modeling parametric models constrain the properties of a system which can then be evaluated using available analysis tools constraints are expressed as equations with parameters of the equations being bound to the properties of the project s system a parametric diagram within an mbse model can be used to represent one or more engineering analyses of a system s design to incorporate this capability we performed the following designed internal block definition ibds diagrams for vehicle components in the mbse model integrated parametric diagrams to support the ibds and generate sysml relational connectors between them and the ibds using ports implemented constraint equations to govern cbm design of the digital twin version of the vehicle and executed computational evaluations of the cbm design we incorporated parametrics as an auxiliary task to facilitate future reliability computations that can be taken directly from the mbse model 4 1 reliability parametric analysis as a part of the mbse effort we have included parametrics in the vehicle model these parameters constrain the values of model parameters permitting the use of simulation tools to extract relevant model information we utilize parametric analysis to produce a baseline value of the total system reliability to which we compare our extracted reliability taken from connectivity assumptions we utilize the national institute of standards nist definition of reliability which defines reliability as the ability of a system or component to function under stated conditions for a specified period of time ross et al 2019 in the case of a uuv system we apply this definition and define reliability as the ability for the vehicle to operate according to mission requirements for the duration of the mission s operational time the specific tasks enumerated under mission requirements include basic navigational capabilities such as navigating between waypoints ascending and descending and performing routine surface behaviors to establish communications to capture the reliability of the vehicle we utilize input from the system architects and data sheets about estimated subsystem reliabilities unfortunately since the development and expanded use of the vehicle is in its nascency we do not have experimental data from operational missions which is an alternative source of reliability determinations utilizing these values and analyzing subsystem connections we can calculate total system reliability utilizing the well known reliability functions defined by nist tobias 2013 because we are modeling reliability in the normal operating period or intrinsic failure period of the bathtub curve we assume constant failure rates and an exponential distribution of subsystem reliabilities the equation for component i s reliability r i is given as 1 r i t e λ i t where t is the time in hours of operation and λ i is the failure rate of component i the explicit dependence on time indicates that the reliability of the system is not fixed however for the purposes of our work we assume that all reliability estimates are calculated with respect to a constant operation completion time t op to make the conversation more informative we cast 1 in terms of the number of missions n rewriting 1 gives 2 r i n e λ i t op n we then estimate the mean time between failures mtbf in units of number of missions to arrive at reliability estimates for operational mission duration this makes the conversation with operators who aren t necessarily familiar with the exact numbers of failure rates and reliabilities more informative by means of placing failures in context an example would be after how many missions do you the operator need to realign or adjust the waterproof servos on the vehicle if the answer is every 25 missions then if t op 2 hr the failure rate is 1 50 hr 1 yielding a reliability of 3 r t op 2 hr e 1 50 hr 2 hr 0 9231 this simple calculation is a helpful approximation for complex analysis by casting the reliability in units of number of missions the operators and maintainers can inform the discussion much more easily since the burden of the calculation falls on the operations analyst or system analyst the overall reliability of a system depends on the network connections for n components attached in series then the reliability of the subsystem is 4 r series t i n r i t the reliability of the subsystem of components attached in parallel is 5 r parallel t 1 i n 1 r i t the equations assume that the subsystems are statistically independent parallel subsystems typically refers to the same subsystem and indicates redundancy where the failure of the subsystem is mitigated by the redundancy series subsystems define the connection between two different subsystems that are connected via single or multiple data connections the functionality of the different components results in the processing or utilization of the data for different purposes one can think of these connections as an analogy to parallel and series resistors from electronics circuits a series connections permits a current flow along a single path whereas a parallel connection permits the division of current along multiple paths whereas in circuit analysis these connections result from a transmitted current through physical connections the connections of subsystems can be quite different and include any connection and the transfer of any data type in the next section we introduce how we define layered connectivity and how we automatically extract these connections from the output of the mbse process 4 2 extraction of network connectivity a natural result of performing an mbse effort retroactively is the determination of how subsystems are connected to each other necessarily connections can be abstract for example the passage of energy between a battery and a dependent electronic device see fig 5 for an example of energy shown as a blue dotted line passing between the battery and multiple subsystems however abstract if the model is detailed enough to capture these connections then utilizing the output of the mbse we can extract the total system reliability which we use as a primary input in the next section section 5 for performing our optimization of subsystem selection we assume these connections establish the basis for calculating the total reliability as a product over 4 and 5 to extract those connections from the model we assume a layered network topology each layer l i defines how many subsystems are redundant within the layer within a redundant layer we use 5 to calculate the reliability individual layers are assumed to be connected in series this permits fast iteration over the network subsystems and allows us to construct a one dimensional representation of the network we show the layers in fig 6 notice that this permits an arbitrarily complex system to be captured in the one dimensional data structure in fig 6 subsystems are represented by black dots and labeled by s i components s 4 s 7 and s 9 s 12 are in parallel and are redundant subsystems the remaining components are attached in series with the parallel subsystems from this graphical representation which closely mimics the representation one might see within a sysml model we can extract the layer vector l the layer vector is constructed from the cardinality of the subsets attached in series because s 4 7 and s 9 12 are attached in parallel then the l 4 and l 6 vector elements equal 4 written out 6 l 1 1 1 4 1 4 where the number indicates the total number of redundant subsystems the utility of this layer data structure will become apparent when we calculate reliability improvement expectations 5 reliability improvement expectations we have argued thus far that one can utilize the output of the mbse process to represent the underlying subsystem connections as a one dimensional data structure l this in turn can be used to calculate the reliability of the system as a whole since it is a discrete representation of the total system reliability to show how l can be used to calculate the expected reliability improvements as a result of utilizing a digital twin to monitor subsystems we introduce an moop to determine expected reliabilities and cost estimates for implementing digital twins for the uuv subsystems the main objectives we consider are the reliability difference δ r r which is the difference in reliabilities between the base system and the resulting system after implementing digital twins and the total cost c tot which is the cost of implementing all digital twins within the triage subset problem 1 multi objective optimization problem statement for a system comprising n subsystems s s 1 s 2 s n with reliabilities r r 1 r 2 r n digital twin development costs c c 1 c 2 c n and known reliabilities for components with corresponding digital twins r r 1 r 2 r n find binary indicator vectors x r and x c that maximize the reliability difference δ r r r r and minimize total development cost c t o t subject to the constraints that the total number of nonzero elements in both x r and x c does not exceed n the sets which satisfy both objective functions are the pareto optimal sets these provide the corresponding tdt set of components s stated as a bi objective optimization problem 7 minimize x r x δ r r r x r r 8 minimize x c x c tot x c t c 9 subject to x 0 1 n 10 x r t x r n 11 x c t x c n note that to facilitate ease of computation we have utilized the duality principle in optimization to convert the maximization of reliability improvement function to a minimization by multiplying by 1 the objective function given by 7 represents the difference in reliability improvements where the decision variable is given by x r the function r yields the system reliability as a result of switching out the candidate set of components x r t the value r represents the total system reliability before improvements this is calculated either from the mbse model using the parametric diagrams or from the connectivity vector l in theory 7 should be negative for every subset x r assuming that the digital twins are designed properly and function no worse than the real time system this is a reasonable assumption since the digital twins are engineered by a team of experts typically those with data science or machine learning backgrounds and those with hardware and software expertise in the component area the variable c is a vector equivalent of the set of implementation costs c 5 1 numerical approximation methods we compare two optimization methods these are chosen partially out of convenience and for illustrative purposes we emphasize that the methods introduced here are not novel or in anyway prescriptive any method that solves problem 1 suffices for producing the tdt subsets the first is a direct computation of the subsets since the number of subsystem components is reasonably small that employing a direct method of computation is feasible similar to the method employed by custódio et al 2011 this direct calculation iterates over the entire component space which for a practical standpoint for a uuv is not unreasonable however if the number of components grows sufficiently large n 20 then more efficient methods must be considered such as gray code methods savage 1997 or evolutionary algorithms the direct computation method is shown in the procedure bruteforceoptimization in algorithm 1 we show this method and its auxiliary procedures to calculate all candidate subsets of reliabilities and costs though we do not provide the pseudocode for the procedure allcombinations it is a relatively simple combinatorial task to generate all possible combinations since one can use the binomial coefficient n k as a starting point producing up to k n 1 combinations to satisfy 10 and 11 once all possible combinations of subsystem reliabilities and costs are generated then we use objective to return the total system reliability as a result of utilizing digital twins r the objective procedure closely follows 7 in that it utilizes the connectivity information provided by l to determine how subsystems and components should be treated as in series or parallel once all possible combinations of reliability improvements and costs are calculated they are stored in δ and c tot respectively the keen observer will note that this optimization routine has generated the entire feasible region of the problem to identify only those non dominated or pareto solutions we utilize an additional procedure generateparetofront shown in algorithm 3 the algorithm works by sorting in ascending order the c tot and δ vectors from these we iterate in ascending order recording at each step if the reliability difference δ i is less than at least one point already sampled this produces the non dominated point set the second method we use is the genetic algorithm based normal boundary intersection ganbi method the ganbi method is particularly well suited for engineering design problems because unlike a standard evolutionary algorithm which produces a solution set at each iteration the ganbi algorithm produces a solution that approximates the pareto front at each iteration wettergren 2006 the ganbi algorithm serves as a preprocessor for existing genetic algorithms we utilize the non dominated sorting genetic algorithm nsga as the baseline algorithm for which we use the ganbi preprocessor the interested reader should consult the work of wettergren for a detailed account of the ganbi algorithm including a formal algorithm description of the approximation step wettergren 2006 note that we are comparing the ganbi algorithm to the direct computation to show that for a small system with n 10 components the methods direct and evolutionary are equivalent we also introduce the ganbi algorithm to allow an extension of this work for very large systems with complex connection layers indeed we rely on this method for our real world case study which we compare to the well known nsga we show the pseudocode of the ganbi algorithm in ganbi of algorithm 4 the key distinction between the ganbi algorithm and traditional evolutionary approaches is shown at line 2 in the procedure individualmaxima the ganbi algorithm relies on the calculation of the minima for the individual objective functions without regard to the other objectives if x 1 denotes the minimum of δ and x 2 denotes the minimum of c tot then 12 x x 1 x 2 is the vector that contains the minima for the reliability improvement and total cost objectives correspondingly we can write the matrix f min as 13 f min 0 δ x 2 δ x 1 c tot x 1 c tot x 2 0 this connects the individual minima through the line segment defined by the difference of points the convex hull of individual minima or chim from wettergren s work is given by convex combinations of 13 these are given by 14 chim f min b x b b 1 b 2 t 15 i b i 1 b i 0 the chim provides a coarse approximation to the pareto front produced by the reliability difference and total cost objectives the purpose of this is the creation of supporting objectives f given by nbiobjective the supporting objectives divide the hull into n pts which approximate the vector set normal to the points along the line segment connecting the two minima effectively this creates a point set that can be pushed out normal to the segment and eventually meet the pareto front of the bi objective problem creating the supporting objective functions actually increases computational time but it provides a better approximation to the pareto front than evolutionary approaches without the preprocessing these modified objective functions are then passed into the traditional nsga procedure for which we have declared the procedures but not the implementation of the code these are shown as nextgen and evalpop in algorithm 4 we once again call generateparetofront line 8 to do a final sort on the pareto frontier algorithm 1 direct computation of reliability difference image 1 algorithm 2 reliability from layer connectivity image 2 algorithm 3 producing pareto front from objectives image 3 algorithm 4 ganbi algorithm image 4 5 2 approximation results for example system before we consider the vehicle in our case study it is instructive to utilize our notional system of n 12 components to demonstrate how the algorithms perform understanding the results of the algorithms and placing into context the results as they apply to selecting the tdts and informing decision makers about the trade offs the first step is the enumeration of existing subsystem reliabilities r reliabilities after implementing digital twins r and the estimated cost to implement a digital twin c these are summarized in table 2 to simulate a realistic scenario we have created a randomized set of r where some components are noticeably worse or unreliable in comparison with others as much as an order of magnitude worse the upgraded reliabilities are also randomized these however are randomized within r i 1 0 where r i r this enforces the assumption that the reliability after implementing a digital twin can be no worse than the original the implementation costs are also randomized within the range 500 5000 with arbitrary units the connectivity of the subsystems is given by 6 using these inputs to the bruteforceoptimization we generate the pareto front in fig 7 a as well as show the entire feasible solution space the black star markers indicate the pareto solutions and the black dots indicate a dominated feasible solution the vertical axis represents the percentage increase in reliability as a result of implementing the tdts the abnormally large increases result from markedly improved reliabilities for the exceptionally unreliable subsystems the total system reliability before upgrades is r 0 029 the vertical axis is the scaled version of the objective function 7 or 16 δ r r r 100 we have also plotted on the same axes the pareto front and the feasible solution space for the ganbi and nsga methods which are not required for this simplistic example of n 12 components the feasible space for the ganbi algorithm is shown by the blue crosses the pareto front for the ganbi algorithm is shown by the blue squares the nsga feasible space is shown by red diamonds while the pareto front is shown by the red squares we have used n gen 500 generations in both the ganbi and nsga methods and a population size of n pop 50 for the example system after several numerical runs we determined that neither larger populations nor more generations improved the pareto frontier approximation however by plotting the ganbi algorithm it illustrates that we can approximate the pareto front reasonably well the benefit of using the evolutionary method comes when one considers complex systems with n 20 where it is computationally challenging if not impossible to iterate over all possible combinations of subsystems therefore the ganbi algorithm can be used for these larger complex systems in fig 7a c we have plotted the pareto fronts from the direct ganbi and nsga methods in fig 7d we have also extracted two example subsets s a and s b from the pareto front to show the trade off between reliability improvement and cost note that s a 1 3 8 has a total cost of c tot 6691 arb unit while s b 1 2 3 4 8 9 10 11 12 has a total cost of c tot 26862 arb unit as expected the more components that are selected for digital twin monitoring the higher the reliability improvement and the higher the cost as a result a large part of the process is prioritizing reliability vs cost for critical projects that remove humans from harm no expense should be spared when considering the reliability improvement whereas a project that does rely on the system for critical tasking but does not depend on the system for delivering humans from harm should expect to have reduced development costs while achieving significant reliability improvements 5 3 approximation results for unmanned underwater vehicle now we consider the vehicle in our case study we show the initial reliabilities and improvements based on discussions from the uuv maintainers and operators these values are shown in table 3 below we show the resulting optimization and extraction of candidate tdts s in fig 8 in fig 8a we have plotted the pareto frontier from the ganbi algorithm shown as blue squares as well as the nsga method shown as red circles we have not utilized the direct computation since the system of n 17 components is sufficiently complex that the feasible space is too large to calculate directly we have also extracted three candidate tdt subsets shown as points a b and c these are summarized in table 4 the initial system reliability calculated from r is 0 43 this comes from using a series connected l vector with 17 components since the vehicle is a minimalist uuv there are no redundant components and therefore the total system reliability depends on the individual subsystems as in 4 this initial reliability indicates a failure rate of λ 0 42 hr 1 calculated using t o p 2 hr this gives a mtbf of 2 37 hr or roughly after every mission some component stops functioning as expected using this number we are able to calculate expected system reliabilities for the subsets s a s b and s c shown in table 4 while these subsets are selected at random they raise key questions that need to be answered by continued discussions with decision makers first there is a 750 000 arb unit cost difference between options a and b with a 20 difference in total system reliability does the reliability improvement merit the additional cost burden should option c be prioritized for its simplicity and low cost at this point it is natural to address these questions using higher level information provided by discussions with decision makers without the added information strictly these options are all equivalent something to consider is the aforementioned maintainability of these components which of these is far more challenging to maintain requiring significant downtime the components that present the longest downtimes and appear in the tdt candidate subsets could be prioritized since the maintenance could be scheduled when the vehicle is not required for operations if the uuv is selected for deep water drilling platform inspections then the reliability improvement is likely a significant factor due to the inherent risk of having people perform this job if the uuv is used for shallow water oceanographic surveys then the reliability is likely not as an important factor as the implementation cost and option c will prevail we also show how often each component appears in a tdt candidate subset in fig 8b the histogram shows that there are some differences between the ganbi and the nsga methods used here nevertheless there are standout components that appear consistently more often note that s 7 9 and 12 appear more often this is expected since these have the lower initial reliabilities these are also the components that require maintenance most often according to the vehicle maintainers as a result these components are natural candidates for tdt monitoring equipped with these subsets the conversation with decision makers will be more directed and productive since the selection of the tdt subsets is bolstered by inputs from multiple stakeholders and team members all of whom contribute in a meaningful way guiding the selection process with relevant information moreover the mbse effort establishes the necessary data acquisition interfaces and physical interfaces that directly influence the implementation of dts once a tdt subset is downselected from the candidates this shortens the design and development timeline since at a minimum subject matter experts or those responsible for dt development will have requirements established 5 4 numerical performance comparison for both the example system and the uuv system data analyzed in subsections 5 2 and 5 3 the direct computation nsga and ganbi methods were performed using custom code developed in matlab r2013a on a computer running windows 10 with 8 gb ram and two intel core i5 4200m cpus 2 50 ghz matlab 2013 using a n 12 and n 17 system as a benchmark case with randomly generated reliabilities r 0 50 1 and costs c 100 10 10 3 arb unit we show averaged computation times for the three methods in table 5 based on 10 individual runs of each algorithm the table also contains computational complexities for the three algorithms based on n subsystems according to curry and dagli the nsga algorithm is o n o n pop 3 where n o is the number of objective functions in this case there are two objective functions indicating that the complexity is o 2 n pop 3 the ganbi algorithm is a preprocessor for the nsga so its complexity is that of the nsga plus a term that accounts for the additional helper objective functions n pts 2 n pop 3 the leading order in the large population size limit is n pts n pop 3 the distinction must be made that although the ganbi method requires additional steps to compute the supporting objectives it gives a better approximation to the true pareto front of the moop the direct method requires the computation of all possible combinations of subsystems which strictly is 2 n 1 accounting for the constraint that not all subsystems can be selected this term is dominated by 2 n so we can neglect the 1 this is done for every objective every objective is then compared with every other objective for small values of n n pop it is clear that the direct method is far better than the evolutionary algorithms since the complexity scales with cubic population size the values shown in table 5 are for a notional subsystem with n 7 n 12 and n 17 subsystems we have argued thus far that for a small number of subsystems n 10 the direct method is the most efficient whereas for a large number of subsystems n 20 evolutionary algorithms such as the nsga and the nsga with ganbi are the most efficient the keen observer will note that the computational times shown in the table suggest that the direct method is fast even as the number of subsystems exceeds the lower limit in fact it would seem that the direct method is an order of magnitude faster than the times of the evolutionary algorithms for the n 12 case this directly contradicts the complexities shown in the table as well since a simple calculation for the n 12 case yields o 10 11 for the direct method and o 10 5 and o 10 6 for nsga and ganbi respectively this is because of two primary factors first the direct method computes all combinations of costs and reliabilities which for n 12 is 4095 different combinations accounting for the constraints this is it essentially since a simple comparison is performed to determine the non dominated solutions second the evolutionary algorithms on the other hand must initialize a random population of chromosomes using n pop 50 with length n evaluate fitness reproduce crossover mutate and reevaluate for n gen 500 generations assuming the three algorithms have been programmed to a similar level of efficiency then the evolutionary algorithms take longer from a computational perspective simply because of the number of steps involved it is therefore more appropriate to utilize computational complexity in the large n limit and recognize that for a small number of subsystems the direct method is more efficient because of how few steps there are programmatically 6 discussion we have introduced a generalizable process for determining the subset of components from a sos that when monitored through digital twins yield the maximal increase in total system reliability and minimize the cost entrance hurdle for implementing the digital twins we have utilized our process on a real life application for an unmanned underwater vehicle through a combination of experimentally derived system reliabilities and an mbse effort where numerous discussions were held with the vehicle development team we have been able to demonstrate the applicability of this relatively simple approach to tdt selection the implications for the industry of unmanned underwater vehicles are that through the process developed in the paper groups that rely on uuvs for critical tasking which would otherwise place humans in direct harm can use the process for retroactively developing digital twins to increase system reliability while staying within budgetary constraints our process considers input from a variety of stakeholders and system users to ensure that the most accurate information is solicited for inclusion in the process we have not introduced variables data or parameters that are not readily available or those that would not be determined regardless of the tdt selection process the system reliabilities r are usually well known from experimental test data component data sheets or can be determined from like system analysis the reliabilities as a result of utilizing a twin to monitor the corresponding component r can be estimated based on a decrease in failure rates and discussions with subject matter experts responsible for implementing the digital twin the project management team in collaboration with the subject matter experts can provide cost estimates c for developing digital twins for the subsystems based on known parameters such as labor rates auxiliary software and it costs and historical development and testing timelines these parameters and the outputs of the connectivity analysis from the mbse suffice to perform a selection process on the subsystems to be monitored as we have shown higher level information is required to prioritize the subset of tdts s that are selected as the requisite systems for implementing digital twins such as budgetary constraints or reliability requirements the implications for the field of reliability studies are a generalizable process that is straightforward to utilize for a variety of systems that would like to leverage digital twin technology for enhancing reliability of legacy systems our process is particularly well suited for those who do not know which components to select for digital twin monitoring must rely on legacy systems for critical tasking and do not have the budget to design develop test and deploy complete digital twins for their systems credit authorship contribution statement demetrious t kutzke conceptualization methodology investigation writing original draft writing review editing james b carter methodology investigation writing original draft benjamin t hartman software formal analysis writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank the entire vehicle development team at nswc pcd for informing the modeling process and the continued support they have provided through numerous discussions and meetings the authors would like especially to thank m mcbain who was instrumental in determining the appropriate reliability estimates based on her experience as both an operator and maintainer of the vehicles finally the authors are indebted to dr patrick walters the system architect who designed the vehicle and provided the experimental system on which the paper is based this work has been supported by the nswc pcd naval innovative science and engineering nise program 
20999,digital twins are virtual representations of subsystems within a system of systems they can be utilized to model and predict performance and condition degradation throughout a system s life cycle condition based maintenance or the performance of system maintenance based on the subsystem states is often facilitated by the implementation of digital twins an open challenge is selecting the subsystems that require digital twins we establish a generic process for determining a set of priority based system components requiring digital twin development for condition based maintenance purposes the priority set which we term the triage set represents the set of components that when monitored through a digital twin lead to the greatest increase in total system reliability and simultaneously represent the minimal cost set of components for implementing a digital twin while we focus our process on an unmanned underwater vehicle uuv where we frame the design problem as a multiobjective optimization problem utilizing experimentally determined data and metrics from the model of a real uuv system the process is generic enough that it could be utilized by any system looking at cost and reliability estimates for leveraging digital twin technology keywords digital twin multiobjective optimization pareto optimization reliability nomenclature cbm condition based maintenance dt digital twin ganbi genetic algorithm based normal boundary intersection mbse model based systems engineering moop multiobjective optimization problem sos system of systems tdt triage digital twin uuv unmanned underwater vehicle f min convex hull of individual minima for moop δ r r reliability improvement function c set of known design and development costs for digital twins of subsystems r set of known reliabilities of subsystem components r known reliabilities for components with corresponding digital twin c tot total digital twin implementation cost n gen number of generations in evolutionary algorithm n pop size of population in evolutionary algorithm n pts number of points segmenting line connecting individual minima l vector of component layer information n total number of system components r pareto optimal subset of component reliabilities s triage digital twin components 1 introduction we explore the interplay between total system reliability and the development cost for building a digital twin for an sos industries that depend on complex sos for accomplishing hazardous or laborious tasks that would otherwise place humans in harm require reliable and robust sos that function expectedly medical robotics the airline and automotive industries and smart manufacturing facilities are a few examples of sos that perform tasks to mitigate the risk to the human often digital twins a term first coined by michael grieves facilitate this reliability and enhance the robustness by providing sos operators and maintainers with additional system awareness grieves 2005 daneshmand et al 2017 kousi et al 2019 tao et al 2019a digital twins are virtual representations that mimic the subsystems and dynamics of their real time counterparts digital twins have proliferated in use because of their predictive capacity for the degradation of their real time systems and are now a central part of product life cycle management grieves and vickers 2017 however many legacy sos still rely on traditional methods of reliability management to mitigate risks through a variety of maintenance strategies including preventative reactive and condition based maintenance preventative maintenance entails performing routine maintenance tasks on a fixed schedule swanson 2001 this can lead to significant waste of labor since component failures typically occur as a result of the condition of parts endrenyi et al 2001 if the condition of the part to be replaced has not yet degraded to the point of failure then the replacement part is wasted as is the labor to replace the part reactive maintenance means performing maintenance based on events such as the failure or degradation of a mechanical part to the extent that it is non functional karuppuswamy et al 2006 while the typical maintenance schedule of an sos includes a combination of both preventative and reactive maintenance alternative methods are used throughout the airline automotive and other commercial industries that observe the condition of components to trigger maintenance tasks li and nilkitsaranont 2009 prajapati et al 2012 zou et al 2019 this condition based maintenance provides an opportunity to reduce labor and parts costs since fewer parts are wasted and labor is optimized on an as needed basis visual inspection can provide some degree of accuracy in assessing the condition of certain external components for example the tread on a tire of an automobile horner et al 1997 a newer approach offers more disciplined and less ambiguous condition assessments this is condition based maintenance through the use of a digital twin to minimize the need for visual inspection digital twins are utilized to monitor the condition of components in critical systems like jet engines fuel pumps and robotics for example digital twins have taken a leading role in advancing manufacturing and complex sos throughout the industry 4 0 movement and the proliferation of the internet of things kusiak 2017 fuller et al 2020 koulamas and kalogeras 2018 given the widespread adaptation and integration of multiple data sources throughout a system s lifecycle including sensor performance testing and evaluation and maintenance data for example numerous technologies among which the digital twin belongs integrate and aggregate these data sources into a uniform picture of a system s state qi and tao 2018 tao et al provide a detailed account and survey of digital twin technology including numerous examples from industry that illuminate the utility of digital twins for predicting condition degradation within a sos tao et al 2019b notably tao et al outline how general electric ge has implemented digital twins for their wind turbine systems lund et al 2018a 2018b the total digital twin system constitutes the sensor network by which the physical wind turbines are connected and the network connection to the cloud based turbine model the cloud models are constantly updated with performance data collected across the physical system network the feedback from the cloud model can then be utilized in turn as an optimized controller for the wind turbines creating an optimized feedback loop facilitated by the so called smart connectivity ge s digital twin model emphasizes a general standard that defines a digital twin system there is a physical system a virtual system and connection between the virtual and physical system glaessgen and stargel 2012 another interesting example is the development of a digital twin for a robotic surgery system laaki et al 2019 while laaki et al utilize a robotic arm as a substitute for a real time system they mention the da vinci surgical system manufactured by intuitive surgical inc as a suitable candidate that would benefit from the digital twin boeing has begun utilizing its in house developed discrete event simulation model which incorporates material procurement data and manufacturing automation performance data by using this data and the simulation tool boeing has an end to end supply chain model for its manufacturing businesses together these represent the digital twin hilton and needham 2019 siemens the german manufacturer utilizes numerous digital twin models for its production processes this underscores the key idea behind digital twins there is not one digital twin that governs or represents an entire system rather a digital twin comprises numerous distinct and potentially different models based on the function of the individual subsystems in siemens case they utilize finite element models for stress and strain digital twins in their production line tao and qi 2019 for further examples taken from industry see liu et al 2020 for this paper we choose the unmanned underwater vehicle for a case study since there is a growing dependence on these systems from a variety of industries that directly remove humans from harm as a result of leveraging uuv technology uuvs or autonomous underwater vehicles auvs have witnessed significant growth in their utility for a variety of industries including sea floor and oceanographic surveys deep water drilling platform inspections ship hull inspections bridge maintenance and surveys and various academic uses hylton 2020 whitcomb 2000 fletcher 2000 mcfarlane 2008 fletcher and wernli 2003 miller 1996 kukulya et al 2010 the wide adaptation and continued use of uuvs indicates a high level of dependence on these platforms for critical tasking tasking which would otherwise place humans in direct risk of harm thieme and utne 2017 this dependence largely requires reliable and available systems that can be expected to function according to specifications runtime mission failures present potentially catastrophic consequences for the operators while presenting a challenging task to mitigate these risks for the uuv maintainers a uuv presents a very challenging task for traditional maintenance strategies and cbm through visual inspection since access to internal components is limited or requires significant effort to inspect the internal components are housed inside either a free flooded the hull floods with water for buoyancy control or a hermetically sealed hull the hull is both air and water tight to access the components housed inside the sealed hull requires breaking the seal and accessing the components in a confined space external components can be inspected for wear and condition degradation but these are also challenging since functionality can be degraded without visual cues these challenges can largely be subverted by the use of digital twins for cbm purposes the twin is a digital replica that maintains data and dynamics information in parallel with the real time system building a twin typically involves selecting a data or dynamics driven model for every individual component liu et al 2012 coraddu et al 2019 kim et al 2020 data driven models rely on historical system data for training machine learning models dynamics driven models utilize first principles and physics based modeling for creating models that are data independent the particular methodology depends on the intended use for example a data driven model which utilizes a machine learning process is particularly suited for predicting component degradation hong et al demonstrate the use of one such technique a special ordered map which through unsupervised machine learning they train to extract degradation of ball bearings hong et al 2014 alternative methods have been used which provide performance estimations under unknown conditions these dynamics driven approaches offer higher degrees of predictability than their data driven counterparts since they model time based dynamics these too update model parameters from the real time system but do not depend on historical performance data for their predictive capacity hanachi et al derive a physics based model for capturing the performance of gas turbine engines with applications in the airline industry hanachi et al 2015 their work demonstrates one instance of the applicability of a model based approach for predictive capacity others have developed novel techniques that give hybrid performance lei et al use a model based approach for remaining useful life rul predictions for which they provide experimental evidence demonstrating the method s efficacy on ball bearings the challenge with leveraging data driven models is the necessity for copious amounts of high quality data for the airline and automotive industries which typically have experimental apparatus in place it is decidedly easier to produce the data for predictive maintenance models however for systems like uuvs the presence of high quality data is generally lacking since it is challenging to extract failure mode data from these systems when failures occur at run time and below the sea surface there are two primary mechanisms for handling this case machine learning algorithms that handle limited training data and better experimental apparatus alternative machine learning models exist to leverage digital twin technology without the use of high quality or properly labeled data the work of tan et al demonstrates the use of one such technique to predict condition degradation of a ship s propulsion system without properly labeled data sets tan et al 2019 2020 alternative test setups can be fashioned to run repeated experimental tests to extract relevant performance data under typical operational mission profiles see fig 1 for an example experimental setup in the figure an oscilloscope is connected to the uuv while the uuv s autonomy computer is running in order to collect sensory signal data on the workbench user interface components are connected directly to the autonomy computer to manipulate simulation characteristics on the bench the uuv shown in the figure is the system we consider for the case study in this paper section 3 provides a detailed overview of the system even these setups lack in realistic simulation since external failures can occur from the uuv hitting something in the water or during docking and deploying the uuv from a ship the repeated insertion and extraction deploying and docking of the uuv can create significant wear on the system because many of the external components are very sensitive such as the fins and propeller to accurately represent these mechanical failures is challenging in a benchtop environment the apparatus shown in fig 1 is only capable of testing the electronic components and as such falls short at capturing the entirety of the potential failure modes here we are not considering the particular model type only that some model will be selected to serve as the twin we do make the distinction that the digital twin for an entire system comprises any number of individual digital twins for the subsystems being monitored each subsystem has its own model requirements data or dynamics driven and has its own requirements for data acquisition and physical interfaces data acquisition establishes the means by which the twin acquires data from the real time subsystem this could be through client server style resources as in the robot operating system ros or exchanging data through some other means via ethernet for example stanford artificial intelligence laboratory et al physical interfaces indicate the required ports to facilitate the data acquisition process these could be any physical connection such as universal serial bus usb ethernet or other serial port connections there are two pathways to leveraging digital twin technology for cbm purposes first the system designer can build a twin for each component incorporating the necessary data and physical interfaces into the system design second the system can be retrofitted with the information acquisition resources data and physical interfaces to extract the relevant information to support the twin the former requires a significant amount of design effort since the system designer must meet the standard system specifications and requirements as well as incorporate the acquisition resources for the digital twin for the relevant components the second pathway provides a means for retrofitting the system with digital twins it also provides attachability meaning legacy systems that are critical for removing humans from direct harm can still benefit from digital twin technology the second also has the advantage of an established perhaps inefficient maintenance schedule that can be optimized from the incorporation of digital twins for cbm purposes however the questions unanswered from the perspective of decision makers and developers alike remain what components should have digital twins how should the system be retrofitted with the data acquisition resources for the digital twins we address the cost issue associated with incorporating a digital twin by developing a novel approach that incorporates both mbse and multiobjective optimization to enable the selection of appropriate components for digital twin representation these triage components produce the largest increase in total system reliability and minimize the cost entrance hurdle for leveraging digital twin technology we utilize the term triage to reflect the fact that some components are prioritized over others much like the triage process utilized during disaster relief by first responders prioritization of limited medical treatment resources optimizes the care given ensuring that those who qualify and meet the selection criteria receive treatment first koenig and schultz 2010 though the criteria change based on the triage system used the idea remains the same those who benefit most from treatment receive priority over those who would benefit the least such as someone with significant blood loss over someone with a minor cut likewise certain subsystems yield larger and more significant benefits to total system reliability than other subsystems the paper is organized as follows in section 2 we explore established research for reliability predictions redundancy allocation and reliability optimization in section 3 we introduce the platform used for modeling a minimalist uuv system as well as a basic description of the vehicle and additional reference data in section 4 we introduce our mbse approach including the language and modeling used to develop the model for the uuv system as well as challenges in implementing mbse retroactively in section 5 we explain in detail the reliability analysis and demonstrate results from applying our process to the uuv under test we conclude the case study in section 6 by commenting on the implications of the case study for the field of uuvs and how the work can be used to inform the tdt design process we address the implications on the work for the field of reliability studies and how the process generalizes for arbitrary sos looking at implementing a tdt 2 related work much of the existing literature in the fields of redundancy allocation and reliability predictions offer technically rigorous mechanisms for improving sos reliabilities through the introduction of redundant components and sophisticated methods for predicting and optimizing sos reliability as a result these methods provide a breadth of established research that can be used for a variety of sos our contribution is a coupling of an mbse approach and an moop providing a simplified process that incorporates data from a variety of stakeholders system maintainers and operators to guide the reliability improvement analysis and frame the discussion with decision makers by providing candidate subsets for tdt implementation our specific contributions are as follows a novel methodology to prioritize and select a triage set of subsystems that comprise the digital twin of the total system an mbse approach that elucidates the necessary data acquisition and physical interfaces that must be established for future digital twin development a reliability analysis based on the application of our methodology to a case study on a uuv qualitative analysis of the implications of our methodology on the development of next generation unmanned systems on the tdt design process we will now discuss the state of the art in digital twin development and reliability improvements for sos and how they are augmented by our methodology biggs et al introduce the contemporary challenges in utilizing sysml as the primary mbse language to include reliability considerations in an mbse effort early in a project s life cycle biggs et al 2018 they advocate for the inclusion of new language concepts that extend sysml to better model reliability requirements than are currently possible at the time of this authorship we are not aware of the inclusion of these concepts in the sysml standard their work is notable because they address several issues that we have encountered including the tracking of reliability and safety data across different documents and spreadsheets these are challenging to maintain and often the critical information is lost to mitigate this challenge we capture reliability data directly in the mbse model as we conduct discussions with the system maintainers and architects this information is tracked and can be updated as the model is updated throughout its life cycle additional techniques are utilizing the central structure that mbse provides for conducting failure modes and effects analysis fmea huang et al 2017 our choice in using mbse for modeling complex sos is supported by the use and acceptance of several organizations d ambrosio and soremekun 2017 mitchell 2010 given the complexity of many sos mbse is gaining traction across organizations that would like to simplify system life cycle maintenance since it unifies many traditionally disparate data sources and documents into one accessible and traceable location several strategies are used to improve system reliability one such strategy is the introduction of redundant components by introducing redundant components or backups the failure of the component is mitigated by these alternates indeed this is an integral part of robust system design and the topic of numerous papers on designing for reliability rochlin et al 1987 kim and kim 2017 muhuri et al 2018 an example is the electronic flight data recorder or black box used in commercial airplanes the electronic flight data recorder tracks and records flight data and system diagnostics it is recovered after airplane crashes and used to provide investigators with vital system information leading to the failure and crash the data recorder is often installed with a redundant data recorder to improve the chances of finding the device in a crash and to improve the reliability downer 2011 a challenging problem is determining how many redundant components should be used to achieve a desired level of reliability this is the redundancy allocation problem for parallel subsystems coit and smith introduce a genetic algorithm for the redundancy allocation problem in parallel subsystems coit and smith 1996 the genetic algorithm of coit and smith scales well for large systems and offers a unique formulation for determining redundancy levels and searching the component trade space as a consequence they can quickly identify the level of redundancy required to achieve a stated level of reliability within cost constraints our work seeks a similar calculation except that we are not considering parallel subsystems exclusively and we do not have reliability requirements muhuri et al provide a detailed approach to the redundancy allocation problem they go beyond the work of coit and smith by accommodating traditionally challenging trade space parameters such as physical dimensions and weight of redundant components through fuzzy parameters in their optimization routine the challenge with such an approach is utilizing this retroactively while this is an excellent approach when utilized early in the design phase of a system existing components are largely fixed and the system has been optimized to accommodate those components fundamentally the reliability can only be changed through a more intelligent maintenance routine such as a cbm approach yeh and fiondella expound in great detail on a redundancy allocation application in computer networks yeh and fiondella 2017 they utilize a simulated annealing algorithm to solve the allocation problem garg and sharma perform a strikingly similar analysis as our work they utilize a particle swarm optimization algorithm to solve their moop which is a bi objective problem maximizing reliability improvement from the introduction of redundant components they also minimize system design cost garg and sharma 2013 we also optimize for a reliability difference which is the difference between the base system and the new proposed system with digital twins for cbm purposes the work is distinct in that they minimize the cost for adding the redundant components whereas our work considers selecting candidate subsets that minimize tdt implementation costs there have been significant advances in reliability predictions for complex systems in recent years as of 2018 yuan et al introduced a statistical mechanism for reliability evaluation yuan et al 2018 using bayesian networks bn they construct object oriented representations of subsystems which they utilize to construct a bn for propagating uncertainties about component conditions these dynamic object oriented bayesian networks doobns facilitate ease of modeling since the connections between subsystems are concise and built from conversations between the modelers and the domain experts kumar et al show using fuzzy set logic a method for computing reliability of series parallel systems kumar et al 2020 in their survey pérez rosés outlines numerous other mechanisms that exist for reliability optimization and redundancy allocations on complex systems and over series parallel networks pérez rosés 2018 3 unmanned underwater vehicle for case study in fig 2 we show the low cost vehicle with subsystem labels and components we have chosen this vehicle as our case study system for two reasons first we have direct access to design specifications bill of materials and the system architects second the system provides a baseline representation of a uuv without the added components and complexity of legacy commercial off the shelf systems the experimental vehicle offers the minimal set of functioning components as a result the systems engineering process is simplified to complete retroactively we acknowledge that for a more complex system this process would not be as straightforward particularly since access to the original architects or maintainers may be severely limited we argue those who perform routine maintenance can provide insight into the design and the components that are the most challenging to maintain the system operators are also an excellent resource since they have a better idea of how the system functions under normal or expected operating conditions which helps inform the triage component selection process the output of the process in this paper guarantees subsets of components maximizing reliability and minimizing digital twin development cost but it does not say whether these components are the most challenging to maintain cost does not necessarily imply difficulty of maintenance if the component is challenging to reach such as an electronics component in the interior of the hull but is low cost like a resistor this would be a component that is hard to maintain but low unit cost while we concede that there is generally a labor cost associated with performing maintenance here we do not consider this we do not address maintainability directly in this work but it should be considered during the discussion phase with decision makers future work will address maintainability in a more rigorous fashion by including a maintainability metric in the objective set in section 6 we discuss the use of this and other higher level information which can be used to scale the optimal subsets of components provided by the moop in our process the vehicle comprises 17 main subsystems here we do not make a distinction between a subsystem and a component for a minimalist system like the vehicle these can be used interchangeably the components listed in fig 2 represent subsystems supporting communication between the vehicle and the operators navigation and intelligence the communication subsystems are the acoustic modem transducer acoustic modem electronics and comms antenna contained in the handle the navigation components are the passive sonar array inertial measurement unit satellite navigation velocity sensor and depth sensor the intelligence subsystems support the higher level vehicle control including path planning ascending descending and waypoint navigation the primary intelligence is provided by the vehicle computer and electronics all of these subsystems depend on the energy source provided by the batteries the components are assembled in the external housing which is composed of the nose cone front bulkhead mid section rear bulkhead o rings and tail cone the propeller and fins provide propulsion and control respectively the only subsystem we refer to that is not shown in fig 2 is the propeller shroud which is concentric with the propeller and shields the propeller from any damage together these subsystems constitute a minimalist uuv and provide the ideal experimental apparatus to test our decision process on selecting triage component sets for implementing digital twins however to understand the process for determining the triage components we must first understand the connections of the subsystems we utilize an mbse process to facilitate this understanding 4 model based systems engineering approach ideally mbse models associated with physical systems are designed in the early stages of a project life cycle this method captures full and accurate physical system information capabilities and design decisions in the model as the project evolves it also permits mbse modeling products to influence the evolving project retrofitting an mbse model to a system that has already been designed and manufactured can be challenging one of the challenges is collecting accurate data about the system requirements and physical components from documented resources those documents may be out of date or located in various locations that may be difficult to access another challenge is attempting to develop an understanding of how and why the system s components interact with each other based on analyzing the final design to counteract these challenges we initiated routine meetings with the vehicle engineers to collect the most current system information to help develop a vehicle cbm based mbse model these discussions are an integral part in the overall process demonstrated in fig 3 indeed they permit the collection and organization of relevant reliability and cost estimating data required for implementing the triage component selection algorithms regardless of whether an mbse model is generated at the start or the finish of its associated physical system s creation the design of an mbse model mainly depends on the nature of the project what the project is trying to achieve what are the expected outputs of the project and the resources available to the project during its life cycle another key aspect of an mbse methodology is ensuring that the method provides a framework for specifying both the structure and operation of the project system and for analyzing its performance additionally the steps taken in designing an mbse model are often written in sequence but many of them are executed in parallel the same is true for the mbse methodology of this project the mbse method chosen for the vehicle digital twin project is a modified version of the methodology described throughout friedenthal et al s well known text on mbse in sysml friedenthal et al 2015 the first step in retroactively applying an mbse methodology is the identification of the core components of the system as a result the core components also constitute the core components of a digital twin if one is implemented enterprise architect e a is the mbse software tool utilized to develop the model sparx systems we chose e a after a detailed trade study on the utility of various sysml implementations we selected e a after determining that it aligns with industry use and supports the infrastructure for mbse model life cycle maintenance an additional feature that assists the automation of our proposed process is e a s support for the xml metadata interchange xmi format this allows us to exchange the model with different mbse software tools it also allows us to easily parse the xmi formatted output for connectivity of the subsystems which for a very large system proves formidable if undertaken by hand the model s package structure defines the organization hierarchy in fig 4 we show this hierarchy the packages in the model are organized based on the artifacts and elements they contain since we are informing the development of a digital twin for a uuv our first step is to develop the requirements for the digital twin these requirements closely track those of the actual system since the twin is a virtual representation of the vehicle real time system according to friedenthal et al the initial phase of establishing requirements is implemented by generating requirements from a project s mission statement or original problem concept that the project is trying to solve or answer the modeling team facilitated the following efforts to obtain the most relevant current requirements communicated with the vehicle s initial designers and stakeholders to retrieve initial project requirements met with the vehicle engineering team to refine the requirements to their current status and generated requirement elements in the vehicle digital twin mbse model in requirements diagrams table 1 shows the requirements gathered retroactively these are shown here as tabular data but are extracted directly from the mbse requirements diagram we do not show the diagram for the sake of clarity by including a requirements diagram in the mbse model we can trace the functionality of the subsystems to the original project requirements and also establish a working set of initial requirements for future dt development the dts constructed will have requirements that closely track those of the original subsystems since for cbm purposes any subsystem that stops functioning as expected will manifest the failure in the requirement an example is a depth sensor shown in fig 5 the depth sensor participates in localization and waypoint navigation if the depth sensor malfunctions then requirements 6 and 11 are no longer met consequently the sensor will no longer deliver depth data to the main vehicle computer which is responsible for higher level planning and waypoint navigation this depth data shown as a red dotted item flow in fig 5 defines an interface that would be monitored through the data driven dt updating the dt s learning model based on expected and actual functionality the structural vehicle block elements in the mbse model represent the physical components of the vehicle we show the entire system composition from the mbse process in fig 5 block definition diagrams bdds represent the physical components of the system next the digital twin cbm physical components are specified in the model this step involved two main phases generating block element representations of the physical components based on vehicle design documentation and adding data and energy flow connectors between appropriate components for both phases the uuv digital twin mbse modeling team communicated with the vehicle engineers to verify and update designated cbm components and connections according to friedenthal et al a key effort in designing systems involves performing various engineering analyses such as trade studies sensitivity analysis and design optimization friedenthal et al 2015 it may include the analysis of performance reliability cost and physical properties of the project system mbse modeling supports these types of analyses via sysml parametric modeling parametric models constrain the properties of a system which can then be evaluated using available analysis tools constraints are expressed as equations with parameters of the equations being bound to the properties of the project s system a parametric diagram within an mbse model can be used to represent one or more engineering analyses of a system s design to incorporate this capability we performed the following designed internal block definition ibds diagrams for vehicle components in the mbse model integrated parametric diagrams to support the ibds and generate sysml relational connectors between them and the ibds using ports implemented constraint equations to govern cbm design of the digital twin version of the vehicle and executed computational evaluations of the cbm design we incorporated parametrics as an auxiliary task to facilitate future reliability computations that can be taken directly from the mbse model 4 1 reliability parametric analysis as a part of the mbse effort we have included parametrics in the vehicle model these parameters constrain the values of model parameters permitting the use of simulation tools to extract relevant model information we utilize parametric analysis to produce a baseline value of the total system reliability to which we compare our extracted reliability taken from connectivity assumptions we utilize the national institute of standards nist definition of reliability which defines reliability as the ability of a system or component to function under stated conditions for a specified period of time ross et al 2019 in the case of a uuv system we apply this definition and define reliability as the ability for the vehicle to operate according to mission requirements for the duration of the mission s operational time the specific tasks enumerated under mission requirements include basic navigational capabilities such as navigating between waypoints ascending and descending and performing routine surface behaviors to establish communications to capture the reliability of the vehicle we utilize input from the system architects and data sheets about estimated subsystem reliabilities unfortunately since the development and expanded use of the vehicle is in its nascency we do not have experimental data from operational missions which is an alternative source of reliability determinations utilizing these values and analyzing subsystem connections we can calculate total system reliability utilizing the well known reliability functions defined by nist tobias 2013 because we are modeling reliability in the normal operating period or intrinsic failure period of the bathtub curve we assume constant failure rates and an exponential distribution of subsystem reliabilities the equation for component i s reliability r i is given as 1 r i t e λ i t where t is the time in hours of operation and λ i is the failure rate of component i the explicit dependence on time indicates that the reliability of the system is not fixed however for the purposes of our work we assume that all reliability estimates are calculated with respect to a constant operation completion time t op to make the conversation more informative we cast 1 in terms of the number of missions n rewriting 1 gives 2 r i n e λ i t op n we then estimate the mean time between failures mtbf in units of number of missions to arrive at reliability estimates for operational mission duration this makes the conversation with operators who aren t necessarily familiar with the exact numbers of failure rates and reliabilities more informative by means of placing failures in context an example would be after how many missions do you the operator need to realign or adjust the waterproof servos on the vehicle if the answer is every 25 missions then if t op 2 hr the failure rate is 1 50 hr 1 yielding a reliability of 3 r t op 2 hr e 1 50 hr 2 hr 0 9231 this simple calculation is a helpful approximation for complex analysis by casting the reliability in units of number of missions the operators and maintainers can inform the discussion much more easily since the burden of the calculation falls on the operations analyst or system analyst the overall reliability of a system depends on the network connections for n components attached in series then the reliability of the subsystem is 4 r series t i n r i t the reliability of the subsystem of components attached in parallel is 5 r parallel t 1 i n 1 r i t the equations assume that the subsystems are statistically independent parallel subsystems typically refers to the same subsystem and indicates redundancy where the failure of the subsystem is mitigated by the redundancy series subsystems define the connection between two different subsystems that are connected via single or multiple data connections the functionality of the different components results in the processing or utilization of the data for different purposes one can think of these connections as an analogy to parallel and series resistors from electronics circuits a series connections permits a current flow along a single path whereas a parallel connection permits the division of current along multiple paths whereas in circuit analysis these connections result from a transmitted current through physical connections the connections of subsystems can be quite different and include any connection and the transfer of any data type in the next section we introduce how we define layered connectivity and how we automatically extract these connections from the output of the mbse process 4 2 extraction of network connectivity a natural result of performing an mbse effort retroactively is the determination of how subsystems are connected to each other necessarily connections can be abstract for example the passage of energy between a battery and a dependent electronic device see fig 5 for an example of energy shown as a blue dotted line passing between the battery and multiple subsystems however abstract if the model is detailed enough to capture these connections then utilizing the output of the mbse we can extract the total system reliability which we use as a primary input in the next section section 5 for performing our optimization of subsystem selection we assume these connections establish the basis for calculating the total reliability as a product over 4 and 5 to extract those connections from the model we assume a layered network topology each layer l i defines how many subsystems are redundant within the layer within a redundant layer we use 5 to calculate the reliability individual layers are assumed to be connected in series this permits fast iteration over the network subsystems and allows us to construct a one dimensional representation of the network we show the layers in fig 6 notice that this permits an arbitrarily complex system to be captured in the one dimensional data structure in fig 6 subsystems are represented by black dots and labeled by s i components s 4 s 7 and s 9 s 12 are in parallel and are redundant subsystems the remaining components are attached in series with the parallel subsystems from this graphical representation which closely mimics the representation one might see within a sysml model we can extract the layer vector l the layer vector is constructed from the cardinality of the subsets attached in series because s 4 7 and s 9 12 are attached in parallel then the l 4 and l 6 vector elements equal 4 written out 6 l 1 1 1 4 1 4 where the number indicates the total number of redundant subsystems the utility of this layer data structure will become apparent when we calculate reliability improvement expectations 5 reliability improvement expectations we have argued thus far that one can utilize the output of the mbse process to represent the underlying subsystem connections as a one dimensional data structure l this in turn can be used to calculate the reliability of the system as a whole since it is a discrete representation of the total system reliability to show how l can be used to calculate the expected reliability improvements as a result of utilizing a digital twin to monitor subsystems we introduce an moop to determine expected reliabilities and cost estimates for implementing digital twins for the uuv subsystems the main objectives we consider are the reliability difference δ r r which is the difference in reliabilities between the base system and the resulting system after implementing digital twins and the total cost c tot which is the cost of implementing all digital twins within the triage subset problem 1 multi objective optimization problem statement for a system comprising n subsystems s s 1 s 2 s n with reliabilities r r 1 r 2 r n digital twin development costs c c 1 c 2 c n and known reliabilities for components with corresponding digital twins r r 1 r 2 r n find binary indicator vectors x r and x c that maximize the reliability difference δ r r r r and minimize total development cost c t o t subject to the constraints that the total number of nonzero elements in both x r and x c does not exceed n the sets which satisfy both objective functions are the pareto optimal sets these provide the corresponding tdt set of components s stated as a bi objective optimization problem 7 minimize x r x δ r r r x r r 8 minimize x c x c tot x c t c 9 subject to x 0 1 n 10 x r t x r n 11 x c t x c n note that to facilitate ease of computation we have utilized the duality principle in optimization to convert the maximization of reliability improvement function to a minimization by multiplying by 1 the objective function given by 7 represents the difference in reliability improvements where the decision variable is given by x r the function r yields the system reliability as a result of switching out the candidate set of components x r t the value r represents the total system reliability before improvements this is calculated either from the mbse model using the parametric diagrams or from the connectivity vector l in theory 7 should be negative for every subset x r assuming that the digital twins are designed properly and function no worse than the real time system this is a reasonable assumption since the digital twins are engineered by a team of experts typically those with data science or machine learning backgrounds and those with hardware and software expertise in the component area the variable c is a vector equivalent of the set of implementation costs c 5 1 numerical approximation methods we compare two optimization methods these are chosen partially out of convenience and for illustrative purposes we emphasize that the methods introduced here are not novel or in anyway prescriptive any method that solves problem 1 suffices for producing the tdt subsets the first is a direct computation of the subsets since the number of subsystem components is reasonably small that employing a direct method of computation is feasible similar to the method employed by custódio et al 2011 this direct calculation iterates over the entire component space which for a practical standpoint for a uuv is not unreasonable however if the number of components grows sufficiently large n 20 then more efficient methods must be considered such as gray code methods savage 1997 or evolutionary algorithms the direct computation method is shown in the procedure bruteforceoptimization in algorithm 1 we show this method and its auxiliary procedures to calculate all candidate subsets of reliabilities and costs though we do not provide the pseudocode for the procedure allcombinations it is a relatively simple combinatorial task to generate all possible combinations since one can use the binomial coefficient n k as a starting point producing up to k n 1 combinations to satisfy 10 and 11 once all possible combinations of subsystem reliabilities and costs are generated then we use objective to return the total system reliability as a result of utilizing digital twins r the objective procedure closely follows 7 in that it utilizes the connectivity information provided by l to determine how subsystems and components should be treated as in series or parallel once all possible combinations of reliability improvements and costs are calculated they are stored in δ and c tot respectively the keen observer will note that this optimization routine has generated the entire feasible region of the problem to identify only those non dominated or pareto solutions we utilize an additional procedure generateparetofront shown in algorithm 3 the algorithm works by sorting in ascending order the c tot and δ vectors from these we iterate in ascending order recording at each step if the reliability difference δ i is less than at least one point already sampled this produces the non dominated point set the second method we use is the genetic algorithm based normal boundary intersection ganbi method the ganbi method is particularly well suited for engineering design problems because unlike a standard evolutionary algorithm which produces a solution set at each iteration the ganbi algorithm produces a solution that approximates the pareto front at each iteration wettergren 2006 the ganbi algorithm serves as a preprocessor for existing genetic algorithms we utilize the non dominated sorting genetic algorithm nsga as the baseline algorithm for which we use the ganbi preprocessor the interested reader should consult the work of wettergren for a detailed account of the ganbi algorithm including a formal algorithm description of the approximation step wettergren 2006 note that we are comparing the ganbi algorithm to the direct computation to show that for a small system with n 10 components the methods direct and evolutionary are equivalent we also introduce the ganbi algorithm to allow an extension of this work for very large systems with complex connection layers indeed we rely on this method for our real world case study which we compare to the well known nsga we show the pseudocode of the ganbi algorithm in ganbi of algorithm 4 the key distinction between the ganbi algorithm and traditional evolutionary approaches is shown at line 2 in the procedure individualmaxima the ganbi algorithm relies on the calculation of the minima for the individual objective functions without regard to the other objectives if x 1 denotes the minimum of δ and x 2 denotes the minimum of c tot then 12 x x 1 x 2 is the vector that contains the minima for the reliability improvement and total cost objectives correspondingly we can write the matrix f min as 13 f min 0 δ x 2 δ x 1 c tot x 1 c tot x 2 0 this connects the individual minima through the line segment defined by the difference of points the convex hull of individual minima or chim from wettergren s work is given by convex combinations of 13 these are given by 14 chim f min b x b b 1 b 2 t 15 i b i 1 b i 0 the chim provides a coarse approximation to the pareto front produced by the reliability difference and total cost objectives the purpose of this is the creation of supporting objectives f given by nbiobjective the supporting objectives divide the hull into n pts which approximate the vector set normal to the points along the line segment connecting the two minima effectively this creates a point set that can be pushed out normal to the segment and eventually meet the pareto front of the bi objective problem creating the supporting objective functions actually increases computational time but it provides a better approximation to the pareto front than evolutionary approaches without the preprocessing these modified objective functions are then passed into the traditional nsga procedure for which we have declared the procedures but not the implementation of the code these are shown as nextgen and evalpop in algorithm 4 we once again call generateparetofront line 8 to do a final sort on the pareto frontier algorithm 1 direct computation of reliability difference image 1 algorithm 2 reliability from layer connectivity image 2 algorithm 3 producing pareto front from objectives image 3 algorithm 4 ganbi algorithm image 4 5 2 approximation results for example system before we consider the vehicle in our case study it is instructive to utilize our notional system of n 12 components to demonstrate how the algorithms perform understanding the results of the algorithms and placing into context the results as they apply to selecting the tdts and informing decision makers about the trade offs the first step is the enumeration of existing subsystem reliabilities r reliabilities after implementing digital twins r and the estimated cost to implement a digital twin c these are summarized in table 2 to simulate a realistic scenario we have created a randomized set of r where some components are noticeably worse or unreliable in comparison with others as much as an order of magnitude worse the upgraded reliabilities are also randomized these however are randomized within r i 1 0 where r i r this enforces the assumption that the reliability after implementing a digital twin can be no worse than the original the implementation costs are also randomized within the range 500 5000 with arbitrary units the connectivity of the subsystems is given by 6 using these inputs to the bruteforceoptimization we generate the pareto front in fig 7 a as well as show the entire feasible solution space the black star markers indicate the pareto solutions and the black dots indicate a dominated feasible solution the vertical axis represents the percentage increase in reliability as a result of implementing the tdts the abnormally large increases result from markedly improved reliabilities for the exceptionally unreliable subsystems the total system reliability before upgrades is r 0 029 the vertical axis is the scaled version of the objective function 7 or 16 δ r r r 100 we have also plotted on the same axes the pareto front and the feasible solution space for the ganbi and nsga methods which are not required for this simplistic example of n 12 components the feasible space for the ganbi algorithm is shown by the blue crosses the pareto front for the ganbi algorithm is shown by the blue squares the nsga feasible space is shown by red diamonds while the pareto front is shown by the red squares we have used n gen 500 generations in both the ganbi and nsga methods and a population size of n pop 50 for the example system after several numerical runs we determined that neither larger populations nor more generations improved the pareto frontier approximation however by plotting the ganbi algorithm it illustrates that we can approximate the pareto front reasonably well the benefit of using the evolutionary method comes when one considers complex systems with n 20 where it is computationally challenging if not impossible to iterate over all possible combinations of subsystems therefore the ganbi algorithm can be used for these larger complex systems in fig 7a c we have plotted the pareto fronts from the direct ganbi and nsga methods in fig 7d we have also extracted two example subsets s a and s b from the pareto front to show the trade off between reliability improvement and cost note that s a 1 3 8 has a total cost of c tot 6691 arb unit while s b 1 2 3 4 8 9 10 11 12 has a total cost of c tot 26862 arb unit as expected the more components that are selected for digital twin monitoring the higher the reliability improvement and the higher the cost as a result a large part of the process is prioritizing reliability vs cost for critical projects that remove humans from harm no expense should be spared when considering the reliability improvement whereas a project that does rely on the system for critical tasking but does not depend on the system for delivering humans from harm should expect to have reduced development costs while achieving significant reliability improvements 5 3 approximation results for unmanned underwater vehicle now we consider the vehicle in our case study we show the initial reliabilities and improvements based on discussions from the uuv maintainers and operators these values are shown in table 3 below we show the resulting optimization and extraction of candidate tdts s in fig 8 in fig 8a we have plotted the pareto frontier from the ganbi algorithm shown as blue squares as well as the nsga method shown as red circles we have not utilized the direct computation since the system of n 17 components is sufficiently complex that the feasible space is too large to calculate directly we have also extracted three candidate tdt subsets shown as points a b and c these are summarized in table 4 the initial system reliability calculated from r is 0 43 this comes from using a series connected l vector with 17 components since the vehicle is a minimalist uuv there are no redundant components and therefore the total system reliability depends on the individual subsystems as in 4 this initial reliability indicates a failure rate of λ 0 42 hr 1 calculated using t o p 2 hr this gives a mtbf of 2 37 hr or roughly after every mission some component stops functioning as expected using this number we are able to calculate expected system reliabilities for the subsets s a s b and s c shown in table 4 while these subsets are selected at random they raise key questions that need to be answered by continued discussions with decision makers first there is a 750 000 arb unit cost difference between options a and b with a 20 difference in total system reliability does the reliability improvement merit the additional cost burden should option c be prioritized for its simplicity and low cost at this point it is natural to address these questions using higher level information provided by discussions with decision makers without the added information strictly these options are all equivalent something to consider is the aforementioned maintainability of these components which of these is far more challenging to maintain requiring significant downtime the components that present the longest downtimes and appear in the tdt candidate subsets could be prioritized since the maintenance could be scheduled when the vehicle is not required for operations if the uuv is selected for deep water drilling platform inspections then the reliability improvement is likely a significant factor due to the inherent risk of having people perform this job if the uuv is used for shallow water oceanographic surveys then the reliability is likely not as an important factor as the implementation cost and option c will prevail we also show how often each component appears in a tdt candidate subset in fig 8b the histogram shows that there are some differences between the ganbi and the nsga methods used here nevertheless there are standout components that appear consistently more often note that s 7 9 and 12 appear more often this is expected since these have the lower initial reliabilities these are also the components that require maintenance most often according to the vehicle maintainers as a result these components are natural candidates for tdt monitoring equipped with these subsets the conversation with decision makers will be more directed and productive since the selection of the tdt subsets is bolstered by inputs from multiple stakeholders and team members all of whom contribute in a meaningful way guiding the selection process with relevant information moreover the mbse effort establishes the necessary data acquisition interfaces and physical interfaces that directly influence the implementation of dts once a tdt subset is downselected from the candidates this shortens the design and development timeline since at a minimum subject matter experts or those responsible for dt development will have requirements established 5 4 numerical performance comparison for both the example system and the uuv system data analyzed in subsections 5 2 and 5 3 the direct computation nsga and ganbi methods were performed using custom code developed in matlab r2013a on a computer running windows 10 with 8 gb ram and two intel core i5 4200m cpus 2 50 ghz matlab 2013 using a n 12 and n 17 system as a benchmark case with randomly generated reliabilities r 0 50 1 and costs c 100 10 10 3 arb unit we show averaged computation times for the three methods in table 5 based on 10 individual runs of each algorithm the table also contains computational complexities for the three algorithms based on n subsystems according to curry and dagli the nsga algorithm is o n o n pop 3 where n o is the number of objective functions in this case there are two objective functions indicating that the complexity is o 2 n pop 3 the ganbi algorithm is a preprocessor for the nsga so its complexity is that of the nsga plus a term that accounts for the additional helper objective functions n pts 2 n pop 3 the leading order in the large population size limit is n pts n pop 3 the distinction must be made that although the ganbi method requires additional steps to compute the supporting objectives it gives a better approximation to the true pareto front of the moop the direct method requires the computation of all possible combinations of subsystems which strictly is 2 n 1 accounting for the constraint that not all subsystems can be selected this term is dominated by 2 n so we can neglect the 1 this is done for every objective every objective is then compared with every other objective for small values of n n pop it is clear that the direct method is far better than the evolutionary algorithms since the complexity scales with cubic population size the values shown in table 5 are for a notional subsystem with n 7 n 12 and n 17 subsystems we have argued thus far that for a small number of subsystems n 10 the direct method is the most efficient whereas for a large number of subsystems n 20 evolutionary algorithms such as the nsga and the nsga with ganbi are the most efficient the keen observer will note that the computational times shown in the table suggest that the direct method is fast even as the number of subsystems exceeds the lower limit in fact it would seem that the direct method is an order of magnitude faster than the times of the evolutionary algorithms for the n 12 case this directly contradicts the complexities shown in the table as well since a simple calculation for the n 12 case yields o 10 11 for the direct method and o 10 5 and o 10 6 for nsga and ganbi respectively this is because of two primary factors first the direct method computes all combinations of costs and reliabilities which for n 12 is 4095 different combinations accounting for the constraints this is it essentially since a simple comparison is performed to determine the non dominated solutions second the evolutionary algorithms on the other hand must initialize a random population of chromosomes using n pop 50 with length n evaluate fitness reproduce crossover mutate and reevaluate for n gen 500 generations assuming the three algorithms have been programmed to a similar level of efficiency then the evolutionary algorithms take longer from a computational perspective simply because of the number of steps involved it is therefore more appropriate to utilize computational complexity in the large n limit and recognize that for a small number of subsystems the direct method is more efficient because of how few steps there are programmatically 6 discussion we have introduced a generalizable process for determining the subset of components from a sos that when monitored through digital twins yield the maximal increase in total system reliability and minimize the cost entrance hurdle for implementing the digital twins we have utilized our process on a real life application for an unmanned underwater vehicle through a combination of experimentally derived system reliabilities and an mbse effort where numerous discussions were held with the vehicle development team we have been able to demonstrate the applicability of this relatively simple approach to tdt selection the implications for the industry of unmanned underwater vehicles are that through the process developed in the paper groups that rely on uuvs for critical tasking which would otherwise place humans in direct harm can use the process for retroactively developing digital twins to increase system reliability while staying within budgetary constraints our process considers input from a variety of stakeholders and system users to ensure that the most accurate information is solicited for inclusion in the process we have not introduced variables data or parameters that are not readily available or those that would not be determined regardless of the tdt selection process the system reliabilities r are usually well known from experimental test data component data sheets or can be determined from like system analysis the reliabilities as a result of utilizing a twin to monitor the corresponding component r can be estimated based on a decrease in failure rates and discussions with subject matter experts responsible for implementing the digital twin the project management team in collaboration with the subject matter experts can provide cost estimates c for developing digital twins for the subsystems based on known parameters such as labor rates auxiliary software and it costs and historical development and testing timelines these parameters and the outputs of the connectivity analysis from the mbse suffice to perform a selection process on the subsystems to be monitored as we have shown higher level information is required to prioritize the subset of tdts s that are selected as the requisite systems for implementing digital twins such as budgetary constraints or reliability requirements the implications for the field of reliability studies are a generalizable process that is straightforward to utilize for a variety of systems that would like to leverage digital twin technology for enhancing reliability of legacy systems our process is particularly well suited for those who do not know which components to select for digital twin monitoring must rely on legacy systems for critical tasking and do not have the budget to design develop test and deploy complete digital twins for their systems credit authorship contribution statement demetrious t kutzke conceptualization methodology investigation writing original draft writing review editing james b carter methodology investigation writing original draft benjamin t hartman software formal analysis writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments the authors would like to thank the entire vehicle development team at nswc pcd for informing the modeling process and the continued support they have provided through numerous discussions and meetings the authors would like especially to thank m mcbain who was instrumental in determining the appropriate reliability estimates based on her experience as both an operator and maintainer of the vehicles finally the authors are indebted to dr patrick walters the system architect who designed the vehicle and provided the experimental system on which the paper is based this work has been supported by the nswc pcd naval innovative science and engineering nise program 
