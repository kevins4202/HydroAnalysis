index,text
26415,height above the nearest drainage hand a state of the art topo hydrological index has been increasingly used in geo environmental studies it describes the local normalized drainage potential of a large region to date a trial and error and cumbersome multistep process has been used to obtain the hand index which does not result in an optimal threshold for contributing area this study aims at developing a user friendly geographic information system gis tool handtool using the python programming language we successfully applied the tool for the chehel chai watershed iran and the random forest algorithm was used to model groundwater potential results revealed that the hand index made a great contribution to groundwater potential modeling among the other conditioning factors this tool gives valuable insights on the soil topography moisture shared interactions and vegetation condition especially in ungauged watersheds keywords handtool draining potential automation gis random forest software and data availability name of tool handtool developers samadi m kornejady a and rahmati o hardware required general purpose computer 3 gb ram software required arcgis 10 2 programming languages python 2 7 program size 231 kb availability and cost freely available in github https github com mahmoodsamadi handtool git year first available 2018 1 introduction topographical hydrological and topo hydrological factors are useful in many fields of geo environmental research including geomorphology ecology and water resources management since terrain attributes have long been known to correlate with soil properties gessler et al 2000 daws et al 2002 hansen et al 2009 they provide important information about subsurface runoff dynamics and spatial patterns of soil moisture key parameter in conditioning landscape ecology turner 1989 qiu et al 2001 dahl et al 2007 therefore they can help in understanding hydrological processes and characterizing the properties of watersheds that depict suitability of a region for agriculture reforestation or urbanization antrop 2000 2004 rodriguez iturbe 2000 luck and wu 2002 serra et al 2008 a range of topographic factors in terrain modeling are available which allow several quantitative relief features and analytical interpretations to be obtained from the digital elevation model dem altitude slope aspect drainage density and specific catchment area are common topographical descriptors in hydrology geomorphology and landscape analyses in addition relief shape factors such as curvatures e g plan profile and general and form indicators can also be produced based on a dem furthermore hydrological indices extracted from the dem such as accumulated contributing area stream density superficial runoff trajectories stream order stream flow periodicity and groundwater related factors e g tarboton and ames 2001 tarboton 2003 have been applied in terrain modeling at the watershed scale gichamo et al 2012 although altitude i e absolute height has been used as a relief descriptor at large scales its descriptive power may be limited when local environments in the fine scale relief are considered rennó et al 2008 the basic hypothesis in delineating drainage networks for deriving an apt topo hydrological descriptor is the determination of channel heads where concentrated fluxes begins to dominate over diffusive fluxes and where there is a transition from convex to concave profiles o callaghan and mark 1984 tarboton et al 1991 1992 tarboton 2003 marthews et al 2015 hence a number of studies applied automated or manual procedures for extracting dem derived stream networks through the selection of the contributing area threshold cat e g tesfa et al 2011 gichamo et al 2012 bhowmik et al 2015 several topo hydrological factors have been proposed in previous years which allow us to describe understand and predict soil water gravitational potential energy and water storage and movements seibert and mcglynn 2007 wu et al 2008 temimi et al 2010 for example the topographical wetness index twi beven and kirkby 1979 has been widely applied to different fields for describing hydrological behavior and soil water wetness conditions at the catchment scale e g sørensen et al 2005 sørensen and seibert 2007 grabs et al 2009 pei et al 2010 besnard et al 2013 however the major limitation of twi is it relies on some assumptions which are not necessarily true for all cases i it is assumed that groundwater gradients always equal surface gradients and ii it is also assumed that local slope is an adequate proxy for the effective downslope hydraulic gradient which is problematic in low relief terrain grabs et al 2009 lei et al 2016 therefore this index is less suitable in flat areas because of rather undefined flow directions which can be significantly different from ground surface slopes and also more likely to change over time a new terrain model named height above the nearest drainage hand has been introduced by nobre et al 2011 defined as a drainage normalized version of a digital elevation model the z axis variable of the hand model is the normalized local height defined as the vertical distance from a hillslope surface cell to a respective outlet to the drainage cell i e the difference in level between such cells that belong to a mutually connecting flowpath among the many terrain indices developed the hand is considered the best indicator of stationary soil moisture distribution because of its capacity to predict hydrological conditions of the terrain and soil environments has been successfully investigated sutanudjaja et al 2013 nobre et al 2016 the rapidly growing application of hand already includes hydrological modeling e g nobre et al 2011 cuartas et al 2012 hydrological geomorphological landscape analysis e g gharari et al 2011 nobre et al 2016 papageorgaki and nalbantis 2016 owusu et al 2017 landslide and or flood susceptibility e g young and nobre 2012 rosim et al 2014 martinis et al 2015 schlaffer et al 2015 bhatt et al 2016 policelli et al 2016 twele et al 2016 clement et al 2017 kesler 2017 kornejady et al 2017a 2017b manavalan 2017 sharma et al 2017 souffront alcantara et al 2017 speckhann et al 2017 vimal et al 2017 digital soil mapping zeng et al 2016 surface water mapping huang et al 2017 and riparian and plant ecology e g de freitas et al 2014 figueiredo et al 2014 moser et al 2014 schietti et al 2014 guitet et al 2015 the hand model is a version of a digital elevation model where heights have been normalized according to the vertical distance to the nearest drainage channel nobre et al 2011 for producing the hand terrain model a channel initiation must be recognized which is established by a contributing area threshold cat predicting and understanding soil moisture conditions subsurface runoff generation mechanisms groundwater potential and subsurface flow related processes using topo hydrological metrics is highly important especially in developing countries where observed data from groundwater monitoring wells and detailed hydrological information are scarce the development of automated gis tools have been suggested to improve reliability and reproducibility in environmental modeling and geospatial research jolma et al 2008 steiniger and hay 2009 neteler et al 2012 this study is aimed at developing an effective tool for automatic computation of the hand based on dem data chehel chai watershed in golestan province northwest iran was selected as a case study for the purpose of this research due to its similarities in landform variety with central amazonia where the hand was first introduced the specific objectives of this study are to i develop a novel and user friendly geographic information tool using python language allowing the user to quickly generate a hand layer and ii compare contribution of the hand to groundwater potential modeling along with other topographical topo hydrological factors using random forest model as a common and advanced machine learning algorithm 2 hand theory and tool development a detailed description regarding the hand index was presented in rennó et al 2008 nobre et al 2011 introduced the hand index and its physical and hydrological basis and cuartas et al 2012 made the first application of the hand index in the parameterization of a distributed hydrological model hand normalizes the altitude of a basin based on the relative height along the drainage network and determines the gravitational or the relative drainage potential of an area hand is a relative height difference between a particular cell on a dem map and its hydrologically related cell in the drainage channel the resulting values can be interpreted as a normalized altitude map in which areas with low hand values can exhibit saturation excess flow saturate response zone moving on the terrain towards higher hand values different mechanisms prevail such as subsurface rapid flow slope zone and deep percolation flow plateau zone so the hand normalized topology is now a dem enriched with useful information including response zones with specific runoff generation mechanisms soil properties and vegetation types the handtool was written in python a modern high level programming language python is a general purpose language freely available and quite popular in the programming community it allows development from scratch and or the assemblage and connection of existing software components in a productive environment neuwirth et al 2015 wohlstadter et al 2016 karssenberg et al 2007 attribute python popularity to the fact that users do not have to be specialist in computer programing the handtool appears in the arctoolbox and runs as an extension of arcgis10 2 software the design of the handtool was divided into three parts 1 input dem and topo hydrological computations which contains all the code that introduces the dem in raster format and the correct identification of the stream network and 2 selection of the method for determining cat which contains codes for manual and automatic procedures and 3 output which contains codes that generate the hand layer in raster format along with other supplementary layers such as corrected dem flow direction flow accumulation watersheds and automatically extracted stream network if needed the graphical user interface is highly important in model designing which allows users to change important parameters as well as to select the calculation procedures based on the available data and maps the conceptual architecture of handtool is illustrated in fig 1 coherent topology adjusts the flow path network eliminating sinks which is the source data for extracting the drainage network istanbulluoglu et al 2002 mcnamara et al 2006 lindsay 2006 according to literature breaching method martz and garbrecht 1999 was used for dealing with dem depressions because it fares better for areas with moderate relief e g jones 2002 lindsay and creed 2005 hence this method was also suggested by nobre et al 2011 as the best for generating the hand layer after carrying out dem depression correcting process identifying the drainage network of the watershed is a fundamental step of hand generation procedure because the network elevations are to be used for computing the nearest normalized terrain heights to achieve this channel initiation ci value is the only deterministic threshold that needs to be assessed nobre et al 2011 we developed two methods for considering the contributing area threshold including automatic and manual procedures the tool has a simple and clear graphical interface which allows the user to select the threshold method and then easily introduce the available layer and or data for generating the hand model in the manual procedure a trial and error approach is used to choose an appropriate cat value i e corresponds to the channel initiation where the user has to consider multiple cat values to reach the most desired drainage network that reflects the characteristics of the watershed the identification of the drainage network has been thoroughly explained by nobre et al 2011 unlike a manual procedure the automatic procedure uses an accurate drainage network called mapped stream network msn which has been produced based on field works with a global positioning system gps device in this stage the handtool selects different cats for extracting a drainage network with the highest similarity to the msn layer regarding the calculation process of hand rennó et al 2008 demonstrated that cat is the tunable parameter and assessed the impact of different contributing area thresholds on the hand layer i e the sensitivity of the hand layer to varying contributing areas recently a framework of automated accumulation threshold selection was introduced by bhowmik et al 2015 which uses the percentage of overlapped stream cells with buffered mapped streams however there are some limitations to this framework regarding the selection of candidate threshold values and uncertainty caused by buffering especially when facing a complex topography this was eased with the proposed automatic procedure in this study in this study we developed an effective framework which uses an iterative loop for identifying an optimal cat value fig 2 exemplifies the automatic procedure used in selecting the best cat the first step is to rasterize the msn layer based on the dem cell size in fig 2 we provided a msn map with 37 cells n ms the second step is to overlay the flow accumulation produced from dem and msn layer identify the ci values of msn and extract the flow accumulation values for these ci values note that there are eight ci cells in msn layer shown in fig 2a the flow accumulation values correspond to these cells are 15 19 26 33 45 57 63 and 72 which will be used as thresholds next the minimum threshold value i e 15 was considered as a cat and stream drainage network was then prepared according to table 1 see step 1 the number of dsn cells n ds corresponding to cat of 15 is 55 and it is higher than n ms i e 37 fig 2b another threshold was selected using the median method to overlap optimization between msn and dem derived streams therefore in next step a stream drainage network was generated based on the threshold of 45 fig 2c in contrast to the previous step the number of dsn cells n ds is 32 which is lower than n ms value see step 2 in table 1 so the cat value should be decreased this time because n ds is an inverse function of it i e a lower cat extracts a higher number of streams and vice versa this process continues until we reach a minimum difference between n ds and n ms in this example the optimal cat stood at 33 resulting in a dsn layer with n ds of 38 so that the difference between n ds and n ms is reduced to one cell fig 2e and table 1 hence the main part of handtool coding and structure designing was devoted to develop the automated procedure for selection of the optimal cat fig 3 3 case study 3 1 study area the handtool was applied to produce the hand index in the chehel chai watershed it is located in golestan province northwest iran which supplies a considerable amount of water for drinking water agriculture and other purposes the chehel chai watershed has an area of approximately 23 071 ha with an elevation ranged from 189 4 m to 2527 6 m fig 4 and an average slope of about 21 the study area has a humid climate with an average annual rainfall of 766 mm the city of minudasht borrows more than 40 of its irrigation and drinking water demands from the groundwater and surface water provided by the chehel chai watershed importantly since there are numerous groundwater springs in the watershed mountainous springs water is an important water supply resource for downstream populations according to iranian department of water resources management idwrm the average spring discharge approximately stands at 10 lit s in the study area additionally the general trend of groundwater flow is in accordance with the general topographic gradient from south to the north 3 2 construction of the hand map a 1 25 000 topographic map was used in the current study to generate the dem raster with a 10 m resolution then the dem layer was used for a sequence of computations to create a hydrologically coherent dem to identify flow paths and to delineate the drainage channels the msn layers were obtained from iranian department of water resources management idwrm golestan province as the only available data source and also validated by accurate precise and reliable ground truth bhowmik et al 2015 moreover the msn obtained was validated using several field surveys in this case study the automatic procedure was carried out for creating the hand map therefore the spatial data used in handtool included a dem as well as the msn fig 5 when the automatic procedure is selected by the user the drainage network field will be active the user interface design was a useful component of the handtool as it allowed us to easily input layers and select the manual automatic procedure various optimization searches for identifying an optimal cat value as well as flow accumulation raster computation and hand layer production were considered fig 5a the optimal cat stood at 77 which can be seen in fig 5b 3 3 groundwater potential modeling due to the diverse topo hydrological properties stored in hand index especially bearing on different water generation mechanisms we aimed to explore the contribution of the hand index to groundwater potential modeling along with other topographical topo hydrological descriptors in order to assess groundwater potential it is not feasible to obtain a large number of well spring data points in a large region because of limitations such as high cost and time consuming procedures and inaccessibility problems in mountainous areas oh et al 2011 to overcome this problem the data driven and machine learning models have been widely applied to delineate the groundwater potential at large scales e g oh et al 2011 ozdemir 2011 nampak et al 2014 pourtaghi and pourghasemi 2014 rahmati et al 2016 naghibi et al 2017 in general groundwater potential is affected by many geo environmental and topographical factors such as lithology soil geological structure slope steepness and morphology vegetation cover land use and stream evolution lee et al 2012 in groundwater potential field random forest rf is one of the effective machine learning models nowadays since the model makes no strict assumptions prior to the study and it can handle data from various measurement scales naghibi and pourghasemi 2015 rahmati et al 2016 moreover it conducts a contribution analysis to evaluate the effect of each factor i e predictive variable independently on the groundwater potential a detailed mathematical description of rf model is given in breiman 2001 liaw and wiener 2002 in this study rf were considered to model the groundwater potential using 18 groundwater related factors mentioned in the literature e g park et al 2014 pourghasemi and beheshtirad 2015 naghibi et al 2016 davoodi moghaddam et al 2015 sahoo et al 2017 tillman et al 2017 these factors include altitude topographic position index tpi distance from road topographic wetness index twi plan curvature profile curvature hand index distance from fault convergence index distance from stream lithology relative slope position rsp terrain ruggedness index tri melton ruggedness index mri slope degree slope aspect land use cover and soil texture the mathematical procedure of rf was conducted in the randomforest package of r open source software a spring inventory map was produced for the study area through several field surveys using geoinformatics gps and arcgis 10 2 encompassing 221 springs fig 8 then 70 30 randomly partitioned datasets were respectively used for training the models i e 155 cases for calibration and the validation purpose 66 cases naghibi and pourghasemi 2015 location of the training and validation sets is shown in fig 6 finally the groundwater potential map was validated using the receiver operating characteristic roc curve oh et al 2011 the area under the roc curve auc has been widely considered as quantitative evaluation criteria to assess the accuracy of the groundwater potential models pradhan 2009 manap et al 2014 nampak et al 2014 park et al 2014 detailed information on the auc method can be found in the literature kornejady et al 2014 2015 chen et al 2017 pourghasemi et al 2017 finally the rf model was run and the contribution of conditioning factors was ordered via mean decrease accuracy mda index andriyas and mckee 2013 al abadi and shahid 2016 4 results and discussion 4 1 automated accumulated area threshold selection the optimal cat value determined by handtool was set to 77 which resulted in a good agreement between dem derived stream network dsn and the mapped stream network msn maps in addition the ground truth and field verification of actual stream initiation i e channel heads in the chehel chai watershed demonstrated that the contributing area threshold of 76 grid points generates the most accurate drainage network map moreover the handtool showed high computational parsimony and time efficiency the application of median method results in a reduction of required time for searching the optimal threshold in a large numerical range and over a large spatial scale murphy et al 2008 stated that spatial scale impacts on the selection of a cat value large and small scales studies often require low and high cat values respectively this comparative reasoning allows the threshold to be adjusted to choose best cat value and to produce a realistic dem derived stream network dsn map in addition the handtool is scale independent to be applied at any different scales from a catchment to large watersheds when dsn map exhibited good agreement with the msn map the hand index is calculated through normalization of the dem according to distributed vertical distances relative to the drainage channels 4 2 hand map as abovementioned the hand map was constructed through the automatic procedure of handtool in arcgis 10 2 software fig 7 variations in vertical profile reveal interesting patterns which can be applied to landscape studies as a quantitative and accurate data source as presented by nobre et al 2011 the hand map can be classified based on the soil moisture water table depth and stream flow discharge data through calibration and validation processes since there are no piezometric data in the entire study area this study could not classify the hand map however classification of the landscape based on long time water table data of piezometers and detailed field data is beyond the aim of the present work in the current study the handtool processed large input dem and msn in the golestan province that comprises a lot of streams and a complex topography the handtool showed an advantage in terms of processing large dems which was entailed by the efficient computational processing capability in python running as an extension of arcgis software other advantages of the automatic tool procedures include i it is easy to implement ii it produces reasonably accurate results and iii in terms of time requirements it is also superior when compared to traditional manual procedures i e trial and error approach 4 3 groundwater potential modeling and factor contribution analysis the groundwater potential map of the study area was generated using rf model finally this map was reclassified into four classes low moderate high and very high groundwater potential fig 8 as shown the high potential areas are found in the western southern and eastern parts of the study area which were generally nearby the faults streams and roads as well as the concave profile curvatures the area under the roc curve auc value for the rf model was calculated as 91 7 which indicates that the rf model is a good estimator of groundwater potential in the study area according to the proposed classification of auc values by yesilnacar 2005 it can be conceived that rf model gave a perfect accuracy in groundwater potential modeling the model indicates a reasonable performance with respect to previous studies subject to the rf model such as naghibi and pourghasemi 2015 and rahmati et al 2016 the results from this study demonstrated that the rf model can provide an advanced geospatial analysis tool to establish the probabilistic relationship between groundwater potential i e dependent variable and geo environmental and topographical factors i e independent variables this study addressed the contribution of the hand as a relative distributed drainage potential factor to spatial groundwater potential as a locally significant terrain controlling process compared to other topographical based factors in table 2 the most influencing factors on groundwater occurrence accordingly include profile curvature mda 35 1 distance from fault mda 33 hand mda 27 2 distance from stream mda 25 4 and distance from road mda 20 5 therefore the factor contribution analysis reveals that the hand index a state of the art topo hydrological factor can determine and predict the relative gravitational potential better than other topographical and topo hydrological factors except profile curvature here furthermore the hand is an informative and robust factor for identification of relevant soil water conditions and groundwater potential assessment in addition assessment of spatial pattern of spring occurrences with hand index indicates that the groundwater potential follows a local normalized topography this finding is in line with haitjema and mitchell bruker 2005 and morin et al 2010 which shows that topography can significantly control the position of the water table in shallow aquifers o loughlin 1986 indicated that the groundwater flow is generally controlled by surface topography at the landscape scale the results of contribution analysis are in accordance with the findings of lin et al 2005 and liu et al 2007 highlighting the important effect of topography on subsurface flow and groundwater distribution therefore evaluation of the relationship between the topo hydrological factors and groundwater potential provides a theoretical platform for conceptual understanding of the effect of topography on subsurface flows wörman et al 2006 height variations in the hand map have hydrological significance and can provide an accurate spatial representation of soil water conditions i e hidden local environments and local draining potentials nobre 2011 in general the hand map allows to determine spatial patterns and characteristics and also to describe spatially variable hydrologic conditions in a more cost effective way than conducting physically based models or extensive field surveys especially when we encounter data paucity 5 conclusion knowledge on the topo hydrological properties of the watersheds is notably important to recognize the physical characteristics as well as to understand the hydrological and geomorphological processes the height above the nearest drainage hand model a novel topo hydrological metric focuses on the height difference along flow paths and gravitational or draining potentials in the field of landscape ecology we developed a user friendly tool for producing the hand map using python language which includes both manual and automatic procedures to extract drainage networks from a dem more importantly the findings of the current study revealed that not only the handtool facilitates the production of the hand map in hydrological and geo environmental analyses in a precise manner in the case of factor contribution analysis in groundwater potential modeling the profile curvature mda about 35 was the most influential factor among the 18 groundwater conditioning factors followed by the distance from the fault mda 33 and hand mda about 27 these analyses in the chehel chai watershed golestan province iran demonstrate a strong and robust relationship between the hand index and groundwater potential as an important conclusion the hand is a useful and quick tool especially in ungauged catchments available for ecological researchers and decision makers dealing with natural resources especially on the subjects related to soil moisture and groundwater potential components the hand terrain model can help to advance physically based hydrological models and provide a new quantitative and qualitative view on the steady state landscape nonetheless this handtool can still be improved by embedding an automatic classification option similar and beyond to the original hand model using the available direct and or indirect water related variables such as terrain properties e g slope curvature etc and field data i e water table depth vegetation etc acknowledgments we thank the iranian department of water resources management idwrm and department of geology survey idgs for providing necessary data and maps we are grateful to the editor prof d p ames and anonymous referees for useful insights which improved a previous version of this manuscript 
26415,height above the nearest drainage hand a state of the art topo hydrological index has been increasingly used in geo environmental studies it describes the local normalized drainage potential of a large region to date a trial and error and cumbersome multistep process has been used to obtain the hand index which does not result in an optimal threshold for contributing area this study aims at developing a user friendly geographic information system gis tool handtool using the python programming language we successfully applied the tool for the chehel chai watershed iran and the random forest algorithm was used to model groundwater potential results revealed that the hand index made a great contribution to groundwater potential modeling among the other conditioning factors this tool gives valuable insights on the soil topography moisture shared interactions and vegetation condition especially in ungauged watersheds keywords handtool draining potential automation gis random forest software and data availability name of tool handtool developers samadi m kornejady a and rahmati o hardware required general purpose computer 3 gb ram software required arcgis 10 2 programming languages python 2 7 program size 231 kb availability and cost freely available in github https github com mahmoodsamadi handtool git year first available 2018 1 introduction topographical hydrological and topo hydrological factors are useful in many fields of geo environmental research including geomorphology ecology and water resources management since terrain attributes have long been known to correlate with soil properties gessler et al 2000 daws et al 2002 hansen et al 2009 they provide important information about subsurface runoff dynamics and spatial patterns of soil moisture key parameter in conditioning landscape ecology turner 1989 qiu et al 2001 dahl et al 2007 therefore they can help in understanding hydrological processes and characterizing the properties of watersheds that depict suitability of a region for agriculture reforestation or urbanization antrop 2000 2004 rodriguez iturbe 2000 luck and wu 2002 serra et al 2008 a range of topographic factors in terrain modeling are available which allow several quantitative relief features and analytical interpretations to be obtained from the digital elevation model dem altitude slope aspect drainage density and specific catchment area are common topographical descriptors in hydrology geomorphology and landscape analyses in addition relief shape factors such as curvatures e g plan profile and general and form indicators can also be produced based on a dem furthermore hydrological indices extracted from the dem such as accumulated contributing area stream density superficial runoff trajectories stream order stream flow periodicity and groundwater related factors e g tarboton and ames 2001 tarboton 2003 have been applied in terrain modeling at the watershed scale gichamo et al 2012 although altitude i e absolute height has been used as a relief descriptor at large scales its descriptive power may be limited when local environments in the fine scale relief are considered rennó et al 2008 the basic hypothesis in delineating drainage networks for deriving an apt topo hydrological descriptor is the determination of channel heads where concentrated fluxes begins to dominate over diffusive fluxes and where there is a transition from convex to concave profiles o callaghan and mark 1984 tarboton et al 1991 1992 tarboton 2003 marthews et al 2015 hence a number of studies applied automated or manual procedures for extracting dem derived stream networks through the selection of the contributing area threshold cat e g tesfa et al 2011 gichamo et al 2012 bhowmik et al 2015 several topo hydrological factors have been proposed in previous years which allow us to describe understand and predict soil water gravitational potential energy and water storage and movements seibert and mcglynn 2007 wu et al 2008 temimi et al 2010 for example the topographical wetness index twi beven and kirkby 1979 has been widely applied to different fields for describing hydrological behavior and soil water wetness conditions at the catchment scale e g sørensen et al 2005 sørensen and seibert 2007 grabs et al 2009 pei et al 2010 besnard et al 2013 however the major limitation of twi is it relies on some assumptions which are not necessarily true for all cases i it is assumed that groundwater gradients always equal surface gradients and ii it is also assumed that local slope is an adequate proxy for the effective downslope hydraulic gradient which is problematic in low relief terrain grabs et al 2009 lei et al 2016 therefore this index is less suitable in flat areas because of rather undefined flow directions which can be significantly different from ground surface slopes and also more likely to change over time a new terrain model named height above the nearest drainage hand has been introduced by nobre et al 2011 defined as a drainage normalized version of a digital elevation model the z axis variable of the hand model is the normalized local height defined as the vertical distance from a hillslope surface cell to a respective outlet to the drainage cell i e the difference in level between such cells that belong to a mutually connecting flowpath among the many terrain indices developed the hand is considered the best indicator of stationary soil moisture distribution because of its capacity to predict hydrological conditions of the terrain and soil environments has been successfully investigated sutanudjaja et al 2013 nobre et al 2016 the rapidly growing application of hand already includes hydrological modeling e g nobre et al 2011 cuartas et al 2012 hydrological geomorphological landscape analysis e g gharari et al 2011 nobre et al 2016 papageorgaki and nalbantis 2016 owusu et al 2017 landslide and or flood susceptibility e g young and nobre 2012 rosim et al 2014 martinis et al 2015 schlaffer et al 2015 bhatt et al 2016 policelli et al 2016 twele et al 2016 clement et al 2017 kesler 2017 kornejady et al 2017a 2017b manavalan 2017 sharma et al 2017 souffront alcantara et al 2017 speckhann et al 2017 vimal et al 2017 digital soil mapping zeng et al 2016 surface water mapping huang et al 2017 and riparian and plant ecology e g de freitas et al 2014 figueiredo et al 2014 moser et al 2014 schietti et al 2014 guitet et al 2015 the hand model is a version of a digital elevation model where heights have been normalized according to the vertical distance to the nearest drainage channel nobre et al 2011 for producing the hand terrain model a channel initiation must be recognized which is established by a contributing area threshold cat predicting and understanding soil moisture conditions subsurface runoff generation mechanisms groundwater potential and subsurface flow related processes using topo hydrological metrics is highly important especially in developing countries where observed data from groundwater monitoring wells and detailed hydrological information are scarce the development of automated gis tools have been suggested to improve reliability and reproducibility in environmental modeling and geospatial research jolma et al 2008 steiniger and hay 2009 neteler et al 2012 this study is aimed at developing an effective tool for automatic computation of the hand based on dem data chehel chai watershed in golestan province northwest iran was selected as a case study for the purpose of this research due to its similarities in landform variety with central amazonia where the hand was first introduced the specific objectives of this study are to i develop a novel and user friendly geographic information tool using python language allowing the user to quickly generate a hand layer and ii compare contribution of the hand to groundwater potential modeling along with other topographical topo hydrological factors using random forest model as a common and advanced machine learning algorithm 2 hand theory and tool development a detailed description regarding the hand index was presented in rennó et al 2008 nobre et al 2011 introduced the hand index and its physical and hydrological basis and cuartas et al 2012 made the first application of the hand index in the parameterization of a distributed hydrological model hand normalizes the altitude of a basin based on the relative height along the drainage network and determines the gravitational or the relative drainage potential of an area hand is a relative height difference between a particular cell on a dem map and its hydrologically related cell in the drainage channel the resulting values can be interpreted as a normalized altitude map in which areas with low hand values can exhibit saturation excess flow saturate response zone moving on the terrain towards higher hand values different mechanisms prevail such as subsurface rapid flow slope zone and deep percolation flow plateau zone so the hand normalized topology is now a dem enriched with useful information including response zones with specific runoff generation mechanisms soil properties and vegetation types the handtool was written in python a modern high level programming language python is a general purpose language freely available and quite popular in the programming community it allows development from scratch and or the assemblage and connection of existing software components in a productive environment neuwirth et al 2015 wohlstadter et al 2016 karssenberg et al 2007 attribute python popularity to the fact that users do not have to be specialist in computer programing the handtool appears in the arctoolbox and runs as an extension of arcgis10 2 software the design of the handtool was divided into three parts 1 input dem and topo hydrological computations which contains all the code that introduces the dem in raster format and the correct identification of the stream network and 2 selection of the method for determining cat which contains codes for manual and automatic procedures and 3 output which contains codes that generate the hand layer in raster format along with other supplementary layers such as corrected dem flow direction flow accumulation watersheds and automatically extracted stream network if needed the graphical user interface is highly important in model designing which allows users to change important parameters as well as to select the calculation procedures based on the available data and maps the conceptual architecture of handtool is illustrated in fig 1 coherent topology adjusts the flow path network eliminating sinks which is the source data for extracting the drainage network istanbulluoglu et al 2002 mcnamara et al 2006 lindsay 2006 according to literature breaching method martz and garbrecht 1999 was used for dealing with dem depressions because it fares better for areas with moderate relief e g jones 2002 lindsay and creed 2005 hence this method was also suggested by nobre et al 2011 as the best for generating the hand layer after carrying out dem depression correcting process identifying the drainage network of the watershed is a fundamental step of hand generation procedure because the network elevations are to be used for computing the nearest normalized terrain heights to achieve this channel initiation ci value is the only deterministic threshold that needs to be assessed nobre et al 2011 we developed two methods for considering the contributing area threshold including automatic and manual procedures the tool has a simple and clear graphical interface which allows the user to select the threshold method and then easily introduce the available layer and or data for generating the hand model in the manual procedure a trial and error approach is used to choose an appropriate cat value i e corresponds to the channel initiation where the user has to consider multiple cat values to reach the most desired drainage network that reflects the characteristics of the watershed the identification of the drainage network has been thoroughly explained by nobre et al 2011 unlike a manual procedure the automatic procedure uses an accurate drainage network called mapped stream network msn which has been produced based on field works with a global positioning system gps device in this stage the handtool selects different cats for extracting a drainage network with the highest similarity to the msn layer regarding the calculation process of hand rennó et al 2008 demonstrated that cat is the tunable parameter and assessed the impact of different contributing area thresholds on the hand layer i e the sensitivity of the hand layer to varying contributing areas recently a framework of automated accumulation threshold selection was introduced by bhowmik et al 2015 which uses the percentage of overlapped stream cells with buffered mapped streams however there are some limitations to this framework regarding the selection of candidate threshold values and uncertainty caused by buffering especially when facing a complex topography this was eased with the proposed automatic procedure in this study in this study we developed an effective framework which uses an iterative loop for identifying an optimal cat value fig 2 exemplifies the automatic procedure used in selecting the best cat the first step is to rasterize the msn layer based on the dem cell size in fig 2 we provided a msn map with 37 cells n ms the second step is to overlay the flow accumulation produced from dem and msn layer identify the ci values of msn and extract the flow accumulation values for these ci values note that there are eight ci cells in msn layer shown in fig 2a the flow accumulation values correspond to these cells are 15 19 26 33 45 57 63 and 72 which will be used as thresholds next the minimum threshold value i e 15 was considered as a cat and stream drainage network was then prepared according to table 1 see step 1 the number of dsn cells n ds corresponding to cat of 15 is 55 and it is higher than n ms i e 37 fig 2b another threshold was selected using the median method to overlap optimization between msn and dem derived streams therefore in next step a stream drainage network was generated based on the threshold of 45 fig 2c in contrast to the previous step the number of dsn cells n ds is 32 which is lower than n ms value see step 2 in table 1 so the cat value should be decreased this time because n ds is an inverse function of it i e a lower cat extracts a higher number of streams and vice versa this process continues until we reach a minimum difference between n ds and n ms in this example the optimal cat stood at 33 resulting in a dsn layer with n ds of 38 so that the difference between n ds and n ms is reduced to one cell fig 2e and table 1 hence the main part of handtool coding and structure designing was devoted to develop the automated procedure for selection of the optimal cat fig 3 3 case study 3 1 study area the handtool was applied to produce the hand index in the chehel chai watershed it is located in golestan province northwest iran which supplies a considerable amount of water for drinking water agriculture and other purposes the chehel chai watershed has an area of approximately 23 071 ha with an elevation ranged from 189 4 m to 2527 6 m fig 4 and an average slope of about 21 the study area has a humid climate with an average annual rainfall of 766 mm the city of minudasht borrows more than 40 of its irrigation and drinking water demands from the groundwater and surface water provided by the chehel chai watershed importantly since there are numerous groundwater springs in the watershed mountainous springs water is an important water supply resource for downstream populations according to iranian department of water resources management idwrm the average spring discharge approximately stands at 10 lit s in the study area additionally the general trend of groundwater flow is in accordance with the general topographic gradient from south to the north 3 2 construction of the hand map a 1 25 000 topographic map was used in the current study to generate the dem raster with a 10 m resolution then the dem layer was used for a sequence of computations to create a hydrologically coherent dem to identify flow paths and to delineate the drainage channels the msn layers were obtained from iranian department of water resources management idwrm golestan province as the only available data source and also validated by accurate precise and reliable ground truth bhowmik et al 2015 moreover the msn obtained was validated using several field surveys in this case study the automatic procedure was carried out for creating the hand map therefore the spatial data used in handtool included a dem as well as the msn fig 5 when the automatic procedure is selected by the user the drainage network field will be active the user interface design was a useful component of the handtool as it allowed us to easily input layers and select the manual automatic procedure various optimization searches for identifying an optimal cat value as well as flow accumulation raster computation and hand layer production were considered fig 5a the optimal cat stood at 77 which can be seen in fig 5b 3 3 groundwater potential modeling due to the diverse topo hydrological properties stored in hand index especially bearing on different water generation mechanisms we aimed to explore the contribution of the hand index to groundwater potential modeling along with other topographical topo hydrological descriptors in order to assess groundwater potential it is not feasible to obtain a large number of well spring data points in a large region because of limitations such as high cost and time consuming procedures and inaccessibility problems in mountainous areas oh et al 2011 to overcome this problem the data driven and machine learning models have been widely applied to delineate the groundwater potential at large scales e g oh et al 2011 ozdemir 2011 nampak et al 2014 pourtaghi and pourghasemi 2014 rahmati et al 2016 naghibi et al 2017 in general groundwater potential is affected by many geo environmental and topographical factors such as lithology soil geological structure slope steepness and morphology vegetation cover land use and stream evolution lee et al 2012 in groundwater potential field random forest rf is one of the effective machine learning models nowadays since the model makes no strict assumptions prior to the study and it can handle data from various measurement scales naghibi and pourghasemi 2015 rahmati et al 2016 moreover it conducts a contribution analysis to evaluate the effect of each factor i e predictive variable independently on the groundwater potential a detailed mathematical description of rf model is given in breiman 2001 liaw and wiener 2002 in this study rf were considered to model the groundwater potential using 18 groundwater related factors mentioned in the literature e g park et al 2014 pourghasemi and beheshtirad 2015 naghibi et al 2016 davoodi moghaddam et al 2015 sahoo et al 2017 tillman et al 2017 these factors include altitude topographic position index tpi distance from road topographic wetness index twi plan curvature profile curvature hand index distance from fault convergence index distance from stream lithology relative slope position rsp terrain ruggedness index tri melton ruggedness index mri slope degree slope aspect land use cover and soil texture the mathematical procedure of rf was conducted in the randomforest package of r open source software a spring inventory map was produced for the study area through several field surveys using geoinformatics gps and arcgis 10 2 encompassing 221 springs fig 8 then 70 30 randomly partitioned datasets were respectively used for training the models i e 155 cases for calibration and the validation purpose 66 cases naghibi and pourghasemi 2015 location of the training and validation sets is shown in fig 6 finally the groundwater potential map was validated using the receiver operating characteristic roc curve oh et al 2011 the area under the roc curve auc has been widely considered as quantitative evaluation criteria to assess the accuracy of the groundwater potential models pradhan 2009 manap et al 2014 nampak et al 2014 park et al 2014 detailed information on the auc method can be found in the literature kornejady et al 2014 2015 chen et al 2017 pourghasemi et al 2017 finally the rf model was run and the contribution of conditioning factors was ordered via mean decrease accuracy mda index andriyas and mckee 2013 al abadi and shahid 2016 4 results and discussion 4 1 automated accumulated area threshold selection the optimal cat value determined by handtool was set to 77 which resulted in a good agreement between dem derived stream network dsn and the mapped stream network msn maps in addition the ground truth and field verification of actual stream initiation i e channel heads in the chehel chai watershed demonstrated that the contributing area threshold of 76 grid points generates the most accurate drainage network map moreover the handtool showed high computational parsimony and time efficiency the application of median method results in a reduction of required time for searching the optimal threshold in a large numerical range and over a large spatial scale murphy et al 2008 stated that spatial scale impacts on the selection of a cat value large and small scales studies often require low and high cat values respectively this comparative reasoning allows the threshold to be adjusted to choose best cat value and to produce a realistic dem derived stream network dsn map in addition the handtool is scale independent to be applied at any different scales from a catchment to large watersheds when dsn map exhibited good agreement with the msn map the hand index is calculated through normalization of the dem according to distributed vertical distances relative to the drainage channels 4 2 hand map as abovementioned the hand map was constructed through the automatic procedure of handtool in arcgis 10 2 software fig 7 variations in vertical profile reveal interesting patterns which can be applied to landscape studies as a quantitative and accurate data source as presented by nobre et al 2011 the hand map can be classified based on the soil moisture water table depth and stream flow discharge data through calibration and validation processes since there are no piezometric data in the entire study area this study could not classify the hand map however classification of the landscape based on long time water table data of piezometers and detailed field data is beyond the aim of the present work in the current study the handtool processed large input dem and msn in the golestan province that comprises a lot of streams and a complex topography the handtool showed an advantage in terms of processing large dems which was entailed by the efficient computational processing capability in python running as an extension of arcgis software other advantages of the automatic tool procedures include i it is easy to implement ii it produces reasonably accurate results and iii in terms of time requirements it is also superior when compared to traditional manual procedures i e trial and error approach 4 3 groundwater potential modeling and factor contribution analysis the groundwater potential map of the study area was generated using rf model finally this map was reclassified into four classes low moderate high and very high groundwater potential fig 8 as shown the high potential areas are found in the western southern and eastern parts of the study area which were generally nearby the faults streams and roads as well as the concave profile curvatures the area under the roc curve auc value for the rf model was calculated as 91 7 which indicates that the rf model is a good estimator of groundwater potential in the study area according to the proposed classification of auc values by yesilnacar 2005 it can be conceived that rf model gave a perfect accuracy in groundwater potential modeling the model indicates a reasonable performance with respect to previous studies subject to the rf model such as naghibi and pourghasemi 2015 and rahmati et al 2016 the results from this study demonstrated that the rf model can provide an advanced geospatial analysis tool to establish the probabilistic relationship between groundwater potential i e dependent variable and geo environmental and topographical factors i e independent variables this study addressed the contribution of the hand as a relative distributed drainage potential factor to spatial groundwater potential as a locally significant terrain controlling process compared to other topographical based factors in table 2 the most influencing factors on groundwater occurrence accordingly include profile curvature mda 35 1 distance from fault mda 33 hand mda 27 2 distance from stream mda 25 4 and distance from road mda 20 5 therefore the factor contribution analysis reveals that the hand index a state of the art topo hydrological factor can determine and predict the relative gravitational potential better than other topographical and topo hydrological factors except profile curvature here furthermore the hand is an informative and robust factor for identification of relevant soil water conditions and groundwater potential assessment in addition assessment of spatial pattern of spring occurrences with hand index indicates that the groundwater potential follows a local normalized topography this finding is in line with haitjema and mitchell bruker 2005 and morin et al 2010 which shows that topography can significantly control the position of the water table in shallow aquifers o loughlin 1986 indicated that the groundwater flow is generally controlled by surface topography at the landscape scale the results of contribution analysis are in accordance with the findings of lin et al 2005 and liu et al 2007 highlighting the important effect of topography on subsurface flow and groundwater distribution therefore evaluation of the relationship between the topo hydrological factors and groundwater potential provides a theoretical platform for conceptual understanding of the effect of topography on subsurface flows wörman et al 2006 height variations in the hand map have hydrological significance and can provide an accurate spatial representation of soil water conditions i e hidden local environments and local draining potentials nobre 2011 in general the hand map allows to determine spatial patterns and characteristics and also to describe spatially variable hydrologic conditions in a more cost effective way than conducting physically based models or extensive field surveys especially when we encounter data paucity 5 conclusion knowledge on the topo hydrological properties of the watersheds is notably important to recognize the physical characteristics as well as to understand the hydrological and geomorphological processes the height above the nearest drainage hand model a novel topo hydrological metric focuses on the height difference along flow paths and gravitational or draining potentials in the field of landscape ecology we developed a user friendly tool for producing the hand map using python language which includes both manual and automatic procedures to extract drainage networks from a dem more importantly the findings of the current study revealed that not only the handtool facilitates the production of the hand map in hydrological and geo environmental analyses in a precise manner in the case of factor contribution analysis in groundwater potential modeling the profile curvature mda about 35 was the most influential factor among the 18 groundwater conditioning factors followed by the distance from the fault mda 33 and hand mda about 27 these analyses in the chehel chai watershed golestan province iran demonstrate a strong and robust relationship between the hand index and groundwater potential as an important conclusion the hand is a useful and quick tool especially in ungauged catchments available for ecological researchers and decision makers dealing with natural resources especially on the subjects related to soil moisture and groundwater potential components the hand terrain model can help to advance physically based hydrological models and provide a new quantitative and qualitative view on the steady state landscape nonetheless this handtool can still be improved by embedding an automatic classification option similar and beyond to the original hand model using the available direct and or indirect water related variables such as terrain properties e g slope curvature etc and field data i e water table depth vegetation etc acknowledgments we thank the iranian department of water resources management idwrm and department of geology survey idgs for providing necessary data and maps we are grateful to the editor prof d p ames and anonymous referees for useful insights which improved a previous version of this manuscript 
26416,this paper presents mulesme a software designed for the systematic mapping of surface soil moisture using sentinel 1 sar data mulesme implements a multi temporal algorithm that uses time series of sentinel 1 data and ancillary data such as a plant water content map as inputs a secondary software module generates the plant water content map from optical data provided by landsat 8 or sentinel 2 or modis each output of mulesme includes another map showing the level of uncertainty of the soil moisture estimates mulesme was tested by using both synthetic and actual data the results of the tests showed that root mean square error is in the range between 0 03 m3 m3 synthetic data and 0 06 m3 m3 actual data for bare soil the accuracy decreases in the presence of vegetation root mean square in the range 0 08 0 12 m3 m3 as expected keywords soil moisture sentinel 1 multi temporal algorithm plant water content landsat 8 sentinel 2 modis software availability name of software mulesme multitemporal least square moisture estimator developer luca pulvirenti cima research foundation via a magliotto 2 17100 savona italy luca pulvirenti cimafoundation org first year available 2016 programming language idl required hardware 16 gb ram minimum supported systems windows linux required software idl envi mulesme was designed and tested using the envi 5 4 1 version the modis conversion toolkit must be used to process modis data if used the freely available esa sentinel application platform snap must be used for the pre processing of sentinel 1 data availability mail to luca pulvirenti cimafoundation org to request the idl envi source code of mulesme a set of test data can be provided too license envi idl commercial license harris geospatial 1 introduction the role of soil moisture sm as a key variable for the characterization of the global climate is widely recognized within the international scientific community surface sm controls the partitioning of available energy at the ground surface into latent and sensible heat exchange through evaporation and transpiration processes anagnostopoulos et al 2017 petropoulos and mccalmont 2017 furthermore the sm content of the root zone regulates the redistribution of precipitation into infiltration runoff storage in the root zone and percolation into deeper ground water storage sheikh et al 2009 coarse resolution 25 50 km sm estimates provided by satellite microwave radiometers or scatterometers are useful in support of numerical weather prediction climate monitoring and flood forecasting brocca et al 2017 hornacek et al 2012 high resolution 0 1 1 km products obtained from synthetic aperture radar sar data can be useful even for applications such as monitoring of agricultural yield at field level or irrigation management hornacek et al 2012 although c band is not the ideal frequency for soil moisture retrieval applications being also sensitive to soil roughness and the presence of vegetation fascetti et al 2016 the availability of six day repeat sentinel 1 s1 c band sar data currently represents the only opportunity to systematically produce surface depth of 5 cm sm maps at high spatial resolution recent literature studies demonstrated that s1 data can be suitable for sm mapping balenzano et al 2012 hornacek et al 2012 paloscia et al 2013 pierdicca et al 2014 nonetheless the systematic use of s1 data for providing end users with an operational sm mapping service poses two problems the first one regards the accuracy of sm estimates because sm retrieval from sar data is an ill posed problem in fact even considering the most favorable condition i e a bare terrain sar measurements are sensitive not only to sm but also to soil roughness marzahn et al 2012 and are also very noisy because of the speckle noise characteristic of any sar image this problem was dealt with in the literature by developing multi temporal retrieval algorithms balenzano et al 2011 hornacek et al 2012 kim et al 2012 pierdicca et al 2010 which assume that the temporal scale of variation of soil roughness is considerably slower than that of sm hence if a dense time series of sar data is available as expected using s1 short term changes in the backscattering coefficient σ0 that represents the sar measurement are basically related to sm variations balenzano et al 2011 the situation is further complicated by the dependence of σ0 on biomass parameters as well as plant structure and geometry if vegetation is present to correct for the vegetation influence on σ0 simple semi empirical models such as the water cloud model attema and ulaby 1978 using few bulk parameters such as the plant water content w are commonly used in the literature these models can be easily inverted to discriminate the soil contribution to the sar measurement from that related to vegetation but require reliable data about the bulk parameters various studies demonstrated the potential of retrieving w from optical images in particular using semi empirical relationships between w and the normalized difference vegetation index ndvi e g jackson et al 1999 liu and shi 2016 pierdicca et al 2010 however it must be underlined that tackling the effects of vegetation is still a challenge for any estimation approach because semi empirical models may lack of generality in the literature accuracies in the order of 0 04 0 13 m3 m3 root mean square error rmse are reported e g hajnsek et al 2009 for sm retrieval from sar but these scores often refer to specific test sites and or case studies in which multi frequency or fully polarimetric data see section 4 2 were available using s1 data at large e g national scale even higher rmse can be expected especially if sar observations are performed under dense vegetation conditions so that the need to improve the quality of sm estimates for instance by assimilating them into a hydrological model e g brocca et al 2012 cenci et al 2016a clearly emerges it should also be pointed out that in areas where w is very high as well as in forested and urban areas and in areas with complex topography sm retrieval from sar is unfeasible so that the corresponding maps have gaps i e masked areas the second problem connected to the systematic use of s1 data for designing a sm mapping service is related to the more general need of developing software tools that allow the community to really take advantage of the progresses achieved in earth observation eo technology examples of these tools are those developed by petropoulos et al 2013 for the pre processing of the spinning enhanced visible and infrared imager seviri data keramitsoglou et al 2006 for sar based oil spill detection boni et al 2016 and martinis et al 2015 to produce sar based maps of flooded areas for what concerns sm retrieval the need of eo based software tools was recently highlighted by srivastava 2017 and petropoulos et al 2015 tischler et al 2007 designed a gis tool to integrate sm predictions from a land surface model with eo measurements this paper presents mulesme multitemporal least square moisture estimator a software implementing an automated processing chain designed for an operational sar based service whose aim is the production of daily high resolution 500 500 m2 sm maps at national italian scale the paper is focused on the design of the software and does not propose a new sm retrieval algorithm note that an operational sar based sm mapping service does not exist to date and this prevents potential users from fully exploiting the advances achieved in retrieving sm or at least its variations from short revisit s1 data hence a paper presenting a software able to implement this kind of service by systematically producing an updated high resolution sm map as soon as new s1 images are available represents a novel contribution to the literature besides hydrologists and meteorologists potential users interested in this software may be authorities or government agencies at national scale to monitor either antecedent soil wetness conditions in case of flood alert issues teng et al 2017 or water resources consumption in areas affected by droughts even agricultural managers could be interested in a sm mapping service in order to get timely information about water requirements of the soil flores carrillo et al 2017 to our knowledge a high resolution sm mapping service was never proposed in the literature as previously pointed out a near real time sm distribution service is implemented by the european organization for the exploitation of meteorological satellites eumetsat using low resolution advanced scatterometer ascat data wagner et al 2013 the european space agency esa recently released the soil moisture ocean salinity smos level 2 soil moisture near real time neural network data product rodriguez fernandez et al 2015 even in this case the spatial resolution is in the order of tens of km mulesme uses as input data time series of s1 interferometric wide swath products see section 2 1 as well as ancillary data namely a land cover map topographic slope information local incidence angle maps and a map representing the state of the vegetation the latter is generated by a secondary processor that uses optical data landsat 8 sentinel 2 modis as inputs the software was implemented using the idl language and the envi routines that can be launched by means of specific idl instructions it was developed within the framework of the mida italian acronym of maps of soil moisture for hydrologic data assimilation project funded by the italian space agency asi and the wasdi web based asi spatial data infrastructure project funded by the european space agency esa on behalf of asi in particular the software was firstly designed in the framework of the mida project whose aim is the generation of sm maps through the assimilation of s1 derived estimates into a hydrological model in the near future mulesme will be installed in the wasdi platform connected to the italian sentinel collaborative ground segment coll it in order to exploit the coll it storage capability and its computing resources without the need of moving big amounts of data towards the processors section 2 gives an overview on sentinel 1 data and describes the algorithms that are implemented in mulesme to retrieve sm estimate w and correct for the effects of vegetation section 3 describes in detail mulesme while the results of some tests are discussed in section 4 section 5 gives some indications about the future developments of mulesme and finally section 6 draws the concluding remarks 2 data and methods this section firstly provides a brief overview on sentinel 1 data then it describes the methods derived from past literature studies and adapted to be implemented in the proposed system used to retrieve sm from c band s1 images estimate the status of the vegetation from optical data and single out the soil contribution related to soil moisture and roughness to the s1 measurements thus correcting for the effects of vegetation on c band σ0 2 1 sentinel 1 data sentinel 1 is a two satellite constellation with the prime objectives of land and ocean monitoring the payload of sentinel 1 is a synthetic aperture radar working at c band 5 4 ghz that provides continuous imagery day night and all weather the sar instrument operates in stripmap interferometric wide swath extra wide swath and wave modes the interferometric wide swath iws is the default acquisition mode over land it acquires data with a swath width of 250 km at a spatial resolution of 5 20 m2 single look sentinel data products are made available systematically and free of charge to all data users through the copernicus open access hub previously known as sentinels scientific data hub dhus whose web address is https scihub copernicus eu dhus for the italian territory sentinel data are also available through the italian sentinel collaborative data hub http collaborative mt asi it the proposed software makes use of s1 level 1 ground range detected grd products spatial resolution of 20 20 m2 available in dual polarization vv vh for the iws mode according to the terrain observation with progressive scans sar topsar technique de zan and monti guarnieri 2006 iws mode captures three sub swaths and the iws beams have an incidence angle between 29 16 sub swath 1 at maximum orbit altitude and 46 sub swath 3 at minimum orbit altitude considering both satellites of the constellation the revisit time of s1 images is six days 2 2 retrieval of soil moisture from sentinel 1 data the algorithm used to estimate soil moisture is based on a multi temporal maximum likelihood ml approach e g kim et al 2012 used to invert a direct model of backscattering from a bare soil hence the need to discriminate the soil contribution to the radar backscatter before running the algorithm among the numerous bare soil backscattering models available in the literature that proposed by oh 2004 was selected hereafter denoted as oh model with respect to the previous versions of the oh model the distinctive characteristic of the version published in 2004 is that it uses only the surface height standard deviation s cm to represent soil roughness the various versions of the oh model were validated against real c band data by álvarez mozos et al 2007 baghdadi and zribi 2006 khabazan et al 2013 merzouki et al 2010 any forward backscattering model relates the state of the soil represented by the pair sm s in this case to the backscattering coefficient σ0 in the proposed processing chain this relationship is represented in the form of lookup table lut kim et al 2012 pierdicca et al 2013 2014 which was generated by applying the oh model considering as inputs 50 values of s between 0 5 e 4 5 cm with a discretization of 0 0816 cm 100 values of sm between 0 05 e 0 4 m3 m3 with a discretization of 0 0035 m3 m3 and 13 values of incidence angle θ between 26 and 50 with a discretization of 2 the range of sm and s values is approximately the same as used by pierdicca et al 2013 2014 and accounts for the range of validity of the oh model as for the θ range with respect to the iws nominal incidence angle range see section 2 1 a larger interval was considered for the lut to account for topography for each pair sm s 13 values of σ0 at vv polarization one for each θ value were computed they are indicated as σ vv model 0 so that the lut contains 65000 records 13 θ 100 sm 50 s the choice of using 100 values of sm 50 values of s and 13 values of θ to generate the lut basically represents a trade off between efficiency and accuracy using this lut in the retrieval algorithm it was possible to achieve an accuracy of 0 03 0 06 m3 m3 rmse over bare soil see section 4 thus meeting the requirement 0 05 m3 m3 given by the world meteorological organization wmo for sm products see pierdicca et al 2014 moreover it was found that the use of a more finely resolved lut i e a larger number of records does not give rise to a significant decrease of the rmse but implies an increase of the computational time the lut was generated once and for all in the design phase of the software the oh model produces also σ0 at vh and hh polarizations the latter is not included in the lut because the default co polarized channel of s1 is vv while although s1 iws generally acquires cross polarized vh measurements too see section 2 1 they are not used for sm retrieval being often very low and very sensitive to soil roughness and the presence of vegetation canopy e g richards 2009 vh measurements and simulations are only used to distinguish between vegetation that attenuates the c band radar signal and vegetation that produces an increase of σ0 due to the preponderance of scattering effects see section 2 3 mulesme is the acronym of multitemporal least square moisture estimator in fact the retrieval algorithm assumes that a time series of m 1 measurements at the current time t and at m previous times t 1 t m is available it is based on the minimization of the square difference between measured and modeled values of σ0 i e on a least square search kim and van zyl 2009 1 d s m t s m t 1 s m t m s θ σ v v s o i l 0 t d b σ v v m odel 0 s m t s θ d b 2 σ v v s o i l 0 t 1 d b σ v v m odel 0 s m t 1 s θ d b 2 σ v v s o i l 0 t m d b σ v v m odel 0 s m t m s θ d b 2 where d is the cost function that has to be minimized and symbol d b indicates that the backscatter values are expressed in logarithmic units in 1 σ vv soil 0 refers to the soil contribution to the s1 measurements so that the effects of vegetation have to be corrected before determining the cost function d according to the hypothesis that the temporal scale of variation of s is considerably slower than that of sm the unknowns in 1 are one value of s assumed as constant in the time interval t t m and m 1 values of sm following kim et al 2012 the minimization of d is accomplished by firstly retrieving s and then for the selected s value by finding the m 1 values of sm that individually minimize each addend of 1 details in section 3 2 3 in this way increases and decreases of σ0 are related to increases and decreases of sm because according to the oh model σ0 is an increasing monotonic function of sm for specific s and θ values hence temporal variations of sm are basically estimated as pointed out in the introduction the choice of m is a tradeoff between sm estimation accuracy and computational time in agreement with the findings of pierdicca et al 2014 who used a different multi temporal algorithm m 4 was chosen more details about this choice are provided in section 4 1 2 3 retrieval of plant water content from optical data and correction of the vegetation effects on sentinel 1 data as commonly done in the literature an approach based on semi empirical models was implemented in mulesme to correct for the vegetation effects on s1 measurements these models require data about vegetation optical data showed a great potential to derive biophysical parameters of vegetation such as w this derivation is generally accomplished by means of direct relationships between w and the ndvi defined as 2 n d v i ρ n i r ρ r e d ρ n i r ρ r e d where ρ n i r and ρ r e d are the reflectance of red and near infrared bands respectively to relate ndvi to w the relation proposed by pierdicca et al 2010 2013 was used 3 w 11 92 ndvi 2 73 kg m2 this relation is valid for ndvi 0 23 and was developed using experimental data gathered in italy an almost equal relation was obtained by paloscia et al 2013 using different data collected in italy hence 3 is suitable for mulesme that was designed to be applied for the italian territory note that if w 0 25 kg m2 the influence of vegetation on the radar signal is considered as negligible and the s1 backscatter is not corrected pierdicca et al 2013 two semi empirical models were selected for identifying the soil contribution to s1 data one for vegetation characterized by small plant constituents and another one for vegetation with bigger plant constituents the rationale is based on the results of macelloni et al 2001 who found that for crops characterized by small plant constituents narrow leaf crops the backscatter decreases as the biomass increases i e vegetation mainly attenuates the radar signal whereas the trend is the opposite in plants with bigger leaves and stems broad leaf crops for vegetation with small constituents the water cloud model attema and ulaby 1978 was chosen according to the water cloud model wcm the measured backscatter is expressed as 4a σ0 σ0 veg τ2σ0 soil 4b σ0 veg awcosθ 1 τ2 4c τ2 exp 2bwsecθ where a and b are empirical coefficients according to 4a the backscatter from vegetated terrains is the sum of the contributions of vegetation σ0 veg related to the plant water content and soil σ0 soil the latter being attenuated by the two way vegetation transmissivity τ2 the interactions involving soil and vegetation are usually neglected in the wcm for the coefficients of 4b and 4c the values obtained by bindlish and barros 2001 for all land uses a 0 0012 and b 0 091 were selected these values were derived considering agricultural fields where vegetation was at moderate stage of growth according to the wcm when the term σ0 veg is considerably larger than τ2σ0 soil the backscatter is determined by w and tends to be insensitive to sm however joseph et al 2010 demonstrated that even at peak biomass the backscatter response to sm can be notable because of the scattering along the soil vegetation pathway that may become significant for some vegetation species e g corn and includes information on sm they developed the ratio method rm whose reliability was assessed also by fascetti et al 2017 the rm expresses the radar measurements as 5 σ0 soil σ0 cw 2 exp dw where c and d are again empirical coefficients actually for c band joseph et al proposed to add another empirical coefficient to the 2nd member of 5 however this addition applies only for small incidence angles 15 while the range of θ considered here is between 26 and 50 see sections 2 1 and 2 2 since joseph et al provided values of c and d only for 15 35 and 55 for the other angles c and d were determined by interpolating the aforementioned three values with a 2nd order polynomial thus obtaining c 6 25 10 6 θ l 2 0 00111θ l 0 0533 and d 8 55 10 5 θ l 2 0 0201θ l 0 233 where θ l is the local incidence angle for the case study considered to develop the rm the maximum value of w was about 5 kg m2 above this value the retrieval of sm was therefore assumed as totally unreliable so that mulesme masks pixels where w 5 kg m2 when retrieving sm see section 3 2 3 to decide whether to apply relations 4a 4c or equation 5 to correct for the vegetation effects on s1 data i e to distinguish between vegetation characterized by small plant constituents wcm is applied and vegetation with bigger plant constituents rm is applied a threshold on the cross polarized s1 data vh polarization was used the rationale is based on the results obtained by satalino et al 2014 who used cross polarized c band envisat asar and radarsat 2 backscatter measurements normalized for the cosine of the incidence angle γ vh to discriminate vegetation that attenuates the radar signal small plant constituents from vegetation dominated by scattering according to their experimental results the γ vh signature of scattering dominated crops is generally larger than 14 db although satalino et al 2014 pointed out that the discrimination between the two kinds of vegetation can be more reliable by applying an automatic thresholding technique this kind of technique works well only if the distribution of the data is bimodal boni et al 2016 since in general the populations of pixels that attenuate and scatter the radar signal do not give rise to two distinguishable histogram peaks a fixed threshold value on γ vh was used to be consistent with the application of the oh forward backscattering model to generate the lut the histogram of γ vh was produced considering all the 65000 records of the lut see section 2 2 i e all the values of sm s and θ in the lut the histogram is shown in fig 1 it can be noted that according to the oh model in bare soil conditions γ vh is mostly less than 14 db only 5 of the lut population exceeds this value it can be therefore expected that when a significant volume scattering effect occurs γ vh 14 db in agreement with the findings of satalino et al 2014 this value was therefore chosen as a threshold above which vegetation produces dominant scattering effects when retrieving sm 4a is applied to s1 pixels where γ vh 14 db while 5 to pixels where γ vh 14 db optical and s1 data are resampled and reprojected to a common pixel size and cartographic projection see section 3 2 3 the methodology previously described based on simple semi empirical models to estimate firstly w and finally σ vv soil 0 can be considered the most suitable for a software conceived to be used in near real time operational applications because semi empirical models are simple and use few parameters and variables hence they can easily be inverted conversely the use of theoretical models of scattering from vegetation requires the knowledge of several parameters that accurately describe each vegetation species in addition these models are not easy to be inverted the weakness of the adopted methodology is the lack of generality because semi empirical algorithms are calibrated considering specific conditions and because of the use of a fixed threshold this weakness is taken into account by including in the software a module that assigns a degree of uncertainty to each estimate details in section 2 4 2 4 assignment of a degree of uncertainty to soil moisture retrievals in order to associate a degree of uncertainty to each sm estimate the following factors were considered 1 growth stage of vegetation 2 local incidence angle and slope 3 number of images n img actually used for the considered s1 image pixel to retrieve sm not always constant as explained later on fuzzy logic was applied to transform the problem of the assignation of a degree of uncertainty into a problem of determination of a degree of membership to the class of pixels whose sm est is uncertain hereafter this class will be denoted as sm est un class fuzzy logic allows for taking into account very different factors as those listed above through the combination of different rules pulvirenti et al 2014 simply speaking elements of a fuzzy set have degrees of membership to a class which are defined through membership functions whose values are real numbers between zero no membership and one maximum membership the application of the membership functions represents the so called fuzzification that in mulesme is performed through the standard z and s functions these functions will be indicated in the following as zfun x x 1 x 2 and sfun x x 1 x 2 where x is the independent variable of the function and x 1 and x 2 are the parameters of the function see fig 2 basically corresponding to threshold values to assign maximum or minimum membership to the sm est un class as for vegetation its presence implies the increase of the ill posedness of the retrieval problem and the use of semi empirical algorithms that may lack of generality it can be expected that the sm retrieval accuracy decreases with the increase of w so that sfun was used to assign a high degree of membership to the sm est un class to pixels with high w this rule was combined with another rule that assigns a high degree of membership to the sm est un class to pixels with high γ vh the rationale is that if γ vh is high vegetation likely tends to scatter the radar signal satalino et al 2014 so that the sensitivity of the s1 measurement to sm is quite low the aforementioned rules were defined and then combined in the following way 6a d w sfun w x 1 0 25 x 2 5 6b d γ sfun γ vh x 1 18 x 2 10 6c d veg max d w d γ where d w and d γ are degrees of membership pertinent to w and γ vh respectively and d veg is the degree of membership accounting for the presence of vegetation rule 6a assigns minimum membership to the sm est un class to pixels with w 0 25 kg m2 which are actually not corrected for the effects of vegetation then d w increases and becomes 1 for w 5 kg m2 that is the value above which pixels are masked and uncertainty is not defined rule 6b assigns minimum membership to the sm est un class to pixels with γ vh 18 db this value approximately corresponds to the mean of the γ vh samples in the lut γ v h l u t the assumption is that γ vh values less than γ v h l u t likely correspond to pixels that are not affected by volume scattering furthermore rule 6b assigns maximum membership to pixels with γ vh 10 db in this way the γ vh value chosen to distinguish the vegetation type 14 db see section 2 3 is exactly in the middle of the interval where d γ varies between 0 and 1 these two rules are then combined in 6c through a logical or operator which corresponds to compute the maximum between d w and d γ for what concerns local incidence angle and topography it is well known that the impact of vegetation and surface roughness on the radar measurements is lower for acquisitions at low incidence angles obviously nadir observations are not considered since sar is a side looking sensor it should also be considered that measurements over flat areas can be assumed as less uncertain than measurements carried out over areas with very complex topography these considerations were accounted for by introducing the following rules 7a d slo sfun slope x 1 2 x 2 15 7b d θ sfun θ l x 1 29 x 2 46 7c d topo max d slo d θ where again the logical or corresponding to compute the maximum between d slo degree of membership pertinent to the slope and d θ pertinent to local incidence angle is used for combining the rules rule 7a assigns minimum membership to the sm est un class to pixels where the slope extracted from a dem see section 3 2 1 is less than 2 then d slo increases and becomes 1 for a slope equal to 15 value above which the pixel is masked the rationale is that topographic relief causes not only range displacement effects but also modifications of the intensity of a sar image richards 2009 slope variations of 2 or less correspond to very small variations of the local incidence angle and hence to very small variations of the radar intensity when the slope increases θ l tends to abruptly fluctuate and this applies to the radar intensity too leading to an increase of the uncertainty of sm estimates rule 7b assigns minimum membership to pixels with θ l 29 and maximum membership to pixels with θ l 46 these two values correspond to the minimum nominal incidence angle of iws beams and the maximum nominal incidence angle of iws beams respectively see section 2 1 although for the retrieval of sm m 1 5 s1 images are expected to be available it may happen that for a given pixel a smaller number of measurements is actually used for instance because of backscatter outliers or w 5 kg m2 hence through the zfun minimum degree of membership to the class of pixels with uncertain sm est is given to pixels for which five σ0 measurements are used for the retrieval while maximum membership is given to pixels for which only one measurement is used 8 d meas zfun n img x 1 1 x 2 5 the outputs of 6c 7c and 8 have to be combined so that from the fuzzy sets that represent these outputs a single fuzzy set is derived this is done by computing the weighted average of d veg d topo and d meas 9 d pixel 0 5 d veg 0 25 d topo 0 25 d meas in 9 the largest weight 0 5 is given to the presence of vegetation that was assumed as the major source of uncertainty in the retrieval process the final operation of any fuzzy based approach is the defuzzification that assigns each element of a fuzzy set to a class according to the final membership degree pulvirenti et al 2014 it was decided to distinguish among three classes of uncertainty of the sm retrievals namely low medium and high this was carried out by simply dividing the range spanned by d pixel in three intervals 10a high uncertainty 2 3 d pixel 1 10b medium uncertainty 1 3 d pixel 2 3 10c low uncertainty 0 d pixel 1 3 3 the software 3 1 the secondary processor the secondary software module generates one of the inputs of mulesme i e an updated w map the input of this module hereafter indicated also as optical processor consists of images acquired by multi spectral optical sensors at present landsat 8 l8 level 1 precision terrain l1tp data are mainly used but nothing prevents the user from using also sentinel 2 s2 level 1c products a recent paper mandanici and bitelli 2016 showed that in most cases the two sensors can be well combined but their combination to create a unique dataset of optical data is beyond the scope of this work alternatively even the 16 day repeat modis ndvi data mod13q1 product see huete et al 2011 can be directly used mulesme assumes a directory structure as the one shown in fig 3 optical data are stored in a directory mulesme opticaldir that on its turn contains two subdirectories for every kind of optical data l8newdir and l8olddir s2newdir and s2olddir modisnewdir and modisolddir see the central panel of fig 3 the optical processor searches on a daily basis for the presence of new images in the l8newdir s2newdir and modisnewdir these directories contain the optical data downloaded from the respective catalogues i e u s geological survey earth explorer for l8 copernicus open access hub or italian sentinel collaborative data hub for s2 and the level 1 and atmosphere archive distribution system laads distributed active archive center daac for modis l8 and s2 data are assumed to be in geotiff format and the mod13q1 product is in hdf format they do not require any preprocessing except unzipping if necessary when one or more new images are found they are processed in sequence if the mod13q1 product is not used the processing consists of firstly deriving the ndvi equation 2 since the presence of clouds totally modifies the ndvi value of an image pixel thus producing outliers the fmask algorithm zhu et al 2015 zhu and woodcock 2012 available through envi is preliminarily applied to discriminate and mask clouds finally for the non masked pixels w is computed by applying 3 and the w map is updated by inserting the new plant water content values instead of the old values this map is placed in the opticaldir see the central panel of fig 3 and is in envi format if no new optical imagery is available or only cloudy pixels are found the w map is not updated and the last available values for w are used in this way the optical data processor provides mulesme with the latest possible information about the state of the vegetation to cope with the different spatial domains and pixel sizes of optical images and s1 iws images the vegetation map is resampled and reprojected to a common output projection and pixel size by exploiting the envi layer stacking tool this operation requires choosing a master product used as geographic reference for cartographic projection and pixel size since the proposed software was conceived to operate at national scale for the italian territory the image derived from the rasterization of the shapefile representing the italian land cover according to the corine land cover 2012 available at http land copernicus eu pan european corine land cover clc 2012 was used as master product this image also used as land cover lc map see section 3 2 1 has projection utm 32 and datum wgs 84 the pixel size is about 100 100 m2 the lc map was generated once and for all during the implementation phase of the software it is shown in fig 4 that includes also the result of the projection of a w map to the geographic reference it is foreseen that when updated land cover data will be released in the frame of the corine project they will be used by mulesme although for figure clarity the right panel of fig 4 displays the w map derived from only one single optical image this map is actually composed of a mosaic of maps derived by processing l8 and or s2 and or modis observations of the whole italian territory as soon as they are available note that l8 and the mod13q1 product have a revisit time 16 days which is suitable to monitor the phenological cycle of vegetation a significantly better temporal resolution 5 days can be achieved using both satellites of the s2 constellation mulesme was designed to be routinely run in a scheduled manner once a day firstly the secondary optical processor verifies the availability of new optical images and if so updates the vegetation map then if new s1 data are available mulesme produces new sm estimates and generates a sm map at national scale see section 3 2 3 3 2 mulesme the workflow of the mulesme software is shown in fig 5 the software basically accomplishes the following operations 1 reads all the data necessary to generate the output maps 2 resizes the data 3 corrects the effects of vegetation on c band s1 data 4 masks the pixels where the retrieval is unfeasible 5 runs the multi temporal sm retrieval algorithm and applies a low pass filter to the resulting sm maps 6 assigns a degree of uncertainty to each pixel of the map 3 2 1 the input data input data are i1 a set of m 1 s1 images i2 a set of maps of local incidence angle θ l i3 a land cover lc map i4 a map of topographic slope i5 the w map produced by the secondary processor inputs i1 are calibrated backscattering data in m2 m2 produced by applying the freely available esa sentinel application platform snap software tool to the s1 grd products downloaded from the copernicus open access hub or the italian sentinel collaborative data hub for this purpose the following operations have to be carried out using snap 1 apply orbit file 2 thermal noise removal 3 calibration 4 multi looking to obtain a 100 100 m2 square pixel 5 terrain correction utm wgs84 projection should be chosen snap can also be used to generate the local incidence angle maps inputs i1 are in the beam dimap format the default snap output format which is envi conform and refer to a single s1 slice in fact for any track s1 level 1 products are segmented into slices for the purpose of data manageability each slice is a stand alone product that can be processed independently inputs i2 are in envi format more details in section 3 2 2 inputs i3 i5 are maps at national scale with a pixel size of 100 100 m2 georeferenced in utm wgs84 projection the lc and the slope maps are required to have the same number of lines and columns the current release of mulesme assumes the level 3 corine code for the lc map mulesme reads the input data from three directories see the left panel of fig 3 1 directory that contains the s1 new i e not already processed data at vv and vh polarizations produced by the snap tool hereafter denoted as snapnewdir 2 directory that contains the ancillary data i e inputs i2 i4 denoted as ancillarydir 3 the opticaldir where optical processor saves the w map in addition mulesme uses other two directories where s1 data are temporarily saved i e s1newdir and s1previousdir details in the following 3 2 2 preliminary operations since the software works at national scale it has to process several files related to different slices however in the grd product filename there is no information about what slice is being processed and on its geographical location hence the automatic identification of every single slice should be carried out slice identification and change of the filename box in fig 5 this operation is accomplished by taking advantage of information that can be derived from the product metadata as a the relative orbit number which is the same over time as opposed to the absolute orbit number b the map coordinates of the center scene pixel that may slightly vary over time for this purpose the filename of any calibrated and geocoded grd product generated by snap and saved in the snapnewdir is automatically modified by mulesme by adding the suffix orb lat lon where orb is the relative orbit lat is the latitude of the center scene pixel and lon is the longitude of the center scene pixel for this purpose mulesme searches in the ancillarydir for all the files containing the local incidence angle maps θ l filename lia orb lat lon then it selects the θ l file whose relative orbit is the same as that of the considered grd product and whose coordinates of the center scene pixel are the closest to those of the considered grd product it is worth pointing out that the possible s1 relative orbits and coordinates of the center scene pixels of the slices covering the italian territory are known a priori because of the use of iws products for instance for what concerns the morning passes descending orbits over the italian territory the relative orbit numbers and the coordinates of the pixel centers are reported in table 1 note that morning passes are preferable for sm retrieval because in the morning the thermal equilibrium of surface and vegetation can be reached van der velde et al 2014 the use of iws products allowed us to generate the θ l maps ones and for all during the design phase of mulesme for this purpose the snap tool was firstly used since all the θ l maps produced by snap have the same filename localincidenceangle img the latter was changed according to the formalism lia orb lat lon and saved in envi format fig 6 shows the θ l map for the slice identified by the tern orb i lat i lon i 66 44 8 8 1 see table 1 it is worth mentioning that in case a mulesme user has to process a single s1 slice anywhere outside italy he she has just to put in the snapnewdir ancillarydir and opticaldir the s1 and ancillary data of his her interest see the beginning of section 3 2 for the input data requirements it is understood that in this case the software does not work at national scale but at the spatial scale of the s1 slice hence only one θ l map is needed mulesme checks at a daily interval the presence of new files in the snapnewdir and if one or more files are found their names are modified before starting the actual sm retrieval the files with the new filenames are automatically saved by mulesme in the s1newdir whereas the original beam dimap file is moved in the snapolddir see the left panel of fig 3 hereafter the total number of θ l maps in the ancillarydir will be indicated as n lia mulesme loops through the n lia filenames corresponding to the values of relative orbit latitude and longitude listed in table 1 if s1 morning passes are considered and for each tern orb i lat i lon i i 1 n lia searches in s1newdir for a filename ending with orb i lat i lon i when a s1 file that ends with orb i lat i lon i is found in the s1newdir mulesme searches in the s1previousdir for the files whose name ends with the same suffix note that these files can be at the most m 4 see section 2 2 because as soon as a file in the s1newdir is processed it is moved in the s1previousdir and if after this cut and paste operation in the latter directory the number of files ending with orb i lat i lon i is greater than 4 the oldest is deleted after having read the s1 files and the corresponding θ l map see section 3 2 1 mulesme reads also the lc map the map of the topographic slope and the w map analogously to the lc map and the maps of θ l relative to the various slices that cover the italian territory even the map of topographic slope was generated once and for all during the design phase of the software firstly the freely available srtm dem was resampled and projected to the reference projection and pixel size then the envi topographic modeling tool was used to extract the slope once all the mulesme input data are stored in memory they are resized to the spatial domain of the considered slice orb i lat i lon i data resize box in fig 5 then mulesme reads the lut which is represented by an ascii file lut oh04 f5 4 txt placed in the ancillarydir right panel of fig 3 at this point all the data necessary to compute the cost function d equation 1 for the non masked pixels of the considered slice are available before computing the cost function the correction of the vegetation effects is carried out see the corresponding box in fig 5 let us consider a s1 image at current time t directory s1newdir γ vh is firstly computed in order to choose which model wcm or rm has to be used to correct for the effects of vegetation see section 2 3 note that this correction is performed only if w 0 25 kg m2 otherwise the terrain is assumed as bare pierdicca et al 2013 the image at vv polarization produced after applying the correction of the vegetation effects is then stored in memory for the computation of the cost function 1 and saved in s1previousdir so that s1previousdir contains vv data that are already corrected for the vegetation effects 3 2 3 generation and filtering of the soil moisture map the size of a s1 image multi looked to obtain a pixel size of 100 100 m2 see section 3 2 1 is in the order of 2800 2900 2000 2500 pixels for the purpose of data manageability and to avoid an excessive memory usage the m 1 images used to generate the sm map for a specific s1 slice are firstly split in spatial subsets formed by 500 500 pixels as done by pulvirenti et al 2014 then the masking of the pixels of the considered subset where sm retrieval is unfeasible is performed see the image splitting data masking box in fig 5 both lc and slope maps are used to mask areas where the sm estimate is not feasible in particular mulesme masks urban areas forests water bodies identified by their corine codes see the caption of fig 4 as well as pixels with complex topography identified as those where slope is greater than 15 in addition pixels with w 5 kg m2 see section 2 3 and pixels where θ l is less than 24 minimum incidence angle in the lut minus 2 db of tolerance or larger than 52 maximum incidence angle in the lut plus 2 db of tolerance are also masked to avoid outliers even pixels whose backscatter at vv polarization is less than 19 db likely corresponding to pixels covered by water or frozen soil or even wet snow or larger than 2 db likely corresponding to urban areas or forests are masked pierdicca et al 2014 with respect to previous works regarding sm retrieval from sar the use of s1 data to produce sm maps implies that the large difference between far range and near range incidence angles see section 2 1 which is characteristic of iws products should be taken into account for each pixel of the considered spatial subset the incidence angle value in the lut θ lut that is most similar to θ l is identified successively a secondary map of local incidence angle θ l2 whose possible values are only those included in the lut is produced then mulesme loops through the 13 values of θ lut see section 2 2 and for a given value θ lut h h 1 13 all the pixels of the considered subset having θ l2 θ lut h are simultaneously processed as done by kim et al 2012 to generate the sm maps the roughness s assumed to be the same for the various addends of 1 is firstly estimated to this aim all the possible values of s in the lut are considered and for each s the soil moisture values in the lut that minimize each addend of 1 individually are computed they are denoted as sm m i i t t m the sum of those addends represents the minimum cost function for the considered s value hence denoting by s a generic value of s in the lut d min s is given by 11 d min s σ v v s o i l 0 t d b σ v v m odel 0 s m m t s θ l 2 d b 2 σ v v s o i l 0 t 1 d b σ v v m odel 0 s m m t 1 s θ l 2 d b 2 σ v v s o i l 0 t m d b σ v v m odel 0 s m m t m s θ l 2 d b 2 where 12 s m m i s m σ v v s o i l 0 i d b σ v v m odel 0 s m i s θ l 2 d b 2 min σ v v s o i l 0 i d b σ v v m odel 0 s m i s θ l 2 d b 2 i t t m by combining the various d min s for the different values of s in the lut the cost function for the estimation of s is determined by denoting this function as d s the estimated value of s s est is the s value in the lut that minimizes d s the sm estimates sm est at times t t 1 t m are the sm values in the lut obtained when deriving d min s est kim et al 2012 i e the values obtained through 12 when s s est after having performed the procedure described above for every spatial subset of the considered slice the sm map is finally produced from 12 it can be deduced that not only the sm map at current time t but also m maps at previous times may be produced since the service was conceived to provide the end users with daily data only the map at current time t is used to generate the mulesme output to avoid providing the end users e g the italian civil protection department with a noisy map and considering that the sm maps are conceived to be assimilated into a hydrological model a low pass filter with a 5 5 kernel is applied see the filtering box in fig 5 consequently the actual resolution of the sm maps is in the order of 500 500 m2 the rationale is that this resolution is the same of hydrological model that will be used for the future assimilation of the s1 derived sm maps see section 5 note that this filtering process is not equivalent to perform a further multi look of the original images because the masking procedure applied to the data before carrying out the sm retrieval reduces the risk that the filtering process mixes up pixels where estimating sm is not feasible with non masked pixels the filtered map is saved in geotiff format an example of daily august 02 2016 national sm map is shown in the upper left panel of fig 7 it is composed by a collection of maps derived by processing single s1 slices belonging to relative orbit 95 lower panel of fig 7 which corresponds to the only s1 overpass of italy on august 02 2016 the area highlighted by the blue box in the upper left panel of fig 7 is shown in the upper left panel of fig 8 which includes also the associated histogram upper central panel and the lc map upper right panel the spatial variability of sm with respect to the land cover can be noted most of the yellow pixels in the right panels belong to the non irrigated arable land corine class the lower panels of fig 8 are the same as the upper panels but for a different level of zoom any daily national sm map is associated to a daily map representing the level of uncertainty low medium or high of the estimates this map is produced by mulesme after the generation of the sm map by applying the fuzzy logic approach described in section 2 4 the upper right panel of fig 7 shows the uncertainty map associated to the map in the upper left panel even the uncertainty map is saved in geotiff format a personal computer operative system windows 10 with an intel core i7 cpu 4 cores and 32 gb ram was used for testing the mulesme processing time the time required to produce an updated w map i e the running time of the secondary processor ranged from about 15 s for modis 250 250 m2 of resolution to 4 min for l8 30 30 m2 of resolution and 10 min for s2 10 10 m2 of resolution as for the s1 processor using a series of five s1 images for the multi temporal retrieval of sm the processing time was in the order of 25 30 min depending on the number of the masked pixels hence in our tests the total processing time varied between 25 and 40 min 4 tests 4 1 test on simulated data bare soil a first test of the proposed software was carried out by simulating a time series of ten synthetic c band sar multi looked images representing a schematic scene of different homogeneous bare fields having different values of sm and s to generate the simulations the oh model was applied by assuming for each field a constant s over time whereas sm was supposed as randomly varying in time to the synthetic images the multi temporal sm retrieval algorithm described in section 2 2 was applied for the retrieval at time t i i 2 10 all the images acquired at times t j t i j 1 9 j i were used too the results are shown in fig 9 in terms of correlation coefficient r between retrieved and reference data those used to simulate the sar observations and rmse plotted in function of the number of processed images equal to m 1 i e the image at current time t plus m images acquired before the current one see section 2 2 it can be seen that the retrieval performances significantly improve r increases and rmse decreases until m 1 5 this demonstrates the potentiality of a multi temporal approach for m 1 5 the trends of r and rmse tend to oscillate this explains the choice of m 4 see section 2 2 which seems to be the best compromise between accuracy and efficiency this result confirms that obtained by pierdicca et al 2014 who performed a similar exercise using a different multi temporal algorithm looking at fig 9 it can be noted that for m 1 5 very good results were obtained for the sm retrieval accuracy i e r 0 96 and rmse 0 03 m3 m3 it must be underlined that this test regarded a favorable situation i e sar observations of bare fields and backscatter measurements within the expected range of values 4 2 test on experimental data vegetated soils although the software was conceived to be applied for the italian territory nothing prevents a user from running mulesme for different geographic areas as pointed out in section 3 2 2 hence the experimental data derived from the esa agrisar 2006 campaign balenzano et al 2011 hajnsek et al 2009 whose principal objective was to assess the impact of esa sentinel 1 and 2 missions for land applications were used to perform a second test of the retrieval algorithm the campaign was carried out over the demmin agricultural site in northern germany during the period april 19 july 26 2006 encompassing the vegetation growing season and providing sar and ground truth data acquired almost weekly among the airborne sar measurements performed during the agrisar 2006 campaign only c band data were provided us within the framework of a past project funded by esa namely the gmes sentinel 1 soil moisture algorithm development these data were acquired by the experimental sar e sar airborne system eleven dual polarization vv vh acquisitions were used to carry out the test of the algorithm in order to be consistent with s1 iws observations see section 2 1 their dates are april 19 may 3 11 16 24 june 7 13 21 july 5 12 26 in this case plant water content was directly derived from ground truth data the latter included surface sm field measurements as well which were gathered almost simultaneously to the radar measurements different fields where different crop types were present were monitored during the agrisar 2006 campaign those considered in this test are reported in table 2 that includes also the indication on the local incidence angle of e sar c band observations w was quite low in april less than 1 kg m2 except for rape fields when some fields were still bare then it rapidly increased reaching and even exceeding the value of 5 kg m2 above which data are masked by mulesme this occurred already in may for rape fields and in june july for the other fields for rape barley and wheat fields w reached its maximum and the end of june beginning of july and then decreased while for maize and sugar beet it constantly increased from the beginning of june to the end of the campaign for the whole agrisar 2006 dataset available for this test the rmse was quite high 0 12 m3 m3 because the presence of vegetation at an advanced stage of growth in june july 2006 had a big impact on the accuracy of the retrievals note that in previous works using agrisar 2006 data to assess sm retrieval algorithms l band less sensitive to vegetation than c band fully polarimetric measurements four channels i e vv hv vh hh where not only amplitudes but also relative phases are measured were mostly used with this kind of data hajnsek et al 2009 obtained rmse in the range 0 03 0 14 m3 m3 however s1 does not have fully polarimetric capabilities and works at c band on the other hand s1 represents the only sar sensor currently in operation that has a revisit time compliant with the timeliness requirements of operational sm applications in the order of five days see pierdicca et al 2014 so that it is worthwhile to focus on this sensor to design a large scale sm mapping service considering only retrievals with low or medium level of uncertainty the results significantly improve see fig 10 with r 0 6 and rmse 0 08 m3 m3 this demonstrates that the level of uncertainty computed as described in section 2 4 can be a useful proxy to indicate that the ill posedness of the sm retrieval problem mostly due to the presence of developed vegetation is such to produce estimates with low accuracy a rmse in the order of 0 08 m3 m3 represents a value aligned with those found in the literature for sar observations performed when the soil is vegetated see section 1 note that considering only the few cases in which fields were bare o scarcely vegetated w 0 25 kg m2 a rmse equal to 0 06 m3 m3 was obtained a value that almost meets the accuracy target recommended by wmo see section 2 2 as underlined in the introduction this paper is focused on the design of a software implementing an automated processing chain and does not propose a new algorithm to improve literature results for sm retrieval in any case nothing prevents future releases of mulesme from implementing a sm retrieval algorithm different from that described in section 2 2 if it will be proved that a different algorithm produces better results the same applies for the semi empirical models described in section 2 3 to change the algorithms it is sufficient to change the soil moisture retrieval module and or the correction of vegetation effects module of the software see fig 5 the rest of the processing chain does not need any modification 5 future developments mulesme was conceived to be installed in the wasdi platform connected to the italian sentinel collaborative ground segment coll it in order to exploit the coll it storage capability and its computing resources wasdi is a project whose scope is the development of software tools for the coll it in order to foster the exploitation of the asset concerning earth observation data and satellite products it can query different catalogues such as the sentinel data hub system dhus and gives the users the possibility to immediately display the selected data or the output of a processing through a dedicated web based workspace the added value of wasdi with respect to currently existing catalogues is its capability to process the earth observation data e g sentinel 1 selected by the user directly on the server taking advantage of the coll it facilities the coll it project includes big computation resources thus enabling to run processes directly on data stored in a local cloud fig 11 shows the interface of the current release of wasdi as it appears to a user it is foreseen that once the wasdi platform will be fully operational it will allow users to sequentially perform the operations of downloading sar and optical data preprocessing sar data wasdi will implement all the snap tools useful for this purpose executing mulesme and downloading its outputs although a test of mulesme was already performed on wasdi other tests will be performed using different s1 observations before officially releasing mulesme for wasdi authorized users the main idea underpinning wasdi is to avoid the transfer of big amounts of data to the users that is to move the processing to the data rather than the data to the user wasdi will allow users to further process the outputs of mulesme in particular to improve the quality of sm estimates especially if s1 observations are performed under dense vegetation conditions it is foreseen that the sm mapping software implemented in the wasdi platform will be complemented by a module producing also a more physically consistent map through the assimilation of the retrievals into a hydrological model cenci et al 2016b through an appropriate uncertainty modeling data assimilation da allows for the optimal combination of soil moisture estimates obtained from external observations e g satellites and numerical simulations e g hydrological models in order to obtain more accurate estimates e g massari et al 2015 a time continuous spatially distributed physically based hydrological model will be used for the da namely the continuum model silvestro et al 2013 this model currently used in italy at operational level by the italian civil protection department produces maps of root zone soil moisture for the italian territory at the same spatial resolution of the s1 derived maps i e 500 500 m2 as mentioned in the introduction root zone soil moisture constitutes an important variable for hydrological and weather forecast models so that the implementation of the da scheme into the wasdi platform will enable to provide users with a more complete information about soil moisture 6 conclusions several algorithms available in the literature dealt with the problem of soil moisture retrieval using synthetic aperture radar sar data conversely the problem of the creation of a processing chain that automates the various steps needed to set up an operational soil moisture mapping service based on sar data was rarely tackled a software for accomplishing a surface soil moisture mapping service using sentinel 1 and ancillary data was presented in this paper its outputs consist of high resolution 500 500 m2 soil moisture maps daily produced at national italian scale although in principle nothing prevents a user from using the proposed service for other geographic areas a map in which the uncertainty of the estimates is characterized complements any daily soil moisture map three levels of uncertainty low medium high are considered the proposed software automates all the steps related to the systematic retrieval of soil moisture using sar data the sequential execution of these steps required manual interaction so far the core of the software is represented by a multi temporal algorithm based on previous literature studies and adapted to be used for sentinel 1 data designed to take advantage of the short revisit time of sentinel 1 images from a test of the soil moisture retrieval algorithm carried out using simulated data it emerged that under bare soil conditions its outputs are very accurate performing a second test using actual sar observations of vegetated soils it emerged that vegetation at an advanced stage of growth can have a big impact on the accuracy of the retrievals as expected the level of uncertainty turned out to be a good indicator of the estimates that have low quality because of the presence of dense vegetation to pursue the objective of an improvement of the quality and the completeness of the proposed service future work will concern the assimilation of sentinel 1 derived surface soil moisture maps in a hydrological model to produce physically based maps of root zone soil moisture the software was conceived to be installed in the wasdi platform wasdi is connected to the sentinel italian collaborative ground segment where the sentinel 1 observations of italy are stored in this way the processing will be moved to the data rather than the data to the users acknowledgements this work has been funded by the italian space agency asi 2015 018 i o in the framework of the mida project and by the european space agency esa 4000116310 15 i sbo in the framework of the wasdi project agrisar 2006 data were provided in the framework of the gmes sentinel 1 soil moisture algorithm development project funded by esa m chini contribution was supported by the national research fund of luxembourg through the inter dfg 14 02 caos 2 catchments as organised systems project 
26416,this paper presents mulesme a software designed for the systematic mapping of surface soil moisture using sentinel 1 sar data mulesme implements a multi temporal algorithm that uses time series of sentinel 1 data and ancillary data such as a plant water content map as inputs a secondary software module generates the plant water content map from optical data provided by landsat 8 or sentinel 2 or modis each output of mulesme includes another map showing the level of uncertainty of the soil moisture estimates mulesme was tested by using both synthetic and actual data the results of the tests showed that root mean square error is in the range between 0 03 m3 m3 synthetic data and 0 06 m3 m3 actual data for bare soil the accuracy decreases in the presence of vegetation root mean square in the range 0 08 0 12 m3 m3 as expected keywords soil moisture sentinel 1 multi temporal algorithm plant water content landsat 8 sentinel 2 modis software availability name of software mulesme multitemporal least square moisture estimator developer luca pulvirenti cima research foundation via a magliotto 2 17100 savona italy luca pulvirenti cimafoundation org first year available 2016 programming language idl required hardware 16 gb ram minimum supported systems windows linux required software idl envi mulesme was designed and tested using the envi 5 4 1 version the modis conversion toolkit must be used to process modis data if used the freely available esa sentinel application platform snap must be used for the pre processing of sentinel 1 data availability mail to luca pulvirenti cimafoundation org to request the idl envi source code of mulesme a set of test data can be provided too license envi idl commercial license harris geospatial 1 introduction the role of soil moisture sm as a key variable for the characterization of the global climate is widely recognized within the international scientific community surface sm controls the partitioning of available energy at the ground surface into latent and sensible heat exchange through evaporation and transpiration processes anagnostopoulos et al 2017 petropoulos and mccalmont 2017 furthermore the sm content of the root zone regulates the redistribution of precipitation into infiltration runoff storage in the root zone and percolation into deeper ground water storage sheikh et al 2009 coarse resolution 25 50 km sm estimates provided by satellite microwave radiometers or scatterometers are useful in support of numerical weather prediction climate monitoring and flood forecasting brocca et al 2017 hornacek et al 2012 high resolution 0 1 1 km products obtained from synthetic aperture radar sar data can be useful even for applications such as monitoring of agricultural yield at field level or irrigation management hornacek et al 2012 although c band is not the ideal frequency for soil moisture retrieval applications being also sensitive to soil roughness and the presence of vegetation fascetti et al 2016 the availability of six day repeat sentinel 1 s1 c band sar data currently represents the only opportunity to systematically produce surface depth of 5 cm sm maps at high spatial resolution recent literature studies demonstrated that s1 data can be suitable for sm mapping balenzano et al 2012 hornacek et al 2012 paloscia et al 2013 pierdicca et al 2014 nonetheless the systematic use of s1 data for providing end users with an operational sm mapping service poses two problems the first one regards the accuracy of sm estimates because sm retrieval from sar data is an ill posed problem in fact even considering the most favorable condition i e a bare terrain sar measurements are sensitive not only to sm but also to soil roughness marzahn et al 2012 and are also very noisy because of the speckle noise characteristic of any sar image this problem was dealt with in the literature by developing multi temporal retrieval algorithms balenzano et al 2011 hornacek et al 2012 kim et al 2012 pierdicca et al 2010 which assume that the temporal scale of variation of soil roughness is considerably slower than that of sm hence if a dense time series of sar data is available as expected using s1 short term changes in the backscattering coefficient σ0 that represents the sar measurement are basically related to sm variations balenzano et al 2011 the situation is further complicated by the dependence of σ0 on biomass parameters as well as plant structure and geometry if vegetation is present to correct for the vegetation influence on σ0 simple semi empirical models such as the water cloud model attema and ulaby 1978 using few bulk parameters such as the plant water content w are commonly used in the literature these models can be easily inverted to discriminate the soil contribution to the sar measurement from that related to vegetation but require reliable data about the bulk parameters various studies demonstrated the potential of retrieving w from optical images in particular using semi empirical relationships between w and the normalized difference vegetation index ndvi e g jackson et al 1999 liu and shi 2016 pierdicca et al 2010 however it must be underlined that tackling the effects of vegetation is still a challenge for any estimation approach because semi empirical models may lack of generality in the literature accuracies in the order of 0 04 0 13 m3 m3 root mean square error rmse are reported e g hajnsek et al 2009 for sm retrieval from sar but these scores often refer to specific test sites and or case studies in which multi frequency or fully polarimetric data see section 4 2 were available using s1 data at large e g national scale even higher rmse can be expected especially if sar observations are performed under dense vegetation conditions so that the need to improve the quality of sm estimates for instance by assimilating them into a hydrological model e g brocca et al 2012 cenci et al 2016a clearly emerges it should also be pointed out that in areas where w is very high as well as in forested and urban areas and in areas with complex topography sm retrieval from sar is unfeasible so that the corresponding maps have gaps i e masked areas the second problem connected to the systematic use of s1 data for designing a sm mapping service is related to the more general need of developing software tools that allow the community to really take advantage of the progresses achieved in earth observation eo technology examples of these tools are those developed by petropoulos et al 2013 for the pre processing of the spinning enhanced visible and infrared imager seviri data keramitsoglou et al 2006 for sar based oil spill detection boni et al 2016 and martinis et al 2015 to produce sar based maps of flooded areas for what concerns sm retrieval the need of eo based software tools was recently highlighted by srivastava 2017 and petropoulos et al 2015 tischler et al 2007 designed a gis tool to integrate sm predictions from a land surface model with eo measurements this paper presents mulesme multitemporal least square moisture estimator a software implementing an automated processing chain designed for an operational sar based service whose aim is the production of daily high resolution 500 500 m2 sm maps at national italian scale the paper is focused on the design of the software and does not propose a new sm retrieval algorithm note that an operational sar based sm mapping service does not exist to date and this prevents potential users from fully exploiting the advances achieved in retrieving sm or at least its variations from short revisit s1 data hence a paper presenting a software able to implement this kind of service by systematically producing an updated high resolution sm map as soon as new s1 images are available represents a novel contribution to the literature besides hydrologists and meteorologists potential users interested in this software may be authorities or government agencies at national scale to monitor either antecedent soil wetness conditions in case of flood alert issues teng et al 2017 or water resources consumption in areas affected by droughts even agricultural managers could be interested in a sm mapping service in order to get timely information about water requirements of the soil flores carrillo et al 2017 to our knowledge a high resolution sm mapping service was never proposed in the literature as previously pointed out a near real time sm distribution service is implemented by the european organization for the exploitation of meteorological satellites eumetsat using low resolution advanced scatterometer ascat data wagner et al 2013 the european space agency esa recently released the soil moisture ocean salinity smos level 2 soil moisture near real time neural network data product rodriguez fernandez et al 2015 even in this case the spatial resolution is in the order of tens of km mulesme uses as input data time series of s1 interferometric wide swath products see section 2 1 as well as ancillary data namely a land cover map topographic slope information local incidence angle maps and a map representing the state of the vegetation the latter is generated by a secondary processor that uses optical data landsat 8 sentinel 2 modis as inputs the software was implemented using the idl language and the envi routines that can be launched by means of specific idl instructions it was developed within the framework of the mida italian acronym of maps of soil moisture for hydrologic data assimilation project funded by the italian space agency asi and the wasdi web based asi spatial data infrastructure project funded by the european space agency esa on behalf of asi in particular the software was firstly designed in the framework of the mida project whose aim is the generation of sm maps through the assimilation of s1 derived estimates into a hydrological model in the near future mulesme will be installed in the wasdi platform connected to the italian sentinel collaborative ground segment coll it in order to exploit the coll it storage capability and its computing resources without the need of moving big amounts of data towards the processors section 2 gives an overview on sentinel 1 data and describes the algorithms that are implemented in mulesme to retrieve sm estimate w and correct for the effects of vegetation section 3 describes in detail mulesme while the results of some tests are discussed in section 4 section 5 gives some indications about the future developments of mulesme and finally section 6 draws the concluding remarks 2 data and methods this section firstly provides a brief overview on sentinel 1 data then it describes the methods derived from past literature studies and adapted to be implemented in the proposed system used to retrieve sm from c band s1 images estimate the status of the vegetation from optical data and single out the soil contribution related to soil moisture and roughness to the s1 measurements thus correcting for the effects of vegetation on c band σ0 2 1 sentinel 1 data sentinel 1 is a two satellite constellation with the prime objectives of land and ocean monitoring the payload of sentinel 1 is a synthetic aperture radar working at c band 5 4 ghz that provides continuous imagery day night and all weather the sar instrument operates in stripmap interferometric wide swath extra wide swath and wave modes the interferometric wide swath iws is the default acquisition mode over land it acquires data with a swath width of 250 km at a spatial resolution of 5 20 m2 single look sentinel data products are made available systematically and free of charge to all data users through the copernicus open access hub previously known as sentinels scientific data hub dhus whose web address is https scihub copernicus eu dhus for the italian territory sentinel data are also available through the italian sentinel collaborative data hub http collaborative mt asi it the proposed software makes use of s1 level 1 ground range detected grd products spatial resolution of 20 20 m2 available in dual polarization vv vh for the iws mode according to the terrain observation with progressive scans sar topsar technique de zan and monti guarnieri 2006 iws mode captures three sub swaths and the iws beams have an incidence angle between 29 16 sub swath 1 at maximum orbit altitude and 46 sub swath 3 at minimum orbit altitude considering both satellites of the constellation the revisit time of s1 images is six days 2 2 retrieval of soil moisture from sentinel 1 data the algorithm used to estimate soil moisture is based on a multi temporal maximum likelihood ml approach e g kim et al 2012 used to invert a direct model of backscattering from a bare soil hence the need to discriminate the soil contribution to the radar backscatter before running the algorithm among the numerous bare soil backscattering models available in the literature that proposed by oh 2004 was selected hereafter denoted as oh model with respect to the previous versions of the oh model the distinctive characteristic of the version published in 2004 is that it uses only the surface height standard deviation s cm to represent soil roughness the various versions of the oh model were validated against real c band data by álvarez mozos et al 2007 baghdadi and zribi 2006 khabazan et al 2013 merzouki et al 2010 any forward backscattering model relates the state of the soil represented by the pair sm s in this case to the backscattering coefficient σ0 in the proposed processing chain this relationship is represented in the form of lookup table lut kim et al 2012 pierdicca et al 2013 2014 which was generated by applying the oh model considering as inputs 50 values of s between 0 5 e 4 5 cm with a discretization of 0 0816 cm 100 values of sm between 0 05 e 0 4 m3 m3 with a discretization of 0 0035 m3 m3 and 13 values of incidence angle θ between 26 and 50 with a discretization of 2 the range of sm and s values is approximately the same as used by pierdicca et al 2013 2014 and accounts for the range of validity of the oh model as for the θ range with respect to the iws nominal incidence angle range see section 2 1 a larger interval was considered for the lut to account for topography for each pair sm s 13 values of σ0 at vv polarization one for each θ value were computed they are indicated as σ vv model 0 so that the lut contains 65000 records 13 θ 100 sm 50 s the choice of using 100 values of sm 50 values of s and 13 values of θ to generate the lut basically represents a trade off between efficiency and accuracy using this lut in the retrieval algorithm it was possible to achieve an accuracy of 0 03 0 06 m3 m3 rmse over bare soil see section 4 thus meeting the requirement 0 05 m3 m3 given by the world meteorological organization wmo for sm products see pierdicca et al 2014 moreover it was found that the use of a more finely resolved lut i e a larger number of records does not give rise to a significant decrease of the rmse but implies an increase of the computational time the lut was generated once and for all in the design phase of the software the oh model produces also σ0 at vh and hh polarizations the latter is not included in the lut because the default co polarized channel of s1 is vv while although s1 iws generally acquires cross polarized vh measurements too see section 2 1 they are not used for sm retrieval being often very low and very sensitive to soil roughness and the presence of vegetation canopy e g richards 2009 vh measurements and simulations are only used to distinguish between vegetation that attenuates the c band radar signal and vegetation that produces an increase of σ0 due to the preponderance of scattering effects see section 2 3 mulesme is the acronym of multitemporal least square moisture estimator in fact the retrieval algorithm assumes that a time series of m 1 measurements at the current time t and at m previous times t 1 t m is available it is based on the minimization of the square difference between measured and modeled values of σ0 i e on a least square search kim and van zyl 2009 1 d s m t s m t 1 s m t m s θ σ v v s o i l 0 t d b σ v v m odel 0 s m t s θ d b 2 σ v v s o i l 0 t 1 d b σ v v m odel 0 s m t 1 s θ d b 2 σ v v s o i l 0 t m d b σ v v m odel 0 s m t m s θ d b 2 where d is the cost function that has to be minimized and symbol d b indicates that the backscatter values are expressed in logarithmic units in 1 σ vv soil 0 refers to the soil contribution to the s1 measurements so that the effects of vegetation have to be corrected before determining the cost function d according to the hypothesis that the temporal scale of variation of s is considerably slower than that of sm the unknowns in 1 are one value of s assumed as constant in the time interval t t m and m 1 values of sm following kim et al 2012 the minimization of d is accomplished by firstly retrieving s and then for the selected s value by finding the m 1 values of sm that individually minimize each addend of 1 details in section 3 2 3 in this way increases and decreases of σ0 are related to increases and decreases of sm because according to the oh model σ0 is an increasing monotonic function of sm for specific s and θ values hence temporal variations of sm are basically estimated as pointed out in the introduction the choice of m is a tradeoff between sm estimation accuracy and computational time in agreement with the findings of pierdicca et al 2014 who used a different multi temporal algorithm m 4 was chosen more details about this choice are provided in section 4 1 2 3 retrieval of plant water content from optical data and correction of the vegetation effects on sentinel 1 data as commonly done in the literature an approach based on semi empirical models was implemented in mulesme to correct for the vegetation effects on s1 measurements these models require data about vegetation optical data showed a great potential to derive biophysical parameters of vegetation such as w this derivation is generally accomplished by means of direct relationships between w and the ndvi defined as 2 n d v i ρ n i r ρ r e d ρ n i r ρ r e d where ρ n i r and ρ r e d are the reflectance of red and near infrared bands respectively to relate ndvi to w the relation proposed by pierdicca et al 2010 2013 was used 3 w 11 92 ndvi 2 73 kg m2 this relation is valid for ndvi 0 23 and was developed using experimental data gathered in italy an almost equal relation was obtained by paloscia et al 2013 using different data collected in italy hence 3 is suitable for mulesme that was designed to be applied for the italian territory note that if w 0 25 kg m2 the influence of vegetation on the radar signal is considered as negligible and the s1 backscatter is not corrected pierdicca et al 2013 two semi empirical models were selected for identifying the soil contribution to s1 data one for vegetation characterized by small plant constituents and another one for vegetation with bigger plant constituents the rationale is based on the results of macelloni et al 2001 who found that for crops characterized by small plant constituents narrow leaf crops the backscatter decreases as the biomass increases i e vegetation mainly attenuates the radar signal whereas the trend is the opposite in plants with bigger leaves and stems broad leaf crops for vegetation with small constituents the water cloud model attema and ulaby 1978 was chosen according to the water cloud model wcm the measured backscatter is expressed as 4a σ0 σ0 veg τ2σ0 soil 4b σ0 veg awcosθ 1 τ2 4c τ2 exp 2bwsecθ where a and b are empirical coefficients according to 4a the backscatter from vegetated terrains is the sum of the contributions of vegetation σ0 veg related to the plant water content and soil σ0 soil the latter being attenuated by the two way vegetation transmissivity τ2 the interactions involving soil and vegetation are usually neglected in the wcm for the coefficients of 4b and 4c the values obtained by bindlish and barros 2001 for all land uses a 0 0012 and b 0 091 were selected these values were derived considering agricultural fields where vegetation was at moderate stage of growth according to the wcm when the term σ0 veg is considerably larger than τ2σ0 soil the backscatter is determined by w and tends to be insensitive to sm however joseph et al 2010 demonstrated that even at peak biomass the backscatter response to sm can be notable because of the scattering along the soil vegetation pathway that may become significant for some vegetation species e g corn and includes information on sm they developed the ratio method rm whose reliability was assessed also by fascetti et al 2017 the rm expresses the radar measurements as 5 σ0 soil σ0 cw 2 exp dw where c and d are again empirical coefficients actually for c band joseph et al proposed to add another empirical coefficient to the 2nd member of 5 however this addition applies only for small incidence angles 15 while the range of θ considered here is between 26 and 50 see sections 2 1 and 2 2 since joseph et al provided values of c and d only for 15 35 and 55 for the other angles c and d were determined by interpolating the aforementioned three values with a 2nd order polynomial thus obtaining c 6 25 10 6 θ l 2 0 00111θ l 0 0533 and d 8 55 10 5 θ l 2 0 0201θ l 0 233 where θ l is the local incidence angle for the case study considered to develop the rm the maximum value of w was about 5 kg m2 above this value the retrieval of sm was therefore assumed as totally unreliable so that mulesme masks pixels where w 5 kg m2 when retrieving sm see section 3 2 3 to decide whether to apply relations 4a 4c or equation 5 to correct for the vegetation effects on s1 data i e to distinguish between vegetation characterized by small plant constituents wcm is applied and vegetation with bigger plant constituents rm is applied a threshold on the cross polarized s1 data vh polarization was used the rationale is based on the results obtained by satalino et al 2014 who used cross polarized c band envisat asar and radarsat 2 backscatter measurements normalized for the cosine of the incidence angle γ vh to discriminate vegetation that attenuates the radar signal small plant constituents from vegetation dominated by scattering according to their experimental results the γ vh signature of scattering dominated crops is generally larger than 14 db although satalino et al 2014 pointed out that the discrimination between the two kinds of vegetation can be more reliable by applying an automatic thresholding technique this kind of technique works well only if the distribution of the data is bimodal boni et al 2016 since in general the populations of pixels that attenuate and scatter the radar signal do not give rise to two distinguishable histogram peaks a fixed threshold value on γ vh was used to be consistent with the application of the oh forward backscattering model to generate the lut the histogram of γ vh was produced considering all the 65000 records of the lut see section 2 2 i e all the values of sm s and θ in the lut the histogram is shown in fig 1 it can be noted that according to the oh model in bare soil conditions γ vh is mostly less than 14 db only 5 of the lut population exceeds this value it can be therefore expected that when a significant volume scattering effect occurs γ vh 14 db in agreement with the findings of satalino et al 2014 this value was therefore chosen as a threshold above which vegetation produces dominant scattering effects when retrieving sm 4a is applied to s1 pixels where γ vh 14 db while 5 to pixels where γ vh 14 db optical and s1 data are resampled and reprojected to a common pixel size and cartographic projection see section 3 2 3 the methodology previously described based on simple semi empirical models to estimate firstly w and finally σ vv soil 0 can be considered the most suitable for a software conceived to be used in near real time operational applications because semi empirical models are simple and use few parameters and variables hence they can easily be inverted conversely the use of theoretical models of scattering from vegetation requires the knowledge of several parameters that accurately describe each vegetation species in addition these models are not easy to be inverted the weakness of the adopted methodology is the lack of generality because semi empirical algorithms are calibrated considering specific conditions and because of the use of a fixed threshold this weakness is taken into account by including in the software a module that assigns a degree of uncertainty to each estimate details in section 2 4 2 4 assignment of a degree of uncertainty to soil moisture retrievals in order to associate a degree of uncertainty to each sm estimate the following factors were considered 1 growth stage of vegetation 2 local incidence angle and slope 3 number of images n img actually used for the considered s1 image pixel to retrieve sm not always constant as explained later on fuzzy logic was applied to transform the problem of the assignation of a degree of uncertainty into a problem of determination of a degree of membership to the class of pixels whose sm est is uncertain hereafter this class will be denoted as sm est un class fuzzy logic allows for taking into account very different factors as those listed above through the combination of different rules pulvirenti et al 2014 simply speaking elements of a fuzzy set have degrees of membership to a class which are defined through membership functions whose values are real numbers between zero no membership and one maximum membership the application of the membership functions represents the so called fuzzification that in mulesme is performed through the standard z and s functions these functions will be indicated in the following as zfun x x 1 x 2 and sfun x x 1 x 2 where x is the independent variable of the function and x 1 and x 2 are the parameters of the function see fig 2 basically corresponding to threshold values to assign maximum or minimum membership to the sm est un class as for vegetation its presence implies the increase of the ill posedness of the retrieval problem and the use of semi empirical algorithms that may lack of generality it can be expected that the sm retrieval accuracy decreases with the increase of w so that sfun was used to assign a high degree of membership to the sm est un class to pixels with high w this rule was combined with another rule that assigns a high degree of membership to the sm est un class to pixels with high γ vh the rationale is that if γ vh is high vegetation likely tends to scatter the radar signal satalino et al 2014 so that the sensitivity of the s1 measurement to sm is quite low the aforementioned rules were defined and then combined in the following way 6a d w sfun w x 1 0 25 x 2 5 6b d γ sfun γ vh x 1 18 x 2 10 6c d veg max d w d γ where d w and d γ are degrees of membership pertinent to w and γ vh respectively and d veg is the degree of membership accounting for the presence of vegetation rule 6a assigns minimum membership to the sm est un class to pixels with w 0 25 kg m2 which are actually not corrected for the effects of vegetation then d w increases and becomes 1 for w 5 kg m2 that is the value above which pixels are masked and uncertainty is not defined rule 6b assigns minimum membership to the sm est un class to pixels with γ vh 18 db this value approximately corresponds to the mean of the γ vh samples in the lut γ v h l u t the assumption is that γ vh values less than γ v h l u t likely correspond to pixels that are not affected by volume scattering furthermore rule 6b assigns maximum membership to pixels with γ vh 10 db in this way the γ vh value chosen to distinguish the vegetation type 14 db see section 2 3 is exactly in the middle of the interval where d γ varies between 0 and 1 these two rules are then combined in 6c through a logical or operator which corresponds to compute the maximum between d w and d γ for what concerns local incidence angle and topography it is well known that the impact of vegetation and surface roughness on the radar measurements is lower for acquisitions at low incidence angles obviously nadir observations are not considered since sar is a side looking sensor it should also be considered that measurements over flat areas can be assumed as less uncertain than measurements carried out over areas with very complex topography these considerations were accounted for by introducing the following rules 7a d slo sfun slope x 1 2 x 2 15 7b d θ sfun θ l x 1 29 x 2 46 7c d topo max d slo d θ where again the logical or corresponding to compute the maximum between d slo degree of membership pertinent to the slope and d θ pertinent to local incidence angle is used for combining the rules rule 7a assigns minimum membership to the sm est un class to pixels where the slope extracted from a dem see section 3 2 1 is less than 2 then d slo increases and becomes 1 for a slope equal to 15 value above which the pixel is masked the rationale is that topographic relief causes not only range displacement effects but also modifications of the intensity of a sar image richards 2009 slope variations of 2 or less correspond to very small variations of the local incidence angle and hence to very small variations of the radar intensity when the slope increases θ l tends to abruptly fluctuate and this applies to the radar intensity too leading to an increase of the uncertainty of sm estimates rule 7b assigns minimum membership to pixels with θ l 29 and maximum membership to pixels with θ l 46 these two values correspond to the minimum nominal incidence angle of iws beams and the maximum nominal incidence angle of iws beams respectively see section 2 1 although for the retrieval of sm m 1 5 s1 images are expected to be available it may happen that for a given pixel a smaller number of measurements is actually used for instance because of backscatter outliers or w 5 kg m2 hence through the zfun minimum degree of membership to the class of pixels with uncertain sm est is given to pixels for which five σ0 measurements are used for the retrieval while maximum membership is given to pixels for which only one measurement is used 8 d meas zfun n img x 1 1 x 2 5 the outputs of 6c 7c and 8 have to be combined so that from the fuzzy sets that represent these outputs a single fuzzy set is derived this is done by computing the weighted average of d veg d topo and d meas 9 d pixel 0 5 d veg 0 25 d topo 0 25 d meas in 9 the largest weight 0 5 is given to the presence of vegetation that was assumed as the major source of uncertainty in the retrieval process the final operation of any fuzzy based approach is the defuzzification that assigns each element of a fuzzy set to a class according to the final membership degree pulvirenti et al 2014 it was decided to distinguish among three classes of uncertainty of the sm retrievals namely low medium and high this was carried out by simply dividing the range spanned by d pixel in three intervals 10a high uncertainty 2 3 d pixel 1 10b medium uncertainty 1 3 d pixel 2 3 10c low uncertainty 0 d pixel 1 3 3 the software 3 1 the secondary processor the secondary software module generates one of the inputs of mulesme i e an updated w map the input of this module hereafter indicated also as optical processor consists of images acquired by multi spectral optical sensors at present landsat 8 l8 level 1 precision terrain l1tp data are mainly used but nothing prevents the user from using also sentinel 2 s2 level 1c products a recent paper mandanici and bitelli 2016 showed that in most cases the two sensors can be well combined but their combination to create a unique dataset of optical data is beyond the scope of this work alternatively even the 16 day repeat modis ndvi data mod13q1 product see huete et al 2011 can be directly used mulesme assumes a directory structure as the one shown in fig 3 optical data are stored in a directory mulesme opticaldir that on its turn contains two subdirectories for every kind of optical data l8newdir and l8olddir s2newdir and s2olddir modisnewdir and modisolddir see the central panel of fig 3 the optical processor searches on a daily basis for the presence of new images in the l8newdir s2newdir and modisnewdir these directories contain the optical data downloaded from the respective catalogues i e u s geological survey earth explorer for l8 copernicus open access hub or italian sentinel collaborative data hub for s2 and the level 1 and atmosphere archive distribution system laads distributed active archive center daac for modis l8 and s2 data are assumed to be in geotiff format and the mod13q1 product is in hdf format they do not require any preprocessing except unzipping if necessary when one or more new images are found they are processed in sequence if the mod13q1 product is not used the processing consists of firstly deriving the ndvi equation 2 since the presence of clouds totally modifies the ndvi value of an image pixel thus producing outliers the fmask algorithm zhu et al 2015 zhu and woodcock 2012 available through envi is preliminarily applied to discriminate and mask clouds finally for the non masked pixels w is computed by applying 3 and the w map is updated by inserting the new plant water content values instead of the old values this map is placed in the opticaldir see the central panel of fig 3 and is in envi format if no new optical imagery is available or only cloudy pixels are found the w map is not updated and the last available values for w are used in this way the optical data processor provides mulesme with the latest possible information about the state of the vegetation to cope with the different spatial domains and pixel sizes of optical images and s1 iws images the vegetation map is resampled and reprojected to a common output projection and pixel size by exploiting the envi layer stacking tool this operation requires choosing a master product used as geographic reference for cartographic projection and pixel size since the proposed software was conceived to operate at national scale for the italian territory the image derived from the rasterization of the shapefile representing the italian land cover according to the corine land cover 2012 available at http land copernicus eu pan european corine land cover clc 2012 was used as master product this image also used as land cover lc map see section 3 2 1 has projection utm 32 and datum wgs 84 the pixel size is about 100 100 m2 the lc map was generated once and for all during the implementation phase of the software it is shown in fig 4 that includes also the result of the projection of a w map to the geographic reference it is foreseen that when updated land cover data will be released in the frame of the corine project they will be used by mulesme although for figure clarity the right panel of fig 4 displays the w map derived from only one single optical image this map is actually composed of a mosaic of maps derived by processing l8 and or s2 and or modis observations of the whole italian territory as soon as they are available note that l8 and the mod13q1 product have a revisit time 16 days which is suitable to monitor the phenological cycle of vegetation a significantly better temporal resolution 5 days can be achieved using both satellites of the s2 constellation mulesme was designed to be routinely run in a scheduled manner once a day firstly the secondary optical processor verifies the availability of new optical images and if so updates the vegetation map then if new s1 data are available mulesme produces new sm estimates and generates a sm map at national scale see section 3 2 3 3 2 mulesme the workflow of the mulesme software is shown in fig 5 the software basically accomplishes the following operations 1 reads all the data necessary to generate the output maps 2 resizes the data 3 corrects the effects of vegetation on c band s1 data 4 masks the pixels where the retrieval is unfeasible 5 runs the multi temporal sm retrieval algorithm and applies a low pass filter to the resulting sm maps 6 assigns a degree of uncertainty to each pixel of the map 3 2 1 the input data input data are i1 a set of m 1 s1 images i2 a set of maps of local incidence angle θ l i3 a land cover lc map i4 a map of topographic slope i5 the w map produced by the secondary processor inputs i1 are calibrated backscattering data in m2 m2 produced by applying the freely available esa sentinel application platform snap software tool to the s1 grd products downloaded from the copernicus open access hub or the italian sentinel collaborative data hub for this purpose the following operations have to be carried out using snap 1 apply orbit file 2 thermal noise removal 3 calibration 4 multi looking to obtain a 100 100 m2 square pixel 5 terrain correction utm wgs84 projection should be chosen snap can also be used to generate the local incidence angle maps inputs i1 are in the beam dimap format the default snap output format which is envi conform and refer to a single s1 slice in fact for any track s1 level 1 products are segmented into slices for the purpose of data manageability each slice is a stand alone product that can be processed independently inputs i2 are in envi format more details in section 3 2 2 inputs i3 i5 are maps at national scale with a pixel size of 100 100 m2 georeferenced in utm wgs84 projection the lc and the slope maps are required to have the same number of lines and columns the current release of mulesme assumes the level 3 corine code for the lc map mulesme reads the input data from three directories see the left panel of fig 3 1 directory that contains the s1 new i e not already processed data at vv and vh polarizations produced by the snap tool hereafter denoted as snapnewdir 2 directory that contains the ancillary data i e inputs i2 i4 denoted as ancillarydir 3 the opticaldir where optical processor saves the w map in addition mulesme uses other two directories where s1 data are temporarily saved i e s1newdir and s1previousdir details in the following 3 2 2 preliminary operations since the software works at national scale it has to process several files related to different slices however in the grd product filename there is no information about what slice is being processed and on its geographical location hence the automatic identification of every single slice should be carried out slice identification and change of the filename box in fig 5 this operation is accomplished by taking advantage of information that can be derived from the product metadata as a the relative orbit number which is the same over time as opposed to the absolute orbit number b the map coordinates of the center scene pixel that may slightly vary over time for this purpose the filename of any calibrated and geocoded grd product generated by snap and saved in the snapnewdir is automatically modified by mulesme by adding the suffix orb lat lon where orb is the relative orbit lat is the latitude of the center scene pixel and lon is the longitude of the center scene pixel for this purpose mulesme searches in the ancillarydir for all the files containing the local incidence angle maps θ l filename lia orb lat lon then it selects the θ l file whose relative orbit is the same as that of the considered grd product and whose coordinates of the center scene pixel are the closest to those of the considered grd product it is worth pointing out that the possible s1 relative orbits and coordinates of the center scene pixels of the slices covering the italian territory are known a priori because of the use of iws products for instance for what concerns the morning passes descending orbits over the italian territory the relative orbit numbers and the coordinates of the pixel centers are reported in table 1 note that morning passes are preferable for sm retrieval because in the morning the thermal equilibrium of surface and vegetation can be reached van der velde et al 2014 the use of iws products allowed us to generate the θ l maps ones and for all during the design phase of mulesme for this purpose the snap tool was firstly used since all the θ l maps produced by snap have the same filename localincidenceangle img the latter was changed according to the formalism lia orb lat lon and saved in envi format fig 6 shows the θ l map for the slice identified by the tern orb i lat i lon i 66 44 8 8 1 see table 1 it is worth mentioning that in case a mulesme user has to process a single s1 slice anywhere outside italy he she has just to put in the snapnewdir ancillarydir and opticaldir the s1 and ancillary data of his her interest see the beginning of section 3 2 for the input data requirements it is understood that in this case the software does not work at national scale but at the spatial scale of the s1 slice hence only one θ l map is needed mulesme checks at a daily interval the presence of new files in the snapnewdir and if one or more files are found their names are modified before starting the actual sm retrieval the files with the new filenames are automatically saved by mulesme in the s1newdir whereas the original beam dimap file is moved in the snapolddir see the left panel of fig 3 hereafter the total number of θ l maps in the ancillarydir will be indicated as n lia mulesme loops through the n lia filenames corresponding to the values of relative orbit latitude and longitude listed in table 1 if s1 morning passes are considered and for each tern orb i lat i lon i i 1 n lia searches in s1newdir for a filename ending with orb i lat i lon i when a s1 file that ends with orb i lat i lon i is found in the s1newdir mulesme searches in the s1previousdir for the files whose name ends with the same suffix note that these files can be at the most m 4 see section 2 2 because as soon as a file in the s1newdir is processed it is moved in the s1previousdir and if after this cut and paste operation in the latter directory the number of files ending with orb i lat i lon i is greater than 4 the oldest is deleted after having read the s1 files and the corresponding θ l map see section 3 2 1 mulesme reads also the lc map the map of the topographic slope and the w map analogously to the lc map and the maps of θ l relative to the various slices that cover the italian territory even the map of topographic slope was generated once and for all during the design phase of the software firstly the freely available srtm dem was resampled and projected to the reference projection and pixel size then the envi topographic modeling tool was used to extract the slope once all the mulesme input data are stored in memory they are resized to the spatial domain of the considered slice orb i lat i lon i data resize box in fig 5 then mulesme reads the lut which is represented by an ascii file lut oh04 f5 4 txt placed in the ancillarydir right panel of fig 3 at this point all the data necessary to compute the cost function d equation 1 for the non masked pixels of the considered slice are available before computing the cost function the correction of the vegetation effects is carried out see the corresponding box in fig 5 let us consider a s1 image at current time t directory s1newdir γ vh is firstly computed in order to choose which model wcm or rm has to be used to correct for the effects of vegetation see section 2 3 note that this correction is performed only if w 0 25 kg m2 otherwise the terrain is assumed as bare pierdicca et al 2013 the image at vv polarization produced after applying the correction of the vegetation effects is then stored in memory for the computation of the cost function 1 and saved in s1previousdir so that s1previousdir contains vv data that are already corrected for the vegetation effects 3 2 3 generation and filtering of the soil moisture map the size of a s1 image multi looked to obtain a pixel size of 100 100 m2 see section 3 2 1 is in the order of 2800 2900 2000 2500 pixels for the purpose of data manageability and to avoid an excessive memory usage the m 1 images used to generate the sm map for a specific s1 slice are firstly split in spatial subsets formed by 500 500 pixels as done by pulvirenti et al 2014 then the masking of the pixels of the considered subset where sm retrieval is unfeasible is performed see the image splitting data masking box in fig 5 both lc and slope maps are used to mask areas where the sm estimate is not feasible in particular mulesme masks urban areas forests water bodies identified by their corine codes see the caption of fig 4 as well as pixels with complex topography identified as those where slope is greater than 15 in addition pixels with w 5 kg m2 see section 2 3 and pixels where θ l is less than 24 minimum incidence angle in the lut minus 2 db of tolerance or larger than 52 maximum incidence angle in the lut plus 2 db of tolerance are also masked to avoid outliers even pixels whose backscatter at vv polarization is less than 19 db likely corresponding to pixels covered by water or frozen soil or even wet snow or larger than 2 db likely corresponding to urban areas or forests are masked pierdicca et al 2014 with respect to previous works regarding sm retrieval from sar the use of s1 data to produce sm maps implies that the large difference between far range and near range incidence angles see section 2 1 which is characteristic of iws products should be taken into account for each pixel of the considered spatial subset the incidence angle value in the lut θ lut that is most similar to θ l is identified successively a secondary map of local incidence angle θ l2 whose possible values are only those included in the lut is produced then mulesme loops through the 13 values of θ lut see section 2 2 and for a given value θ lut h h 1 13 all the pixels of the considered subset having θ l2 θ lut h are simultaneously processed as done by kim et al 2012 to generate the sm maps the roughness s assumed to be the same for the various addends of 1 is firstly estimated to this aim all the possible values of s in the lut are considered and for each s the soil moisture values in the lut that minimize each addend of 1 individually are computed they are denoted as sm m i i t t m the sum of those addends represents the minimum cost function for the considered s value hence denoting by s a generic value of s in the lut d min s is given by 11 d min s σ v v s o i l 0 t d b σ v v m odel 0 s m m t s θ l 2 d b 2 σ v v s o i l 0 t 1 d b σ v v m odel 0 s m m t 1 s θ l 2 d b 2 σ v v s o i l 0 t m d b σ v v m odel 0 s m m t m s θ l 2 d b 2 where 12 s m m i s m σ v v s o i l 0 i d b σ v v m odel 0 s m i s θ l 2 d b 2 min σ v v s o i l 0 i d b σ v v m odel 0 s m i s θ l 2 d b 2 i t t m by combining the various d min s for the different values of s in the lut the cost function for the estimation of s is determined by denoting this function as d s the estimated value of s s est is the s value in the lut that minimizes d s the sm estimates sm est at times t t 1 t m are the sm values in the lut obtained when deriving d min s est kim et al 2012 i e the values obtained through 12 when s s est after having performed the procedure described above for every spatial subset of the considered slice the sm map is finally produced from 12 it can be deduced that not only the sm map at current time t but also m maps at previous times may be produced since the service was conceived to provide the end users with daily data only the map at current time t is used to generate the mulesme output to avoid providing the end users e g the italian civil protection department with a noisy map and considering that the sm maps are conceived to be assimilated into a hydrological model a low pass filter with a 5 5 kernel is applied see the filtering box in fig 5 consequently the actual resolution of the sm maps is in the order of 500 500 m2 the rationale is that this resolution is the same of hydrological model that will be used for the future assimilation of the s1 derived sm maps see section 5 note that this filtering process is not equivalent to perform a further multi look of the original images because the masking procedure applied to the data before carrying out the sm retrieval reduces the risk that the filtering process mixes up pixels where estimating sm is not feasible with non masked pixels the filtered map is saved in geotiff format an example of daily august 02 2016 national sm map is shown in the upper left panel of fig 7 it is composed by a collection of maps derived by processing single s1 slices belonging to relative orbit 95 lower panel of fig 7 which corresponds to the only s1 overpass of italy on august 02 2016 the area highlighted by the blue box in the upper left panel of fig 7 is shown in the upper left panel of fig 8 which includes also the associated histogram upper central panel and the lc map upper right panel the spatial variability of sm with respect to the land cover can be noted most of the yellow pixels in the right panels belong to the non irrigated arable land corine class the lower panels of fig 8 are the same as the upper panels but for a different level of zoom any daily national sm map is associated to a daily map representing the level of uncertainty low medium or high of the estimates this map is produced by mulesme after the generation of the sm map by applying the fuzzy logic approach described in section 2 4 the upper right panel of fig 7 shows the uncertainty map associated to the map in the upper left panel even the uncertainty map is saved in geotiff format a personal computer operative system windows 10 with an intel core i7 cpu 4 cores and 32 gb ram was used for testing the mulesme processing time the time required to produce an updated w map i e the running time of the secondary processor ranged from about 15 s for modis 250 250 m2 of resolution to 4 min for l8 30 30 m2 of resolution and 10 min for s2 10 10 m2 of resolution as for the s1 processor using a series of five s1 images for the multi temporal retrieval of sm the processing time was in the order of 25 30 min depending on the number of the masked pixels hence in our tests the total processing time varied between 25 and 40 min 4 tests 4 1 test on simulated data bare soil a first test of the proposed software was carried out by simulating a time series of ten synthetic c band sar multi looked images representing a schematic scene of different homogeneous bare fields having different values of sm and s to generate the simulations the oh model was applied by assuming for each field a constant s over time whereas sm was supposed as randomly varying in time to the synthetic images the multi temporal sm retrieval algorithm described in section 2 2 was applied for the retrieval at time t i i 2 10 all the images acquired at times t j t i j 1 9 j i were used too the results are shown in fig 9 in terms of correlation coefficient r between retrieved and reference data those used to simulate the sar observations and rmse plotted in function of the number of processed images equal to m 1 i e the image at current time t plus m images acquired before the current one see section 2 2 it can be seen that the retrieval performances significantly improve r increases and rmse decreases until m 1 5 this demonstrates the potentiality of a multi temporal approach for m 1 5 the trends of r and rmse tend to oscillate this explains the choice of m 4 see section 2 2 which seems to be the best compromise between accuracy and efficiency this result confirms that obtained by pierdicca et al 2014 who performed a similar exercise using a different multi temporal algorithm looking at fig 9 it can be noted that for m 1 5 very good results were obtained for the sm retrieval accuracy i e r 0 96 and rmse 0 03 m3 m3 it must be underlined that this test regarded a favorable situation i e sar observations of bare fields and backscatter measurements within the expected range of values 4 2 test on experimental data vegetated soils although the software was conceived to be applied for the italian territory nothing prevents a user from running mulesme for different geographic areas as pointed out in section 3 2 2 hence the experimental data derived from the esa agrisar 2006 campaign balenzano et al 2011 hajnsek et al 2009 whose principal objective was to assess the impact of esa sentinel 1 and 2 missions for land applications were used to perform a second test of the retrieval algorithm the campaign was carried out over the demmin agricultural site in northern germany during the period april 19 july 26 2006 encompassing the vegetation growing season and providing sar and ground truth data acquired almost weekly among the airborne sar measurements performed during the agrisar 2006 campaign only c band data were provided us within the framework of a past project funded by esa namely the gmes sentinel 1 soil moisture algorithm development these data were acquired by the experimental sar e sar airborne system eleven dual polarization vv vh acquisitions were used to carry out the test of the algorithm in order to be consistent with s1 iws observations see section 2 1 their dates are april 19 may 3 11 16 24 june 7 13 21 july 5 12 26 in this case plant water content was directly derived from ground truth data the latter included surface sm field measurements as well which were gathered almost simultaneously to the radar measurements different fields where different crop types were present were monitored during the agrisar 2006 campaign those considered in this test are reported in table 2 that includes also the indication on the local incidence angle of e sar c band observations w was quite low in april less than 1 kg m2 except for rape fields when some fields were still bare then it rapidly increased reaching and even exceeding the value of 5 kg m2 above which data are masked by mulesme this occurred already in may for rape fields and in june july for the other fields for rape barley and wheat fields w reached its maximum and the end of june beginning of july and then decreased while for maize and sugar beet it constantly increased from the beginning of june to the end of the campaign for the whole agrisar 2006 dataset available for this test the rmse was quite high 0 12 m3 m3 because the presence of vegetation at an advanced stage of growth in june july 2006 had a big impact on the accuracy of the retrievals note that in previous works using agrisar 2006 data to assess sm retrieval algorithms l band less sensitive to vegetation than c band fully polarimetric measurements four channels i e vv hv vh hh where not only amplitudes but also relative phases are measured were mostly used with this kind of data hajnsek et al 2009 obtained rmse in the range 0 03 0 14 m3 m3 however s1 does not have fully polarimetric capabilities and works at c band on the other hand s1 represents the only sar sensor currently in operation that has a revisit time compliant with the timeliness requirements of operational sm applications in the order of five days see pierdicca et al 2014 so that it is worthwhile to focus on this sensor to design a large scale sm mapping service considering only retrievals with low or medium level of uncertainty the results significantly improve see fig 10 with r 0 6 and rmse 0 08 m3 m3 this demonstrates that the level of uncertainty computed as described in section 2 4 can be a useful proxy to indicate that the ill posedness of the sm retrieval problem mostly due to the presence of developed vegetation is such to produce estimates with low accuracy a rmse in the order of 0 08 m3 m3 represents a value aligned with those found in the literature for sar observations performed when the soil is vegetated see section 1 note that considering only the few cases in which fields were bare o scarcely vegetated w 0 25 kg m2 a rmse equal to 0 06 m3 m3 was obtained a value that almost meets the accuracy target recommended by wmo see section 2 2 as underlined in the introduction this paper is focused on the design of a software implementing an automated processing chain and does not propose a new algorithm to improve literature results for sm retrieval in any case nothing prevents future releases of mulesme from implementing a sm retrieval algorithm different from that described in section 2 2 if it will be proved that a different algorithm produces better results the same applies for the semi empirical models described in section 2 3 to change the algorithms it is sufficient to change the soil moisture retrieval module and or the correction of vegetation effects module of the software see fig 5 the rest of the processing chain does not need any modification 5 future developments mulesme was conceived to be installed in the wasdi platform connected to the italian sentinel collaborative ground segment coll it in order to exploit the coll it storage capability and its computing resources wasdi is a project whose scope is the development of software tools for the coll it in order to foster the exploitation of the asset concerning earth observation data and satellite products it can query different catalogues such as the sentinel data hub system dhus and gives the users the possibility to immediately display the selected data or the output of a processing through a dedicated web based workspace the added value of wasdi with respect to currently existing catalogues is its capability to process the earth observation data e g sentinel 1 selected by the user directly on the server taking advantage of the coll it facilities the coll it project includes big computation resources thus enabling to run processes directly on data stored in a local cloud fig 11 shows the interface of the current release of wasdi as it appears to a user it is foreseen that once the wasdi platform will be fully operational it will allow users to sequentially perform the operations of downloading sar and optical data preprocessing sar data wasdi will implement all the snap tools useful for this purpose executing mulesme and downloading its outputs although a test of mulesme was already performed on wasdi other tests will be performed using different s1 observations before officially releasing mulesme for wasdi authorized users the main idea underpinning wasdi is to avoid the transfer of big amounts of data to the users that is to move the processing to the data rather than the data to the user wasdi will allow users to further process the outputs of mulesme in particular to improve the quality of sm estimates especially if s1 observations are performed under dense vegetation conditions it is foreseen that the sm mapping software implemented in the wasdi platform will be complemented by a module producing also a more physically consistent map through the assimilation of the retrievals into a hydrological model cenci et al 2016b through an appropriate uncertainty modeling data assimilation da allows for the optimal combination of soil moisture estimates obtained from external observations e g satellites and numerical simulations e g hydrological models in order to obtain more accurate estimates e g massari et al 2015 a time continuous spatially distributed physically based hydrological model will be used for the da namely the continuum model silvestro et al 2013 this model currently used in italy at operational level by the italian civil protection department produces maps of root zone soil moisture for the italian territory at the same spatial resolution of the s1 derived maps i e 500 500 m2 as mentioned in the introduction root zone soil moisture constitutes an important variable for hydrological and weather forecast models so that the implementation of the da scheme into the wasdi platform will enable to provide users with a more complete information about soil moisture 6 conclusions several algorithms available in the literature dealt with the problem of soil moisture retrieval using synthetic aperture radar sar data conversely the problem of the creation of a processing chain that automates the various steps needed to set up an operational soil moisture mapping service based on sar data was rarely tackled a software for accomplishing a surface soil moisture mapping service using sentinel 1 and ancillary data was presented in this paper its outputs consist of high resolution 500 500 m2 soil moisture maps daily produced at national italian scale although in principle nothing prevents a user from using the proposed service for other geographic areas a map in which the uncertainty of the estimates is characterized complements any daily soil moisture map three levels of uncertainty low medium high are considered the proposed software automates all the steps related to the systematic retrieval of soil moisture using sar data the sequential execution of these steps required manual interaction so far the core of the software is represented by a multi temporal algorithm based on previous literature studies and adapted to be used for sentinel 1 data designed to take advantage of the short revisit time of sentinel 1 images from a test of the soil moisture retrieval algorithm carried out using simulated data it emerged that under bare soil conditions its outputs are very accurate performing a second test using actual sar observations of vegetated soils it emerged that vegetation at an advanced stage of growth can have a big impact on the accuracy of the retrievals as expected the level of uncertainty turned out to be a good indicator of the estimates that have low quality because of the presence of dense vegetation to pursue the objective of an improvement of the quality and the completeness of the proposed service future work will concern the assimilation of sentinel 1 derived surface soil moisture maps in a hydrological model to produce physically based maps of root zone soil moisture the software was conceived to be installed in the wasdi platform wasdi is connected to the sentinel italian collaborative ground segment where the sentinel 1 observations of italy are stored in this way the processing will be moved to the data rather than the data to the users acknowledgements this work has been funded by the italian space agency asi 2015 018 i o in the framework of the mida project and by the european space agency esa 4000116310 15 i sbo in the framework of the wasdi project agrisar 2006 data were provided in the framework of the gmes sentinel 1 soil moisture algorithm development project funded by esa m chini contribution was supported by the national research fund of luxembourg through the inter dfg 14 02 caos 2 catchments as organised systems project 
26417,forecasts of water use are crucial to efficiently manage water utilities to meet growing demand in urban areas improved household level forecasts may be useful to water managers in order to accurately identify and potentially target for management and conservation low efficiency homes and relative high demand customers advanced machine learning ml techniques are available for feature based predictions but many of these methods ignore multiscale spatiotemporal associations that may improve prediction accuracy we use a large dataset collected by tampa bay water a regional water wholesaler in southwest florida to evaluate an array of spatiotemporal statistical models and ml algorithms using out of sample prediction accuracy and uncertainty quantification to find the best tools for forecasting household level monthly water demand time series models appear to provide the best short term forecasts indicating that the temporal dynamics of water use are more important for prediction than any exogenous features keywords predictive modeling spatial modeling time series tree based methods uncertainty quantification urban water use 1 introduction rapidly increasing urban populations have put new stress on water utilities as they try to meet growing demands for water effective management of water utilities requires anticipating future water use both in the short term in order to efficiently meet demand and over longer temporal ranges so that they may best allocate scarce investment resources accurate household level forecasts may be used for correctly anticipating future demand and identifying households that are predicted to use large quantities of water relative to lot and or household size in the future as potential targets for efficiency monitoring however creating these accurate predictive models for utilities data can be challenging due to the vast amounts of data involved donkor et al 2014 summarized water demand forecasting methodologies used by utilities some of these methods rely on simple per capita usage averages which have considerable deviation around the mean the public supply gross per capita use in florida was 134 gallons per person per day in 2010 but ranged from less than 100 to more than 200 by county marella 2014 others use simulations and scenario based decision systems to model future water demand williamson et al 2002 billings and jones 2008 polebitski et al 2011 more advanced forecasting techniques have been proposed using time series models including linear regression autoregressive integrated moving average arima models stochastic process models and artificial neural networks ann the success of ann models in particular billings and jones 2008 bennett et al 2013 tiwari and adamowski 2015 suggests that additional nonparametric machine learning ml techniques could produce similar or superior forecasts however very few studies have assessed the quality or uncertainty of water demand forecasts made by machine learning methods this paper seeks to address this gap in the literature other studies have modeled water use on finer timescales e g daily and hourly with the data recorded by smart meters herrera et al 2010 cominola et al 2015 however not all water providers collect data at the daily or hourly resolution specialized approaches have been developed that focus on household demand and in particular that of single family homes deoreo and mayer 2012 provide a thorough end use analysis of fixtures and various uses of water in the household this detailed analysis results in a precise per capita use estimate for households presumably this information could be used to forecast future water demand if one knew the relative growth and composition of future household construction however even knowing details on end uses requires knowledge of population growth and prediction of new construction trends deoreo and mayer 2012 point out that indoor use declined from 187 gpd household on homes built in the early 1990s to 162 gpd household for homes built around 2007 and as low as 107 gpd household for new high efficiency homes this decrease of indoor demand was primarily due to high efficiency toilets and clothes washers mandated and used in newer construction similarly abdallah and rosenberg 2014 attributed changes in indoor water use over time to efficiency gains in technology and not to conservative behavior however deoreo and mayer 2012 point out that outdoor use did not change between the older and newer homes this observation is important since outdoor use e g irrigation in southern states like florida has been shown to be as high as 74 of total household water use in typical landscapes haley et al 2007 the purpose of this paper is to evaluate alternatives for water demand forecasting and to compare several advanced machine learning techniques and spatio temporal models that are available for feature based predictions our goal is to determine if these alternative models can improve prediction and uncertainty quantification of the forecasts as judged by root mean squared error rmse and prediction interval based metrics such as the width and empirical coverage rate respectively the ml algorithms considered in this paper are random forest rf bayesian additive regression trees bart and gradient boosting algorithms gbm see e g friedman et al 2001 for an overview and algorithmic details of these models these methods make use of exogenous features but do not explicitly take into account multiscale spatial and temporal associations that may improve predictive quality of the models in high spatio temporal resolution e g monthly household water demand for comparison we also evaluate the prediction accuracy and uncertainty quantification of an array of statistical models which explicitly include parametric dependence and semiparametric trend structures to account for spatio temporal dynamics and compare these models with our nonparametric ml algorithms in order to identify the best tools for forecasting water demand the models developed here do not make any assumptions about rates of urban growth changes in construction methods improvements in water efficiency or other global drivers of water use if the true relationship between the features used to create the models and water usage is altered by changes in exogenous factors the models need only be refit using updated data the only constraint on the models adapting to exogenous changes is the rate at which new data becomes available which includes these altered dynamics the data set used for this study contains monthly total water usage by single family homes from tampa bay water tbw a water authority operating within the southwest florida water management district swfwmd for three member governments located in hillsborough pasco and pinellas counties recorded approximately from 1998 to 2010 with some variation by region boyer et al 2014 the data includes monthly water usage collected for each household parcel based on billing records parcel and billing records were augmented with environmental covariates including precipitation evapotranspiration and temperature this case study allows us access to a large amount of high quality data which has been screened for accuracy and completeness and hence presents an excellent opportunity to evaluate ml and spatio temporal models for predicting water usage within a municipal utility this manuscript is organized as follows section 2 outlines the available data and the covariates used in our study section 3 describes the models used in our analysis and the criteria by which they are evaluated section 5 presents our model comparisons and section 6 provides further discussion of these results and directions for possible future study as per editor s request we provide magnified versions of all figures in the supplements at the end of the manuscript 2 data 2 1 water use data the dataset considered here consists of monthly potable water billing records water usage data from tbw for parts of three counties in east central florida hillsborough pasco and pinellas and recorded approximately from 1998 to 2010 with some variation by region boyer et al 2014 the data includes between 6 months and 12 years of monthly records from over one million unique customers with water usage collected in monthly increments for each unique parcel based on billing records for this study we use only parcels which contain exactly one single family residence to focus on household level water demand the data is both spatial and temporal in nature with observations throughout the tampa bay region this paper focuses on forecasting the total water usage per month in each parcel to increase the number of statistical and ml methods for comparison and to mitigate computational burdens in comparing the methods our analysis focused on a representative subset of over 100 000 observations household month records within the city of tampa shown in fig 1 c to allow for the full scope of spatio temporal models to be used for forecasting we focused on 973 households without missing data over 137 months see section 4 2 2 for details on this constraint the data exhibits significant spatio temporal heterogeneity fig 1 shows the location of the study within florida and the spatial distribution of the households and water usage included in this study fig 2 shows the total monthly water use for each household as multiple time series while there are aggregate trends the patterns within individual households are much less regular the highlighted lines indicate the monthly water usage of two typical individual households which shows strong autocorrelation and possible seasonal variation as well as less structured household specific temporal variation the average across all households is also shown and the figure indicates that the variation of household water use around the mean is quite large as an exploratory step we view the spatial heterogeneity and temporal structure of the data aggregated to census blocks in fig 3 a which shows the total water use for each census block averaged over time and indicates that some spatial dependence may be present in the data but with significant between household variation observed within even very small spatial areas the totals are highly skewed and many billing records are missing from the full data set a simple exploratory time series model was fit to each census block and the estimated one month autocorrelation coefficients for each block are shown in fig 3 b almost all of the coefficients are over 0 5 and many are near one indicating strong temporal dependence of water usage over the entire region and implying that autoregressive time series models may be effective at producing accurate forecasts additional acf and pacf plots in figs 5 and 6 of the supplemental materials reinforce the appropriateness of temporal and spatio temporal models to the water use dataset 2 2 covariates several exogenous variables were identified as potential predictors of total monthly water use outdoor water use e g irrigation can account for a high percentage of total water use in florida and irrigation is potentially influenced by weather e g precipitation evapotranspiration and irrigated area e g green space the covariates were screened for inclusion in the models using variance inflation factors vifs to account for a high level of collinearity within the potential predictors a vif for each covariate x j was obtained by regressing the variable on all other explanatory variables and calculating 1 1 r j 2 where r j 2 is the coefficient of determination for this regression model covariates with sufficiently high vif values were removed for this application we removed all covariates with vifs greater than 5 based on our preliminary study examining the vif cutoff above which variables made little to no improvement in prediction quality two broad types of covariates were used in this research environmental and parcel specific environmental covariates include monthly averages for rainfall evapotransporation and daily maximum temperature these covariates were recorded via satellite throughout the tampa bay region and values were applied over a grid of 2 km by 2 km pixels monthly average precipitation and monthly average evapotranspiration data was obtained from the usgs 2005 2011 and swfwmd exploratory data analyses revealed that both precipitation and evapotranspiration are potentially predictive in our models but that average daily maximum temperature is not a significant predictor a geographic information system gis shapefile for the corresponding 2 km by 2 km pixel grid was also provided by swfwmd additionally soil type data was obtained from the usda soil data mart usda natural resources conservation service u s dept of agriculture 2013 soil data were available by county and included soil types available water holding capacity awhc and gis shapefiles of soil polygons the only soil covariate found to be potentially predictive during exploratory analyses was awhc the parcel specific measures included were land value building value structure footprint area the year the most recent structure was built green space defined as vegetated area within the parcel and the area of heated structures on the parcel each of which were collected from the florida department of revenue the data was supplied as gis shapefiles for each parcel which provided the easting and northing values giving the centroid of each parcel the parcel shapefiles were then matched to monthly water usage data by parcel identification number and overlaid by the environmental pixels finally temporal variables were included as month and year of observation and the number of days within the observed month table 1 shows descriptive statistics for each predictor 3 methods in this study predictive performance of classical time series models spatio temporal gaussian process models and several popular modern ml algorithms for forecasting household level monthly water demand were evaluated using both point rmse gini score and interval forecast metrics empirical coverage interval width interval score more details on the metrics used for prediction evaluation are presented in section 3 1 all methods were implemented in the statistical environment r and are freely available r core team 2016 each method was fit to a subset of historical data and used to make forecasts for left out test data as described in section 3 2 essential details for the predictive models used are reviewed in sections 4 1 4 3 3 1 forecast metrics our measurement criteria for model performance were the root mean squared error rmse gini coefficient gini average prediction interval width awpi average empirical coverage rate ecpi and the negatively oriented interval score nois gneiting and raftery 2007 the formulas for the comparison metrics are given in table 2 the rmse measures the average prediction error for held out data while the gini coefficient provides a measure of how well a ranked list of predicted values lines up with a ranked list of the true values in the test data the gini coefficient is a measure of how well low and high demand households are identified the gini coefficient can be visualized as the area between the cumulative prediction of our models and those of simple overall mean model a gini coefficient closer to one suggests that the model performs well in correctly predicting when observations will be below or above the overall data mean while a gini coefficient of zero indicates that the model performs as poorly as merely predicting the overall mean for all future observations the prediction interval width allows us to compare uncertainty in model predictions while the empirical coverage rate allows one to assess whether the uncertainty quantification by the prediction intervals is accurate i e the empirical coverage rate of the prediction intervals on left out test data is close to the nominal coverage probability in this manuscript we use one sided upper 95 prediction intervals to assess how well our models quantify the uncertainty of extreme water use by each household water use is strictly non negative so each prediction interval has a lower bound at zero the nois serves as a combination of awpi and ecpi penalizing models for large intervals and for empirical rates that differ from theoretical expectations specifically the nois is computed as the awpi plus a penalty for each prediction interval that does not contain the true value the penalty is proportional to the distance of the observation from the prediction interval boundary with these criteria we evaluate how well our models make forecasts how well they quantify uncertainty and how well they can identify and separate low and high demand users 3 2 validation to validate forecasts from each predictive model the data were split into training and test subsets the forecasts were validated by both short term one month ahead and longer term k months ahead for k 2 12 forecasts because of the temporal dependence in the data one cannot take a random subset for training and validation but must maintain temporal ordering within training and validation subsets so as to capture temporal dynamics for short term forecasts the training data consisted of all past observations preceding the month of the forecast which was held out as the test subset this was repeated 12 times for the last 12 months in the data set to reflect a real world scenario where data is continuously added to the model the fitted model is updated and used to forecast demand in the next month the assessment metrics were averaged over each of the 12 months to provide an aggregate measure of one month forecast accuracy for longer term forecasts the test set contained all observations for the last 12 months in the data set forecasts were made for each of the 12 months in the test set by holding the training data set fixed without adding additional data or refitting a model the assessment metrics were again averaged for each of the 12 months predicted for both short and long term assessments the test sets contain all households in the study that is no subset of water usage is observed within the month being predicted to align with real world forecasting needs for feature based ml models the future predictor values e g next month s precipitation were assumed known when making forecasts it should be noted that using predicted values for as yet unobserved features such as historical averages for monthly precipitation would introduce additional uncertainty and noise into the predictions 4 models 4 1 baseline regression models 4 1 1 linear and linear mixed models with month effects in this section we outline three linear and linear mixed models mcculloch and searle 2003 to provide a baseline for the more complex methods to follow in subsequent sections in order to investigate the improvements that can be made by machine learning methods and by accounting for temporal and spatial dependence the simplest model fit is a monthly mean model the average total water use is calculated for the combined households for each month and used as the predictor of future water usage statistically the model is a one way anova model y i j α m j ε i j where y i j is the total water use for household i during month j α m j is the fixed effect population mean of the calendar month m j 1 12 shared by all households and ε i j is a gaussian white noise process the model is then extended to fit monthly means for each household separately i e using a two way anova with household month interaction as y i j α m j γ i m j ε i j where γ i m j are fixed i e nonrandom household specific effects of the months constrained as i γ i m j 0 for identifiability finally a random effects model is fit with shared monthly means and random household deviations from these means the model is still y i j α m j γ i m j ε i j but the vectors γ i 1 γ i 12 are now independent multivariate normal household specific random effects deviations from the grand monthly means α 1 α 12 the advantage of the random effects model is reduction in the effective number of model parameters since the γ i m j are integrated out rather than estimated and consequently potential reduction in the estimation error for model parameters and mitigation of overfitting 4 1 2 linear regression we also fit a multiple linear regression model as another baseline for comparison with forecasts by other competing models this model regresses household monthly water use on predictors and their two way interactions to account for any interacting effects that may boost forecast performance stepwise variable selection using the akaike information criterion aic was performed to exclude insignificant effects and avoid overfitting friedman et al 2001 all main effects as well as 45 out of a possible 55 two way interactions were chosen by the variable selection procedure the model is given by y i j x i j β ε i j where x i j is the vector of selected predictors and two way interactions for the i t h household and j t h month and β is the vector of regression coefficients given an estimate β ˆ for β forecasts for timepoint j are made using y ˆ i j x i j β ˆ 4 2 space time models 4 2 1 time series models ar 1 and arima the autoregressive model with a lag of one month ar 1 model regresses the water usage observation y i j on its lagged value as y i j μ i j ρ i y i j 1 μ i j 1 ε i j where μ i j is a deterministic e g linear mean function of covariates ρ i is the autoregressive coefficient and ε i j is gaussian white noise lütkepohl 2005 the simplest special case is the global model without covariates where the intercepts and autoregressive coefficients are shared by all households i e μ i j μ 0 and ρ i ρ for every i and j an expanded ar 1 model with household specific intercepts and a shared autoregressive coefficient was also fit in addition to the standard ar 1 model we fit autoregressive integrated moving average arima models to our data these models expand on the ar 1 models by differencing the data to achieve approximate stationarity and model the time series of the differenced data as an autoregressive moving average process the arima models were fit using an automatic algorithm that selects household specific autoregressive differencing and moving average parameters i e the orders p d q and corresponding coefficients by optimizing the aic for this study an arima p d q model has the form 1 k 1 p α k l k 1 l d z i j 1 k 1 q β k l k ε i j which uses differencing order d and where z i j y i j μ i j l is the lag operator i e l k z i j z i j k α k are the p autoregressive coefficients and β k are the q moving average coefficients for more details on arima models see e g lütkepohl 2005 4 2 2 spatio temporal gaussian process models st water demand may be spatially correlated due to unobserved spatially varying factors and capturing spatial correlations if present can improve predictive accuracy however spatio temporal models for large data are often computationally expensive if tractable at all sun et al 2012 for a univariate second order stationary random field with respective spatial and temporal domains s and t under balanced space time sampling where n s and n t represent the dimensions of the spatial and temporal components we would need to perform inversion or factorization of a n s n t n s n t covariance matrix to avoid these prohibitive computation tasks we make use of separable covariance structures separable covariance functions are a class of spatio temporal covariance structures that mitigate computationally expensive matrix manipulations in geostatistical models for a univariate second order stationary random field w s t s t s t with spatial and temporal domains s ℝ 2 and t ℝ let c h u cov w s t w s h t u be the covariance function determined only by the spatial and temporal lags h and u a space time separable covariance function is defined as c h u c h 0 c 0 u c 0 0 that is the covariance function can be factored into a product of spatial only and temporal only covariance functions e g exponential covariance function that we use in our study cressie and wikle 2011 banerjee et al 2014 when the data is completely observed e g water use is observed for each household for the same set of months space time separability allows the full covariance matrix σ to be written as a kronecker product of two smaller matrices as σ σ s σ t where the spatial and temporal covariance matrices σ s and σ t are determined by the appropriate covariance functions kronecker products have nice properties related to matrix inversion and factorization specifically the problem of storage and factorization of the full n s n t n s n t covariance matrix can be reduced to storage and factorization of two matrices of size n s n s and n t n t which typically reduces the computational resources necessary to fit a model and obtain predictions by orders of magnitude harville 1997 rakitsch et al 2013 furthermore space time separable processes have an intuitive interpretation for a fixed location the process evolves according to the time series defined by the temporal covariance function and for a fixed time point the spatially referenced values of the field follow a standard spatial statistical model a downside to the separability assumption is that these models require the complete observation of every location at every time point in order to take advantage of the kronecker product decomposition furthermore some spatio temporal data may exhibit a lack of space time separability and require non separable covariance functions to accurately capture spatio temporal correlations genton 2007 li et al 2008 4 2 3 generalized additive models gam the generalized additive model gam hastie and tibshirani 1986 is an extension of the generalized linear model glm in the case of gaussian models of interest in this study the expected value of the response variable is modeled as a sum of unknown smooth functions of the features 1 e y β 0 j 1 j f j x j where x x 1 x j is the vector of j features for the observation y the unknown functions f 1 f j may be represented using a linear combination of a sufficiently large set of basis functions 2 f j x k 1 k j u j k ϕ j k x where u j u j 1 u j k j are the coefficients corresponding to each basis function ϕ j k typically the basis functions are smoothing splines and include a linear term ϕ j k x x for some k the functions f 1 f j are assumed to be continuous and of low rank meaning they can be represented by a moderate number of basis functions coefficients are estimated by maximization of a penalized likelihood where the penalty is placed on some measure of the wiggliness of the functions e g an integral of the squared second derivative wood 2004 alternatively a bayesian approach may be used where the penalty is imposed through the prior on the coefficients crainiceanu et al 2005 merrill et al 2016 wood 2016 spatio temporal trends may be represented with gams as well specifically we construct f s t s t by using the tensor product of a bivariate spatial smooth and univariate temporal smooth 3 f s t s t k 1 k s u s k ϕ s k s l 1 k t u t l ϕ t l t k 1 k s l 1 k t u s t k l ϕ s k s ϕ t l t the interaction term allows for deviations from a strictly additive space time pattern in which the temporal trend would be the same at all locations ruppert et al 2003 and wood 2004 provide more information about choice of ϕ s k s etc space time gams may be used in conjunction with covariance functions the model for the mean of the response is a gam while the covariance function for the response uses a separable structure as in section 4 2 2 for example a space time gam with a separable covariance function and no predictors is defined by the gaussian process 4 y s t g p f s t s t c in this formulation the gam models large scale spatio temporal trends through the mean while the covariance matrix captures small scale spatio temporal variability e g bliznyuk et al 2012 2014 the full response vector y y s 1 t 1 y s 1 t 2 y s s t t is normally distributed with mean f s t s 1 t 1 f s t s 1 t 2 f s t s s t t and covariance matrix σ s σ t assuming no missing data any unknown parameters may be estimated by maximum likelihood typically restricted reml or markov chain monte carlo mcmc 4 3 machine learning algorithms the temporal and spatio temporal models described above were compared with popular ml algorithms which do not explicitly account for spatio temporal dependency the selected ml algorithms are random forests rf bayesian additive regression trees bart and gradient boosting machines gbm bart rf and gbm are sum of trees models which are built from simple decision trees the methods selected have a history of performing well on a wide variety of nonlinear problems the capability to handle large amounts of heterogeneous features e g continuous categorical and binary and are well suited for construction of prediction intervals additional methods including artificial neural networks elasticnet models and lasso regression were also tested in preliminary work and discarded due to underperformance severe computational demands or inapplicability to interval based prediction the final models chosen are all flexible nonlinear models that have produced excellent results in creating predictions from large complex data sets chipman et al 2010 below we provide outlines of the methods full mathematical details are available in friedman et al 2001 4 3 1 gradient boosting machine gbm gradient boosting machines combine simple models iteratively to create a single ensemble estimate the gbm is a boosting model which iteratively builds an additive model by fitting regression trees to the gradient of the loss function and adding them into the model friedman 2001 at step t a new tree model f t x is fit to the vector of residuals r of the current ensemble model f x subsequently the current ensemble is updated using a shrunken version of f t x as f x f x λ f t x and the kth residual is updated as r k r k λ f t x k for k 1 n the final forecast by a boosted model is y ˆ x λ t 1 t f t x although our gbm models include temporal and spatial covariates no explicit structure is specified for spatio temporal dependence a grid search with five fold cross validation is used for choosing tuning parameters λ and t the optimal set of parameters is used to make forecasts on the test set 4 3 2 random forest rf random forests are sum of trees models which are built on decision trees breiman 2001 random forests fit a fixed typically large number t of decision trees f 1 f t each to a different bootstrap subsample of the training data specifically for a given dataset of size n each tree is created by taking n samples with replacement from the full dataset i e bootstrapping to prevent a single tree or variable from dominating at each stage in the tree growth process only a randomly selected subset of size m of the candidate covariates is considered for splitting restricting covariates on which splitting occurs helps to further explore the space of possible trees and prevents dominant trees from overpowering the ensemble the number of trees t and the subset size m are a tuning parameter that are calibrated to achieve an optimal trade off between the computational costs of fitting additional trees and the increase in accuracy they provide to form predictions the new data is fed into each decision tree and the results of all terminal nodes are averaged into a single prediction for each new observation as y ˆ x t 1 t f t x t the mean of the predictions from each tree f t t 1 t random forest also provides an out of bag estimate of model sensitivity to individual variables and interactions further details and illustration are provided in fig 7 in the supplemental materials 4 3 3 bayesian additive regression trees bart bayesian additive regression tree bart models are an alternative bayesian approach to ensemble trees methods bart is similar to rf approaches and boosting methods freund and schapire 1997 but bart is defined by a prior and a likelihood using a full statistical model allows for point and interval estimates of the underlying regression equations and the marginal effects of predictors chipman et al 2010 the bart model resembles a simple sum of trees model but uses priors on the size and make up of the trees to keep the individual tree effects small chipman et al 2010 and limit the effect of each component tree to prevent any individual tree from dominating the estimate specifically the model is given by y i t 1 t f t x i ε i with prior distributions placed on the trees f t and the variance σ 2 of the errors ε i the priors serve a similar purpose to the randomization in random forests forcing the model to give weight to a more diverse collection of trees and allowing for a more robust estimate with these priors in place the bart model can be efficiently fit using a bayesian backfitting mcmc algorithm developed by hastie and tibshirani 2000 5 results 5 1 summary the results of our study suggest that water use is strongly temporally correlated and that accounting for temporal dependence is more effective at producing accurate forecasts than modeling associations with exogenous features the explicitly temporal and spatio temporal models give the best one month ahead forecast accuracy while providing the most accurate i e narrow prediction intervals that achieve nominal empirical coverage rates including spatial correlations in the model did not improve forecasts the estimated correlation between two households was greater than 0 05 only for homes less than 100 m apart implying that spatial dependence decays rapidly as the distance between sites increases the simple ar 1 models outperform each ml algorithm even when fit with a shared autocorrelation coefficient ρ their remarkable relative performance can be explained by both the strength of the temporal relationships and the weak predictive power of the model covariates and suggests that the household specific temporal dynamics within the data is the strongest driving force behind observed variation in water usage that is a given household s previous water use is more predictive of its future use than external factors such as precipitation etc however we did find some evidence that ml techniques may be useful in quantifying long term uncertainty of the forecasts in particular the rf provided the best 12 month ahead uncertainty quantification and approached the performance of the ar 1 model for long term point prediction accuracy the out of bag variable importance metrics for rf indicates that the temporal trend and its nonlinear associations with other covariates has the greatest impact on the quality of the forecasts see supplemental fig 7 metrics related to building and lot size including heated area overall green space and land value were the next most important features these covariates likely serve as proxies for the household size and irrigated land area in the tables below we compare aggregated results for 1 month and k months ahead forecasts for statistical models with dependence and the ml models lines 4 10 sections 4 2 4 3 using the results of linear and linear mixed models lines 1 3 section 4 1 as baselines 5 2 model comparison the results for one month ahead are shown in table 3 for one month ahead forecasts the ml methods underperform the simpler time series methods the ar 1 model had the lowest rmse and outperformed the spatio temporal st model which included spatial effects along with an autoregressive term the arima model had the best gini awpi and nois which indicates that it provides the best forecasted orderings of households and best short term uncertainty quantification the gam without short range dependence performed the worst underperforming even the household specific monthly mean model likely because predictions were based on extrapolating spatio temporal trends into the future rather than relying on temporal autocorrelation as noted in deoreo and mayer 2012 the gam identified an overall decreasing trend in water use over the time period of our study but this information was not useful for competitive forecasting the rf bart and gbm had similar point prediction performance but the interval predictions made by bart were often too low all three tree based methods performed better than the linear fixed effects models but considerably worse overall than the temporal and spatio temporal models with the exception of gam additional techniques were also attempted but performed very poorly in initial tests and were removed from the study most notably neural networks ripley 1996 and fixed rank kriging cressie and johannesson 2008 were unable to provide accurate prediction on even moderately sized datasets the k month ahead assessment is shown in table 4 the results were similar for k months ahead forecasts with some important differences again the ar 1 model performed best but other methods made forecasts with competitive accuracy and all models outperformed the simple monthly mean model most methods also improved upon the individual mean models and several performed better than the random effects model notably the rf outperformed all models except the ar 1 with respect to rmse and was ranked best by nois even though its ecpi was somewhat below nominal this indicates that exogenous variables may be useful for long term forecasts especially with respect to uncertainty quantification and allow us to improve over monthly mean models which ignore these covariates fig 4 shows how the validation metrics change for each model as we predict further into the future the rmse tends to increase while gini generally decreases as expected the prediction interval widths increase for ar 1 arima and st models but stay somewhat constant for gam rf and bart for arima the prediction intervals are initially the lowest but by 12 months out become the highest of all competing methods possibly due to the additional uncertainty in estimating a large number of parameters it is clear that the gam and bart performed quite poorly for all forecasts 6 discussion the results of this study indicate that autoregressive models provide the most accurate short term forecasts of monthly water use at the household level monthly water usage displays significant variability both within and between households which is largely unexplained by the available covariates the data aggregated spatially exhibits seasonal trends with water usage varying along with seasonal rainfall patterns however month to month household specific temporal variation tends to overwhelm these patterns transformations of the response were attempted including log transformation and the box cox power family of transformations but did not improve model performance except for the spatio temporal model despite the advanced models applied the most accurate predictor of future water use by rmse remained the simple ar 1 model using only the previous months water usage to predict future usage however the rf provided the best long term uncertainty quantification and its forecasts approached those of the ar 1 in quality the spatial correlation within our water use data decays rapidly as distance increases correlations between water use at two households 100 m apart or more were estimated to be below 0 05 suggesting a small neighborhood effect that was not useful for improving forecast accuracy over simpler models as a result spatio temporal models struggle to perform better than the temporal only models the high spatial variability results in very low estimates for our spatial correlation parameters and accounting for spatial dependence leads to no improvements in prediction accuracy over temporal only models the slightly reduced predictive performance of the spatio temporal models on these data appears to be the price for their increased complexity relative to the simpler ar 1 model that is nested in our spatio temporal models due to the use of the exponential correlation function adding covariates to the spatio temporal and temporal models did not improve prediction the covariates available are not strongly associated with monthly water use particularly when the serial correlation is accounted for one obvious shortcoming of the covariates is the lack of exact information on the number of residents in each household the current data only included census block level estimates for residents per household which was not found to be predictive the household specific variables most correlated with monthly water use are those that are associated with the size of the parcel it is likely that these variables are proxies for outdoor irrigation which has been shown to be a driver of water use in florida haley et al 2007 marella 2014 the low predictive efficacy of the available covariates also limits the effectiveness of our ml algorithms even when assuming future covariate values such as precipitation are known the ml methods do not provide forecasts as accurate as time series models in real world applications ml forecasts would be necessarily based on predicted features which would introduce additional forecast error each of the ml techniques applied is capable of accounting for temporal dependence using time as a feature however they do not include an explicit model of temporal or spatial correlation instead treating space and time as ordinary covariates as a result the ml algorithms trade temporal and spatial structure for flexibility in utilizing what have turned out to be largely non predictive covariates at the request of a referee we also applied a subset of models to aggregated water demand to illustrate the use of some proposed models for forecasting total water demand with details given in the supplementary material improved data collection and methods are necessary to increase prediction accuracy for household level monthly water usage higher resolution covariates may potentially increase forecast quality especially long term forecasts forecasts may also be improved by using utilities specific predictors such as pricing rebate programs and water restriction policies and their interactions with additional household level demographic information such as income kenney et al 2008 it is likely that extending the size of the dataset to increase the spatial density of the observations would improve spatio temporal model performance by capturing possible short range spatial dependence among neighboring houses however this would require further simplifications within the models or and access to distributed data and computing resources to make them computationally feasible our models required several hours to several days to run with the exception of the time series models which ran for several minutes our investigation of reduced dimension models such as fixed rank kriging cressie and johannesson 2008 resulted in overly smooth spatial components that were unable to capture the high resolution spatial variation present in our data 7 conclusion this research sought to identify methods for improving forecasts of household level water demand motivated by the data collected for the tampa bay area time series models were able to improve forecasts of water demand over simpler monthly average models multiple linear regression and sophisticated machine learning models even when future environmental features were assumed known machine learning methods failed to provide forecasts as accurate as time series models although some small spatial correlation was present incorporating spatial dependence into the models did not significantly improve forecast quality due to the fact that spatial correlations decay rapidly as distance between two households increases this study filled a gap in the literature by assessing the quality and uncertainty of machine learning methods for forecasting urban water demand machine learning methods were able to provide better long term prediction and uncertainty quantification machine learning temporal and spatio temporal models all have the capacity to create models which help managers efficiently manage water utilities meet growing demand in urban areas by predicting household level water use by describing household level water use trends and identifying less efficient homes and high users whose predicted water use is large relative to lot and or household size 8 software and data availability all methods were implemented in the statistical environment r r core team 2016 machine learning methods were done using the freely available packages randomforest quantregforest rf gbm gbm mgcv gam and bayestree bart the random effects model was fit using lme4 the forecast package was used to create autoregressive and arima models the spatio temporal models were constructed in r and c with the aid of the rcpp package and are available at github com hrmerrill ems 2017 supp code the machine learning and spatio temporal models were run on the university of florida high performance cluster at this stage we do not have the permission to release or make the data publicly available appendix a supplementary data the following is the supplementary data related to this article mmc1 mmc1 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 01 002 
26417,forecasts of water use are crucial to efficiently manage water utilities to meet growing demand in urban areas improved household level forecasts may be useful to water managers in order to accurately identify and potentially target for management and conservation low efficiency homes and relative high demand customers advanced machine learning ml techniques are available for feature based predictions but many of these methods ignore multiscale spatiotemporal associations that may improve prediction accuracy we use a large dataset collected by tampa bay water a regional water wholesaler in southwest florida to evaluate an array of spatiotemporal statistical models and ml algorithms using out of sample prediction accuracy and uncertainty quantification to find the best tools for forecasting household level monthly water demand time series models appear to provide the best short term forecasts indicating that the temporal dynamics of water use are more important for prediction than any exogenous features keywords predictive modeling spatial modeling time series tree based methods uncertainty quantification urban water use 1 introduction rapidly increasing urban populations have put new stress on water utilities as they try to meet growing demands for water effective management of water utilities requires anticipating future water use both in the short term in order to efficiently meet demand and over longer temporal ranges so that they may best allocate scarce investment resources accurate household level forecasts may be used for correctly anticipating future demand and identifying households that are predicted to use large quantities of water relative to lot and or household size in the future as potential targets for efficiency monitoring however creating these accurate predictive models for utilities data can be challenging due to the vast amounts of data involved donkor et al 2014 summarized water demand forecasting methodologies used by utilities some of these methods rely on simple per capita usage averages which have considerable deviation around the mean the public supply gross per capita use in florida was 134 gallons per person per day in 2010 but ranged from less than 100 to more than 200 by county marella 2014 others use simulations and scenario based decision systems to model future water demand williamson et al 2002 billings and jones 2008 polebitski et al 2011 more advanced forecasting techniques have been proposed using time series models including linear regression autoregressive integrated moving average arima models stochastic process models and artificial neural networks ann the success of ann models in particular billings and jones 2008 bennett et al 2013 tiwari and adamowski 2015 suggests that additional nonparametric machine learning ml techniques could produce similar or superior forecasts however very few studies have assessed the quality or uncertainty of water demand forecasts made by machine learning methods this paper seeks to address this gap in the literature other studies have modeled water use on finer timescales e g daily and hourly with the data recorded by smart meters herrera et al 2010 cominola et al 2015 however not all water providers collect data at the daily or hourly resolution specialized approaches have been developed that focus on household demand and in particular that of single family homes deoreo and mayer 2012 provide a thorough end use analysis of fixtures and various uses of water in the household this detailed analysis results in a precise per capita use estimate for households presumably this information could be used to forecast future water demand if one knew the relative growth and composition of future household construction however even knowing details on end uses requires knowledge of population growth and prediction of new construction trends deoreo and mayer 2012 point out that indoor use declined from 187 gpd household on homes built in the early 1990s to 162 gpd household for homes built around 2007 and as low as 107 gpd household for new high efficiency homes this decrease of indoor demand was primarily due to high efficiency toilets and clothes washers mandated and used in newer construction similarly abdallah and rosenberg 2014 attributed changes in indoor water use over time to efficiency gains in technology and not to conservative behavior however deoreo and mayer 2012 point out that outdoor use did not change between the older and newer homes this observation is important since outdoor use e g irrigation in southern states like florida has been shown to be as high as 74 of total household water use in typical landscapes haley et al 2007 the purpose of this paper is to evaluate alternatives for water demand forecasting and to compare several advanced machine learning techniques and spatio temporal models that are available for feature based predictions our goal is to determine if these alternative models can improve prediction and uncertainty quantification of the forecasts as judged by root mean squared error rmse and prediction interval based metrics such as the width and empirical coverage rate respectively the ml algorithms considered in this paper are random forest rf bayesian additive regression trees bart and gradient boosting algorithms gbm see e g friedman et al 2001 for an overview and algorithmic details of these models these methods make use of exogenous features but do not explicitly take into account multiscale spatial and temporal associations that may improve predictive quality of the models in high spatio temporal resolution e g monthly household water demand for comparison we also evaluate the prediction accuracy and uncertainty quantification of an array of statistical models which explicitly include parametric dependence and semiparametric trend structures to account for spatio temporal dynamics and compare these models with our nonparametric ml algorithms in order to identify the best tools for forecasting water demand the models developed here do not make any assumptions about rates of urban growth changes in construction methods improvements in water efficiency or other global drivers of water use if the true relationship between the features used to create the models and water usage is altered by changes in exogenous factors the models need only be refit using updated data the only constraint on the models adapting to exogenous changes is the rate at which new data becomes available which includes these altered dynamics the data set used for this study contains monthly total water usage by single family homes from tampa bay water tbw a water authority operating within the southwest florida water management district swfwmd for three member governments located in hillsborough pasco and pinellas counties recorded approximately from 1998 to 2010 with some variation by region boyer et al 2014 the data includes monthly water usage collected for each household parcel based on billing records parcel and billing records were augmented with environmental covariates including precipitation evapotranspiration and temperature this case study allows us access to a large amount of high quality data which has been screened for accuracy and completeness and hence presents an excellent opportunity to evaluate ml and spatio temporal models for predicting water usage within a municipal utility this manuscript is organized as follows section 2 outlines the available data and the covariates used in our study section 3 describes the models used in our analysis and the criteria by which they are evaluated section 5 presents our model comparisons and section 6 provides further discussion of these results and directions for possible future study as per editor s request we provide magnified versions of all figures in the supplements at the end of the manuscript 2 data 2 1 water use data the dataset considered here consists of monthly potable water billing records water usage data from tbw for parts of three counties in east central florida hillsborough pasco and pinellas and recorded approximately from 1998 to 2010 with some variation by region boyer et al 2014 the data includes between 6 months and 12 years of monthly records from over one million unique customers with water usage collected in monthly increments for each unique parcel based on billing records for this study we use only parcels which contain exactly one single family residence to focus on household level water demand the data is both spatial and temporal in nature with observations throughout the tampa bay region this paper focuses on forecasting the total water usage per month in each parcel to increase the number of statistical and ml methods for comparison and to mitigate computational burdens in comparing the methods our analysis focused on a representative subset of over 100 000 observations household month records within the city of tampa shown in fig 1 c to allow for the full scope of spatio temporal models to be used for forecasting we focused on 973 households without missing data over 137 months see section 4 2 2 for details on this constraint the data exhibits significant spatio temporal heterogeneity fig 1 shows the location of the study within florida and the spatial distribution of the households and water usage included in this study fig 2 shows the total monthly water use for each household as multiple time series while there are aggregate trends the patterns within individual households are much less regular the highlighted lines indicate the monthly water usage of two typical individual households which shows strong autocorrelation and possible seasonal variation as well as less structured household specific temporal variation the average across all households is also shown and the figure indicates that the variation of household water use around the mean is quite large as an exploratory step we view the spatial heterogeneity and temporal structure of the data aggregated to census blocks in fig 3 a which shows the total water use for each census block averaged over time and indicates that some spatial dependence may be present in the data but with significant between household variation observed within even very small spatial areas the totals are highly skewed and many billing records are missing from the full data set a simple exploratory time series model was fit to each census block and the estimated one month autocorrelation coefficients for each block are shown in fig 3 b almost all of the coefficients are over 0 5 and many are near one indicating strong temporal dependence of water usage over the entire region and implying that autoregressive time series models may be effective at producing accurate forecasts additional acf and pacf plots in figs 5 and 6 of the supplemental materials reinforce the appropriateness of temporal and spatio temporal models to the water use dataset 2 2 covariates several exogenous variables were identified as potential predictors of total monthly water use outdoor water use e g irrigation can account for a high percentage of total water use in florida and irrigation is potentially influenced by weather e g precipitation evapotranspiration and irrigated area e g green space the covariates were screened for inclusion in the models using variance inflation factors vifs to account for a high level of collinearity within the potential predictors a vif for each covariate x j was obtained by regressing the variable on all other explanatory variables and calculating 1 1 r j 2 where r j 2 is the coefficient of determination for this regression model covariates with sufficiently high vif values were removed for this application we removed all covariates with vifs greater than 5 based on our preliminary study examining the vif cutoff above which variables made little to no improvement in prediction quality two broad types of covariates were used in this research environmental and parcel specific environmental covariates include monthly averages for rainfall evapotransporation and daily maximum temperature these covariates were recorded via satellite throughout the tampa bay region and values were applied over a grid of 2 km by 2 km pixels monthly average precipitation and monthly average evapotranspiration data was obtained from the usgs 2005 2011 and swfwmd exploratory data analyses revealed that both precipitation and evapotranspiration are potentially predictive in our models but that average daily maximum temperature is not a significant predictor a geographic information system gis shapefile for the corresponding 2 km by 2 km pixel grid was also provided by swfwmd additionally soil type data was obtained from the usda soil data mart usda natural resources conservation service u s dept of agriculture 2013 soil data were available by county and included soil types available water holding capacity awhc and gis shapefiles of soil polygons the only soil covariate found to be potentially predictive during exploratory analyses was awhc the parcel specific measures included were land value building value structure footprint area the year the most recent structure was built green space defined as vegetated area within the parcel and the area of heated structures on the parcel each of which were collected from the florida department of revenue the data was supplied as gis shapefiles for each parcel which provided the easting and northing values giving the centroid of each parcel the parcel shapefiles were then matched to monthly water usage data by parcel identification number and overlaid by the environmental pixels finally temporal variables were included as month and year of observation and the number of days within the observed month table 1 shows descriptive statistics for each predictor 3 methods in this study predictive performance of classical time series models spatio temporal gaussian process models and several popular modern ml algorithms for forecasting household level monthly water demand were evaluated using both point rmse gini score and interval forecast metrics empirical coverage interval width interval score more details on the metrics used for prediction evaluation are presented in section 3 1 all methods were implemented in the statistical environment r and are freely available r core team 2016 each method was fit to a subset of historical data and used to make forecasts for left out test data as described in section 3 2 essential details for the predictive models used are reviewed in sections 4 1 4 3 3 1 forecast metrics our measurement criteria for model performance were the root mean squared error rmse gini coefficient gini average prediction interval width awpi average empirical coverage rate ecpi and the negatively oriented interval score nois gneiting and raftery 2007 the formulas for the comparison metrics are given in table 2 the rmse measures the average prediction error for held out data while the gini coefficient provides a measure of how well a ranked list of predicted values lines up with a ranked list of the true values in the test data the gini coefficient is a measure of how well low and high demand households are identified the gini coefficient can be visualized as the area between the cumulative prediction of our models and those of simple overall mean model a gini coefficient closer to one suggests that the model performs well in correctly predicting when observations will be below or above the overall data mean while a gini coefficient of zero indicates that the model performs as poorly as merely predicting the overall mean for all future observations the prediction interval width allows us to compare uncertainty in model predictions while the empirical coverage rate allows one to assess whether the uncertainty quantification by the prediction intervals is accurate i e the empirical coverage rate of the prediction intervals on left out test data is close to the nominal coverage probability in this manuscript we use one sided upper 95 prediction intervals to assess how well our models quantify the uncertainty of extreme water use by each household water use is strictly non negative so each prediction interval has a lower bound at zero the nois serves as a combination of awpi and ecpi penalizing models for large intervals and for empirical rates that differ from theoretical expectations specifically the nois is computed as the awpi plus a penalty for each prediction interval that does not contain the true value the penalty is proportional to the distance of the observation from the prediction interval boundary with these criteria we evaluate how well our models make forecasts how well they quantify uncertainty and how well they can identify and separate low and high demand users 3 2 validation to validate forecasts from each predictive model the data were split into training and test subsets the forecasts were validated by both short term one month ahead and longer term k months ahead for k 2 12 forecasts because of the temporal dependence in the data one cannot take a random subset for training and validation but must maintain temporal ordering within training and validation subsets so as to capture temporal dynamics for short term forecasts the training data consisted of all past observations preceding the month of the forecast which was held out as the test subset this was repeated 12 times for the last 12 months in the data set to reflect a real world scenario where data is continuously added to the model the fitted model is updated and used to forecast demand in the next month the assessment metrics were averaged over each of the 12 months to provide an aggregate measure of one month forecast accuracy for longer term forecasts the test set contained all observations for the last 12 months in the data set forecasts were made for each of the 12 months in the test set by holding the training data set fixed without adding additional data or refitting a model the assessment metrics were again averaged for each of the 12 months predicted for both short and long term assessments the test sets contain all households in the study that is no subset of water usage is observed within the month being predicted to align with real world forecasting needs for feature based ml models the future predictor values e g next month s precipitation were assumed known when making forecasts it should be noted that using predicted values for as yet unobserved features such as historical averages for monthly precipitation would introduce additional uncertainty and noise into the predictions 4 models 4 1 baseline regression models 4 1 1 linear and linear mixed models with month effects in this section we outline three linear and linear mixed models mcculloch and searle 2003 to provide a baseline for the more complex methods to follow in subsequent sections in order to investigate the improvements that can be made by machine learning methods and by accounting for temporal and spatial dependence the simplest model fit is a monthly mean model the average total water use is calculated for the combined households for each month and used as the predictor of future water usage statistically the model is a one way anova model y i j α m j ε i j where y i j is the total water use for household i during month j α m j is the fixed effect population mean of the calendar month m j 1 12 shared by all households and ε i j is a gaussian white noise process the model is then extended to fit monthly means for each household separately i e using a two way anova with household month interaction as y i j α m j γ i m j ε i j where γ i m j are fixed i e nonrandom household specific effects of the months constrained as i γ i m j 0 for identifiability finally a random effects model is fit with shared monthly means and random household deviations from these means the model is still y i j α m j γ i m j ε i j but the vectors γ i 1 γ i 12 are now independent multivariate normal household specific random effects deviations from the grand monthly means α 1 α 12 the advantage of the random effects model is reduction in the effective number of model parameters since the γ i m j are integrated out rather than estimated and consequently potential reduction in the estimation error for model parameters and mitigation of overfitting 4 1 2 linear regression we also fit a multiple linear regression model as another baseline for comparison with forecasts by other competing models this model regresses household monthly water use on predictors and their two way interactions to account for any interacting effects that may boost forecast performance stepwise variable selection using the akaike information criterion aic was performed to exclude insignificant effects and avoid overfitting friedman et al 2001 all main effects as well as 45 out of a possible 55 two way interactions were chosen by the variable selection procedure the model is given by y i j x i j β ε i j where x i j is the vector of selected predictors and two way interactions for the i t h household and j t h month and β is the vector of regression coefficients given an estimate β ˆ for β forecasts for timepoint j are made using y ˆ i j x i j β ˆ 4 2 space time models 4 2 1 time series models ar 1 and arima the autoregressive model with a lag of one month ar 1 model regresses the water usage observation y i j on its lagged value as y i j μ i j ρ i y i j 1 μ i j 1 ε i j where μ i j is a deterministic e g linear mean function of covariates ρ i is the autoregressive coefficient and ε i j is gaussian white noise lütkepohl 2005 the simplest special case is the global model without covariates where the intercepts and autoregressive coefficients are shared by all households i e μ i j μ 0 and ρ i ρ for every i and j an expanded ar 1 model with household specific intercepts and a shared autoregressive coefficient was also fit in addition to the standard ar 1 model we fit autoregressive integrated moving average arima models to our data these models expand on the ar 1 models by differencing the data to achieve approximate stationarity and model the time series of the differenced data as an autoregressive moving average process the arima models were fit using an automatic algorithm that selects household specific autoregressive differencing and moving average parameters i e the orders p d q and corresponding coefficients by optimizing the aic for this study an arima p d q model has the form 1 k 1 p α k l k 1 l d z i j 1 k 1 q β k l k ε i j which uses differencing order d and where z i j y i j μ i j l is the lag operator i e l k z i j z i j k α k are the p autoregressive coefficients and β k are the q moving average coefficients for more details on arima models see e g lütkepohl 2005 4 2 2 spatio temporal gaussian process models st water demand may be spatially correlated due to unobserved spatially varying factors and capturing spatial correlations if present can improve predictive accuracy however spatio temporal models for large data are often computationally expensive if tractable at all sun et al 2012 for a univariate second order stationary random field with respective spatial and temporal domains s and t under balanced space time sampling where n s and n t represent the dimensions of the spatial and temporal components we would need to perform inversion or factorization of a n s n t n s n t covariance matrix to avoid these prohibitive computation tasks we make use of separable covariance structures separable covariance functions are a class of spatio temporal covariance structures that mitigate computationally expensive matrix manipulations in geostatistical models for a univariate second order stationary random field w s t s t s t with spatial and temporal domains s ℝ 2 and t ℝ let c h u cov w s t w s h t u be the covariance function determined only by the spatial and temporal lags h and u a space time separable covariance function is defined as c h u c h 0 c 0 u c 0 0 that is the covariance function can be factored into a product of spatial only and temporal only covariance functions e g exponential covariance function that we use in our study cressie and wikle 2011 banerjee et al 2014 when the data is completely observed e g water use is observed for each household for the same set of months space time separability allows the full covariance matrix σ to be written as a kronecker product of two smaller matrices as σ σ s σ t where the spatial and temporal covariance matrices σ s and σ t are determined by the appropriate covariance functions kronecker products have nice properties related to matrix inversion and factorization specifically the problem of storage and factorization of the full n s n t n s n t covariance matrix can be reduced to storage and factorization of two matrices of size n s n s and n t n t which typically reduces the computational resources necessary to fit a model and obtain predictions by orders of magnitude harville 1997 rakitsch et al 2013 furthermore space time separable processes have an intuitive interpretation for a fixed location the process evolves according to the time series defined by the temporal covariance function and for a fixed time point the spatially referenced values of the field follow a standard spatial statistical model a downside to the separability assumption is that these models require the complete observation of every location at every time point in order to take advantage of the kronecker product decomposition furthermore some spatio temporal data may exhibit a lack of space time separability and require non separable covariance functions to accurately capture spatio temporal correlations genton 2007 li et al 2008 4 2 3 generalized additive models gam the generalized additive model gam hastie and tibshirani 1986 is an extension of the generalized linear model glm in the case of gaussian models of interest in this study the expected value of the response variable is modeled as a sum of unknown smooth functions of the features 1 e y β 0 j 1 j f j x j where x x 1 x j is the vector of j features for the observation y the unknown functions f 1 f j may be represented using a linear combination of a sufficiently large set of basis functions 2 f j x k 1 k j u j k ϕ j k x where u j u j 1 u j k j are the coefficients corresponding to each basis function ϕ j k typically the basis functions are smoothing splines and include a linear term ϕ j k x x for some k the functions f 1 f j are assumed to be continuous and of low rank meaning they can be represented by a moderate number of basis functions coefficients are estimated by maximization of a penalized likelihood where the penalty is placed on some measure of the wiggliness of the functions e g an integral of the squared second derivative wood 2004 alternatively a bayesian approach may be used where the penalty is imposed through the prior on the coefficients crainiceanu et al 2005 merrill et al 2016 wood 2016 spatio temporal trends may be represented with gams as well specifically we construct f s t s t by using the tensor product of a bivariate spatial smooth and univariate temporal smooth 3 f s t s t k 1 k s u s k ϕ s k s l 1 k t u t l ϕ t l t k 1 k s l 1 k t u s t k l ϕ s k s ϕ t l t the interaction term allows for deviations from a strictly additive space time pattern in which the temporal trend would be the same at all locations ruppert et al 2003 and wood 2004 provide more information about choice of ϕ s k s etc space time gams may be used in conjunction with covariance functions the model for the mean of the response is a gam while the covariance function for the response uses a separable structure as in section 4 2 2 for example a space time gam with a separable covariance function and no predictors is defined by the gaussian process 4 y s t g p f s t s t c in this formulation the gam models large scale spatio temporal trends through the mean while the covariance matrix captures small scale spatio temporal variability e g bliznyuk et al 2012 2014 the full response vector y y s 1 t 1 y s 1 t 2 y s s t t is normally distributed with mean f s t s 1 t 1 f s t s 1 t 2 f s t s s t t and covariance matrix σ s σ t assuming no missing data any unknown parameters may be estimated by maximum likelihood typically restricted reml or markov chain monte carlo mcmc 4 3 machine learning algorithms the temporal and spatio temporal models described above were compared with popular ml algorithms which do not explicitly account for spatio temporal dependency the selected ml algorithms are random forests rf bayesian additive regression trees bart and gradient boosting machines gbm bart rf and gbm are sum of trees models which are built from simple decision trees the methods selected have a history of performing well on a wide variety of nonlinear problems the capability to handle large amounts of heterogeneous features e g continuous categorical and binary and are well suited for construction of prediction intervals additional methods including artificial neural networks elasticnet models and lasso regression were also tested in preliminary work and discarded due to underperformance severe computational demands or inapplicability to interval based prediction the final models chosen are all flexible nonlinear models that have produced excellent results in creating predictions from large complex data sets chipman et al 2010 below we provide outlines of the methods full mathematical details are available in friedman et al 2001 4 3 1 gradient boosting machine gbm gradient boosting machines combine simple models iteratively to create a single ensemble estimate the gbm is a boosting model which iteratively builds an additive model by fitting regression trees to the gradient of the loss function and adding them into the model friedman 2001 at step t a new tree model f t x is fit to the vector of residuals r of the current ensemble model f x subsequently the current ensemble is updated using a shrunken version of f t x as f x f x λ f t x and the kth residual is updated as r k r k λ f t x k for k 1 n the final forecast by a boosted model is y ˆ x λ t 1 t f t x although our gbm models include temporal and spatial covariates no explicit structure is specified for spatio temporal dependence a grid search with five fold cross validation is used for choosing tuning parameters λ and t the optimal set of parameters is used to make forecasts on the test set 4 3 2 random forest rf random forests are sum of trees models which are built on decision trees breiman 2001 random forests fit a fixed typically large number t of decision trees f 1 f t each to a different bootstrap subsample of the training data specifically for a given dataset of size n each tree is created by taking n samples with replacement from the full dataset i e bootstrapping to prevent a single tree or variable from dominating at each stage in the tree growth process only a randomly selected subset of size m of the candidate covariates is considered for splitting restricting covariates on which splitting occurs helps to further explore the space of possible trees and prevents dominant trees from overpowering the ensemble the number of trees t and the subset size m are a tuning parameter that are calibrated to achieve an optimal trade off between the computational costs of fitting additional trees and the increase in accuracy they provide to form predictions the new data is fed into each decision tree and the results of all terminal nodes are averaged into a single prediction for each new observation as y ˆ x t 1 t f t x t the mean of the predictions from each tree f t t 1 t random forest also provides an out of bag estimate of model sensitivity to individual variables and interactions further details and illustration are provided in fig 7 in the supplemental materials 4 3 3 bayesian additive regression trees bart bayesian additive regression tree bart models are an alternative bayesian approach to ensemble trees methods bart is similar to rf approaches and boosting methods freund and schapire 1997 but bart is defined by a prior and a likelihood using a full statistical model allows for point and interval estimates of the underlying regression equations and the marginal effects of predictors chipman et al 2010 the bart model resembles a simple sum of trees model but uses priors on the size and make up of the trees to keep the individual tree effects small chipman et al 2010 and limit the effect of each component tree to prevent any individual tree from dominating the estimate specifically the model is given by y i t 1 t f t x i ε i with prior distributions placed on the trees f t and the variance σ 2 of the errors ε i the priors serve a similar purpose to the randomization in random forests forcing the model to give weight to a more diverse collection of trees and allowing for a more robust estimate with these priors in place the bart model can be efficiently fit using a bayesian backfitting mcmc algorithm developed by hastie and tibshirani 2000 5 results 5 1 summary the results of our study suggest that water use is strongly temporally correlated and that accounting for temporal dependence is more effective at producing accurate forecasts than modeling associations with exogenous features the explicitly temporal and spatio temporal models give the best one month ahead forecast accuracy while providing the most accurate i e narrow prediction intervals that achieve nominal empirical coverage rates including spatial correlations in the model did not improve forecasts the estimated correlation between two households was greater than 0 05 only for homes less than 100 m apart implying that spatial dependence decays rapidly as the distance between sites increases the simple ar 1 models outperform each ml algorithm even when fit with a shared autocorrelation coefficient ρ their remarkable relative performance can be explained by both the strength of the temporal relationships and the weak predictive power of the model covariates and suggests that the household specific temporal dynamics within the data is the strongest driving force behind observed variation in water usage that is a given household s previous water use is more predictive of its future use than external factors such as precipitation etc however we did find some evidence that ml techniques may be useful in quantifying long term uncertainty of the forecasts in particular the rf provided the best 12 month ahead uncertainty quantification and approached the performance of the ar 1 model for long term point prediction accuracy the out of bag variable importance metrics for rf indicates that the temporal trend and its nonlinear associations with other covariates has the greatest impact on the quality of the forecasts see supplemental fig 7 metrics related to building and lot size including heated area overall green space and land value were the next most important features these covariates likely serve as proxies for the household size and irrigated land area in the tables below we compare aggregated results for 1 month and k months ahead forecasts for statistical models with dependence and the ml models lines 4 10 sections 4 2 4 3 using the results of linear and linear mixed models lines 1 3 section 4 1 as baselines 5 2 model comparison the results for one month ahead are shown in table 3 for one month ahead forecasts the ml methods underperform the simpler time series methods the ar 1 model had the lowest rmse and outperformed the spatio temporal st model which included spatial effects along with an autoregressive term the arima model had the best gini awpi and nois which indicates that it provides the best forecasted orderings of households and best short term uncertainty quantification the gam without short range dependence performed the worst underperforming even the household specific monthly mean model likely because predictions were based on extrapolating spatio temporal trends into the future rather than relying on temporal autocorrelation as noted in deoreo and mayer 2012 the gam identified an overall decreasing trend in water use over the time period of our study but this information was not useful for competitive forecasting the rf bart and gbm had similar point prediction performance but the interval predictions made by bart were often too low all three tree based methods performed better than the linear fixed effects models but considerably worse overall than the temporal and spatio temporal models with the exception of gam additional techniques were also attempted but performed very poorly in initial tests and were removed from the study most notably neural networks ripley 1996 and fixed rank kriging cressie and johannesson 2008 were unable to provide accurate prediction on even moderately sized datasets the k month ahead assessment is shown in table 4 the results were similar for k months ahead forecasts with some important differences again the ar 1 model performed best but other methods made forecasts with competitive accuracy and all models outperformed the simple monthly mean model most methods also improved upon the individual mean models and several performed better than the random effects model notably the rf outperformed all models except the ar 1 with respect to rmse and was ranked best by nois even though its ecpi was somewhat below nominal this indicates that exogenous variables may be useful for long term forecasts especially with respect to uncertainty quantification and allow us to improve over monthly mean models which ignore these covariates fig 4 shows how the validation metrics change for each model as we predict further into the future the rmse tends to increase while gini generally decreases as expected the prediction interval widths increase for ar 1 arima and st models but stay somewhat constant for gam rf and bart for arima the prediction intervals are initially the lowest but by 12 months out become the highest of all competing methods possibly due to the additional uncertainty in estimating a large number of parameters it is clear that the gam and bart performed quite poorly for all forecasts 6 discussion the results of this study indicate that autoregressive models provide the most accurate short term forecasts of monthly water use at the household level monthly water usage displays significant variability both within and between households which is largely unexplained by the available covariates the data aggregated spatially exhibits seasonal trends with water usage varying along with seasonal rainfall patterns however month to month household specific temporal variation tends to overwhelm these patterns transformations of the response were attempted including log transformation and the box cox power family of transformations but did not improve model performance except for the spatio temporal model despite the advanced models applied the most accurate predictor of future water use by rmse remained the simple ar 1 model using only the previous months water usage to predict future usage however the rf provided the best long term uncertainty quantification and its forecasts approached those of the ar 1 in quality the spatial correlation within our water use data decays rapidly as distance increases correlations between water use at two households 100 m apart or more were estimated to be below 0 05 suggesting a small neighborhood effect that was not useful for improving forecast accuracy over simpler models as a result spatio temporal models struggle to perform better than the temporal only models the high spatial variability results in very low estimates for our spatial correlation parameters and accounting for spatial dependence leads to no improvements in prediction accuracy over temporal only models the slightly reduced predictive performance of the spatio temporal models on these data appears to be the price for their increased complexity relative to the simpler ar 1 model that is nested in our spatio temporal models due to the use of the exponential correlation function adding covariates to the spatio temporal and temporal models did not improve prediction the covariates available are not strongly associated with monthly water use particularly when the serial correlation is accounted for one obvious shortcoming of the covariates is the lack of exact information on the number of residents in each household the current data only included census block level estimates for residents per household which was not found to be predictive the household specific variables most correlated with monthly water use are those that are associated with the size of the parcel it is likely that these variables are proxies for outdoor irrigation which has been shown to be a driver of water use in florida haley et al 2007 marella 2014 the low predictive efficacy of the available covariates also limits the effectiveness of our ml algorithms even when assuming future covariate values such as precipitation are known the ml methods do not provide forecasts as accurate as time series models in real world applications ml forecasts would be necessarily based on predicted features which would introduce additional forecast error each of the ml techniques applied is capable of accounting for temporal dependence using time as a feature however they do not include an explicit model of temporal or spatial correlation instead treating space and time as ordinary covariates as a result the ml algorithms trade temporal and spatial structure for flexibility in utilizing what have turned out to be largely non predictive covariates at the request of a referee we also applied a subset of models to aggregated water demand to illustrate the use of some proposed models for forecasting total water demand with details given in the supplementary material improved data collection and methods are necessary to increase prediction accuracy for household level monthly water usage higher resolution covariates may potentially increase forecast quality especially long term forecasts forecasts may also be improved by using utilities specific predictors such as pricing rebate programs and water restriction policies and their interactions with additional household level demographic information such as income kenney et al 2008 it is likely that extending the size of the dataset to increase the spatial density of the observations would improve spatio temporal model performance by capturing possible short range spatial dependence among neighboring houses however this would require further simplifications within the models or and access to distributed data and computing resources to make them computationally feasible our models required several hours to several days to run with the exception of the time series models which ran for several minutes our investigation of reduced dimension models such as fixed rank kriging cressie and johannesson 2008 resulted in overly smooth spatial components that were unable to capture the high resolution spatial variation present in our data 7 conclusion this research sought to identify methods for improving forecasts of household level water demand motivated by the data collected for the tampa bay area time series models were able to improve forecasts of water demand over simpler monthly average models multiple linear regression and sophisticated machine learning models even when future environmental features were assumed known machine learning methods failed to provide forecasts as accurate as time series models although some small spatial correlation was present incorporating spatial dependence into the models did not significantly improve forecast quality due to the fact that spatial correlations decay rapidly as distance between two households increases this study filled a gap in the literature by assessing the quality and uncertainty of machine learning methods for forecasting urban water demand machine learning methods were able to provide better long term prediction and uncertainty quantification machine learning temporal and spatio temporal models all have the capacity to create models which help managers efficiently manage water utilities meet growing demand in urban areas by predicting household level water use by describing household level water use trends and identifying less efficient homes and high users whose predicted water use is large relative to lot and or household size 8 software and data availability all methods were implemented in the statistical environment r r core team 2016 machine learning methods were done using the freely available packages randomforest quantregforest rf gbm gbm mgcv gam and bayestree bart the random effects model was fit using lme4 the forecast package was used to create autoregressive and arima models the spatio temporal models were constructed in r and c with the aid of the rcpp package and are available at github com hrmerrill ems 2017 supp code the machine learning and spatio temporal models were run on the university of florida high performance cluster at this stage we do not have the permission to release or make the data publicly available appendix a supplementary data the following is the supplementary data related to this article mmc1 mmc1 appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 01 002 
26418,the soil erosion and associated lateral movement of eroded carbon c have been identified as a possible mechanism explaining the elusive terrestrial c sink of ca 1 7 2 6 pgc yr 1 here we evaluated the swat c model for simulating long term soil erosion and associated eroded c yields our method couples the century carbon cycling processes with a modified universal soil loss equation musle to estimate c losses associated with soil erosion the results show that swat c is able to simulate well long term average eroded c yields as well as correctly estimate the relative magnitude of eroded c yields by crop rotations we also evaluated three methods of calculating c enrichment ratio in mobilized sediments and found that errors associated with enrichment ratio estimation represent a significant uncertainty in swat c simulations furthermore we discussed limitations and future development directions for swat c to advance c cycling modeling and assessment keywords agriculture greenhouse gases erosion soil organic carbon software availability software swat c developer xuesong zhang operating systems windows linux dependent software fortran 90 availability free of charge swat c has been released at http swat tamu edu software swat executables within the latest version of swat the new code revision regarding eroded c yields calculation and enrichment ratio estimation will be released to the public through the swat website 1 introduction accurate quantification of carbon c cycling in the earth system is crucial for effective development of science based decision tools and management strategies aimed at reducing c emissions current estimates of global co2 fluxes consistently infer a missing terrestrial c sink also known as residual terrestrial or land sink of 1 7 and 2 6 pg c yr 1 for the 1980s and 1990s respectively ipcc 2013 this residual sink is comparable in magnitude to other major components of the global c budget e g the net ocean uptake of ca 2 3 pg c yr 1 or c emissions of ca 1 0 pg c yr 1 from land use change ciais et al 2014 a possible mechanism contributing to this missing sink is the soil erosion processes which may induce a global c sink of 0 12 1 5 pgc yr 1 smith et al 2001 stallard 1998 van oost et al 2007 quinton et al 2010 however the c dynamics across terrestrial aquatic interfaces regulated by both biotic and abiotic processes across various temporal and spatial scales remain poorly characterized given the magnitude and the degree of uncertainty associated with the erosion induced c sink there is an urgent need to elucidate its causes and mechanisms in order to avoid unexpected consequences when developing and deploying c management strategies and policies houghton 2002 soil erosion and lateral movement of sediment and nutrients from land to waters not only modify soil quality but also alter terrestrial biogeochemical cycles lal 2004 liu et al 2003 berhe et al 2007 soil erosion laterally redistributes and removes soil organic carbon soc and other nutrients across terrestrial landscapes global estimates of soc erosion fluxes have varied widely from 0 5 to 6 0 pg c yr 1 lal 2003 van oost et al 2007 müller nedebock and chaplot 2015 process based terrestrial ecosystem modeling framework based on the century terrestrial c model parton et al 1994 have been developed and tested for quantifying soc erosion and associated biogeochemical processes harden et al 1999 liu et al 2003 izaurralde et al 2007 additionally the soil erosion critically impacts trophic states as well as c stocks and flows in aquatic ecosystems cole et al 2007 tranvik et al 2009 battin et al 2009 tank et al 2010 soil erosion mobilizes and introduces large amounts of particulate organic carbon poc from upland landscapes into streams rivers and reservoirs where poc undergoes complex transport and transformation processes poc not consumed in inland waters is transported by rivers to estuarine and coastal ecosystems hope et al 1994 where it could be buried biogeochemically transformed or returned back to the atmosphere as co2 bauer and bianchi 2011 c transport and transformation processes link c cycling across terrestrial and aquatic ecosystems at the watershed scale and represent an important component of the boundless global c cycle battin et al 2009 but has not been well understood and characterized trimmer et al 2012 multiple field scale soil erosion models are available the empirically based universal soil loss equation usle wischmeier and smith 1978 wischmeir 1965 is a field scale model that is capable of simultaneously considering multiple soil erosion control factors such as surface cover terrain characteristics precipitation and conservation practices based on the usle model multiple revised methods have been proposed and widely adopted such as revised usle rusle by renard et al 1991 and modified usle musle by williams and berndt 1977 more physically based soil erosion models jetten et al 1999 nearing et al 2005 such as water erosion prediction project wepp nearing et al 1989 kinematic runoff and erosion kineros woolhiser et al 1990 european soil erosion model eurosem morgan et al 1998 and plot soil erosion model 2d psem 2d nord and esteves 2005 have been developed to explicitly represent detachment and transport processes during soil erosion ellison 1947 previous studies showed that field scale soil erosion modeling is subjective to multiple errors sources jetten et al 1999 nearing et al 2005 nord and esteves 2005 such as input data quality user s choices in preparing input data and inherent errors from simplified representation of the soil processes often the importance of different uncertainty sources varies by models and experimental data employed in general the physically based models require more detailed spatial data and finer execution time step e g minutes and are often event based a comparison of field scale soil erosion models jetten et al 1999 showed that empirically models do not underperform physically models for long term continuous simulations given the availability of terrain climate and management data and the purpose of linking erosion with soc losses for long term simulations we chose the musle soil erosion model in addition the musle has been incorporated within the swat model arnold et al 1998 which is a widely used process based watershed model for reproducing observed hydrologic and or pollutant loads across a wide range of watershed scales and environmental conditions as well as for assessing impacts of conservation practices land use climate change water management and other scenarios gassman et al 2007 using musle within the swat framework will greatly benefit future efforts to understand the fate of eroded sediments and c in downstream aquatic ecosystems and assess watershed scale c balance furthermore in recognition of the need of a coupled watershed scale c cycling model recent efforts yang and zhang 2016 yang et al 2017 zhang et al 2013b enhanced and tested swat for simulating carbon dioxide co2 and nitrous oxide n2o fluxes of diverse upland ecosystems referred to as swat c hereafter the revised coupled c nitrogen and phosphorus cycles in swat c are derived from three agroecosystem models including the century model parton et al 1994 and its daily version daycent del grosso et al 2001 the environmental policy integrated climate epic model williams 1990 izaurralde et al 2006 and the decision support system for agrotechnology transfer model dssat jones et al 2003 gijsman et al 2002 as described in zhang et al 2013b wu et al 2016 also explored the joint use of swat and daycent to assess carbon dynamics the swat c model s c module has been tested for simulating co2 fluxes at 16 eddy covariance flux towers yang and zhang 2016 zhang et al 2013b those efforts lay a solid foundation for linking terrestrial c cycling with soil erosion here the major objective of this study is to test swat c for simulating long term sediment and eroded c using the long term measurements from a small watershed w118 in the north appalachian experimental watershed naew research station hao et al 2001 the outcome resulting from this study is expected to help understand the strength and weaknesses of swat c for predicting the lateral movement of c from cropland into adjacent water bodies thereby supporting its future development and applications to help understand c cycling across terrestrial and aquatic ecosystems 2 materials and methods 2 1 description of the swat c model the swat model is a continuous long term distributed parameter hydrologic model which has been incorporated into the u s environmental protection agency us epa better assessment science integrating point nonpoint sources basins software package luzio et al 2002 and is also being considered as a core watershed model by the united states department of agriculture usda for applications in the conservation effects assessment project ceap richardson et al 2008 across watersheds in the u s for a watershed application swat subdivides a watershed into subbasins connected by a stream network and further delineates hydrologic response units hrus consisting of unique combinations of land cover and soils in each subbasin for each hru swat simulates surface and subsurface flow evapotranspiration soil moisture sediment generation carbon and nutrient cycling and plant growth and development neitsch et al 2011 the plant growth processes in swat are based on the epic model which uses a revised version of crop environment resource synthesis ceres williams et al 1989 jones et al 1991 and employs the concept of radiation use efficiency by which a fraction of daily photosynthetically active solar radiation is intercepted by the plant canopy and converted into plant biomass daily gains in plant biomass are affected by vapor pressure deficits atmospheric co2 concentrations nutrients availability and other environmental controls and stresses in the swat c version zhang et al 2013b following the century model parton et al 1994 the soil organic matter som and residue are represented with five pools plant litter is divided into the easily decomposable metabolic e g proteins and sugars and recalcitrant structural e g lignin and cell walls component an active microbial biomass pool that has a turnover of months to a few years including soil microbes and microbial products the slow humus pool receives c and n from the decomposition of structural litter metabolic litter and microbial biomass and often has a turnover time of 20 50 years the most recalcitrant som lies in the passive humus pool which includes physically and chemically stabilized som sorbed to clays with long turnover times 400 2000 years parton et al 1993 1994 in addition to substrate specific properties the decomposition and transformation of structural litter metabolic litter passive humus slow humus and microbial biomass are also influenced by abiotic factors such as soil temperature soil water content tillage enhancement oxygen availability and soil texture parton et al 1994 gijsman et al 2002 izaurralde et al 2006 swat c simulates soil erosion using the modified universal soil loss equation musle williams and berndt 1977 eroded soc loss is derived by multiplying the amount of eroded soil with the concentration of soc in mineral soils and an enrichment ratio the musle is a variant of the equation universal soil loss equation usle wischmeier and smith 1978 wischmeir 1965 and is represented in the following form 1 s e d 11 8 q s u r f q p e a k a r e a h r u 0 56 k u s l e c u s l e p u s l e l s u s l e c f r g where s e d is the sediment yield on a given day mg q s u r f is the surface runoff volume mm h2o ha 1 q p e a k is the peak runoff rate m3 s 1 a r e a h r u is the area of the hru ha k u s l e is the usle soil erodibility factor that is determined by sand clay silt and organic c content c u s l e is the usle cover and management factor dimensionless p u s l e is the usle support practice factor dimensionless l s u s l e is the usle topographic factor dimensionless c f r g is the coarse fragment factor dimension less c u s l e is land cover specific with grassland having smaller values than row crops residue collection influences this factor by reducing surface cover leading to more erosion the concentration of soc in eroded mineral soils is a product of the concentration of soc in top soil and an enrichment ratio we further use the following equation to calculate the amount of eroded soc 2 s e d c s e d c o n c s o c s o i l e r where s e d c is the eroded c yield on a given day mg c o n c s o c s o i l is the fraction of soc in the top soil layer where eroded sediment comes from e r is the ratio of the concentration of organic c transported with the sediment to the concentration in the soil surface layer in the experimental site measured e r was 1 7 hao et al 2002 which was assumed to be fixed over time in the simulation study 2 2 enrichment ratio calculation as smaller particles weigh less and are more easily transported than coarser particles the sediment load to streams often has a greater proportion of clay sized particles or enriched in clay particles som is attached primarily to colloidal clay particles so the sediment load will also contain a greater proportion of concentration of organic c than that found in the soil surface layer in swat the enrichment ratio is estimated using the following empirical formula 3 e r 0 78 c o n c s e d s u r f 0 2468 where c o n c s e d s u r f is the concentration of sediment in surface runoff mg m 3 h2o our initial assessment of the default swat enrichment ratio calculation equation eq 3 showed that it estimated much higher e r than those reported in literature that are 3 in most cases menzel 1980 this finding led us to examine other e r calculation options that have been derived from previous field experimental data here two equations are selected to understand uncertainties associated with e r calculation and subsequent implications for eroded c simulations based on multiple experimental data menzel 1980 derived a generalized equation that is hoped to hold for a wide range of vegetation and soil conditions 4 e r 7 4 s e d u 0 2 where s e d u is sediment yield per unit area kg ha 1 this relationship has been widely used in nonpoint source pollution models such as the chemicals runoff and erosion from agricultural management systems creams knisel 1980 to calculate nutrient enrichment ratios wang et al 2013 derived a soc enrichment ratio relationship based on field rainfall simulation experiments in the loam belt area in central belgium 5 e r 2 46 e 0 065 s c 1 0 where sc is sediment concentration in surface runoff with a unit of g l 1 h2o 2 3 description of the experimental site the experimental site is a small watershed w118 located within the usda s naew research station 40 22 n 81 48 w near coshocton ohio which was established in 1938 to study runoff erosion and water quality as influenced by varying agroecosystems under different crop covers and management practices more detailed description of the study site and its location is provided by owens et al 2010 the study area receives long term annual average precipitation of 937 mm 1951 1998 with a standard deviation of 49 9 mm on average spring april may and june and summer july august and september receive 283 1 mm and 269 2 mm precipitation respectively in contrast precipitation is less in autumn october november and december and winter january february and march which is 185 9 mm and 200 1 mm respectively annual average daily air temperature is above 16 0 c with average daily maximum air temperature of 16 0 c and average daily minimum air temperature 3 4 c the w118 watershed covers an area of 0 79 ha and has a slope gradient of 10 with the slope length of 132 m the sediment and eroded c transported by surface runoff were collected at the outlet of the small catchment to determine the yields of sediment and eroded c hao et al 2001 the dominant soil type of the watershed is silt loam kelly 1975 historical cropping systems have been described in hao et al 2001 kelly 1975 shipitalo and edwards 1998 and in owens and edwards 1993 and can be grouped into four major phases the first phase is between 1951 and 1970 with a four year rotation of plow tilled corn zea mays l winter wheat triticum aestivum l meadow meadow cwmm for corn years soils were plowed with moldboard disk twice and harrow once before planting in late april or early may and a rate of 56 kg ha 1 fertilizer 5 20 20 that contains 5 nitrogen 20 phosphorus 20 potash and 9 mg ha 1 cattle manure was applied or plowed into the soil corn harvesting occurred in early october with corn stover chopped and spread on the field for winter wheat soils were disked before drilling the seeds and planting date is within 2 weeks from corn harvest winter wheat received a fertilization rate of 112 kg ha 1 fertilizer 5 20 20 and was harvested in next year s early july for the two meadow years hay harvesting occurred twice in late june and early august respectively the second phase 1971 1975 experienced plow tilled continuous corn cc except no till corn in 1974 during this period soil amendments included n fertilizer of 225 kg ha 1 of urea or nh4no3 applied in spring and phosphorous applied in fall to reduce nutrient stress on plant growth the third phase 1976 193 is continuous meadow with no till and twice harvesting in late june and early august respectively the fourth phase is between 1985 and 1998 planted with a no till corn and soybean glycine max l merr rotation cs during this phase corn received n fertilizer of 225 kg ha 1 of urea or nh4no3 applied in spring and phosphorous applied in fall in general corn and soybean were planted in late april or early may and harvested october residues from corn and soybean are left intact on ground surface contour farming was adopted for row crops 2 4 model evaluation moriasi et al 2007 reviewed and summarized multiple evaluation metrics used in model skill assessment here we selected three widely used descriptive statistics that has been widely used for evaluating performance of the swat model the first metric is percent bias p b i a s gupta et al 1999 calculated as 6 p b i a s k 1 t f k y k k 1 t y k 100 where f k is the model simulated value at a time unit or location k y k is the corresponding benchmark data value and t represents the total pairs of data p b i a s measures the average tendency of the simulated data to be larger or smaller than their observed counterparts small p b i a s values means less model bias the second metric is coefficient of determination r 2 legates and mccabe 1999 7 r 2 k 1 t y k y f k f k 1 t y k y 2 0 5 k 1 t f k f 2 0 5 2 where y is the mean of observed data for the entire time period or across all sites under evaluation f is the mean of simulated data the other symbols are the same as defined above r 2 ranges between 0 0 and 1 0 and represents the proportion of the total variance in the observed data that is explained by the model the higher the r 2 values the better the model performance the third metric is nash sutcliffe efficiency e ns nash and sutcliffe 1970 8 e n s 1 0 k 1 t y k f k 2 k 1 t y k y 2 all symbols are the same as those introduced above e ns indicates how well the plot of the observed value versus the simulated value fits the 1 1 line and ranges from to 1 3 results and discussion 3 1 comparison between simulated and observed long term sediment and eroded carbon yields with a fixed e r value of 1 7 we simulated annual sediment and eroded c yields over the period of 1951 1998 fig 1 averaged over 1951 1998 swat c slightly underestimated sediment yield by 14 with the simulated average of 1 03 mg ha 1 yr 1 vs the observed average of 1 2 mg ha 1 yr 1 fig 2 for eroded c swat c simulated value of 0 022 mg c ha 1 yr 1 was 29 lower than the observed value of 0 031 mg c ha 1 yr 1 the time series plots in fig 1 also showed that swat c captured well the overall temporal pattern of sediment and eroded c yield over the simulation period in particular swat c captured years with the highest and second highest yields of sediment of 19 7 and 7 63 mg ha 1 yr 1 respectively but with less magnitude similarly we found swat c also reproduced the peak eroded c yield during those two years overall the high coefficient of determination values for both simulated sediment and eroded c yields 0 85 and 0 84 respectively indicate the capability of swat c to explain temporal variability of lateral flow of sediment and eroded c over a long period however the e ns values of 0 70 and 0 61 for sediment and eroded c yields simulations showed that there are noticeable different between the simulated and observed magnitude of the variables of interests at the annual time step further examination of individual years sediment and eroded c yields revealed larger uncertainties of swat c simulations at the annual time scale for example swat c underestimated sediment and eroded c yields by 37 and 50 respectively for year 1975 for year 1973 the p b i a s values were 54 and 63 respectively for sediment and eroded c yields summarized over the 41 years with observations swat c prediction error was larger than 50 for 29 years for both sediment and eroded c yields simulations when the two years with highest sediment yields are removed the r 2 values decreased to 0 09 and 0 08 respectively for sediment and eroded c simulations this finding indicates the high uncertainty of using swat c to predict sediment and eroded c yield for a specific year which may be caused by numerous factors related to characterizing biophysical and biogeochemical processes within an agricultural field swat c uses soc content in the top 10 mm soils and enrichment ratio to estimate c concentration in sediment therefore in table 1 we also listed the simulated top 10 mm soc content to show the variation in swat c performance for different crop rotations due to the lack to observations for the top 10 mm we could not directly assess swat c s performance for this top layer but in combination with the simulations of eroded c for the four crop rotations we will discuss the potential implications of top 10 mm soc estimation for explaining bias in simulated eroded c in the following section 3 2 in addition to reasonable reproduction of long term eroded c swat c was assessed for simulating soc stocks over the simulation period table 1 swat c correctly simulated the direction of the change of soc storage in the top 30 cm soils but over predicted the magnitude by 1 1 mg c ha 1 over the 48 years period a closer look at the predicted soc stocks by soil depth indicated that swat c overestimated the changes of soc in the top 0 10 cm and 10 20 cm soil horizons but underestimated the soc change in the soil depth between 20 and 30 cm although both observed data and swat simulations show increases in the top 0 10 cm the magnitude of observed increase was 0 5 mg c ha 1 which is much lower than the simulated increase of 3 6 mg c ha 1 in contrast for soc in 20 30 cm soil horizons swat c simulated a decrease of 0 53 mg c ha 1 while observed values indicate an increase of 2 5 mg c ha 1 for the 10 20 cm soil horizon both swat c and observed values showed a decrease in soc storage over the simulation period swat c was able to simulate responses of soc storage to different crop rotations table 1 as the lack of soc observations we could not give direct assessment of the accuracy of simulated soc storage under these four crop rotations in general it seems reasonable that the two rotations with meadow exhibited higher soc in deeper soil layers than the cc pt and cs nt rotations given that perennial grasses have deeper root and higher root shoot ratio than annual crops zhang et al 2011 in general swat c predictions matched well the total soc storage in the 0 30 cm soil depths note that there was noticeable difference in simulated and observed soc for each soil layer the mismatch between the swat c simulated and observed soc stocks may be caused by uncertainties from different sources the first source of uncertainty arises from the uncertainties associated with the soc measurements measurements taken at different locations within a field vary from each other due to spatial heterogeneity hoffmann et al 2014 often multiple replicate measurements were taken to estimate uncertainties arising from spatial heterogeneity hao et al 2002 as illustrated by the ranges of soc observations obtained at upper middle and lower slope positions table 1 for example the measured 0 30 cm soc ranged between 33 3 and 39 0 mg c ha 1 the range of soc values were derived through repeated measurements at a limited number of locations within the agricultural fields which are unlikely to reliably to represent total uncertainty caused by soil spatial heterogeneity donovan 2012 in addition accuracy of soc measurements suffers from uncertainties in soil bulk density determination walter et al 2016 and intrinsic limitations of soc measurement techniques as discussed in schumacher 2002 and da silva dias et al 2013 the second type of uncertainties mainly lie in errors in model simulations for example errors associated with model inputs e g climate forcing soil properties timing and characterization of each agronomic operations can translate into errors in model simulations grosz et al 2017 the uncertainties associated with swat s hydrologic and biogeochemical simulation algorithms e g evapotranspiration surface runoff plant nutrient uptake root development and soc decomposition may influence water budget plant cover soc dynamics and biogeochemical constituents zhang et al 2014 although the uncertainties associated with field measurements and model simulations prevent us from achieving simulations that exactly match the observations the statistical metrics fig 2 and table 1 show that swat c can reasonably reproduce the average magnitude and temporal variable of long term annual sediment and eroded c loads furthermore swat c simulated well the long term average soc stocks in the top 30 cm but swat c did not represent well the depth distribution of soc changes indicating that the below ground root development and vertical variation of controls on soc dynamics await further examination and improvements 3 2 soil erosion and eroded c yield by crop management the analysis in section 3 1 reveals the noticeable discrepancies at the annual scale between simulated and observed sediment and eroded c loads although the long term average was well reproduced this result is not surprising as previous studies showed that swat c was able to capture long term characteristics of agroecosystems but performed less at the annual time scale given large uncertainties associated with input data and imperfections of the numerical algorithms srinivasan et al 2010 zhang et al 2013a this finding led to a follow up question how do swat c perform over an intermediate time scale that is coarser than annual but finer than overall average here we conducted further examination of swat c performances by different crop rotations or types swat c simulated sediment and eroded c yields matched the relative magnitude of observed data by crop rotation fig 3 the cc pt rotation exhibited the highest soil erosion and associated soc losses this result is consistent with previous studies that soil plowing disturbs soil surface and increases the risks of erosion devanand et al 2006 leduc et al 2016 swat c underestimated the sediment and associated eroded c yields during the cc pt rotation by 2 5 mg ha 1 yr 1 than observed which is the major reason causing the lower simulated sediment load by swat c as the 5 year total sediment yields disproportionately accounted for ca 61 of the total sediment yields over the 48 years in contrast to the plow tilled cc rotation swat c overestimated sediment yields during the no till cs rotation collectively swat c estimates narrowed the effects of conversion of conventional tillage to no till practices on soil conservation similar to our sediment yield analysis the patterns of eroded c yield by crop rotation illustrate that swat c tended to overestimate eroded c losses for crop rotations with low sediment yields while underestimate eroded c losses for crop rotations with high sediment yields these two types of bias offset each other and resulted in relatively low errors for the entire period but diminish the value of swat c to distinguish the effects of crop rotations on sediment and eroded c losses note that the pbias values in simulated yields are larger than those in simulated eroded c fig 3c indicating that swat c consistently underestimated soc concentration in sediment in general pbias values in simulated eroded c is consistently lower than biased in simulated sediment yields by 13 26 over the four assessment periods fig 3c here we excluded the m nt period for analysis due to the large relative biases in swat c simulated erosion under perennial grass cover assuming the fixed enrichment ratio derived from observations has little error a possible explanation for this under estimation of soc concentration in sediment is that swat c underestimated the 10 mm soc this finding calls for future examination of swat c for simulating top 10 mm soc against observations which hold the potential to further improve eroded c simulations further analyses by crop type show that swat c underestimated sediment yields for corn and winter wheat but overestimated sediment yields for soybean and meadow as shown in fig 4 similar patterns were obtained for swat c simulated eroded c yields it is worth noting that for perennial grasses swat c estimates an average sediment yield of ca 0 22 mg ha 1 yr 1 which was nearly10 times that of the observed 0 0027 mg ha 1 yr 1 as perennial grasses are believed to provide valuable soil conservation benefits they have been widely promoted as a conservation reserve program crp practice leduc et al 2016 and a promising source of cellulosic biomass to avoid food vs biofuel conflict gelfand et al 2013 tilman et al 2006 the overestimation of sediment yield and eroded c losses for meadow represent a weakness of swat c to understand environmental benefits of perennial grasses 3 3 sensitivity of model simulations to different enrichment ratio calculation methods model simulations with different e r calculation methods reveal substantial variations in predicted e r values averaged over time as well as in temporal e r patterns fig 5a in general the default method in swat and the menzel method overestimated e r values for most days in particular for those days with small sediment yield or sediment concentration this finding is in line with previous studies that showed larger uncertainties in e r values associated with storm events with low sediment yield or concentrations wang et al 2013 menzel 1980 also identified large uncertainties associated with e r estimations and concluded that the menzel method could over or under estimate within a factor of 5 for individual runoff events and within a factor of 2 for an annual average estimate the e r values predicted by the wang method matched well with the observed e r of 1 7 with slight overestimation for most days and noticeable underestimation for several years e g 1971 1976 not surprisingly the substantial difference in e r values predicted by different methods translated into the large discrepancy between simulated eroded c yields fig 5b however the magnitude of difference between e r values is less than that between the eroded c yields table 2 for example the average e r values derived by the wang menzel and default equations were respectively 1 02 3 07 and 3 97 times the observed e r of 1 7 in contrast the eroded c yields predicted by the three methods were respectively 0 91 1 38 and 1 88 times that predicted with the fixed e r of 1 7 the higher e r resulted in more depletion of soc in the surface soil layer therefore the increasing rate of eroded c yields is less than that of sediment yields in response to increases in e r values woods and schuman 1988 3 4 limitations and future directions based on the previous analyses we identified the following limitations of swat c that deserve future research to improve upon in order to increase its credibility of representing the lateral flow of c that couples the terrestrial and aquatic ecosystem processes a major limitation of this model assessment effort was that we did not have access to exact timing of crop management practices which was shown to have significant impacts on the simulated c balance in previous site scale swat c assessment zhang et al 2013b in addition we used generic parameters in the swat database to characterize fertilization tillage and harvesting management practices these settings may not represent well the site specific conditions such as tillage depth harvest index and fertilizer application depth that influence surface residue cover vertical soc mixing and nutrient availability for soc decomposition therefore future assessment of swat c at field sites with more detailed and accurate agronomic information would help better understand the strengths and weaknesses of swat c to simulate the lateral movement of eroded c as discussed in section 3 1 swat c captured the long term average sediment and eroded c yields but exhibited relatively large errors for individual year predictions a possible reason is that the swat c currently operates on a daily time step preventing it from directly using hourly or sub hourly precipitation to simulate peak flow given the significance of peak flow in the musle equation based soil erosion estimation the use of long term statistical estimation of half an hour precipitation intensity makes it difficult for swat c to accurately simulate rainfall event scale soil erosion and associated c losses recently a physically based soil erosion calculation method was incorporated into swat jeong et al 2011 that integrates features from eurosem and areal nonpoint source watershed environmental resources simulation answers park et al 1982 this method can be used to calculate hourly or subhourly soil erosion processes in addition the agricultural field was treated as a homogeneous unit which ignores important effects of spatial variability on sediment detachment and deposition for example hao et al 2002 showed that c stocks differentiated greatly between the upper middle and lower slope positions of the w118 experimental sites swat is able to use a flexible configuration of upland landscapes e g divide hillslope and floodplain arnold et al 2010 allowing for simulating the redistribution of sediment and soc along the upland landscapes regulated by surface runoff carrying capacity and erosion deposition processes further coupling between swat c with the advanced landscape configuration functions within swat holds the potential to further improve eroded c erosion deposition processes using refined precipitation data based on the results in figs 2 and 3 the pbias values for simulated eroded c are lower than those for simulated sediment yields with a difference between 13 and 26 for different crop rotations and assessment periods for example over the entire simulation period the pbias is 14 and 29 respectively for sediment yields and eroded c estimation these differences in pbias values indicate that uncertainties in simulated eroded c include both errors arising from sediment yield simulations and inherent errors in soc algorithms given the lack of daily sediment yield data to drive swat c we could not perform simulations to analyze potential implications of reducing sediment yield errors for improving eroded c estimation however such an exercise is valuable for better understanding sources of uncertainties in eroded c simulation and await future research the large uncertainties associated with e r estimation deserve closer examination the default e r calculation method within swat significantly overestimated observed e r values and led to much overestimation of eroded c losses although the wang method matched closely with the observed average e r values it seems not able to represent variability of e r associated with individual rainfall runoff events that have been demonstrated in previous field experiments wang et al 2013 using multiple e r equations to provide ensemble prediction may be a feasible option to estimate uncertainty in simulated eroded c yields evaluating more e r calculation methods against field data and identify the application conditions of each e r method will help choose the most appropriate method for a specific region or management conditions thereby facilitating reducing uncertainty in eroded c predictions 4 conclusions soil erosion links terrestrial and aquatic ecosystem processes and has been identified as an important process understudied for elucidating global regional carbon cycles in this study we evaluated the swat c model for simulating long term annual sediment and eroded c yields at an experimental site within the naew research station the results demonstrate the strengths of swat c in reproducing long term average eroded c yields and relative magnitude of eroded c yields by crop rotation or type noticeable biases were observed at the annual scale which translated into the pronounced over or under estimation of eroded c yields by crop rotation or type in general swat c overestimated eroded c losses for crop rotations or types with low sediment yields while underestimated eroded c losses for crop rotations or types with high sediment yields this weakness may cause swat c to discount the environmental benefits of soil conservation practices based on the strengths and weaknesses of swat c we discussed future directions of further development of swat to better represent the lateral movement of eroded c such as assessing more e r calculation methods and identifying each method s appropriate application contexts and linking swat c with advanced landscape configuration functions of swat to used physically based algorithms to represent soil erosion sediment deposition processes we anticipate the swat c model assessment and development efforts presented here will help lay the foundation for a watershed tool to study watershed scale c cycling across terrestrial and aquatic ecosystems acknowledgements this work was funded by the nasa nnx17ae66g and usda 2017 67003 26485 and 2017 67003 26484 interagency carbon cycle science program nasa s new investigator award nnh13zda001n and nsf infews 1639327 appendix a supplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 01 005 
26418,the soil erosion and associated lateral movement of eroded carbon c have been identified as a possible mechanism explaining the elusive terrestrial c sink of ca 1 7 2 6 pgc yr 1 here we evaluated the swat c model for simulating long term soil erosion and associated eroded c yields our method couples the century carbon cycling processes with a modified universal soil loss equation musle to estimate c losses associated with soil erosion the results show that swat c is able to simulate well long term average eroded c yields as well as correctly estimate the relative magnitude of eroded c yields by crop rotations we also evaluated three methods of calculating c enrichment ratio in mobilized sediments and found that errors associated with enrichment ratio estimation represent a significant uncertainty in swat c simulations furthermore we discussed limitations and future development directions for swat c to advance c cycling modeling and assessment keywords agriculture greenhouse gases erosion soil organic carbon software availability software swat c developer xuesong zhang operating systems windows linux dependent software fortran 90 availability free of charge swat c has been released at http swat tamu edu software swat executables within the latest version of swat the new code revision regarding eroded c yields calculation and enrichment ratio estimation will be released to the public through the swat website 1 introduction accurate quantification of carbon c cycling in the earth system is crucial for effective development of science based decision tools and management strategies aimed at reducing c emissions current estimates of global co2 fluxes consistently infer a missing terrestrial c sink also known as residual terrestrial or land sink of 1 7 and 2 6 pg c yr 1 for the 1980s and 1990s respectively ipcc 2013 this residual sink is comparable in magnitude to other major components of the global c budget e g the net ocean uptake of ca 2 3 pg c yr 1 or c emissions of ca 1 0 pg c yr 1 from land use change ciais et al 2014 a possible mechanism contributing to this missing sink is the soil erosion processes which may induce a global c sink of 0 12 1 5 pgc yr 1 smith et al 2001 stallard 1998 van oost et al 2007 quinton et al 2010 however the c dynamics across terrestrial aquatic interfaces regulated by both biotic and abiotic processes across various temporal and spatial scales remain poorly characterized given the magnitude and the degree of uncertainty associated with the erosion induced c sink there is an urgent need to elucidate its causes and mechanisms in order to avoid unexpected consequences when developing and deploying c management strategies and policies houghton 2002 soil erosion and lateral movement of sediment and nutrients from land to waters not only modify soil quality but also alter terrestrial biogeochemical cycles lal 2004 liu et al 2003 berhe et al 2007 soil erosion laterally redistributes and removes soil organic carbon soc and other nutrients across terrestrial landscapes global estimates of soc erosion fluxes have varied widely from 0 5 to 6 0 pg c yr 1 lal 2003 van oost et al 2007 müller nedebock and chaplot 2015 process based terrestrial ecosystem modeling framework based on the century terrestrial c model parton et al 1994 have been developed and tested for quantifying soc erosion and associated biogeochemical processes harden et al 1999 liu et al 2003 izaurralde et al 2007 additionally the soil erosion critically impacts trophic states as well as c stocks and flows in aquatic ecosystems cole et al 2007 tranvik et al 2009 battin et al 2009 tank et al 2010 soil erosion mobilizes and introduces large amounts of particulate organic carbon poc from upland landscapes into streams rivers and reservoirs where poc undergoes complex transport and transformation processes poc not consumed in inland waters is transported by rivers to estuarine and coastal ecosystems hope et al 1994 where it could be buried biogeochemically transformed or returned back to the atmosphere as co2 bauer and bianchi 2011 c transport and transformation processes link c cycling across terrestrial and aquatic ecosystems at the watershed scale and represent an important component of the boundless global c cycle battin et al 2009 but has not been well understood and characterized trimmer et al 2012 multiple field scale soil erosion models are available the empirically based universal soil loss equation usle wischmeier and smith 1978 wischmeir 1965 is a field scale model that is capable of simultaneously considering multiple soil erosion control factors such as surface cover terrain characteristics precipitation and conservation practices based on the usle model multiple revised methods have been proposed and widely adopted such as revised usle rusle by renard et al 1991 and modified usle musle by williams and berndt 1977 more physically based soil erosion models jetten et al 1999 nearing et al 2005 such as water erosion prediction project wepp nearing et al 1989 kinematic runoff and erosion kineros woolhiser et al 1990 european soil erosion model eurosem morgan et al 1998 and plot soil erosion model 2d psem 2d nord and esteves 2005 have been developed to explicitly represent detachment and transport processes during soil erosion ellison 1947 previous studies showed that field scale soil erosion modeling is subjective to multiple errors sources jetten et al 1999 nearing et al 2005 nord and esteves 2005 such as input data quality user s choices in preparing input data and inherent errors from simplified representation of the soil processes often the importance of different uncertainty sources varies by models and experimental data employed in general the physically based models require more detailed spatial data and finer execution time step e g minutes and are often event based a comparison of field scale soil erosion models jetten et al 1999 showed that empirically models do not underperform physically models for long term continuous simulations given the availability of terrain climate and management data and the purpose of linking erosion with soc losses for long term simulations we chose the musle soil erosion model in addition the musle has been incorporated within the swat model arnold et al 1998 which is a widely used process based watershed model for reproducing observed hydrologic and or pollutant loads across a wide range of watershed scales and environmental conditions as well as for assessing impacts of conservation practices land use climate change water management and other scenarios gassman et al 2007 using musle within the swat framework will greatly benefit future efforts to understand the fate of eroded sediments and c in downstream aquatic ecosystems and assess watershed scale c balance furthermore in recognition of the need of a coupled watershed scale c cycling model recent efforts yang and zhang 2016 yang et al 2017 zhang et al 2013b enhanced and tested swat for simulating carbon dioxide co2 and nitrous oxide n2o fluxes of diverse upland ecosystems referred to as swat c hereafter the revised coupled c nitrogen and phosphorus cycles in swat c are derived from three agroecosystem models including the century model parton et al 1994 and its daily version daycent del grosso et al 2001 the environmental policy integrated climate epic model williams 1990 izaurralde et al 2006 and the decision support system for agrotechnology transfer model dssat jones et al 2003 gijsman et al 2002 as described in zhang et al 2013b wu et al 2016 also explored the joint use of swat and daycent to assess carbon dynamics the swat c model s c module has been tested for simulating co2 fluxes at 16 eddy covariance flux towers yang and zhang 2016 zhang et al 2013b those efforts lay a solid foundation for linking terrestrial c cycling with soil erosion here the major objective of this study is to test swat c for simulating long term sediment and eroded c using the long term measurements from a small watershed w118 in the north appalachian experimental watershed naew research station hao et al 2001 the outcome resulting from this study is expected to help understand the strength and weaknesses of swat c for predicting the lateral movement of c from cropland into adjacent water bodies thereby supporting its future development and applications to help understand c cycling across terrestrial and aquatic ecosystems 2 materials and methods 2 1 description of the swat c model the swat model is a continuous long term distributed parameter hydrologic model which has been incorporated into the u s environmental protection agency us epa better assessment science integrating point nonpoint sources basins software package luzio et al 2002 and is also being considered as a core watershed model by the united states department of agriculture usda for applications in the conservation effects assessment project ceap richardson et al 2008 across watersheds in the u s for a watershed application swat subdivides a watershed into subbasins connected by a stream network and further delineates hydrologic response units hrus consisting of unique combinations of land cover and soils in each subbasin for each hru swat simulates surface and subsurface flow evapotranspiration soil moisture sediment generation carbon and nutrient cycling and plant growth and development neitsch et al 2011 the plant growth processes in swat are based on the epic model which uses a revised version of crop environment resource synthesis ceres williams et al 1989 jones et al 1991 and employs the concept of radiation use efficiency by which a fraction of daily photosynthetically active solar radiation is intercepted by the plant canopy and converted into plant biomass daily gains in plant biomass are affected by vapor pressure deficits atmospheric co2 concentrations nutrients availability and other environmental controls and stresses in the swat c version zhang et al 2013b following the century model parton et al 1994 the soil organic matter som and residue are represented with five pools plant litter is divided into the easily decomposable metabolic e g proteins and sugars and recalcitrant structural e g lignin and cell walls component an active microbial biomass pool that has a turnover of months to a few years including soil microbes and microbial products the slow humus pool receives c and n from the decomposition of structural litter metabolic litter and microbial biomass and often has a turnover time of 20 50 years the most recalcitrant som lies in the passive humus pool which includes physically and chemically stabilized som sorbed to clays with long turnover times 400 2000 years parton et al 1993 1994 in addition to substrate specific properties the decomposition and transformation of structural litter metabolic litter passive humus slow humus and microbial biomass are also influenced by abiotic factors such as soil temperature soil water content tillage enhancement oxygen availability and soil texture parton et al 1994 gijsman et al 2002 izaurralde et al 2006 swat c simulates soil erosion using the modified universal soil loss equation musle williams and berndt 1977 eroded soc loss is derived by multiplying the amount of eroded soil with the concentration of soc in mineral soils and an enrichment ratio the musle is a variant of the equation universal soil loss equation usle wischmeier and smith 1978 wischmeir 1965 and is represented in the following form 1 s e d 11 8 q s u r f q p e a k a r e a h r u 0 56 k u s l e c u s l e p u s l e l s u s l e c f r g where s e d is the sediment yield on a given day mg q s u r f is the surface runoff volume mm h2o ha 1 q p e a k is the peak runoff rate m3 s 1 a r e a h r u is the area of the hru ha k u s l e is the usle soil erodibility factor that is determined by sand clay silt and organic c content c u s l e is the usle cover and management factor dimensionless p u s l e is the usle support practice factor dimensionless l s u s l e is the usle topographic factor dimensionless c f r g is the coarse fragment factor dimension less c u s l e is land cover specific with grassland having smaller values than row crops residue collection influences this factor by reducing surface cover leading to more erosion the concentration of soc in eroded mineral soils is a product of the concentration of soc in top soil and an enrichment ratio we further use the following equation to calculate the amount of eroded soc 2 s e d c s e d c o n c s o c s o i l e r where s e d c is the eroded c yield on a given day mg c o n c s o c s o i l is the fraction of soc in the top soil layer where eroded sediment comes from e r is the ratio of the concentration of organic c transported with the sediment to the concentration in the soil surface layer in the experimental site measured e r was 1 7 hao et al 2002 which was assumed to be fixed over time in the simulation study 2 2 enrichment ratio calculation as smaller particles weigh less and are more easily transported than coarser particles the sediment load to streams often has a greater proportion of clay sized particles or enriched in clay particles som is attached primarily to colloidal clay particles so the sediment load will also contain a greater proportion of concentration of organic c than that found in the soil surface layer in swat the enrichment ratio is estimated using the following empirical formula 3 e r 0 78 c o n c s e d s u r f 0 2468 where c o n c s e d s u r f is the concentration of sediment in surface runoff mg m 3 h2o our initial assessment of the default swat enrichment ratio calculation equation eq 3 showed that it estimated much higher e r than those reported in literature that are 3 in most cases menzel 1980 this finding led us to examine other e r calculation options that have been derived from previous field experimental data here two equations are selected to understand uncertainties associated with e r calculation and subsequent implications for eroded c simulations based on multiple experimental data menzel 1980 derived a generalized equation that is hoped to hold for a wide range of vegetation and soil conditions 4 e r 7 4 s e d u 0 2 where s e d u is sediment yield per unit area kg ha 1 this relationship has been widely used in nonpoint source pollution models such as the chemicals runoff and erosion from agricultural management systems creams knisel 1980 to calculate nutrient enrichment ratios wang et al 2013 derived a soc enrichment ratio relationship based on field rainfall simulation experiments in the loam belt area in central belgium 5 e r 2 46 e 0 065 s c 1 0 where sc is sediment concentration in surface runoff with a unit of g l 1 h2o 2 3 description of the experimental site the experimental site is a small watershed w118 located within the usda s naew research station 40 22 n 81 48 w near coshocton ohio which was established in 1938 to study runoff erosion and water quality as influenced by varying agroecosystems under different crop covers and management practices more detailed description of the study site and its location is provided by owens et al 2010 the study area receives long term annual average precipitation of 937 mm 1951 1998 with a standard deviation of 49 9 mm on average spring april may and june and summer july august and september receive 283 1 mm and 269 2 mm precipitation respectively in contrast precipitation is less in autumn october november and december and winter january february and march which is 185 9 mm and 200 1 mm respectively annual average daily air temperature is above 16 0 c with average daily maximum air temperature of 16 0 c and average daily minimum air temperature 3 4 c the w118 watershed covers an area of 0 79 ha and has a slope gradient of 10 with the slope length of 132 m the sediment and eroded c transported by surface runoff were collected at the outlet of the small catchment to determine the yields of sediment and eroded c hao et al 2001 the dominant soil type of the watershed is silt loam kelly 1975 historical cropping systems have been described in hao et al 2001 kelly 1975 shipitalo and edwards 1998 and in owens and edwards 1993 and can be grouped into four major phases the first phase is between 1951 and 1970 with a four year rotation of plow tilled corn zea mays l winter wheat triticum aestivum l meadow meadow cwmm for corn years soils were plowed with moldboard disk twice and harrow once before planting in late april or early may and a rate of 56 kg ha 1 fertilizer 5 20 20 that contains 5 nitrogen 20 phosphorus 20 potash and 9 mg ha 1 cattle manure was applied or plowed into the soil corn harvesting occurred in early october with corn stover chopped and spread on the field for winter wheat soils were disked before drilling the seeds and planting date is within 2 weeks from corn harvest winter wheat received a fertilization rate of 112 kg ha 1 fertilizer 5 20 20 and was harvested in next year s early july for the two meadow years hay harvesting occurred twice in late june and early august respectively the second phase 1971 1975 experienced plow tilled continuous corn cc except no till corn in 1974 during this period soil amendments included n fertilizer of 225 kg ha 1 of urea or nh4no3 applied in spring and phosphorous applied in fall to reduce nutrient stress on plant growth the third phase 1976 193 is continuous meadow with no till and twice harvesting in late june and early august respectively the fourth phase is between 1985 and 1998 planted with a no till corn and soybean glycine max l merr rotation cs during this phase corn received n fertilizer of 225 kg ha 1 of urea or nh4no3 applied in spring and phosphorous applied in fall in general corn and soybean were planted in late april or early may and harvested october residues from corn and soybean are left intact on ground surface contour farming was adopted for row crops 2 4 model evaluation moriasi et al 2007 reviewed and summarized multiple evaluation metrics used in model skill assessment here we selected three widely used descriptive statistics that has been widely used for evaluating performance of the swat model the first metric is percent bias p b i a s gupta et al 1999 calculated as 6 p b i a s k 1 t f k y k k 1 t y k 100 where f k is the model simulated value at a time unit or location k y k is the corresponding benchmark data value and t represents the total pairs of data p b i a s measures the average tendency of the simulated data to be larger or smaller than their observed counterparts small p b i a s values means less model bias the second metric is coefficient of determination r 2 legates and mccabe 1999 7 r 2 k 1 t y k y f k f k 1 t y k y 2 0 5 k 1 t f k f 2 0 5 2 where y is the mean of observed data for the entire time period or across all sites under evaluation f is the mean of simulated data the other symbols are the same as defined above r 2 ranges between 0 0 and 1 0 and represents the proportion of the total variance in the observed data that is explained by the model the higher the r 2 values the better the model performance the third metric is nash sutcliffe efficiency e ns nash and sutcliffe 1970 8 e n s 1 0 k 1 t y k f k 2 k 1 t y k y 2 all symbols are the same as those introduced above e ns indicates how well the plot of the observed value versus the simulated value fits the 1 1 line and ranges from to 1 3 results and discussion 3 1 comparison between simulated and observed long term sediment and eroded carbon yields with a fixed e r value of 1 7 we simulated annual sediment and eroded c yields over the period of 1951 1998 fig 1 averaged over 1951 1998 swat c slightly underestimated sediment yield by 14 with the simulated average of 1 03 mg ha 1 yr 1 vs the observed average of 1 2 mg ha 1 yr 1 fig 2 for eroded c swat c simulated value of 0 022 mg c ha 1 yr 1 was 29 lower than the observed value of 0 031 mg c ha 1 yr 1 the time series plots in fig 1 also showed that swat c captured well the overall temporal pattern of sediment and eroded c yield over the simulation period in particular swat c captured years with the highest and second highest yields of sediment of 19 7 and 7 63 mg ha 1 yr 1 respectively but with less magnitude similarly we found swat c also reproduced the peak eroded c yield during those two years overall the high coefficient of determination values for both simulated sediment and eroded c yields 0 85 and 0 84 respectively indicate the capability of swat c to explain temporal variability of lateral flow of sediment and eroded c over a long period however the e ns values of 0 70 and 0 61 for sediment and eroded c yields simulations showed that there are noticeable different between the simulated and observed magnitude of the variables of interests at the annual time step further examination of individual years sediment and eroded c yields revealed larger uncertainties of swat c simulations at the annual time scale for example swat c underestimated sediment and eroded c yields by 37 and 50 respectively for year 1975 for year 1973 the p b i a s values were 54 and 63 respectively for sediment and eroded c yields summarized over the 41 years with observations swat c prediction error was larger than 50 for 29 years for both sediment and eroded c yields simulations when the two years with highest sediment yields are removed the r 2 values decreased to 0 09 and 0 08 respectively for sediment and eroded c simulations this finding indicates the high uncertainty of using swat c to predict sediment and eroded c yield for a specific year which may be caused by numerous factors related to characterizing biophysical and biogeochemical processes within an agricultural field swat c uses soc content in the top 10 mm soils and enrichment ratio to estimate c concentration in sediment therefore in table 1 we also listed the simulated top 10 mm soc content to show the variation in swat c performance for different crop rotations due to the lack to observations for the top 10 mm we could not directly assess swat c s performance for this top layer but in combination with the simulations of eroded c for the four crop rotations we will discuss the potential implications of top 10 mm soc estimation for explaining bias in simulated eroded c in the following section 3 2 in addition to reasonable reproduction of long term eroded c swat c was assessed for simulating soc stocks over the simulation period table 1 swat c correctly simulated the direction of the change of soc storage in the top 30 cm soils but over predicted the magnitude by 1 1 mg c ha 1 over the 48 years period a closer look at the predicted soc stocks by soil depth indicated that swat c overestimated the changes of soc in the top 0 10 cm and 10 20 cm soil horizons but underestimated the soc change in the soil depth between 20 and 30 cm although both observed data and swat simulations show increases in the top 0 10 cm the magnitude of observed increase was 0 5 mg c ha 1 which is much lower than the simulated increase of 3 6 mg c ha 1 in contrast for soc in 20 30 cm soil horizons swat c simulated a decrease of 0 53 mg c ha 1 while observed values indicate an increase of 2 5 mg c ha 1 for the 10 20 cm soil horizon both swat c and observed values showed a decrease in soc storage over the simulation period swat c was able to simulate responses of soc storage to different crop rotations table 1 as the lack of soc observations we could not give direct assessment of the accuracy of simulated soc storage under these four crop rotations in general it seems reasonable that the two rotations with meadow exhibited higher soc in deeper soil layers than the cc pt and cs nt rotations given that perennial grasses have deeper root and higher root shoot ratio than annual crops zhang et al 2011 in general swat c predictions matched well the total soc storage in the 0 30 cm soil depths note that there was noticeable difference in simulated and observed soc for each soil layer the mismatch between the swat c simulated and observed soc stocks may be caused by uncertainties from different sources the first source of uncertainty arises from the uncertainties associated with the soc measurements measurements taken at different locations within a field vary from each other due to spatial heterogeneity hoffmann et al 2014 often multiple replicate measurements were taken to estimate uncertainties arising from spatial heterogeneity hao et al 2002 as illustrated by the ranges of soc observations obtained at upper middle and lower slope positions table 1 for example the measured 0 30 cm soc ranged between 33 3 and 39 0 mg c ha 1 the range of soc values were derived through repeated measurements at a limited number of locations within the agricultural fields which are unlikely to reliably to represent total uncertainty caused by soil spatial heterogeneity donovan 2012 in addition accuracy of soc measurements suffers from uncertainties in soil bulk density determination walter et al 2016 and intrinsic limitations of soc measurement techniques as discussed in schumacher 2002 and da silva dias et al 2013 the second type of uncertainties mainly lie in errors in model simulations for example errors associated with model inputs e g climate forcing soil properties timing and characterization of each agronomic operations can translate into errors in model simulations grosz et al 2017 the uncertainties associated with swat s hydrologic and biogeochemical simulation algorithms e g evapotranspiration surface runoff plant nutrient uptake root development and soc decomposition may influence water budget plant cover soc dynamics and biogeochemical constituents zhang et al 2014 although the uncertainties associated with field measurements and model simulations prevent us from achieving simulations that exactly match the observations the statistical metrics fig 2 and table 1 show that swat c can reasonably reproduce the average magnitude and temporal variable of long term annual sediment and eroded c loads furthermore swat c simulated well the long term average soc stocks in the top 30 cm but swat c did not represent well the depth distribution of soc changes indicating that the below ground root development and vertical variation of controls on soc dynamics await further examination and improvements 3 2 soil erosion and eroded c yield by crop management the analysis in section 3 1 reveals the noticeable discrepancies at the annual scale between simulated and observed sediment and eroded c loads although the long term average was well reproduced this result is not surprising as previous studies showed that swat c was able to capture long term characteristics of agroecosystems but performed less at the annual time scale given large uncertainties associated with input data and imperfections of the numerical algorithms srinivasan et al 2010 zhang et al 2013a this finding led to a follow up question how do swat c perform over an intermediate time scale that is coarser than annual but finer than overall average here we conducted further examination of swat c performances by different crop rotations or types swat c simulated sediment and eroded c yields matched the relative magnitude of observed data by crop rotation fig 3 the cc pt rotation exhibited the highest soil erosion and associated soc losses this result is consistent with previous studies that soil plowing disturbs soil surface and increases the risks of erosion devanand et al 2006 leduc et al 2016 swat c underestimated the sediment and associated eroded c yields during the cc pt rotation by 2 5 mg ha 1 yr 1 than observed which is the major reason causing the lower simulated sediment load by swat c as the 5 year total sediment yields disproportionately accounted for ca 61 of the total sediment yields over the 48 years in contrast to the plow tilled cc rotation swat c overestimated sediment yields during the no till cs rotation collectively swat c estimates narrowed the effects of conversion of conventional tillage to no till practices on soil conservation similar to our sediment yield analysis the patterns of eroded c yield by crop rotation illustrate that swat c tended to overestimate eroded c losses for crop rotations with low sediment yields while underestimate eroded c losses for crop rotations with high sediment yields these two types of bias offset each other and resulted in relatively low errors for the entire period but diminish the value of swat c to distinguish the effects of crop rotations on sediment and eroded c losses note that the pbias values in simulated yields are larger than those in simulated eroded c fig 3c indicating that swat c consistently underestimated soc concentration in sediment in general pbias values in simulated eroded c is consistently lower than biased in simulated sediment yields by 13 26 over the four assessment periods fig 3c here we excluded the m nt period for analysis due to the large relative biases in swat c simulated erosion under perennial grass cover assuming the fixed enrichment ratio derived from observations has little error a possible explanation for this under estimation of soc concentration in sediment is that swat c underestimated the 10 mm soc this finding calls for future examination of swat c for simulating top 10 mm soc against observations which hold the potential to further improve eroded c simulations further analyses by crop type show that swat c underestimated sediment yields for corn and winter wheat but overestimated sediment yields for soybean and meadow as shown in fig 4 similar patterns were obtained for swat c simulated eroded c yields it is worth noting that for perennial grasses swat c estimates an average sediment yield of ca 0 22 mg ha 1 yr 1 which was nearly10 times that of the observed 0 0027 mg ha 1 yr 1 as perennial grasses are believed to provide valuable soil conservation benefits they have been widely promoted as a conservation reserve program crp practice leduc et al 2016 and a promising source of cellulosic biomass to avoid food vs biofuel conflict gelfand et al 2013 tilman et al 2006 the overestimation of sediment yield and eroded c losses for meadow represent a weakness of swat c to understand environmental benefits of perennial grasses 3 3 sensitivity of model simulations to different enrichment ratio calculation methods model simulations with different e r calculation methods reveal substantial variations in predicted e r values averaged over time as well as in temporal e r patterns fig 5a in general the default method in swat and the menzel method overestimated e r values for most days in particular for those days with small sediment yield or sediment concentration this finding is in line with previous studies that showed larger uncertainties in e r values associated with storm events with low sediment yield or concentrations wang et al 2013 menzel 1980 also identified large uncertainties associated with e r estimations and concluded that the menzel method could over or under estimate within a factor of 5 for individual runoff events and within a factor of 2 for an annual average estimate the e r values predicted by the wang method matched well with the observed e r of 1 7 with slight overestimation for most days and noticeable underestimation for several years e g 1971 1976 not surprisingly the substantial difference in e r values predicted by different methods translated into the large discrepancy between simulated eroded c yields fig 5b however the magnitude of difference between e r values is less than that between the eroded c yields table 2 for example the average e r values derived by the wang menzel and default equations were respectively 1 02 3 07 and 3 97 times the observed e r of 1 7 in contrast the eroded c yields predicted by the three methods were respectively 0 91 1 38 and 1 88 times that predicted with the fixed e r of 1 7 the higher e r resulted in more depletion of soc in the surface soil layer therefore the increasing rate of eroded c yields is less than that of sediment yields in response to increases in e r values woods and schuman 1988 3 4 limitations and future directions based on the previous analyses we identified the following limitations of swat c that deserve future research to improve upon in order to increase its credibility of representing the lateral flow of c that couples the terrestrial and aquatic ecosystem processes a major limitation of this model assessment effort was that we did not have access to exact timing of crop management practices which was shown to have significant impacts on the simulated c balance in previous site scale swat c assessment zhang et al 2013b in addition we used generic parameters in the swat database to characterize fertilization tillage and harvesting management practices these settings may not represent well the site specific conditions such as tillage depth harvest index and fertilizer application depth that influence surface residue cover vertical soc mixing and nutrient availability for soc decomposition therefore future assessment of swat c at field sites with more detailed and accurate agronomic information would help better understand the strengths and weaknesses of swat c to simulate the lateral movement of eroded c as discussed in section 3 1 swat c captured the long term average sediment and eroded c yields but exhibited relatively large errors for individual year predictions a possible reason is that the swat c currently operates on a daily time step preventing it from directly using hourly or sub hourly precipitation to simulate peak flow given the significance of peak flow in the musle equation based soil erosion estimation the use of long term statistical estimation of half an hour precipitation intensity makes it difficult for swat c to accurately simulate rainfall event scale soil erosion and associated c losses recently a physically based soil erosion calculation method was incorporated into swat jeong et al 2011 that integrates features from eurosem and areal nonpoint source watershed environmental resources simulation answers park et al 1982 this method can be used to calculate hourly or subhourly soil erosion processes in addition the agricultural field was treated as a homogeneous unit which ignores important effects of spatial variability on sediment detachment and deposition for example hao et al 2002 showed that c stocks differentiated greatly between the upper middle and lower slope positions of the w118 experimental sites swat is able to use a flexible configuration of upland landscapes e g divide hillslope and floodplain arnold et al 2010 allowing for simulating the redistribution of sediment and soc along the upland landscapes regulated by surface runoff carrying capacity and erosion deposition processes further coupling between swat c with the advanced landscape configuration functions within swat holds the potential to further improve eroded c erosion deposition processes using refined precipitation data based on the results in figs 2 and 3 the pbias values for simulated eroded c are lower than those for simulated sediment yields with a difference between 13 and 26 for different crop rotations and assessment periods for example over the entire simulation period the pbias is 14 and 29 respectively for sediment yields and eroded c estimation these differences in pbias values indicate that uncertainties in simulated eroded c include both errors arising from sediment yield simulations and inherent errors in soc algorithms given the lack of daily sediment yield data to drive swat c we could not perform simulations to analyze potential implications of reducing sediment yield errors for improving eroded c estimation however such an exercise is valuable for better understanding sources of uncertainties in eroded c simulation and await future research the large uncertainties associated with e r estimation deserve closer examination the default e r calculation method within swat significantly overestimated observed e r values and led to much overestimation of eroded c losses although the wang method matched closely with the observed average e r values it seems not able to represent variability of e r associated with individual rainfall runoff events that have been demonstrated in previous field experiments wang et al 2013 using multiple e r equations to provide ensemble prediction may be a feasible option to estimate uncertainty in simulated eroded c yields evaluating more e r calculation methods against field data and identify the application conditions of each e r method will help choose the most appropriate method for a specific region or management conditions thereby facilitating reducing uncertainty in eroded c predictions 4 conclusions soil erosion links terrestrial and aquatic ecosystem processes and has been identified as an important process understudied for elucidating global regional carbon cycles in this study we evaluated the swat c model for simulating long term annual sediment and eroded c yields at an experimental site within the naew research station the results demonstrate the strengths of swat c in reproducing long term average eroded c yields and relative magnitude of eroded c yields by crop rotation or type noticeable biases were observed at the annual scale which translated into the pronounced over or under estimation of eroded c yields by crop rotation or type in general swat c overestimated eroded c losses for crop rotations or types with low sediment yields while underestimated eroded c losses for crop rotations or types with high sediment yields this weakness may cause swat c to discount the environmental benefits of soil conservation practices based on the strengths and weaknesses of swat c we discussed future directions of further development of swat to better represent the lateral movement of eroded c such as assessing more e r calculation methods and identifying each method s appropriate application contexts and linking swat c with advanced landscape configuration functions of swat to used physically based algorithms to represent soil erosion sediment deposition processes we anticipate the swat c model assessment and development efforts presented here will help lay the foundation for a watershed tool to study watershed scale c cycling across terrestrial and aquatic ecosystems acknowledgements this work was funded by the nasa nnx17ae66g and usda 2017 67003 26485 and 2017 67003 26484 interagency carbon cycle science program nasa s new investigator award nnh13zda001n and nsf infews 1639327 appendix a supplementary data the following is the supplementary data related to this article data profile data profile appendix a supplementary data supplementary data related to this article can be found at https doi org 10 1016 j envsoft 2018 01 005 
26419,constructed wetlands treating combined sewer overflow cso cws are vertical flow filters in france with outflow limitation and detention basin treating storm generated flows reduces pollutants and flow peaks entering natural waters storm generated flows are stochastic and therefore optimized cso cw design requires a dynamic approach i e a modelling software targeting engineers therefore a new tool called orage was developed orage consists of a core model an iterative shell and a user interface it optimizes dimensions and materials of cso cws site specifically based on inflow series and a low number of input parameters the core model simulates hydraulics and tss cod and nh4 n removal manual fitting of the core showed good results with a single load the same parameters gave satisfying accuracy when simulating load series with closed material balance sensitivity analysis confirmed model robustness and justified coupling with an automatic shell algorithm for automatic optimization based on a single output keywords combined sewer overflow constructed wetland design support modelling dynamic design stormwater treatment orage abbreviations tss total suspended solids nh4 n ammonium nitrogen cod chemical oxygen demand software availability name of software orage alpha 0 6 developer irstea and megao informatique france contact remy arnaud remi arnaud megao com availability freeware version 1 0 available online at epnac irstea fr from 2018 1 introduction 1 1 cso cws and stormwater treatment urbanization impacts negatively the hydrology physical chemical properties and biota of surface and groundwater preventive measures are often absent and as a consequence waters suffer the effects of untreated urban runoffs these are rejected with combined sewer overflows cso or as separate sewer outlet sso urban stream syndrome is the generalized ecological degradation of streams draining urban land chocat et al 1994 walsh et al 2005 combined sewers accommodate high flows of stormwater mixed with domestic sewage overflow mechanisms prevent overfilling of pipes and limit downpipe flow rates to the capacity of the wastewater treatment plant unwanted peaks discharge as cso carry significant amount of organics nutrients heavy metals and bacteria in contrast sso is released end of pipe and carry less organic matter and nutrient but suspended solids specific organic pollutants and heavy metals are a concern both cso and sso erode and or silt up stream habitat and change streambed morphology meyer et al 2013 constructed wetlands cws for cso treatment cso cws are implemented or are planned to be in several countries in europe vertical downflow vf arrangements are promising e g meyer et al 2013 after positive experiences with retention soil filters rsfs dittmer et al 2016 uhl and dittmer 2005 in germany the european water framework directive 2000 60 ec calls for the good quality of natural waters and the limitation and or treatment of cso is needed to reach its goals different types of cws exist fonder and headley 2013 but the solution in france for cso treatment is a specific vertical downflow arrangement with outflow rate limitation in this paper cso cw refers to this new state of the art unless otherwise specified in france stormwater is collected in about 25 of the lines by combined sewers soes 2011 and treatment of overflows started recently the key specificity of cso cws is that in contrast to cws treating domestic wastewater inflows have stochastic periodicity volume and quality furthermore these systems have a detention basin above the filter material loadings saturate the porous media and cause ponding intra event state several hours might pass until the detained water is filtered leaving through an orifice to limit outflow rate after this the pores get filled again with air for several days inter event state and might even dry out in extreme cases some treatment processes can be attributed by their dominant occurrence to the intra event others to the inter event environment filtration adsorption and anaerobic biodegradation take place during intra event while aerobic bioprocesses predominantly the nitrification of adsorbed ammonia and organic matter biodegradation dominate the inter event phase dittmer et al 2005 2016 dittmer and schmitt 2011 meyer 2011 dittmer et al 2005 uhl and dittmer 2005 1 2 design support modelling of cso cws due to the stochastic nature of storm generated flows and the related existence of intra and inter event phases design optimization needs a dynamic approach this can be achieved through modelling numerical modelling of wetlands treating combined sewer overflows is a new direction of constructed wetland research and the range of publications dealing with the topic is therefore relatively limited some existing models have a wider application domain but match the complexity of the task such is the process based hydrus cw2d langergraber and šimůnek 2005 validated for laboratory cso cw columns recently the works of pálfy et al 2015a meyer 2011 henrichs et al 2009 2007 has progressively extended the scope of the software s non regular application for cso cws but has also pushed it to its limits modelling tools with system optimization purpose exist as well these strive to be practical in terms of handling see e g meyer et al 2015 targeting practitioners in order to facilitate the design of stormwater treatment systems for watershed scale a module of sustain lee et al 2012 provides a generalized scheme of process based simulation of flow and pollutant transport for a handful of structural best management practices bmp however simulating cso cw technology requires the representation of adsorption processes and an outflow rate limitation that governs system hydraulics specifically for single basin cso cws that pioneer in germany retention soil filters or rsfs rsf sim is a design oriented model it has a well described development track meyer and dittmer 2015 meyer 2011 schmitt and dittmer 2007 dittmer 2006 it simulates full scale variably saturated vertical flow constructed wetlands with good accuracy meyer and dittmer 2015 tondera et al 2013 but french systems have specificities in their technical implementation meyer et al 2013 in light of new knowledge and developments such as the appearance of dual sided filters in france and also in germany new models of cso cws need to satisfy four additional needs namely to 1 be capable to simulate two sided filters 2 include processes that describe the behaviour of overscaled filters and predict their weak performance so that such constructions can be avoided in the future 3 select certain removal parameters automatically depending from climatic factors that can impact those and 4 provide discrete output which is easy to compare with legislative thresholds on emission concentrations such model could serve automatic cso cw optimization which is a necessity due to 1 the stochastic nature of combined sewer overflows 2 the limited land availability in urban areas and 3 the expectable costs of treatment at the high number of overflow points to be implemented in light of the water framework directive and related national legislations for these reasons we have developed orage an engineering tool that proposes cso cw dimensions and material based on multi year series of combined sewer overflows and pollutant concentrations it consists of a core model and an autonomous optimization algorithm it is integrated into we present the core model in this paper to know more about the optimization algorithm the reader is advised to refer to pálfy et al 2017a the core model simulates hydraulics and total suspended solid tss chemical oxygen demand cod and ammonium nitrogen nh4 n removal it selects several parameters autonomously according to environmental factors such as regional climate season or the length of the last inter event period apart of two sided cso cws the core can simulate single basin wetlands as these treat stormwater in france we focus in this paper on two sided cso cw applications one of the two key objectives of our paper is to show that the new needs listed above can be addressed efficiently by a model that has simple process descriptions and with good accuracy in terms of predicted effluent quality to reach this objective we introduce the functionality and the structure of the core model of orage and demonstrate its ability to simulate the operation of a real cso cw built at marcy l etoile france that has been monitored continuously secondly we define the core model s parameter sensitivity to show how it can be integrated into an automatic optimization algorithm as it requires many parameters to be fixed or selected from pre defined tables this also sheds light on how the simplification of model output series into a single value could benefit a practice which works to satisfy discrete emission thresholds 2 materials and methods 2 1 the concept of cso cws in france the current state of the art in france fig 1 is inspired 1 by experiences from germany dittmer and schmitt 2011 frechen et al 2006 uhl and dittmer 2005 2 by french design cws treating unsettled municipal wastewater molle et al 2005 and 3 by pilot scale research fournel 2012 key considerations in their design are the following i treating unsettled water facilitates sludge management the twin filter sides allow sequential feeding this means one side stays unloaded at regular events small volumes both beds are simultaneously fed in the case of bigger loads only the primary filter receives the inflow the secondary filter receives settled water through the primary if any alternation of filter priority allows longer inter events in the secondary filter which favours mineralization of any previously accumulated sludge and organics the purpose is to avoid clogging sludge mineralization is discussed in pálfy et al 2017b ii the permanently saturated bottom zone provides water to living organisms during droughts iii aeration is separated from the drainage pipes and separate pipes are laid in the process layer drainage pipes are permanently underwater iv zeolite is added to the filter media if higher ammonium removal is needed see pálfy et al 2017c v compost is spread on the surface of the filter to facilitate reed establishment in the start up phase of the system an impervious liner is placed at the bottom of the filter storm generated flows enter the primary filter at the inflow point and fill the porous media at the beginning of each load the infiltration and percolation are limited to the area close to the inlet pores saturate rapidly because the outflow rate is limited by an orifice pálfy et al 2017c ponding follows in the detention space the outflow limitation ensures then a fairly uniform flow near plug flow and extends the detention time in the process layer favouring pollutant removal dittmer 2006 an impermeable wall separates the filter sides crossflow occurs only if the water reaches the cross connection pipe making the secondary filter operational in case of extreme cso volumes overflows from the wetland might occur as well when the loading is over the detained volumes percolate through the filter media progressively and the system empties the operating conditions described above allow cso cws to retain and or degrade tss cod and nh4 n which would otherwise contaminate natural waters mass removal for the three pollutants can reach up to 97 80 and 85 respectively pálfy et al 2017b the first stage of treatment is sedimentation and physical filtration in the top few centimetres of the filter dittmer 2006 the dominant processes for dissolved pollutants are anaerobic bacterial uptake of dissolved cod and adsorption of nh4 n these processes dominate during intra event periods during inter event periods however the filter is drained and the wet but aerated media favours nitrification and mineralization of organic solids dittmer and schmitt 2011 meyer 2011 dittmer et al 2005 uhl and dittmer 2005 the filters regenerate 2 2 the core model of orage 2 2 1 development and novelty the core model of orage has been conceptualized based on research at column pilot and full scale cso cw plants as well as system behaviour learnt from simulation studies pálfy et al 2015a felmeden 2013 fournel et al 2013 fournel 2012 dittmer and schmitt 2011 turković and fuchs 2010 heinrichs et al 2007 2009 waldhoff 2008 woźniak 2008 woźniak et al 2007 dittmer 2006 frechen et al 2006 dittmer et al 2005 it is a dynamic and deterministic model however due to its simplified process descriptions no differential equations are solved simplicity lowers simulation times and thus it favours automatic optimization the model works with input series that consist of arriving cso volumes in m3 and the concentrations of three pollutants tss cod and nh4 n in g m3 with a temporal discretization typically 6 min measured cso flows and concentrations as well as simulation output of sewer modelling software like kosim mike urban swmm and mouse engine or canoe schütze et al 2002 insavalor and sogreah 1997 can be used as boundary data the core model of orage is inspired by rsf sim which is also a dynamic model with relatively simple process descriptions meyer and dittmer 2015 new features in our model are 1 the hydraulic model can simulate both single and twin compartment filters see subchapter 2 2 2 2 effects of hydraulic shortcuts are simulated as these can decrease performances and cause oversized filters to fail pálfy et al 2017c see the second part of subchapter 2 2 3 on nh4 n removal 3 the model selects parameters environmental dependently climate region temperature loads following a drought see subchapter 2 2 3 4 it was built to be integrated into an autonomous optimization code meaning that simulations not only generate output series with temporal discretization but also calculate a single output that is a concentration value for comparison with emission thresholds see subchapter 2 2 4 5 the removal of total cod is calculated instead of the dissolved fraction 2 2 2 hydraulics the outflow orifice assures a stable and slow percolation around 0 02 l s m2 flow and transport processes are based on constant outflow rate and continuously stirred tank reactors in two parallel series fig 2 equations are valid for single sided filters when the area of the secondary side f2 and the cross connection level are zero the core simulates shortcutting at commencing load as discussed in subchapter 2 2 3 volumes and concentrations of flows and storage are calculated at each time step t1 and are available from the preceding time step t0 the model space is discretized into seven tanks the permanently saturated drainage layer is represented by d t 1 f 1 and d t 1 f 2 which have constant volume but concentrations may vary the process layer is represented by p t 1 f 1 and p t 1 f 2 with volumes between the residual water and saturation removal processes are modelled in this layer the detention space is discretized into three tanks r e t t 1 f 1 r e t t 1 f 2 and b a s i n t 1 and have volumes between zero and their maximum flow and solute transport is calculated after perfect mixing within the compartments the inflow 1 arrives to the primary retention side r e t t 1 f 1 it infiltrates 2 to the primary process layer p t 1 f 1 infiltration gets limited by the primary outflow orifice to match the outflow 71 when p t 1 f 1 is full otherwise the inflow 1 infiltrates instantaneously water percolates deeper 3 to the primary drainage layer d t 1 f 1 and an equal volume leaves the filter limited by 71 if the water in r e t t 1 f 1 reaches the level of the cross connection cross flow 4 occurs through the pipe that is built into the wall the cross flow 4 for the secondary retention side r e t t 1 f 2 is like the inflow 1 for the primary flows have an identical path infiltration to p t 1 f 2 5 and percolation to d t 1 f 2 6 leads to a limited outflow 72 in case the water reaches the cross connection level in r e t t 1 f 2 as well a common water level is established inflow 1 volumes are halved and distributed instantaneously still r e t t 1 f 2 receives water through r e t t 1 f 1 after complete mixing if r e t t 1 f 1 and r e t t 1 f 2 are both full b a s i n t 1 starts to get filled in this case inflow 1 is distributed between the three compartments of the detention space r e t t 1 f 1 and r e t t 1 f 2 has priority and receives equal volumes the rest of the inflow 1 is added 8 to b a s i n t 1 mixing happens independently by compartment if b a s i n t 1 is filled overflow 9 is instantaneous detained volumes leave through 71 and 72 calculations are detailed in appendix a the simplified flow and transport model can be considered as a good approximation of reality in the case of the three tanks that represent the detention space however in the porous media completely stirred tanks are applicable only because the percolation speed is governed by the outflow rate limitation instead of the hydraulic properties of the filter media even so a strong mitigation effect can be expected from the process and drainage layers on rapid concentration changes unlike if they were modelled through an approach that is more apt to simulate plug flow this disadvantage loses its importance as the existence of detention space ponding water to which inflow arrives and mixes with already rules out strong fluctuations potential impacts on model output would be the flattening of the outflow concentration curve 2 2 3 pollutant removal cod and tss removal are calculated when water is leaving the process layer flows 3 and 6 based on empirical equations these have been parameterized for tss to yield a constant background value and therefore our discussion focuses on cod for cod the existence of a correlation was observed between inflow and outflow concentrations fournel 2012 suggested an approach that was modified and implemented in the core model of orage outflow in orage is 1 a background constant for diluted inflows k g m3 up to inflow concentration c1 g m3 2 a linear correlation at moderate concentrations removal rate nu 1 applied between inflow concentrations c1 and c2 g m3 and 3 at high concentrations a higher removal rate nu 2 above c2 g m3 these parameters describe a correlation between the concentrations in the process layer and exfiltration flows 3 and 6 on fig 2 and as such the mixing of inflows with the ponding water is accounted for process equations can be found in the subroutine v d calc of appendix a measured data showed a rather large variance as such using a single correlation rule could have led to weak designs unless performance was underestimated which in itself reduces optimization efficiency meyer and dittmer 2015 improved model predictions in rsf sim taking into account the length of the preceding inter event period fig 3 parameters k c1 nu 1 c2 nu 2 can be calibrated and automatically selected by the tool depending on the inter event duration the season and the climate region dry and hot days were assumed to cause a drop in cod removal through bacterial starvation and drought pálfy et al 2015a dittmer 2006 parameters are selected as follows 1 selection of a climate season factor according to the climate and actual season of the pre defined region 2 normalization of the duration of the preceding inter event period in days based on this factor a multiplier between 0 and 1 3 selection of the corresponding inter event period range e g 2 8 days for 6 2 days 4 application of the set of parameters k c1 nu 1 c2 nu 2 associated to this range and according to the operation mode normal or shortcutting nh 4 n removal is a two step process adsorption in the solid phase during loads and nitrification limited to the inter event adsorption capacities in the material database represent 2 slope isotherms as shown in fig 4 the curve shows the instantaneous equilibrium between liquid and solid phase concentrations in the process layer it is a simplification of a freundlich isotherm having low mean absolute error mae at the concentration range of stormwater and cso e g sztruhár et al 2002 it allows to express the state of equilibrium without solving a differential equation only the inlet zone is water contacted in the filters at the beginning of each load this shortcutting state might last if inflow rates are low percolation is limited to the inlet zone thus sorption capacity is limited as well pálfy et al 2015b therefore in the model calculations are different until the water level is below the one defined by the constant h e fig 5 equilibrium concentrations are calculated for the infiltration zone only considering exclusively the infiltrant water is mixed then with that in the process layer the surface area of infiltration is estimated using eq 1 based on the infiltrating volume and darcy s law mass of water contacted media can then be estimated using eq 2 1 a i n f t 1 f x f i n f t 1 f x k 2 m a c t i v e t 1 f x a i n f t 1 f x d f i l t r h o m e d i a where fx refers to f1 or f2 according to which filter side the calculation is done for a i n f t 1 f x is the area of infiltration m2 f i n f t 1 f x the infiltrating volume m3 k the infiltration m per time step through the organic deposit and compost on the top m a c t i v e t 1 f x the mass of media kg in contact d filt the depth of the filter layer m and rho media the bulk density of the media kg m3 the adsorbed mass of nh 4 n is calculated for the overall mass of filter media n h 4 o l d m a s s t 1 f x and the fraction stored in the shortcutting zone n h 4 i n f z o n e m t 1 f x sorption sites in the shortcutting zone might saturate independently from the rest of the filter allowing shortcutting peaks to occur in the simulations the shortcutting zone changes as a function of the infiltrating volume inflow at each time step fig 5 if the infiltration area increases or decreases the mass of sorbed nh 4 n is recalculated a closed mass balance is ensured by the exchange with the mass stored in the rest of the filter non infiltration area which exchange is linearly proportional to the gain or loss of the infiltration non infiltration area nitrification starts as soon as the filter layer begins to empty the initial rate is linearly proportional to the emptied volume compared to the full rate the full rate is calculated according to eq 3 based on the work of meyer and dittmer 2015 the rate is the function of the mass in the solid phase and the mean seasonal temperature nh 4 n in the drainage layer is solely in solution but nitrified anyway after the outflow ceases down to a background concentration 3 n h 4 n t 1 n h 4 n t 0 e x x d i e t 20 r c where n h 4 n is the mass of ammonium nitrogen at time step t1 or t0 g d i is a rate constant 1 time step t is the temperature c and rc the constant expressing temperature sensibility parameters are calibrated based on field measurements pálfy et al 2017c 2 2 4 shell integration the iterative shell of orage pálfy et al 2017a calls the core model repetitively i e simulations with different filter parameters until the design is considered optimal the connection between the core model and the iterative algorithm is the model s single output which is one concentration g m3 value for each pollutant the core model returns a single value as output based on 1 the multiple year inflow dataset 2 input parameters and 3 the pollutant which the simulation is called for tss cod or nh4 n this single variable is called peak ma cc peak of moving average concentrations g m3 and can be understood as the concentration of a composite sample from the worst event for small events with outflow duration under 6 h this value can be modified the value of peak ma cc isn t recorded for outflow from six to 24 h the maximum of the mean outflow concentrations calculated at each time step is selected from 24 h on the maximum might be updated based on moving average concentrations from the last 24 h blocks the tested design is acceptable if peak ma cc is at the legislative threshold within a tight tolerance range the optimization approach iterative shell is discussed in pálfy et al 2017a 2 3 calibration of the core model 2 3 1 first calibration to a single extreme load calibration was based on flow and concentration series acquired at the full scale cso cw operated at marcy l etoile france pálfy et al 2015b meyer et al 2013 an extremely long event event 14 was selected and 1 parameters of or measured at the real site 2 rsf sim standards meyer and dittmer 2015 or 3 estimated values were used as the base of the calibration the constant of outflow limitation was fine tuned to fit water levels cod parameters were then adjusted manually until a visually good fit was reached without considering the effect of inter event durations event 14 was a heavy load 156 g m2 so nh 4 n sorption was fitted to a real breakthrough curve 2 3 2 testing accuracy and stability with event series event series were simulated without further parameter refinement simulations served two purposes to evaluate model accuracy and to show if the model stays stable with the alternation of intra and inter event periods so if it can be applied in the future with long term data for design optimization four consecutive loads with closed material balance and short inter events were modelled event 14 was added to see if preceding loads change output table 1 summarizes the characteristics of the five events 2 3 3 assessment of model accuracy series of simulated cod and nh4n effluent concentrations were compared to values measured at the outlet of the marcy l étoile site pálfy et al 2017b accuracy was assessed by the following calculations a difference of simulated 6 24 h peak ma cc compared to the measured g m3 b difference to measured mass removal mae c time weighted event mean concentrations emc mae g m3 mae d difference of total nitrified mass e difference in shortcutting durations for sensitivity analysis only f time shift to measured nh 4 n breakthrough h g goodness of fit e j ahnert et al 2007 the coefficient of efficiency e j was calculated with j 1 to make it more sensitive to fitting inaccuracies ahnert et al 2007 composite samples covered various time intervals this was counterbalanced by including time weighing in the classical equation 4 e j 1 i 1 n m i t i e i t i j i 1 n m i t i m t i j where m i is the measured concentration for composite i e i is the average of simulated concentrations coinciding with composite i m is the time weighted average of all measured concentrations and t i is the time represented by composite i no classification ranges i e good fit bad fit were proposed by ahnert et al 2007 they suggested to apply other numerical methods simultaneously and to present charts for visual interpretation if the value of e j is below zero either the arithmetic mean is a better predictor than the model or the measured values were too low or nearly constant pálfy and langergraber 2014 the interpretation of e j was aided by calculating the mean time weighed deviation 5 d e v i 1 n m i t i e i t i t where e i is the simulated value for composite i t is the duration of the intra event period on which the analysis is done d e v g m3 and d e v helps to decide if e j indicates a poor fit or fails the goodness of fit was considered weak if e j indicated weak results with a value below 0 1 and d e v seemed important 2 3 4 sensitivity analysis model sensitivity was tested using a one factor at a time oat screening technique called the morris method morris 1991 applied with the improvements of campolongo et al 2007 the method yielded two values describing the importance of each scrutinized model parameter one was correlated to the overall influence μ i on the output and the other to the non linearity interactions with other factors σi the analysis was carried out separately on cod removal number of parameters k 16 and on nh 4 n removal k 21 because the model did not allow to take into account interactions between the two pollutants and can be called on one pollutant at a time common parameters were those describing hydraulics and temperature dependence each model parameter xi i 1 k was varied within a pre defined input range at four levels p 4 yielding n 160 simulations for cod and n 220 for nh 4 n input ranges were selected to be realistic for cso cws values for μ i and σi were calculated based on the values of elementary effects ee detailed description of the calculation were given by morris 1991 and campolongo et al 2007 an ee was defined for each input vector x consisting of k parameters one changed at a time for a given x the ee linked to the ith input factor is defined as 6 d i x y x i x i 1 x i δ x i 1 x k y x δ the basis of evaluation is often taken to be the arithmetic mean of model output i e y x emc x for a more detailed outcome about model sensitivity and robustness the analysis was done on all statistics listed in subchapter 2 3 3 as for goodness of fit a single numerical had to be calculated from e j and d e v scores 1 worst were derived based on arbitrarily selected ranges table 2 the final score was based on e j if the score for d e v was the higher e j was increased by one otherwise it was left unchanged the arithmetic mean of six final scores for five events one by filter side was defined as y x the ranges of input parameters are listed in appendix b a wide range was used on filter area a tot 200 m2 2000 m2 to focus the analysis on shortcutting and to see if a tot really has a minor effect on cod removal then the analysis for nh 4 n was repeated with a tighter range which was assumed to be hydrologically optimized 250 650 m2 table 3 lists shortcutting times in the function of filter area 3 results 3 1 first calibration to a single and extreme load the results of the first calibration are summarized in table 4 some parameters had been refined since the experiments of this paper like e g those that are related to processes discussed in pálfy et al 2017c the single run showed a good fit to measured hydraulics fig 6 and outflow concentrations fig 7 water levels and ponding duration were also well predicted regardless the extreme length of the event the existence of a constant outflow rate simplified indeed greatly the hydraulics of the system the changes in cod were followed with a slight shift in time and with flattened amplitude still well fitted ej 0 1 mean time weighted deviation 7 5 g m3 nh 4 n was fitted excellently ej 0 7 mean time weighted deviation 1 2 g m3 the time of predicted breakthrough showed a 2 h delay which did not cause any visible shift on the chart fitting nh 4 n concentrations is crucial for a good design especially after the breakthrough see before 72 h event time on fig 7 3 2 testing accuracy and stability with event series the fit between simulated and experimental effluent concentrations was between fairly good and good with a score of 3 50 for cod and 3 33 for nh 4 n results of statistical analysis are summarized in table 5 model predictions were satisfying for most of the events still a gap of 26 9 or 18 9 g m3 for cod peak ma cc was obtained which should be improved because this variable will be used by the design optimization algorithm fig 8 shows intra event concentrations at events 16 19 the largest error was due to event 16 where effluent concentrations were underestimated by the model the possible reasons for this were that 1 the samples for events 16 and 19 were taken from settled ponding water so concentrations of model input were less than that of the real inflow and 2 the dry period before event 16 was two months long and its possible impact on modelled performances had not been calibrated yet leaving away event 16 would have decreased the gap between the simulated and measured values to 9 5 for nh 4 n the event mean concentration had an average difference of 33 5 mae expressed in concentrations this difference was small 1 4 g m3 over the measured value shortcutting peaks were excessively large at events 17 and 18 a parameter k2 was set deliberately low to make shortcut effects clearly visible k2 shall be fixed equal or just slightly lower to its counterpart used under normal operation in order to have smaller peaks lowering the initial shortcutting peaks would result weaker fit because nh 4 n concentrations were starting from close to zero this can be counterbalanced by increasing the background concentration parameter higher event 14 was excluded from fig 8 because model predictions did not cause visually notable alternation compared to the single load shown on fig 7 the stability of the model was verified through the simulation of alternated intra and inter event periods the regeneration in the inter event periods allowed predicting nh4 n concentrations in the following events with no shift in material balances and due to the discrete values of parameters behind removal processes the model is anticipated to have no limitation regarding the length of input data 3 3 sensitivity analysis 3 3 1 sensitivity analysis of cod removal calculations the sensitivity analysis sa on cod removal confirmed the importance of the performance parameters nu 1 c2 and nu 2 for 6 24 h peak ma cc fig 9 nu 1 and nu 2 set removal efficiency and c2 set in every time step which one to use however the other two performance parameters k and c1 showed influence only at lower inflow concentrations their effect was small because inflow concentrations were too high in our dataset to trigger background values in the effluent results confirmed model robustness as other parameters had little effect on simulations especially on 6 24 h peak ma cc 3 3 2 sensitivity analysis of nh 4 n removal calculations with excessive shortcutting durations wide parameter ranges were causing shortcutting to be the dominant operation in the domain for almost all vectors x of the experiment ranges were tightened therefore in a second experiment to what physical research and design practice could justify as such one of the two analyses targeted performances at shortcutting wide ranges for area and the other the classical operation with little shortcutting tight ranges for area the results at excessive shortcutting durations fig 10 highlighted significant parameters which determine shortcutting duration i e how long it takes until the water level fills up to the shortcutting threshold depth h e in the simulations domain these were 1 h e itself m 2 the base outflow rate f limit base m3 m2 h and 3 the total filter area a tot m2 the higher these numbers were the longer it took to get a water level above h e it can be anticipated that a bad combination of these hit simulated and real world performances badly therefore parameters which describe adsorption capacities in the shortcutting zone showed less importance k1 a1 c1 during long hydraulic shortcutting adsorption sites could get easily saturated in the infiltration zone limited to the inlet area overall the total filter area a tot was the most significant of those parameters which are not going to be fixed for the automatic optimization 3 3 3 sensitivity analysis of nh 4 n removal calculations with normal shortcutting durations the range of the filter area a tot and the flow limitation f limit base were selected to give hydraulically consistent domains fig 11 shows results with such input vectors x f limit base was significant for the goodness of fit index because at some vectors x the remaining shortcutting peaks affected the fit even if the peaks themselves were fleeting adsorption related parameters were otherwise the most significant these were 1 the material specific adsorption capacity a1 m3 kg and 2 the depth of the filter layer d filt m the depth of the filter together with its area a tot determines the total mass kg of the media and with that its total adsorption capacity a1 can be calibrated to measurements and a tot is going to be optimized by the iterative shell of orage it must be noted that d filt was not a target of the optimization algorithms and strong correlation had been absent between treatment performances and filter depth in pilot scale research done by fournel 2012 meanwhile a tot on which the automatic optimization of orage will be based was deemed to be less significant by our sa as such we identified a weakpoint of the model doubling the filter thickness had the same effect on the virtual adsorption capacities as doubling filter area and that is to be addressed in practical optimization applications e g by fixing filter depth 4 discussion the core model of orage was calibrated to a full scale cso cw marcy l etoile treating unsettled water in twin basins manual calibration gave excellent goodness of fit to the single event even though hydraulic and pollutant loads were high then a medium term event series was simulated consisting of five loads the goodness of fit was moderate to good without changing parameters between the events the unloaded inter event periods allowed the simulation domain to return to a stable condition to background levels of water content and nh 4 n in both the liquid and solid phases as such the model remained stable with the alternation of intra and inter event periods this in the light of process simplification discrete parameters defining adsorption capacity cod and tss removal and storage volumes to overflow indicated readiness for long term data several alternations statistical analyses of measured and simulated effluent data also confirmed model accuracy the peak of moving average on effluent concentrations peak ma cc had been included in the model to have a single concentration value as key output and to serve as connection between the core model and the optimization not presented here for nh 4 n simulated peak ma cc fit well that which was calculated from measured effluent error 1 7 g m3 or 12 2 the error was rather large for cod 18 9 g m3 or 26 9 due to one event that arrived after a warm and long inter event and where ponding water was sampled instead of the inlet calibrating the effect of inter event periods on cod removal should increase accuracy the sensitivity analysis has proven model robustness most model parameters show little effect on the output within their realistic range and can safely be fixed other parameters that are significant are either fixed in design guidelines e g percolation speed in the filter media f limit base or will need meticulous calibration nh 4 n adsorption parameters by material cod removal parameters as the function of dry periods and temperature the total filter area a tot is important for the simulated nh 4 n removal not only due to the available adsorption capacities but also due to hydraulic shortcuts that cause performance drop for excessively large filters the analysis highlights that filter depth d filt is important too unlike in reality this might be the weak point of the model because adsorption capacities are correlated with the mass of the filter media in reality the available organic matter plays a role as well and the correlation is less direct fournel 2012 the accuracy of the core model can be improved further modelling a diversity of full scale sites would be beneficial after enough sites are built to do so this is especially true for parameters recorded in internal tables such as those responsible to select the climatic and inter event effects for cod removal and the material database containing the adsorption isotherms 5 conclusions the simple process descriptions of orage are satisfactory for modelling cso cws on one hand we extended successfully the simple hydraulic model for 1 two sided filters and 2 hydraulic shortcutting in oversized filters although a tank in series approach is insufficient to simulate processes that happen only in a part of the filter by the combination with another simple model a simple approach might be kept in our case such coupling is used at very low water levels in the porous media as that focuses infiltration close to the inlet and enables the simulation of performance drops of oversized systems in general such coupling can help to keep the model simple as well as to keep the advantages of simple handling and faster simulation speeds another example for simplification is the discretization of the adsorption isotherm this enabled to calculate the process without solving differential equations this approach could be refined by quantizing the curve or working with multiple stage isotherms to increase precision and simplified models might benefit from it for the same reasons of speed and handling mentioned above from the user s perspective the core model targets practitioners to provide support for design and to serve the automatic optimization of filter area and materials returning a single output which is directly comparable to the legislative thresholds on effluent concentrations serves the core s integration into an automatic algorithm overall the low number of input parameters can keep handling simple without compromising the accuracy of predictions the core is ready to be integrated in an autonomous iterative shell as it had shown accuracy and robustness acknowledgements the authors thank jean marc croumier the flexibility and patience in transferring our ideas into a computer program the wastewater treatment team s engineers and technicians for their effort which supported field measurements nicolas forquet for his advices and the script to generate parameter sets onema and rmc water authorities for their financial support appendix a calculation of flows and pollutant removal in the core model of orage image 1 appendix b parameter ranges of the sensitivity analysis image 2 
26419,constructed wetlands treating combined sewer overflow cso cws are vertical flow filters in france with outflow limitation and detention basin treating storm generated flows reduces pollutants and flow peaks entering natural waters storm generated flows are stochastic and therefore optimized cso cw design requires a dynamic approach i e a modelling software targeting engineers therefore a new tool called orage was developed orage consists of a core model an iterative shell and a user interface it optimizes dimensions and materials of cso cws site specifically based on inflow series and a low number of input parameters the core model simulates hydraulics and tss cod and nh4 n removal manual fitting of the core showed good results with a single load the same parameters gave satisfying accuracy when simulating load series with closed material balance sensitivity analysis confirmed model robustness and justified coupling with an automatic shell algorithm for automatic optimization based on a single output keywords combined sewer overflow constructed wetland design support modelling dynamic design stormwater treatment orage abbreviations tss total suspended solids nh4 n ammonium nitrogen cod chemical oxygen demand software availability name of software orage alpha 0 6 developer irstea and megao informatique france contact remy arnaud remi arnaud megao com availability freeware version 1 0 available online at epnac irstea fr from 2018 1 introduction 1 1 cso cws and stormwater treatment urbanization impacts negatively the hydrology physical chemical properties and biota of surface and groundwater preventive measures are often absent and as a consequence waters suffer the effects of untreated urban runoffs these are rejected with combined sewer overflows cso or as separate sewer outlet sso urban stream syndrome is the generalized ecological degradation of streams draining urban land chocat et al 1994 walsh et al 2005 combined sewers accommodate high flows of stormwater mixed with domestic sewage overflow mechanisms prevent overfilling of pipes and limit downpipe flow rates to the capacity of the wastewater treatment plant unwanted peaks discharge as cso carry significant amount of organics nutrients heavy metals and bacteria in contrast sso is released end of pipe and carry less organic matter and nutrient but suspended solids specific organic pollutants and heavy metals are a concern both cso and sso erode and or silt up stream habitat and change streambed morphology meyer et al 2013 constructed wetlands cws for cso treatment cso cws are implemented or are planned to be in several countries in europe vertical downflow vf arrangements are promising e g meyer et al 2013 after positive experiences with retention soil filters rsfs dittmer et al 2016 uhl and dittmer 2005 in germany the european water framework directive 2000 60 ec calls for the good quality of natural waters and the limitation and or treatment of cso is needed to reach its goals different types of cws exist fonder and headley 2013 but the solution in france for cso treatment is a specific vertical downflow arrangement with outflow rate limitation in this paper cso cw refers to this new state of the art unless otherwise specified in france stormwater is collected in about 25 of the lines by combined sewers soes 2011 and treatment of overflows started recently the key specificity of cso cws is that in contrast to cws treating domestic wastewater inflows have stochastic periodicity volume and quality furthermore these systems have a detention basin above the filter material loadings saturate the porous media and cause ponding intra event state several hours might pass until the detained water is filtered leaving through an orifice to limit outflow rate after this the pores get filled again with air for several days inter event state and might even dry out in extreme cases some treatment processes can be attributed by their dominant occurrence to the intra event others to the inter event environment filtration adsorption and anaerobic biodegradation take place during intra event while aerobic bioprocesses predominantly the nitrification of adsorbed ammonia and organic matter biodegradation dominate the inter event phase dittmer et al 2005 2016 dittmer and schmitt 2011 meyer 2011 dittmer et al 2005 uhl and dittmer 2005 1 2 design support modelling of cso cws due to the stochastic nature of storm generated flows and the related existence of intra and inter event phases design optimization needs a dynamic approach this can be achieved through modelling numerical modelling of wetlands treating combined sewer overflows is a new direction of constructed wetland research and the range of publications dealing with the topic is therefore relatively limited some existing models have a wider application domain but match the complexity of the task such is the process based hydrus cw2d langergraber and šimůnek 2005 validated for laboratory cso cw columns recently the works of pálfy et al 2015a meyer 2011 henrichs et al 2009 2007 has progressively extended the scope of the software s non regular application for cso cws but has also pushed it to its limits modelling tools with system optimization purpose exist as well these strive to be practical in terms of handling see e g meyer et al 2015 targeting practitioners in order to facilitate the design of stormwater treatment systems for watershed scale a module of sustain lee et al 2012 provides a generalized scheme of process based simulation of flow and pollutant transport for a handful of structural best management practices bmp however simulating cso cw technology requires the representation of adsorption processes and an outflow rate limitation that governs system hydraulics specifically for single basin cso cws that pioneer in germany retention soil filters or rsfs rsf sim is a design oriented model it has a well described development track meyer and dittmer 2015 meyer 2011 schmitt and dittmer 2007 dittmer 2006 it simulates full scale variably saturated vertical flow constructed wetlands with good accuracy meyer and dittmer 2015 tondera et al 2013 but french systems have specificities in their technical implementation meyer et al 2013 in light of new knowledge and developments such as the appearance of dual sided filters in france and also in germany new models of cso cws need to satisfy four additional needs namely to 1 be capable to simulate two sided filters 2 include processes that describe the behaviour of overscaled filters and predict their weak performance so that such constructions can be avoided in the future 3 select certain removal parameters automatically depending from climatic factors that can impact those and 4 provide discrete output which is easy to compare with legislative thresholds on emission concentrations such model could serve automatic cso cw optimization which is a necessity due to 1 the stochastic nature of combined sewer overflows 2 the limited land availability in urban areas and 3 the expectable costs of treatment at the high number of overflow points to be implemented in light of the water framework directive and related national legislations for these reasons we have developed orage an engineering tool that proposes cso cw dimensions and material based on multi year series of combined sewer overflows and pollutant concentrations it consists of a core model and an autonomous optimization algorithm it is integrated into we present the core model in this paper to know more about the optimization algorithm the reader is advised to refer to pálfy et al 2017a the core model simulates hydraulics and total suspended solid tss chemical oxygen demand cod and ammonium nitrogen nh4 n removal it selects several parameters autonomously according to environmental factors such as regional climate season or the length of the last inter event period apart of two sided cso cws the core can simulate single basin wetlands as these treat stormwater in france we focus in this paper on two sided cso cw applications one of the two key objectives of our paper is to show that the new needs listed above can be addressed efficiently by a model that has simple process descriptions and with good accuracy in terms of predicted effluent quality to reach this objective we introduce the functionality and the structure of the core model of orage and demonstrate its ability to simulate the operation of a real cso cw built at marcy l etoile france that has been monitored continuously secondly we define the core model s parameter sensitivity to show how it can be integrated into an automatic optimization algorithm as it requires many parameters to be fixed or selected from pre defined tables this also sheds light on how the simplification of model output series into a single value could benefit a practice which works to satisfy discrete emission thresholds 2 materials and methods 2 1 the concept of cso cws in france the current state of the art in france fig 1 is inspired 1 by experiences from germany dittmer and schmitt 2011 frechen et al 2006 uhl and dittmer 2005 2 by french design cws treating unsettled municipal wastewater molle et al 2005 and 3 by pilot scale research fournel 2012 key considerations in their design are the following i treating unsettled water facilitates sludge management the twin filter sides allow sequential feeding this means one side stays unloaded at regular events small volumes both beds are simultaneously fed in the case of bigger loads only the primary filter receives the inflow the secondary filter receives settled water through the primary if any alternation of filter priority allows longer inter events in the secondary filter which favours mineralization of any previously accumulated sludge and organics the purpose is to avoid clogging sludge mineralization is discussed in pálfy et al 2017b ii the permanently saturated bottom zone provides water to living organisms during droughts iii aeration is separated from the drainage pipes and separate pipes are laid in the process layer drainage pipes are permanently underwater iv zeolite is added to the filter media if higher ammonium removal is needed see pálfy et al 2017c v compost is spread on the surface of the filter to facilitate reed establishment in the start up phase of the system an impervious liner is placed at the bottom of the filter storm generated flows enter the primary filter at the inflow point and fill the porous media at the beginning of each load the infiltration and percolation are limited to the area close to the inlet pores saturate rapidly because the outflow rate is limited by an orifice pálfy et al 2017c ponding follows in the detention space the outflow limitation ensures then a fairly uniform flow near plug flow and extends the detention time in the process layer favouring pollutant removal dittmer 2006 an impermeable wall separates the filter sides crossflow occurs only if the water reaches the cross connection pipe making the secondary filter operational in case of extreme cso volumes overflows from the wetland might occur as well when the loading is over the detained volumes percolate through the filter media progressively and the system empties the operating conditions described above allow cso cws to retain and or degrade tss cod and nh4 n which would otherwise contaminate natural waters mass removal for the three pollutants can reach up to 97 80 and 85 respectively pálfy et al 2017b the first stage of treatment is sedimentation and physical filtration in the top few centimetres of the filter dittmer 2006 the dominant processes for dissolved pollutants are anaerobic bacterial uptake of dissolved cod and adsorption of nh4 n these processes dominate during intra event periods during inter event periods however the filter is drained and the wet but aerated media favours nitrification and mineralization of organic solids dittmer and schmitt 2011 meyer 2011 dittmer et al 2005 uhl and dittmer 2005 the filters regenerate 2 2 the core model of orage 2 2 1 development and novelty the core model of orage has been conceptualized based on research at column pilot and full scale cso cw plants as well as system behaviour learnt from simulation studies pálfy et al 2015a felmeden 2013 fournel et al 2013 fournel 2012 dittmer and schmitt 2011 turković and fuchs 2010 heinrichs et al 2007 2009 waldhoff 2008 woźniak 2008 woźniak et al 2007 dittmer 2006 frechen et al 2006 dittmer et al 2005 it is a dynamic and deterministic model however due to its simplified process descriptions no differential equations are solved simplicity lowers simulation times and thus it favours automatic optimization the model works with input series that consist of arriving cso volumes in m3 and the concentrations of three pollutants tss cod and nh4 n in g m3 with a temporal discretization typically 6 min measured cso flows and concentrations as well as simulation output of sewer modelling software like kosim mike urban swmm and mouse engine or canoe schütze et al 2002 insavalor and sogreah 1997 can be used as boundary data the core model of orage is inspired by rsf sim which is also a dynamic model with relatively simple process descriptions meyer and dittmer 2015 new features in our model are 1 the hydraulic model can simulate both single and twin compartment filters see subchapter 2 2 2 2 effects of hydraulic shortcuts are simulated as these can decrease performances and cause oversized filters to fail pálfy et al 2017c see the second part of subchapter 2 2 3 on nh4 n removal 3 the model selects parameters environmental dependently climate region temperature loads following a drought see subchapter 2 2 3 4 it was built to be integrated into an autonomous optimization code meaning that simulations not only generate output series with temporal discretization but also calculate a single output that is a concentration value for comparison with emission thresholds see subchapter 2 2 4 5 the removal of total cod is calculated instead of the dissolved fraction 2 2 2 hydraulics the outflow orifice assures a stable and slow percolation around 0 02 l s m2 flow and transport processes are based on constant outflow rate and continuously stirred tank reactors in two parallel series fig 2 equations are valid for single sided filters when the area of the secondary side f2 and the cross connection level are zero the core simulates shortcutting at commencing load as discussed in subchapter 2 2 3 volumes and concentrations of flows and storage are calculated at each time step t1 and are available from the preceding time step t0 the model space is discretized into seven tanks the permanently saturated drainage layer is represented by d t 1 f 1 and d t 1 f 2 which have constant volume but concentrations may vary the process layer is represented by p t 1 f 1 and p t 1 f 2 with volumes between the residual water and saturation removal processes are modelled in this layer the detention space is discretized into three tanks r e t t 1 f 1 r e t t 1 f 2 and b a s i n t 1 and have volumes between zero and their maximum flow and solute transport is calculated after perfect mixing within the compartments the inflow 1 arrives to the primary retention side r e t t 1 f 1 it infiltrates 2 to the primary process layer p t 1 f 1 infiltration gets limited by the primary outflow orifice to match the outflow 71 when p t 1 f 1 is full otherwise the inflow 1 infiltrates instantaneously water percolates deeper 3 to the primary drainage layer d t 1 f 1 and an equal volume leaves the filter limited by 71 if the water in r e t t 1 f 1 reaches the level of the cross connection cross flow 4 occurs through the pipe that is built into the wall the cross flow 4 for the secondary retention side r e t t 1 f 2 is like the inflow 1 for the primary flows have an identical path infiltration to p t 1 f 2 5 and percolation to d t 1 f 2 6 leads to a limited outflow 72 in case the water reaches the cross connection level in r e t t 1 f 2 as well a common water level is established inflow 1 volumes are halved and distributed instantaneously still r e t t 1 f 2 receives water through r e t t 1 f 1 after complete mixing if r e t t 1 f 1 and r e t t 1 f 2 are both full b a s i n t 1 starts to get filled in this case inflow 1 is distributed between the three compartments of the detention space r e t t 1 f 1 and r e t t 1 f 2 has priority and receives equal volumes the rest of the inflow 1 is added 8 to b a s i n t 1 mixing happens independently by compartment if b a s i n t 1 is filled overflow 9 is instantaneous detained volumes leave through 71 and 72 calculations are detailed in appendix a the simplified flow and transport model can be considered as a good approximation of reality in the case of the three tanks that represent the detention space however in the porous media completely stirred tanks are applicable only because the percolation speed is governed by the outflow rate limitation instead of the hydraulic properties of the filter media even so a strong mitigation effect can be expected from the process and drainage layers on rapid concentration changes unlike if they were modelled through an approach that is more apt to simulate plug flow this disadvantage loses its importance as the existence of detention space ponding water to which inflow arrives and mixes with already rules out strong fluctuations potential impacts on model output would be the flattening of the outflow concentration curve 2 2 3 pollutant removal cod and tss removal are calculated when water is leaving the process layer flows 3 and 6 based on empirical equations these have been parameterized for tss to yield a constant background value and therefore our discussion focuses on cod for cod the existence of a correlation was observed between inflow and outflow concentrations fournel 2012 suggested an approach that was modified and implemented in the core model of orage outflow in orage is 1 a background constant for diluted inflows k g m3 up to inflow concentration c1 g m3 2 a linear correlation at moderate concentrations removal rate nu 1 applied between inflow concentrations c1 and c2 g m3 and 3 at high concentrations a higher removal rate nu 2 above c2 g m3 these parameters describe a correlation between the concentrations in the process layer and exfiltration flows 3 and 6 on fig 2 and as such the mixing of inflows with the ponding water is accounted for process equations can be found in the subroutine v d calc of appendix a measured data showed a rather large variance as such using a single correlation rule could have led to weak designs unless performance was underestimated which in itself reduces optimization efficiency meyer and dittmer 2015 improved model predictions in rsf sim taking into account the length of the preceding inter event period fig 3 parameters k c1 nu 1 c2 nu 2 can be calibrated and automatically selected by the tool depending on the inter event duration the season and the climate region dry and hot days were assumed to cause a drop in cod removal through bacterial starvation and drought pálfy et al 2015a dittmer 2006 parameters are selected as follows 1 selection of a climate season factor according to the climate and actual season of the pre defined region 2 normalization of the duration of the preceding inter event period in days based on this factor a multiplier between 0 and 1 3 selection of the corresponding inter event period range e g 2 8 days for 6 2 days 4 application of the set of parameters k c1 nu 1 c2 nu 2 associated to this range and according to the operation mode normal or shortcutting nh 4 n removal is a two step process adsorption in the solid phase during loads and nitrification limited to the inter event adsorption capacities in the material database represent 2 slope isotherms as shown in fig 4 the curve shows the instantaneous equilibrium between liquid and solid phase concentrations in the process layer it is a simplification of a freundlich isotherm having low mean absolute error mae at the concentration range of stormwater and cso e g sztruhár et al 2002 it allows to express the state of equilibrium without solving a differential equation only the inlet zone is water contacted in the filters at the beginning of each load this shortcutting state might last if inflow rates are low percolation is limited to the inlet zone thus sorption capacity is limited as well pálfy et al 2015b therefore in the model calculations are different until the water level is below the one defined by the constant h e fig 5 equilibrium concentrations are calculated for the infiltration zone only considering exclusively the infiltrant water is mixed then with that in the process layer the surface area of infiltration is estimated using eq 1 based on the infiltrating volume and darcy s law mass of water contacted media can then be estimated using eq 2 1 a i n f t 1 f x f i n f t 1 f x k 2 m a c t i v e t 1 f x a i n f t 1 f x d f i l t r h o m e d i a where fx refers to f1 or f2 according to which filter side the calculation is done for a i n f t 1 f x is the area of infiltration m2 f i n f t 1 f x the infiltrating volume m3 k the infiltration m per time step through the organic deposit and compost on the top m a c t i v e t 1 f x the mass of media kg in contact d filt the depth of the filter layer m and rho media the bulk density of the media kg m3 the adsorbed mass of nh 4 n is calculated for the overall mass of filter media n h 4 o l d m a s s t 1 f x and the fraction stored in the shortcutting zone n h 4 i n f z o n e m t 1 f x sorption sites in the shortcutting zone might saturate independently from the rest of the filter allowing shortcutting peaks to occur in the simulations the shortcutting zone changes as a function of the infiltrating volume inflow at each time step fig 5 if the infiltration area increases or decreases the mass of sorbed nh 4 n is recalculated a closed mass balance is ensured by the exchange with the mass stored in the rest of the filter non infiltration area which exchange is linearly proportional to the gain or loss of the infiltration non infiltration area nitrification starts as soon as the filter layer begins to empty the initial rate is linearly proportional to the emptied volume compared to the full rate the full rate is calculated according to eq 3 based on the work of meyer and dittmer 2015 the rate is the function of the mass in the solid phase and the mean seasonal temperature nh 4 n in the drainage layer is solely in solution but nitrified anyway after the outflow ceases down to a background concentration 3 n h 4 n t 1 n h 4 n t 0 e x x d i e t 20 r c where n h 4 n is the mass of ammonium nitrogen at time step t1 or t0 g d i is a rate constant 1 time step t is the temperature c and rc the constant expressing temperature sensibility parameters are calibrated based on field measurements pálfy et al 2017c 2 2 4 shell integration the iterative shell of orage pálfy et al 2017a calls the core model repetitively i e simulations with different filter parameters until the design is considered optimal the connection between the core model and the iterative algorithm is the model s single output which is one concentration g m3 value for each pollutant the core model returns a single value as output based on 1 the multiple year inflow dataset 2 input parameters and 3 the pollutant which the simulation is called for tss cod or nh4 n this single variable is called peak ma cc peak of moving average concentrations g m3 and can be understood as the concentration of a composite sample from the worst event for small events with outflow duration under 6 h this value can be modified the value of peak ma cc isn t recorded for outflow from six to 24 h the maximum of the mean outflow concentrations calculated at each time step is selected from 24 h on the maximum might be updated based on moving average concentrations from the last 24 h blocks the tested design is acceptable if peak ma cc is at the legislative threshold within a tight tolerance range the optimization approach iterative shell is discussed in pálfy et al 2017a 2 3 calibration of the core model 2 3 1 first calibration to a single extreme load calibration was based on flow and concentration series acquired at the full scale cso cw operated at marcy l etoile france pálfy et al 2015b meyer et al 2013 an extremely long event event 14 was selected and 1 parameters of or measured at the real site 2 rsf sim standards meyer and dittmer 2015 or 3 estimated values were used as the base of the calibration the constant of outflow limitation was fine tuned to fit water levels cod parameters were then adjusted manually until a visually good fit was reached without considering the effect of inter event durations event 14 was a heavy load 156 g m2 so nh 4 n sorption was fitted to a real breakthrough curve 2 3 2 testing accuracy and stability with event series event series were simulated without further parameter refinement simulations served two purposes to evaluate model accuracy and to show if the model stays stable with the alternation of intra and inter event periods so if it can be applied in the future with long term data for design optimization four consecutive loads with closed material balance and short inter events were modelled event 14 was added to see if preceding loads change output table 1 summarizes the characteristics of the five events 2 3 3 assessment of model accuracy series of simulated cod and nh4n effluent concentrations were compared to values measured at the outlet of the marcy l étoile site pálfy et al 2017b accuracy was assessed by the following calculations a difference of simulated 6 24 h peak ma cc compared to the measured g m3 b difference to measured mass removal mae c time weighted event mean concentrations emc mae g m3 mae d difference of total nitrified mass e difference in shortcutting durations for sensitivity analysis only f time shift to measured nh 4 n breakthrough h g goodness of fit e j ahnert et al 2007 the coefficient of efficiency e j was calculated with j 1 to make it more sensitive to fitting inaccuracies ahnert et al 2007 composite samples covered various time intervals this was counterbalanced by including time weighing in the classical equation 4 e j 1 i 1 n m i t i e i t i j i 1 n m i t i m t i j where m i is the measured concentration for composite i e i is the average of simulated concentrations coinciding with composite i m is the time weighted average of all measured concentrations and t i is the time represented by composite i no classification ranges i e good fit bad fit were proposed by ahnert et al 2007 they suggested to apply other numerical methods simultaneously and to present charts for visual interpretation if the value of e j is below zero either the arithmetic mean is a better predictor than the model or the measured values were too low or nearly constant pálfy and langergraber 2014 the interpretation of e j was aided by calculating the mean time weighed deviation 5 d e v i 1 n m i t i e i t i t where e i is the simulated value for composite i t is the duration of the intra event period on which the analysis is done d e v g m3 and d e v helps to decide if e j indicates a poor fit or fails the goodness of fit was considered weak if e j indicated weak results with a value below 0 1 and d e v seemed important 2 3 4 sensitivity analysis model sensitivity was tested using a one factor at a time oat screening technique called the morris method morris 1991 applied with the improvements of campolongo et al 2007 the method yielded two values describing the importance of each scrutinized model parameter one was correlated to the overall influence μ i on the output and the other to the non linearity interactions with other factors σi the analysis was carried out separately on cod removal number of parameters k 16 and on nh 4 n removal k 21 because the model did not allow to take into account interactions between the two pollutants and can be called on one pollutant at a time common parameters were those describing hydraulics and temperature dependence each model parameter xi i 1 k was varied within a pre defined input range at four levels p 4 yielding n 160 simulations for cod and n 220 for nh 4 n input ranges were selected to be realistic for cso cws values for μ i and σi were calculated based on the values of elementary effects ee detailed description of the calculation were given by morris 1991 and campolongo et al 2007 an ee was defined for each input vector x consisting of k parameters one changed at a time for a given x the ee linked to the ith input factor is defined as 6 d i x y x i x i 1 x i δ x i 1 x k y x δ the basis of evaluation is often taken to be the arithmetic mean of model output i e y x emc x for a more detailed outcome about model sensitivity and robustness the analysis was done on all statistics listed in subchapter 2 3 3 as for goodness of fit a single numerical had to be calculated from e j and d e v scores 1 worst were derived based on arbitrarily selected ranges table 2 the final score was based on e j if the score for d e v was the higher e j was increased by one otherwise it was left unchanged the arithmetic mean of six final scores for five events one by filter side was defined as y x the ranges of input parameters are listed in appendix b a wide range was used on filter area a tot 200 m2 2000 m2 to focus the analysis on shortcutting and to see if a tot really has a minor effect on cod removal then the analysis for nh 4 n was repeated with a tighter range which was assumed to be hydrologically optimized 250 650 m2 table 3 lists shortcutting times in the function of filter area 3 results 3 1 first calibration to a single and extreme load the results of the first calibration are summarized in table 4 some parameters had been refined since the experiments of this paper like e g those that are related to processes discussed in pálfy et al 2017c the single run showed a good fit to measured hydraulics fig 6 and outflow concentrations fig 7 water levels and ponding duration were also well predicted regardless the extreme length of the event the existence of a constant outflow rate simplified indeed greatly the hydraulics of the system the changes in cod were followed with a slight shift in time and with flattened amplitude still well fitted ej 0 1 mean time weighted deviation 7 5 g m3 nh 4 n was fitted excellently ej 0 7 mean time weighted deviation 1 2 g m3 the time of predicted breakthrough showed a 2 h delay which did not cause any visible shift on the chart fitting nh 4 n concentrations is crucial for a good design especially after the breakthrough see before 72 h event time on fig 7 3 2 testing accuracy and stability with event series the fit between simulated and experimental effluent concentrations was between fairly good and good with a score of 3 50 for cod and 3 33 for nh 4 n results of statistical analysis are summarized in table 5 model predictions were satisfying for most of the events still a gap of 26 9 or 18 9 g m3 for cod peak ma cc was obtained which should be improved because this variable will be used by the design optimization algorithm fig 8 shows intra event concentrations at events 16 19 the largest error was due to event 16 where effluent concentrations were underestimated by the model the possible reasons for this were that 1 the samples for events 16 and 19 were taken from settled ponding water so concentrations of model input were less than that of the real inflow and 2 the dry period before event 16 was two months long and its possible impact on modelled performances had not been calibrated yet leaving away event 16 would have decreased the gap between the simulated and measured values to 9 5 for nh 4 n the event mean concentration had an average difference of 33 5 mae expressed in concentrations this difference was small 1 4 g m3 over the measured value shortcutting peaks were excessively large at events 17 and 18 a parameter k2 was set deliberately low to make shortcut effects clearly visible k2 shall be fixed equal or just slightly lower to its counterpart used under normal operation in order to have smaller peaks lowering the initial shortcutting peaks would result weaker fit because nh 4 n concentrations were starting from close to zero this can be counterbalanced by increasing the background concentration parameter higher event 14 was excluded from fig 8 because model predictions did not cause visually notable alternation compared to the single load shown on fig 7 the stability of the model was verified through the simulation of alternated intra and inter event periods the regeneration in the inter event periods allowed predicting nh4 n concentrations in the following events with no shift in material balances and due to the discrete values of parameters behind removal processes the model is anticipated to have no limitation regarding the length of input data 3 3 sensitivity analysis 3 3 1 sensitivity analysis of cod removal calculations the sensitivity analysis sa on cod removal confirmed the importance of the performance parameters nu 1 c2 and nu 2 for 6 24 h peak ma cc fig 9 nu 1 and nu 2 set removal efficiency and c2 set in every time step which one to use however the other two performance parameters k and c1 showed influence only at lower inflow concentrations their effect was small because inflow concentrations were too high in our dataset to trigger background values in the effluent results confirmed model robustness as other parameters had little effect on simulations especially on 6 24 h peak ma cc 3 3 2 sensitivity analysis of nh 4 n removal calculations with excessive shortcutting durations wide parameter ranges were causing shortcutting to be the dominant operation in the domain for almost all vectors x of the experiment ranges were tightened therefore in a second experiment to what physical research and design practice could justify as such one of the two analyses targeted performances at shortcutting wide ranges for area and the other the classical operation with little shortcutting tight ranges for area the results at excessive shortcutting durations fig 10 highlighted significant parameters which determine shortcutting duration i e how long it takes until the water level fills up to the shortcutting threshold depth h e in the simulations domain these were 1 h e itself m 2 the base outflow rate f limit base m3 m2 h and 3 the total filter area a tot m2 the higher these numbers were the longer it took to get a water level above h e it can be anticipated that a bad combination of these hit simulated and real world performances badly therefore parameters which describe adsorption capacities in the shortcutting zone showed less importance k1 a1 c1 during long hydraulic shortcutting adsorption sites could get easily saturated in the infiltration zone limited to the inlet area overall the total filter area a tot was the most significant of those parameters which are not going to be fixed for the automatic optimization 3 3 3 sensitivity analysis of nh 4 n removal calculations with normal shortcutting durations the range of the filter area a tot and the flow limitation f limit base were selected to give hydraulically consistent domains fig 11 shows results with such input vectors x f limit base was significant for the goodness of fit index because at some vectors x the remaining shortcutting peaks affected the fit even if the peaks themselves were fleeting adsorption related parameters were otherwise the most significant these were 1 the material specific adsorption capacity a1 m3 kg and 2 the depth of the filter layer d filt m the depth of the filter together with its area a tot determines the total mass kg of the media and with that its total adsorption capacity a1 can be calibrated to measurements and a tot is going to be optimized by the iterative shell of orage it must be noted that d filt was not a target of the optimization algorithms and strong correlation had been absent between treatment performances and filter depth in pilot scale research done by fournel 2012 meanwhile a tot on which the automatic optimization of orage will be based was deemed to be less significant by our sa as such we identified a weakpoint of the model doubling the filter thickness had the same effect on the virtual adsorption capacities as doubling filter area and that is to be addressed in practical optimization applications e g by fixing filter depth 4 discussion the core model of orage was calibrated to a full scale cso cw marcy l etoile treating unsettled water in twin basins manual calibration gave excellent goodness of fit to the single event even though hydraulic and pollutant loads were high then a medium term event series was simulated consisting of five loads the goodness of fit was moderate to good without changing parameters between the events the unloaded inter event periods allowed the simulation domain to return to a stable condition to background levels of water content and nh 4 n in both the liquid and solid phases as such the model remained stable with the alternation of intra and inter event periods this in the light of process simplification discrete parameters defining adsorption capacity cod and tss removal and storage volumes to overflow indicated readiness for long term data several alternations statistical analyses of measured and simulated effluent data also confirmed model accuracy the peak of moving average on effluent concentrations peak ma cc had been included in the model to have a single concentration value as key output and to serve as connection between the core model and the optimization not presented here for nh 4 n simulated peak ma cc fit well that which was calculated from measured effluent error 1 7 g m3 or 12 2 the error was rather large for cod 18 9 g m3 or 26 9 due to one event that arrived after a warm and long inter event and where ponding water was sampled instead of the inlet calibrating the effect of inter event periods on cod removal should increase accuracy the sensitivity analysis has proven model robustness most model parameters show little effect on the output within their realistic range and can safely be fixed other parameters that are significant are either fixed in design guidelines e g percolation speed in the filter media f limit base or will need meticulous calibration nh 4 n adsorption parameters by material cod removal parameters as the function of dry periods and temperature the total filter area a tot is important for the simulated nh 4 n removal not only due to the available adsorption capacities but also due to hydraulic shortcuts that cause performance drop for excessively large filters the analysis highlights that filter depth d filt is important too unlike in reality this might be the weak point of the model because adsorption capacities are correlated with the mass of the filter media in reality the available organic matter plays a role as well and the correlation is less direct fournel 2012 the accuracy of the core model can be improved further modelling a diversity of full scale sites would be beneficial after enough sites are built to do so this is especially true for parameters recorded in internal tables such as those responsible to select the climatic and inter event effects for cod removal and the material database containing the adsorption isotherms 5 conclusions the simple process descriptions of orage are satisfactory for modelling cso cws on one hand we extended successfully the simple hydraulic model for 1 two sided filters and 2 hydraulic shortcutting in oversized filters although a tank in series approach is insufficient to simulate processes that happen only in a part of the filter by the combination with another simple model a simple approach might be kept in our case such coupling is used at very low water levels in the porous media as that focuses infiltration close to the inlet and enables the simulation of performance drops of oversized systems in general such coupling can help to keep the model simple as well as to keep the advantages of simple handling and faster simulation speeds another example for simplification is the discretization of the adsorption isotherm this enabled to calculate the process without solving differential equations this approach could be refined by quantizing the curve or working with multiple stage isotherms to increase precision and simplified models might benefit from it for the same reasons of speed and handling mentioned above from the user s perspective the core model targets practitioners to provide support for design and to serve the automatic optimization of filter area and materials returning a single output which is directly comparable to the legislative thresholds on effluent concentrations serves the core s integration into an automatic algorithm overall the low number of input parameters can keep handling simple without compromising the accuracy of predictions the core is ready to be integrated in an autonomous iterative shell as it had shown accuracy and robustness acknowledgements the authors thank jean marc croumier the flexibility and patience in transferring our ideas into a computer program the wastewater treatment team s engineers and technicians for their effort which supported field measurements nicolas forquet for his advices and the script to generate parameter sets onema and rmc water authorities for their financial support appendix a calculation of flows and pollutant removal in the core model of orage image 1 appendix b parameter ranges of the sensitivity analysis image 2 
