index,text
6380,geometric characteristics and manning s roughness coefficient n are needed in steady and unsteady flow analysis in open channels and rivers various methods are used to estimate n of a river reach while there is always some uncertainty in its estimation one of the methods for estimating n is its calibration using observed inflow and outflow hydrographs in a river reach this calibration procedure is conducted by adjusting n such that the outflow hydrograph calculated by an adopted flow routing model matches the observed outflow hydrograph the available calibration methods usually consider a uniform roughness along the reach of a river in this study a new method for calibration of n is presented that can recognize different regions with different n in a river reach even when only one recorded inflow and corresponding outflow hydrographs are available in the proposed method at first different cases are generated where in each case the river reach is divided into several sub reaches in a systematic procedure then for each case the n of all sub reaches are optimized by using the monte carlo method and random search optimization in the next step the best case among all cases is identified by applying similarity criteria defined in this study finally a clustering method is employed to identify different regions with different n values for the selected best case the method was applied to some synthetic data and also tiber river data and showed promising results keywords manning s roughness coefficient calibration random search optimization similarity concept clustering 1 introduction and background information about the peak depth and discharge especially at the time of critical flood events is needed to design structures and to protect property and life rashid and chaudhry 1995 however uncertainty is an inherent ingredient in the estimation of flood depth or discharge hydrographs because of the uncertainty involved in model structure and parameters used in simulating flood events among other parameters the roughness coefficient is known to be a key parameter for a realistic simulation of open channel flows but remains especially difficult to determine ballesteros et al 2011 for a difference of 50 in the roughness coefficient kidson et al 2002 calculated a discharge error of 40 for a palaeoflood in a bedrock river they concluded that initial uncertainty in the selection of manning s n propagates and amplifies uncertainty in discharge estimates and then in flood frequency estimates boyer 1954 states that the manning s roughness coefficient in open channels plays an important role in the determination of discharge using the usual slope area method li and zhang 2001 refer to the manning s roughness coefficient n as one of the most important parameters for analyzing water flow over the ground and provide a technique for calculation of field n coon 1995 found the differences between n values computed from a study site and those estimated from published n value equations and concluded that no one equation was capable of accurately estimating n values for all stages on all channels hosseini 2000 discussed the key role of n and manning s equation in evaluating the accuracy of energy and momentum principles for the analysis of one dimensional open channel flow in general it can be concluded from different studies that the estimation of n is a hard task because of its dependency on different flow resistance factors cowan 1956 that can vary along a river and are hard to quantify hence uncertainty would be an inherent ingredient in estimating n johnson 1996 studied the uncertainty of various hydraulic parameters including n for the paint branch stream in maryland she concluded that the probability distribution of n was uniform zoppou and li 1993 studied the uncertainty due to the natural variability of n in open channels and its influence on water surface profile calculations using a developed point estimation method to quantify uncertainty propagation considering the uncertainties involved in estimating n calibration techniques can provide a way to estimate or adjust n in a reach of a river if flow data is available and a reliable simulation or flow routing model is adopted one of the commonly used calibration methods is based on using observed inflow and outflow hydrographs in the reach of a channel in this case the reach scale estimation of n is made by optimizing the coefficient to minimize the difference between simulated and observed outflow hydrograph s for the corresponding inflow hydrograph s many studies have been performed to calibrate n by assuming a uniform or constant n value for any reach of a channel having a known or specified length aronica et al 1998 applied the generalized likelihood uncertainty estimation glue procedure to a complex distributed model of a study area which is located in the southern part of sicily and is crossed by the imera river based on little information they used two different techniques to calibrate n based around a statistical model error and fuzzy rule based system they concluded that the likelihood distributions predicted by the two techniques are similar pappenberger et al 2005 presented the uncertainty analysis of the unsteady flow component of the one dimensional model hec ras in two different rivers within the framework of glue taking surface roughness as an uncertain input parameter the results of varying the reach scale roughness showed that many parameter sets could perform equally well even with extreme values the necessity to distinguish between effective parameters and real physical parameters was also emphasized kidson et al 2006 examined the uncertainty in discharge estimation of palaeoflood events particularly associated with manning s n and optimal water surface their case study was the mae chaem river in northern thailand they also assessed the influence of discharge uncertainty on flood frequency analysis to estimate return periods boulomytis et al 2017 estimated n of the main channel and floodplain of juqueriquere river basin using cowan method based on field observations then these data and measured flow data were inserted into the hec ras model for the calibration of the roughness coefficients in a trial and error process they stated that both estimation and calibration methods were efficient having no significant difference ramesh et al 2000 employed the sequential quadratic programming optimization algorithm to calibrate n values in a hypothetical rectangular multiple reach open channel system under unsteady flow condition their results showed that the model did not perform satisfactorily when the number of observation stations was less than the number of parameters to be estimated timbadiya et al 2011 showed that different n were required for upper and lower reaches of the tapi river in india for finding a satisfactory agreement between observed hydrographs and those calculated by hec ras in the present study an innovative method for calibrating n is proposed that is capable of identifying the length and n value of any sub reach along a river reach between two gauging stations briefly the proposed methodology applies a pattern recognition procedure coupled with an optimization procedure and clustering that enhance the capabilities and accuracy of the method to find the length and n value of all sub reaches in a river reach between two gauging stations in other words the method identifies possible distinct regions in a river reach section 2 presents the methodology presented in this study in section 3 the results of applying the methodology to three synthetic data sets and also tiber river field data are reported and discussed section 4 highlights the general conclusions made in this study 2 methodology in this study the framework used to calibrate n is similar to the framework used by many other researchers this framework has three main elements 1 a flood simulation or routing model 2 a set of observed inflow and corresponding outflow hydrographs and 3 a methodology for calibrating or optimizing n to make a good agreement between the simulated and observed outflow hydrographs however as described in section 1 the main difference of the current study with the previous ones is related to item 3 in this section a brief description of the flood simulation or routing model used in this study is provided while the methodology used to calibrate n is described in detail 2 1 flood routing model governing equations and numerical solution in the absence of lateral flow the one dimensional governing equations for analysis of gradually varied unsteady flow in open channels are eqs 1 and 2 which are commonly referred to as the saint venant equations 1 a t q x 0 2 q t β q 2 a x g a y x g a s 0 s f 0 where q is the discharge a is the cross sectional area normal to the flow β is the momentum correction factor g is the acceleration due to gravity y is the flow depth s0 is the bed slope sf is the friction slope t is the time and x refers to the distance from the reference point there is no analytical solution for these equations except for idealized situations and numerical methods are employed to solve these equations different numerical methods are used to solve the saint venant equations the numerical method used in this research is the weighted four point implicit finite difference scheme commonly referred to as the preissman scheme fread 1993 singh 1996 in a discretized domain of time and distance the scheme approximates any function f and its derivatives with respect to time and distance as 3 f θ f i 1 j 1 f i j 1 2 1 θ f i 1 j f i j 2 4 f t f i j 1 f i j f i 1 j 1 f i 1 j 2 δ t 5 f x θ f i 1 j 1 f i j 1 δ x i 1 θ f i 1 j f i j δ x i where i and j refer to distance and time respectively and θ is a weighting factor that varies between 0 and 1 hosseini and joy 2007 in this study the weighting factor was considered 0 55 based on a recommendation made by fread for flood waves fread 1974 initial and boundary conditions are required to solve eqs 1 and 2 the initial conditions are the specified depth and discharge along the river at the start the boundary conditions used in this study were the imposed depth hydrograph upstream and a stage discharge relationship downstream 2 2 methodology for calibrating n fig 1 shows a river reach with an overall length of l l i where li refers to the length of regions i having manning s roughness coefficient ni the existence of regions with different n values can be the characteristic of long natural rivers fig 1 also presents an inflow depth or discharge hydrograph entering the reach and the corresponding outflow hydrograph while previous research focused on calibrating n have ignored the variation of n along the river reach between the two gauging stations 1 and 2 the main objective of the current study was to introduce a method to recognize the pattern shown in fig 1 identify the distinct regions with different length and n along the river reach and determine the length and n of each region the data required in this method is at least one observed inflow and outflow depth or discharge hydrograph as shown in fig 1 the following steps were introduced and followed to achieve the objective of this study although in this study the steps were followed to analyze some illustrative examples described in section 3 they are general and can be applied to any problem under study step 1 main point the river is divided into two equal sub reaches and the best n of each sub reach is determined in the proposed method the river is first divided into two equal sub reaches and for each sub reach a set of random data of n is generated using monte carlo simulation assuming a uniform distribution it is better to consider a wide interval for n distribution based on experience or field observation for all n values of the generated data the outflow hydrograph is developed using the imposed inflow hydrograph as the input to the river reach this can be done using any flood routing model such as the one described in section 2 1 then the best simultaneous n values of all sub reaches are those that minimize the error between calculated and observed outflow hydrographs based on eq 6 6 sse i 1 w h oi h ci 2 where hoi and hci are the ordinates of observed and computed depth or discharge outflow hydrograph respectively w is the total number of data points and sse is the sum of the square of errors step 2 main point the river is divided into three equal sub reaches and the best n of each sub reach is determined the same procedure described in step 1 is followed in step 2 while the number of sub reaches is three in this step step 3 main point the river is divided into four sub reaches and the mean n value of each sub reach is first estimated based on the results of the previous two steps and then optimized fig 2 shows a schematic of view of the different runs used in this study in fig 2 k refers to the run number while c is the number of sub reaches as fig 2 shows step 3 is the key step in step 3 the river is divided into four sub reaches and the mean n value of each sub reach is calculated using eqs 7 10 in these equations the n of each sub reach is related to the corresponding n values obtained at the previous two runs for example as a general equation eq 8 is the equation that is used to estimate n 2 3 the mean n value of sub reach number 2 at run 3 eq 8 indicates that a weighted mean value of n 2 3 is determined where the weighting parameter depends on the length and sse values of the previous two runs that are related to n 2 3 and l 3 7 n 1 3 n 1 1 l 3 1 s s e 1 n 1 2 l 3 1 s s e 2 l 3 1 s s e 1 l 3 1 s s e 2 n 1 1 1 s s e 1 n 1 2 1 s s e 2 1 1 s s e 1 1 1 s s e 2 8 n 2 3 n 1 1 l 3 1 s s e 1 n 1 2 x 1 1 s s e 2 n 2 2 x 2 1 s s e 2 l 3 1 s s e 1 x 1 1 s s e 2 x 2 1 s s e 2 9 n 3 3 n 2 1 l 3 1 s s e 1 n 3 2 x 1 1 s s e 2 n 2 2 x 2 1 s s e 2 l 3 1 s s e 1 x 1 1 s s e 2 x 2 1 s s e 2 10 n 4 3 n 2 1 l 3 1 s s e 1 n 3 2 l 3 1 s s e 2 l 3 1 s s e 1 l 3 1 s s e 2 n 2 1 1 s s e 1 n 3 2 1 s s e 2 1 1 s s e 1 1 1 s s e 2 in the above equations n i 3 is the n of sub reach i at run 3 while ss e 1 and ss e 2 refer to the least sum of the square of errors at runs 1 and 2 respectively the lengths x 1 and x 2 having different n values that have an effect on n 2 3 and n 3 3 can be observed in fig 2 after determining the mean n value of each sub reach different probable n values in each sub reach are generated using monte carlo simulation assuming a uniform distribution where the interval of the distribution is calculated by eq 11 11 1 α i 3 n i 3 n 1 α i 3 n i 3 where α i 3 denotes the interval definition parameter α of the sub reach i at run 3 the choice of α i 3 is very important it must be bigger for the sub reaches that are influenced by more different n values such as sub reaches 2 and 3 in fig 2 eq 12 is used to find α i 3 where α i 3 is determined based on the maximum and minimum values of n that control n i 3 12 α i 3 max n 1 n 2 min n 1 n 2 2 n i 3 where α i 3 is the interval definition parameter of the sub reach i and n 1 and n 2 refer to the n values in runs 1 and 2 that have an effect on the determination of n i 3 based on eq 7 10 it is possible that the value of α i k in some sub reaches tend to zero at the initial runs and consequently n is not accurately identified in these sub reaches therefore in each sub reach a minimum value of α i k was considered to increase the accuracy of the estimated n value this minimum value adds more degrees of freedom in approaching the real n in each sub reach theoretically this minimum value must decrease as the number of sub reaches c or equivalently k 1 increases after testing different case studies general eq 13 was proposed to find α i min k which results in a value of 0 0625 for α i min 3 13 α i min k 0 25 c 0 25 k 1 where c represents the number of river sub reaches and k is run number in conclusion the mean n values of all sub reaches can be found using eqs 7 10 and the corresponding uniform distribution intervals can be specified by eqs 11 13 therefore in each sub reach a set of random n values can be generated using monte carlo simulation by a random combination of the n values in sub reaches as previously discussed in step 1 the outflow hydrographs are calculated by employing the flood routing model and using the imposed inflow hydrograph as the input to the river reach and a specified downstream boundary condition in subcritical flow finally eq 6 can be used to find the best scenario and the corresponding n values of all sub reaches step 4 main point the number of sub reaches is increased and analysis similar to that of step 3 repeated the same procedure described in step 3 was continued in each run by increasing the number of sub reaches after calculating the mean n values of all sub reaches its interval is determined according to the analyses of the two previous runs for each sub reach using eqs 13 15 then a set of random data for each sub reach is generated using monte carlo simulation finally the best set of the simultaneous n values of all sub reaches is identified by multiple runs of the flood routing model and criterion defined by eq 6 14 1 α i k n i k n 1 α i k n i k 15 α i k max n k 2 n k 1 min n k 2 n k 1 2 n i k step 5 main point a calculation stopping condition is proposed the calculation termination condition was defined according to eq 16 16 l k l k 1 δ where δ is the difference between the length of two sub reaches at runs k and k 1 a δ of less than one percent of the length of the river reach is suggested for the pattern recognition as a result as will be discussed in section 3 all calculations were performed in eleven runs in all examples provided in this study step 6 main point the best run from all runs is chosen the best run must be determined after stopping the calculations if at run k the river is divided into c sub reaches the number of river sub reaches is equal to 2c at run 2 k 1 in other words each sub reach at run k is divided into two sub reaches with equal length at run 2 k 1 if the n values of all sub reaches at run 2 k 1 are not significantly different from the corresponding n values at run k it can be accepted that n has been identified well on the other hand another factor that plays a role in the selection of the best run is the sse between the computed and observed outflow hydrographs eq 17 includes the combined effects of the similarity between the n values and sse 17 e i 1 c n 2 i 2 k 1 n i k i 1 c n 2 i 1 2 k 1 n i k l 2 k 1 ss e k s s e 2 k 1 where c is the number of river sub reaches at run k the e value can be calculated for all conjugate runs k and 2 k 1 starting from k 1 the best conjugate runs were suggested to be those with the minimum e value between the two best conjugate runs k and 2 k 1 the one with less sse was considered to be the final answer step 7 main point different regions having different roughness coefficients are identified by applying a clustering algorithm it must be considered that the n values of sub reaches resulting from step 6 can be close to each other in some sub reaches practically the proximity of n values highlights the need for the identification of distinct regions having the same n to recognize the pattern of n it can be accepted that adjacent sub reaches with nearly similar n values can be classified as one region by the use of a clustering algorithm such as the k means method used in this study hartigan and wong 1979 provide details of the k means method the following procedure was suggested and employed to apply the k means method in this study a after the termination of calculations and choosing the best answer as described in step 6 n values at some locations are selected as seeds of the clusters the number of clusters is identified based on the variation of n observed in the best answer each seed contains information about the distance from the beginning of the river reach x and the corresponding n value b each sub reach is assigned to the nearest cluster based on the euclidian distance between the cluster seed and the center of that sub reach the euclidian distance is calculated using normalized n values and log x to normalize n the n value in each sub reach is divided by the maximum n found along the river reach the normalized log x is calculated similarly c the new centroid of each cluster is determined which basically includes the arithmetic mean of the normalized n and log x of the sub reaches positioned in one cluster these centroids are the new seeds d the items b and c described above are repeated until the convergence is achieved and the centroids of all clusters remain unchanged e finally the arithmetic mean of n values of all sub reaches positioned in one cluster is considered as the n value of that cluster or region 3 application of the method to some case studies results and discussion to show the capabilities of the method three examples based on synthetic data and one real world example are presented in this section 3 1 example 1 using synthetic data fig 3 shows the schematic view of a hypothetical river used in this example it is a rectangular river with 10 m width and 3000 m length and a bed slope of 0 0001 the river has three distinct regions having different n values the first and last regions are 500 m long with an n of 0 03 while the middle region is 2 km in length and has an n of 0 02 the initial condition before the arrival of the flood wave is a subcritical flow with a constant discharge of 3 308 m3 s the water surface profile and depths corresponding to the initial discharge shown in fig 4 a were calculated using the conventional standard step method fig 4 b shows the hypothetical inflow hydrograph and the corresponding outflow hydrograph the outflow hydrograph was calculated using the priessman scheme discussed in section 1 assuming a downstream boundary condition of s 0 s f 0 where s 0 and s f are the longitudinal slope of the river and friction slope respectively this boundary condition basically means that a manning equation type stage discharge relationship controls the flow downstream the objective of this example was to use the inflow and outflow hydrographs as available data and as an inverse problem recognize or identify the pattern in manning s roughness distribution shown in fig 3 by using the method and steps introduced in section 2 a uniformly distributed random error in the interval 1 1 cm was added to the ordinates of the outflow hydrograph to apply the steps introduced in section 2 2 the parameters of the method were selected as follows 1 in steps 1 and 2 the n values were randomly sampled from the uniform distribution 0 015 0 05 2 a thousand random n values were generated using monte carlo simulation in all runs 3 a δ value of 25 m was considered for the termination condition as discussed in step 5 of section 2 2 the summary of the results obtained in all 11 runs by applying the proposed methodology can be observed in fig 5 the sum of the square of the errors for all 11 runs is shown in fig 6 fig 7 shows the e values calculated by eq 17 according to fig 7 the minimum e is related to the runs when the river reach is divided into 6 and 12 sub reaches followed by the cases when the river is divided into 5 and 10 sub reaches therefore the cases when the river reach was divided into 6 and 12 sub reaches were selected as the best pattern candidates the selection between these two sub reach numbers was made based on the sse between the ordinates of the outflow hydrographs therefore as fig 6 shows the run 5 results corresponding to 6 sub reaches had the best rank similarly figs 6 and 7 show that the run 4 results corresponding to 5 sub reaches ranked second a review of the n values shown in fig 5 especially those related to the two best cases indicated three distinct regions regions with higher n value in the first and last parts of the river and a region with lower n value in the middle part of the river therefore three seeds were selected for clustering initial seeds for clustering were selected arbitrarily in sub reaches 1 3 and 6 of the river based on the results of run 5 the clustering results are shown in fig 8 fig 8 also shows similar results for run 4 where the initial seeds were selected in sub reaches 1 3 and 5 this example shows that the proposed methodology was able to recognize three distinct regions having different lengths and n values 3 2 example 2 using synthetic data fig 9 shows the schematic view of a hypothetical river used in this example it is a rectangular river with 10 m width and 3000 m length and a bed slope of 0 0001 the river has two distinct regions having different n values the first region is 1000 m long with n of 0 02 while the second region is 2 km in length and has n of 0 03 the initial condition before the arrival of the flood wave is a subcritical flow with a constant discharge of 3 21 m3 s the water surface profile and depths corresponding to the initial discharge shown in fig 10 a were calculated using the conventional standard step method fig 10 b shows the hypothetical inflow hydrograph and the corresponding outflow hydrograph the outflow hydrograph was calculated using the priessman scheme discussed in section 2 1 assuming a downstream boundary condition of s 0 s f 0 where s 0 and s f are the longitudinal slope of the river and friction slope respectively similar to the example 1 the main objective of this example was to use the inflow and outflow hydrographs as available data and as an inverse problem recognize or identify the pattern in manning s roughness distribution shown in fig 9 by using the method and steps introduced in section 2 2 a uniformly distributed random error in the interval 1 1 cm was added to the ordinates of the outflow hydrograph in example 1 the application of the proposed method and the results were presented however in example 2 a sensitivity analysis on some arbitrarily selected numerical parameters was conducted the selected parameters are the support of the uniform distribution considered for n in steps 1 and 2 of the proposed methodology and the initial seeds considered for clustering in step 7 as mentioned an interval for n must be considered for performing the analysis in steps 1 and 2 this interval can be estimated based on experience or field observations it is possible that the real value of n in one sub reach or more is out of the selected interval if this interval is estimated with some errors in this example in the first place the effect of such errors on the pattern recognition results was studied the interval considered for the uniformly distributed n was 0 025 0 04 in steps 1 and 2 as fig 9 shows the n value in region 1 is out of the selected interval additionally for all runs including steps 1 and 2 five hundred random data were generated using monte carlo simulation and in eq 14 a δ of 25 m was considered as the calculation termination condition the summary of the results obtained in this example for all 11 runs of analysis is shown in fig 11 the sum of the square of the errors for all 11 runs of analysis is shown in fig 12 while fig 13 shows the e values calculated by eq 17 the minimum e and sse are related to the cases when the river is divided into 6 and 12 sub reaches which correspond to k 5 and k 11 respectively however the 12 sub reach results are somewhat better fig 11 indicates the presence of two distinct regions at k 11 by selecting the n in the first and last sub reaches as the two initial arbitrary seeds in the clustering procedure the results shown in fig 14 were obtained the pattern in fig 14 reasonably matches with the real pattern shown in fig 9 the reason for such a reasonable pattern recognition regardless of initially out of range selected interval of the n is imposing a minimum value for α based on eq 13 according to fig 11 the results of the analysis performed in the first and second runs indicate a value of 0 025 for the n in the first sub reach of the river which results in α value of zero based on eq 12 in the third run for this sub reach however the imposed minimum α based on eq 13 contributes to the better calibration of n and its convergence to the real n value in the first sub reach in another study the sensitivity of the clustering results to the selection of initial seeds was investigated table 1 presents the clustering results when the two initial seeds were randomly selected in different sub reaches as table 1 shows the clustering results did not show any sensitivity to the initial seeds this is because the clustering procedure introduced in section 2 2 has the capability of approaching the real physical system 3 3 example 3 application of the method to the tiber river data to evaluate the application of the method proposed in this study to the real world problems the field data of the tiber river in central italy for the river reach between the gauged section of pierantonio upstream and ponte felcino downstream was used the overall length of the reach is 15 km with a bed slope of 0 0016 a manning roughness coefficient of 0 049 was proposed for this river reach perumal et al 2007 the cross sections of the tiber river at pierantonio and ponte felcino gauging stations are shown in fig 15 the data related to the floods in december 1996 and november 1997 were used in this study the data of flood in 1996 was used to recognize any possible pattern in the distribution of n if it exists the data of flood in 1997 were used to verify the results the observed inflow and corresponding outflow depth hydrographs related to the two floods are shown in fig 16 the downstream boundary condition was the stage discharge relationship q vs y depicted in fig 17 perumal et al 2007 the interval considered for the uniformly distributed n was 0 04 0 06 in steps 1 and 2 additionally for all runs including steps 1 and 2 two hundred random data were generated using monte carlo simulation the method presented in this research was applied to the data of the 1996 flood fig 18 shows a summary of the results after 11 runs fig 19 shows the sse values of all 11 runs while fig 20 shows the e values for all conjugate runs calculated by eq 17 fig 20 shows the e values calculated by eq 17 although the sse values are not significantly different in different runs the e values change significantly as fig 20 shows by considering e criterion as the main criterion and sse criterion it was concluded that the best result was achieved when the river reach was divided into 4 sub reaches which corresponds to k 3 in fig 18 by looking at the relatively close n values in fig 18 at k 3 and arbitrarily selecting two initial seeds the clustering analysis indicated the following two regions 1 region 1 with a length of 3750 m and n of 0 0485 and 2 region 2 with a length of 11250 m and n of 0 0524 in other words although from a practical point of view a uniform roughness coefficient for the river reach can be accepted the current analysis reveals that the upstream part of the river reach has somewhat lower roughness coefficient than the rest of the river reach fig 21 shows the computed depth y and discharge q hydrographs based on the pattern selected in this study and also independent uniform n 0 049 suggested by perumal et al 2007 versus the corresponding observed hydrographs at the ponte felcino station as fig 21 shows the model with calibrated n values performs reasonably well both in calibration and verification phases this indicates that the river system has not changed significantly in a time scale of about one year although the tiber river n value does not show a significant change over time this cannot be true for all natural river systems the n values in natural river systems can change between different seasons flood events and with channel changes over time given the dependence of n on discharge vegetation and local conditions this issue highlights the fact that the effective n values calibrated for one flood using the hydraulic approach and method presented in this study cannot be applied to another flood with certainty although this issue of non unique n values can be considered as a potential limitation of the hydraulic approach used in this study collection of data under different conditions calibration and uncertainty analysis can shed more light on the extent of the problem for any river under study 3 4 example 4 using synthetic data the river reach used in this example is similar to the river used in examples 1 and 2 with a difference in the distribution of n the river has three distinct regions having different n values the first and last parts are 500 m long with n of 0 02 and 0 03 respectively the middle region is 2 km in length and n linearly varies from 0 02 to 0 03 in this region the initial condition before the arrival of the flood wave is a subcritical flow with a constant discharge of 1 69 m3 s the boundary conditions are the same as those considered in examples 1 and 2 reported in sections 3 1 and 3 2 the water surface profile and depths corresponding to the initial discharge shown in fig 22 a were calculated using the conventional standard step method fig 22 b shows the hypothetical inflow hydrograph and the corresponding outflow hydrograph the outflow hydrograph was calculated using the hydraulic routing model assuming the same boundary conditions as those considered in examples 1 and 2 although the method presented in this research was for the patterns with sharp boundaries the objective of this example was to see how the performance of the proposed method would be in analyzing such a complex river system to apply the steps introduced in section 2 2 the parameters of the method were selected as follows 1 in steps 1 and 2 the n values were randomly sampled from the uniform distribution 0 015 0 04 2 one thousand random n values were generated using monte carlo simulation in all runs in comparison with the previous examples it was required to increase the number of random n values in example 4 to achieve better accuracy better accuracy facilitates the selection of the best case as the following analysis shows 3 a δ value of 25 m was considered for the termination condition as discussed in step 5 of section 2 2 a uniformly distributed random error in the interval 1 1 cm was added to the ordinates of the outflow hydrograph and the same procedure used in examples 1 and 2 was followed in this example to find the results the summary of the results obtained in all 11 runs by applying the proposed methodology can be observed in fig 23 the e and sse diagrams are not shown here for the sake of brevity the e diagram showed that the best pattern was related to the conjugate run 5 11 with an e value of 0 129 however the sse values for runs 5 and 11 were 0 0247 and 0 0242 m2 respectively therefore the 12 sub reach case corresponding to k 11 results were slightly better and selected as the best case for further analysis fig 24 demonstrates the distribution of n captured by the proposed method against the n of the real system as fig 24 indicates there is a good match between the discretized distribution of n and the linear trend in variation of the real system n the distribution of n can be used by any practicing engineer involved in modeling flow system in this river although fig 24 indicates that the clustering analysis was not required in this case three initial arbitrary seeds of 0 0199 0 0236 and 0 03 based on fig 24 were selected and clustering analysis was also performed to further investigate the performance of the method the clustering analysis indicated an equivalent system consisting of three distinct regions the first 750 m of the river with n of 0 0196 the second or middle region with a length of 1000 m and n of 0 0241 and the remaining 1250 m with n of 0 0292 the results were not surprising because it was expected that the method would result in equivalent or effective roughness coefficients that approximate the roughness coefficient in the region with linearly varying n to evaluate the performance of the hydraulic model under equivalent roughness coefficients the roughness coefficient was also calibrated using conventional methods assuming a uniform roughness along the river a single n value of 0 0203 was found in this case although a higher value for the single n was expected the interaction of many factors including roughness distribution initial and boundary conditions may justify the constant n calibrated for such a non linear flow system the sensitivity analysis indicated that in this case the outflow depth hydrograph was more controlled by the roughness coefficient in the upstream region of the river than those in the middle and last regions fig 25 shows the performance of the hydraulic routing model under different inflow hydrographs as discussed only the inflow and corresponding outflow hydrographs shown in the middle were used in the calibration phase while the other two inflow hydrographs were used to evaluate the performance of the calibrated hydraulic model under significantly different flow conditions table 2 quantifies the difference between the performance of the two equivalent hydraulic systems using three standard error measures sse the absolute value of the relative error in peak depth arepd and the absolute value of the relative error in peak depth time arepdt in each case the absolute value of the relative error was calculated by dividing the absolute value of the difference between the predicted and corresponding real value by the real value reported in percentage as fig 25 and table 2 show the hydraulic model calibrated with equivalent roughness coefficients performs better than the model calibrated with the single n value the results of the four examples presented above indicate that if there is no information regarding the number of distinct regions the number of initial seeds can be selected based on the model outputs for instance in example 1 the results indicated that n first decreased and then increased along the river reach as a result three initial seeds were selected another advantage of the proposed method is that it can appropriately recognize distinct regions even if the interval of n for starting the analysis is not known properly meanwhile depending on the field condition as long as a proper hydraulic routing model that can model any flow condition e g subcritical and supercritical flow and handle any channel geometry is employed the developed method can be used to estimate the n values within the framework proposed in this study although the method proposed in this study was developed to recognize patterns in n in river reaches having different regions with constant n values separated by sharp boundaries as discussed in example 4 the method can result in reasonable equivalent roughness coefficients along a river reach when there is a linear trend in variation of n it can be stated that based on the examples discussed in this article a few limitations can be considered for the hydraulic approach and methodology presented in this research for calibration of n in rivers uncertainty in estimated n values in natural rivers discussed in the tiber river case and piecewise estimation of n values in the presence of a trend in variation of n discussed in example 4 can be given as examples also like any other numerical method the numerical parameters of the proposed method must be selected properly to preserve both accuracy and computational efficiency another limitation of the proposed methodology is that a uniform or constant n value in a river cross section is assumed in other words the proposed method cannot handle compound channels where the roughness of the floodplains is different from that of the main channel this issue is currently under study 4 conclusions optimization based conventional methods used for calibration of n in a river usually assume a uniform manning s roughness coefficient along a river reach between two gauged stations the application of the conventional calibration methods would be computationally hard and time consuming if different regions of a river reach have different n values separated by sharp boundaries in these situations the conventional methods may require a predefined length for each region to be able to calibrate the n values in different regions such information may not be available or be subject to high uncertainty in most situations in this study a new method was proposed that can identify different regions with different roughness coefficients along the long river reaches just based on at least one inflow and corresponding outflow hydrograph the method has the following three main components 1 dividing the river reach into a different number of sub reaches in a systematic manner and in any sub reach arrangement or case calibrating n in each sub reach by applying a random search optimization using the monte carlo simulation 2 finding the best case among different cases considering the similarity between different cases and applying the similarity criteria defined in this study and 3 using clustering methods to recognize different regions with different n results from applying the proposed method to two test examples developed by synthetic data and tiber river data indicated that the method could recognize different regions with different n along the river reach when only one recorded inflow and corresponding outflow hydrograph were available the method is particularly useful in long river reaches when the number of gauging stations are limited the main advantage of using the proposed method in comparison with the conventional methods is that information about the variation of n in a river system is generated with the same amount of data this information not only improves the prediction accuracy of the flood routing models but also can be useful in river restoration dredging and management projects by spotting regions with high roughness also information about the variation of n along a river may reduce the cost of river engineering projects by reducing the amount of field work declaration of competing interest none acknowledgment the authors are thankful to the department of environment planning and infrastructure umbria region and irpi perugia italy for providing the tiber river data used in this study the authors would also like to thank the anonymous reviewers for their detailed and valuable comments and suggestions 
6380,geometric characteristics and manning s roughness coefficient n are needed in steady and unsteady flow analysis in open channels and rivers various methods are used to estimate n of a river reach while there is always some uncertainty in its estimation one of the methods for estimating n is its calibration using observed inflow and outflow hydrographs in a river reach this calibration procedure is conducted by adjusting n such that the outflow hydrograph calculated by an adopted flow routing model matches the observed outflow hydrograph the available calibration methods usually consider a uniform roughness along the reach of a river in this study a new method for calibration of n is presented that can recognize different regions with different n in a river reach even when only one recorded inflow and corresponding outflow hydrographs are available in the proposed method at first different cases are generated where in each case the river reach is divided into several sub reaches in a systematic procedure then for each case the n of all sub reaches are optimized by using the monte carlo method and random search optimization in the next step the best case among all cases is identified by applying similarity criteria defined in this study finally a clustering method is employed to identify different regions with different n values for the selected best case the method was applied to some synthetic data and also tiber river data and showed promising results keywords manning s roughness coefficient calibration random search optimization similarity concept clustering 1 introduction and background information about the peak depth and discharge especially at the time of critical flood events is needed to design structures and to protect property and life rashid and chaudhry 1995 however uncertainty is an inherent ingredient in the estimation of flood depth or discharge hydrographs because of the uncertainty involved in model structure and parameters used in simulating flood events among other parameters the roughness coefficient is known to be a key parameter for a realistic simulation of open channel flows but remains especially difficult to determine ballesteros et al 2011 for a difference of 50 in the roughness coefficient kidson et al 2002 calculated a discharge error of 40 for a palaeoflood in a bedrock river they concluded that initial uncertainty in the selection of manning s n propagates and amplifies uncertainty in discharge estimates and then in flood frequency estimates boyer 1954 states that the manning s roughness coefficient in open channels plays an important role in the determination of discharge using the usual slope area method li and zhang 2001 refer to the manning s roughness coefficient n as one of the most important parameters for analyzing water flow over the ground and provide a technique for calculation of field n coon 1995 found the differences between n values computed from a study site and those estimated from published n value equations and concluded that no one equation was capable of accurately estimating n values for all stages on all channels hosseini 2000 discussed the key role of n and manning s equation in evaluating the accuracy of energy and momentum principles for the analysis of one dimensional open channel flow in general it can be concluded from different studies that the estimation of n is a hard task because of its dependency on different flow resistance factors cowan 1956 that can vary along a river and are hard to quantify hence uncertainty would be an inherent ingredient in estimating n johnson 1996 studied the uncertainty of various hydraulic parameters including n for the paint branch stream in maryland she concluded that the probability distribution of n was uniform zoppou and li 1993 studied the uncertainty due to the natural variability of n in open channels and its influence on water surface profile calculations using a developed point estimation method to quantify uncertainty propagation considering the uncertainties involved in estimating n calibration techniques can provide a way to estimate or adjust n in a reach of a river if flow data is available and a reliable simulation or flow routing model is adopted one of the commonly used calibration methods is based on using observed inflow and outflow hydrographs in the reach of a channel in this case the reach scale estimation of n is made by optimizing the coefficient to minimize the difference between simulated and observed outflow hydrograph s for the corresponding inflow hydrograph s many studies have been performed to calibrate n by assuming a uniform or constant n value for any reach of a channel having a known or specified length aronica et al 1998 applied the generalized likelihood uncertainty estimation glue procedure to a complex distributed model of a study area which is located in the southern part of sicily and is crossed by the imera river based on little information they used two different techniques to calibrate n based around a statistical model error and fuzzy rule based system they concluded that the likelihood distributions predicted by the two techniques are similar pappenberger et al 2005 presented the uncertainty analysis of the unsteady flow component of the one dimensional model hec ras in two different rivers within the framework of glue taking surface roughness as an uncertain input parameter the results of varying the reach scale roughness showed that many parameter sets could perform equally well even with extreme values the necessity to distinguish between effective parameters and real physical parameters was also emphasized kidson et al 2006 examined the uncertainty in discharge estimation of palaeoflood events particularly associated with manning s n and optimal water surface their case study was the mae chaem river in northern thailand they also assessed the influence of discharge uncertainty on flood frequency analysis to estimate return periods boulomytis et al 2017 estimated n of the main channel and floodplain of juqueriquere river basin using cowan method based on field observations then these data and measured flow data were inserted into the hec ras model for the calibration of the roughness coefficients in a trial and error process they stated that both estimation and calibration methods were efficient having no significant difference ramesh et al 2000 employed the sequential quadratic programming optimization algorithm to calibrate n values in a hypothetical rectangular multiple reach open channel system under unsteady flow condition their results showed that the model did not perform satisfactorily when the number of observation stations was less than the number of parameters to be estimated timbadiya et al 2011 showed that different n were required for upper and lower reaches of the tapi river in india for finding a satisfactory agreement between observed hydrographs and those calculated by hec ras in the present study an innovative method for calibrating n is proposed that is capable of identifying the length and n value of any sub reach along a river reach between two gauging stations briefly the proposed methodology applies a pattern recognition procedure coupled with an optimization procedure and clustering that enhance the capabilities and accuracy of the method to find the length and n value of all sub reaches in a river reach between two gauging stations in other words the method identifies possible distinct regions in a river reach section 2 presents the methodology presented in this study in section 3 the results of applying the methodology to three synthetic data sets and also tiber river field data are reported and discussed section 4 highlights the general conclusions made in this study 2 methodology in this study the framework used to calibrate n is similar to the framework used by many other researchers this framework has three main elements 1 a flood simulation or routing model 2 a set of observed inflow and corresponding outflow hydrographs and 3 a methodology for calibrating or optimizing n to make a good agreement between the simulated and observed outflow hydrographs however as described in section 1 the main difference of the current study with the previous ones is related to item 3 in this section a brief description of the flood simulation or routing model used in this study is provided while the methodology used to calibrate n is described in detail 2 1 flood routing model governing equations and numerical solution in the absence of lateral flow the one dimensional governing equations for analysis of gradually varied unsteady flow in open channels are eqs 1 and 2 which are commonly referred to as the saint venant equations 1 a t q x 0 2 q t β q 2 a x g a y x g a s 0 s f 0 where q is the discharge a is the cross sectional area normal to the flow β is the momentum correction factor g is the acceleration due to gravity y is the flow depth s0 is the bed slope sf is the friction slope t is the time and x refers to the distance from the reference point there is no analytical solution for these equations except for idealized situations and numerical methods are employed to solve these equations different numerical methods are used to solve the saint venant equations the numerical method used in this research is the weighted four point implicit finite difference scheme commonly referred to as the preissman scheme fread 1993 singh 1996 in a discretized domain of time and distance the scheme approximates any function f and its derivatives with respect to time and distance as 3 f θ f i 1 j 1 f i j 1 2 1 θ f i 1 j f i j 2 4 f t f i j 1 f i j f i 1 j 1 f i 1 j 2 δ t 5 f x θ f i 1 j 1 f i j 1 δ x i 1 θ f i 1 j f i j δ x i where i and j refer to distance and time respectively and θ is a weighting factor that varies between 0 and 1 hosseini and joy 2007 in this study the weighting factor was considered 0 55 based on a recommendation made by fread for flood waves fread 1974 initial and boundary conditions are required to solve eqs 1 and 2 the initial conditions are the specified depth and discharge along the river at the start the boundary conditions used in this study were the imposed depth hydrograph upstream and a stage discharge relationship downstream 2 2 methodology for calibrating n fig 1 shows a river reach with an overall length of l l i where li refers to the length of regions i having manning s roughness coefficient ni the existence of regions with different n values can be the characteristic of long natural rivers fig 1 also presents an inflow depth or discharge hydrograph entering the reach and the corresponding outflow hydrograph while previous research focused on calibrating n have ignored the variation of n along the river reach between the two gauging stations 1 and 2 the main objective of the current study was to introduce a method to recognize the pattern shown in fig 1 identify the distinct regions with different length and n along the river reach and determine the length and n of each region the data required in this method is at least one observed inflow and outflow depth or discharge hydrograph as shown in fig 1 the following steps were introduced and followed to achieve the objective of this study although in this study the steps were followed to analyze some illustrative examples described in section 3 they are general and can be applied to any problem under study step 1 main point the river is divided into two equal sub reaches and the best n of each sub reach is determined in the proposed method the river is first divided into two equal sub reaches and for each sub reach a set of random data of n is generated using monte carlo simulation assuming a uniform distribution it is better to consider a wide interval for n distribution based on experience or field observation for all n values of the generated data the outflow hydrograph is developed using the imposed inflow hydrograph as the input to the river reach this can be done using any flood routing model such as the one described in section 2 1 then the best simultaneous n values of all sub reaches are those that minimize the error between calculated and observed outflow hydrographs based on eq 6 6 sse i 1 w h oi h ci 2 where hoi and hci are the ordinates of observed and computed depth or discharge outflow hydrograph respectively w is the total number of data points and sse is the sum of the square of errors step 2 main point the river is divided into three equal sub reaches and the best n of each sub reach is determined the same procedure described in step 1 is followed in step 2 while the number of sub reaches is three in this step step 3 main point the river is divided into four sub reaches and the mean n value of each sub reach is first estimated based on the results of the previous two steps and then optimized fig 2 shows a schematic of view of the different runs used in this study in fig 2 k refers to the run number while c is the number of sub reaches as fig 2 shows step 3 is the key step in step 3 the river is divided into four sub reaches and the mean n value of each sub reach is calculated using eqs 7 10 in these equations the n of each sub reach is related to the corresponding n values obtained at the previous two runs for example as a general equation eq 8 is the equation that is used to estimate n 2 3 the mean n value of sub reach number 2 at run 3 eq 8 indicates that a weighted mean value of n 2 3 is determined where the weighting parameter depends on the length and sse values of the previous two runs that are related to n 2 3 and l 3 7 n 1 3 n 1 1 l 3 1 s s e 1 n 1 2 l 3 1 s s e 2 l 3 1 s s e 1 l 3 1 s s e 2 n 1 1 1 s s e 1 n 1 2 1 s s e 2 1 1 s s e 1 1 1 s s e 2 8 n 2 3 n 1 1 l 3 1 s s e 1 n 1 2 x 1 1 s s e 2 n 2 2 x 2 1 s s e 2 l 3 1 s s e 1 x 1 1 s s e 2 x 2 1 s s e 2 9 n 3 3 n 2 1 l 3 1 s s e 1 n 3 2 x 1 1 s s e 2 n 2 2 x 2 1 s s e 2 l 3 1 s s e 1 x 1 1 s s e 2 x 2 1 s s e 2 10 n 4 3 n 2 1 l 3 1 s s e 1 n 3 2 l 3 1 s s e 2 l 3 1 s s e 1 l 3 1 s s e 2 n 2 1 1 s s e 1 n 3 2 1 s s e 2 1 1 s s e 1 1 1 s s e 2 in the above equations n i 3 is the n of sub reach i at run 3 while ss e 1 and ss e 2 refer to the least sum of the square of errors at runs 1 and 2 respectively the lengths x 1 and x 2 having different n values that have an effect on n 2 3 and n 3 3 can be observed in fig 2 after determining the mean n value of each sub reach different probable n values in each sub reach are generated using monte carlo simulation assuming a uniform distribution where the interval of the distribution is calculated by eq 11 11 1 α i 3 n i 3 n 1 α i 3 n i 3 where α i 3 denotes the interval definition parameter α of the sub reach i at run 3 the choice of α i 3 is very important it must be bigger for the sub reaches that are influenced by more different n values such as sub reaches 2 and 3 in fig 2 eq 12 is used to find α i 3 where α i 3 is determined based on the maximum and minimum values of n that control n i 3 12 α i 3 max n 1 n 2 min n 1 n 2 2 n i 3 where α i 3 is the interval definition parameter of the sub reach i and n 1 and n 2 refer to the n values in runs 1 and 2 that have an effect on the determination of n i 3 based on eq 7 10 it is possible that the value of α i k in some sub reaches tend to zero at the initial runs and consequently n is not accurately identified in these sub reaches therefore in each sub reach a minimum value of α i k was considered to increase the accuracy of the estimated n value this minimum value adds more degrees of freedom in approaching the real n in each sub reach theoretically this minimum value must decrease as the number of sub reaches c or equivalently k 1 increases after testing different case studies general eq 13 was proposed to find α i min k which results in a value of 0 0625 for α i min 3 13 α i min k 0 25 c 0 25 k 1 where c represents the number of river sub reaches and k is run number in conclusion the mean n values of all sub reaches can be found using eqs 7 10 and the corresponding uniform distribution intervals can be specified by eqs 11 13 therefore in each sub reach a set of random n values can be generated using monte carlo simulation by a random combination of the n values in sub reaches as previously discussed in step 1 the outflow hydrographs are calculated by employing the flood routing model and using the imposed inflow hydrograph as the input to the river reach and a specified downstream boundary condition in subcritical flow finally eq 6 can be used to find the best scenario and the corresponding n values of all sub reaches step 4 main point the number of sub reaches is increased and analysis similar to that of step 3 repeated the same procedure described in step 3 was continued in each run by increasing the number of sub reaches after calculating the mean n values of all sub reaches its interval is determined according to the analyses of the two previous runs for each sub reach using eqs 13 15 then a set of random data for each sub reach is generated using monte carlo simulation finally the best set of the simultaneous n values of all sub reaches is identified by multiple runs of the flood routing model and criterion defined by eq 6 14 1 α i k n i k n 1 α i k n i k 15 α i k max n k 2 n k 1 min n k 2 n k 1 2 n i k step 5 main point a calculation stopping condition is proposed the calculation termination condition was defined according to eq 16 16 l k l k 1 δ where δ is the difference between the length of two sub reaches at runs k and k 1 a δ of less than one percent of the length of the river reach is suggested for the pattern recognition as a result as will be discussed in section 3 all calculations were performed in eleven runs in all examples provided in this study step 6 main point the best run from all runs is chosen the best run must be determined after stopping the calculations if at run k the river is divided into c sub reaches the number of river sub reaches is equal to 2c at run 2 k 1 in other words each sub reach at run k is divided into two sub reaches with equal length at run 2 k 1 if the n values of all sub reaches at run 2 k 1 are not significantly different from the corresponding n values at run k it can be accepted that n has been identified well on the other hand another factor that plays a role in the selection of the best run is the sse between the computed and observed outflow hydrographs eq 17 includes the combined effects of the similarity between the n values and sse 17 e i 1 c n 2 i 2 k 1 n i k i 1 c n 2 i 1 2 k 1 n i k l 2 k 1 ss e k s s e 2 k 1 where c is the number of river sub reaches at run k the e value can be calculated for all conjugate runs k and 2 k 1 starting from k 1 the best conjugate runs were suggested to be those with the minimum e value between the two best conjugate runs k and 2 k 1 the one with less sse was considered to be the final answer step 7 main point different regions having different roughness coefficients are identified by applying a clustering algorithm it must be considered that the n values of sub reaches resulting from step 6 can be close to each other in some sub reaches practically the proximity of n values highlights the need for the identification of distinct regions having the same n to recognize the pattern of n it can be accepted that adjacent sub reaches with nearly similar n values can be classified as one region by the use of a clustering algorithm such as the k means method used in this study hartigan and wong 1979 provide details of the k means method the following procedure was suggested and employed to apply the k means method in this study a after the termination of calculations and choosing the best answer as described in step 6 n values at some locations are selected as seeds of the clusters the number of clusters is identified based on the variation of n observed in the best answer each seed contains information about the distance from the beginning of the river reach x and the corresponding n value b each sub reach is assigned to the nearest cluster based on the euclidian distance between the cluster seed and the center of that sub reach the euclidian distance is calculated using normalized n values and log x to normalize n the n value in each sub reach is divided by the maximum n found along the river reach the normalized log x is calculated similarly c the new centroid of each cluster is determined which basically includes the arithmetic mean of the normalized n and log x of the sub reaches positioned in one cluster these centroids are the new seeds d the items b and c described above are repeated until the convergence is achieved and the centroids of all clusters remain unchanged e finally the arithmetic mean of n values of all sub reaches positioned in one cluster is considered as the n value of that cluster or region 3 application of the method to some case studies results and discussion to show the capabilities of the method three examples based on synthetic data and one real world example are presented in this section 3 1 example 1 using synthetic data fig 3 shows the schematic view of a hypothetical river used in this example it is a rectangular river with 10 m width and 3000 m length and a bed slope of 0 0001 the river has three distinct regions having different n values the first and last regions are 500 m long with an n of 0 03 while the middle region is 2 km in length and has an n of 0 02 the initial condition before the arrival of the flood wave is a subcritical flow with a constant discharge of 3 308 m3 s the water surface profile and depths corresponding to the initial discharge shown in fig 4 a were calculated using the conventional standard step method fig 4 b shows the hypothetical inflow hydrograph and the corresponding outflow hydrograph the outflow hydrograph was calculated using the priessman scheme discussed in section 1 assuming a downstream boundary condition of s 0 s f 0 where s 0 and s f are the longitudinal slope of the river and friction slope respectively this boundary condition basically means that a manning equation type stage discharge relationship controls the flow downstream the objective of this example was to use the inflow and outflow hydrographs as available data and as an inverse problem recognize or identify the pattern in manning s roughness distribution shown in fig 3 by using the method and steps introduced in section 2 a uniformly distributed random error in the interval 1 1 cm was added to the ordinates of the outflow hydrograph to apply the steps introduced in section 2 2 the parameters of the method were selected as follows 1 in steps 1 and 2 the n values were randomly sampled from the uniform distribution 0 015 0 05 2 a thousand random n values were generated using monte carlo simulation in all runs 3 a δ value of 25 m was considered for the termination condition as discussed in step 5 of section 2 2 the summary of the results obtained in all 11 runs by applying the proposed methodology can be observed in fig 5 the sum of the square of the errors for all 11 runs is shown in fig 6 fig 7 shows the e values calculated by eq 17 according to fig 7 the minimum e is related to the runs when the river reach is divided into 6 and 12 sub reaches followed by the cases when the river is divided into 5 and 10 sub reaches therefore the cases when the river reach was divided into 6 and 12 sub reaches were selected as the best pattern candidates the selection between these two sub reach numbers was made based on the sse between the ordinates of the outflow hydrographs therefore as fig 6 shows the run 5 results corresponding to 6 sub reaches had the best rank similarly figs 6 and 7 show that the run 4 results corresponding to 5 sub reaches ranked second a review of the n values shown in fig 5 especially those related to the two best cases indicated three distinct regions regions with higher n value in the first and last parts of the river and a region with lower n value in the middle part of the river therefore three seeds were selected for clustering initial seeds for clustering were selected arbitrarily in sub reaches 1 3 and 6 of the river based on the results of run 5 the clustering results are shown in fig 8 fig 8 also shows similar results for run 4 where the initial seeds were selected in sub reaches 1 3 and 5 this example shows that the proposed methodology was able to recognize three distinct regions having different lengths and n values 3 2 example 2 using synthetic data fig 9 shows the schematic view of a hypothetical river used in this example it is a rectangular river with 10 m width and 3000 m length and a bed slope of 0 0001 the river has two distinct regions having different n values the first region is 1000 m long with n of 0 02 while the second region is 2 km in length and has n of 0 03 the initial condition before the arrival of the flood wave is a subcritical flow with a constant discharge of 3 21 m3 s the water surface profile and depths corresponding to the initial discharge shown in fig 10 a were calculated using the conventional standard step method fig 10 b shows the hypothetical inflow hydrograph and the corresponding outflow hydrograph the outflow hydrograph was calculated using the priessman scheme discussed in section 2 1 assuming a downstream boundary condition of s 0 s f 0 where s 0 and s f are the longitudinal slope of the river and friction slope respectively similar to the example 1 the main objective of this example was to use the inflow and outflow hydrographs as available data and as an inverse problem recognize or identify the pattern in manning s roughness distribution shown in fig 9 by using the method and steps introduced in section 2 2 a uniformly distributed random error in the interval 1 1 cm was added to the ordinates of the outflow hydrograph in example 1 the application of the proposed method and the results were presented however in example 2 a sensitivity analysis on some arbitrarily selected numerical parameters was conducted the selected parameters are the support of the uniform distribution considered for n in steps 1 and 2 of the proposed methodology and the initial seeds considered for clustering in step 7 as mentioned an interval for n must be considered for performing the analysis in steps 1 and 2 this interval can be estimated based on experience or field observations it is possible that the real value of n in one sub reach or more is out of the selected interval if this interval is estimated with some errors in this example in the first place the effect of such errors on the pattern recognition results was studied the interval considered for the uniformly distributed n was 0 025 0 04 in steps 1 and 2 as fig 9 shows the n value in region 1 is out of the selected interval additionally for all runs including steps 1 and 2 five hundred random data were generated using monte carlo simulation and in eq 14 a δ of 25 m was considered as the calculation termination condition the summary of the results obtained in this example for all 11 runs of analysis is shown in fig 11 the sum of the square of the errors for all 11 runs of analysis is shown in fig 12 while fig 13 shows the e values calculated by eq 17 the minimum e and sse are related to the cases when the river is divided into 6 and 12 sub reaches which correspond to k 5 and k 11 respectively however the 12 sub reach results are somewhat better fig 11 indicates the presence of two distinct regions at k 11 by selecting the n in the first and last sub reaches as the two initial arbitrary seeds in the clustering procedure the results shown in fig 14 were obtained the pattern in fig 14 reasonably matches with the real pattern shown in fig 9 the reason for such a reasonable pattern recognition regardless of initially out of range selected interval of the n is imposing a minimum value for α based on eq 13 according to fig 11 the results of the analysis performed in the first and second runs indicate a value of 0 025 for the n in the first sub reach of the river which results in α value of zero based on eq 12 in the third run for this sub reach however the imposed minimum α based on eq 13 contributes to the better calibration of n and its convergence to the real n value in the first sub reach in another study the sensitivity of the clustering results to the selection of initial seeds was investigated table 1 presents the clustering results when the two initial seeds were randomly selected in different sub reaches as table 1 shows the clustering results did not show any sensitivity to the initial seeds this is because the clustering procedure introduced in section 2 2 has the capability of approaching the real physical system 3 3 example 3 application of the method to the tiber river data to evaluate the application of the method proposed in this study to the real world problems the field data of the tiber river in central italy for the river reach between the gauged section of pierantonio upstream and ponte felcino downstream was used the overall length of the reach is 15 km with a bed slope of 0 0016 a manning roughness coefficient of 0 049 was proposed for this river reach perumal et al 2007 the cross sections of the tiber river at pierantonio and ponte felcino gauging stations are shown in fig 15 the data related to the floods in december 1996 and november 1997 were used in this study the data of flood in 1996 was used to recognize any possible pattern in the distribution of n if it exists the data of flood in 1997 were used to verify the results the observed inflow and corresponding outflow depth hydrographs related to the two floods are shown in fig 16 the downstream boundary condition was the stage discharge relationship q vs y depicted in fig 17 perumal et al 2007 the interval considered for the uniformly distributed n was 0 04 0 06 in steps 1 and 2 additionally for all runs including steps 1 and 2 two hundred random data were generated using monte carlo simulation the method presented in this research was applied to the data of the 1996 flood fig 18 shows a summary of the results after 11 runs fig 19 shows the sse values of all 11 runs while fig 20 shows the e values for all conjugate runs calculated by eq 17 fig 20 shows the e values calculated by eq 17 although the sse values are not significantly different in different runs the e values change significantly as fig 20 shows by considering e criterion as the main criterion and sse criterion it was concluded that the best result was achieved when the river reach was divided into 4 sub reaches which corresponds to k 3 in fig 18 by looking at the relatively close n values in fig 18 at k 3 and arbitrarily selecting two initial seeds the clustering analysis indicated the following two regions 1 region 1 with a length of 3750 m and n of 0 0485 and 2 region 2 with a length of 11250 m and n of 0 0524 in other words although from a practical point of view a uniform roughness coefficient for the river reach can be accepted the current analysis reveals that the upstream part of the river reach has somewhat lower roughness coefficient than the rest of the river reach fig 21 shows the computed depth y and discharge q hydrographs based on the pattern selected in this study and also independent uniform n 0 049 suggested by perumal et al 2007 versus the corresponding observed hydrographs at the ponte felcino station as fig 21 shows the model with calibrated n values performs reasonably well both in calibration and verification phases this indicates that the river system has not changed significantly in a time scale of about one year although the tiber river n value does not show a significant change over time this cannot be true for all natural river systems the n values in natural river systems can change between different seasons flood events and with channel changes over time given the dependence of n on discharge vegetation and local conditions this issue highlights the fact that the effective n values calibrated for one flood using the hydraulic approach and method presented in this study cannot be applied to another flood with certainty although this issue of non unique n values can be considered as a potential limitation of the hydraulic approach used in this study collection of data under different conditions calibration and uncertainty analysis can shed more light on the extent of the problem for any river under study 3 4 example 4 using synthetic data the river reach used in this example is similar to the river used in examples 1 and 2 with a difference in the distribution of n the river has three distinct regions having different n values the first and last parts are 500 m long with n of 0 02 and 0 03 respectively the middle region is 2 km in length and n linearly varies from 0 02 to 0 03 in this region the initial condition before the arrival of the flood wave is a subcritical flow with a constant discharge of 1 69 m3 s the boundary conditions are the same as those considered in examples 1 and 2 reported in sections 3 1 and 3 2 the water surface profile and depths corresponding to the initial discharge shown in fig 22 a were calculated using the conventional standard step method fig 22 b shows the hypothetical inflow hydrograph and the corresponding outflow hydrograph the outflow hydrograph was calculated using the hydraulic routing model assuming the same boundary conditions as those considered in examples 1 and 2 although the method presented in this research was for the patterns with sharp boundaries the objective of this example was to see how the performance of the proposed method would be in analyzing such a complex river system to apply the steps introduced in section 2 2 the parameters of the method were selected as follows 1 in steps 1 and 2 the n values were randomly sampled from the uniform distribution 0 015 0 04 2 one thousand random n values were generated using monte carlo simulation in all runs in comparison with the previous examples it was required to increase the number of random n values in example 4 to achieve better accuracy better accuracy facilitates the selection of the best case as the following analysis shows 3 a δ value of 25 m was considered for the termination condition as discussed in step 5 of section 2 2 a uniformly distributed random error in the interval 1 1 cm was added to the ordinates of the outflow hydrograph and the same procedure used in examples 1 and 2 was followed in this example to find the results the summary of the results obtained in all 11 runs by applying the proposed methodology can be observed in fig 23 the e and sse diagrams are not shown here for the sake of brevity the e diagram showed that the best pattern was related to the conjugate run 5 11 with an e value of 0 129 however the sse values for runs 5 and 11 were 0 0247 and 0 0242 m2 respectively therefore the 12 sub reach case corresponding to k 11 results were slightly better and selected as the best case for further analysis fig 24 demonstrates the distribution of n captured by the proposed method against the n of the real system as fig 24 indicates there is a good match between the discretized distribution of n and the linear trend in variation of the real system n the distribution of n can be used by any practicing engineer involved in modeling flow system in this river although fig 24 indicates that the clustering analysis was not required in this case three initial arbitrary seeds of 0 0199 0 0236 and 0 03 based on fig 24 were selected and clustering analysis was also performed to further investigate the performance of the method the clustering analysis indicated an equivalent system consisting of three distinct regions the first 750 m of the river with n of 0 0196 the second or middle region with a length of 1000 m and n of 0 0241 and the remaining 1250 m with n of 0 0292 the results were not surprising because it was expected that the method would result in equivalent or effective roughness coefficients that approximate the roughness coefficient in the region with linearly varying n to evaluate the performance of the hydraulic model under equivalent roughness coefficients the roughness coefficient was also calibrated using conventional methods assuming a uniform roughness along the river a single n value of 0 0203 was found in this case although a higher value for the single n was expected the interaction of many factors including roughness distribution initial and boundary conditions may justify the constant n calibrated for such a non linear flow system the sensitivity analysis indicated that in this case the outflow depth hydrograph was more controlled by the roughness coefficient in the upstream region of the river than those in the middle and last regions fig 25 shows the performance of the hydraulic routing model under different inflow hydrographs as discussed only the inflow and corresponding outflow hydrographs shown in the middle were used in the calibration phase while the other two inflow hydrographs were used to evaluate the performance of the calibrated hydraulic model under significantly different flow conditions table 2 quantifies the difference between the performance of the two equivalent hydraulic systems using three standard error measures sse the absolute value of the relative error in peak depth arepd and the absolute value of the relative error in peak depth time arepdt in each case the absolute value of the relative error was calculated by dividing the absolute value of the difference between the predicted and corresponding real value by the real value reported in percentage as fig 25 and table 2 show the hydraulic model calibrated with equivalent roughness coefficients performs better than the model calibrated with the single n value the results of the four examples presented above indicate that if there is no information regarding the number of distinct regions the number of initial seeds can be selected based on the model outputs for instance in example 1 the results indicated that n first decreased and then increased along the river reach as a result three initial seeds were selected another advantage of the proposed method is that it can appropriately recognize distinct regions even if the interval of n for starting the analysis is not known properly meanwhile depending on the field condition as long as a proper hydraulic routing model that can model any flow condition e g subcritical and supercritical flow and handle any channel geometry is employed the developed method can be used to estimate the n values within the framework proposed in this study although the method proposed in this study was developed to recognize patterns in n in river reaches having different regions with constant n values separated by sharp boundaries as discussed in example 4 the method can result in reasonable equivalent roughness coefficients along a river reach when there is a linear trend in variation of n it can be stated that based on the examples discussed in this article a few limitations can be considered for the hydraulic approach and methodology presented in this research for calibration of n in rivers uncertainty in estimated n values in natural rivers discussed in the tiber river case and piecewise estimation of n values in the presence of a trend in variation of n discussed in example 4 can be given as examples also like any other numerical method the numerical parameters of the proposed method must be selected properly to preserve both accuracy and computational efficiency another limitation of the proposed methodology is that a uniform or constant n value in a river cross section is assumed in other words the proposed method cannot handle compound channels where the roughness of the floodplains is different from that of the main channel this issue is currently under study 4 conclusions optimization based conventional methods used for calibration of n in a river usually assume a uniform manning s roughness coefficient along a river reach between two gauged stations the application of the conventional calibration methods would be computationally hard and time consuming if different regions of a river reach have different n values separated by sharp boundaries in these situations the conventional methods may require a predefined length for each region to be able to calibrate the n values in different regions such information may not be available or be subject to high uncertainty in most situations in this study a new method was proposed that can identify different regions with different roughness coefficients along the long river reaches just based on at least one inflow and corresponding outflow hydrograph the method has the following three main components 1 dividing the river reach into a different number of sub reaches in a systematic manner and in any sub reach arrangement or case calibrating n in each sub reach by applying a random search optimization using the monte carlo simulation 2 finding the best case among different cases considering the similarity between different cases and applying the similarity criteria defined in this study and 3 using clustering methods to recognize different regions with different n results from applying the proposed method to two test examples developed by synthetic data and tiber river data indicated that the method could recognize different regions with different n along the river reach when only one recorded inflow and corresponding outflow hydrograph were available the method is particularly useful in long river reaches when the number of gauging stations are limited the main advantage of using the proposed method in comparison with the conventional methods is that information about the variation of n in a river system is generated with the same amount of data this information not only improves the prediction accuracy of the flood routing models but also can be useful in river restoration dredging and management projects by spotting regions with high roughness also information about the variation of n along a river may reduce the cost of river engineering projects by reducing the amount of field work declaration of competing interest none acknowledgment the authors are thankful to the department of environment planning and infrastructure umbria region and irpi perugia italy for providing the tiber river data used in this study the authors would also like to thank the anonymous reviewers for their detailed and valuable comments and suggestions 
6381,karst features in limestone aquifers often exhibit highly heterogeneous patterns which are strongly governed by structural complexities such as the spatial distribution and organization of fractures in natural carbonate rocks however until now little is known about the impact of structural complexity on karstification processes in this paper we use numerical models to investigate how structural heterogeneity affects the generation of incipient karst in natural fractured systems we develop a numerical model which couples the processes of fluid flow mass transport and dissolution kinetics that govern the growth of fracture aperture based on discrete fracture networks we apply the model to simulate conduit evolution in a natural joint network that displays a distinctive topological pattern a wide range of hydraulic gradient and initial fracture aperture is considered our results show that the network topology may generate a significant impact on dissolution pattern depending on how flow is organized within the discrete network if a channelized structure occurs in the flow network the dissolution pattern depends highly on the initial hydrogeological settings while if the flow network consists of branched segments a similar dissolution pattern emerges for a broad range of initial hydrogeological settings when the flow direction is normal to the persisting fracture orientation intermittent interruptions to the positive feedback process between flow and dissolution occur therefore the breakthrough is delayed we discuss the link between our results of dissolution modeling in fracture networks to previous modelling efforts in the context of single rough fractures and fracture network formed by orthogonal fracture sets keywords discrete fracture network karst network topology reactive flow 1 introduction fluid flow in karstified limestone rocks is highly heterogeneous and often exhibits hierarchical structures the majority of flow in a karstic aquifer is often focused along a few highly transmissive conduits which are created by the dissolution of discrete pathways of a proto fracture network consisting of fractures and bedding planes the generation and evolution of karstic conduits is governed by a positive feedback mechanism conduits carrying a higher flow experience a higher growth of aperture size the increased aperture in turn leads to less flow resistance thus attracting more flow from neighboring regions hanna and rajaram 1998 szymczak and ladd 2006 this competition process operates from dissolutional water entering the rock mass until one preferentially enlarged conduit emerges in the past several speleogenesis models that simulate the positive feedback mechanism between dissolution and flow have been proposed to understand the early stage evolution of karstic conduits in carbonate rocks dreybrodt 1990 and dreybrodt et al 1996 first proposed a one dimensional conduit model to investigate the evolution of caves from initially narrow conduits lauritzen and odling 1992 investigated the conduit growth in two dimensional conduit networks exhibiting regular patterns the numerical approach was further extended by groves and howard 1994 to include the effect of turbulent flow these conduit network models have been used to understand how hydrogeological and hydrochemical conditions such as recharge discharge type and mixing criteria influence the breakthrough time aperture evolution and dissolution pattern e g gabrovšek and dreybrodt 2000 romanov et al 2003 hubinger and birk 2011 matrix flow has also been coupled to the conduit network models to investigate the potential effect of exchange flow between conduits and matrix on the growth of karstic conduits liedl et al 2003 kaufmann and braun 2000 in these studies the dissolution process was simulated on predefined conduit networks the networks represent the initial flow paths composed by interconnected fractures and or bedding planes before the initiation of the karstification process since previous authors focus was primarily on gaining insights into the physical processes of conduit development the geometrical configuration of their models is often highly hypothetical and simple however it should be noted that the structural heterogeneities induced by network geometries may have a significant impact on the karstification process since they strongly influence solute transport ronayne 2013 borghi et al 2016 in previous modelling work the aquifer heterogeneities are typically introduced into existing speleogenesis models either by mapping variable hydraulic properties onto a network consisting of two orthogonal fracture sets e g gabrovšek et al 2004 dreybrodt et al 2007 or by adopting an incompletely filled lattice grid siemers and dreybrodt 1998 with these synthetically generated structures some geometrical properties of natural fracture networks such as the length and intensity may be preserved however the distinctive topology exhibited by natural systems is largely omitted in previous studies one exception is the numerical model of kaufmann and braun 1999 since unstructured grids were adopted it was possible to model the karstification process on irregular proto conduit networks with more realistic connectivity properties however the authors only simulated the development of karstic conduit networks in simple synthetic models and did not investigate the role of network topology in the evolution of conduit networks in general the rock properties are not only controlled by geometrical properties but also by topological properties of the fracture networks zimmerman and main 2003 depending on how fractures are spatially organized two fracture networks that contain the same geometrical elements may have very different connectivities and thus different flow patterns sanderson and nixon 2015 the complex connectivity of the fracture networks may cause significant flow channeling tsang and neretnieks 1998 this phenomenon of flow localization has not been captured in the flow models of previous speleogenesis studies based on simple fracture patterns a channelized flow pattern implies a long range correlation structure in the flow field the growth rate of a preferential flow channel will be much higher at the initial time and will be progressively accelerated by capturing flow from neighboring flow paths of slower flow hanna and rajaram 1998 szymczak and ladd 2006 comparing to the randomly distributed flow fields considered in previous speleogenesis models a channelized flow structure would lead to a highly uneven dissolution front and could potentially reduce breakthrough times another topological parameter that may influence the dissolution process is the type of fracture contacts such as the abutting or cross cutting relationship at fracture intersections the fracture contact type determines the coordination numbers of fractures which controls flux solute mixing and redistribution at the intersections kupper et al 1995 park et al 2001a berkowitz et al 1994 the regular lattice networks widely used in previous speleogenesis simulations contain only intersections with a coordination number of four however in natural fracture networks abutting connections are more prevailing pollard and aydin 1988 renshaw and park 1997 davy et al 2013 most fracture intersections may have coordination numbers less than four park et al 2001b this implies performing dissolution simulations in natural fracture networks is not a trivial extension of previous investigations based on regular grids instead it may provide new insights into the development of incipient karst in natural systems in this work we aim to provide a closer examination of the influence of the topology of natural fracture networks on karst evolution in carbonate rocks our geological model was constructed based on a field fracture pattern mapped from limestone outcrops the fracture network consists of a persistent joint set and a set of subsequently formed cross joints that abut the persistent ones the abutting relationship is a representative topological feature that is commonly observed in natural joint networks given such a network topology contrasting structures of flow fields form when the flow direction is parallel or perpendicular to the long fracture set the anisotropic flow structures allow us to gain insights into the effect of natural network topology on the dissolution process in limestones our numerical models account for the key features of the coupled physical chemical processes that govern dissolution of limestone fractures namely the positive feedback mechanism we have focused on the initial phase of karst evolution thus our simulations were terminated at the breakthrough time which is defined as the time at which turbulent flow first occurs anywhere within the computational domain 2 methodology 2 1 fracture network the fracture network used in our simulations is a natural fracture pattern in triassic limestone beds located at kilve on the southern margin of the bristol channel basin uk fig 1 the geometry is two dimensional and in plan view so that gravitational forces are not considered the fracture network consists of two well connected major sets an e w striking set containing through going fractures long set and a n s striking formed by small joints that abut the e w fractures short set the emergent ladder pattern represents a typical hierarchical morphology of natural joint networks pollard and aydin 1988 fig 1b the fracture pattern has been used extensively for numerical simulations of single and multi phase flow and transport in fractured reservoir analogues matthäi and belayneh 2004 belayneh et al 2006 geiger boschung et al 2009 matthäi et al 2010 geiger and emmanuel 2010 to focus on the geometric effect we assume the initial aperture of the fracture network is constant in space simulations were carried out with five different aperture values 0 09 mm 0 10 mm 0 12 mm 0 13 mm and 0 14 mm only an area of 8 8 m2 on the right side of the full pattern fig 1a was chosen as the input network to our simulations for the sake of expediency in comparison of results obtained for the x and y directions the distinct topology structure of the ladder pattern leads to significant flow anisotropy and therefore different flux distribution in the two directions 2 2 reactive transport model the incipient karst generation in fracture networks is modelled as a coupled process of flow transport of ca2 and dissolution enlargement of fracture aperture the process is simulated using a finite difference technique based on a resistor network odling and webman 1991 fig 1c flow through the system is assumed to occur only in fractures the fracture network is discretized by linear segments the aperture of each segment is assigned independently the local flow velocities are calculated from assigned apertures using the poiseuille equation for laminar flow through parallel plates as follows zimmerman et al 1991 1 v a 2 12 μ h where v is the flow velocity a is the hydraulic aperture h is the hydraulic head and μ is the dynamic viscosity of the fluid the fracture flow in the numerical grid is solved by invoking the condition of flow conservation assuming the fluid is incompressible fig 1c at each grid node as 2 q in q out 0 where q in and q out represent the rate of fluid flow into and out of the node respectively the reactive transport model considers the rock fluid dissolution effect and the evolution and transport of dissolved species during fluid flow diffusion is only considered within the fracture aperture between the fracture wall and the main flow stream when the fluid passes through a segment due to the dissolution of fracture walls the concentration increases by 3 δ c r c q δ t where r c is the reaction rate q is the flow rate and δ t is the time interval the reactive transport problem in the channel network is solved by assuming mass conservation at the nodes where multiple segments are connected we assume complete mixing of solution at the nodes in the network configuration shown in fig 1c the concentration of the central node c 0 is calculated by a flux weighted formula 4 c 0 c 3 δ c 3 0 q 3 0 c 4 δ c 4 0 q 4 0 q 3 0 q 4 0 where c 3 and c 4 are concentrations at the surrounding nodes that transfer fluids to the central node c 0 δ c 3 0 and δ c 4 0 are the concentration increments when the fluids flowing from nodes 3 and 4 to the central node 0 q 3 0 and q 4 0 are the corresponding flow rates along the two branches the dissolution of limestone is controlled by two serial steps 1 surface reaction and 2 transport of ca2 into the main flow stream by diffusion the slower process determines the overall reaction rate when the aperture is small the surface reaction is the rate limiting process in this case the reaction rate is expressed by palmer 1991 dreybrodt et al 1996 5 r c k 1 c eq c where k 1 is the reaction kinetics ceq is the concentration at saturation and c is the concentration although other high order kinetic laws which have been applied in previous numerical studies can be readily implemented to model the trigger mechanism white 1977 we consider that the linear kinetic mechanism is sufficient for our modeling purposes also szymczak and ladd 2011 has demonstrated that the high order kinetics is not a prerequisite for generating extended conduits if a two dimensional model is used when the aperture is large the dissolution rate is limited by diffusion the mass transfer rate is determined using the following expression incropera and dewitt 1990 6 r c dsh a c eq c where d is the molecular diffusion coefficient for ca2 in water a is the fracture aperture sh is the sherwood coefficient and c eq is the calcium saturation equilibrium concentration the concentration c for a segment is approximated by the mean of the concentrations of inlet and outlet nodes in our simulations we use d 6 73 10 10 m2 s 1 dreybrodt 1990 sh 8 for laminar flow szymczak and ladd 2011 and ceq 2 mol m 3 dreybrodt et al 1996 by assuming the dissolved mass is evenly distributed over a sufficiently short segment of length l the amount of aperture growth can be calculated from 7 δ a δ c q δ t ρ r l where ρ r 2 7 109 mg m 3 is the density of rock material 2 3 characterization of karst network evolution the uneven propagation of the dissolution front within the fracture network is quantitatively characterized by the temporal evolution of the correlation dimension of the flow rate d 2 q d 2 corresponding to i 2 of generalized fractal dimension d i which is defined as cowie et al 1995 bonnet et al 2001 6 d i lim l 0 l o g k 1 m p k i log l where i is the fractal moment p k is the proportion of a measure within a grid element to the cumulative amount of the measure in the grid l is the dimension of the grid elements in general multifractal measures give the distribution of a physical quantity on a geometric support feder 1988 bonnet et al 2001 the principle of calculating the fractal dimension is demonstrated in fig 2 in this work we use a 20 by 20 square grid in our calculation of d 2 thus l equals to 0 4 m see section 2 1 for model dimension p k corresponds to spatial distribution of flow rate within each grid the correlation dimension has been used previously for quantitative analyses of the heterogeneous spatial distribution of fault patterns davy and cobbold 1991 sornette et al 1994 and fault displacements cowie et al 1995 as well as degree of flow channeling sanderson and zhang 1999 bruderer weng et al 2004 wang et al 2017 once the karstification process starts the value of d 2 q would drop progressively due to enhanced flow focusing created by the formation of a few karstic conduits of favored dissolution the shape of a d 2 q curve may provide further quantitative information regarding the competition process during the course of incipient karst generation in general d 2 q should decrease monotonically however an increase of d 2 q may occur in specific cases under a fixed hydraulic gradient the lowest point of a d 2 q curve occurs when the first developed karstic conduits arrive to the outlet after this event if the total flow is small d 2 q is expected to increase due to the sudden pressure drop in the developed karstic conduit which leads to reflux of dissolutional fluid into other immature flow paths to enable their further growth this reflux process may lead to a more uniform flux distribution therefore a higher d 2 q value 3 numerical implementation the reactive transport model eqs 1 5 is solved using the finite difference method each of the interconnected fracture segments in the network is subdivided into small elements of maximum length of 0 1 m unlike previous work on dissolution in single fractures e g hanna and rajaram 1998 upadhyay et al 2015 cheung and rajaram 2002 and a network of orthogonal fracture sets groves and howard 1994 gabrovšek et al 2004 an exact uniform spatial discretization cannot be applied due to the unequal length of natural fractures instead we apply an average element length of 0 05 m in the global discretization so that the number of elements per fracture segment is calculated through dividing the segment s length by the average element length an extra finer discretization dx 0 01 m is adopted for the segments within the first 0 1 m from the inlet to avoid numerical saturation groves and howard 1994 this spatial discretization is sufficient to spread about ten nodes over the initial penetration length l p to capture the rapid variation of the concentration field upadhyay et al 2015 in all flow simulations presented in this paper the inlet and outlet of the study domain are assigned constant hydraulic heads while no flow conditions are assumed for the two orthogonal boundaries a constant head boundary is reasonable for early stage evolution of karst aquifers where flow rates in the system are smaller than the recharge rate palmer 1991 for the reactive transport simulations a zero concentration of ca2 is assumed at the inflow boundary a quasi stationary approximation is adopted to simulate the coupled processes of dissolution and flow hanna and rajaram 1998 dreybrodt and gabrovšek 2018 based on the initial aperture field the steady state flow and concentration fields as well as reaction rates are computed over a dissolution time step the aperture field is modified based on the reaction rate when calculating the aperture growth it is assumed that the amount of dissolved calcite is evenly distributed that is no aperture variation is considered over a single segment the process is repeated until breakthrough or turbulent flow occurs the detection of turbulent flow is based on the first occurrence of a reynolds number 2100 in any fracture segments within the domain according to the local flow velocity and hydraulic aperture appropriate time steps dt 0 01 year for x direction simulations and dt 0 1 year for y direction simulations were found by a preliminary sensitivity analysis further reduction in time step does not lead to a significant change in the dissolution pattern and breakthrough time 4 results simulations of dissolution in fracture networks with natural geometrical and topological characteristics presented in section 2 1 have been carried out using the reactive transport model described in section 2 2 because we aim to gain insight into the controlling effect of structural heterogeneities on the dissolution pattern in real fracture networks we have decided to focus on the three most fundamental and influential parameters reactive flow direction hydraulic boundary condition and initial fracture aperture 4 1 influence of flow direction fig 3 shows distributions of flow rate and fracture aperture at the breakthrough time for speleogenesis simulations in the x and y directions when flow occurs in the x direction enhanced dissolution is restricted to a few through going fractures in the flow direction before breakthrough the developed karst conduits are predominately linear features fig 3b and c branching features were observed on the longest conduit near the outlet boundary in contrast when flow is in the y direction the dissolution pattern is very branched and the development of each conduit in the direction transverse to flow is largely enhanced fig 3e and f the range of aperture variability of the karst conduits is reduced to less than one order of magnitude fig 3e fig 4 shows a plot of the correlation dimension of flow rate d 2 q versus time t for dissolution simulations along x and y directions as presented in fig 3 before the initiation of conduit growth d 2 has a high value close to 2 fig 4 the discrepancy from 2 is caused by the incomplete filling of flow in two dimensional space due to the presence of structural heterogeneity the distinctive shape of the two d 2 curves presented in fig 4 highlights the impact of the network topology on the incipient karst generation first the breakthrough time of the transport simulation in the x direction is much shorter than that in the y direction note the logarithmic time scale of fig 4 second the d 2 curves of the two flow directions exhibit distinctive evolution paths indicating different competition mechanism during the karst genesis process on the d 2 curve for the x direction simulation three regimes indicated by different slopes can be observed over the first four years the value d 2 stays high and only reduced slightly comparing to the value at the initiation of the karstification process during the second regime the d 2 value drops at a much higher rate in the last regime the decreasing rate of d 2 is the highest the d 2 value is close to 1 at the breakthrough confirming that only one conduit reaches to the outlet figs 3 and 4 the trend of gradually increased slope indicates a sustained competition procedure between various favored karstic conduits we found that the slope may relate to the number of competing candidates or the spacing between them in general a larger slope corresponds to less flow paths this point is further illustrated using a synthetic fracture network where the fracture aperture is modelled using a lognormal distribution fig a 1 see also appendix i for the model description the results for the y direction simulation exhibit a different behavior of evolution over a considerable time period more than sixty years the slope of the d 2 curve does not show a distinguishable difference until around eighty years the value of d 2 only drops of 0 1 in the last stage a quite rapid decrease of d 2 is observed in both cases the final stage of evolution corresponds to a highly hierarchical flow structure composed of a major flow path carrying the majority of the total flux a few secondary paths carrying highly reduced flux and numerous minor paths carrying negligible flux fig 3d 4 2 influence of hydraulic boundary condition with a fixed network geometry and initial fracture aperture a series of hydraulic gradients are created by fixing the outlet hydraulic head at 0 m and varying the inlet hydraulic head hin from 0 4 m to 1 0 m the flow distribution at the breakthrough time for the five tested models are shown in fig 5 for flow in the x and y directions respectively in the case of flow along the x direction when the hydraulic gradient is small fig 5 hin 0 4 m one preferential path develops at the upper part of the model other conduits stop to grow before reaching to the half length of the model domain as hin increases the dissolution is less localized along the major enlarged conduit the secondary conduits experience more enlargements and develop deeper into the domain fig 5 hin 0 6 m and 0 8 m when hin is increased to 1 0 m a second conduit at the bottom of the domain develops sufficiently and reaches the outlet at breakthrough the total flow is distributed along the two developed paths interestingly this second developed conduit does not show up in the simulations with smaller hin i e hin 0 4 m or 0 6 m as hin increases the downstream hydraulic boundary generates different impact on the conduit dissolution this can be seen quantitatively in fig 6 where the normalized concentration profile is plotted for the five hin cases the dashed line in fig 6a indicates the location where the outlet hydraulic boundary condition becomes important for the simulation with hin 0 4 m on the left side of the dashed line the undersaturation value remains high because only a few karstic conduits developed in that domain on the right side the averaged undersaturation value dropped considerably due to diffused dissolution caused by the outlet hydraulic boundary condition as the hydraulic gradient becomes larger the overall level of the undersaturation profile decreases the area of the diffused dissolution is increased indicated by smaller undersaturation values for higher hin values also the dissolution plume starts to develop at a smaller distance from the inlet the evolution of d 2 as shown in fig 7 further illustrates the influence of hin on karstic conduit development although the total initial flow rate is different in each of the simulations due to different hydraulic gradients being imposed the spatial distribution of initial fluxes is the same initially this is confirmed by the same initial d 2 value for the five models fig 7a however as the karstification process starts in the x direction the evolution of the flux distribution for different simulations follows distinct paths for the simulation model with hin 0 4 m the d 2 value remains high during a longer period before it drops when hin is increased the d 2 curve starts to decrease at an early time and its final value is well above 1 implying more than one conduit developed to reach the outlet fig 5 in contrast when the flow is along the y direction the number and location of developed conduits are insensitive to the change in hin fig 6 the normalized concentration profiles for the five hin cases are rather similar fig 7d also the evolution of d 2 curves is similar for the five cases fig 7b the only difference is how fast a curve drops to a certain value the d 2 curve of hin 1 0 m is only a horizontally stretched version of hin 0 4 m along the time axis overall the dissolution patterns resulted from y direction simulations are much simpler than that from x direction simulations in particular in the region near the outlet one marked characteristic of the y direction simulations is the presence of step features on the d 2 evolution curves these features are absent in the x direction results the origin of these features is linked to a particular flow structure which is discussed in detail in section 5 1 4 3 influence of initial aperture the hydraulic gradient was kept constant by fixing hin at 1 m the dissolution simulations were run for x and y directions for each aperture value fig 8 presents the results for dissolution simulations at the breakthrough time with flow in x top two rows and y bottom two rows directions the evolution of d 2 for the two scenarios of flow direction is given in fig 9 when flow is in the x direction the final dissolution pattern changes significantly when a 0 is altered the overall trend is that a larger initial aperture leads to a more complex dissolution pattern consisting of an increased number of conduits with more branches fig 8 row one this observation is consistent with previous findings of siemers and dreybrodt 1998 on an incompletely filled lattice grid when a 0 0 09 mm the most dissolved conduit is located in the upper part of the simulation domain while two other conduits located in the lower part of the domain also developed but they only penetrate to a limited distance less than the half length of the model domain when a 0 is increased to 0 10 mm and 0 11 mm the location of the most developed conduit remains unchanged but more branches at the downstream end were observed moreover the relative extent of the secondary dissolved paths increased significantly when a 0 is increased when a 0 0 12 mm the conduit located at 1 m above the lower model boundary develops and reaches the outlet however this path does not even show a potential to grow in the simulations with smaller a 0 e g a 0 0 09 mm and 0 10 mm the different dissolution behaviors were confirmed by the distinct shape of the evolution curve for d 2 at various a 0 fig 9a in the contrary the conduit growth in the dissolution simulations following the y direction exhibit a completely different response to the change in a 0 first the location where the main conduit develops remains similar across the tested range of a 0 fig 8 the only difference is the relative extent of growth of the secondary conduits initiated in the middle of the inlet boundary a higher a 0 results in a deeper growth of this conduit the similarity in conduit evolution may also been seen from fig 9b where the form of the d 2 evolution for various a 0 is highly similar in fact if the curves are scaled by the breakthrough time or by corresponding flow rates they would collapse to a single curve fig 9b in general the influence induced by the aperture variation is similar to that induced by changing hin figs 5 and 7 5 discussions 5 1 influence of network topology on incipient karst generation according to the positive feedback mechanism an intuitive expectation is that the location of developed karstic conduits should coincide with the shortest flow path whose resistance to flow is the least however after a careful comparison we obtained a rather interesting observation the enlarged conduits coincide with the shortest flow path only when the flow is in the y direction but not for the simulations with flow following the x direction cf fig 3 and fig 10 surprisingly the most developed conduit in the simulations with x direction flow does not even relate to any of the ten shortest paths fig 10a the different behaviors of karstic conduit evolution in the x and y directions is linked to the different topological characteristics of fractures which lead to different flow structures in fact two distinct characteristic flow organizations exist for the two scenarios of flow direction fig 11 when the main flow direction coincides with that of the long fracture set i e in the x direction the long fractures are the main paths for fluid flow while the short fracture set connecting multiple long fractures induces local flow exchange between the main flow paths it is this local exchange of fluid that generates a variability in concentration in the direction transverse to the long fractures although small the variability may significantly alter the preferential paths for further dissolution due to the presence of competition between neighboring flow paths hence the emergence of karst conduits depends not only on the initial settings but also strongly on the variability of the concentration field during the evolution the difference in the dissolution pattern of the simulations following the x direction may be attributed to the difference in the initial penetration length caused by a variety of hin and a 0 see appendix b for a detailed explanation in contrast when the main flow direction is aligned with that of the short fracture set i e in the y direction the major flow paths are formed by segments of both the short and long fracture sets when flowing through the fracture network the aggressive water must pass many t like junctions of fractures however there is significantly less local flow exchange between the developing karst conduits therefore less influence on the continued growth of a conduit generated by its connected neighbors it follows that the flow paths of least resistance to flow would be selected as the favored channel for karstification the network topology is also responsible for the delayed breakthrough and the generation of the step features on the d 2 evolution curves of the y direction simulations the periodic stabilization of d 2 implies intermittent interruptions to the positive feedback loop governing the karst genesis process to illustrate this phenomenon at each time step a distribution of flow change in each fracture segment is computed by subtracting the flow rate at the current time from the flow rate of the previous time the total flow change at that time step is computed by summing up the values of flow difference in all fracture segments of the network normalization of the simulation time by the breakthrough time is then applied to directly compare the datasets from simulations of the x and y directions fig 12 presents an example using the simulation model with a 0 0 09 mm and δh 1 m it can be seen that the two curves of total flow change evolve very different to breakthrough the evolution curve for the x direction simulation exhibit a smooth variation with time while the curve of the y direction simulation is characterized by abrupt fluctuations whose periodicity seems to associate with that of the occurrence of the step features fig 13 presents a series of distributions of flow rate change corresponding to different d 2 variation periods in the case of flow in the x direction high flow rate changes occur along the developed conduits fig 13a throughout the entire course of the evolution the increase of flow rate in all developing conduits is continued the only difference is that the magnitude of the flow rate increase is higher in longer conduits however when the dissolution simulation is performed in the y direction the flow rate variation in the enlarged conduits may switch between increasing and decreasing when passing through t like junctions fig 13b compare results of time 17 time 23 and time 28 namely the positive feedback process between flow and dissolution is intermittently interrupted in the leading conduit in this way the shorter conduits gain extra chance to grow and hence against the tendency of progressively enhanced flow localization into long conduits i e maintaining d 2 this explains also the delayed breakthrough of simulations in the y direction 5 2 relationship with lattice dissolution model and simple growth law model previous studies on conduit growth in fracture networks have performed on either a completely or partly filled lattice grid e g siemers and dreybrodt 1998 hubinger and birk 2011 or an orthogonal network formed by two persistent fracture sets that go through the model domain e g gabrovšek et al 2004 dreybrodt and gabrovšek 2018 bloomfield et al 2005 also performed dissolution simulations based on a lattice grid with a simple growth law which assume that the aperture growth is proportional to velocity to an exponent of 0 2 0 8 heterogeneities are introduced into these models through assigning variable apertures normally obeying an uncorrelated lognormal distribution to the fracture segments because the structured computational grid does not possess any structural heterogeneity the numerical models in general do not generate a flow field with long range correlations this means that the flows within the network are organized in a way similar to that presented in fig 11b thus one may expect that the emergent conduits may correspond to the few channels of shortest distances across the imposed hydraulic gradient in this case the dissolution model assumes simple growth laws may predict similar dissolution trajectory to that generated by physical based dissolution models this may explain the results of hubinger and birk 2011 which showed that on a lattice grid the enlargements of conduits create a bi mode aperture distribution despite whether a physically based or a simple growth model is adopted the similar mode of aperture distribution may be caused by similar dissolution trajectories developed when a hierarchical flow structure is absent fig 11b since the paths are similar the difference between the evolved aperture distribution of the two types of model is only quantitative not qualitative however the difference between the models based on physically based kinetics and on simple growth laws is expected to be significant for natural fracture networks where fracture flows are organized in a hierarchical manner following the complex network geometry fig 11a accordingly the dissolution model assumes simple growth laws may provide completely faulty characterizations we note that it is possible to reproduce a correlated flow field to some level in a lattice model through incomplete filling of the grid siemers and dreybrodt 1998 or superimposing a correlated permeability structure gabrovšek and dreybrodt 2000 however these models may significantly underrepresent the spatial distribution and organization of fractures in natural systems hence they may hinder our understanding of the physical mechanisms governing natural karstification processes when attempting to connect findings from numerical models to geological phenomena one must capture sufficiently the geometry and topology of geological structures 5 3 scaling of karstic conduit spacing it can be seen from the results shown in section 4 that the karstification process in the natural fracture network forms dissolution patterns that exhibit a general relation that the spacing between karstic conduits is proportional to the length of the karstic conduits figs 5 6 8 and 9 this is consistent with previous observations for wormhole formation in porous media hoefner and fogler 1988 and in single fractures szymczak and ladd 2009 this implies that the linear stability analysis szymczak and ladd 2011 is valid for characterizing the general dissolution mechanism in conduit networks our simulation results also show that the geological complexities may lead to a variation in the proportionality constant when channelized flow is due to structural heterogeneities i e simulations with reactive flux occurring in the direction of persistent fractures figs 5 and 8 top two rows an alteration in hydraulic gradient or initial fracture aperture may change the proportionality constant however its value still falls in the range between 1 and 2 which has been observed for single dissolving fractures upadhyay et al 2015 in contrast when flow channeling is absent i e simulations with reactive flux occurring in the direction of short fractures that abut the persistent fractures figs 5 and 8 bottom two rows the proportionality constant is not sensitive to a variation in initial model settings 5 4 limitations and perspectives in this paper we simulate incipient karst generation in a natural fracture pattern based on linear dissolution kinetics this is reasonable as in two dimensional dissolution models where flow focusing and competition between developing conduits are the most important mechanisms in driving conduit growth szymczak and ladd 2011 also we chose to perform our simulation in models with a square area fig 1 to ensure the dissolution stays within the regime where linear reaction kinetics dominate higher order kinetics may be required for high aspect ratio models in that case nonlinear kinetics are essential to sustain conduit growth as the competition between conduits focuses the majority of flow to a single conduit when it reaches to a distance proportional to the transverse model dimension our investigation is limited to the initial phase of karstification where the fluid flow is under the laminar flow condition to investigate the evolution of karst networks after the breakthrough time the nonlinear darcy weisbach flow law has to be solved dreybrodt 1988 alternatively we can adopt the full range pipe flow model to avoid switching between laminar and turbulent flow conditions swamee and swamee 2007 de rooij and graham 2017 the onset of turbulent flow would result in reduced flow rates in a given conduit kaufmann 2009 we have also limited our study to a small area of 8 m by 8 m the choice is made for the sake of efficiency while ensuring accuracy because a fine discretization 0 01 m for fracture segments near the inlet and 0 for the rest was adopted here the primary objective is to demonstrate the potential of the proposed model as an efficient approach to generate of realistic karstic conduit network overall the geomorphological properties of the enlarged conduits and the hierarchical structure of the conduit networks presented in this work is close to those that have been observed in nature the approach can be extended to larger scales to investigate evolution of karst catchments if reliable fracture data e g orientation density length and aperture of main fracture sets is available at the regional scale the boundary condition of fixed head gradient used in this work may still be valid at the initial stage as the development of karst conduit networks the drainage capacity of the system increases the karst system will switch from hydraulic to catchment control accordingly a numerical implementation of the switch from fixed head gradient to recharge flux boundary is required bauer et al 2005 de rooij and graham 2017 also a focused recharge is more appropriate than the distributive recharge boundary considered in the present work our two dimensional models can be regarded as a conduit network formed along a bedding plane by intersections of subvertical joints in the adjacent layers and the bedding plane we emphasize that they are significantly different from a quasi 3d model which is formed by a network of 2d vertical discrete fractures or by a uniform extrusion of our 2d network to the third dimension if fractures are modeled by 2d discrete planes even with a uniform aperture distribution an uneven dissolution front may quickly develop which then leads the conduit growth to a three dimensional process in that case a 3d discretization must be invoked similar to the contribution of kaufmann and braun 1999 and 2000 our simulation code may be adapted with the delaunay triangulation technique to generate an efficient computation mesh only along the fracture planes that are interconnected in 3d space other factors that will be considered in a future paper include aperture variability and stress condition 6 conclusion we have developed a reactive transport model for simulating incipient karst generation in two dimensions with discrete fracture networks we focused on investigating the influence of fracture network topology on the conduit evolution in our simulations a natural joint network that exhibit a ladder pattern was used as the geometrical model a sensitivity test was conducted for hydraulic gradient and initial fracture aperture for each configuration dissolution simulations were performed for two major flow directions following respectively the orientation of the two main fracture sets our results demonstrate that the heterogeneity induced by geometrical complexities may play a decisive role in the early stage of the karstification processes in fractured carbonate rocks when the flow is in the direction of the long persistent fracture sets which provide direct connection between the model inlet and outlet enhanced karstification occurs preferentially along the long fractures however the location of the main karstic conduits does not correspond to the shortest path across the model a change in hydraulic gradient and initial fracture aperture may significantly change the dissolution pattern in contrast when the flow is in the direction of the short fracture set that are arrested by the long fracture set the shortest path across the model is always selected as the favored stations for enhanced karstification the differences in the conduit evolution and the final dissolution pattern introduced by varying hydraulic gradient and initial fracture aperture are almost indistinguishable also intermittent interruptions to the positive feedback mechanism were observed when the flow direction is perpendicular to the orientation of the persistent fracture set as a consequence the occurrence of the breakthrough event is severely delayed our results highlight the important effect of network topology on the conduit evolution the proposed karstification model based on realistic fracture networks may be used to investigate the spatial relationship between tectonic structures and karst cavities and to understand the mechanism governing its formation which has important implications for production of groundwater and hydrocarbon resources in fractured carbonate reservoirs to make reliable designs for practical engineering applications the structural heterogeneities must be properly considered in reactive transport simulations declaration of competing interest none acknowledgement this work benefited from fruitful discussions within the framework of the karst observatory network www sokarst org initiative from the insu cnrs which aims to strengthen knowledge sharing and promote cross disciplinary research on karst systems as well as with qinghua lei during the preparation of this manuscript we thank three anonymous reviewers for their constructive comments which improve the quality of the paper appendix a to illustrate the possible relationship between the correlation dimension d 2 and the spacing of evolved karstic conduits we conduct a dissolution simulation on a 25 m by 25 m synthetic fracture model consisting of a 60 by 60 lattice grid the length of each fracture segment is 0 833 m the aperture field is modelled by a lognormal distribution with a mean of 0 3 mm and a standard deviation of 0 1 mm the left model boundary is assigned with a fixed head of 0 5 m the right model boundary is assigned with a fixed head of 0 m the two other boundaries are no flow boundaries other parameters used here are the same as in the models presented in section 4 fig a 1 presents the evolution of d 2 and several aperture distributions at different stages of the conduit evolution the evolution stages separated by the dashed lines are defined by different slopes of the d 2 curve it can be seen as the system evolves from the stage 2 via the stage 3 to the stage 4 the slopes of d 2 curve is successively increased examining the aperture fields a good correlation between the slope of the d 2 curve and the conduit spacing can be observed the stage 4 has the largest conduit spacing the conduit spacing of the stage 3 is smaller than that of the stage 4 but larger than that of the stage 2 in short a large slope of the d 2 curve corresponds to a large conduit spacing appendix b to illustrate the influence of hydraulic configuration on the evolution path of the system a dissolution simulation on a simple geometrical model consists of two long fractures interconnected by a short one fig b 1 a both fractures 1 and 2 will dissolve however due to the local flow exchange induced by fracture 3 the concentration profile along fracture 1 will be slightly lower than that along fracture 2 fig b 1b with a higher value of hin or a 0 a longer penetration length is formed a deeper penetration of undersaturated fluid leads to a larger difference between the concentration profiles in the two fractures near the fracture inlet compare the thin dashed line and thin solid line in fig b 1c this difference in concentration determines the relative difference in the growth rate of the two fractures and therefore the relative difference in the intensity of competition for flow operated by the positive feedback loop between the two fractures the larger the difference in concentration the more contrast in fracture growth the less competition between the fractures as time evolves the difference in concentration increases more rapidly with a short l p in comparison to a long l p fig b 1c this means that with a higher hin or a 0 value the required time for flow to focus in the developed conduits is longer i e the secondary conduits have a larger tendency to grow deeper appendix c supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 05 082 appendix c supplementary data the following are the supplementary data to this article supplementary data 1 
6381,karst features in limestone aquifers often exhibit highly heterogeneous patterns which are strongly governed by structural complexities such as the spatial distribution and organization of fractures in natural carbonate rocks however until now little is known about the impact of structural complexity on karstification processes in this paper we use numerical models to investigate how structural heterogeneity affects the generation of incipient karst in natural fractured systems we develop a numerical model which couples the processes of fluid flow mass transport and dissolution kinetics that govern the growth of fracture aperture based on discrete fracture networks we apply the model to simulate conduit evolution in a natural joint network that displays a distinctive topological pattern a wide range of hydraulic gradient and initial fracture aperture is considered our results show that the network topology may generate a significant impact on dissolution pattern depending on how flow is organized within the discrete network if a channelized structure occurs in the flow network the dissolution pattern depends highly on the initial hydrogeological settings while if the flow network consists of branched segments a similar dissolution pattern emerges for a broad range of initial hydrogeological settings when the flow direction is normal to the persisting fracture orientation intermittent interruptions to the positive feedback process between flow and dissolution occur therefore the breakthrough is delayed we discuss the link between our results of dissolution modeling in fracture networks to previous modelling efforts in the context of single rough fractures and fracture network formed by orthogonal fracture sets keywords discrete fracture network karst network topology reactive flow 1 introduction fluid flow in karstified limestone rocks is highly heterogeneous and often exhibits hierarchical structures the majority of flow in a karstic aquifer is often focused along a few highly transmissive conduits which are created by the dissolution of discrete pathways of a proto fracture network consisting of fractures and bedding planes the generation and evolution of karstic conduits is governed by a positive feedback mechanism conduits carrying a higher flow experience a higher growth of aperture size the increased aperture in turn leads to less flow resistance thus attracting more flow from neighboring regions hanna and rajaram 1998 szymczak and ladd 2006 this competition process operates from dissolutional water entering the rock mass until one preferentially enlarged conduit emerges in the past several speleogenesis models that simulate the positive feedback mechanism between dissolution and flow have been proposed to understand the early stage evolution of karstic conduits in carbonate rocks dreybrodt 1990 and dreybrodt et al 1996 first proposed a one dimensional conduit model to investigate the evolution of caves from initially narrow conduits lauritzen and odling 1992 investigated the conduit growth in two dimensional conduit networks exhibiting regular patterns the numerical approach was further extended by groves and howard 1994 to include the effect of turbulent flow these conduit network models have been used to understand how hydrogeological and hydrochemical conditions such as recharge discharge type and mixing criteria influence the breakthrough time aperture evolution and dissolution pattern e g gabrovšek and dreybrodt 2000 romanov et al 2003 hubinger and birk 2011 matrix flow has also been coupled to the conduit network models to investigate the potential effect of exchange flow between conduits and matrix on the growth of karstic conduits liedl et al 2003 kaufmann and braun 2000 in these studies the dissolution process was simulated on predefined conduit networks the networks represent the initial flow paths composed by interconnected fractures and or bedding planes before the initiation of the karstification process since previous authors focus was primarily on gaining insights into the physical processes of conduit development the geometrical configuration of their models is often highly hypothetical and simple however it should be noted that the structural heterogeneities induced by network geometries may have a significant impact on the karstification process since they strongly influence solute transport ronayne 2013 borghi et al 2016 in previous modelling work the aquifer heterogeneities are typically introduced into existing speleogenesis models either by mapping variable hydraulic properties onto a network consisting of two orthogonal fracture sets e g gabrovšek et al 2004 dreybrodt et al 2007 or by adopting an incompletely filled lattice grid siemers and dreybrodt 1998 with these synthetically generated structures some geometrical properties of natural fracture networks such as the length and intensity may be preserved however the distinctive topology exhibited by natural systems is largely omitted in previous studies one exception is the numerical model of kaufmann and braun 1999 since unstructured grids were adopted it was possible to model the karstification process on irregular proto conduit networks with more realistic connectivity properties however the authors only simulated the development of karstic conduit networks in simple synthetic models and did not investigate the role of network topology in the evolution of conduit networks in general the rock properties are not only controlled by geometrical properties but also by topological properties of the fracture networks zimmerman and main 2003 depending on how fractures are spatially organized two fracture networks that contain the same geometrical elements may have very different connectivities and thus different flow patterns sanderson and nixon 2015 the complex connectivity of the fracture networks may cause significant flow channeling tsang and neretnieks 1998 this phenomenon of flow localization has not been captured in the flow models of previous speleogenesis studies based on simple fracture patterns a channelized flow pattern implies a long range correlation structure in the flow field the growth rate of a preferential flow channel will be much higher at the initial time and will be progressively accelerated by capturing flow from neighboring flow paths of slower flow hanna and rajaram 1998 szymczak and ladd 2006 comparing to the randomly distributed flow fields considered in previous speleogenesis models a channelized flow structure would lead to a highly uneven dissolution front and could potentially reduce breakthrough times another topological parameter that may influence the dissolution process is the type of fracture contacts such as the abutting or cross cutting relationship at fracture intersections the fracture contact type determines the coordination numbers of fractures which controls flux solute mixing and redistribution at the intersections kupper et al 1995 park et al 2001a berkowitz et al 1994 the regular lattice networks widely used in previous speleogenesis simulations contain only intersections with a coordination number of four however in natural fracture networks abutting connections are more prevailing pollard and aydin 1988 renshaw and park 1997 davy et al 2013 most fracture intersections may have coordination numbers less than four park et al 2001b this implies performing dissolution simulations in natural fracture networks is not a trivial extension of previous investigations based on regular grids instead it may provide new insights into the development of incipient karst in natural systems in this work we aim to provide a closer examination of the influence of the topology of natural fracture networks on karst evolution in carbonate rocks our geological model was constructed based on a field fracture pattern mapped from limestone outcrops the fracture network consists of a persistent joint set and a set of subsequently formed cross joints that abut the persistent ones the abutting relationship is a representative topological feature that is commonly observed in natural joint networks given such a network topology contrasting structures of flow fields form when the flow direction is parallel or perpendicular to the long fracture set the anisotropic flow structures allow us to gain insights into the effect of natural network topology on the dissolution process in limestones our numerical models account for the key features of the coupled physical chemical processes that govern dissolution of limestone fractures namely the positive feedback mechanism we have focused on the initial phase of karst evolution thus our simulations were terminated at the breakthrough time which is defined as the time at which turbulent flow first occurs anywhere within the computational domain 2 methodology 2 1 fracture network the fracture network used in our simulations is a natural fracture pattern in triassic limestone beds located at kilve on the southern margin of the bristol channel basin uk fig 1 the geometry is two dimensional and in plan view so that gravitational forces are not considered the fracture network consists of two well connected major sets an e w striking set containing through going fractures long set and a n s striking formed by small joints that abut the e w fractures short set the emergent ladder pattern represents a typical hierarchical morphology of natural joint networks pollard and aydin 1988 fig 1b the fracture pattern has been used extensively for numerical simulations of single and multi phase flow and transport in fractured reservoir analogues matthäi and belayneh 2004 belayneh et al 2006 geiger boschung et al 2009 matthäi et al 2010 geiger and emmanuel 2010 to focus on the geometric effect we assume the initial aperture of the fracture network is constant in space simulations were carried out with five different aperture values 0 09 mm 0 10 mm 0 12 mm 0 13 mm and 0 14 mm only an area of 8 8 m2 on the right side of the full pattern fig 1a was chosen as the input network to our simulations for the sake of expediency in comparison of results obtained for the x and y directions the distinct topology structure of the ladder pattern leads to significant flow anisotropy and therefore different flux distribution in the two directions 2 2 reactive transport model the incipient karst generation in fracture networks is modelled as a coupled process of flow transport of ca2 and dissolution enlargement of fracture aperture the process is simulated using a finite difference technique based on a resistor network odling and webman 1991 fig 1c flow through the system is assumed to occur only in fractures the fracture network is discretized by linear segments the aperture of each segment is assigned independently the local flow velocities are calculated from assigned apertures using the poiseuille equation for laminar flow through parallel plates as follows zimmerman et al 1991 1 v a 2 12 μ h where v is the flow velocity a is the hydraulic aperture h is the hydraulic head and μ is the dynamic viscosity of the fluid the fracture flow in the numerical grid is solved by invoking the condition of flow conservation assuming the fluid is incompressible fig 1c at each grid node as 2 q in q out 0 where q in and q out represent the rate of fluid flow into and out of the node respectively the reactive transport model considers the rock fluid dissolution effect and the evolution and transport of dissolved species during fluid flow diffusion is only considered within the fracture aperture between the fracture wall and the main flow stream when the fluid passes through a segment due to the dissolution of fracture walls the concentration increases by 3 δ c r c q δ t where r c is the reaction rate q is the flow rate and δ t is the time interval the reactive transport problem in the channel network is solved by assuming mass conservation at the nodes where multiple segments are connected we assume complete mixing of solution at the nodes in the network configuration shown in fig 1c the concentration of the central node c 0 is calculated by a flux weighted formula 4 c 0 c 3 δ c 3 0 q 3 0 c 4 δ c 4 0 q 4 0 q 3 0 q 4 0 where c 3 and c 4 are concentrations at the surrounding nodes that transfer fluids to the central node c 0 δ c 3 0 and δ c 4 0 are the concentration increments when the fluids flowing from nodes 3 and 4 to the central node 0 q 3 0 and q 4 0 are the corresponding flow rates along the two branches the dissolution of limestone is controlled by two serial steps 1 surface reaction and 2 transport of ca2 into the main flow stream by diffusion the slower process determines the overall reaction rate when the aperture is small the surface reaction is the rate limiting process in this case the reaction rate is expressed by palmer 1991 dreybrodt et al 1996 5 r c k 1 c eq c where k 1 is the reaction kinetics ceq is the concentration at saturation and c is the concentration although other high order kinetic laws which have been applied in previous numerical studies can be readily implemented to model the trigger mechanism white 1977 we consider that the linear kinetic mechanism is sufficient for our modeling purposes also szymczak and ladd 2011 has demonstrated that the high order kinetics is not a prerequisite for generating extended conduits if a two dimensional model is used when the aperture is large the dissolution rate is limited by diffusion the mass transfer rate is determined using the following expression incropera and dewitt 1990 6 r c dsh a c eq c where d is the molecular diffusion coefficient for ca2 in water a is the fracture aperture sh is the sherwood coefficient and c eq is the calcium saturation equilibrium concentration the concentration c for a segment is approximated by the mean of the concentrations of inlet and outlet nodes in our simulations we use d 6 73 10 10 m2 s 1 dreybrodt 1990 sh 8 for laminar flow szymczak and ladd 2011 and ceq 2 mol m 3 dreybrodt et al 1996 by assuming the dissolved mass is evenly distributed over a sufficiently short segment of length l the amount of aperture growth can be calculated from 7 δ a δ c q δ t ρ r l where ρ r 2 7 109 mg m 3 is the density of rock material 2 3 characterization of karst network evolution the uneven propagation of the dissolution front within the fracture network is quantitatively characterized by the temporal evolution of the correlation dimension of the flow rate d 2 q d 2 corresponding to i 2 of generalized fractal dimension d i which is defined as cowie et al 1995 bonnet et al 2001 6 d i lim l 0 l o g k 1 m p k i log l where i is the fractal moment p k is the proportion of a measure within a grid element to the cumulative amount of the measure in the grid l is the dimension of the grid elements in general multifractal measures give the distribution of a physical quantity on a geometric support feder 1988 bonnet et al 2001 the principle of calculating the fractal dimension is demonstrated in fig 2 in this work we use a 20 by 20 square grid in our calculation of d 2 thus l equals to 0 4 m see section 2 1 for model dimension p k corresponds to spatial distribution of flow rate within each grid the correlation dimension has been used previously for quantitative analyses of the heterogeneous spatial distribution of fault patterns davy and cobbold 1991 sornette et al 1994 and fault displacements cowie et al 1995 as well as degree of flow channeling sanderson and zhang 1999 bruderer weng et al 2004 wang et al 2017 once the karstification process starts the value of d 2 q would drop progressively due to enhanced flow focusing created by the formation of a few karstic conduits of favored dissolution the shape of a d 2 q curve may provide further quantitative information regarding the competition process during the course of incipient karst generation in general d 2 q should decrease monotonically however an increase of d 2 q may occur in specific cases under a fixed hydraulic gradient the lowest point of a d 2 q curve occurs when the first developed karstic conduits arrive to the outlet after this event if the total flow is small d 2 q is expected to increase due to the sudden pressure drop in the developed karstic conduit which leads to reflux of dissolutional fluid into other immature flow paths to enable their further growth this reflux process may lead to a more uniform flux distribution therefore a higher d 2 q value 3 numerical implementation the reactive transport model eqs 1 5 is solved using the finite difference method each of the interconnected fracture segments in the network is subdivided into small elements of maximum length of 0 1 m unlike previous work on dissolution in single fractures e g hanna and rajaram 1998 upadhyay et al 2015 cheung and rajaram 2002 and a network of orthogonal fracture sets groves and howard 1994 gabrovšek et al 2004 an exact uniform spatial discretization cannot be applied due to the unequal length of natural fractures instead we apply an average element length of 0 05 m in the global discretization so that the number of elements per fracture segment is calculated through dividing the segment s length by the average element length an extra finer discretization dx 0 01 m is adopted for the segments within the first 0 1 m from the inlet to avoid numerical saturation groves and howard 1994 this spatial discretization is sufficient to spread about ten nodes over the initial penetration length l p to capture the rapid variation of the concentration field upadhyay et al 2015 in all flow simulations presented in this paper the inlet and outlet of the study domain are assigned constant hydraulic heads while no flow conditions are assumed for the two orthogonal boundaries a constant head boundary is reasonable for early stage evolution of karst aquifers where flow rates in the system are smaller than the recharge rate palmer 1991 for the reactive transport simulations a zero concentration of ca2 is assumed at the inflow boundary a quasi stationary approximation is adopted to simulate the coupled processes of dissolution and flow hanna and rajaram 1998 dreybrodt and gabrovšek 2018 based on the initial aperture field the steady state flow and concentration fields as well as reaction rates are computed over a dissolution time step the aperture field is modified based on the reaction rate when calculating the aperture growth it is assumed that the amount of dissolved calcite is evenly distributed that is no aperture variation is considered over a single segment the process is repeated until breakthrough or turbulent flow occurs the detection of turbulent flow is based on the first occurrence of a reynolds number 2100 in any fracture segments within the domain according to the local flow velocity and hydraulic aperture appropriate time steps dt 0 01 year for x direction simulations and dt 0 1 year for y direction simulations were found by a preliminary sensitivity analysis further reduction in time step does not lead to a significant change in the dissolution pattern and breakthrough time 4 results simulations of dissolution in fracture networks with natural geometrical and topological characteristics presented in section 2 1 have been carried out using the reactive transport model described in section 2 2 because we aim to gain insight into the controlling effect of structural heterogeneities on the dissolution pattern in real fracture networks we have decided to focus on the three most fundamental and influential parameters reactive flow direction hydraulic boundary condition and initial fracture aperture 4 1 influence of flow direction fig 3 shows distributions of flow rate and fracture aperture at the breakthrough time for speleogenesis simulations in the x and y directions when flow occurs in the x direction enhanced dissolution is restricted to a few through going fractures in the flow direction before breakthrough the developed karst conduits are predominately linear features fig 3b and c branching features were observed on the longest conduit near the outlet boundary in contrast when flow is in the y direction the dissolution pattern is very branched and the development of each conduit in the direction transverse to flow is largely enhanced fig 3e and f the range of aperture variability of the karst conduits is reduced to less than one order of magnitude fig 3e fig 4 shows a plot of the correlation dimension of flow rate d 2 q versus time t for dissolution simulations along x and y directions as presented in fig 3 before the initiation of conduit growth d 2 has a high value close to 2 fig 4 the discrepancy from 2 is caused by the incomplete filling of flow in two dimensional space due to the presence of structural heterogeneity the distinctive shape of the two d 2 curves presented in fig 4 highlights the impact of the network topology on the incipient karst generation first the breakthrough time of the transport simulation in the x direction is much shorter than that in the y direction note the logarithmic time scale of fig 4 second the d 2 curves of the two flow directions exhibit distinctive evolution paths indicating different competition mechanism during the karst genesis process on the d 2 curve for the x direction simulation three regimes indicated by different slopes can be observed over the first four years the value d 2 stays high and only reduced slightly comparing to the value at the initiation of the karstification process during the second regime the d 2 value drops at a much higher rate in the last regime the decreasing rate of d 2 is the highest the d 2 value is close to 1 at the breakthrough confirming that only one conduit reaches to the outlet figs 3 and 4 the trend of gradually increased slope indicates a sustained competition procedure between various favored karstic conduits we found that the slope may relate to the number of competing candidates or the spacing between them in general a larger slope corresponds to less flow paths this point is further illustrated using a synthetic fracture network where the fracture aperture is modelled using a lognormal distribution fig a 1 see also appendix i for the model description the results for the y direction simulation exhibit a different behavior of evolution over a considerable time period more than sixty years the slope of the d 2 curve does not show a distinguishable difference until around eighty years the value of d 2 only drops of 0 1 in the last stage a quite rapid decrease of d 2 is observed in both cases the final stage of evolution corresponds to a highly hierarchical flow structure composed of a major flow path carrying the majority of the total flux a few secondary paths carrying highly reduced flux and numerous minor paths carrying negligible flux fig 3d 4 2 influence of hydraulic boundary condition with a fixed network geometry and initial fracture aperture a series of hydraulic gradients are created by fixing the outlet hydraulic head at 0 m and varying the inlet hydraulic head hin from 0 4 m to 1 0 m the flow distribution at the breakthrough time for the five tested models are shown in fig 5 for flow in the x and y directions respectively in the case of flow along the x direction when the hydraulic gradient is small fig 5 hin 0 4 m one preferential path develops at the upper part of the model other conduits stop to grow before reaching to the half length of the model domain as hin increases the dissolution is less localized along the major enlarged conduit the secondary conduits experience more enlargements and develop deeper into the domain fig 5 hin 0 6 m and 0 8 m when hin is increased to 1 0 m a second conduit at the bottom of the domain develops sufficiently and reaches the outlet at breakthrough the total flow is distributed along the two developed paths interestingly this second developed conduit does not show up in the simulations with smaller hin i e hin 0 4 m or 0 6 m as hin increases the downstream hydraulic boundary generates different impact on the conduit dissolution this can be seen quantitatively in fig 6 where the normalized concentration profile is plotted for the five hin cases the dashed line in fig 6a indicates the location where the outlet hydraulic boundary condition becomes important for the simulation with hin 0 4 m on the left side of the dashed line the undersaturation value remains high because only a few karstic conduits developed in that domain on the right side the averaged undersaturation value dropped considerably due to diffused dissolution caused by the outlet hydraulic boundary condition as the hydraulic gradient becomes larger the overall level of the undersaturation profile decreases the area of the diffused dissolution is increased indicated by smaller undersaturation values for higher hin values also the dissolution plume starts to develop at a smaller distance from the inlet the evolution of d 2 as shown in fig 7 further illustrates the influence of hin on karstic conduit development although the total initial flow rate is different in each of the simulations due to different hydraulic gradients being imposed the spatial distribution of initial fluxes is the same initially this is confirmed by the same initial d 2 value for the five models fig 7a however as the karstification process starts in the x direction the evolution of the flux distribution for different simulations follows distinct paths for the simulation model with hin 0 4 m the d 2 value remains high during a longer period before it drops when hin is increased the d 2 curve starts to decrease at an early time and its final value is well above 1 implying more than one conduit developed to reach the outlet fig 5 in contrast when the flow is along the y direction the number and location of developed conduits are insensitive to the change in hin fig 6 the normalized concentration profiles for the five hin cases are rather similar fig 7d also the evolution of d 2 curves is similar for the five cases fig 7b the only difference is how fast a curve drops to a certain value the d 2 curve of hin 1 0 m is only a horizontally stretched version of hin 0 4 m along the time axis overall the dissolution patterns resulted from y direction simulations are much simpler than that from x direction simulations in particular in the region near the outlet one marked characteristic of the y direction simulations is the presence of step features on the d 2 evolution curves these features are absent in the x direction results the origin of these features is linked to a particular flow structure which is discussed in detail in section 5 1 4 3 influence of initial aperture the hydraulic gradient was kept constant by fixing hin at 1 m the dissolution simulations were run for x and y directions for each aperture value fig 8 presents the results for dissolution simulations at the breakthrough time with flow in x top two rows and y bottom two rows directions the evolution of d 2 for the two scenarios of flow direction is given in fig 9 when flow is in the x direction the final dissolution pattern changes significantly when a 0 is altered the overall trend is that a larger initial aperture leads to a more complex dissolution pattern consisting of an increased number of conduits with more branches fig 8 row one this observation is consistent with previous findings of siemers and dreybrodt 1998 on an incompletely filled lattice grid when a 0 0 09 mm the most dissolved conduit is located in the upper part of the simulation domain while two other conduits located in the lower part of the domain also developed but they only penetrate to a limited distance less than the half length of the model domain when a 0 is increased to 0 10 mm and 0 11 mm the location of the most developed conduit remains unchanged but more branches at the downstream end were observed moreover the relative extent of the secondary dissolved paths increased significantly when a 0 is increased when a 0 0 12 mm the conduit located at 1 m above the lower model boundary develops and reaches the outlet however this path does not even show a potential to grow in the simulations with smaller a 0 e g a 0 0 09 mm and 0 10 mm the different dissolution behaviors were confirmed by the distinct shape of the evolution curve for d 2 at various a 0 fig 9a in the contrary the conduit growth in the dissolution simulations following the y direction exhibit a completely different response to the change in a 0 first the location where the main conduit develops remains similar across the tested range of a 0 fig 8 the only difference is the relative extent of growth of the secondary conduits initiated in the middle of the inlet boundary a higher a 0 results in a deeper growth of this conduit the similarity in conduit evolution may also been seen from fig 9b where the form of the d 2 evolution for various a 0 is highly similar in fact if the curves are scaled by the breakthrough time or by corresponding flow rates they would collapse to a single curve fig 9b in general the influence induced by the aperture variation is similar to that induced by changing hin figs 5 and 7 5 discussions 5 1 influence of network topology on incipient karst generation according to the positive feedback mechanism an intuitive expectation is that the location of developed karstic conduits should coincide with the shortest flow path whose resistance to flow is the least however after a careful comparison we obtained a rather interesting observation the enlarged conduits coincide with the shortest flow path only when the flow is in the y direction but not for the simulations with flow following the x direction cf fig 3 and fig 10 surprisingly the most developed conduit in the simulations with x direction flow does not even relate to any of the ten shortest paths fig 10a the different behaviors of karstic conduit evolution in the x and y directions is linked to the different topological characteristics of fractures which lead to different flow structures in fact two distinct characteristic flow organizations exist for the two scenarios of flow direction fig 11 when the main flow direction coincides with that of the long fracture set i e in the x direction the long fractures are the main paths for fluid flow while the short fracture set connecting multiple long fractures induces local flow exchange between the main flow paths it is this local exchange of fluid that generates a variability in concentration in the direction transverse to the long fractures although small the variability may significantly alter the preferential paths for further dissolution due to the presence of competition between neighboring flow paths hence the emergence of karst conduits depends not only on the initial settings but also strongly on the variability of the concentration field during the evolution the difference in the dissolution pattern of the simulations following the x direction may be attributed to the difference in the initial penetration length caused by a variety of hin and a 0 see appendix b for a detailed explanation in contrast when the main flow direction is aligned with that of the short fracture set i e in the y direction the major flow paths are formed by segments of both the short and long fracture sets when flowing through the fracture network the aggressive water must pass many t like junctions of fractures however there is significantly less local flow exchange between the developing karst conduits therefore less influence on the continued growth of a conduit generated by its connected neighbors it follows that the flow paths of least resistance to flow would be selected as the favored channel for karstification the network topology is also responsible for the delayed breakthrough and the generation of the step features on the d 2 evolution curves of the y direction simulations the periodic stabilization of d 2 implies intermittent interruptions to the positive feedback loop governing the karst genesis process to illustrate this phenomenon at each time step a distribution of flow change in each fracture segment is computed by subtracting the flow rate at the current time from the flow rate of the previous time the total flow change at that time step is computed by summing up the values of flow difference in all fracture segments of the network normalization of the simulation time by the breakthrough time is then applied to directly compare the datasets from simulations of the x and y directions fig 12 presents an example using the simulation model with a 0 0 09 mm and δh 1 m it can be seen that the two curves of total flow change evolve very different to breakthrough the evolution curve for the x direction simulation exhibit a smooth variation with time while the curve of the y direction simulation is characterized by abrupt fluctuations whose periodicity seems to associate with that of the occurrence of the step features fig 13 presents a series of distributions of flow rate change corresponding to different d 2 variation periods in the case of flow in the x direction high flow rate changes occur along the developed conduits fig 13a throughout the entire course of the evolution the increase of flow rate in all developing conduits is continued the only difference is that the magnitude of the flow rate increase is higher in longer conduits however when the dissolution simulation is performed in the y direction the flow rate variation in the enlarged conduits may switch between increasing and decreasing when passing through t like junctions fig 13b compare results of time 17 time 23 and time 28 namely the positive feedback process between flow and dissolution is intermittently interrupted in the leading conduit in this way the shorter conduits gain extra chance to grow and hence against the tendency of progressively enhanced flow localization into long conduits i e maintaining d 2 this explains also the delayed breakthrough of simulations in the y direction 5 2 relationship with lattice dissolution model and simple growth law model previous studies on conduit growth in fracture networks have performed on either a completely or partly filled lattice grid e g siemers and dreybrodt 1998 hubinger and birk 2011 or an orthogonal network formed by two persistent fracture sets that go through the model domain e g gabrovšek et al 2004 dreybrodt and gabrovšek 2018 bloomfield et al 2005 also performed dissolution simulations based on a lattice grid with a simple growth law which assume that the aperture growth is proportional to velocity to an exponent of 0 2 0 8 heterogeneities are introduced into these models through assigning variable apertures normally obeying an uncorrelated lognormal distribution to the fracture segments because the structured computational grid does not possess any structural heterogeneity the numerical models in general do not generate a flow field with long range correlations this means that the flows within the network are organized in a way similar to that presented in fig 11b thus one may expect that the emergent conduits may correspond to the few channels of shortest distances across the imposed hydraulic gradient in this case the dissolution model assumes simple growth laws may predict similar dissolution trajectory to that generated by physical based dissolution models this may explain the results of hubinger and birk 2011 which showed that on a lattice grid the enlargements of conduits create a bi mode aperture distribution despite whether a physically based or a simple growth model is adopted the similar mode of aperture distribution may be caused by similar dissolution trajectories developed when a hierarchical flow structure is absent fig 11b since the paths are similar the difference between the evolved aperture distribution of the two types of model is only quantitative not qualitative however the difference between the models based on physically based kinetics and on simple growth laws is expected to be significant for natural fracture networks where fracture flows are organized in a hierarchical manner following the complex network geometry fig 11a accordingly the dissolution model assumes simple growth laws may provide completely faulty characterizations we note that it is possible to reproduce a correlated flow field to some level in a lattice model through incomplete filling of the grid siemers and dreybrodt 1998 or superimposing a correlated permeability structure gabrovšek and dreybrodt 2000 however these models may significantly underrepresent the spatial distribution and organization of fractures in natural systems hence they may hinder our understanding of the physical mechanisms governing natural karstification processes when attempting to connect findings from numerical models to geological phenomena one must capture sufficiently the geometry and topology of geological structures 5 3 scaling of karstic conduit spacing it can be seen from the results shown in section 4 that the karstification process in the natural fracture network forms dissolution patterns that exhibit a general relation that the spacing between karstic conduits is proportional to the length of the karstic conduits figs 5 6 8 and 9 this is consistent with previous observations for wormhole formation in porous media hoefner and fogler 1988 and in single fractures szymczak and ladd 2009 this implies that the linear stability analysis szymczak and ladd 2011 is valid for characterizing the general dissolution mechanism in conduit networks our simulation results also show that the geological complexities may lead to a variation in the proportionality constant when channelized flow is due to structural heterogeneities i e simulations with reactive flux occurring in the direction of persistent fractures figs 5 and 8 top two rows an alteration in hydraulic gradient or initial fracture aperture may change the proportionality constant however its value still falls in the range between 1 and 2 which has been observed for single dissolving fractures upadhyay et al 2015 in contrast when flow channeling is absent i e simulations with reactive flux occurring in the direction of short fractures that abut the persistent fractures figs 5 and 8 bottom two rows the proportionality constant is not sensitive to a variation in initial model settings 5 4 limitations and perspectives in this paper we simulate incipient karst generation in a natural fracture pattern based on linear dissolution kinetics this is reasonable as in two dimensional dissolution models where flow focusing and competition between developing conduits are the most important mechanisms in driving conduit growth szymczak and ladd 2011 also we chose to perform our simulation in models with a square area fig 1 to ensure the dissolution stays within the regime where linear reaction kinetics dominate higher order kinetics may be required for high aspect ratio models in that case nonlinear kinetics are essential to sustain conduit growth as the competition between conduits focuses the majority of flow to a single conduit when it reaches to a distance proportional to the transverse model dimension our investigation is limited to the initial phase of karstification where the fluid flow is under the laminar flow condition to investigate the evolution of karst networks after the breakthrough time the nonlinear darcy weisbach flow law has to be solved dreybrodt 1988 alternatively we can adopt the full range pipe flow model to avoid switching between laminar and turbulent flow conditions swamee and swamee 2007 de rooij and graham 2017 the onset of turbulent flow would result in reduced flow rates in a given conduit kaufmann 2009 we have also limited our study to a small area of 8 m by 8 m the choice is made for the sake of efficiency while ensuring accuracy because a fine discretization 0 01 m for fracture segments near the inlet and 0 for the rest was adopted here the primary objective is to demonstrate the potential of the proposed model as an efficient approach to generate of realistic karstic conduit network overall the geomorphological properties of the enlarged conduits and the hierarchical structure of the conduit networks presented in this work is close to those that have been observed in nature the approach can be extended to larger scales to investigate evolution of karst catchments if reliable fracture data e g orientation density length and aperture of main fracture sets is available at the regional scale the boundary condition of fixed head gradient used in this work may still be valid at the initial stage as the development of karst conduit networks the drainage capacity of the system increases the karst system will switch from hydraulic to catchment control accordingly a numerical implementation of the switch from fixed head gradient to recharge flux boundary is required bauer et al 2005 de rooij and graham 2017 also a focused recharge is more appropriate than the distributive recharge boundary considered in the present work our two dimensional models can be regarded as a conduit network formed along a bedding plane by intersections of subvertical joints in the adjacent layers and the bedding plane we emphasize that they are significantly different from a quasi 3d model which is formed by a network of 2d vertical discrete fractures or by a uniform extrusion of our 2d network to the third dimension if fractures are modeled by 2d discrete planes even with a uniform aperture distribution an uneven dissolution front may quickly develop which then leads the conduit growth to a three dimensional process in that case a 3d discretization must be invoked similar to the contribution of kaufmann and braun 1999 and 2000 our simulation code may be adapted with the delaunay triangulation technique to generate an efficient computation mesh only along the fracture planes that are interconnected in 3d space other factors that will be considered in a future paper include aperture variability and stress condition 6 conclusion we have developed a reactive transport model for simulating incipient karst generation in two dimensions with discrete fracture networks we focused on investigating the influence of fracture network topology on the conduit evolution in our simulations a natural joint network that exhibit a ladder pattern was used as the geometrical model a sensitivity test was conducted for hydraulic gradient and initial fracture aperture for each configuration dissolution simulations were performed for two major flow directions following respectively the orientation of the two main fracture sets our results demonstrate that the heterogeneity induced by geometrical complexities may play a decisive role in the early stage of the karstification processes in fractured carbonate rocks when the flow is in the direction of the long persistent fracture sets which provide direct connection between the model inlet and outlet enhanced karstification occurs preferentially along the long fractures however the location of the main karstic conduits does not correspond to the shortest path across the model a change in hydraulic gradient and initial fracture aperture may significantly change the dissolution pattern in contrast when the flow is in the direction of the short fracture set that are arrested by the long fracture set the shortest path across the model is always selected as the favored stations for enhanced karstification the differences in the conduit evolution and the final dissolution pattern introduced by varying hydraulic gradient and initial fracture aperture are almost indistinguishable also intermittent interruptions to the positive feedback mechanism were observed when the flow direction is perpendicular to the orientation of the persistent fracture set as a consequence the occurrence of the breakthrough event is severely delayed our results highlight the important effect of network topology on the conduit evolution the proposed karstification model based on realistic fracture networks may be used to investigate the spatial relationship between tectonic structures and karst cavities and to understand the mechanism governing its formation which has important implications for production of groundwater and hydrocarbon resources in fractured carbonate reservoirs to make reliable designs for practical engineering applications the structural heterogeneities must be properly considered in reactive transport simulations declaration of competing interest none acknowledgement this work benefited from fruitful discussions within the framework of the karst observatory network www sokarst org initiative from the insu cnrs which aims to strengthen knowledge sharing and promote cross disciplinary research on karst systems as well as with qinghua lei during the preparation of this manuscript we thank three anonymous reviewers for their constructive comments which improve the quality of the paper appendix a to illustrate the possible relationship between the correlation dimension d 2 and the spacing of evolved karstic conduits we conduct a dissolution simulation on a 25 m by 25 m synthetic fracture model consisting of a 60 by 60 lattice grid the length of each fracture segment is 0 833 m the aperture field is modelled by a lognormal distribution with a mean of 0 3 mm and a standard deviation of 0 1 mm the left model boundary is assigned with a fixed head of 0 5 m the right model boundary is assigned with a fixed head of 0 m the two other boundaries are no flow boundaries other parameters used here are the same as in the models presented in section 4 fig a 1 presents the evolution of d 2 and several aperture distributions at different stages of the conduit evolution the evolution stages separated by the dashed lines are defined by different slopes of the d 2 curve it can be seen as the system evolves from the stage 2 via the stage 3 to the stage 4 the slopes of d 2 curve is successively increased examining the aperture fields a good correlation between the slope of the d 2 curve and the conduit spacing can be observed the stage 4 has the largest conduit spacing the conduit spacing of the stage 3 is smaller than that of the stage 4 but larger than that of the stage 2 in short a large slope of the d 2 curve corresponds to a large conduit spacing appendix b to illustrate the influence of hydraulic configuration on the evolution path of the system a dissolution simulation on a simple geometrical model consists of two long fractures interconnected by a short one fig b 1 a both fractures 1 and 2 will dissolve however due to the local flow exchange induced by fracture 3 the concentration profile along fracture 1 will be slightly lower than that along fracture 2 fig b 1b with a higher value of hin or a 0 a longer penetration length is formed a deeper penetration of undersaturated fluid leads to a larger difference between the concentration profiles in the two fractures near the fracture inlet compare the thin dashed line and thin solid line in fig b 1c this difference in concentration determines the relative difference in the growth rate of the two fractures and therefore the relative difference in the intensity of competition for flow operated by the positive feedback loop between the two fractures the larger the difference in concentration the more contrast in fracture growth the less competition between the fractures as time evolves the difference in concentration increases more rapidly with a short l p in comparison to a long l p fig b 1c this means that with a higher hin or a 0 value the required time for flow to focus in the developed conduits is longer i e the secondary conduits have a larger tendency to grow deeper appendix c supplementary data supplementary data to this article can be found online at https doi org 10 1016 j jhydrol 2019 05 082 appendix c supplementary data the following are the supplementary data to this article supplementary data 1 
6382,river bathymetry which is vital for accurate hydraulic modeling is not readily available at large scales because of the logistical difficulties in field surveys and uncertainties associated with remote sensing techniques several studies have explored the potential of conceptual models and interpolation algorithms to estimate bathymetry these models have certain underlying assumptions that limit their accuracy and widespread implementation this study aims to provide insights into the choice of bathymetric model for different hydraulic applications by analyzing the effect of different bathymetric models on hydraulic modeling under different geomorphologic and flow settings this study does not aim to reinforce the importance of bathymetry rather its objective is to identify the bathymetric properties that are critical to accurate estimation of different hydraulic outputs the study accomplishes its objectives by implementing three different bathymetric models with varying cost and efficiency at four sites with diverse bathymetric characteristics five hydraulic outputs namely wetted cross sectional area water surface elevation inundation extents velocity and shear are estimated at three characteristic low and high flows and the results from the four sites are grouped together to perform an unbiased and robust evaluation the performance of these models is evaluated using the best available bathymetric representation generated from detailed field surveys as a benchmark the results indicate that 1d flood modeling is somewhat insensitive to channel shape as long as the estimated shape reflects the channel storage accurately velocity and shear related applications should incorporate bathymetry that represent both the cross sectional area and channel thalweg accurately reaches with low sinuosity 1 5 or small width and depth can be modeled reasonably using simple geometric shapes whereas for larger streams interpolation of surveyed data along the thalweg or complex bathymetric models that account for river anisotropy are recommended keywords river bathymetry hydraulic modeling river channel morphology model flood inundation mapping hec ras channel geometry 1 introduction accurate representation of river bed topography commonly referred to as bathymetry plays a critical role in a variety of hydrologic and hydraulic applications including but not limited to flood modeling sediment transport quantifying nutrient exchanges and aquatic habitat mapping cook and merwade 2009 legleiter et al 2011 marcus and fonstad 2010 mckean et al 2009 stromberg et al 2007 most commonly bathymetry data are collected through ground surveys using total station in wadeable streams or gps equipped boat mounted surveying techniques in deep streams allouis et al 2010 bangen et al 2014 hostache et al 2015 however this bathymetry data collection approach is most suitable for small individual reaches and is not used for an entire stream network due to logistics cost and safety considerations allouis et al 2010 casas et al 2006 mckean et al 2014 2009 recently developed large scale bathymetry data collection methods including the bathymetric light detection and ranging lidar and spectral photogrammetry do not work for turbid turbulent or deep streams and rivers feurer et al 2008 kinzel et al 2013 2007 legleiter 2014 legleiter and overstreet 2012 pan et al 2015 due to the challenges associated with acquiring bathymetry data it is common to use alternative methods or models for estimating bathymetry for use in hydraulic or hydrologic analyses as summarized in table 1 some of these methods estimate bathymetry by assuming standard geometric shapes such as triangular trapezoidal or parabola for a river cross section grimaldi et al 2018 trigg et al 2009 whereas other methods use hydraulic and geomorphologic concepts to create more realistic bed topography bhuyian et al 2015 brown et al 2014 price 2009 in general the models that assume simple geometry shapes require less data and are computationally faster than the ones that use hydraulic or geomorphologic concepts altenau et al 2017 while these methods referred hereafter as bathymetry models provide a means to include bathymetry where there are no data they do have limitations for example bhuyian et al 2015 presented in table 1 modeled the river channel as a triangle and parabola to capture the effect of flow on the side slopes of the bank but this model did not incorporate in channel sedimentation processes similarly price 2009 proposed a bathymetry model to accurately estimate uniform river cross sections at upstream and downstream ends of a reach but this model did not capture topographic anisotropy in across the cross sections the development and applicability of bathymetric models is also limited by the availability of information on channel geometry such as depth width and slope for calibrating model parameters these estimates are obtained using either observed bathymetry bailly et al 2010 trigg et al 2009 or from publicly available data for example river centerline can be obtained from the national hydrography dataset nhd bjerklie 2007 dodov and foufoula georgiou 2004 van der most and hudson 2017 bank elevations can be obtained from digital elevation models dems grimaldi et al 2018 and depth information can be obtained from united states geologic surveys usgs stream gauging station measurements he and wilkerson 2011 merwade 2004 pan et al 2016 since this geometric information is site specific the model parameters calibrated for a specific river reach may not be spatially transferrable to other rivers especially those with different geomorphologic characteristics such as sinuosity stream order slope and width among others grimaldi et al 2018 this drastically limits the applicability of bathymetry models beyond the calibrated regions additionally when a particular bathymetric model is used for one study or reach it is unknown whether the same model will work for other reaches currently no studies exist that have tested the performance of bathymetric models across diverse river channels spatial scales flow conditions and hydraulic outputs this study aims to fill this gap by using multiple bathymetric models on different river reaches with varying geomorphologic characteristics to quantify the effect of different bathymetric representations on hydraulic outputs specifically this study aims to address the following research questions i how is a hydraulic simulation affected from different bathymetric representations at varying flow conditions ii what bathymetric properties such as shape size and area play a role in providing robust hydraulic outputs iii can simplistic bathymetric shapes adequately represent the channel geometry for accurately estimating hydraulic outputs several studies have already proven that incorporating bathymetry provides more accurate hydraulic simulations so the goal of this study is not to reinforce these past findings but to understand the sensitivity of key hydraulic attributes to different bathymetric representations under variable geomorphologic and flow settings it is expected that the results from this study will help in identifying bathymetric models that are not only simple and computationally efficient to apply but can also provide fairly accurate performances across different reaches i e spatially transferable at different flow conditions 2 study area and data description this study focuses on comparing bathymetric models with respect to their spatial transferability and applicability and therefore four river reaches three in indiana and one in texas with different geomorphic climatic and hydrologic characteristics are used fig 1 and table 2 the tippecanoe river in indiana the shortest and narrowest of the four reaches is a highly sinuous reach with a v shaped channel that flows through the urban city of winamac the tippecanoe river experienced widespread flooding due to a combination of rainfall and snowmelt during february 2018 the second reach st joseph river near elkhart in northern indiana has a u shaped channel with large variability in channel width ranging from approximately 50 m at the upstream end to about 400 m near the downstream end the st joseph river experienced severe flooding in 2008 2009 and 2018 the 20 km long east fork white river near bedford indiana is a major tributary of the wabash river the major river basin in indiana and is characterized by a deep channel with relatively flat floodplains with a few meanders across its length it is located in an agricultural setting with vegetation on both banks that serve as natural barriers during high flow conditions this river experienced historical flooding during the summer floods of indiana in 2013 the 60 km long brazos river reach in texas flows through an agricultural land and is characterized by a relatively shallow unbraided and clayey channel with a number of meanders and a flat floodplain due to recurring floods in the regions levees have been created around the river channel most recently this reach was inundated for days in the aftermath of hurricane harvey and the levees were breached at several locations jonkman et al 2018 bathymetry data are available in the form of point measurements obtained from boat mounted echo sounders and a hand held gps for all the study reaches the bathymetry datasets for the tippecanoe river st joseph river and east fork white river are obtained from the indiana water science center and that for brazos river are obtained from the texas water development board a boat mounted echo sounder has a vertical accuracy of 1 cm floodplain topography is represented in the form of lidar dems with a horizontal resolution of 3 m 10 ft the lidar dems for the indiana reaches are obtained from the indiana spatial data portal and the lidar dem for the brazos river is obtained from fort bend county in texas the vertical accuracy of lidar data used in this study is reported to be 15 cm 25 cm aguilar et al 2010 saksena and merwade 2015 bathymetric information is typically used for hydraulic modeling of extreme flows for flood mapping to bank full flows for aquatic organism passages aops and low flows to represent draught conditions therefore the bathymetric models used in this study are compared across a range of flows more specifically three characteristic low and high flows are selected for each reach some studies have denoted mean daily flow as the upper boundary of low flows smakhtin 2001 hence the three low flows adopted for this study are the 10th f1 25th f2 and 50th f3 percentile of daily flow the 10th percentile flow is used to characterize drought conditions while the 50th percentile flow provides an indication of the central tendency of the flow distribution on the other hand the flows corresponding to 2 year f4 10 year f5 and 100 year f6 return periods are chosen to compare models during high flow conditions bankfull flows generally correspond to flows with a return period of 1 to 2 years robinson 2013 saksena and merwade 2017a and are considered to be channel maintaining flows the 10 year flow is important for certain floodplain and ecological processes such as riparian exchange and transport of nutrients and sediments mahoney and rood 1998 rood et al 2005 stromberg et al 1993 the 100 year flow is often used in designing of hydraulic structures hydraulic design series number 5 2012 and for other regulatory purposes including flood risk management and insurance saksena and merwade 2017b sangwan and merwade 2015 each reach has a usgs streamflow gauge at the upstream end which is used to obtain the time series of daily mean flows and annual maximum flows the characteristic low flows are evaluated by fitting a lognormal distribution beard 1943 to the daily mean flow and estimating the 10th percentile f1 25th percentile f2 and 50th f3 percentile flows using the distribution similarly for the characteristic high flows a log pearson type iii distribution lpiii is fitted to the annual maximum flow time series as per bulletin 17b u s water resources council 1982 to obtain flow corresponding to 2 year f3 10 year f4 and 100 year f5 return periods table 3 shows the values of these six characteristic flows for the four reaches 3 bathymetry model description bathymetric models vary based on their computational efficiency implementation cost and scalability a computationally efficient model requires less computational time uses parameters that are obtainable from easily accessible data sources and is scalable across large reaches on the other hand the implementation cost includes the cost of surveying for evaluating model parameters and post processing of data which can vary depending on the scale and resolution at which the survey is carried out in this study four models with different metrics for implementation cost and efficiency are chosen for comparison 3 1 m1 low cost and high efficiency several studies have used simple geometric shapes such as parabola bhuyian et al 2015 rectangle neal et al 2015 trigg et al 2009 or triangle dodov and foufoula georgiou 2004 gichamo et al 2012 to represent channel bathymetry due to the low implementation cost and high efficiency therefore in this study a simple triangular channel shape is chosen m1 to incorporate this category of bathymetric models first the channel depth is interpolated linearly along the channel between the upstream and downstream end of the reach for m1 as shown in fig 2 second the channel thalweg location is estimated along the reach by relating it to the radius of curvature of the stream centerline using a power law function please refer to appendix or merwade 2004 for more details after identifying the thalweg location and digitizing the channel banks triangular cross sections at a specified distance along the channel are created finally profile lines are drawn in longitudinal direction to create a bathymetric mesh representing the triangular shaped channel while channel centerline and banks can be digitized using publicly available data the depths at upstream and downstream ends of the reach can be obtained either from usgs gauges or from regional regression equation in the absence of surveyed data robinson 2013 saksena 2015 therefore this model has a low cost and high efficiency unlike previous studies gichamo et al 2012 saleh et al 2012 m1 fits a triangular channel along the thalweg instead of the centerline it should be noted that a rectangular shape is not considered for m1 because of its inability to reflect the reduction in flow width and the meandering thalweg which are important at low flows neal et al 2012 additionally when incorporating a rectangular cross section studies have concluded that the area of the rectangular cross section should be the same as the observed cross section grimaldi et al 2018 trigg et al 2009 this requires the incorporation of surveyed cross sections into the model therefore increasing the cost and lowering the efficiency of the model 3 2 m2 low cost and moderate efficiency in this model bathymetry is generated by implementing rcmm a conceptual model that incorporates channel planform information such as channel thalweg and banklines using a linear combination of beta functions to generate a functional bathymetric surface as shown in fig 2 merwade 2004 more details about the development procedure are provided in appendix while the depth inputs to m2 are the same as m1 the computations are more intensive as the cross sections are determined using four parameters as highlighted in appendix therefore m2 is characterized as low cost but moderate efficiency 3 3 m3 moderate cost and moderate efficiency often bathymetric surveys are carried out across large distances tens to hundreds of kilometers to accommodate larger reach lengths while reducing survey cost to incorporate bathymetric surfaces generated from sparsely distributed surveys only surveyed cross sections located at the upstream and downstream ends of the reach are used to create m3 this is achieved by linearly interpolating between these two cross sections using a curvilinear reference system along the river centerline merwade et al 2008 since m3 requires two surveyed cross sections the cost of implementation increases to moderate when compared to m1 and m2 additionally significant pre processing is required to convert the surveyed points to cross sections which is difficult to implement at larger scales therefore its efficiency is rated as moderate comparing the performance of m3 with m1 and m2 can help in evaluating if there is a significant advantage in interpolating between sparsely distributed cross sections in the absence of high resolution surveyed cross sections for different reach lengths 3 4 control high cost and low efficiency control is created by linearly interpolating between all available surveyed cross sections in the reach using a curvilinear coordinate system along the centerline casas et al 2006 reported that the cost of a detailed bathymetric survey is 300 per hectare approximately 35 000 km2 the associated cost of this model is the highest because it requires multiple closely spaced surveyed cross sections along the reach which in turn also increases the extent of pre processing the associated logistics make it impractical for its implementation in large scale applications therefore this model has a low efficiency since control incorporates all available cross sections for a reach it is the most accurate bathymetric representation available therefore this model is used as a benchmark against which all other models are evaluated finally a lidar derived dem without any bathymetric information henceforth referred to as lidar is also included in the comparative analysis this dataset is included solely for quantifying the scale of improvement in hydraulic modeling after incorporating different bathymetric models in comparison to the scenario when lidar is used directly 4 methodology 4 1 bathymetric integration the output from all four bathymetric models is a 3d mesh representing the channel bathymetry which needs to be incorporated into lidar for a complete representation of the topography the 3d mesh is converted to points which are then interpolated using the natural neighbor technique to form a channel dem natural neighbor interpolation is used as it is reported to perform better compared to other techniques such as idw or spline for bathymetric datasets in cartesian coordinates merwade et al 2006 the channel dem is then mosaicked with lidar to create final dems for all models across all sites 4 2 hydraulic modeling hydraulic modeling for all configurations are performed using 1d hydrologic engineering center river analysis system hec ras brunner 2010 hec ras requires geometric description of the channel in the form of cross sections for performing hydraulic computations for a given reach same cross sections are used to extract the river geometry for all topography configurations using hec georas ackerman 2009 the manning s n and boundary conditions are extracted from previously calibrated hec ras models saksena 2015 saksena and merwade 2015 these are also kept the same across configurations for a given reach to ensure that the comparisons are consistent and the difference in outputs is solely due to the change in bathymetric representation hydraulic simulations in hec ras are performed with steady state assumption using the standard step energy method and normal depth downstream boundary condition for all six characteristic flow values table 3 hec ras estimates cross sectional average flow depth wse flow velocity and shear at each cross section wse estimates are then exported into arcgis using hec georas to create flood inundation maps 4 3 comparison of bathymetric representation and hydraulic outputs the errors in the bathymetric representation for m1 m2 and m3 are compared to control by calculating the mean absolute error mae as given in eq 1 1 mae σ i 1 n e m e r n where e m is the elevation of the i th cell for the dem being evaluated and e r is the elevation of the i th cell for control and n is the number of cells in the dem this comparison provides an overall estimate of the topographic characteristics of different models given the nonlinear nature of hydraulic modeling it is also important to evaluate the extent to which these errors propagate to the hydraulic outputs to evaluate the suitability of different bathymetric models for various hydraulic applications five hydraulic outputs are chosen for comparison including wetted cross sectional area wse inundation extent velocity and shear the hydraulic outputs generated at the cross sections for each of the bathymetric models are compared to the corresponding estimate generated using control by performing this comparison at all cross sections for all four sites and all six flows a total of 1176 data points 196 cross sections per flow 6 flows are generated for each of m1 m2 m3 and lidar evaluating the estimates across all cross sections sites and flows simultaneously ensures that the results encompass the variability across scales site characteristics and flows conditions this allows for a more generalized analysis and the conclusions drawn from such an analysis can be applied to other sites as well it should be noted that all four sites have approximately the same number of cross sections table 2 therefore grouping the results from all four sites does not bias the comparison towards any one site the estimates are compared against control using scatter plots the slope and coefficient of determination r2 of the fitted line indicate the performance of these models additionally the degree to which each bathymetric model improves the hydraulic output estimates over lidar is quantified using a new index bathymetric improvement efficiency bie which is given in eq 2 2 bie 1 σ i 1 n y i y i 2 σ i 1 n y lidar i y i 2 where y i is the value of a hydraulic output generated at the ith cross section for the bathymetric model being evaluated m1 m2 or m3 y i is the value generated at the ith cross section for the reference bathymetric model control y lidar i is the value generated at the ith cross section for original dem without any bathymetry incorporation lidar and n is the total number of observations this formulation is very similar to nash sutcliffe efficiency nse nash and sutcliffe 1970 except for the denominator where the mean of the observed values in case of nse is replaced by the sse of lidar generated estimate for bie this ensures that the performance of the bathymetric models are scaled between control and lidar similar to nse bie is also independent of scale and has a range of 1 a value of 1 corresponds to a bathymetric model whose performance is as good as control whereas a value of 0 corresponds to the case where incorporating bathymetry does not lead to any improvement in the accuracy of hydraulic output estimates negative values of bie indicate that incorporating bathymetry is in fact decreasing the accuracy of hydraulic estimates instead of improving them and lidar is a better estimate besides comparing different hydraulic variables using bie the flood inundation extent resulting from each bathymetric model is also compared using the f statistic as given in eq 3 3 f s t a t i s t i c a op a o a p a op 100 where a o is the observed inundation area inundation area of the reference model in this case a p is the modeled inundation area and a op is the area that is common to both observed and modeled inundation maps 5 results and discussion 5 1 comparison of cross sections and bathymetric dems all sites have different channel geometries and therefore the bathymetry cannot be estimated accurately using standard shapes such as a triangle parabola or rectangle across different rivers as presented in fig 3 for a typical cross section on each reach the tippecanoe river channel fig 3a is approximately triangular but all the other reaches do not have a specific geometric shape m1 and m2 provide reasonable approximations of the channel shape for all reaches but significantly underestimate the channel storage area 15 52 for m1 and 18 50 for m2 which is significantly more than those by m3 10 for all reaches except the tippecanoe river m3 s inability to model the in channel variations leads to highly erroneous cross sections for a highly sinuous reach such as the tippecanoe river where the m3 estimated cross section has an error of 49 as compared to 12 and 6 for m1 and m2 respectively in the case of the st joseph river fig 3b all three models underestimate the channel depth significantly 1 1 m 1 8 m since these models linearly interpolate the depth between the upstream and downstream ends of the reaches they fail to incorporate any sudden changes in the longitudinal slope of the channel overall m3 performs better at estimating the channel cross sectional area but produces erroneous channel geometry due to inability to accurately locate thalweg along the entire reach by just using surveyed cross sections at the upstream and downstream ends this is especially true when the surveyed cross sections are located at large distances for example in the case of east fork white river m3 estimates an approximately trapezoidal shape fig 3c which is different from control even though the cross sectional area for both the models are approximately the same in the case of brazos river the error due to incorrect thalweg location in m3 gets exacerbated even further and results in highly erroneous cross sections when compared to m1 and m2 the results suggest that the linear interpolation between the upstream and downstream cross sections in bathymetric models should be modified to incorporate the channel thalweg for more realistic predictions the cross sectional area for m1 and m2 does not match with control as shown by the underestimation of the cross sectional area of the channel however m2 has the ability to incorporate the channel variability across the stream better than m1 and m3 since the model parameters for m2 are evaluated based on the thalweg location which can change the channel shape a better approximation of bathymetry can be obtained by m2 if its parameters are calibrated using surveyed cross sections for individual reaches instead of relying on default model parameters and spatially transferring them onto another however this seems to be impractical for widespread application because of the limited availability of surveyed bathymetry data bathymetric dems generated using m1 m2 m3 and lidar are compared quantitatively by evaluating the site specific and overall mae with respect to control as shown in table 4 it is evident from the results that m1 has the lowest mae followed by m2 and m3 but m3 is closer to lidar than to m2 this reinforces the fact that the channel shape estimated using m3 is significantly different from control despite having a similar cross sectional area for example there is no overlap between the cross sections estimated by m3 and control for the brazos river fig 3d does this mean that m3 is the worst performing model among the three despite having higher cost and lower efficiency than m1 and m2 as the mae for different models is calculated using a cell by cell comparison of the dems the mae estimates fail to account for cases where two different bathymetric configurations have similar attributes such as channel storage and average depth but do not have the same thalweg and channel shape also mae and other such metrics such root mean square error and sse are scale dependent therefore a smaller reach such as the tippecanoe river has lower mae for all models as compared to a large reach such as the brazos river therefore mae may not be indicative of the relative performance of the models across different reaches the results from this section highlight the site specific variability in the model performance and suggest that bathymetric models that incorporate channel thalweg can capture geometric variability better while models that incorporate surveyed cross sections predict the channel cross sectional area or available storage more accurately for example despite having a higher mae fig 3 indicates that m3 estimates the total channel storage more accurately whereas m1 and m2 have lower elevation errors due to accurate thalweg incorporation since different elements of bathymetry such as thalweg location cross sectional area and channel shape can impact hydraulic modeling outputs differently which is presented in the following sections 5 2 comparison of wetted cross sectional area wse and inundation extent to analyze how bathymetric errors affect hydraulic simulations dems generated from different bathymetric models are used to simulate 1d steady state hydraulic models for all the reaches for six flows presented in table 3 the flow area estimates for six flows from all the bathymetric models across all sites are compared against control using scatter plots about the line y x fig 4 and bie table 5 fig 4a and b show that m1 and m2 have a tendency to over predict the flow area whereas m3 tends to under predict the flow area overall m3 has the highest r 2 value and its slope is closer to 1 when compared to m1 and m2 the results for flow area are synonymous to the findings from the previous section that show that m3 produces better estimates of the channel cross sectional area compared to m1 and m2 despite providing poor estimates of the overall channel shape and thalweg location from a hydraulic modeling perspective this result indicates that the total volume of water flowing across a unit length of the channel for a given flow rate is predicted accurately by m3 additionally the bie value also indicates that among the three models m3 leads to the highest improvement in flow area prediction when compared to lidar it is well known that the lidar configuration represents the channel bed as a flat line which is actually representative of the water surface in the reach when the lidar surveys are conducted therefore the channel storage of lidar is underestimated as demonstrated in fig 4 also the longitudinal slope of the channel is often underestimated because the slope of the water surface at the time of survey is usually less than the slope of the channel bed these biases propagate to hydraulic outputs leading to errors such as overestimation of inundation area and wse cook and merwade 2009 dey 2016 grimaldi et al 2018 saleh et al 2012 trigg et al 2009 the scatter plot fig 5 d clearly shows that many of the points lie far from the y x line 1 1 line which in turn leads to a high sum of square errors sse and reduces the r2 table 5 the results suggest that since m3 incorporates two surveyed cross sections at the upstream and downstream ends it tends to provide better estimates of flow area across all sites irrespective of the magnitude of flows these results are indicative of the invariability of channel cross sectional area across a single reach length even though the channel thalweg location and shape may change significantly therefore in applications that require estimating only flow area or available channel storage for example determining the change in channel conveyance due to dredging m3 may be more relevant than m1 and m2 however it should be noted that these results are only applicable for 1d hydraulic modeling and this may not be true for 2d hydraulic models or even unsteady state simulations the superior performance of m3 in predicting flow area also does not necessarily imply an improved estimation of other hydraulic variables since different channel shapes thalweg locations and flows can yield the same value for flow area therefore other hydraulic variables such as wse and inundation extent need to be analyzed to better assess the performance of the bathymetric models to remove the altitude effect and provide consistent comparison of model performance the effect of base reference elevation in wse is removed by subtracting the mean wse of each site from the individual wse s at that site across all cross sections and all flows and dividing the resultant by the standard deviation of all wse s at that location for a specific configuration this normalization is implemented for all configurations m1 m2 m3 lidar and control separately finally the normalized wse values for m1 m2 m3 and lidar are compared with control fig 5 shows the scatter plots of normalized wse estimated at all cross sections and across all flows for all sites table 5 provides the values of bie for each model the scatter plots show that m3 provides slightly better estimates of wse when compared to m1 and m2 indicated by the highest r2 however the slope about the line y x is close to 1 for all models indicating a good performance in estimating wse across all sites and flows both the slope and r 2 for the three models are significantly better than lidar which highlights the improvement after any type of bathymetric incorporation similarly m3 has a bie of 0 94 while m1 and m2 have a bie of 0 90 which further reinforces the fact that all three models lead to significant improvement in wse estimates when compared to lidar overall the performance of m3 is slightly better than that of m1 and m2 despite the fact that the dems generated using m3 have the highest mae table 4 these results suggest that in 1d hydraulic modeling accurate estimation of cross sectional area is more essential compared to thalweg location and channel shape which also results in more accurate wse prediction while wse may be directly correlated with flow area the inundation extents are also a function of the channel topography in addition to the flow area therefore inundation extents are generated for all flows and sites and evaluated against control using f statistic and bie for the three bathymetric models using the same principle of evaluating overall model performance across all sites and flows in a unified manner for the three bathymetric models box plots of f statistic for each model are generated and shown in fig 6 a the box plots highlight the large variability in the f statistic 26 to 98 across all models the median values suggest that m1 median f statistic 73 and m2 median f statistic 72 5 have similar performance while m3 median f statistic 77 has a slightly better performance than m1 and m2 additionally the range of variation in f statistic is also similar for the three models although m3 has a slightly wider range overall these results indicate that the accuracy of inundation extents does not vary significantly with choice of bathymetric models therefore in addition to wse the inundation extents are also less sensitive to the choice of bathymetric representation in the case of 1d hydraulic modeling this is further reinforced by the 10 year flood maps shown in fig 7 a all three flood maps show a good match with control and exhibit a significant improvement over lidar the fact that m2 is outperformed by m1 may indicate that the care should be taken when transferring conceptual models from one reach to another especially if the parameters of the model are calibrated on a reach with markedly different characteristics than the one in which it is to be implemented in order to further analyze the effect of channel characteristics on the performance of bathymetric models box plots of f statistic for each site across all model configurations are created as shown in fig 6b which clearly highlight the effect of reach scale and channel geometry on the performance of bathymetric models more specifically the highest estimated f statistic is 98 for the east fork white river at f6 a reach with low sinuosity while the worst performance across all models is reported at the brazos river for f1 where m1 m2 and m3 have f statistic values of 34 33 and 26 respectively the slightly wider range for m3 in fig 6a can be explained by the reduced performance at the brazos river for f1 the superior performance at the east fork white river is further demonstrated in the inundation extents for f3 shown in fig 7b all the models provide fairly accurate estimates of the inundation extent for this reach which shows that the choice of bathymetric model may not be critical for a reach with low sinuosity it is essential to note that the performance of the models is also dependent on the magnitude of flows this dependence on the magnitude of flow is further illustrated by the box plot for f statistic for each flow shown in fig 6c the box plot clearly shows that the performance of the models improves with increasing flow the median of f statistic increases from 58 in the case of f1 to 91 in the case of f5 before flattening out at 93 for f6 at low flows f1 f3 the entire volume of water is conveyed by the river channel therefore any error in channel bathymetry such as inaccurate channel storage thalweg location or shape impacts the inundation area significantly leading to more erroneous estimates as the magnitude of flow increases beyond bankfull flow water is conveyed by both the channel and floodplains since the floodplains are significantly wider compared to the river channels and have the same topography across all models the relative impact of the errors in channel bathymetry decreases as more water is routed through the floodplains this is especially true for small channels with flat and wide floodplains such as the east fork white river at high flows 100 year where inaccuracy in channel geometry becomes insignificant as more water is routed through the floodplains overall the bathymetric models perform accurately for both the tippecanoe river and the east fork white river with a slightly diminished performance for the st joseph river followed by the brazos river it should be noted that this comparison is also affected by the intrinsic inaccuracy of lidar for these sites which is highest for the brazos river in this regard the bie estimates for the three models shown in table 5 suggest that m3 0 96 has the highest improvement from lidar for inundation area closely followed by m1 0 95 and lowest for m2 0 91 it should also be noted that the tippecanoe river is the smallest of all four reaches with the smallest reach length average width and channel depth similarly the east fork white river is the second smallest reach geometrically and also has the smallest sinuosity thus these two reaches have the lowest variability in channel geometry along the reach lengths and therefore have the highest f statistic across all models and flows overall the results show that regardless of the bathymetric model used accurate prediction of channel storage or cross sectional area will lead to significant improvement in the prediction of hydraulic variables used for flood modeling therefore a simplistic low cost and high efficiency bathymetry model such as m1 can be implemented to generate flood maps with reasonable accuracy using 1d hydraulic modeling however the percentage of improvement is determinant on whether the bathymetric model incorporates channel variability in the form of thalweg location and channel shape therefore it does not matter what shape is burned into the lidar as a representation of bathymetry as the fundamental assumptions of 1d hydraulic modeling override the importance of channel characteristics this is especially true for creating flood inundation maps which involves simulating 1d hydraulic models for high flows 10 year return period the results from this study also indicate that the choice of bathymetric model becomes irrelevant at high flows for predicting hydraulic outputs essential for flood modeling such as wse flow area and inundation extents therefore 1d hydraulic models for high flows do not require incorporation of geometric variability in channels and even using a simple triangular or rectangular shape is sufficient for flood modeling purposes 5 3 comparison of velocity and shear estimates velocity and shear are two important hydraulic outputs that are crucial in sediment transport aop and contaminant transport most bathymetric models fit a functional surface to the river channel and neglect local variations in channel such as pools and riffles while these issues are not essential for mapping flood extents these inaccuracies may impact the flow velocity and the shear stress exerted on the river bed this section analyzes the performance of m1 m2 and m3 with respect to control in estimating the average velocity and shear at each cross section across all sites and flows similar to previous section scatter plots are created for velocity fig 8 and shear fig 9 estimates and the bie values are tabulated in table 5 the results for velocity suggest that the r2 values for all models are comparable but the slope indicates that m1 and m2 have a tendency to under predict the velocity while the slope of m3 is close to 1 this results follow a similar trend to that of flow area because the average velocity is a direct function of wetted cross sectional area for a given flow however the bie values indicate that m3 shows the least overall improvement over lidar among the three models on the other hand m3 has the highest r2 with a slope close to 1 as shown in fig 8 additionally as the channel storage is estimated accurately by m3 this directly results in more accurate flow area wse and inundation extents this raises a question as to why the performance of m3 is less accurate for velocity estimation even with accurate channel storage compared to control as indicated in section 5 1 this contradiction can be explained by the relative sensitivity of bie to individual erroneous observations compared to r2 or slope as shown in fig 8c there are a few observations near the y axis where m3 overestimates the velocity significantly the error induced due to these observations is in fact higher than lidar since bie penalizes these points more severely it leads to a lower value indicating that m1 may be a better model to estimate velocity this error in predicting velocity highlights the importance of accurately estimating the thalweg and channel shape in case of shear the results are contradictory to previous hydraulic variables as m1 has the best performance closely followed by m2 in fact both these models outperform m3 significantly when comparing the slope and r2 as shown in fig 9 a similar result is found from bie values which also suggest a superior performance for m1 followed by m2 with m3 having the lowest percentage of improvement from lidar among these three models the results for shear are indicative of its dependence on not only the flow area wetted cross sectional area but also the wetted perimeter since the wetter perimeter is a function of both the thalweg location sinuosity and channel shape wherein any two channels can have the same cross sectional area but completely differ in their wetted perimeters for a given wse even though m3 captures the channel storage more accurately m1 and m2 have better shear estimates since they incorporate the thalweg location in addition to being better at reflecting the channel shape this also indicates that the performance of m3 can be improved significantly if the upstream and downstream cross sections in m3 are interpolated along the channel thalweg instead of linearly interpolating along the channel centerline the bie values table 5 for shear are very high for all three bathymetric models even as the slope and r2 values suggest erroneous prediction due to the extremely poor performance of lidar fig 9 in estimating shear since bie signifies the overall improvement with respect to lidar all models tend to improve shear estimates significantly when compared to lidar the superior performance of m1 and m2 over m3 indicate that models that incorporate thalweg are better suited for applications involving shear estimates 6 summary and conclusion river bathymetry is critical to hydraulic modeling but is not readily available especially for large scale applications in the absence of high resolution field surveys and reliable remote sensing techniques interpolation based algorithms or bathymetry models are useful alternatives for estimating bathymetry this study analyzes the suitability of these bathymetric models with varying cost and efficiency for different hydraulic applications by comparing five hydraulic outputs wetted cross sectional area wse inundation extents velocity and shear these models are implemented at four reaches with varying bathymetric characteristics and the estimated values of the hydraulic outputs from all reaches are grouped together for a comprehensive and unbiased comparison the conclusions drawn from the study are as follows 1 flood modeling using 1d hydraulic models is insensitive to the choice of bathymetric model as long as the estimated channel incorporates the cross sectional area or channel storage accurately therefore models with standard shapes such as a triangle m1 are recommended even if they do not reflect the shape of the channel adequately 2 the accuracy of velocity and shear estimates depends on both the channel shape and channel storage as they are influenced by not only the wetted cross sectional area but also the wetted perimeter therefore applications involving velocity and shear estimation such as aop sediment transport contaminant transport among others should implement bathymetric models that represent both the cross sectional area and channel thalweg accurately in this regard using bathymetric models that are calibrated on reaches with similar characteristics or using surveyed data m2 on a different reach of the same river would be useful 3 the analyses showed that both simple model m1 and a relatively complex model m2 performed similarly when the channel thalweg was incorporated this indicates that thalweg must be incorporated in bathymetry when used for hydraulic modeling 4 linear interpolation along the channel centerline between large cross sections m3 can introduce considerable errors in thalweg location along the reach length which can also influence the channel shape therefore interpolation should preferably be implemented in a thalweg based curvilinear coordinate system rather than along the centerline thalweg can be estimated using regression based equations example rcmm used by m1 and m2 in data sparse regions similarly the cross sectional area of standard shapes m1 can be calibrated using rating curves available at usgs gauges and the intermediate bathymetry can be generated using linear interpolation based algorithm m3 5 the intrinsic inaccuracy of dems affect hydraulic modeling and needs to be taken into account when evaluating the applicability of bathymetric models bie scales the performance of the bathymetric dems with respect to the non bathymetric dems and is a useful index for quantifying the extent to which bathymetric incorporation improves hydraulic estimates 6 the reaches with low sinuosity 1 5 small width and depth were found to be less sensitive to type of bathymetric models in comparison to the reaches with high geometric variability large width and depth therefore small streams can be reasonably modeled using simple geometries whereas larger streams may need more complex models or surveyed data for accurate hydraulic modeling linearly interpolating sparsely surveyed datasets with surveyed cross sections at distances as large as 300 times the width can also perform reasonably for large streams 7 since all the models have similar performance for small or less sinuous reaches a low cost high efficiency model m1 is recommended for such reaches also given the low sensitivity of hydraulic modeling to bathymetric shapes at high flows a moderate cost moderate efficiency model m3 involving upstream and downstream cross sectional surveys can be preferred over a high cost low efficiency method involving dense cross sectional surveys control this can be especially useful for extending bathymetric surveys to large scale flood modeling 8 the performance of complex bathymetric model m2 is similar or sometimes slightly worse than a simple bathymetric model m1 this highlights the fallacies of validating a bathymetric model on limited number of reaches with similar characteristics and transferring such a bathymetric model to a reach with significantly different characteristics while it is expected that calibrating the model parameters for m2 on the same reach will lead to better estimates surveyed data is rarely available for calibration especially for large scale applications therefore future studies should aim to select reaches with significantly different geometric characteristics for a more robust model validation this study implements 1d steady state modeling for comparing the bathymetric models while it does provide useful insights that can provide guidance on the choice of bathymetric model the conclusions drawn here may not be completely valid for 2d hydraulic modeling additionally the bathymetric models in this study are applied to lidar derived dems which have a fairly accurate representation of the floodplains lidar derived dems are becoming popular but are not yet readily available everywhere therefore future studies could aim to expand their application to other dem sources such as the national elevation dataset ned which is available for the entire united states and the shuttle radar topography mission srtm which is available globally it is reasonable to expect that bathymetric incorporation will be even more essential for such dems because of the higher uncertainty associated with these dems the study is limited to single reaches of varying lengths which does not take into account the lateral inflows and headwater streams for large watersheds the importance of bathymetry maybe significant in estimating the channel beds of lower order streams that contribute to a larger network of rivers bathymetry estimation may have significant implications on hydrologic estimation of large storm events spanning across large watersheds with an increasing focus on large scale hydraulic modeling spanning entire watersheds de moel et al 2015 it is important to study the effect of bathymetry on hydraulic modeling at watershed scales spanning multiple reaches therefore future work should focus on developing a methodology for estimating bathymetry for entire river networks lastly the models compared in this study linearly interpolate the depth between the upstream and downstream while this may be reasonable for reaches with low variation in longitudinal profile this can introduce significant errors in channels with high variation in longitudinal slope such as those in mountainous regions depth is an important bathymetric attribute but is difficult to estimate in the absence of surveyed data in this regard remote sensing techniques can provide a potential avenue for estimating depth along a channel which in turn can improve bathymetry estimation further declaration of competing interest none acknowledgments we thank the editor dr corrado corradini the associate editor dr subashisa dutta the reviewer dr samir al gamal and one anonymous reviewer for providing constructive comments to revise the manuscript we would also like to thank ms kimberly peterson from the lyles school of civil engineering at purdue university for proof reading the final version of this manuscript appendix river channel morphology model rcmm is a conceptual model that estimates the channel topography using channel planform information for a detailed description please refer to merwade 2004 a meandering bend within a channel experiences sediment deposition on the inner bank and sediment erosion on the outer bank from the flowing water this leads to an asymmetric channel cross section with the thalweg being closer to the outer bank in a meander in relatively straight reaches within the river the thalweg approximately follows the centerline rcmm conceptualizes this physical process to create an empirical channel cross section in three steps in the first step the channel shape is standardized into a non dimensional space where both the channel width and depth are equal to unity in the second step the thalweg is located by using the radius of curvature of the channel centerline through a power law function eq a 1 a1 t a r b 0 5 r 2 0 r 2 where t is the thalweg location from the river centerline in normalized coordinate system where the width of the channel is unity r is the normalized radius of curvature of the centerline segment and a and b are parameters the parameters a and b can be calibrated for a river but calibration requires observed bathymetry data which is scarce in the third step the three points defined by two bank locations and the thalweg are then used to generate a cross sectional shape in the form of composite beta function using eq a 2 the parameters are estimated separately for different thalweg locations by least square regression of measured bathymetry data a2 z f n α 1 β 1 f n α 2 β 2 k where z is the depth estimate f n α 1 β 1 and f n α 2 β 2 are the two beta functions and k α 1 β 1 α 2 and β 2 are parameters that are dependent on the thalweg location in this study all rcmm parameters in eq a 1 and a 2 are estimated from bathymetry data available for a part of the brazos river reach and applied to all other reaches in the final step the normalized cross section width 1 and thalweg depth 1 is then rescaled using the bankfull width and depth at the corresponding cross section the bankfull depth for any cross section along a reach are determined by linearly interpolating the input provided by the user at the upstream and downstream locations of the reach the bankfull width is estimated from the banks which are manually digitized using areal imagery and dem the rescaled cross sections can be joined to create a 3d mesh which can then be used for creating the bathymetric dem 
6382,river bathymetry which is vital for accurate hydraulic modeling is not readily available at large scales because of the logistical difficulties in field surveys and uncertainties associated with remote sensing techniques several studies have explored the potential of conceptual models and interpolation algorithms to estimate bathymetry these models have certain underlying assumptions that limit their accuracy and widespread implementation this study aims to provide insights into the choice of bathymetric model for different hydraulic applications by analyzing the effect of different bathymetric models on hydraulic modeling under different geomorphologic and flow settings this study does not aim to reinforce the importance of bathymetry rather its objective is to identify the bathymetric properties that are critical to accurate estimation of different hydraulic outputs the study accomplishes its objectives by implementing three different bathymetric models with varying cost and efficiency at four sites with diverse bathymetric characteristics five hydraulic outputs namely wetted cross sectional area water surface elevation inundation extents velocity and shear are estimated at three characteristic low and high flows and the results from the four sites are grouped together to perform an unbiased and robust evaluation the performance of these models is evaluated using the best available bathymetric representation generated from detailed field surveys as a benchmark the results indicate that 1d flood modeling is somewhat insensitive to channel shape as long as the estimated shape reflects the channel storage accurately velocity and shear related applications should incorporate bathymetry that represent both the cross sectional area and channel thalweg accurately reaches with low sinuosity 1 5 or small width and depth can be modeled reasonably using simple geometric shapes whereas for larger streams interpolation of surveyed data along the thalweg or complex bathymetric models that account for river anisotropy are recommended keywords river bathymetry hydraulic modeling river channel morphology model flood inundation mapping hec ras channel geometry 1 introduction accurate representation of river bed topography commonly referred to as bathymetry plays a critical role in a variety of hydrologic and hydraulic applications including but not limited to flood modeling sediment transport quantifying nutrient exchanges and aquatic habitat mapping cook and merwade 2009 legleiter et al 2011 marcus and fonstad 2010 mckean et al 2009 stromberg et al 2007 most commonly bathymetry data are collected through ground surveys using total station in wadeable streams or gps equipped boat mounted surveying techniques in deep streams allouis et al 2010 bangen et al 2014 hostache et al 2015 however this bathymetry data collection approach is most suitable for small individual reaches and is not used for an entire stream network due to logistics cost and safety considerations allouis et al 2010 casas et al 2006 mckean et al 2014 2009 recently developed large scale bathymetry data collection methods including the bathymetric light detection and ranging lidar and spectral photogrammetry do not work for turbid turbulent or deep streams and rivers feurer et al 2008 kinzel et al 2013 2007 legleiter 2014 legleiter and overstreet 2012 pan et al 2015 due to the challenges associated with acquiring bathymetry data it is common to use alternative methods or models for estimating bathymetry for use in hydraulic or hydrologic analyses as summarized in table 1 some of these methods estimate bathymetry by assuming standard geometric shapes such as triangular trapezoidal or parabola for a river cross section grimaldi et al 2018 trigg et al 2009 whereas other methods use hydraulic and geomorphologic concepts to create more realistic bed topography bhuyian et al 2015 brown et al 2014 price 2009 in general the models that assume simple geometry shapes require less data and are computationally faster than the ones that use hydraulic or geomorphologic concepts altenau et al 2017 while these methods referred hereafter as bathymetry models provide a means to include bathymetry where there are no data they do have limitations for example bhuyian et al 2015 presented in table 1 modeled the river channel as a triangle and parabola to capture the effect of flow on the side slopes of the bank but this model did not incorporate in channel sedimentation processes similarly price 2009 proposed a bathymetry model to accurately estimate uniform river cross sections at upstream and downstream ends of a reach but this model did not capture topographic anisotropy in across the cross sections the development and applicability of bathymetric models is also limited by the availability of information on channel geometry such as depth width and slope for calibrating model parameters these estimates are obtained using either observed bathymetry bailly et al 2010 trigg et al 2009 or from publicly available data for example river centerline can be obtained from the national hydrography dataset nhd bjerklie 2007 dodov and foufoula georgiou 2004 van der most and hudson 2017 bank elevations can be obtained from digital elevation models dems grimaldi et al 2018 and depth information can be obtained from united states geologic surveys usgs stream gauging station measurements he and wilkerson 2011 merwade 2004 pan et al 2016 since this geometric information is site specific the model parameters calibrated for a specific river reach may not be spatially transferrable to other rivers especially those with different geomorphologic characteristics such as sinuosity stream order slope and width among others grimaldi et al 2018 this drastically limits the applicability of bathymetry models beyond the calibrated regions additionally when a particular bathymetric model is used for one study or reach it is unknown whether the same model will work for other reaches currently no studies exist that have tested the performance of bathymetric models across diverse river channels spatial scales flow conditions and hydraulic outputs this study aims to fill this gap by using multiple bathymetric models on different river reaches with varying geomorphologic characteristics to quantify the effect of different bathymetric representations on hydraulic outputs specifically this study aims to address the following research questions i how is a hydraulic simulation affected from different bathymetric representations at varying flow conditions ii what bathymetric properties such as shape size and area play a role in providing robust hydraulic outputs iii can simplistic bathymetric shapes adequately represent the channel geometry for accurately estimating hydraulic outputs several studies have already proven that incorporating bathymetry provides more accurate hydraulic simulations so the goal of this study is not to reinforce these past findings but to understand the sensitivity of key hydraulic attributes to different bathymetric representations under variable geomorphologic and flow settings it is expected that the results from this study will help in identifying bathymetric models that are not only simple and computationally efficient to apply but can also provide fairly accurate performances across different reaches i e spatially transferable at different flow conditions 2 study area and data description this study focuses on comparing bathymetric models with respect to their spatial transferability and applicability and therefore four river reaches three in indiana and one in texas with different geomorphic climatic and hydrologic characteristics are used fig 1 and table 2 the tippecanoe river in indiana the shortest and narrowest of the four reaches is a highly sinuous reach with a v shaped channel that flows through the urban city of winamac the tippecanoe river experienced widespread flooding due to a combination of rainfall and snowmelt during february 2018 the second reach st joseph river near elkhart in northern indiana has a u shaped channel with large variability in channel width ranging from approximately 50 m at the upstream end to about 400 m near the downstream end the st joseph river experienced severe flooding in 2008 2009 and 2018 the 20 km long east fork white river near bedford indiana is a major tributary of the wabash river the major river basin in indiana and is characterized by a deep channel with relatively flat floodplains with a few meanders across its length it is located in an agricultural setting with vegetation on both banks that serve as natural barriers during high flow conditions this river experienced historical flooding during the summer floods of indiana in 2013 the 60 km long brazos river reach in texas flows through an agricultural land and is characterized by a relatively shallow unbraided and clayey channel with a number of meanders and a flat floodplain due to recurring floods in the regions levees have been created around the river channel most recently this reach was inundated for days in the aftermath of hurricane harvey and the levees were breached at several locations jonkman et al 2018 bathymetry data are available in the form of point measurements obtained from boat mounted echo sounders and a hand held gps for all the study reaches the bathymetry datasets for the tippecanoe river st joseph river and east fork white river are obtained from the indiana water science center and that for brazos river are obtained from the texas water development board a boat mounted echo sounder has a vertical accuracy of 1 cm floodplain topography is represented in the form of lidar dems with a horizontal resolution of 3 m 10 ft the lidar dems for the indiana reaches are obtained from the indiana spatial data portal and the lidar dem for the brazos river is obtained from fort bend county in texas the vertical accuracy of lidar data used in this study is reported to be 15 cm 25 cm aguilar et al 2010 saksena and merwade 2015 bathymetric information is typically used for hydraulic modeling of extreme flows for flood mapping to bank full flows for aquatic organism passages aops and low flows to represent draught conditions therefore the bathymetric models used in this study are compared across a range of flows more specifically three characteristic low and high flows are selected for each reach some studies have denoted mean daily flow as the upper boundary of low flows smakhtin 2001 hence the three low flows adopted for this study are the 10th f1 25th f2 and 50th f3 percentile of daily flow the 10th percentile flow is used to characterize drought conditions while the 50th percentile flow provides an indication of the central tendency of the flow distribution on the other hand the flows corresponding to 2 year f4 10 year f5 and 100 year f6 return periods are chosen to compare models during high flow conditions bankfull flows generally correspond to flows with a return period of 1 to 2 years robinson 2013 saksena and merwade 2017a and are considered to be channel maintaining flows the 10 year flow is important for certain floodplain and ecological processes such as riparian exchange and transport of nutrients and sediments mahoney and rood 1998 rood et al 2005 stromberg et al 1993 the 100 year flow is often used in designing of hydraulic structures hydraulic design series number 5 2012 and for other regulatory purposes including flood risk management and insurance saksena and merwade 2017b sangwan and merwade 2015 each reach has a usgs streamflow gauge at the upstream end which is used to obtain the time series of daily mean flows and annual maximum flows the characteristic low flows are evaluated by fitting a lognormal distribution beard 1943 to the daily mean flow and estimating the 10th percentile f1 25th percentile f2 and 50th f3 percentile flows using the distribution similarly for the characteristic high flows a log pearson type iii distribution lpiii is fitted to the annual maximum flow time series as per bulletin 17b u s water resources council 1982 to obtain flow corresponding to 2 year f3 10 year f4 and 100 year f5 return periods table 3 shows the values of these six characteristic flows for the four reaches 3 bathymetry model description bathymetric models vary based on their computational efficiency implementation cost and scalability a computationally efficient model requires less computational time uses parameters that are obtainable from easily accessible data sources and is scalable across large reaches on the other hand the implementation cost includes the cost of surveying for evaluating model parameters and post processing of data which can vary depending on the scale and resolution at which the survey is carried out in this study four models with different metrics for implementation cost and efficiency are chosen for comparison 3 1 m1 low cost and high efficiency several studies have used simple geometric shapes such as parabola bhuyian et al 2015 rectangle neal et al 2015 trigg et al 2009 or triangle dodov and foufoula georgiou 2004 gichamo et al 2012 to represent channel bathymetry due to the low implementation cost and high efficiency therefore in this study a simple triangular channel shape is chosen m1 to incorporate this category of bathymetric models first the channel depth is interpolated linearly along the channel between the upstream and downstream end of the reach for m1 as shown in fig 2 second the channel thalweg location is estimated along the reach by relating it to the radius of curvature of the stream centerline using a power law function please refer to appendix or merwade 2004 for more details after identifying the thalweg location and digitizing the channel banks triangular cross sections at a specified distance along the channel are created finally profile lines are drawn in longitudinal direction to create a bathymetric mesh representing the triangular shaped channel while channel centerline and banks can be digitized using publicly available data the depths at upstream and downstream ends of the reach can be obtained either from usgs gauges or from regional regression equation in the absence of surveyed data robinson 2013 saksena 2015 therefore this model has a low cost and high efficiency unlike previous studies gichamo et al 2012 saleh et al 2012 m1 fits a triangular channel along the thalweg instead of the centerline it should be noted that a rectangular shape is not considered for m1 because of its inability to reflect the reduction in flow width and the meandering thalweg which are important at low flows neal et al 2012 additionally when incorporating a rectangular cross section studies have concluded that the area of the rectangular cross section should be the same as the observed cross section grimaldi et al 2018 trigg et al 2009 this requires the incorporation of surveyed cross sections into the model therefore increasing the cost and lowering the efficiency of the model 3 2 m2 low cost and moderate efficiency in this model bathymetry is generated by implementing rcmm a conceptual model that incorporates channel planform information such as channel thalweg and banklines using a linear combination of beta functions to generate a functional bathymetric surface as shown in fig 2 merwade 2004 more details about the development procedure are provided in appendix while the depth inputs to m2 are the same as m1 the computations are more intensive as the cross sections are determined using four parameters as highlighted in appendix therefore m2 is characterized as low cost but moderate efficiency 3 3 m3 moderate cost and moderate efficiency often bathymetric surveys are carried out across large distances tens to hundreds of kilometers to accommodate larger reach lengths while reducing survey cost to incorporate bathymetric surfaces generated from sparsely distributed surveys only surveyed cross sections located at the upstream and downstream ends of the reach are used to create m3 this is achieved by linearly interpolating between these two cross sections using a curvilinear reference system along the river centerline merwade et al 2008 since m3 requires two surveyed cross sections the cost of implementation increases to moderate when compared to m1 and m2 additionally significant pre processing is required to convert the surveyed points to cross sections which is difficult to implement at larger scales therefore its efficiency is rated as moderate comparing the performance of m3 with m1 and m2 can help in evaluating if there is a significant advantage in interpolating between sparsely distributed cross sections in the absence of high resolution surveyed cross sections for different reach lengths 3 4 control high cost and low efficiency control is created by linearly interpolating between all available surveyed cross sections in the reach using a curvilinear coordinate system along the centerline casas et al 2006 reported that the cost of a detailed bathymetric survey is 300 per hectare approximately 35 000 km2 the associated cost of this model is the highest because it requires multiple closely spaced surveyed cross sections along the reach which in turn also increases the extent of pre processing the associated logistics make it impractical for its implementation in large scale applications therefore this model has a low efficiency since control incorporates all available cross sections for a reach it is the most accurate bathymetric representation available therefore this model is used as a benchmark against which all other models are evaluated finally a lidar derived dem without any bathymetric information henceforth referred to as lidar is also included in the comparative analysis this dataset is included solely for quantifying the scale of improvement in hydraulic modeling after incorporating different bathymetric models in comparison to the scenario when lidar is used directly 4 methodology 4 1 bathymetric integration the output from all four bathymetric models is a 3d mesh representing the channel bathymetry which needs to be incorporated into lidar for a complete representation of the topography the 3d mesh is converted to points which are then interpolated using the natural neighbor technique to form a channel dem natural neighbor interpolation is used as it is reported to perform better compared to other techniques such as idw or spline for bathymetric datasets in cartesian coordinates merwade et al 2006 the channel dem is then mosaicked with lidar to create final dems for all models across all sites 4 2 hydraulic modeling hydraulic modeling for all configurations are performed using 1d hydrologic engineering center river analysis system hec ras brunner 2010 hec ras requires geometric description of the channel in the form of cross sections for performing hydraulic computations for a given reach same cross sections are used to extract the river geometry for all topography configurations using hec georas ackerman 2009 the manning s n and boundary conditions are extracted from previously calibrated hec ras models saksena 2015 saksena and merwade 2015 these are also kept the same across configurations for a given reach to ensure that the comparisons are consistent and the difference in outputs is solely due to the change in bathymetric representation hydraulic simulations in hec ras are performed with steady state assumption using the standard step energy method and normal depth downstream boundary condition for all six characteristic flow values table 3 hec ras estimates cross sectional average flow depth wse flow velocity and shear at each cross section wse estimates are then exported into arcgis using hec georas to create flood inundation maps 4 3 comparison of bathymetric representation and hydraulic outputs the errors in the bathymetric representation for m1 m2 and m3 are compared to control by calculating the mean absolute error mae as given in eq 1 1 mae σ i 1 n e m e r n where e m is the elevation of the i th cell for the dem being evaluated and e r is the elevation of the i th cell for control and n is the number of cells in the dem this comparison provides an overall estimate of the topographic characteristics of different models given the nonlinear nature of hydraulic modeling it is also important to evaluate the extent to which these errors propagate to the hydraulic outputs to evaluate the suitability of different bathymetric models for various hydraulic applications five hydraulic outputs are chosen for comparison including wetted cross sectional area wse inundation extent velocity and shear the hydraulic outputs generated at the cross sections for each of the bathymetric models are compared to the corresponding estimate generated using control by performing this comparison at all cross sections for all four sites and all six flows a total of 1176 data points 196 cross sections per flow 6 flows are generated for each of m1 m2 m3 and lidar evaluating the estimates across all cross sections sites and flows simultaneously ensures that the results encompass the variability across scales site characteristics and flows conditions this allows for a more generalized analysis and the conclusions drawn from such an analysis can be applied to other sites as well it should be noted that all four sites have approximately the same number of cross sections table 2 therefore grouping the results from all four sites does not bias the comparison towards any one site the estimates are compared against control using scatter plots the slope and coefficient of determination r2 of the fitted line indicate the performance of these models additionally the degree to which each bathymetric model improves the hydraulic output estimates over lidar is quantified using a new index bathymetric improvement efficiency bie which is given in eq 2 2 bie 1 σ i 1 n y i y i 2 σ i 1 n y lidar i y i 2 where y i is the value of a hydraulic output generated at the ith cross section for the bathymetric model being evaluated m1 m2 or m3 y i is the value generated at the ith cross section for the reference bathymetric model control y lidar i is the value generated at the ith cross section for original dem without any bathymetry incorporation lidar and n is the total number of observations this formulation is very similar to nash sutcliffe efficiency nse nash and sutcliffe 1970 except for the denominator where the mean of the observed values in case of nse is replaced by the sse of lidar generated estimate for bie this ensures that the performance of the bathymetric models are scaled between control and lidar similar to nse bie is also independent of scale and has a range of 1 a value of 1 corresponds to a bathymetric model whose performance is as good as control whereas a value of 0 corresponds to the case where incorporating bathymetry does not lead to any improvement in the accuracy of hydraulic output estimates negative values of bie indicate that incorporating bathymetry is in fact decreasing the accuracy of hydraulic estimates instead of improving them and lidar is a better estimate besides comparing different hydraulic variables using bie the flood inundation extent resulting from each bathymetric model is also compared using the f statistic as given in eq 3 3 f s t a t i s t i c a op a o a p a op 100 where a o is the observed inundation area inundation area of the reference model in this case a p is the modeled inundation area and a op is the area that is common to both observed and modeled inundation maps 5 results and discussion 5 1 comparison of cross sections and bathymetric dems all sites have different channel geometries and therefore the bathymetry cannot be estimated accurately using standard shapes such as a triangle parabola or rectangle across different rivers as presented in fig 3 for a typical cross section on each reach the tippecanoe river channel fig 3a is approximately triangular but all the other reaches do not have a specific geometric shape m1 and m2 provide reasonable approximations of the channel shape for all reaches but significantly underestimate the channel storage area 15 52 for m1 and 18 50 for m2 which is significantly more than those by m3 10 for all reaches except the tippecanoe river m3 s inability to model the in channel variations leads to highly erroneous cross sections for a highly sinuous reach such as the tippecanoe river where the m3 estimated cross section has an error of 49 as compared to 12 and 6 for m1 and m2 respectively in the case of the st joseph river fig 3b all three models underestimate the channel depth significantly 1 1 m 1 8 m since these models linearly interpolate the depth between the upstream and downstream ends of the reaches they fail to incorporate any sudden changes in the longitudinal slope of the channel overall m3 performs better at estimating the channel cross sectional area but produces erroneous channel geometry due to inability to accurately locate thalweg along the entire reach by just using surveyed cross sections at the upstream and downstream ends this is especially true when the surveyed cross sections are located at large distances for example in the case of east fork white river m3 estimates an approximately trapezoidal shape fig 3c which is different from control even though the cross sectional area for both the models are approximately the same in the case of brazos river the error due to incorrect thalweg location in m3 gets exacerbated even further and results in highly erroneous cross sections when compared to m1 and m2 the results suggest that the linear interpolation between the upstream and downstream cross sections in bathymetric models should be modified to incorporate the channel thalweg for more realistic predictions the cross sectional area for m1 and m2 does not match with control as shown by the underestimation of the cross sectional area of the channel however m2 has the ability to incorporate the channel variability across the stream better than m1 and m3 since the model parameters for m2 are evaluated based on the thalweg location which can change the channel shape a better approximation of bathymetry can be obtained by m2 if its parameters are calibrated using surveyed cross sections for individual reaches instead of relying on default model parameters and spatially transferring them onto another however this seems to be impractical for widespread application because of the limited availability of surveyed bathymetry data bathymetric dems generated using m1 m2 m3 and lidar are compared quantitatively by evaluating the site specific and overall mae with respect to control as shown in table 4 it is evident from the results that m1 has the lowest mae followed by m2 and m3 but m3 is closer to lidar than to m2 this reinforces the fact that the channel shape estimated using m3 is significantly different from control despite having a similar cross sectional area for example there is no overlap between the cross sections estimated by m3 and control for the brazos river fig 3d does this mean that m3 is the worst performing model among the three despite having higher cost and lower efficiency than m1 and m2 as the mae for different models is calculated using a cell by cell comparison of the dems the mae estimates fail to account for cases where two different bathymetric configurations have similar attributes such as channel storage and average depth but do not have the same thalweg and channel shape also mae and other such metrics such root mean square error and sse are scale dependent therefore a smaller reach such as the tippecanoe river has lower mae for all models as compared to a large reach such as the brazos river therefore mae may not be indicative of the relative performance of the models across different reaches the results from this section highlight the site specific variability in the model performance and suggest that bathymetric models that incorporate channel thalweg can capture geometric variability better while models that incorporate surveyed cross sections predict the channel cross sectional area or available storage more accurately for example despite having a higher mae fig 3 indicates that m3 estimates the total channel storage more accurately whereas m1 and m2 have lower elevation errors due to accurate thalweg incorporation since different elements of bathymetry such as thalweg location cross sectional area and channel shape can impact hydraulic modeling outputs differently which is presented in the following sections 5 2 comparison of wetted cross sectional area wse and inundation extent to analyze how bathymetric errors affect hydraulic simulations dems generated from different bathymetric models are used to simulate 1d steady state hydraulic models for all the reaches for six flows presented in table 3 the flow area estimates for six flows from all the bathymetric models across all sites are compared against control using scatter plots about the line y x fig 4 and bie table 5 fig 4a and b show that m1 and m2 have a tendency to over predict the flow area whereas m3 tends to under predict the flow area overall m3 has the highest r 2 value and its slope is closer to 1 when compared to m1 and m2 the results for flow area are synonymous to the findings from the previous section that show that m3 produces better estimates of the channel cross sectional area compared to m1 and m2 despite providing poor estimates of the overall channel shape and thalweg location from a hydraulic modeling perspective this result indicates that the total volume of water flowing across a unit length of the channel for a given flow rate is predicted accurately by m3 additionally the bie value also indicates that among the three models m3 leads to the highest improvement in flow area prediction when compared to lidar it is well known that the lidar configuration represents the channel bed as a flat line which is actually representative of the water surface in the reach when the lidar surveys are conducted therefore the channel storage of lidar is underestimated as demonstrated in fig 4 also the longitudinal slope of the channel is often underestimated because the slope of the water surface at the time of survey is usually less than the slope of the channel bed these biases propagate to hydraulic outputs leading to errors such as overestimation of inundation area and wse cook and merwade 2009 dey 2016 grimaldi et al 2018 saleh et al 2012 trigg et al 2009 the scatter plot fig 5 d clearly shows that many of the points lie far from the y x line 1 1 line which in turn leads to a high sum of square errors sse and reduces the r2 table 5 the results suggest that since m3 incorporates two surveyed cross sections at the upstream and downstream ends it tends to provide better estimates of flow area across all sites irrespective of the magnitude of flows these results are indicative of the invariability of channel cross sectional area across a single reach length even though the channel thalweg location and shape may change significantly therefore in applications that require estimating only flow area or available channel storage for example determining the change in channel conveyance due to dredging m3 may be more relevant than m1 and m2 however it should be noted that these results are only applicable for 1d hydraulic modeling and this may not be true for 2d hydraulic models or even unsteady state simulations the superior performance of m3 in predicting flow area also does not necessarily imply an improved estimation of other hydraulic variables since different channel shapes thalweg locations and flows can yield the same value for flow area therefore other hydraulic variables such as wse and inundation extent need to be analyzed to better assess the performance of the bathymetric models to remove the altitude effect and provide consistent comparison of model performance the effect of base reference elevation in wse is removed by subtracting the mean wse of each site from the individual wse s at that site across all cross sections and all flows and dividing the resultant by the standard deviation of all wse s at that location for a specific configuration this normalization is implemented for all configurations m1 m2 m3 lidar and control separately finally the normalized wse values for m1 m2 m3 and lidar are compared with control fig 5 shows the scatter plots of normalized wse estimated at all cross sections and across all flows for all sites table 5 provides the values of bie for each model the scatter plots show that m3 provides slightly better estimates of wse when compared to m1 and m2 indicated by the highest r2 however the slope about the line y x is close to 1 for all models indicating a good performance in estimating wse across all sites and flows both the slope and r 2 for the three models are significantly better than lidar which highlights the improvement after any type of bathymetric incorporation similarly m3 has a bie of 0 94 while m1 and m2 have a bie of 0 90 which further reinforces the fact that all three models lead to significant improvement in wse estimates when compared to lidar overall the performance of m3 is slightly better than that of m1 and m2 despite the fact that the dems generated using m3 have the highest mae table 4 these results suggest that in 1d hydraulic modeling accurate estimation of cross sectional area is more essential compared to thalweg location and channel shape which also results in more accurate wse prediction while wse may be directly correlated with flow area the inundation extents are also a function of the channel topography in addition to the flow area therefore inundation extents are generated for all flows and sites and evaluated against control using f statistic and bie for the three bathymetric models using the same principle of evaluating overall model performance across all sites and flows in a unified manner for the three bathymetric models box plots of f statistic for each model are generated and shown in fig 6 a the box plots highlight the large variability in the f statistic 26 to 98 across all models the median values suggest that m1 median f statistic 73 and m2 median f statistic 72 5 have similar performance while m3 median f statistic 77 has a slightly better performance than m1 and m2 additionally the range of variation in f statistic is also similar for the three models although m3 has a slightly wider range overall these results indicate that the accuracy of inundation extents does not vary significantly with choice of bathymetric models therefore in addition to wse the inundation extents are also less sensitive to the choice of bathymetric representation in the case of 1d hydraulic modeling this is further reinforced by the 10 year flood maps shown in fig 7 a all three flood maps show a good match with control and exhibit a significant improvement over lidar the fact that m2 is outperformed by m1 may indicate that the care should be taken when transferring conceptual models from one reach to another especially if the parameters of the model are calibrated on a reach with markedly different characteristics than the one in which it is to be implemented in order to further analyze the effect of channel characteristics on the performance of bathymetric models box plots of f statistic for each site across all model configurations are created as shown in fig 6b which clearly highlight the effect of reach scale and channel geometry on the performance of bathymetric models more specifically the highest estimated f statistic is 98 for the east fork white river at f6 a reach with low sinuosity while the worst performance across all models is reported at the brazos river for f1 where m1 m2 and m3 have f statistic values of 34 33 and 26 respectively the slightly wider range for m3 in fig 6a can be explained by the reduced performance at the brazos river for f1 the superior performance at the east fork white river is further demonstrated in the inundation extents for f3 shown in fig 7b all the models provide fairly accurate estimates of the inundation extent for this reach which shows that the choice of bathymetric model may not be critical for a reach with low sinuosity it is essential to note that the performance of the models is also dependent on the magnitude of flows this dependence on the magnitude of flow is further illustrated by the box plot for f statistic for each flow shown in fig 6c the box plot clearly shows that the performance of the models improves with increasing flow the median of f statistic increases from 58 in the case of f1 to 91 in the case of f5 before flattening out at 93 for f6 at low flows f1 f3 the entire volume of water is conveyed by the river channel therefore any error in channel bathymetry such as inaccurate channel storage thalweg location or shape impacts the inundation area significantly leading to more erroneous estimates as the magnitude of flow increases beyond bankfull flow water is conveyed by both the channel and floodplains since the floodplains are significantly wider compared to the river channels and have the same topography across all models the relative impact of the errors in channel bathymetry decreases as more water is routed through the floodplains this is especially true for small channels with flat and wide floodplains such as the east fork white river at high flows 100 year where inaccuracy in channel geometry becomes insignificant as more water is routed through the floodplains overall the bathymetric models perform accurately for both the tippecanoe river and the east fork white river with a slightly diminished performance for the st joseph river followed by the brazos river it should be noted that this comparison is also affected by the intrinsic inaccuracy of lidar for these sites which is highest for the brazos river in this regard the bie estimates for the three models shown in table 5 suggest that m3 0 96 has the highest improvement from lidar for inundation area closely followed by m1 0 95 and lowest for m2 0 91 it should also be noted that the tippecanoe river is the smallest of all four reaches with the smallest reach length average width and channel depth similarly the east fork white river is the second smallest reach geometrically and also has the smallest sinuosity thus these two reaches have the lowest variability in channel geometry along the reach lengths and therefore have the highest f statistic across all models and flows overall the results show that regardless of the bathymetric model used accurate prediction of channel storage or cross sectional area will lead to significant improvement in the prediction of hydraulic variables used for flood modeling therefore a simplistic low cost and high efficiency bathymetry model such as m1 can be implemented to generate flood maps with reasonable accuracy using 1d hydraulic modeling however the percentage of improvement is determinant on whether the bathymetric model incorporates channel variability in the form of thalweg location and channel shape therefore it does not matter what shape is burned into the lidar as a representation of bathymetry as the fundamental assumptions of 1d hydraulic modeling override the importance of channel characteristics this is especially true for creating flood inundation maps which involves simulating 1d hydraulic models for high flows 10 year return period the results from this study also indicate that the choice of bathymetric model becomes irrelevant at high flows for predicting hydraulic outputs essential for flood modeling such as wse flow area and inundation extents therefore 1d hydraulic models for high flows do not require incorporation of geometric variability in channels and even using a simple triangular or rectangular shape is sufficient for flood modeling purposes 5 3 comparison of velocity and shear estimates velocity and shear are two important hydraulic outputs that are crucial in sediment transport aop and contaminant transport most bathymetric models fit a functional surface to the river channel and neglect local variations in channel such as pools and riffles while these issues are not essential for mapping flood extents these inaccuracies may impact the flow velocity and the shear stress exerted on the river bed this section analyzes the performance of m1 m2 and m3 with respect to control in estimating the average velocity and shear at each cross section across all sites and flows similar to previous section scatter plots are created for velocity fig 8 and shear fig 9 estimates and the bie values are tabulated in table 5 the results for velocity suggest that the r2 values for all models are comparable but the slope indicates that m1 and m2 have a tendency to under predict the velocity while the slope of m3 is close to 1 this results follow a similar trend to that of flow area because the average velocity is a direct function of wetted cross sectional area for a given flow however the bie values indicate that m3 shows the least overall improvement over lidar among the three models on the other hand m3 has the highest r2 with a slope close to 1 as shown in fig 8 additionally as the channel storage is estimated accurately by m3 this directly results in more accurate flow area wse and inundation extents this raises a question as to why the performance of m3 is less accurate for velocity estimation even with accurate channel storage compared to control as indicated in section 5 1 this contradiction can be explained by the relative sensitivity of bie to individual erroneous observations compared to r2 or slope as shown in fig 8c there are a few observations near the y axis where m3 overestimates the velocity significantly the error induced due to these observations is in fact higher than lidar since bie penalizes these points more severely it leads to a lower value indicating that m1 may be a better model to estimate velocity this error in predicting velocity highlights the importance of accurately estimating the thalweg and channel shape in case of shear the results are contradictory to previous hydraulic variables as m1 has the best performance closely followed by m2 in fact both these models outperform m3 significantly when comparing the slope and r2 as shown in fig 9 a similar result is found from bie values which also suggest a superior performance for m1 followed by m2 with m3 having the lowest percentage of improvement from lidar among these three models the results for shear are indicative of its dependence on not only the flow area wetted cross sectional area but also the wetted perimeter since the wetter perimeter is a function of both the thalweg location sinuosity and channel shape wherein any two channels can have the same cross sectional area but completely differ in their wetted perimeters for a given wse even though m3 captures the channel storage more accurately m1 and m2 have better shear estimates since they incorporate the thalweg location in addition to being better at reflecting the channel shape this also indicates that the performance of m3 can be improved significantly if the upstream and downstream cross sections in m3 are interpolated along the channel thalweg instead of linearly interpolating along the channel centerline the bie values table 5 for shear are very high for all three bathymetric models even as the slope and r2 values suggest erroneous prediction due to the extremely poor performance of lidar fig 9 in estimating shear since bie signifies the overall improvement with respect to lidar all models tend to improve shear estimates significantly when compared to lidar the superior performance of m1 and m2 over m3 indicate that models that incorporate thalweg are better suited for applications involving shear estimates 6 summary and conclusion river bathymetry is critical to hydraulic modeling but is not readily available especially for large scale applications in the absence of high resolution field surveys and reliable remote sensing techniques interpolation based algorithms or bathymetry models are useful alternatives for estimating bathymetry this study analyzes the suitability of these bathymetric models with varying cost and efficiency for different hydraulic applications by comparing five hydraulic outputs wetted cross sectional area wse inundation extents velocity and shear these models are implemented at four reaches with varying bathymetric characteristics and the estimated values of the hydraulic outputs from all reaches are grouped together for a comprehensive and unbiased comparison the conclusions drawn from the study are as follows 1 flood modeling using 1d hydraulic models is insensitive to the choice of bathymetric model as long as the estimated channel incorporates the cross sectional area or channel storage accurately therefore models with standard shapes such as a triangle m1 are recommended even if they do not reflect the shape of the channel adequately 2 the accuracy of velocity and shear estimates depends on both the channel shape and channel storage as they are influenced by not only the wetted cross sectional area but also the wetted perimeter therefore applications involving velocity and shear estimation such as aop sediment transport contaminant transport among others should implement bathymetric models that represent both the cross sectional area and channel thalweg accurately in this regard using bathymetric models that are calibrated on reaches with similar characteristics or using surveyed data m2 on a different reach of the same river would be useful 3 the analyses showed that both simple model m1 and a relatively complex model m2 performed similarly when the channel thalweg was incorporated this indicates that thalweg must be incorporated in bathymetry when used for hydraulic modeling 4 linear interpolation along the channel centerline between large cross sections m3 can introduce considerable errors in thalweg location along the reach length which can also influence the channel shape therefore interpolation should preferably be implemented in a thalweg based curvilinear coordinate system rather than along the centerline thalweg can be estimated using regression based equations example rcmm used by m1 and m2 in data sparse regions similarly the cross sectional area of standard shapes m1 can be calibrated using rating curves available at usgs gauges and the intermediate bathymetry can be generated using linear interpolation based algorithm m3 5 the intrinsic inaccuracy of dems affect hydraulic modeling and needs to be taken into account when evaluating the applicability of bathymetric models bie scales the performance of the bathymetric dems with respect to the non bathymetric dems and is a useful index for quantifying the extent to which bathymetric incorporation improves hydraulic estimates 6 the reaches with low sinuosity 1 5 small width and depth were found to be less sensitive to type of bathymetric models in comparison to the reaches with high geometric variability large width and depth therefore small streams can be reasonably modeled using simple geometries whereas larger streams may need more complex models or surveyed data for accurate hydraulic modeling linearly interpolating sparsely surveyed datasets with surveyed cross sections at distances as large as 300 times the width can also perform reasonably for large streams 7 since all the models have similar performance for small or less sinuous reaches a low cost high efficiency model m1 is recommended for such reaches also given the low sensitivity of hydraulic modeling to bathymetric shapes at high flows a moderate cost moderate efficiency model m3 involving upstream and downstream cross sectional surveys can be preferred over a high cost low efficiency method involving dense cross sectional surveys control this can be especially useful for extending bathymetric surveys to large scale flood modeling 8 the performance of complex bathymetric model m2 is similar or sometimes slightly worse than a simple bathymetric model m1 this highlights the fallacies of validating a bathymetric model on limited number of reaches with similar characteristics and transferring such a bathymetric model to a reach with significantly different characteristics while it is expected that calibrating the model parameters for m2 on the same reach will lead to better estimates surveyed data is rarely available for calibration especially for large scale applications therefore future studies should aim to select reaches with significantly different geometric characteristics for a more robust model validation this study implements 1d steady state modeling for comparing the bathymetric models while it does provide useful insights that can provide guidance on the choice of bathymetric model the conclusions drawn here may not be completely valid for 2d hydraulic modeling additionally the bathymetric models in this study are applied to lidar derived dems which have a fairly accurate representation of the floodplains lidar derived dems are becoming popular but are not yet readily available everywhere therefore future studies could aim to expand their application to other dem sources such as the national elevation dataset ned which is available for the entire united states and the shuttle radar topography mission srtm which is available globally it is reasonable to expect that bathymetric incorporation will be even more essential for such dems because of the higher uncertainty associated with these dems the study is limited to single reaches of varying lengths which does not take into account the lateral inflows and headwater streams for large watersheds the importance of bathymetry maybe significant in estimating the channel beds of lower order streams that contribute to a larger network of rivers bathymetry estimation may have significant implications on hydrologic estimation of large storm events spanning across large watersheds with an increasing focus on large scale hydraulic modeling spanning entire watersheds de moel et al 2015 it is important to study the effect of bathymetry on hydraulic modeling at watershed scales spanning multiple reaches therefore future work should focus on developing a methodology for estimating bathymetry for entire river networks lastly the models compared in this study linearly interpolate the depth between the upstream and downstream while this may be reasonable for reaches with low variation in longitudinal profile this can introduce significant errors in channels with high variation in longitudinal slope such as those in mountainous regions depth is an important bathymetric attribute but is difficult to estimate in the absence of surveyed data in this regard remote sensing techniques can provide a potential avenue for estimating depth along a channel which in turn can improve bathymetry estimation further declaration of competing interest none acknowledgments we thank the editor dr corrado corradini the associate editor dr subashisa dutta the reviewer dr samir al gamal and one anonymous reviewer for providing constructive comments to revise the manuscript we would also like to thank ms kimberly peterson from the lyles school of civil engineering at purdue university for proof reading the final version of this manuscript appendix river channel morphology model rcmm is a conceptual model that estimates the channel topography using channel planform information for a detailed description please refer to merwade 2004 a meandering bend within a channel experiences sediment deposition on the inner bank and sediment erosion on the outer bank from the flowing water this leads to an asymmetric channel cross section with the thalweg being closer to the outer bank in a meander in relatively straight reaches within the river the thalweg approximately follows the centerline rcmm conceptualizes this physical process to create an empirical channel cross section in three steps in the first step the channel shape is standardized into a non dimensional space where both the channel width and depth are equal to unity in the second step the thalweg is located by using the radius of curvature of the channel centerline through a power law function eq a 1 a1 t a r b 0 5 r 2 0 r 2 where t is the thalweg location from the river centerline in normalized coordinate system where the width of the channel is unity r is the normalized radius of curvature of the centerline segment and a and b are parameters the parameters a and b can be calibrated for a river but calibration requires observed bathymetry data which is scarce in the third step the three points defined by two bank locations and the thalweg are then used to generate a cross sectional shape in the form of composite beta function using eq a 2 the parameters are estimated separately for different thalweg locations by least square regression of measured bathymetry data a2 z f n α 1 β 1 f n α 2 β 2 k where z is the depth estimate f n α 1 β 1 and f n α 2 β 2 are the two beta functions and k α 1 β 1 α 2 and β 2 are parameters that are dependent on the thalweg location in this study all rcmm parameters in eq a 1 and a 2 are estimated from bathymetry data available for a part of the brazos river reach and applied to all other reaches in the final step the normalized cross section width 1 and thalweg depth 1 is then rescaled using the bankfull width and depth at the corresponding cross section the bankfull depth for any cross section along a reach are determined by linearly interpolating the input provided by the user at the upstream and downstream locations of the reach the bankfull width is estimated from the banks which are manually digitized using areal imagery and dem the rescaled cross sections can be joined to create a 3d mesh which can then be used for creating the bathymetric dem 
6383,here we propose a new alternative machine learning method that combines the advantage of the random vector functional link network rvfl with moth search algorithm msa to predict the missing values of total algal count during water quality monitoring of surface waters that providing drinking water treatment plants in fayoum egypt total of 34 water quality parameters was measured in 270 water samples during the period 2015 2017 the msa algorithm was used for optimal selection of input features to improve the performance of the rvfl the predicted missing values of the total algal count by the proposed msa rvfl method were strongly correlated with the real observed ones the results of the msa rvfl were better than the support vector machine svm and the adaptive neural fuzzy inference system anfis models at different sizes of training tests compared with ga rvfl and pso rvfl methods using the msa rvfl was relevant to minimize the input variables and to reduce the processing time the msa rvfl model could reduce the number of input variables from thirty four to eighteen and eventually to four variables the most significant variables selected by the msa rvfl to predict the total algal count were ph no3 p and ca based on these four variables the predicted values of algae were significantly matching with the real observations r2 0 9594 accordingly this makes the msa rvfl model to be a useful cost efficient tool during water quality monitoring programs finally the msa rvfl showed higher performance whenever the number of inputs is large or small that gives our suggested method more advantages than the traditional ann models keywords anfis fayoum water quality msa rvfl svm total algal count 1 introduction missing values of a time series during water quality analysis are the most commonly encountered problems in water quality monitoring programs ssali and marwala 2007 these problems can cause gaps in datasets during water quality monitoring data loss during measurements of water quality parameters may arise due to several reasons such as monitoring equipment breakdown instrumental error poor weather and incorrect measurements additional reasons may include sensor failure battery consumption data transmission errors and or loss of a sample before analysis calcagno et al 2010 reporting of a database with missing values can make serious problems such as loss of statistical efficiency difficulties in data interpretations reduction of the power of the statistical estimation and increased bias in data inferences kang 2013 to overcome the problem of missing values important cautions are required as following a careful investigation of the dataset must be conducted to recognize the pattern and type of missing data the most appropriate input method must be selected and any prediction and or estimation of missing values should reach a minimum bias aiming to keep the original structure of the dataset nieh 2011 luengo et al 2010 several techniques handled the problem of missing values deletion of incomplete rows or columns that containing missing values is one of these methods gill et al 2007 but when using the deletion method significant information could be lost in addition if the dataset is incomplete random it can produce a bias rangeti et al 2015 decreasing the sample size is another problem appeared during the deletion of the missing values rangeti et al 2015 the calculated arithmetic mean is commonly used as an easier imputation technique to replace the missing values ssali and marwala 2007 this method requires completely random data to generate unbiased estimates moreover if a simple calculation of arithmetic mean is applied the subject s patterns of scores across all the other variables will not be taken into consideration as a result the resulted narrow variance can make a disturbance in the distribution of the original data enders 2006 another method is to use the linear regression between two variables holder 1985 the resulted regression equation will be used to predict the missing value holder 1985 some other techniques include linear interpolation polynomial or nonparametric methods gotway et al 1994 as reported in diamantopoulou et al 2005 recently the prediction of the missing values using artificial intelligence ai techniques in the water quality sector has been explored one of the most applied ai techniques commonly used in water quality monitoring programs is the artificial neural networks ann smits 2010 starrett et al 2007 ann basically consists of three layers input hidden and output and the back propagation bp method is used to train network singh et al 2009 alizadeh and kavianpour 2015 the support vector regression svr mohammadpour et al 2015 and adaptive neuro fuzzy inference system anfis have been used to estimate the bioactive peptides in relation to climate change yan et al 2010 several studies have been conducted on the prediction of algal blooming using chlorophyll a harmful algae or algal density as outputs for example guallar et al 2016 studied the prediction of harmful algal blooms in alfacs bay using ann kim et al 2019 studied the assessment of chlorophyll a in nakdong river system using the ann model shen et al 2019 simulated algal blooms in responding to the change of nutrient loads using support vector machine ls svm garcía nieto et al 2019 estimated the algal abnormal proliferation using the hybrid algorithm that combines multivariate adaptive regression spline mars and different evaluate de homayoun aria et al 2019 studied the prediction of the eutrophication algal blooms necessitate using ann lee and lee 2018 studied the harmful algal blooms using three deep learning models multilayer perceptron mlp recurrent neural network rnn and long short term memory lstm yi et al 2018 studied algal bloom prediction using extreme learning machine elm models and tran and hoang 2018 studied the prediction of algal appearance using anfis however most of these previous regression methods do not consider the direct connection between the input and output neurons therefore in the current study the random vector functional link rvfl network is proposed to estimate the total algal count the rvfl in general is an ann with a single layer but with the input output connection chen and wan 1999 the hidden layer in ann is equivalent to a set of nodes that are called enhancement nodes abd el aziz and hassanien 2018 in the rvfl the weights between the input nodes and the enhancement nodes are randomly generated within a suitable interval such interval should constrain the activation functions away from the saturation region abd el aziz and hassanien 2018 the weights between the input and output nodes as well as the enhancement and output ones are updated during the training process by using optimization techniques such as a conjugated bp and the least square method abd el aziz and hassanien 2018 to date the rvfl has been applied in different targets including such as the short term electricity load demand forecasting elaziz et al 2018 distributed learning scardapane et al 2015 semi supervised learning scardapane et al 2016 ensemble learning alhamdoosh and wang 2014 english language handwritten script recognition park and pao 2000 time series data prediction chen and wan 1999 hardware implementation martínez villena et al 2014 conditional probability density prediction husmeier and taylor 1998 remote sensing applications ibrahim et al 2018 forecasting the distribution of temperature elaziz et al 2017 and big data wang 2018 the study presents for the first time the application of the hybrid msa rvfl model in water quality modeling in terms of total algal counting as a function of algal blooms in surface water some algae pollution may frequently be toxic for fish and also for humans and animals feeding on polluted water in water treatment processes some algae can produce a fishy odor an aromatic odor resembling that of particular flowers or vegetables and a grassy odor sahu et al 2016 accordingly algal blooms can damage freshwater ecosystems and threaten drinking water supplies the nile river is one of the most important freshwater systems in the world in egypt keeping the nile water clean and suitable for drinking and irrigation purposes is considered as a national security mission reporting water quality data series without missing values is very important to track the quality status of the nile water the quality of surface water in fayoum controls the quality of lake qarun ecosystem especially the eutrophication status of the lake algal blooming is considered as one of the severe consequences due to sludge discharge from drinking water treatment plants dwtps into surface waters in fayoum governorate a new concept that depends on the merging of the moth search algorithm msa and a network msa rvfl method for predicting the total algal count output based on the measured water quality parameters input variables is suggested in the present study the main aim of this research work is to design a novel model as a cost efficient tool to fill the gaps in data series due to the missing of some values of total algal count during water quality monitoring additionally we evaluated the performance of the msa rvfl model against other models such as anfis and support vector machine svm finally we tested the capability of the msa rvfl model to estimate the missing values of the total algal count when minimizing the input variables 2 materials and methods 2 1 site description and water quality data the study area is fayoum governorate a depression located in the western desert of egypt between 29 02 and 29 35 n and 30 23 and 31 05 e fig 1 it extends over 6068 km2 with a population of 3 5 million january 2017 census and is situated about 95 km southwest of cairo the nile water reaches fayoum via bahr yousef waterway and all wastewaters are conveyed to lake qarun fig 1 there are 13 drinking water treatment plants dwtps six conventional drinking water treatment plants six direct filtration unit compact unit and one desalination plant with overall daily drinking water production capacity 862 300 m3 day for the rural and urban areas in el fayoum governorate fig 1 2 2 water sampling and analysis a total of 270 water samples was collected from the surface water raw waters or intakes for dwtps at fayoum during 2015 2017 all the analyses were carried out at the fayoum drinking water and sanitation company water quality central laboratory fayoum governorate in egypt the lab is iso iec 17025 accredited sampling and analyses were performed according to the approved analytical methods apha 2012 the measured water quality parameters were turbidity temperature t ph electrical conductivity ec total dissolved solids tds total alkalinity as caco3 chlorides cl sulfates so4 total hardness as caco3 permanent hardness calcium hardness magnesium hardness calcium ca magnesium mg nitrites as no2 nitrates as no3 phosphorus p fluorides f sodium na potassium k iron fe manganese mn aluminum al strontium sr dissolved oxygen do total organic carbon toc total plate count total coliform tc fecal coliform fc fecal streptococcus fs as well as diatoms green algae blue green algae and the total algal count 2 3 random vector functional link network pao et al 1994 proposed an extension to the single layer feedforward neural network slfnn which is called rvfl the rvfl differs from the slfnn in that there is a direct link between the input layer and output layers as in fig 2 this link improves the quality of rvfl and helps in avoiding the overfitting problem the mathematical model of rvfl as given assumes that the input data has n samples and each input data is represented as x i y i where x i r n y i r m i 1 n these input samples are passed to the enhancement nodes and the output of each node in this layer can be defined as 1 o j α j x i β j 1 1 e α j x i β j β j 0 s α j s s where β j and α j are the bias and weight between the input layer and enhancement nodes respectively meanwhile the parameter s represents a scale factor which is determined during the phase of parameter tuning the next step after computing the output of each enhancement nodes is to compute the output of rvfl using the output weight w as in the following equation 2 z f w w r n p f f 1 f 2 where f is a matrix that contains the input data f 1 and the output of the enhancement node f 2 3 f 1 x 11 x 1 n x n 1 x n n f 2 g 1 α 1 x 1 β 1 g p α p x 1 β p g 1 α 1 x n β 1 g p α p x n β p thereafter the output weight w is updated using either the moore penrose pseudo inverse chen 1996 zhang and suganthan 2016a or the ridge regression zhang and suganthan 2016a as defined in eqs 4 and 5 respectively 4 w f z 5 w f t f i c 1 f t z where i and c represent the moore penrose pseudo inverse the identity matrix and a trading off parameter respectively 2 4 moth search algorithm wang 2018 proposed a new metaheuristic method which emulates the behaviors of moths during the process of searching for the light source this method is called the moth search algorithm msa and it depends on the levy flights and the phototaxis to convert the behaviors of moths to a mathematical formula where the levy flights are used to represent the movement of the moths which have a shorter distance to a light source than other moths as in the following 6 v i v i q max t 2 l q q 0 where v i and t are the position of the i th moth and the current iteration and q max represents the maximum walk step while the l q represents the step generated using levy flights and it is defined as in the following equation 7 l q γ 1 γ γ 1 π q γ sin π γ 1 2 γ 1 5 where γ represents the parameter of the levy distribution wang 2018 and γ is the gamma function moreover the phototaxis is used to represent the movement of the moths that have the longest distance from the light source these moths update their position through flying directly towards the source of light in a straight line as defined in the following equation 8 v i λ v i τ v b v i ρ 0 5 λ v i 1 τ v b v i o t h e r w i s e where v b is the best position of moth while λ and τ represent the scale acceleration factor respectively the pseudo code of the moth search algorithm is given in algorithm 1 algorithm 1 moth search algorithm msa wang 2018 1 input population size n the dimension dim the maximum number of iterations tmax 2 determine the initial value for the parameters smax β and acceleration factor ω 3 constructing a random population x r n d i m 4 evaluate each moth solution x i x i 1 2 n using the fitness function 5 repeat 6 sort x according to the fitness function values 7 divided x into two halves xf and xs according to fitness function values 8 for each solution in xf 9 update x i x f using eqn 6 10 calculate the fitness function of xi 11 end for 12 for each solution in xs 13 update x i x s using eqn 8 14 calculate the fitness function of xi 15 end for 16 t t 1 17 until the stop condition is satisfied 18 return the best solution xs 2 5 the proposed method in this section the full description of the proposed method is introduced since the new method depends on the msa and rvfl network it is called msa rvfl method the first in the proposed msa rvfl is to generate a random population v of size n and dimension n f which represents the total number of features after that the dataset is divided into two sets training and testing and the quality of each solution is computed based on the training set where each solution is converted into a binary solution and the features corresponding to 1s will be selected then these selected features will be used as an input to the rvfl network that learns the output weights and then computes the output count of alga the next step is to compute the performance of such output using the root mean square error rmse thereafter the best solution is determined which has the lower rmse and then each solution will be updated using the msa operation these steps are repeated until the stop conditions are satisfied the description of the previous steps is given in detail in the following 2 5 1 initial phase in this phase the population v is generated using the following equation 9 v i l i ζ u i l i where l i and u i represent the lower and upper boundary of the search space ζ 0 1 is a random number the dataset is divided into training and testing sets after that the current solution v i is converted into a binary solution using the following equation 10 v i 1 v i 0 5 0 o t h e r w i s e the next step is to select the features which correspond to 1 s in v i for example if v i 0 90 60 50 30 10 7 then v i 111001 and this means that the fourth and fifth features will be ignored while the other will be selected the training set is reduced based on those selected features and passed on to the rvfl network which in turn uses them to learn the weight and compute the predicted output algal count 2 5 2 updating the solutions phase this phase starts by computing the performance of the selected features using the root mean square error rmse defined in table 1 then the best solution v b is selected which has the smallest rmse value moreover the position of each moth v i will be updated either using the levy flight as in eq 6 or phototaxis as in eq 8 the steps of the updating phase are repeated again until the stop conditions are reached here is the maximum number of iterations t max 2 5 3 prediction phase in this stage the best solution v b is used to reduce the features of the testing set the reduced set is applied to rvfl that predicts the output and then compute the performance of the prediction output the general framework of the proposed method is given in fig 3 2 6 experiments for model building the monthly data series were randomly divided into training data and tested data at different ratios as 90 10 70 30 and 50 50 respectively the tested data here represents the data series with missing values of the total algal count the performance of the proposed method to predict the algal count is evaluated through a set of experimental series where the parameters of the proposed method are set as the following the population size n 20 and the maximum number of iterations is 100 these parameters were selected based on trial and error and it was found that when they increase the performance slightly increases however it takes more computational time in contrast when the value of these two parameters is decreased the central processing unit cpu time is reduced which decreases the prediction accuracy it is noteworthy to mention that all the algorithms were implemented using the matlab 2017b software 2 7 performance measures a set of three statistical measures are used to evaluate the performance of the proposed method by comparing the predicted output and the actual value these measures are defined in table 1 3 results the proposed rvfl anfis and svm models were constructed to estimate the missing values for the total algal count in the nile river portion located in fayoum governorate in egypt statistical values recorded monthly for 34 water quality parameters are listed in table 2 these data were used to conduct the proposed model based on the method described earlier in section 2 5 3 1 evaluation of the rvfl model against the svm and anfis models the proposed method showed improvement in the prediction of the algal count through two phases 1 selection of the most relevant inputs using msa and 2 enhancement of the regression process by using the rvfl the results of the hybrid method msa rvfl was evaluated against the svm and anfis methods as presented in table 3 and figs 4 7 the results showed that the best prediction method between all the tested models was the rvfl with correlation value r2 equals to 1 at case 90 10 and closes to 1 at case 70 30 the best prediction method between all the tested models was the rvfl table 3 although the r2 of rvfl at 50 50 was 0 5633 however still better than all other methods table 3 3 2 comparison of the msa rvfl method against the ga rvfl and pso rvfl methods in this section other methods such as genetic algorithm ga and particle swarm optimization pso were tested against the msa method using the rvfl network the rvfl was used to predict the total algal count based on features selection from each algorithm i e msa ga and pso the hybrid methods ga rvfl and pso rvfl were applied under the conditions of 70 as a training set and 30 as testing set table 4 and fig 8 the msa rvfl at 70 30 was previously shown in fig 5c the results in table 4 revealed that the pso is better than the ga but the msa showed the best results between all methods r2 0 9734 with using the least number of inputs furthermore the time taken by msa to determine the relevant variables was less than the time required by the two other algorithms i e ga and pso moreover in terms of mre and mae the proposed msa outperforms the pso and the ga algorithms 3 3 selection of the most significant variables since the msa is a stochastic method which means that the results vary for the 25 iterations also pso and ga the most frequent significant variables were determined these variables are ph no3 p and ca the msa rvfl model was tested using these four variables under conditions of 70 as the training set and 30 as the testing set fig 9 the performance of the proposed method based on these four parameters showed good results it was only slightly less than using the eighteen variables at 70 30 ratio in the case of msa rvfl the r2 value of the msa rvfl model using eighteen input variables was 0 9734 table 3 compared to 0 9594 using the abovementioned four variables however the correlation value r2 0 9594 of the msa rvfl model using the most relevant four variables ph no3 p and ca with 70 30 ratio is better than the selected algorithms namely pso with 21 input variables and ga with 23 input variables see table 4 moreover the correlation value r2 0 9594 is also better than the other regression models i e anfis and svm with 18 input variables at ratio 70 30 see table 3 4 discussion based on the previous results the msa rvfl method as compared with svm and anfis showed the highest performance during the prediction of the missing values of algae table 3 and figs 4 7 using this model helps to avoid the problems associated with removing the incomplete data such as loss of relevant information features or decreasing the sample size the traditional ann methods have limitations such as overfitting and slow learning speed due to the presence of irrelevant features in the training set zhang and suganthan 2016b overfitting is the most common problem associated with the application of svm and anfis when using irrelevant inputs al thanoon et al 2019 elaziz et al 2018 2017 kang et al 2019 ling et al 2016 ren et al 2016 thissen et al 2003 many calculations are required to get the optimal solution when using the svm method for solving large size problems thissen et al 2003 also long computation time is involved when svm is applied for solving large size problems cao and tay 2003 dong et al 2005 on the other hand the anfis shows low accuracy if the training data are not enough ghasemi et al 2016 furthermore in the case of svm and anfis the disconnection of the inputs from the output reduces the overall performance of these methods cao et al 2018 zhang and suganthan 2016b therefore the suggested msa rvfl hybrid method that combines the msa as a feature selection method and rvfl as a prediction method that links the input features with the total algae count could achieve better performance than anfis and svm table 3 thus the msa rvfl method is a useful and promising tool for water quality monitoring as approved by this study this will help to avoid the limitations commonly detected during the predictions of water quality parameters when using the traditional ann and its extensions in this study the msa rvfl showed higher performance using fewer input variables than ga and pso table 4 the msa has the ability to balance between the exploitation and exportation of the search space wang 2018 on the other side there is a deficiency in exploitation capability of ga which sequentially affects the local searchability of the algorithm guha et al 2019 with the same manner like ga the diversity of pso is low in the searching process which leads to premature convergence chen et al 2019 generally the use of a small number of inputs helps in decreasing the computational time however the performance of the network decreases if the number of inputs is not enough to capture the underlying behavior of the data muttil and lee 2005 using the msa rvfl for the prediction of total algae count showed the advantages of short computational time in addition to better performance at a fewer number of inputs as compared to ga and pso table 4 although the msa rvfl showed better performance as compared with ga rvfl and pso rvfl still using eighteen inputs is a large number and not consider as a cost efficient prediction tool see table 4 based on this issue an optimal selection of input parameters was essential to minimize the costs of chemical analyses as mentioned earlier see section 3 3 the four variables named ph no3 p and ca were nominated as the most significant input variables to estimate the missing values of the total algal count with using only these four inputs the results of msa rvfl showed a good matching between the predicted and observed values of the total algal count r2 0 9594 this correlation value is very close to that of msa rvfl when eighteen inputs were used r2 0 9734 however the value 0 9594 was better than the results of ga rvfl with 23 inputs pso rvfl with 21 inputs anfis with 18 inputs and svm with 18 inputs all at 70 as the training set and 30 as the testing set see tables 3 and 4 to verify the reliability of the proposed msa rvfl model based on the optimal choice of the input variables ph no3 p and ca it was important in this work to discuss the environmental relationship between the total algal count output and these input variables in the case of ph both distribution and growth of algae are strongly dependent on ph in the aquatic environments the ph controls the distribution of carbon availability and co2 based species it makes changes on the bioavailability of trace metals and at higher ph essential nutrients such as phosphorus can be precipitated as hydroxyapatite in addition direct physiological effects for some algal species can be observed at extreme ph levels chen and durbin 1994 the ph limits the algal growth especially at strong alkaline conditions ph 9 because of the decline in free co2 concentration at higher ph values sakarika and kornaros 2016 co2 is essential for algae as the main source of inorganic carbon during the photosynthesis process however some studies showed that due to the tolerance of some freshwater species for low co2 levels the succession of these species is controlled by their ability to persist and proliferate at higher ph values brock 1973 goldman and shapiro 1973 on the other hand algae affect the ph since it consumes co2 during the photosynthesis process and subsequently the ph increases azov 1982 shapiro 1973 when the concentration of free co2 becomes very low the algae starts working on the bicarbonate hco3 during this process the algal enzyme carbonic anhydrase disassociates the hco3 into co2 and oh as shown in the following equation gerardi and lytle 2015 11 hco 3 carbonic anhydrase co 2 oh according to equation 11 the release of oh results in an increase in ph with a continuously increasing ph the algae start consuming co3 after the depletion of co3 the final form of alkalinity becomes mainly oh and this occurs at the range of ph 10 11 gerardi and lytle 2015 the other most relevant inputs were no3 and p it is well known that the enrichment of water bodies with phosphorus and nitrogen components causes eutrophication algal blooming one of the most common bad consequences of this process is the depletion of dissolved oxygen and subsequently the water becomes toxic for aquatic life calcium ca also was selected by the suggested model as one of the most significant input variables the ca seems to be a required element during the algal growth even at very low concentrations moss 1972 however some species such as roya anglica and desmidiumswartzii under oligotrophic conditions need relatively higher concentrations of ca 1 3 mg l due to their filamentous habit moss 1972 dvořáková hladká 1976 stated that ca acts as a microbiogenous during algal growth as it can take part in the utilization of nitrates nitrogen on the other hand as discussed earlier algal growth can cause an increase in the ph and this enhances the removal of ca through the precipitation of hydroxyapatite ca5 po4 3 oh compared with other literature table 5 the overall observation is that the proposed model msa rvfl showed better performance than the other previous studies with r2 equals to 0 9734 in case of 18 inputs and r2 of 0 9594 in case of 4 inputs moreover when the msa rvfl was conducted at a 90 10 ratio of training sets to testing sets with 18 inputs the r2 value was equal to 1 see table 3 according to the results of lee et al 2003 muttil and chau 2006 and cho et al 2014 the ann showed better performance only when a small number of inputs was used table 5 however ghasemi et al 2016 stated that ann works with bad performance if the input data are not enough in the present study the msa rvfl method could work with better performance whenever the number of inputs is large or small table 5 these findings revealed the importance of features selection made by msa algorithm in the prediction of total algal count using rvfl furthermore we firstly explored the importance of the suggested msa rvfl model in the prediction of a specific water quality parameter based on a limited number of other parameters which makes this model a vital cost efficient tool in water quality monitoring programs moreover we approved that the suggested model can also work with a large number of inputs without appearing of the overfitting problem 5 conclusion this study could simplify the problem of missing values through the suggestion of an applicable method msa rvfl to estimate the missing values of the total algal count using series data measured monthly at fayoum drinking water treatment plants fdwtps the findings showed that the proposed hybrid model msa rvfl as compared to other models such as anfis and svm could predict the missing values with correlation coefficient r2 that is equal to 1 between the predicted values and observed ones when we used 90 10 ratio of the training set to tested set missing values with the application of the 70 30 ratio the suggested model using msa rvfl could provide good results with r2 predicted values almost identical with the observed ones as compared to pso rvfl and ga rvfl models on the other hand using the hybrid model msa rvfl was relevant to minimizing the input variables and the processing time as compared with ga rvfl and pso rvfl methods the impact of the most relevant inputs ph no3 p and ca selected by the performed model on algae was discussed there were strong interactions between these variables and algae in the aquatic ecosystems the suggested model in this study can play an important role in filling the gaps in the data series of water quality monitoring programs full reporting of data series monitored at fdwtps without missing the values of the total algal count is successfully enabled using the suggested model finally based on the good performance of msa rvfl method with least number of inputs ph no3 p and ca this model can be useful as a vital cost efficient tool in water quality monitoring programs declaration of competing interest none acknowledgments the authors are so grateful for fayoum drinking water sanitation company egypt and for lappeenranta university of technology in finland for providing financial support during this research work 
6383,here we propose a new alternative machine learning method that combines the advantage of the random vector functional link network rvfl with moth search algorithm msa to predict the missing values of total algal count during water quality monitoring of surface waters that providing drinking water treatment plants in fayoum egypt total of 34 water quality parameters was measured in 270 water samples during the period 2015 2017 the msa algorithm was used for optimal selection of input features to improve the performance of the rvfl the predicted missing values of the total algal count by the proposed msa rvfl method were strongly correlated with the real observed ones the results of the msa rvfl were better than the support vector machine svm and the adaptive neural fuzzy inference system anfis models at different sizes of training tests compared with ga rvfl and pso rvfl methods using the msa rvfl was relevant to minimize the input variables and to reduce the processing time the msa rvfl model could reduce the number of input variables from thirty four to eighteen and eventually to four variables the most significant variables selected by the msa rvfl to predict the total algal count were ph no3 p and ca based on these four variables the predicted values of algae were significantly matching with the real observations r2 0 9594 accordingly this makes the msa rvfl model to be a useful cost efficient tool during water quality monitoring programs finally the msa rvfl showed higher performance whenever the number of inputs is large or small that gives our suggested method more advantages than the traditional ann models keywords anfis fayoum water quality msa rvfl svm total algal count 1 introduction missing values of a time series during water quality analysis are the most commonly encountered problems in water quality monitoring programs ssali and marwala 2007 these problems can cause gaps in datasets during water quality monitoring data loss during measurements of water quality parameters may arise due to several reasons such as monitoring equipment breakdown instrumental error poor weather and incorrect measurements additional reasons may include sensor failure battery consumption data transmission errors and or loss of a sample before analysis calcagno et al 2010 reporting of a database with missing values can make serious problems such as loss of statistical efficiency difficulties in data interpretations reduction of the power of the statistical estimation and increased bias in data inferences kang 2013 to overcome the problem of missing values important cautions are required as following a careful investigation of the dataset must be conducted to recognize the pattern and type of missing data the most appropriate input method must be selected and any prediction and or estimation of missing values should reach a minimum bias aiming to keep the original structure of the dataset nieh 2011 luengo et al 2010 several techniques handled the problem of missing values deletion of incomplete rows or columns that containing missing values is one of these methods gill et al 2007 but when using the deletion method significant information could be lost in addition if the dataset is incomplete random it can produce a bias rangeti et al 2015 decreasing the sample size is another problem appeared during the deletion of the missing values rangeti et al 2015 the calculated arithmetic mean is commonly used as an easier imputation technique to replace the missing values ssali and marwala 2007 this method requires completely random data to generate unbiased estimates moreover if a simple calculation of arithmetic mean is applied the subject s patterns of scores across all the other variables will not be taken into consideration as a result the resulted narrow variance can make a disturbance in the distribution of the original data enders 2006 another method is to use the linear regression between two variables holder 1985 the resulted regression equation will be used to predict the missing value holder 1985 some other techniques include linear interpolation polynomial or nonparametric methods gotway et al 1994 as reported in diamantopoulou et al 2005 recently the prediction of the missing values using artificial intelligence ai techniques in the water quality sector has been explored one of the most applied ai techniques commonly used in water quality monitoring programs is the artificial neural networks ann smits 2010 starrett et al 2007 ann basically consists of three layers input hidden and output and the back propagation bp method is used to train network singh et al 2009 alizadeh and kavianpour 2015 the support vector regression svr mohammadpour et al 2015 and adaptive neuro fuzzy inference system anfis have been used to estimate the bioactive peptides in relation to climate change yan et al 2010 several studies have been conducted on the prediction of algal blooming using chlorophyll a harmful algae or algal density as outputs for example guallar et al 2016 studied the prediction of harmful algal blooms in alfacs bay using ann kim et al 2019 studied the assessment of chlorophyll a in nakdong river system using the ann model shen et al 2019 simulated algal blooms in responding to the change of nutrient loads using support vector machine ls svm garcía nieto et al 2019 estimated the algal abnormal proliferation using the hybrid algorithm that combines multivariate adaptive regression spline mars and different evaluate de homayoun aria et al 2019 studied the prediction of the eutrophication algal blooms necessitate using ann lee and lee 2018 studied the harmful algal blooms using three deep learning models multilayer perceptron mlp recurrent neural network rnn and long short term memory lstm yi et al 2018 studied algal bloom prediction using extreme learning machine elm models and tran and hoang 2018 studied the prediction of algal appearance using anfis however most of these previous regression methods do not consider the direct connection between the input and output neurons therefore in the current study the random vector functional link rvfl network is proposed to estimate the total algal count the rvfl in general is an ann with a single layer but with the input output connection chen and wan 1999 the hidden layer in ann is equivalent to a set of nodes that are called enhancement nodes abd el aziz and hassanien 2018 in the rvfl the weights between the input nodes and the enhancement nodes are randomly generated within a suitable interval such interval should constrain the activation functions away from the saturation region abd el aziz and hassanien 2018 the weights between the input and output nodes as well as the enhancement and output ones are updated during the training process by using optimization techniques such as a conjugated bp and the least square method abd el aziz and hassanien 2018 to date the rvfl has been applied in different targets including such as the short term electricity load demand forecasting elaziz et al 2018 distributed learning scardapane et al 2015 semi supervised learning scardapane et al 2016 ensemble learning alhamdoosh and wang 2014 english language handwritten script recognition park and pao 2000 time series data prediction chen and wan 1999 hardware implementation martínez villena et al 2014 conditional probability density prediction husmeier and taylor 1998 remote sensing applications ibrahim et al 2018 forecasting the distribution of temperature elaziz et al 2017 and big data wang 2018 the study presents for the first time the application of the hybrid msa rvfl model in water quality modeling in terms of total algal counting as a function of algal blooms in surface water some algae pollution may frequently be toxic for fish and also for humans and animals feeding on polluted water in water treatment processes some algae can produce a fishy odor an aromatic odor resembling that of particular flowers or vegetables and a grassy odor sahu et al 2016 accordingly algal blooms can damage freshwater ecosystems and threaten drinking water supplies the nile river is one of the most important freshwater systems in the world in egypt keeping the nile water clean and suitable for drinking and irrigation purposes is considered as a national security mission reporting water quality data series without missing values is very important to track the quality status of the nile water the quality of surface water in fayoum controls the quality of lake qarun ecosystem especially the eutrophication status of the lake algal blooming is considered as one of the severe consequences due to sludge discharge from drinking water treatment plants dwtps into surface waters in fayoum governorate a new concept that depends on the merging of the moth search algorithm msa and a network msa rvfl method for predicting the total algal count output based on the measured water quality parameters input variables is suggested in the present study the main aim of this research work is to design a novel model as a cost efficient tool to fill the gaps in data series due to the missing of some values of total algal count during water quality monitoring additionally we evaluated the performance of the msa rvfl model against other models such as anfis and support vector machine svm finally we tested the capability of the msa rvfl model to estimate the missing values of the total algal count when minimizing the input variables 2 materials and methods 2 1 site description and water quality data the study area is fayoum governorate a depression located in the western desert of egypt between 29 02 and 29 35 n and 30 23 and 31 05 e fig 1 it extends over 6068 km2 with a population of 3 5 million january 2017 census and is situated about 95 km southwest of cairo the nile water reaches fayoum via bahr yousef waterway and all wastewaters are conveyed to lake qarun fig 1 there are 13 drinking water treatment plants dwtps six conventional drinking water treatment plants six direct filtration unit compact unit and one desalination plant with overall daily drinking water production capacity 862 300 m3 day for the rural and urban areas in el fayoum governorate fig 1 2 2 water sampling and analysis a total of 270 water samples was collected from the surface water raw waters or intakes for dwtps at fayoum during 2015 2017 all the analyses were carried out at the fayoum drinking water and sanitation company water quality central laboratory fayoum governorate in egypt the lab is iso iec 17025 accredited sampling and analyses were performed according to the approved analytical methods apha 2012 the measured water quality parameters were turbidity temperature t ph electrical conductivity ec total dissolved solids tds total alkalinity as caco3 chlorides cl sulfates so4 total hardness as caco3 permanent hardness calcium hardness magnesium hardness calcium ca magnesium mg nitrites as no2 nitrates as no3 phosphorus p fluorides f sodium na potassium k iron fe manganese mn aluminum al strontium sr dissolved oxygen do total organic carbon toc total plate count total coliform tc fecal coliform fc fecal streptococcus fs as well as diatoms green algae blue green algae and the total algal count 2 3 random vector functional link network pao et al 1994 proposed an extension to the single layer feedforward neural network slfnn which is called rvfl the rvfl differs from the slfnn in that there is a direct link between the input layer and output layers as in fig 2 this link improves the quality of rvfl and helps in avoiding the overfitting problem the mathematical model of rvfl as given assumes that the input data has n samples and each input data is represented as x i y i where x i r n y i r m i 1 n these input samples are passed to the enhancement nodes and the output of each node in this layer can be defined as 1 o j α j x i β j 1 1 e α j x i β j β j 0 s α j s s where β j and α j are the bias and weight between the input layer and enhancement nodes respectively meanwhile the parameter s represents a scale factor which is determined during the phase of parameter tuning the next step after computing the output of each enhancement nodes is to compute the output of rvfl using the output weight w as in the following equation 2 z f w w r n p f f 1 f 2 where f is a matrix that contains the input data f 1 and the output of the enhancement node f 2 3 f 1 x 11 x 1 n x n 1 x n n f 2 g 1 α 1 x 1 β 1 g p α p x 1 β p g 1 α 1 x n β 1 g p α p x n β p thereafter the output weight w is updated using either the moore penrose pseudo inverse chen 1996 zhang and suganthan 2016a or the ridge regression zhang and suganthan 2016a as defined in eqs 4 and 5 respectively 4 w f z 5 w f t f i c 1 f t z where i and c represent the moore penrose pseudo inverse the identity matrix and a trading off parameter respectively 2 4 moth search algorithm wang 2018 proposed a new metaheuristic method which emulates the behaviors of moths during the process of searching for the light source this method is called the moth search algorithm msa and it depends on the levy flights and the phototaxis to convert the behaviors of moths to a mathematical formula where the levy flights are used to represent the movement of the moths which have a shorter distance to a light source than other moths as in the following 6 v i v i q max t 2 l q q 0 where v i and t are the position of the i th moth and the current iteration and q max represents the maximum walk step while the l q represents the step generated using levy flights and it is defined as in the following equation 7 l q γ 1 γ γ 1 π q γ sin π γ 1 2 γ 1 5 where γ represents the parameter of the levy distribution wang 2018 and γ is the gamma function moreover the phototaxis is used to represent the movement of the moths that have the longest distance from the light source these moths update their position through flying directly towards the source of light in a straight line as defined in the following equation 8 v i λ v i τ v b v i ρ 0 5 λ v i 1 τ v b v i o t h e r w i s e where v b is the best position of moth while λ and τ represent the scale acceleration factor respectively the pseudo code of the moth search algorithm is given in algorithm 1 algorithm 1 moth search algorithm msa wang 2018 1 input population size n the dimension dim the maximum number of iterations tmax 2 determine the initial value for the parameters smax β and acceleration factor ω 3 constructing a random population x r n d i m 4 evaluate each moth solution x i x i 1 2 n using the fitness function 5 repeat 6 sort x according to the fitness function values 7 divided x into two halves xf and xs according to fitness function values 8 for each solution in xf 9 update x i x f using eqn 6 10 calculate the fitness function of xi 11 end for 12 for each solution in xs 13 update x i x s using eqn 8 14 calculate the fitness function of xi 15 end for 16 t t 1 17 until the stop condition is satisfied 18 return the best solution xs 2 5 the proposed method in this section the full description of the proposed method is introduced since the new method depends on the msa and rvfl network it is called msa rvfl method the first in the proposed msa rvfl is to generate a random population v of size n and dimension n f which represents the total number of features after that the dataset is divided into two sets training and testing and the quality of each solution is computed based on the training set where each solution is converted into a binary solution and the features corresponding to 1s will be selected then these selected features will be used as an input to the rvfl network that learns the output weights and then computes the output count of alga the next step is to compute the performance of such output using the root mean square error rmse thereafter the best solution is determined which has the lower rmse and then each solution will be updated using the msa operation these steps are repeated until the stop conditions are satisfied the description of the previous steps is given in detail in the following 2 5 1 initial phase in this phase the population v is generated using the following equation 9 v i l i ζ u i l i where l i and u i represent the lower and upper boundary of the search space ζ 0 1 is a random number the dataset is divided into training and testing sets after that the current solution v i is converted into a binary solution using the following equation 10 v i 1 v i 0 5 0 o t h e r w i s e the next step is to select the features which correspond to 1 s in v i for example if v i 0 90 60 50 30 10 7 then v i 111001 and this means that the fourth and fifth features will be ignored while the other will be selected the training set is reduced based on those selected features and passed on to the rvfl network which in turn uses them to learn the weight and compute the predicted output algal count 2 5 2 updating the solutions phase this phase starts by computing the performance of the selected features using the root mean square error rmse defined in table 1 then the best solution v b is selected which has the smallest rmse value moreover the position of each moth v i will be updated either using the levy flight as in eq 6 or phototaxis as in eq 8 the steps of the updating phase are repeated again until the stop conditions are reached here is the maximum number of iterations t max 2 5 3 prediction phase in this stage the best solution v b is used to reduce the features of the testing set the reduced set is applied to rvfl that predicts the output and then compute the performance of the prediction output the general framework of the proposed method is given in fig 3 2 6 experiments for model building the monthly data series were randomly divided into training data and tested data at different ratios as 90 10 70 30 and 50 50 respectively the tested data here represents the data series with missing values of the total algal count the performance of the proposed method to predict the algal count is evaluated through a set of experimental series where the parameters of the proposed method are set as the following the population size n 20 and the maximum number of iterations is 100 these parameters were selected based on trial and error and it was found that when they increase the performance slightly increases however it takes more computational time in contrast when the value of these two parameters is decreased the central processing unit cpu time is reduced which decreases the prediction accuracy it is noteworthy to mention that all the algorithms were implemented using the matlab 2017b software 2 7 performance measures a set of three statistical measures are used to evaluate the performance of the proposed method by comparing the predicted output and the actual value these measures are defined in table 1 3 results the proposed rvfl anfis and svm models were constructed to estimate the missing values for the total algal count in the nile river portion located in fayoum governorate in egypt statistical values recorded monthly for 34 water quality parameters are listed in table 2 these data were used to conduct the proposed model based on the method described earlier in section 2 5 3 1 evaluation of the rvfl model against the svm and anfis models the proposed method showed improvement in the prediction of the algal count through two phases 1 selection of the most relevant inputs using msa and 2 enhancement of the regression process by using the rvfl the results of the hybrid method msa rvfl was evaluated against the svm and anfis methods as presented in table 3 and figs 4 7 the results showed that the best prediction method between all the tested models was the rvfl with correlation value r2 equals to 1 at case 90 10 and closes to 1 at case 70 30 the best prediction method between all the tested models was the rvfl table 3 although the r2 of rvfl at 50 50 was 0 5633 however still better than all other methods table 3 3 2 comparison of the msa rvfl method against the ga rvfl and pso rvfl methods in this section other methods such as genetic algorithm ga and particle swarm optimization pso were tested against the msa method using the rvfl network the rvfl was used to predict the total algal count based on features selection from each algorithm i e msa ga and pso the hybrid methods ga rvfl and pso rvfl were applied under the conditions of 70 as a training set and 30 as testing set table 4 and fig 8 the msa rvfl at 70 30 was previously shown in fig 5c the results in table 4 revealed that the pso is better than the ga but the msa showed the best results between all methods r2 0 9734 with using the least number of inputs furthermore the time taken by msa to determine the relevant variables was less than the time required by the two other algorithms i e ga and pso moreover in terms of mre and mae the proposed msa outperforms the pso and the ga algorithms 3 3 selection of the most significant variables since the msa is a stochastic method which means that the results vary for the 25 iterations also pso and ga the most frequent significant variables were determined these variables are ph no3 p and ca the msa rvfl model was tested using these four variables under conditions of 70 as the training set and 30 as the testing set fig 9 the performance of the proposed method based on these four parameters showed good results it was only slightly less than using the eighteen variables at 70 30 ratio in the case of msa rvfl the r2 value of the msa rvfl model using eighteen input variables was 0 9734 table 3 compared to 0 9594 using the abovementioned four variables however the correlation value r2 0 9594 of the msa rvfl model using the most relevant four variables ph no3 p and ca with 70 30 ratio is better than the selected algorithms namely pso with 21 input variables and ga with 23 input variables see table 4 moreover the correlation value r2 0 9594 is also better than the other regression models i e anfis and svm with 18 input variables at ratio 70 30 see table 3 4 discussion based on the previous results the msa rvfl method as compared with svm and anfis showed the highest performance during the prediction of the missing values of algae table 3 and figs 4 7 using this model helps to avoid the problems associated with removing the incomplete data such as loss of relevant information features or decreasing the sample size the traditional ann methods have limitations such as overfitting and slow learning speed due to the presence of irrelevant features in the training set zhang and suganthan 2016b overfitting is the most common problem associated with the application of svm and anfis when using irrelevant inputs al thanoon et al 2019 elaziz et al 2018 2017 kang et al 2019 ling et al 2016 ren et al 2016 thissen et al 2003 many calculations are required to get the optimal solution when using the svm method for solving large size problems thissen et al 2003 also long computation time is involved when svm is applied for solving large size problems cao and tay 2003 dong et al 2005 on the other hand the anfis shows low accuracy if the training data are not enough ghasemi et al 2016 furthermore in the case of svm and anfis the disconnection of the inputs from the output reduces the overall performance of these methods cao et al 2018 zhang and suganthan 2016b therefore the suggested msa rvfl hybrid method that combines the msa as a feature selection method and rvfl as a prediction method that links the input features with the total algae count could achieve better performance than anfis and svm table 3 thus the msa rvfl method is a useful and promising tool for water quality monitoring as approved by this study this will help to avoid the limitations commonly detected during the predictions of water quality parameters when using the traditional ann and its extensions in this study the msa rvfl showed higher performance using fewer input variables than ga and pso table 4 the msa has the ability to balance between the exploitation and exportation of the search space wang 2018 on the other side there is a deficiency in exploitation capability of ga which sequentially affects the local searchability of the algorithm guha et al 2019 with the same manner like ga the diversity of pso is low in the searching process which leads to premature convergence chen et al 2019 generally the use of a small number of inputs helps in decreasing the computational time however the performance of the network decreases if the number of inputs is not enough to capture the underlying behavior of the data muttil and lee 2005 using the msa rvfl for the prediction of total algae count showed the advantages of short computational time in addition to better performance at a fewer number of inputs as compared to ga and pso table 4 although the msa rvfl showed better performance as compared with ga rvfl and pso rvfl still using eighteen inputs is a large number and not consider as a cost efficient prediction tool see table 4 based on this issue an optimal selection of input parameters was essential to minimize the costs of chemical analyses as mentioned earlier see section 3 3 the four variables named ph no3 p and ca were nominated as the most significant input variables to estimate the missing values of the total algal count with using only these four inputs the results of msa rvfl showed a good matching between the predicted and observed values of the total algal count r2 0 9594 this correlation value is very close to that of msa rvfl when eighteen inputs were used r2 0 9734 however the value 0 9594 was better than the results of ga rvfl with 23 inputs pso rvfl with 21 inputs anfis with 18 inputs and svm with 18 inputs all at 70 as the training set and 30 as the testing set see tables 3 and 4 to verify the reliability of the proposed msa rvfl model based on the optimal choice of the input variables ph no3 p and ca it was important in this work to discuss the environmental relationship between the total algal count output and these input variables in the case of ph both distribution and growth of algae are strongly dependent on ph in the aquatic environments the ph controls the distribution of carbon availability and co2 based species it makes changes on the bioavailability of trace metals and at higher ph essential nutrients such as phosphorus can be precipitated as hydroxyapatite in addition direct physiological effects for some algal species can be observed at extreme ph levels chen and durbin 1994 the ph limits the algal growth especially at strong alkaline conditions ph 9 because of the decline in free co2 concentration at higher ph values sakarika and kornaros 2016 co2 is essential for algae as the main source of inorganic carbon during the photosynthesis process however some studies showed that due to the tolerance of some freshwater species for low co2 levels the succession of these species is controlled by their ability to persist and proliferate at higher ph values brock 1973 goldman and shapiro 1973 on the other hand algae affect the ph since it consumes co2 during the photosynthesis process and subsequently the ph increases azov 1982 shapiro 1973 when the concentration of free co2 becomes very low the algae starts working on the bicarbonate hco3 during this process the algal enzyme carbonic anhydrase disassociates the hco3 into co2 and oh as shown in the following equation gerardi and lytle 2015 11 hco 3 carbonic anhydrase co 2 oh according to equation 11 the release of oh results in an increase in ph with a continuously increasing ph the algae start consuming co3 after the depletion of co3 the final form of alkalinity becomes mainly oh and this occurs at the range of ph 10 11 gerardi and lytle 2015 the other most relevant inputs were no3 and p it is well known that the enrichment of water bodies with phosphorus and nitrogen components causes eutrophication algal blooming one of the most common bad consequences of this process is the depletion of dissolved oxygen and subsequently the water becomes toxic for aquatic life calcium ca also was selected by the suggested model as one of the most significant input variables the ca seems to be a required element during the algal growth even at very low concentrations moss 1972 however some species such as roya anglica and desmidiumswartzii under oligotrophic conditions need relatively higher concentrations of ca 1 3 mg l due to their filamentous habit moss 1972 dvořáková hladká 1976 stated that ca acts as a microbiogenous during algal growth as it can take part in the utilization of nitrates nitrogen on the other hand as discussed earlier algal growth can cause an increase in the ph and this enhances the removal of ca through the precipitation of hydroxyapatite ca5 po4 3 oh compared with other literature table 5 the overall observation is that the proposed model msa rvfl showed better performance than the other previous studies with r2 equals to 0 9734 in case of 18 inputs and r2 of 0 9594 in case of 4 inputs moreover when the msa rvfl was conducted at a 90 10 ratio of training sets to testing sets with 18 inputs the r2 value was equal to 1 see table 3 according to the results of lee et al 2003 muttil and chau 2006 and cho et al 2014 the ann showed better performance only when a small number of inputs was used table 5 however ghasemi et al 2016 stated that ann works with bad performance if the input data are not enough in the present study the msa rvfl method could work with better performance whenever the number of inputs is large or small table 5 these findings revealed the importance of features selection made by msa algorithm in the prediction of total algal count using rvfl furthermore we firstly explored the importance of the suggested msa rvfl model in the prediction of a specific water quality parameter based on a limited number of other parameters which makes this model a vital cost efficient tool in water quality monitoring programs moreover we approved that the suggested model can also work with a large number of inputs without appearing of the overfitting problem 5 conclusion this study could simplify the problem of missing values through the suggestion of an applicable method msa rvfl to estimate the missing values of the total algal count using series data measured monthly at fayoum drinking water treatment plants fdwtps the findings showed that the proposed hybrid model msa rvfl as compared to other models such as anfis and svm could predict the missing values with correlation coefficient r2 that is equal to 1 between the predicted values and observed ones when we used 90 10 ratio of the training set to tested set missing values with the application of the 70 30 ratio the suggested model using msa rvfl could provide good results with r2 predicted values almost identical with the observed ones as compared to pso rvfl and ga rvfl models on the other hand using the hybrid model msa rvfl was relevant to minimizing the input variables and the processing time as compared with ga rvfl and pso rvfl methods the impact of the most relevant inputs ph no3 p and ca selected by the performed model on algae was discussed there were strong interactions between these variables and algae in the aquatic ecosystems the suggested model in this study can play an important role in filling the gaps in the data series of water quality monitoring programs full reporting of data series monitored at fdwtps without missing the values of the total algal count is successfully enabled using the suggested model finally based on the good performance of msa rvfl method with least number of inputs ph no3 p and ca this model can be useful as a vital cost efficient tool in water quality monitoring programs declaration of competing interest none acknowledgments the authors are so grateful for fayoum drinking water sanitation company egypt and for lappeenranta university of technology in finland for providing financial support during this research work 
6384,flooding is a very common natural hazard that causes catastrophic effects worldwide recently ensemble based techniques have become popular in flood susceptibility modelling due to their greater strength and efficiency in the prediction of flood locations thus the aim of this study was to employ machine learning based reduced error pruning trees reptree with bagging bag reptree and random subspace rs reptree ensemble frameworks for spatial prediction of flood susceptibility using a geographic information system gis first a flood spatial database was constructed with 363 flood locations and thirteen flood influencing factors namely altitude slope angle slope aspect curvature stream power index spi sediment transport index sti topographic wetness index twi distance to rivers normalized difference vegetation index ndvi soil land use lithology and rainfall subsequently correlation attribute evaluation cae was used as the factor selection method for optimization of input factors finally the receiver operating characteristic roc curve standard error se confidence interval ci at 95 and wilcoxon signed rank test were used to validate and compare the performance of the models results show that the rs reptree model has the highest prediction capability for flood susceptibility assessment with the highest area under the roc curve auc value 0 949 0 907 the smallest se 0 011 0 023 and the narrowest ci 95 0 928 0 970 0 863 0 952 for the training and validation datasets it was followed by the bag reptree and reptree models respectively the results also proved the superiority of the ensemble method over using these methods individually keywords flood susceptibility machine learning ensemble framework gis china 1 introduction a natural disaster is a major adverse event resulting from natural planetary processes that include floods hurricanes tornadoes volcanic eruptions earthquakes and tsunamis such natural disasters can cause huge loss of life and economic damage hyndman and hyndman 2016 the severity of these disasters depends on the affected population s resilience and ability to recover and on the infrastructural stability among natural disasters flooding is considered one of the most devastating phenomena in the world from 1996 to 2015 around 150 061 flood events occurred in the world and were responsible for 11 1 of the global disaster fatalities based on information from the united nations office for disaster risk reduction unisdr hong et al 2018a flooding is a serious disaster that has caused economic damage and loss of human life throughout history according to a report by the national climate center of china average annual economic loss due to flood events in china has been about 17 billion us dollars b usd since 1990 huang et al 2008 zhang et al 2015 many torrential floods have recently occurred in china due to its high density of population lack of legal supervision of dense intensive construction around rivers and extensive deforestation hong et al 2018b hence preparing flood susceptibility maps fsms is an appropriate management tool needed to identify areas at risk and is essential to prevent construction in such high risk areas and to protect at risk natural resources tehrany et al 2013 geographic information systems giss have become effective tools for analysis of spatial management and data manipulation because of their ability to handle large amounts of spatial data oh and pradhan 2011 khosravi et al 2016a the combination of statistical and probabilistic models with remote sensing rs and gis has been used often by a variety of researchers pradhan 2010 youssef et al 2011 garcía pintado et al 2013 there are two major method in flood susceptibility mapping named qualitative or quantitative degiorgis et al 2012 manfreda et al 2015 gnecco et al 2017 samela et al 2017 khosravi et al 2018 razavi termeh et al 2018 in recent years statistical and probabilistic models have been very popular in quantitative method levy et al 2007 lee et al 2012 for example some of statistical and probabilistic models include frequency ratio fr tehrany et al 2013 rahmati et al 2016 weights of evidence woe tehrany et al 2014 shafapour tehrany et al 2017 and logistic regression lr tehrany et al 2013 the analytical hierarchy process ahp khosravi et al 2016a artificial neural networks anns kia et al 2012 and decision trees dts khosravi et al 2018 have also been useful in particular methods such as adaptive neuro fuzzy inference systems anfiss tien bui et al 2016 the anfis genetic algorithm ga hong et al 2018a and anfis particle swarm optimization pso termeh et al 2018 have advanced both the conceptual and practical aspects of fsms more recently machine learning methods have been applied in flood susceptibility mapping fsm by many researchers maier et al 2010 kia et al 2012 of particular usefulness in fsms have been naïve bayes trees nbt khosravi et al 2018 logistic model trees lmts chapi et al 2017 and fuzzy weight of evidence fuzzy wofe hong et al 2018b however no general agreement has yet been reached on how to select the best model for any natural hazard assessment such as flood susceptibility thus new models are needed and should be tested therefore the main purpose of this study was to present new hybrid approaches of bagging and random subspace based reduced error pruning tree reptree classifiers for flood susceptibility modeling because ensembles of bagging random subspace and reptree have rarely been applied in flood susceptibility mapping these meta classifiers ensembles are novel frameworks for machine learning that are used to increase the prediction accuracy of a base classifier single classifier for this study quannan county of china which is prone to flooding was selected for flood susceptibility modeling data processing was conducted using arcgis 10 5 and weka 3 9 2 software 2 description of study area quannan county covers about 1520 km2 and is located in ganzhou city jiangxi province china the region is defined by 24 30 00 to 25 10 00 n and 114 10 00 to 114 50 00 e fig 1 the elevation in quannan county varies from 146 to 1104 m a s l in quannan county the prevailing climate is mid subtropical monsoon according to a report from the jiangxi meteorology bureau http www weather org cn the average temperature is 18 8 c and the average annual rainfall is 1653 5 mm due to the monsoon condition and geographical position rainfall is unevenly distributed in both time and space for the rainy season from march to august the monthly average rainfall is more than 150 mm for the dry season from october to january the monthly average rainfall is more than 100 mm in the flood season april to june the monthly average rainfall is about 648 2 mm and precipitation within this interval accounts for 39 2 of the annual rainfall analysis of a geological map of quannan county indicates that the area is mainly outcrops of basalt sandstone limestone and syenite the heavy rainfall is the main factor influencing floods according to a recent report by the quannan government http www quannan gov cn and historical records from april 10 to 14 2007 quannan county was subjected to a flood according to statistics this flood in quannan county affected nine townships towns and a population of 95 900 people the crop area affected was 1581 ha related damage included destroyed roadbed surfaces 2 712 km damaged transmission lines 5 92 km damaged embankments 32 and damaged river banks 25 the cumulative direct economic loss was about 5 7 m chy 3 flood database 3 1 flood inventory map a flood inventory map is the first and most important step in flood susceptibility mapping there are many methods to get a flood inventory map in fact historical records and interpretation of aerial images are the main methods to get a reasonable and accurate map there were historical 363 flood events determined in the study area fig 1 whose information were obtained from the historical records field surveys and google earth the data was supported by the jiangxi meteorological bureau 3 2 factors influencing floods the process of flooding is very complicated and comprehensive therefore the factors that influence flooding are complex until now there has been no agreement about how to deal accurately with these factors in this study we drew upon the literature and actual circumstances of quannan county tehrany et al 2015 chapi et al 2017 shafizadeh moghadam et al 2018 the present study analyzed thirteen influencing factors namely altitude slope angle slope aspect curvature stream power index spi sediment transport index sti topographic wetness index twi distance to rivers normalized difference vegetation index ndvi soil land use lithology and rainfall data analysis and visualization was performed in a gis environment with data in a raster format with spatial resolution of 30 m a digital elevation model dem for the study area was generated from the aster gdem version 2 http gdem ersdac jspacesystems or jp based on the dem the altitude slope angle slope aspect curvature twi spi sti and distance to rivers were determined fig 2 a h the ndvi map fig 2i was obtained using landsat 8 oli satellite images acquired on august 20 2017 http www gscloud cn the ndvi values were calculated using the formula 1 ndvi nir r nir r in this case nir and r red are in the near infrared and red band the soil map was compiled to form five classes fig 2j a land use map was created from landsat 8 oli satellite image data of which interpretation yielded five classes farm land forest land grass land water and residential area the maximum likelihood supervision method was used for the classification with classification accuracy of 91 3 fig 2k the lithology map for the study area was obtained from china geology survey http www cgs gov cn and was categorized into nine groups a b c d e f g h and i fig 2l regarding rainfall the mean annual precipitation at 14 rainfall stations was used to create the rainfall map which is from 1871 to 2448 93 mm using the inverse distance weighted method fig 2m 4 methodology flood susceptibility mapping is regarded as an essential tool for prevention and management of the occurrence of future flooding khosravi et al 2016b the step by step procedures used for the proposed method in the current study are shown in fig 3 those involved in the preparation of the flood inventory and influencing factors included selection of flood influencing factors application of proposed models and validation of model performance 4 1 preparation of training and validation datasets the flood inventory map was randomly partitioned into two parts to be used for training and validation respectively in this case 70 254 flood locations was used for the training dataset and the other 30 109 remaining flood locations was used for the validation dataset flood susceptibility mapping using machine learning methods can be considered binary classification which requires the availability of flood and non flood locations simultaneously it is suggested that the number of non flood locations must be similar to the number and distribution of flood locations to avoid bias su et al 2015 therefore a total of 363 non flood locations were selected randomly from areas that are not prone to floods these were also randomly divided in the same ratio as used for the flood locations finally the values of the thirteen flood influencing factors were extracted for the flood and non flood locations to obtain the training and validation datasets 4 2 factor selection using the cae method it is important that flood influencing factors that make no contribution or that generate noise be removed from the modelling process chapi et al 2017 in the present study the contributions of flood influencing factors were evaluated using the correlation attribute evaluation cae method this allows evaluation of the contribution of a flood influencing factor by measuring the pearson s correlation between the factor and the class witten et al 2011 4 3 reptree reptree is considered a fast decision algorithm and is based on the principle of calculating the information gain and reducing the error arising from variance joseph and ravichandran 2012 reptree builds a decision regression tree using information gain as the splitting criterion and then prunes it using reduced error pruning jayanthi and sasikala 2013 the complexity of the decision tree model is decreased using the reduce error pruning method so that the error arising from variance is reduced use of decision trees is a very popular method for classifying problems because of the simple configuration generally there are two ways to prune decision trees pre pruning and post pruning when the number of instances that reach a node is lower than the percentage of the training set that node is not divided it is considered that the variance of the model is generated by training with too few instances and that accordingly the generalization error will increase for this reason if expansion of the tree is stopped as it is being built this process is called pre pruning lakshmi 2015 however in post pruning the tree is expanded until all the leaves are pure and there is no error in the training set then sub trees will be found to memorize and prune later we replace each sub tree with a leaf that is trained by instances covered in the training set of that sub tree next we compare these two options in a pruning set when a leaf does not lead to greater error in the pruning set we will prune the sub tree and use the leaf otherwise we keep the sub tree jayanthi and sasikala 2013 comparing the pre pruning and post pruning processes it is obvious that pre pruning produces trees faster while post pruning produces more successful trees 4 4 bagging bagging is one of the most popular techniques for constructing ensembles prasad et al 2006 chen et al 2018c in bagging each training set is constructed by forming a bootstrap replicate of the original training set breiman 1996 this means that given a training set t of n instances then a new training set t is constructed by drawing n instances uniformly from t an instance in the training set has the probability 1 1 1 n n of being selected at least once in the n times instances are randomly selected from the training set bauer and kohavi 1999 4 5 random subspace similar to bagging the random subspace method rsm benefits from bootstrapping and aggregation however the difference between them is that bagging bootstraps the training samples while rsm bootstraps in the feature space tao et al 2006 there are four inputs in rsm skurichina and duin 2002 the training set x the base classifier w the number of subspaces l and the number of subspaces d s in rsm l subsets of d s features are randomly generated and stored in subspace then the base classifier is trained on each of the subsets in subspace in order to produce l different classifiers these classifiers are combined to produce an ensemble classifier e a detailed description of the algorithm can be seen in kuncheva et al 2010 4 6 receiver operating characteristic curve the receiver operating characteristic roc curve is plotted by considering a range of possible cutoff values of sensitivity and 1 specificity and plotted with the former on the y axis and latter on the x axis ko and lo 2018 chen et al 2019e the area under the curve auc is a significant measurement to assess the prediction capability of models chen et al 2018b and a value approaching 1 0 indicates good prediction ko and lo 2018 5 results and analysis 5 1 selection of influencing factors using the cae method table 1 shows the selection of influencing factors using the correlation attribute evaluation cae method the result shows that all flood influencing factors have positive average merit am for flood occurrences in quannan county in general ndvi has the highest value am 0 757 followed by slope angle am 0 624 distance to rivers am 0 540 and altitude am 0 448 curvature slope aspect and lithology have lower predictive ability values for flood occurrences in the quannan county with am values of 0 024 0 013 and 0 011 respectively 5 2 model validation and comparison the receiver operating characteristic roc chen et al 2018a 2019a plots for the three flood susceptibility maps using the training dataset are shown in fig 4 and the detailed parameters of the roc curves are shown in table 2 the results demonstrate that the rs reptree model has the highest area under the curve auc value of 0 949 it also has the lowest standard error se of 0 011 and an asymptotic 95 confidence interval ci of 0 928 0 970 its performance is followed by that of the bag reptree model with an auc value of 0 935 se 0 012 asymptotic 95 ci 0 912 0 959 and then of the reptree model with an auc value of 0 907 se 0 015 asymptotic 95 ci 0 878 0 936 hence from the analysis results it is determined that all of the three models displayed a reasonable roc and the reptree model shows the best performance in predicting flood susceptibility followed by the bag reptree and reptree models the roc plots for the three flood susceptibility maps using the validation dataset are shown in fig 5 and the detailed parameters of the roc curves are shown in table 3 the results demonstrate that the rs reptree model had the highest auc value of 0 907 and also had the lowest se of 0 023 and an asymptotic 95 ci of 0 863 0 952 its performance was followed by that of the bag reptree model with an auc value of 0 892 se 0 024 asymptotic 95 ci 0 844 0 940 and then of the reptree model with an auc value of 0 879 se 0 026 asymptotic 95 ci 0 829 0 929 therefore from analysis of the results it can be concluded that all three of the models displayed a reasonable roc although the rs reptree model showed the best performance in validating flood susceptibility followed by the bag reptree and reptree models in this study wilcoxon signed rank tests chen et al 2017 khosravi et al 2018 chen et al 2019d between the three predictive models were performed table 4 for the reptree and bag reptree models the p value at a 95 significance level was estimated to be 0 001 0 05 while the z value 3 321 exceeded the critical values of z 1 96 and 1 96 this showed that the performance of the flood susceptibility models was significantly different for the reptree and rs reptree models the p value at a 95 significance level was estimated to be 0 001 0 05 while the z value 4 018 exceeded the critical values of z 1 96 and 1 96 showing that the performances of the flood susceptibility models were significantly different for the bag reptree and rs reptree models the p value at a 95 significance level was estimated to be 0 048 0 05 while the z value 1 981 exceeded the critical values of z 1 96 and 1 96 showing that the performances of the flood susceptibility models were significantly different 5 3 generating flood susceptibility maps the three flood susceptibility maps produced from the reptree bag reptree and rs reptree models are shown in fig 6 four flood susceptibility classes were regrouped for the reptree bag reptree and rs reptree models using the natural break method chen et al 2019b c low moderate high and very high the area percentages of each class for the three flood susceptibility maps are displayed in fig 7 it appears that for the reptree model the low class has the largest area percentage 78 13 followed by very high 16 55 moderate 2 91 and high 2 42 classes for the bag reptree model the area percentages are 82 63 5 99 2 71 and 8 66 for the low moderate high and very high classes respectively for the rs reptree model the area percentages are 76 05 10 85 5 33 and 7 77 for the low moderate high and very high classes respectively 6 discussion and conclusions flooding is one of the most destructive phenomena that occurs in mountainous environments especially in china zhao et al 2018 flood susceptibility mapping is regarded as an indispensable step to prevent and manage future flooding events kourgialas and karatzas 2011 however due to the complex conditions it is difficult to make reliable predictions of flood occurrence the factors generating floods are relatively complex and their mechanisms are still under research in general they can be summarized as internal and external factors among them the internal factors are those involving the basic conditions of the flood occurrence including geomorphology soil geology and hydrology sarhadi et al 2012 found that physio hydrological and land use characteristics are the major factors controlling frequent floods with low return periods studies have shown that heavy rainfall is an important external factor in floods norbiato et al 2008 evaluated a threshold based flash flood warning method by considering a wide range of climatic and physiographic conditions in addition human activities are also significant external factors and include such as destroying forests or grasslands reclaiming land from lakes and encroaching on tidal flat areas of rivers besides the improvement of input data needs more attention in future work for example until now there is no standard rule to select non flood locations in previous studies it is suggested that the number of non flood locations must be similar to the number and distribution of flood locations to avoid bias su et al 2015 besides non flood locations were random selected in study area these methods assume that the locations that did not have flood occurrence should considered as non flood location hong et al 2018b khosravi et al 2018 therefore in future work we should focus on the method to select reliable non flood location to improve the quality of the input data tehrany et al 2013 proposed a combination of frequency ratio fr and logistic regression lr statistical methods and compared the prediction performance with a rule based decision tree dt for flood susceptibility mapping at kelantan malaysia they found that the integrated method of fr and lr success rate 90 prediction rate 83 was superior to dt success rate 87 prediction rate 82 chapi et al 2017 proposed a novel hybrid model bagging and logistic model tree bagging lmt for mapping flood susceptibility for the haraz watershed in northern iran this involved four state of the art benchmark machine learning techniques including lmt logistic regression bayesian logistic regression and random forest models which were used for comparison of the proposed model they concluded that the proposed bagging lmt model produced higher prediction accuracy razavi termeh et al 2018 mapped flood hazards over the jahrom township in fars province using a combination of adaptive neuro fuzzy inference systems anfis with ant colony optimization aco genetic algorithm ga and particle swarm optimization pso the study showed that the auc values of anfis aco anfis ga and anfis pso ensembles were 91 8 92 6 and 94 5 respectively which were superior than with an individual frequency ratio model razavi termeh et al 2018 ensemble learning is a machine learning method that uses a series of methods and integrates various learning results using a certain rule to obtain better results than with a single method the advantage of ensemble learning is that the ability for generalization classification accuracy and operational efficiency are significantly improved in recent years ensemble learning has become a focal topic in natural hazard risk assessment including flood and landslide susceptibility according to the results obtained in the present study the proposed novel hybrid rs reptree model which generated the highest auc value 0 949 the smallest se 0 011 and the narrowest ci 95 0 928 0 970 for the training dataset it also generated the highest auc value 0 907 smallest se 0 023 and narrowest ci 95 0 863 0 952 for the validation dataset and yielded the best results in flood susceptibility mapping however a pairwise comparison using wilcoxon signed rank test between the models revealed that the performance of all the models were different with statistical significance it can also be concluded that although the complexity of a hybrid model is greater than that of a basic model the learning performance can be significantly improved to a certain extent so that the final hybrid model can not only reduce the fitting error but could also improve the generalization ability concerning the percentage of highly susceptibility classes very high and high all three models depicted similar spatial distribution however the hybrid models targeted slightly smaller percentages 11 37 and 13 10 for the bag reptree and rs reptree models respectively compared to that by the individual reptree model 18 97 this implies a more practical result in relation to the hybrid bag reptree and rs reptree models and one which has more precision and reliability this could reduce the time and cost of an effective mitigation plan in those areas targeted for land use planning as a conclusion the outputs attained from this study demonstrated the superiority of hybrid models and the flood susceptibility maps produced can assist decision makers planners and researchers to prevent and reduce the occurrence of floods in the regions determined to be susceptible declaration of competing interest individual contribution of all authors wei chen and shaojun li did the primary survey and data analysis work himan shahabi has contributed in literature survey and statistical analysis haoyuan hong has contributed in writing and statistical analysis wang yi xiaojing wang and baharin bin ahmadhas contributed in improving the manuscript acknowledgments this study was supported by the international partnership program of chinese academy of sciences grant no 115242kysb20170022 the national natural science foundation of china grant no 41807192 natural science basic research program of shaanxi program no 2019jq 094 china postdoctoral science foundation grant no 2018t111084 2017m613168 project funded by shaanxi province postdoctoral science foundation grant no 2017bshydzz07 the iran national science foundation insf grant no 96004000 and universiti teknologi malaysia utm based on a research university grant q j130000 2527 17h84 
6384,flooding is a very common natural hazard that causes catastrophic effects worldwide recently ensemble based techniques have become popular in flood susceptibility modelling due to their greater strength and efficiency in the prediction of flood locations thus the aim of this study was to employ machine learning based reduced error pruning trees reptree with bagging bag reptree and random subspace rs reptree ensemble frameworks for spatial prediction of flood susceptibility using a geographic information system gis first a flood spatial database was constructed with 363 flood locations and thirteen flood influencing factors namely altitude slope angle slope aspect curvature stream power index spi sediment transport index sti topographic wetness index twi distance to rivers normalized difference vegetation index ndvi soil land use lithology and rainfall subsequently correlation attribute evaluation cae was used as the factor selection method for optimization of input factors finally the receiver operating characteristic roc curve standard error se confidence interval ci at 95 and wilcoxon signed rank test were used to validate and compare the performance of the models results show that the rs reptree model has the highest prediction capability for flood susceptibility assessment with the highest area under the roc curve auc value 0 949 0 907 the smallest se 0 011 0 023 and the narrowest ci 95 0 928 0 970 0 863 0 952 for the training and validation datasets it was followed by the bag reptree and reptree models respectively the results also proved the superiority of the ensemble method over using these methods individually keywords flood susceptibility machine learning ensemble framework gis china 1 introduction a natural disaster is a major adverse event resulting from natural planetary processes that include floods hurricanes tornadoes volcanic eruptions earthquakes and tsunamis such natural disasters can cause huge loss of life and economic damage hyndman and hyndman 2016 the severity of these disasters depends on the affected population s resilience and ability to recover and on the infrastructural stability among natural disasters flooding is considered one of the most devastating phenomena in the world from 1996 to 2015 around 150 061 flood events occurred in the world and were responsible for 11 1 of the global disaster fatalities based on information from the united nations office for disaster risk reduction unisdr hong et al 2018a flooding is a serious disaster that has caused economic damage and loss of human life throughout history according to a report by the national climate center of china average annual economic loss due to flood events in china has been about 17 billion us dollars b usd since 1990 huang et al 2008 zhang et al 2015 many torrential floods have recently occurred in china due to its high density of population lack of legal supervision of dense intensive construction around rivers and extensive deforestation hong et al 2018b hence preparing flood susceptibility maps fsms is an appropriate management tool needed to identify areas at risk and is essential to prevent construction in such high risk areas and to protect at risk natural resources tehrany et al 2013 geographic information systems giss have become effective tools for analysis of spatial management and data manipulation because of their ability to handle large amounts of spatial data oh and pradhan 2011 khosravi et al 2016a the combination of statistical and probabilistic models with remote sensing rs and gis has been used often by a variety of researchers pradhan 2010 youssef et al 2011 garcía pintado et al 2013 there are two major method in flood susceptibility mapping named qualitative or quantitative degiorgis et al 2012 manfreda et al 2015 gnecco et al 2017 samela et al 2017 khosravi et al 2018 razavi termeh et al 2018 in recent years statistical and probabilistic models have been very popular in quantitative method levy et al 2007 lee et al 2012 for example some of statistical and probabilistic models include frequency ratio fr tehrany et al 2013 rahmati et al 2016 weights of evidence woe tehrany et al 2014 shafapour tehrany et al 2017 and logistic regression lr tehrany et al 2013 the analytical hierarchy process ahp khosravi et al 2016a artificial neural networks anns kia et al 2012 and decision trees dts khosravi et al 2018 have also been useful in particular methods such as adaptive neuro fuzzy inference systems anfiss tien bui et al 2016 the anfis genetic algorithm ga hong et al 2018a and anfis particle swarm optimization pso termeh et al 2018 have advanced both the conceptual and practical aspects of fsms more recently machine learning methods have been applied in flood susceptibility mapping fsm by many researchers maier et al 2010 kia et al 2012 of particular usefulness in fsms have been naïve bayes trees nbt khosravi et al 2018 logistic model trees lmts chapi et al 2017 and fuzzy weight of evidence fuzzy wofe hong et al 2018b however no general agreement has yet been reached on how to select the best model for any natural hazard assessment such as flood susceptibility thus new models are needed and should be tested therefore the main purpose of this study was to present new hybrid approaches of bagging and random subspace based reduced error pruning tree reptree classifiers for flood susceptibility modeling because ensembles of bagging random subspace and reptree have rarely been applied in flood susceptibility mapping these meta classifiers ensembles are novel frameworks for machine learning that are used to increase the prediction accuracy of a base classifier single classifier for this study quannan county of china which is prone to flooding was selected for flood susceptibility modeling data processing was conducted using arcgis 10 5 and weka 3 9 2 software 2 description of study area quannan county covers about 1520 km2 and is located in ganzhou city jiangxi province china the region is defined by 24 30 00 to 25 10 00 n and 114 10 00 to 114 50 00 e fig 1 the elevation in quannan county varies from 146 to 1104 m a s l in quannan county the prevailing climate is mid subtropical monsoon according to a report from the jiangxi meteorology bureau http www weather org cn the average temperature is 18 8 c and the average annual rainfall is 1653 5 mm due to the monsoon condition and geographical position rainfall is unevenly distributed in both time and space for the rainy season from march to august the monthly average rainfall is more than 150 mm for the dry season from october to january the monthly average rainfall is more than 100 mm in the flood season april to june the monthly average rainfall is about 648 2 mm and precipitation within this interval accounts for 39 2 of the annual rainfall analysis of a geological map of quannan county indicates that the area is mainly outcrops of basalt sandstone limestone and syenite the heavy rainfall is the main factor influencing floods according to a recent report by the quannan government http www quannan gov cn and historical records from april 10 to 14 2007 quannan county was subjected to a flood according to statistics this flood in quannan county affected nine townships towns and a population of 95 900 people the crop area affected was 1581 ha related damage included destroyed roadbed surfaces 2 712 km damaged transmission lines 5 92 km damaged embankments 32 and damaged river banks 25 the cumulative direct economic loss was about 5 7 m chy 3 flood database 3 1 flood inventory map a flood inventory map is the first and most important step in flood susceptibility mapping there are many methods to get a flood inventory map in fact historical records and interpretation of aerial images are the main methods to get a reasonable and accurate map there were historical 363 flood events determined in the study area fig 1 whose information were obtained from the historical records field surveys and google earth the data was supported by the jiangxi meteorological bureau 3 2 factors influencing floods the process of flooding is very complicated and comprehensive therefore the factors that influence flooding are complex until now there has been no agreement about how to deal accurately with these factors in this study we drew upon the literature and actual circumstances of quannan county tehrany et al 2015 chapi et al 2017 shafizadeh moghadam et al 2018 the present study analyzed thirteen influencing factors namely altitude slope angle slope aspect curvature stream power index spi sediment transport index sti topographic wetness index twi distance to rivers normalized difference vegetation index ndvi soil land use lithology and rainfall data analysis and visualization was performed in a gis environment with data in a raster format with spatial resolution of 30 m a digital elevation model dem for the study area was generated from the aster gdem version 2 http gdem ersdac jspacesystems or jp based on the dem the altitude slope angle slope aspect curvature twi spi sti and distance to rivers were determined fig 2 a h the ndvi map fig 2i was obtained using landsat 8 oli satellite images acquired on august 20 2017 http www gscloud cn the ndvi values were calculated using the formula 1 ndvi nir r nir r in this case nir and r red are in the near infrared and red band the soil map was compiled to form five classes fig 2j a land use map was created from landsat 8 oli satellite image data of which interpretation yielded five classes farm land forest land grass land water and residential area the maximum likelihood supervision method was used for the classification with classification accuracy of 91 3 fig 2k the lithology map for the study area was obtained from china geology survey http www cgs gov cn and was categorized into nine groups a b c d e f g h and i fig 2l regarding rainfall the mean annual precipitation at 14 rainfall stations was used to create the rainfall map which is from 1871 to 2448 93 mm using the inverse distance weighted method fig 2m 4 methodology flood susceptibility mapping is regarded as an essential tool for prevention and management of the occurrence of future flooding khosravi et al 2016b the step by step procedures used for the proposed method in the current study are shown in fig 3 those involved in the preparation of the flood inventory and influencing factors included selection of flood influencing factors application of proposed models and validation of model performance 4 1 preparation of training and validation datasets the flood inventory map was randomly partitioned into two parts to be used for training and validation respectively in this case 70 254 flood locations was used for the training dataset and the other 30 109 remaining flood locations was used for the validation dataset flood susceptibility mapping using machine learning methods can be considered binary classification which requires the availability of flood and non flood locations simultaneously it is suggested that the number of non flood locations must be similar to the number and distribution of flood locations to avoid bias su et al 2015 therefore a total of 363 non flood locations were selected randomly from areas that are not prone to floods these were also randomly divided in the same ratio as used for the flood locations finally the values of the thirteen flood influencing factors were extracted for the flood and non flood locations to obtain the training and validation datasets 4 2 factor selection using the cae method it is important that flood influencing factors that make no contribution or that generate noise be removed from the modelling process chapi et al 2017 in the present study the contributions of flood influencing factors were evaluated using the correlation attribute evaluation cae method this allows evaluation of the contribution of a flood influencing factor by measuring the pearson s correlation between the factor and the class witten et al 2011 4 3 reptree reptree is considered a fast decision algorithm and is based on the principle of calculating the information gain and reducing the error arising from variance joseph and ravichandran 2012 reptree builds a decision regression tree using information gain as the splitting criterion and then prunes it using reduced error pruning jayanthi and sasikala 2013 the complexity of the decision tree model is decreased using the reduce error pruning method so that the error arising from variance is reduced use of decision trees is a very popular method for classifying problems because of the simple configuration generally there are two ways to prune decision trees pre pruning and post pruning when the number of instances that reach a node is lower than the percentage of the training set that node is not divided it is considered that the variance of the model is generated by training with too few instances and that accordingly the generalization error will increase for this reason if expansion of the tree is stopped as it is being built this process is called pre pruning lakshmi 2015 however in post pruning the tree is expanded until all the leaves are pure and there is no error in the training set then sub trees will be found to memorize and prune later we replace each sub tree with a leaf that is trained by instances covered in the training set of that sub tree next we compare these two options in a pruning set when a leaf does not lead to greater error in the pruning set we will prune the sub tree and use the leaf otherwise we keep the sub tree jayanthi and sasikala 2013 comparing the pre pruning and post pruning processes it is obvious that pre pruning produces trees faster while post pruning produces more successful trees 4 4 bagging bagging is one of the most popular techniques for constructing ensembles prasad et al 2006 chen et al 2018c in bagging each training set is constructed by forming a bootstrap replicate of the original training set breiman 1996 this means that given a training set t of n instances then a new training set t is constructed by drawing n instances uniformly from t an instance in the training set has the probability 1 1 1 n n of being selected at least once in the n times instances are randomly selected from the training set bauer and kohavi 1999 4 5 random subspace similar to bagging the random subspace method rsm benefits from bootstrapping and aggregation however the difference between them is that bagging bootstraps the training samples while rsm bootstraps in the feature space tao et al 2006 there are four inputs in rsm skurichina and duin 2002 the training set x the base classifier w the number of subspaces l and the number of subspaces d s in rsm l subsets of d s features are randomly generated and stored in subspace then the base classifier is trained on each of the subsets in subspace in order to produce l different classifiers these classifiers are combined to produce an ensemble classifier e a detailed description of the algorithm can be seen in kuncheva et al 2010 4 6 receiver operating characteristic curve the receiver operating characteristic roc curve is plotted by considering a range of possible cutoff values of sensitivity and 1 specificity and plotted with the former on the y axis and latter on the x axis ko and lo 2018 chen et al 2019e the area under the curve auc is a significant measurement to assess the prediction capability of models chen et al 2018b and a value approaching 1 0 indicates good prediction ko and lo 2018 5 results and analysis 5 1 selection of influencing factors using the cae method table 1 shows the selection of influencing factors using the correlation attribute evaluation cae method the result shows that all flood influencing factors have positive average merit am for flood occurrences in quannan county in general ndvi has the highest value am 0 757 followed by slope angle am 0 624 distance to rivers am 0 540 and altitude am 0 448 curvature slope aspect and lithology have lower predictive ability values for flood occurrences in the quannan county with am values of 0 024 0 013 and 0 011 respectively 5 2 model validation and comparison the receiver operating characteristic roc chen et al 2018a 2019a plots for the three flood susceptibility maps using the training dataset are shown in fig 4 and the detailed parameters of the roc curves are shown in table 2 the results demonstrate that the rs reptree model has the highest area under the curve auc value of 0 949 it also has the lowest standard error se of 0 011 and an asymptotic 95 confidence interval ci of 0 928 0 970 its performance is followed by that of the bag reptree model with an auc value of 0 935 se 0 012 asymptotic 95 ci 0 912 0 959 and then of the reptree model with an auc value of 0 907 se 0 015 asymptotic 95 ci 0 878 0 936 hence from the analysis results it is determined that all of the three models displayed a reasonable roc and the reptree model shows the best performance in predicting flood susceptibility followed by the bag reptree and reptree models the roc plots for the three flood susceptibility maps using the validation dataset are shown in fig 5 and the detailed parameters of the roc curves are shown in table 3 the results demonstrate that the rs reptree model had the highest auc value of 0 907 and also had the lowest se of 0 023 and an asymptotic 95 ci of 0 863 0 952 its performance was followed by that of the bag reptree model with an auc value of 0 892 se 0 024 asymptotic 95 ci 0 844 0 940 and then of the reptree model with an auc value of 0 879 se 0 026 asymptotic 95 ci 0 829 0 929 therefore from analysis of the results it can be concluded that all three of the models displayed a reasonable roc although the rs reptree model showed the best performance in validating flood susceptibility followed by the bag reptree and reptree models in this study wilcoxon signed rank tests chen et al 2017 khosravi et al 2018 chen et al 2019d between the three predictive models were performed table 4 for the reptree and bag reptree models the p value at a 95 significance level was estimated to be 0 001 0 05 while the z value 3 321 exceeded the critical values of z 1 96 and 1 96 this showed that the performance of the flood susceptibility models was significantly different for the reptree and rs reptree models the p value at a 95 significance level was estimated to be 0 001 0 05 while the z value 4 018 exceeded the critical values of z 1 96 and 1 96 showing that the performances of the flood susceptibility models were significantly different for the bag reptree and rs reptree models the p value at a 95 significance level was estimated to be 0 048 0 05 while the z value 1 981 exceeded the critical values of z 1 96 and 1 96 showing that the performances of the flood susceptibility models were significantly different 5 3 generating flood susceptibility maps the three flood susceptibility maps produced from the reptree bag reptree and rs reptree models are shown in fig 6 four flood susceptibility classes were regrouped for the reptree bag reptree and rs reptree models using the natural break method chen et al 2019b c low moderate high and very high the area percentages of each class for the three flood susceptibility maps are displayed in fig 7 it appears that for the reptree model the low class has the largest area percentage 78 13 followed by very high 16 55 moderate 2 91 and high 2 42 classes for the bag reptree model the area percentages are 82 63 5 99 2 71 and 8 66 for the low moderate high and very high classes respectively for the rs reptree model the area percentages are 76 05 10 85 5 33 and 7 77 for the low moderate high and very high classes respectively 6 discussion and conclusions flooding is one of the most destructive phenomena that occurs in mountainous environments especially in china zhao et al 2018 flood susceptibility mapping is regarded as an indispensable step to prevent and manage future flooding events kourgialas and karatzas 2011 however due to the complex conditions it is difficult to make reliable predictions of flood occurrence the factors generating floods are relatively complex and their mechanisms are still under research in general they can be summarized as internal and external factors among them the internal factors are those involving the basic conditions of the flood occurrence including geomorphology soil geology and hydrology sarhadi et al 2012 found that physio hydrological and land use characteristics are the major factors controlling frequent floods with low return periods studies have shown that heavy rainfall is an important external factor in floods norbiato et al 2008 evaluated a threshold based flash flood warning method by considering a wide range of climatic and physiographic conditions in addition human activities are also significant external factors and include such as destroying forests or grasslands reclaiming land from lakes and encroaching on tidal flat areas of rivers besides the improvement of input data needs more attention in future work for example until now there is no standard rule to select non flood locations in previous studies it is suggested that the number of non flood locations must be similar to the number and distribution of flood locations to avoid bias su et al 2015 besides non flood locations were random selected in study area these methods assume that the locations that did not have flood occurrence should considered as non flood location hong et al 2018b khosravi et al 2018 therefore in future work we should focus on the method to select reliable non flood location to improve the quality of the input data tehrany et al 2013 proposed a combination of frequency ratio fr and logistic regression lr statistical methods and compared the prediction performance with a rule based decision tree dt for flood susceptibility mapping at kelantan malaysia they found that the integrated method of fr and lr success rate 90 prediction rate 83 was superior to dt success rate 87 prediction rate 82 chapi et al 2017 proposed a novel hybrid model bagging and logistic model tree bagging lmt for mapping flood susceptibility for the haraz watershed in northern iran this involved four state of the art benchmark machine learning techniques including lmt logistic regression bayesian logistic regression and random forest models which were used for comparison of the proposed model they concluded that the proposed bagging lmt model produced higher prediction accuracy razavi termeh et al 2018 mapped flood hazards over the jahrom township in fars province using a combination of adaptive neuro fuzzy inference systems anfis with ant colony optimization aco genetic algorithm ga and particle swarm optimization pso the study showed that the auc values of anfis aco anfis ga and anfis pso ensembles were 91 8 92 6 and 94 5 respectively which were superior than with an individual frequency ratio model razavi termeh et al 2018 ensemble learning is a machine learning method that uses a series of methods and integrates various learning results using a certain rule to obtain better results than with a single method the advantage of ensemble learning is that the ability for generalization classification accuracy and operational efficiency are significantly improved in recent years ensemble learning has become a focal topic in natural hazard risk assessment including flood and landslide susceptibility according to the results obtained in the present study the proposed novel hybrid rs reptree model which generated the highest auc value 0 949 the smallest se 0 011 and the narrowest ci 95 0 928 0 970 for the training dataset it also generated the highest auc value 0 907 smallest se 0 023 and narrowest ci 95 0 863 0 952 for the validation dataset and yielded the best results in flood susceptibility mapping however a pairwise comparison using wilcoxon signed rank test between the models revealed that the performance of all the models were different with statistical significance it can also be concluded that although the complexity of a hybrid model is greater than that of a basic model the learning performance can be significantly improved to a certain extent so that the final hybrid model can not only reduce the fitting error but could also improve the generalization ability concerning the percentage of highly susceptibility classes very high and high all three models depicted similar spatial distribution however the hybrid models targeted slightly smaller percentages 11 37 and 13 10 for the bag reptree and rs reptree models respectively compared to that by the individual reptree model 18 97 this implies a more practical result in relation to the hybrid bag reptree and rs reptree models and one which has more precision and reliability this could reduce the time and cost of an effective mitigation plan in those areas targeted for land use planning as a conclusion the outputs attained from this study demonstrated the superiority of hybrid models and the flood susceptibility maps produced can assist decision makers planners and researchers to prevent and reduce the occurrence of floods in the regions determined to be susceptible declaration of competing interest individual contribution of all authors wei chen and shaojun li did the primary survey and data analysis work himan shahabi has contributed in literature survey and statistical analysis haoyuan hong has contributed in writing and statistical analysis wang yi xiaojing wang and baharin bin ahmadhas contributed in improving the manuscript acknowledgments this study was supported by the international partnership program of chinese academy of sciences grant no 115242kysb20170022 the national natural science foundation of china grant no 41807192 natural science basic research program of shaanxi program no 2019jq 094 china postdoctoral science foundation grant no 2018t111084 2017m613168 project funded by shaanxi province postdoctoral science foundation grant no 2017bshydzz07 the iran national science foundation insf grant no 96004000 and universiti teknologi malaysia utm based on a research university grant q j130000 2527 17h84 
