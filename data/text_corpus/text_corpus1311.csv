index,text
6555,streamflow data is important for studies of water resources and flood management but an inherent problem is that many catchments of interest are ungauged the lack of data is particularly the case for small catchments where flow data with high temporal resolution is needed this paper presents an analysis of regionalizing parameters of the distance distribution dynamics ddd rainfall runoff model for predicting hourly flows at small ungauged rural catchments the performance of the model with hourly time resolution has been evaluated calibrated and validated for 41 small gauged catchments in norway areas from 1 km2 50 km2 the model parameters needing regionalization have been regionalized using three different methods multiple regression physical similarity single donor and pooling group based methods and a combination of the two methods seven independent catchments which are not used in the evaluation are used for validation of the regionalization methods all the three methods the multiple regression pooling group and combined methods perform satisfactorily 0 5 kge 0 75 the combined method which combines multiple regression and pooling group performed slightly better than the other methods some model parameters namely those describing recession characteristics estimated by the regionalization methods appear to be a better choice than those estimated locally from short period of hydro meteorological data for some test catchments the single donor method did not perform satisfactorily the satisfactory performance of the combined method shows that regionalization of ddd model parameters is possible by combining multiple regression and physical similarity methods keywords small ungauged catchments prediction of hourly flow recession parameters regionalizations distance distribution dynamics ddd rainfall runoff model 1 introduction streamflow is important information for water resources management applications such as flood risk management water resources planning and environmental impact assessment parajka et al 2013 westerberg et al 2014 however most of the catchments that we are interested in are ungauged which makes a method to predict flow in ungauged catchments an important prerequisite bloschl et al 2013 parajka et al 2013 tegegne and kim 2018 reliable estimation of continuous streamflow in ungauged catchments has remained a fundamental challenge in hydrology although significant insights have been gained in recent years steinschneider et al 2014 wagener and wheater 2006 wagener et al 2004 to solve the challenges posed by ungauged catchments a number of predictive tools have been developed and tested e g data driven models such as multiple linear regression mlr autoregressive moving average arma and artificial neural networks anns lumped models e g hydrologiska byråns for vattenbalansavdelning model hbv distributed models e g mike she and statistical regionalization that allow objective and quantitative decision making with respect to water resources management but considerable uncertainties remain sivapalan et al 2003 the international prediction in ungauged basins pub initiative recommends the use of an appropriate model structure for predicting flow in ungauged catchments blöschl et al 2013 and the choice of appropriate model structure helps in reducing predictive uncertainty son and sivapalan 2007 flash floods are usually localized disasters that occur in small catchments with response times of a few hours or even less borga et al 2007 the short lead time and small area collectively enhance the difficulty of flood management in such catchments miao et al 2016 in addition small catchments and short time scales are the most under observed and problematic in terms of prediction and design and should be identified as a priority in water resource and flood management spence et al 2013 water resource management problems are increasingly approached using continuous time rainfall runoff modelling lamb and kay 2004 swain and patra 2017 rather than the traditional statistical or event based models simple concept modelssuch as the rational formula and its more sophisticated derivatives are criticized for containing parameters which are difficult to estimate e g the runoff coefficient or for being founded upon questionable assumptions e g identical return period for precipitation and resulting peak flow viviroli et al 2009 the advantage of continuous simulation approaches is that the catchment moisture state prior to the flow producing rainfall event is implicitly incorporated within the modeling framework provided that the model produces reasonable simulations pathiraja et al 2012 furthermore getting the right answers for the right reasons is crucial for getting the right answers at all if conditions shift beyond the range of prior experience due to extreme precipitation events climate change or shifts in land use kirchner 2006 catchment size has an effect in hydrological modelling and hydrological responses of small catchments are likely to be different from and more variable than those of large catchments pilgrim et al 1982 small catchments need to be modelled using shorter time steps blöschl and sivapalan 1995 bronstert 2003 vormoor and skaugen 2013 wetterhall et al 2011 until the 1990s hydrologists had to rely mostly on data with a daily time step e g accumulated rainfall amounts recorded once a day by observers and this caused limitations to the applicability of rainfall runoff models for problems e g flooding needing short time steps blöschl and sivapalan 1995 creutin and obled 1980 however over the last two decades the availability of hourly and even sub hourly data is increasing in many countries especially with the implementation of automatic rain gauge networks and rainfall radars berne and krajewski 2013 creutin and borga 2003 a rainfall runoff model is one of the tools used to predict flows in ungauged catchments nruthya and srinivas 2015 this method requires estimation of the model parameters using regionalization zhang et al 2014 there are different types of rainfall runoff hydrological models and regionalization methods one method may work well for one type of model and another method may work well for another model in different regions razavi and coulibaly 2013 because each model has its own unique characteristics and respective applications devi et al 2015 conceptual rainfall runoff models such as hbv and identification of unit hydrographs and component flows from rainfall evaporation and stream data ihacres have emerged as the most frequently used models for estimating continuous stream flow at ungauged catchments razavi and coulibaly 2013 the three commonly used regionalization methods are regression physical similarity and spatial proximity bao et al 2012 bárdossy 2007 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 some hydrologists have tried to compare and evaluate the methods but the results are not consistent kay et al 2006 mcintyre et al 2005 oudin et al 2008 young 2006 zhang and chiew 2009 young 2006 regionalized the probability distributed model pdm in 260 catchments in the uk and found that the regression method was more accurate than the spatial proximity method skaugen et al 2015 regionalized the distance distribution dynamics ddd model in 84 catchments ranging from small to large sizes in norway using daily data and found that multiple regression equations performed well in predicting flows at ungauged catchments kay et al 2006 tried to compare the performance of regression and physical similarity methods with two models pdm and time area topographic extension tate for 119 catchments across the uk but did not obtain consistent results for the pdm physical similarity was more accurate but regression outperformed physical similarity for tate merz and blöschl 2004 found that the multiple regression method of regionalization at 308 catchments in austria using hbv model involving 11 calibration parameters gave significantly poorer results than the spatial proximity method oudin et al 2008 used two lumped rainfall runoff models with daily data on 913 french catchments and found that when a dense network of gauging stations is available the spatial proximity method provides the best regionalization solution while the regression method shows the least satisfactory results and the physical similarity method is in between the two others in accuracy magette et al 1976 used 21 catchments in usa in the regionalization of six selected parameters of the kentucky watershed model kwm using hourly data and found that a multiple regression method was successful in estimating model parameters from catchment descriptors but a simple linear regression model was unsuccessful kokkonen et al 2003 used 13 catchments in north carolina usa in the regionalization of six parameters of ihacres model with daily data and found that the arithmetic mean method of regionalization gave poorer results than regression and similar hydrologic behavior methods the major goal of the international pub initiative was to reduce the uncertainty in the prediction of runoff by shifting away from tools that require calibration and curve fitting to tools that need little or no calibration parsimonious models spence et al 2013 the pub synthesis book states that the starting point for predicting the runoff hydrograph in ungauged catchments using rainfall runoff models is the choice of an appropriate model structure blöschl et al 2013 sivapalan et al 2003 pointed out that for predicting flow at ungauged catchments it is important to challenge and overcome the potential problem posed by the uniqueness in place beven 2000 of catchments it is hence important that the hydrologic models are parametrically efficient parsimonious and their parameters are identifiable from the available catchment data young and romanowicz 2004 ddd is a parsimonious rainfall runoff model with few calibration parameters recently developed by skaugen and onof 2014 and many of its other parameters can be estimated from the topography and land use of a catchment skaugen and onof 2014 previous experience in using ddd for estimation of flow at ungauged catchments with daily data showed satisfactory results skaugen et al 2015 since ddd is one of the hydrological models which has features acknowledged for prediction of flow at ungauged catchments we used it in this study during the calibration of hydrological models it is common and probable that multiple calibration periods yield multiple optimum parameter sets different sets of optimum parameter values may yield similar performances and this is designated as equifinality beven 2006 since conceptual hydrological models can be viewed as an empirically derived combination of mathematical operators describing the main features of an idealized hydrological cycle one cannot rely on a uniquely determined model parameter set or model prediction kuczera and parent 1998 consequently attention should be given to uncertainties in hydrological modelling prediction uncertainties in hydrological modelling arise from a variety of sources such as errors associated with input data and data for calibration imperfection in model structure calibration accuracy and uncertainty in model parameters benke et al 2008 jin et al 2010 montanari 2011 in this study uncertainty of the calibrated model parameters has been addressed most of the regionalization methods applied so far are based on daily temporal resolution in catchments ranging from small to large sizes masih et al 2010 merz et al 2006 hailegeorgis et al 2015 and viviroli and seibert 2015 have done regionalization studies with hourly resolution but the studies are not specific to small catchments response times of small catchments are typically less than 24 h and thus for flood forecasting purposes hydrological models are required to provide simulations at high temporal resolution reynolds et al 2017 therefore regionalization of model parameters for small catchments with sub daily time resolution is important in this study we have regionalized the ddd model parameters for small catchments with hourly time resolution in order to predict flows at ungauged rural small catchments in norway the specific research objectives are 1 to evaluate the performance of the ddd rainfall runoff hydrological model on rural small catchments with hourly temporal resolution areas from 1 km2 50 km2 it includes the selection of parameters to calibrate or to fix the model goodness of fit and uncertainties in the calibration parameters 2 to evaluate multiple regression based regionalization against a physical similarity based regionalization method 3 to analyze and assess whether there is a combined regression and physical similarity method for regionalizing ddd model parameters 2 study area and data forty one gauged small rural catchments located across norway are used in the study we selected the catchments from the norwegian water resources and energy directorate nve hydra ii database of gauged catchments our definition of a small catchment follows that of fleig and wilson 2013 with an upper area limit of 50 km2 the number of catchments is limited by the availability of hydro meteorological data with the required temporal resolution of 1 h and a length of record that makes calibration possible seven additional gauged catchments which are not used in the model calibration have been used in validation fig 1 shows the location of the study and test catchments time series of precipitation temperature and discharge are the main input data for running and calibrating the ddd model precipitation and temperature are based on a 1 1 km gridded product of the norwegian meteorological institute http thredds met no thredds catalog html with hourly temporal resolution lussana et al 2016 since the data is available from 2010 onwards we have used a total of five years of data for calibration and validation the ddd model uses distributed precipitation and temperature data as input for the model s 10 elevation zones extracted from the hypsographic curve of a catchment the elevation of the center of each temperature and precipitation grid cell has been extracted from the 10 10 m digital elevation model dem of norway for the model elevation zone that contains more than one grid cell mean of the values of temperature and precipitation is used hourly discharge data have been obtained from the norwegian water resources and energy directorates nve hydra ii database the constant model parameters during the simulation period are derived from an analysis of hydro meteorological topographical and land use data for a catchment using gis the source of the topography and land use data is the norwegian mapping authority www statkart no the 10 10 m dem the river network and the 1 50000 scale land use data have been retrieved and used in the study the dem has been re conditioned to the naturally occurring river network using the dem reconditioning tool from arc hydro to create a hydrologically correct terrain model that can improve the accuracy of watershed modeling li 2014 the re conditioned dem is further used to determine the distance distributions of hill slopes and river networks as needed by ddd 3 methodology 3 1 model structure the ddd model is written in r programming language r core and team 2017 and currently runs operationally with daily and three hourly time steps at the norwegian flood forecasting service at nve subsurface and dynamic runoff are the two main modules of the model the volume capacity of the subsurface water reservoir w mm is shared between a saturated zone with volume s mm and an unsaturated zone with volume d mm if the saturated zone is high the unsaturated volume has to be small skaugen and onof 2014 the actual water volume present in the unsaturated zone is described as z mm the subsurface state variables are updated after evaluating whether the current soil moisture z t together with the input of rain and snowmelt g t represent an excess of water over the field capacity r which is fixed at 30 r 0 3 of d t skaugen and onof 2014 if g t z t r d t then the excess water x t is added to s t 1 excess water x t m a x g t z t d t r 0 d t 2 groundwater ds dt x t q t 3 soil water content d z dt g t x t e a t 4 soil water zone dd dt ds dt 5 potential evapotranspiration e p c e a t 6 actual evapotranspiration e a e p s z w q t is runoff and e a t is the actual evapotranspiration which is estimated as a function of potential evapotranspiration and the level of storage a degree hour factor cea is positive for positive temperature t and zero for negative temperature ea is drawn from z this is indeed a simplification but experience from skaugen and onof 2014 shows that the evapotranspiration routine in ddd calculates similar values to the approach used in hbv bergström 1976 a recession analysis of the observed runoff from the catchment is used to estimate the catchment scale fluctuations of storage the capacity of the subsurface water reservoir w see skaugen and mengistu 2016 the dynamics of runoff in ddd has been derived from the catchment features using a gis combined with runoff recession analysis the method for describing the runoff dynamics of a catchment is built on the distance distribution derived from the catchment topography the distances from the points in the catchment to the nearest river reach are calculated for marsh and soil non marsh parts of a hillslope previous studies in more than 120 catchments in norway showed that the exponential distribution described the hillslope distance distribution well and the normal distribution described well the distances between points in the river network and outlet of a catchment skaugen and mengistu 2016 skaugen and onof 2014 fig 2 shows a map of the distance distributions of the marsh and soil non marsh parts of the hillslope and river network for the valen catchment and the corresponding empirical cumulative distribution functions fig 3 shows the structure of the ddd model all gis work is done with arcmap 10 3 and the recession analysis is done using the r script in the model water is conveyed through the soils to the river network by waves with celerity determined by the actual storage s t in the catchment skaugen and mengistu 2016 skaugen and onof 2014 the celerity associated with the different levels of subsurface storage is estimated by assuming exponential recessions with parameter λ in the equation q t q 0 λ e λ t t 0 where q 0 is the peak discharge immediately before the recession starts λ is the slope of change per time t of the recession in the log log space and calculated using eq 7 the distribution of λ is modeled using a two parameter gamma distribution 7 λ t log q t log q t δ t δ t the celerity v is calculated as a function of λ using eq 8 8 v λ d mean δ t d mean is the mean of the distances from points in the catchment to the nearest river the capacity of the subsurface reservoir w mm is divided into storage levels i corresponding to the quantiles of the distribution of λ under the assumption that the higher the storage the higher the value of λ each storage level is further assigned a celerity ν i λ i d mean δ t see eq 8 where λ i is the parameter of the unit hydrograph for the individual storage level i and estimated such that the runoff from several storage levels will give a unit hydrograph equal to the exponential unit hydrograph with a parameter λ i with the assumption that the recession and its distribution carry information on the distribution of catchment scale storage we can consider that the temporal distribution of catchment scale storage s t is a scaled version to that of λ s t is calculated using eq 9 and its distribution is modelled using a two parameter gamma distribution 9 s t q t 1 e λ t 3 2 model parameters and calibration the model has three main groups of parameters the first group are those determined by model calibration against observed discharge the upper 5 in table 1 the second group are those estimated from observed hydro meteorological data the lower 4 in table 1 and the upper 3 in table 2 and the third group are those estimated from geographical data all in table 2 except the upper 3 the calibration of the model is performed using the probability particle swarm optimization ppso algorithm lu and han 2011 the kling gupta efficiency criteria kge has been used as an objective function for the calibration gupta et al 2009 and the kge and bias ratio of the mean of simulated to observed discharge have been used to evaluate the calibrated results in addition the hydrographs of all catchments are visually inspected the calibration intervals of the parameters are set based on literature and experience in using the ddd model skaugen and mengistu 2016 sælthun 1996 since cea and degree hour factor for snow melt cx are sensitive to the temporal resolution we used the ddd model calibration results from 84 catchments with daily time step skaugen et al 2015 as a starting point and literature review for setting the intervals of hourly time step the mean celerity for river flow rv has a standard value of 1 m s in using ddd with catchments ranging from small to large sizes skaugen and mengistu 2016 with daily time steps but it has been calibrated with an interval of plus or minus 0 5 m s of the standard value for hourly resolution from experience and field measurements we have set the calibration interval of maximum liquid water content of snow pro between 3 and 10 fierz et al 2009 saloranta 2012 for the 41 study catchments we have calibrated the model on 2 3 years of data and validated on 1 2 years the selection of the period is mainly based on the availability of flow and gridded precipitation and temperature data the gridded precipitation data in norway is highly uncertain due to rugged terrain and few precipitation stations in elevated areas the data used does not include the correction for undercatch due to the wind and the relation between the precipitation and elevation is introduced only locally around the station locations as a result the predicted precipitation field may potentially underestimate the actual precipitation especially at higher elevations where the station network is sparser such as at the mountainous region of the southern part of norway frauenfelder et al 2017 lussana et al 2018 accordingly we introduced a precipitation correction factor to take this into account so that the long term water balance is correct the correction factor is applied to those catchments that give bias less than 0 8 and the correction factor is the ratio of long term mean annual discharge to mean of simulated discharge for purely ungauged catchments the long term mean annual discharge is estimated from a gridded map of average annual runoff for norway for the period 1961 1990 beldring et al 2003 the threshold temperature for rain or snow and snow melt are fixed with a value of 0 5 c and 0 0 c respectively based on literature saloranta 2012 skaugen 1998 this is done to avoid regressed parameters that do not have a clear physical relationship with any of the catchment descriptors but which can be fixed on a physical or an empirical basis removing parameters from calibration also strengthens the parsimony of the model table 1 lists the nine model parameters needing regionalization five calibrated and four estimated from recession analysis and table 2 lists the non regionalized model parameters the snow routine in ddd has two non regionalized parameters the shape parameter a0 and the decorrelation length d of the gamma distribution of snow and snow water equivalent swe skaugen and weltzien 2016 are estimated from the previous calibration of 84 catchments in norway skaugen et al 2015 3 3 uncertainty analysis of calibrated parameters we calibrated the model using probability particle swarm optimization ppso algorithm with 500 calibration runs for each study catchment and sampled sets of parameters from the calibration runs for uncertainty analysis to select behavioral sets of parameters we used a threshold kge value of 70th percentile a value below which at least 70 of the values lie from the 500 runs for each study catchment evaluating several thousand calibration runs with an hourly resolution at 41 study catchments is computationally costly to check whether the 500 runs used in the calibration give different behavioral sets from several thousand calibration runs we ran the model with 2000 runs at one catchment and 5000 and 10 000 runs at another catchment all the study catchments are run with the behavioral sets of parameters but the results are presented only for four randomly selected catchments for each timestep we sampled the number of discharge values equal to the number of behavioral parameter sets for each catchment and the minimum and maximum discharges are used to estimate the width of the uncertainty bounds 3 4 regionalization methods we used 41 catchments with kge greater than or equal to 0 55 for the regionalization of the model parameters for the three regionalization methods used in this study 19 catchment descriptors cds readily available from catchment data are used at the start and later refined based on their significance in estimating model parameters table 3 since the selected catchments are widely spread across norway the spatial proximity method of regionalization may not be favored and is not considered in this study oudin et al 2008 validation of the regionalization methods is done assuming a selected number of gauged catchments to be ungauged and then comparing simulated runoff using the regionalized parameters with observed runoff 3 4 1 multiple regression method the multiple regression equations which are used to relate the cds with the model parameters are fitted to the calibrated model parameters of the 41 catchments we used a stepwise regression procedure for building the regression model we build the model from 19 candidate cds by entering and removing cds in a stepwise manner into the regression model until there is no convincing reason to enter or remove any more before starting to use the step wise procedure we removed a cd which is highly correlated with another cd s to identify the correlation between the cds we have plotted the scatter plot matrix of the cds predictors when r squared of correlation between two cds is greater than or equal to 0 5 they are considered as highly correlated the stepwise procedure is described in detail as follows i we set a significance level of 0 2 for deciding when to enter into and remove from the stepwise model we set the significance level so that it is not too difficult to enter cds into the model and not too easy to remove cds from the model ii we fit each of the one predictor models that regress each model parameter with all cds one by one example celerity of river flow rv against bare mountain b rv against forest f etc iii of those predictors cds whose p value is less than 0 2 the first predictor introduced to the stepwise model is the cd that has the smallest p value accordingly bare mountain is the first predictor for celerity of river flow iv if no predictor cd has a p value less than 0 2 stop fitting the regression model cfr is a typical example for this step v now we fit each of the two predictor models that include the first cd as a predictor example rv on b and rs rv on b and u etc vi of those predictors whose p value is less than 0 2 the second predictor put in the stepwise model is the predictor that has the smallest p value for the celerity of river flow rv river slope was deemed the best second predictor and it is therefore entered into the stepwise model vii now since the bare mountain was the first predictor we step back and see if entering river slope into the stepwise model somehow affects the significance of the bare mountain predictor that is check whether the p value of bare mountain is less than 0 2 or not if the p value is less than 0 2 the first predictor bare mountain is retained in the stepwise model viii continue the steps as described above until adding an additional predictor does not yield a p value below the significant level chosen both linear and non linear logarithmic forms of the response variables model parameters needing regionalization and predictors cds are tested in the regression model if the non linear values contribute significantly then the non linear form is retained in the model with the transformed value 3 4 2 physical similarity method the physical similarity method relies on the assumption that the same parameter set should be successful in physically similar catchments merz and blöschl 2004 oudin et al 2008 parajka et al 2005 zhang and chiew 2009 the transfer can be made from one or several donor catchments on the basis of a chosen similarity method mcintyre et al 2005 the method transfers entire parameter sets from gauged to ungauged catchments instead of establishing links between model parameters and cds in this study we used two types of physical similarity methods i e single donor based and pooling group based we used 12 cds 2 hydro climatic 4 land uses 3 topographic and 3 that can describe the runoff dynamic processes in ddd the cds used are area mean elevation mean of soil non marsh land distance from a river mean of marsh land distance from the river mean of river distance from outlet river slope effective lake percentage forest urban mean annual precipitation specific discharge and bare mountain for the single donor type we used a rank accumulated method of physical similarity in selecting a donor catchment to a test catchment oudin et al 2008 zhang and chiew 2009 for each cd the catchment with the most similar descriptor to the test catchment is assigned rank 1 the catchment with the second most similar descriptor is assigned rank 2 and so on when two or more catchments have the same value of cds with the test catchment they have been assigned the same rank the rank numbers of cds have been added for each of the study catchments each cd used for regionalization is given equal weight in the ranking system oudin et al 2008 all the 41 catchments are considered in the selection of the most similar catchment to each of the 7 test catchments the single gauged catchment with the smallest total rank is used as a donor catchment in the pooling group type the parameters for an ungauged site are estimated from the calibrated parameters of a pooling group i e a set of gauged catchments considered to be most similar to the target ungauged catchment in terms of some set of cds kay et al 2006 2007 kay et al 2006 defined physical similarity by euclidean distance in a space of cds that was determined for each model parameter as shown in eq 10 10 dis t a b j 1 j x a j x b j σ x j 2 where j indicates one of a total of j cds 12 in this study x a j is the value of that cd at the a th test catchment x b j is the value of the cd at bth study catchment and σ x j is the standard deviation of the cd across all the n study catchments 41 in this study kay et al 2007 suggests that around a 10 member pooling group is preferable to a much larger number particularly when many cds are used to define euclidean distance for the pooling group k 7 in this study closest neighbors minimum distance are selected to create a pooling group for the test catchments after identifying the pooling group the estimate of the model parameter at the test catchment a α a pg is calculated as a weighted average of the corresponding parameters from the study catchments in the pooling group kay et al 2007 stated that it is more appropriate to write the expression for the model parameter as a weighted average of the estimated parameter values α m for all catchments n as shown in eq 11 11 α a pg m 1 n h am α m m 1 n h am catchments not in the pooling group are given a weight h am equal to zero but those in the pooling are assigned weights to reflect their importance which is based on the distance measure dis t a b as defined in eq 10 the weights of the pooling group members are estimated by eq 12 12 h am 1 s am where s am dis t a b d i s t a m a x for l i n e a r l y d e c r e a s i n g w e i g h t s dis t a b d i s t a m a x 2 for q u a d r a t i c a l l y d e c r e a s i n g w e i g h t s where dis t a m a x is set to be 10 larger than the maximum distance of a pooling group member from the test catchment a in this study we used a linear weight assigning method 3 4 3 combined method the 9 model parameters needing regionalization come from two groups with different estimation methods in the combined method the new parameter set is derived by combining regression and physical similarity methods i e when regression is used for the first group physical similarity is used for the second group and vice versa 4 results 4 1 calibration to evaluate the performance of the ddd model in calibration and validation we used the kge bias and visual inspection of hydrographs the model performs satisfactorily 0 5 kge 0 9 both for the study for calibration and validation and for the test catchments for calibration the minimum and maximum kge values during calibration of the study catchments are 0 55 and 0 89 respectively while the median is 0 71 the minimum and maximum kge values during validation are 0 4 and 0 88 respectively while the median is 0 66 the median bias value for calibration and validation is 0 88 as stated in thiemig et al 2013 0 75 kge 0 9 is good 0 5 kge 0 75 is intermediate and 0 0 kge 0 5 is poor when validating 5 27 and 9 study catchments show poor intermediate and good kge values respectively except for one catchment all test catchments give satisfactory calibration results the visual inspection of the hydrographs shows underestimation of floods caused by heavy precipitation 4 2 uncertainty of calibrated parameters from parameter samples of different sizes at two of the study catchments the frequency histograms and dotty plots of the behavioral calibrated parameters show the same optimal value for the different sizes fig 4 a and b show the histogram and dotty plot for one calibrated parameter celerity of river flow respectively the results show that we have the same value of optimal parameter at 500 5000 and 10 000 iterations and hence a sample size of 500 appears to be sufficient for the uncertainty analysis of calibrated parameters the frequency histograms of behavioral calibrated parameters for the 41 study catchments are analyzed the results of histograms pro cea rv and cx for the four randomly selected study catchments are shown in fig 5 a to d the histograms show that the calibrated parameters have a well identifiable modal value the parameters max out the calibration interval except for rv for each timestep we used discharge values simulated from 170 156 183 and 179 behavioral parameter sets in the calibration period to plot the uncertainty bounds for the catchments with identification numbers id 6 10 19 107 73 27 and 123 29 respectively examples of simulated ranges and observed discharges are shown in fig 6 4 3 regionalization results 4 3 1 regression method the multiple regression equations are shown in eqs 13 20 the overall multiple regression model for cfr is statistically insignificant hence the mean of the 41 calibrated catchments 0 007 has been used as the regionalized model parameter for catchments with a cd value of zero in a logarithmic expression a value of 1 has been assigned the units of the model parameters are presented in table 1 there is a probability that parameters estimated using the multiple regression equations can lie outside of the calibration intervals in this case we will use the nearest boundary value from the calibration interval 13 pro 0 017 0 026 log m m 0 066 log m s 0 038 log m r 0 013 log m e 0 029 u 14 cx exp 4 2 0 41 log m e 0 87 log m p 0 95 log m s 15 cea exp 8 78 0 28 log m e 1 17 log m p 0 26 log m m 0 22 log m r 0 003 f 16 rv 0 83 0 05 log r s 0 003 b 17 gscale exp 5 12 0 12 l e 0 22 ln s q 0 3 log m e 18 gshape 0 82 0 0005 m p 0 009 s q 19 gshi 2 047 g s h a p e 0 658 20 g s c i 0 49 g s c a l e 0 0014 the standardized residuals of the regression model for the response variables show a distribution close to normal fig 7 fig 7 shows that few large and small values deviate from the approximated straight line of normal probability plot while many of the residuals lie along the straight line fig 8 shows the actual calibrated and estimated from observed hydro meteorological data and predicted values of the response variables with the multiple regression model the standard error of estimate is a measure of the accuracy of the regression model predictions and informs how much uncertainty is associated with the model prediction the standard error result of the regression model shows that there is uncertainty in the predicted values table 4 presents the summary of the multiple correlation coefficient r 2 their significance and standard errors for the 41 catchments used in the regionalization the non parametric spearman rank correlation was used seibert 1999 4 3 2 physical similarity method for the single donor type table 5 summarizes the smallest total rank used to select a donor catchment for the pooling group type we analyzed different numbers of group members 3 20 to get an overview on the dependency of kge values on the number of group members the kge values are slightly sensitive to the number of group members table 6 table 7 presents the seven pooling group members for test catchment 19 79 with euclidian distance the weights and the weighted average value regionalized value for celerity of river flow rv 4 3 3 combined method and comparison of methods the ddd model parameters needing regionalization are two groups the first group is estimated from calibration and the second group is estimated from observed hydro meteorological described in detail under section 3 4 3 table 8 presents the regionalized model parameters using the three methods physical similarity multiple regression and combined for one of the test catchments id 25 32 and compares with the calibrated parameters and parameters derived from recession the kge and bias performance results for the three regionalization methods are presented in table 9 kge and bias values have an optimum value of 1 fig 9 presents the observed and predicted hydrographs using the three regionalization methods for two of the test catchments and table 10 compares the performance of calibration against regionalization methods 5 discussion 5 1 model performance and parameters the evaluation of calibration and validation results shows that the ddd model performs satisfactorily but we have observed underestimation of floods caused by heavy precipitation events the main reason for the underestimation of floods is likely an underestimation of the higher precipitations in the gridded data comparisons of the gridded precipitation with gauged data for the svarttjønnbekken id 123 29 and area 3 6 km2 and hokfossen id 123 28 and area 8 1 km2 catchments show that the gridded value is lower than the gauge recorded data for several floods since we do not have rain gauges installed within the other small catchments used we have to rely on the gridded data for the nationwide study another reason could be the assumption that the gis derived model parameters are constant during low medium and high flows the distance distributions of the marsh land and soil non marsh land of hillslope and the distance distribution of the river network could be different during the three flow conditions during heavy precipitation events that can cause damaging floods the river network transporting overland flow could increase and produce faster runoff generation and it will be a topic for further investigation 5 2 uncertainty of calibrated parameters both the dotty plots and the frequency histograms of the 5000 and 10 000 sample sizes have the same shape and distribution as the 500 sample size for the behavioral parameters the histograms and dotty plots of the river flow celerity for the catchment with id 19 107 fig 4 a and b show that the optimum celerity parameter is identifiable and has the same value 1 25 m s for sample sizes of 500 5000 and 10000 similar findings have been obtained using sample sizes of 500 and 2000 at another study catchment the calibrated parameters show one clear peak or most frequent value for almost all the study catchments even if the peak is at the extreme boundaries of the calibration interval for some parameters the sharp and peaked distributions are associated with well identifiable parameters and the parameter estimates can unambiguously be inferred as modal values while flat distributions indicate more parameter uncertainty blasone et al 2008 jin et al 2010 the identifiability of the parameters and their small uncertainty resulted in the narrow width of uncertainty bounds the difference between the maximum and minimum discharge for each hour the small uncertainty of the calibrated model parameters reduces uncertainty in the model predictions at ungauged catchments two model parameters degree hour factor for evapotranspiration and snow melt show sharp peaked and skewed distribution to the lower boundary of the calibration intervals since the intervals are set based on experience field results and literature the skewness indicates that we can get a higher performance criteria kge if we let the calibration parameters go beyond the specified intervals however we believe that gaining a higher kge value in these cases comes with a cost of less realistic model parameters and it was decided to keep the parameter intervals within a reasonable value 5 3 regionalization methods 5 3 1 multiple regression and physical similarity the multiple regression performs satisfactorily in regionalizing the ddd model parameters despite the uncertainty in the regression model the pooling group method also performs satisfactorily in regionalizing the model parameters despite the slight sensitivity of the method to the number of pooling group members significant correlations have been obtained between model parameters and cds for the regression equations effective lake percentage mean annual precipitation specific discharge and mean elevation of the catchments are used to estimate the shape and scale parameters of λ and λ the scale parameter of λ is correlated with the effective lake percentage the mean elevation and the specific discharge in the catchment the shape and scale parameters of λ are highly correlated with the shape and scale parameters of λ 0 98 and 0 99 respectively this correlation is expected since the latter is derived from the former see skaugen and onof 2014 accordingly we estimate the shape and scale parameters of λ from the shape and scale parameters of λ with multiple linear regression the performance of the multiple regression method in this study strengthens the statement that relating model parameters to catchment characteristics offers a possibility for estimating hydrological model parameters to predict flow at ungauged catchments magette et al 1976 the results obtained in this paper are consistent with what magette et al 1976 obtained using 21 catchments in usa in the regionalization of six selected parameters of the kwm hydrological model using hourly data they found that the hydrological model with the regressed parameters was successful in predicting flow at ungauged small catchments the satisfactory performance of the multiple regression equations is in agreement with the recent results of skaugen et al 2015 who used daily data on small and large catchments in norway the finding that multiple regression method gives better regionalization is also supported by young 2006 who compares multiple regression against a nearest neighbor based method the performance of the multiple regression method is also supported by the study results of post and jakeman 1999 they regressed six ihacres model parameters from six landscape attributes and the predictions made at the daily stream flow at ungauged catchments gave very good results for some catchments the pooling group type performs better than the single donor type for group members ranging from 3 to 20 the pooling group performance is as good as the multiple regression if we vary the number of members in the pooling group table 6 for each test catchment e g if we take catchment id of 19 79 and 104 22 a pooling group of 17 and 7 members gives as good kge as the multiple regression respectively if we select fixed number of group members multiple regression performs slightly better than the pooling group method we selected 5 7 and 10 members for further analysis a group of 7 members performs as well as a group of 10 members the group of 5 members performs slightly lower than the groups of 7 and 10 members finally the group of 7 members is considered an optimal size of the pooling based physical similarity in this study the performance of the pooling group method in this study adds to the confirmation that the method can be applied for regionalization in different regions with different rainfall runoff hydrological models regionalization results from 119 catchments across england wales and scotland 46 with hourly data 73 with daily data and size ranging from 1 km2 to 1200 km2 showed that pooling group method performed best with the conceptual hydrological model probability distributed model pdm kay et al 2006 bao et al 2012 regionalized variable infiltration capacity vic model parameters using multiple regression and multiple donor 5 donors physical similarity methods at 55 catchments of china and found that the multiple donor performed better than multiple regression 5 3 2 combined method generally the combined method which uses recession parameters estimated from multiple regression and calibrated parameters from the pooling group method of physical similarity performs slightly better than multiple regression and physical similarity methods table 9 the better performance of the combined method shows that multiple regression is slightly better than pooling group method in estimating the recession parameters while the pooling method is slightly better than the regression method in estimating the calibrated model parameters the hydrographs are also used for evaluation of the performance of the regionalization methods in addition to the kge and bias the hydrographs in fig 9 show that the combined method predicted the magnitude and the shape of the observed hydrographs better than the multiple regression and pooling group methods of regionalization the floods are underestimated in both the presented hydrographs when we look at the hydrograph of the catchment with id of 25 32 the combined method predicted the timing and magnitude of the 2014 summer flood better than the pooling group method but the pooling group method of regionalization has a kge value of 0 72 while the combined method has a kge value of 0 71 the combined method combines the advantages from the two methods of regionalizations used in this study physical similarity and multiple regression kokkonen et al 2003 states that exploiting merely relationships between calibrated model parameters and cds can result in a decrease in regionalization performance physical similarity has an advantage of transferring the entire calibrated model parameters from one or few gauged to ungauged catchments arsenault and brissette 2014 mcintyre et al 2005 oudin et al 2010 parajka et al 2005 the recession parameters describe the integrated information of how different factors influence the runoff process fiorotto and caroni 2013 recession parameters are used in the ddd model to estimate the subsurface storage capacity skaugen and mengistu 2016 and they can also be used to model streamflow recession for regionalization and prediction stoelzle et al 2013 vogel and kroll 1996 state that regression procedures for estimating hydrograph recession parameters generally work well which is supported by our findings in that the recession parameters estimated using multiple regression are slightly better than those estimated by physical similarity it must be noted however that the recession parameters derived from the regression method are estimated from hydrographs of 41 study catchments while that of the pooling group method are derived from hydrographs of only 7 study catchments the regionalized recession parameters of ddd model estimated by pooling group multiple regression and combined method are in some cases better than the recession parameters estimated locally from a short period of hydro meteorological data this is the case for four of the test catchments and makes the performance of the regionalization methods better than the calibration result for the four catchments table 10 the main reason that the single donor type of physical similarity performs the poorest is that the recession parameters in the single donor type are estimated from hydrographs of a single catchment while that of a pooling group and multiple regression are estimated from hydrographs of 7 and 41 catchments respectively the other reason is probably the long distance between donor and test catchments the main limitation of this study is related to the precipitation data mainly how heavy precipitation events are represented as discussed previously there are studies which show that the gridded data set has uncertainties and smooths out peaks lussana et al 2018 to reduce the uncertainty in the precipitation we have introduced a precipitation correction factor as mentioned in the methodology section and we estimate the precipitation correction factor for ungauged catchments using a daily specific runoff map of norway produced by nve https atlas nve no another limitation is related to the use of the daily spatial variations of precipitation data for the gamma distributed snow parameters skaugen et al 2015 used observed daily precipitation data from rain gauges to estimate the snow distribution parameters of ddd in this study we assume that the daily spatial variation of precipitation is similar to that of hourly variation and we used the parameters from the 84 calibrated catchments in skaugen et al 2015 due to the lack of sufficient rain gauges with hourly temporal resolution one source of uncertainty in this study that is not yet quantified is the lack of long term discharge data with hourly resolutions for estimating the runoff recession parameters as they are sensitive to the length of the time series 6 conclusions the results of our study show that the ddd model performs satisfactorily both during the calibration and validation periods for small rural catchments in norway area 50 km2 with hourly temporal resolution the model underestimates floods generated by heavy precipitation events and a method to improve the simulation of peak floods should be further investigated the calibrated parameters in the ddd model are identifiable and show small uncertainty in our analysis the uncertainty bound of ddd simulations due to the calibrated parameters is narrow which shows that the uncertainty due to calibrated parameters for predicting flow using hourly temporal resolution is small and this also indicates that the model is suitable for regionalization both the multiple regression and pooling group methods performed satisfactorily except for one test catchment both methods gave a kge performance between 0 5 and 0 75 the combined method which uses recession parameters estimated from multiple regression and calibrated parameters from the pooling group method of physical similarity performed slightly better than the pooling group and multiple regression methods therefore the combined method of regionalization is recommended as a method for estimation of flow at small rural ungauged catchments with hourly resolution in norway the recession parameters estimated by the three regionalization methods are for some catchments better than those estimated from a short period of hydro meteorological data the parameter parsimonious rainfall runoff hydrological model ddd has a capability of generating continuous flow data at ungauged small rural catchments with hourly temporal resolution using regionalized model parameters the satisfactory performance of the combined method shows that regionalization of ddd model parameters is possible by combining multiple regression and physical similarity methods declaration of interests none acknowledgments the authors would like to acknowledge cristian lussana of the norwegian meteorological institute for providing information on how to access and process the 1 1 km spatial and 1 hour temporal resolution gridded precipitation and temperature data for norway we would like to acknowledge abebe girmay also for his support in processing the gridded data the authors also acknowledge and appreciate the anonymous reviewers despite their busy schedules have taken out time to read the manuscript and give us feedback which helped a lot for the improvement of the manuscript finally the authors gratefully acknowledge the financial support by the research council of norway and several partners through the centre for research based innovation klima 2050 see www klima2050 no 
6555,streamflow data is important for studies of water resources and flood management but an inherent problem is that many catchments of interest are ungauged the lack of data is particularly the case for small catchments where flow data with high temporal resolution is needed this paper presents an analysis of regionalizing parameters of the distance distribution dynamics ddd rainfall runoff model for predicting hourly flows at small ungauged rural catchments the performance of the model with hourly time resolution has been evaluated calibrated and validated for 41 small gauged catchments in norway areas from 1 km2 50 km2 the model parameters needing regionalization have been regionalized using three different methods multiple regression physical similarity single donor and pooling group based methods and a combination of the two methods seven independent catchments which are not used in the evaluation are used for validation of the regionalization methods all the three methods the multiple regression pooling group and combined methods perform satisfactorily 0 5 kge 0 75 the combined method which combines multiple regression and pooling group performed slightly better than the other methods some model parameters namely those describing recession characteristics estimated by the regionalization methods appear to be a better choice than those estimated locally from short period of hydro meteorological data for some test catchments the single donor method did not perform satisfactorily the satisfactory performance of the combined method shows that regionalization of ddd model parameters is possible by combining multiple regression and physical similarity methods keywords small ungauged catchments prediction of hourly flow recession parameters regionalizations distance distribution dynamics ddd rainfall runoff model 1 introduction streamflow is important information for water resources management applications such as flood risk management water resources planning and environmental impact assessment parajka et al 2013 westerberg et al 2014 however most of the catchments that we are interested in are ungauged which makes a method to predict flow in ungauged catchments an important prerequisite bloschl et al 2013 parajka et al 2013 tegegne and kim 2018 reliable estimation of continuous streamflow in ungauged catchments has remained a fundamental challenge in hydrology although significant insights have been gained in recent years steinschneider et al 2014 wagener and wheater 2006 wagener et al 2004 to solve the challenges posed by ungauged catchments a number of predictive tools have been developed and tested e g data driven models such as multiple linear regression mlr autoregressive moving average arma and artificial neural networks anns lumped models e g hydrologiska byråns for vattenbalansavdelning model hbv distributed models e g mike she and statistical regionalization that allow objective and quantitative decision making with respect to water resources management but considerable uncertainties remain sivapalan et al 2003 the international prediction in ungauged basins pub initiative recommends the use of an appropriate model structure for predicting flow in ungauged catchments blöschl et al 2013 and the choice of appropriate model structure helps in reducing predictive uncertainty son and sivapalan 2007 flash floods are usually localized disasters that occur in small catchments with response times of a few hours or even less borga et al 2007 the short lead time and small area collectively enhance the difficulty of flood management in such catchments miao et al 2016 in addition small catchments and short time scales are the most under observed and problematic in terms of prediction and design and should be identified as a priority in water resource and flood management spence et al 2013 water resource management problems are increasingly approached using continuous time rainfall runoff modelling lamb and kay 2004 swain and patra 2017 rather than the traditional statistical or event based models simple concept modelssuch as the rational formula and its more sophisticated derivatives are criticized for containing parameters which are difficult to estimate e g the runoff coefficient or for being founded upon questionable assumptions e g identical return period for precipitation and resulting peak flow viviroli et al 2009 the advantage of continuous simulation approaches is that the catchment moisture state prior to the flow producing rainfall event is implicitly incorporated within the modeling framework provided that the model produces reasonable simulations pathiraja et al 2012 furthermore getting the right answers for the right reasons is crucial for getting the right answers at all if conditions shift beyond the range of prior experience due to extreme precipitation events climate change or shifts in land use kirchner 2006 catchment size has an effect in hydrological modelling and hydrological responses of small catchments are likely to be different from and more variable than those of large catchments pilgrim et al 1982 small catchments need to be modelled using shorter time steps blöschl and sivapalan 1995 bronstert 2003 vormoor and skaugen 2013 wetterhall et al 2011 until the 1990s hydrologists had to rely mostly on data with a daily time step e g accumulated rainfall amounts recorded once a day by observers and this caused limitations to the applicability of rainfall runoff models for problems e g flooding needing short time steps blöschl and sivapalan 1995 creutin and obled 1980 however over the last two decades the availability of hourly and even sub hourly data is increasing in many countries especially with the implementation of automatic rain gauge networks and rainfall radars berne and krajewski 2013 creutin and borga 2003 a rainfall runoff model is one of the tools used to predict flows in ungauged catchments nruthya and srinivas 2015 this method requires estimation of the model parameters using regionalization zhang et al 2014 there are different types of rainfall runoff hydrological models and regionalization methods one method may work well for one type of model and another method may work well for another model in different regions razavi and coulibaly 2013 because each model has its own unique characteristics and respective applications devi et al 2015 conceptual rainfall runoff models such as hbv and identification of unit hydrographs and component flows from rainfall evaporation and stream data ihacres have emerged as the most frequently used models for estimating continuous stream flow at ungauged catchments razavi and coulibaly 2013 the three commonly used regionalization methods are regression physical similarity and spatial proximity bao et al 2012 bárdossy 2007 merz and blöschl 2004 oudin et al 2008 parajka et al 2005 some hydrologists have tried to compare and evaluate the methods but the results are not consistent kay et al 2006 mcintyre et al 2005 oudin et al 2008 young 2006 zhang and chiew 2009 young 2006 regionalized the probability distributed model pdm in 260 catchments in the uk and found that the regression method was more accurate than the spatial proximity method skaugen et al 2015 regionalized the distance distribution dynamics ddd model in 84 catchments ranging from small to large sizes in norway using daily data and found that multiple regression equations performed well in predicting flows at ungauged catchments kay et al 2006 tried to compare the performance of regression and physical similarity methods with two models pdm and time area topographic extension tate for 119 catchments across the uk but did not obtain consistent results for the pdm physical similarity was more accurate but regression outperformed physical similarity for tate merz and blöschl 2004 found that the multiple regression method of regionalization at 308 catchments in austria using hbv model involving 11 calibration parameters gave significantly poorer results than the spatial proximity method oudin et al 2008 used two lumped rainfall runoff models with daily data on 913 french catchments and found that when a dense network of gauging stations is available the spatial proximity method provides the best regionalization solution while the regression method shows the least satisfactory results and the physical similarity method is in between the two others in accuracy magette et al 1976 used 21 catchments in usa in the regionalization of six selected parameters of the kentucky watershed model kwm using hourly data and found that a multiple regression method was successful in estimating model parameters from catchment descriptors but a simple linear regression model was unsuccessful kokkonen et al 2003 used 13 catchments in north carolina usa in the regionalization of six parameters of ihacres model with daily data and found that the arithmetic mean method of regionalization gave poorer results than regression and similar hydrologic behavior methods the major goal of the international pub initiative was to reduce the uncertainty in the prediction of runoff by shifting away from tools that require calibration and curve fitting to tools that need little or no calibration parsimonious models spence et al 2013 the pub synthesis book states that the starting point for predicting the runoff hydrograph in ungauged catchments using rainfall runoff models is the choice of an appropriate model structure blöschl et al 2013 sivapalan et al 2003 pointed out that for predicting flow at ungauged catchments it is important to challenge and overcome the potential problem posed by the uniqueness in place beven 2000 of catchments it is hence important that the hydrologic models are parametrically efficient parsimonious and their parameters are identifiable from the available catchment data young and romanowicz 2004 ddd is a parsimonious rainfall runoff model with few calibration parameters recently developed by skaugen and onof 2014 and many of its other parameters can be estimated from the topography and land use of a catchment skaugen and onof 2014 previous experience in using ddd for estimation of flow at ungauged catchments with daily data showed satisfactory results skaugen et al 2015 since ddd is one of the hydrological models which has features acknowledged for prediction of flow at ungauged catchments we used it in this study during the calibration of hydrological models it is common and probable that multiple calibration periods yield multiple optimum parameter sets different sets of optimum parameter values may yield similar performances and this is designated as equifinality beven 2006 since conceptual hydrological models can be viewed as an empirically derived combination of mathematical operators describing the main features of an idealized hydrological cycle one cannot rely on a uniquely determined model parameter set or model prediction kuczera and parent 1998 consequently attention should be given to uncertainties in hydrological modelling prediction uncertainties in hydrological modelling arise from a variety of sources such as errors associated with input data and data for calibration imperfection in model structure calibration accuracy and uncertainty in model parameters benke et al 2008 jin et al 2010 montanari 2011 in this study uncertainty of the calibrated model parameters has been addressed most of the regionalization methods applied so far are based on daily temporal resolution in catchments ranging from small to large sizes masih et al 2010 merz et al 2006 hailegeorgis et al 2015 and viviroli and seibert 2015 have done regionalization studies with hourly resolution but the studies are not specific to small catchments response times of small catchments are typically less than 24 h and thus for flood forecasting purposes hydrological models are required to provide simulations at high temporal resolution reynolds et al 2017 therefore regionalization of model parameters for small catchments with sub daily time resolution is important in this study we have regionalized the ddd model parameters for small catchments with hourly time resolution in order to predict flows at ungauged rural small catchments in norway the specific research objectives are 1 to evaluate the performance of the ddd rainfall runoff hydrological model on rural small catchments with hourly temporal resolution areas from 1 km2 50 km2 it includes the selection of parameters to calibrate or to fix the model goodness of fit and uncertainties in the calibration parameters 2 to evaluate multiple regression based regionalization against a physical similarity based regionalization method 3 to analyze and assess whether there is a combined regression and physical similarity method for regionalizing ddd model parameters 2 study area and data forty one gauged small rural catchments located across norway are used in the study we selected the catchments from the norwegian water resources and energy directorate nve hydra ii database of gauged catchments our definition of a small catchment follows that of fleig and wilson 2013 with an upper area limit of 50 km2 the number of catchments is limited by the availability of hydro meteorological data with the required temporal resolution of 1 h and a length of record that makes calibration possible seven additional gauged catchments which are not used in the model calibration have been used in validation fig 1 shows the location of the study and test catchments time series of precipitation temperature and discharge are the main input data for running and calibrating the ddd model precipitation and temperature are based on a 1 1 km gridded product of the norwegian meteorological institute http thredds met no thredds catalog html with hourly temporal resolution lussana et al 2016 since the data is available from 2010 onwards we have used a total of five years of data for calibration and validation the ddd model uses distributed precipitation and temperature data as input for the model s 10 elevation zones extracted from the hypsographic curve of a catchment the elevation of the center of each temperature and precipitation grid cell has been extracted from the 10 10 m digital elevation model dem of norway for the model elevation zone that contains more than one grid cell mean of the values of temperature and precipitation is used hourly discharge data have been obtained from the norwegian water resources and energy directorates nve hydra ii database the constant model parameters during the simulation period are derived from an analysis of hydro meteorological topographical and land use data for a catchment using gis the source of the topography and land use data is the norwegian mapping authority www statkart no the 10 10 m dem the river network and the 1 50000 scale land use data have been retrieved and used in the study the dem has been re conditioned to the naturally occurring river network using the dem reconditioning tool from arc hydro to create a hydrologically correct terrain model that can improve the accuracy of watershed modeling li 2014 the re conditioned dem is further used to determine the distance distributions of hill slopes and river networks as needed by ddd 3 methodology 3 1 model structure the ddd model is written in r programming language r core and team 2017 and currently runs operationally with daily and three hourly time steps at the norwegian flood forecasting service at nve subsurface and dynamic runoff are the two main modules of the model the volume capacity of the subsurface water reservoir w mm is shared between a saturated zone with volume s mm and an unsaturated zone with volume d mm if the saturated zone is high the unsaturated volume has to be small skaugen and onof 2014 the actual water volume present in the unsaturated zone is described as z mm the subsurface state variables are updated after evaluating whether the current soil moisture z t together with the input of rain and snowmelt g t represent an excess of water over the field capacity r which is fixed at 30 r 0 3 of d t skaugen and onof 2014 if g t z t r d t then the excess water x t is added to s t 1 excess water x t m a x g t z t d t r 0 d t 2 groundwater ds dt x t q t 3 soil water content d z dt g t x t e a t 4 soil water zone dd dt ds dt 5 potential evapotranspiration e p c e a t 6 actual evapotranspiration e a e p s z w q t is runoff and e a t is the actual evapotranspiration which is estimated as a function of potential evapotranspiration and the level of storage a degree hour factor cea is positive for positive temperature t and zero for negative temperature ea is drawn from z this is indeed a simplification but experience from skaugen and onof 2014 shows that the evapotranspiration routine in ddd calculates similar values to the approach used in hbv bergström 1976 a recession analysis of the observed runoff from the catchment is used to estimate the catchment scale fluctuations of storage the capacity of the subsurface water reservoir w see skaugen and mengistu 2016 the dynamics of runoff in ddd has been derived from the catchment features using a gis combined with runoff recession analysis the method for describing the runoff dynamics of a catchment is built on the distance distribution derived from the catchment topography the distances from the points in the catchment to the nearest river reach are calculated for marsh and soil non marsh parts of a hillslope previous studies in more than 120 catchments in norway showed that the exponential distribution described the hillslope distance distribution well and the normal distribution described well the distances between points in the river network and outlet of a catchment skaugen and mengistu 2016 skaugen and onof 2014 fig 2 shows a map of the distance distributions of the marsh and soil non marsh parts of the hillslope and river network for the valen catchment and the corresponding empirical cumulative distribution functions fig 3 shows the structure of the ddd model all gis work is done with arcmap 10 3 and the recession analysis is done using the r script in the model water is conveyed through the soils to the river network by waves with celerity determined by the actual storage s t in the catchment skaugen and mengistu 2016 skaugen and onof 2014 the celerity associated with the different levels of subsurface storage is estimated by assuming exponential recessions with parameter λ in the equation q t q 0 λ e λ t t 0 where q 0 is the peak discharge immediately before the recession starts λ is the slope of change per time t of the recession in the log log space and calculated using eq 7 the distribution of λ is modeled using a two parameter gamma distribution 7 λ t log q t log q t δ t δ t the celerity v is calculated as a function of λ using eq 8 8 v λ d mean δ t d mean is the mean of the distances from points in the catchment to the nearest river the capacity of the subsurface reservoir w mm is divided into storage levels i corresponding to the quantiles of the distribution of λ under the assumption that the higher the storage the higher the value of λ each storage level is further assigned a celerity ν i λ i d mean δ t see eq 8 where λ i is the parameter of the unit hydrograph for the individual storage level i and estimated such that the runoff from several storage levels will give a unit hydrograph equal to the exponential unit hydrograph with a parameter λ i with the assumption that the recession and its distribution carry information on the distribution of catchment scale storage we can consider that the temporal distribution of catchment scale storage s t is a scaled version to that of λ s t is calculated using eq 9 and its distribution is modelled using a two parameter gamma distribution 9 s t q t 1 e λ t 3 2 model parameters and calibration the model has three main groups of parameters the first group are those determined by model calibration against observed discharge the upper 5 in table 1 the second group are those estimated from observed hydro meteorological data the lower 4 in table 1 and the upper 3 in table 2 and the third group are those estimated from geographical data all in table 2 except the upper 3 the calibration of the model is performed using the probability particle swarm optimization ppso algorithm lu and han 2011 the kling gupta efficiency criteria kge has been used as an objective function for the calibration gupta et al 2009 and the kge and bias ratio of the mean of simulated to observed discharge have been used to evaluate the calibrated results in addition the hydrographs of all catchments are visually inspected the calibration intervals of the parameters are set based on literature and experience in using the ddd model skaugen and mengistu 2016 sælthun 1996 since cea and degree hour factor for snow melt cx are sensitive to the temporal resolution we used the ddd model calibration results from 84 catchments with daily time step skaugen et al 2015 as a starting point and literature review for setting the intervals of hourly time step the mean celerity for river flow rv has a standard value of 1 m s in using ddd with catchments ranging from small to large sizes skaugen and mengistu 2016 with daily time steps but it has been calibrated with an interval of plus or minus 0 5 m s of the standard value for hourly resolution from experience and field measurements we have set the calibration interval of maximum liquid water content of snow pro between 3 and 10 fierz et al 2009 saloranta 2012 for the 41 study catchments we have calibrated the model on 2 3 years of data and validated on 1 2 years the selection of the period is mainly based on the availability of flow and gridded precipitation and temperature data the gridded precipitation data in norway is highly uncertain due to rugged terrain and few precipitation stations in elevated areas the data used does not include the correction for undercatch due to the wind and the relation between the precipitation and elevation is introduced only locally around the station locations as a result the predicted precipitation field may potentially underestimate the actual precipitation especially at higher elevations where the station network is sparser such as at the mountainous region of the southern part of norway frauenfelder et al 2017 lussana et al 2018 accordingly we introduced a precipitation correction factor to take this into account so that the long term water balance is correct the correction factor is applied to those catchments that give bias less than 0 8 and the correction factor is the ratio of long term mean annual discharge to mean of simulated discharge for purely ungauged catchments the long term mean annual discharge is estimated from a gridded map of average annual runoff for norway for the period 1961 1990 beldring et al 2003 the threshold temperature for rain or snow and snow melt are fixed with a value of 0 5 c and 0 0 c respectively based on literature saloranta 2012 skaugen 1998 this is done to avoid regressed parameters that do not have a clear physical relationship with any of the catchment descriptors but which can be fixed on a physical or an empirical basis removing parameters from calibration also strengthens the parsimony of the model table 1 lists the nine model parameters needing regionalization five calibrated and four estimated from recession analysis and table 2 lists the non regionalized model parameters the snow routine in ddd has two non regionalized parameters the shape parameter a0 and the decorrelation length d of the gamma distribution of snow and snow water equivalent swe skaugen and weltzien 2016 are estimated from the previous calibration of 84 catchments in norway skaugen et al 2015 3 3 uncertainty analysis of calibrated parameters we calibrated the model using probability particle swarm optimization ppso algorithm with 500 calibration runs for each study catchment and sampled sets of parameters from the calibration runs for uncertainty analysis to select behavioral sets of parameters we used a threshold kge value of 70th percentile a value below which at least 70 of the values lie from the 500 runs for each study catchment evaluating several thousand calibration runs with an hourly resolution at 41 study catchments is computationally costly to check whether the 500 runs used in the calibration give different behavioral sets from several thousand calibration runs we ran the model with 2000 runs at one catchment and 5000 and 10 000 runs at another catchment all the study catchments are run with the behavioral sets of parameters but the results are presented only for four randomly selected catchments for each timestep we sampled the number of discharge values equal to the number of behavioral parameter sets for each catchment and the minimum and maximum discharges are used to estimate the width of the uncertainty bounds 3 4 regionalization methods we used 41 catchments with kge greater than or equal to 0 55 for the regionalization of the model parameters for the three regionalization methods used in this study 19 catchment descriptors cds readily available from catchment data are used at the start and later refined based on their significance in estimating model parameters table 3 since the selected catchments are widely spread across norway the spatial proximity method of regionalization may not be favored and is not considered in this study oudin et al 2008 validation of the regionalization methods is done assuming a selected number of gauged catchments to be ungauged and then comparing simulated runoff using the regionalized parameters with observed runoff 3 4 1 multiple regression method the multiple regression equations which are used to relate the cds with the model parameters are fitted to the calibrated model parameters of the 41 catchments we used a stepwise regression procedure for building the regression model we build the model from 19 candidate cds by entering and removing cds in a stepwise manner into the regression model until there is no convincing reason to enter or remove any more before starting to use the step wise procedure we removed a cd which is highly correlated with another cd s to identify the correlation between the cds we have plotted the scatter plot matrix of the cds predictors when r squared of correlation between two cds is greater than or equal to 0 5 they are considered as highly correlated the stepwise procedure is described in detail as follows i we set a significance level of 0 2 for deciding when to enter into and remove from the stepwise model we set the significance level so that it is not too difficult to enter cds into the model and not too easy to remove cds from the model ii we fit each of the one predictor models that regress each model parameter with all cds one by one example celerity of river flow rv against bare mountain b rv against forest f etc iii of those predictors cds whose p value is less than 0 2 the first predictor introduced to the stepwise model is the cd that has the smallest p value accordingly bare mountain is the first predictor for celerity of river flow iv if no predictor cd has a p value less than 0 2 stop fitting the regression model cfr is a typical example for this step v now we fit each of the two predictor models that include the first cd as a predictor example rv on b and rs rv on b and u etc vi of those predictors whose p value is less than 0 2 the second predictor put in the stepwise model is the predictor that has the smallest p value for the celerity of river flow rv river slope was deemed the best second predictor and it is therefore entered into the stepwise model vii now since the bare mountain was the first predictor we step back and see if entering river slope into the stepwise model somehow affects the significance of the bare mountain predictor that is check whether the p value of bare mountain is less than 0 2 or not if the p value is less than 0 2 the first predictor bare mountain is retained in the stepwise model viii continue the steps as described above until adding an additional predictor does not yield a p value below the significant level chosen both linear and non linear logarithmic forms of the response variables model parameters needing regionalization and predictors cds are tested in the regression model if the non linear values contribute significantly then the non linear form is retained in the model with the transformed value 3 4 2 physical similarity method the physical similarity method relies on the assumption that the same parameter set should be successful in physically similar catchments merz and blöschl 2004 oudin et al 2008 parajka et al 2005 zhang and chiew 2009 the transfer can be made from one or several donor catchments on the basis of a chosen similarity method mcintyre et al 2005 the method transfers entire parameter sets from gauged to ungauged catchments instead of establishing links between model parameters and cds in this study we used two types of physical similarity methods i e single donor based and pooling group based we used 12 cds 2 hydro climatic 4 land uses 3 topographic and 3 that can describe the runoff dynamic processes in ddd the cds used are area mean elevation mean of soil non marsh land distance from a river mean of marsh land distance from the river mean of river distance from outlet river slope effective lake percentage forest urban mean annual precipitation specific discharge and bare mountain for the single donor type we used a rank accumulated method of physical similarity in selecting a donor catchment to a test catchment oudin et al 2008 zhang and chiew 2009 for each cd the catchment with the most similar descriptor to the test catchment is assigned rank 1 the catchment with the second most similar descriptor is assigned rank 2 and so on when two or more catchments have the same value of cds with the test catchment they have been assigned the same rank the rank numbers of cds have been added for each of the study catchments each cd used for regionalization is given equal weight in the ranking system oudin et al 2008 all the 41 catchments are considered in the selection of the most similar catchment to each of the 7 test catchments the single gauged catchment with the smallest total rank is used as a donor catchment in the pooling group type the parameters for an ungauged site are estimated from the calibrated parameters of a pooling group i e a set of gauged catchments considered to be most similar to the target ungauged catchment in terms of some set of cds kay et al 2006 2007 kay et al 2006 defined physical similarity by euclidean distance in a space of cds that was determined for each model parameter as shown in eq 10 10 dis t a b j 1 j x a j x b j σ x j 2 where j indicates one of a total of j cds 12 in this study x a j is the value of that cd at the a th test catchment x b j is the value of the cd at bth study catchment and σ x j is the standard deviation of the cd across all the n study catchments 41 in this study kay et al 2007 suggests that around a 10 member pooling group is preferable to a much larger number particularly when many cds are used to define euclidean distance for the pooling group k 7 in this study closest neighbors minimum distance are selected to create a pooling group for the test catchments after identifying the pooling group the estimate of the model parameter at the test catchment a α a pg is calculated as a weighted average of the corresponding parameters from the study catchments in the pooling group kay et al 2007 stated that it is more appropriate to write the expression for the model parameter as a weighted average of the estimated parameter values α m for all catchments n as shown in eq 11 11 α a pg m 1 n h am α m m 1 n h am catchments not in the pooling group are given a weight h am equal to zero but those in the pooling are assigned weights to reflect their importance which is based on the distance measure dis t a b as defined in eq 10 the weights of the pooling group members are estimated by eq 12 12 h am 1 s am where s am dis t a b d i s t a m a x for l i n e a r l y d e c r e a s i n g w e i g h t s dis t a b d i s t a m a x 2 for q u a d r a t i c a l l y d e c r e a s i n g w e i g h t s where dis t a m a x is set to be 10 larger than the maximum distance of a pooling group member from the test catchment a in this study we used a linear weight assigning method 3 4 3 combined method the 9 model parameters needing regionalization come from two groups with different estimation methods in the combined method the new parameter set is derived by combining regression and physical similarity methods i e when regression is used for the first group physical similarity is used for the second group and vice versa 4 results 4 1 calibration to evaluate the performance of the ddd model in calibration and validation we used the kge bias and visual inspection of hydrographs the model performs satisfactorily 0 5 kge 0 9 both for the study for calibration and validation and for the test catchments for calibration the minimum and maximum kge values during calibration of the study catchments are 0 55 and 0 89 respectively while the median is 0 71 the minimum and maximum kge values during validation are 0 4 and 0 88 respectively while the median is 0 66 the median bias value for calibration and validation is 0 88 as stated in thiemig et al 2013 0 75 kge 0 9 is good 0 5 kge 0 75 is intermediate and 0 0 kge 0 5 is poor when validating 5 27 and 9 study catchments show poor intermediate and good kge values respectively except for one catchment all test catchments give satisfactory calibration results the visual inspection of the hydrographs shows underestimation of floods caused by heavy precipitation 4 2 uncertainty of calibrated parameters from parameter samples of different sizes at two of the study catchments the frequency histograms and dotty plots of the behavioral calibrated parameters show the same optimal value for the different sizes fig 4 a and b show the histogram and dotty plot for one calibrated parameter celerity of river flow respectively the results show that we have the same value of optimal parameter at 500 5000 and 10 000 iterations and hence a sample size of 500 appears to be sufficient for the uncertainty analysis of calibrated parameters the frequency histograms of behavioral calibrated parameters for the 41 study catchments are analyzed the results of histograms pro cea rv and cx for the four randomly selected study catchments are shown in fig 5 a to d the histograms show that the calibrated parameters have a well identifiable modal value the parameters max out the calibration interval except for rv for each timestep we used discharge values simulated from 170 156 183 and 179 behavioral parameter sets in the calibration period to plot the uncertainty bounds for the catchments with identification numbers id 6 10 19 107 73 27 and 123 29 respectively examples of simulated ranges and observed discharges are shown in fig 6 4 3 regionalization results 4 3 1 regression method the multiple regression equations are shown in eqs 13 20 the overall multiple regression model for cfr is statistically insignificant hence the mean of the 41 calibrated catchments 0 007 has been used as the regionalized model parameter for catchments with a cd value of zero in a logarithmic expression a value of 1 has been assigned the units of the model parameters are presented in table 1 there is a probability that parameters estimated using the multiple regression equations can lie outside of the calibration intervals in this case we will use the nearest boundary value from the calibration interval 13 pro 0 017 0 026 log m m 0 066 log m s 0 038 log m r 0 013 log m e 0 029 u 14 cx exp 4 2 0 41 log m e 0 87 log m p 0 95 log m s 15 cea exp 8 78 0 28 log m e 1 17 log m p 0 26 log m m 0 22 log m r 0 003 f 16 rv 0 83 0 05 log r s 0 003 b 17 gscale exp 5 12 0 12 l e 0 22 ln s q 0 3 log m e 18 gshape 0 82 0 0005 m p 0 009 s q 19 gshi 2 047 g s h a p e 0 658 20 g s c i 0 49 g s c a l e 0 0014 the standardized residuals of the regression model for the response variables show a distribution close to normal fig 7 fig 7 shows that few large and small values deviate from the approximated straight line of normal probability plot while many of the residuals lie along the straight line fig 8 shows the actual calibrated and estimated from observed hydro meteorological data and predicted values of the response variables with the multiple regression model the standard error of estimate is a measure of the accuracy of the regression model predictions and informs how much uncertainty is associated with the model prediction the standard error result of the regression model shows that there is uncertainty in the predicted values table 4 presents the summary of the multiple correlation coefficient r 2 their significance and standard errors for the 41 catchments used in the regionalization the non parametric spearman rank correlation was used seibert 1999 4 3 2 physical similarity method for the single donor type table 5 summarizes the smallest total rank used to select a donor catchment for the pooling group type we analyzed different numbers of group members 3 20 to get an overview on the dependency of kge values on the number of group members the kge values are slightly sensitive to the number of group members table 6 table 7 presents the seven pooling group members for test catchment 19 79 with euclidian distance the weights and the weighted average value regionalized value for celerity of river flow rv 4 3 3 combined method and comparison of methods the ddd model parameters needing regionalization are two groups the first group is estimated from calibration and the second group is estimated from observed hydro meteorological described in detail under section 3 4 3 table 8 presents the regionalized model parameters using the three methods physical similarity multiple regression and combined for one of the test catchments id 25 32 and compares with the calibrated parameters and parameters derived from recession the kge and bias performance results for the three regionalization methods are presented in table 9 kge and bias values have an optimum value of 1 fig 9 presents the observed and predicted hydrographs using the three regionalization methods for two of the test catchments and table 10 compares the performance of calibration against regionalization methods 5 discussion 5 1 model performance and parameters the evaluation of calibration and validation results shows that the ddd model performs satisfactorily but we have observed underestimation of floods caused by heavy precipitation events the main reason for the underestimation of floods is likely an underestimation of the higher precipitations in the gridded data comparisons of the gridded precipitation with gauged data for the svarttjønnbekken id 123 29 and area 3 6 km2 and hokfossen id 123 28 and area 8 1 km2 catchments show that the gridded value is lower than the gauge recorded data for several floods since we do not have rain gauges installed within the other small catchments used we have to rely on the gridded data for the nationwide study another reason could be the assumption that the gis derived model parameters are constant during low medium and high flows the distance distributions of the marsh land and soil non marsh land of hillslope and the distance distribution of the river network could be different during the three flow conditions during heavy precipitation events that can cause damaging floods the river network transporting overland flow could increase and produce faster runoff generation and it will be a topic for further investigation 5 2 uncertainty of calibrated parameters both the dotty plots and the frequency histograms of the 5000 and 10 000 sample sizes have the same shape and distribution as the 500 sample size for the behavioral parameters the histograms and dotty plots of the river flow celerity for the catchment with id 19 107 fig 4 a and b show that the optimum celerity parameter is identifiable and has the same value 1 25 m s for sample sizes of 500 5000 and 10000 similar findings have been obtained using sample sizes of 500 and 2000 at another study catchment the calibrated parameters show one clear peak or most frequent value for almost all the study catchments even if the peak is at the extreme boundaries of the calibration interval for some parameters the sharp and peaked distributions are associated with well identifiable parameters and the parameter estimates can unambiguously be inferred as modal values while flat distributions indicate more parameter uncertainty blasone et al 2008 jin et al 2010 the identifiability of the parameters and their small uncertainty resulted in the narrow width of uncertainty bounds the difference between the maximum and minimum discharge for each hour the small uncertainty of the calibrated model parameters reduces uncertainty in the model predictions at ungauged catchments two model parameters degree hour factor for evapotranspiration and snow melt show sharp peaked and skewed distribution to the lower boundary of the calibration intervals since the intervals are set based on experience field results and literature the skewness indicates that we can get a higher performance criteria kge if we let the calibration parameters go beyond the specified intervals however we believe that gaining a higher kge value in these cases comes with a cost of less realistic model parameters and it was decided to keep the parameter intervals within a reasonable value 5 3 regionalization methods 5 3 1 multiple regression and physical similarity the multiple regression performs satisfactorily in regionalizing the ddd model parameters despite the uncertainty in the regression model the pooling group method also performs satisfactorily in regionalizing the model parameters despite the slight sensitivity of the method to the number of pooling group members significant correlations have been obtained between model parameters and cds for the regression equations effective lake percentage mean annual precipitation specific discharge and mean elevation of the catchments are used to estimate the shape and scale parameters of λ and λ the scale parameter of λ is correlated with the effective lake percentage the mean elevation and the specific discharge in the catchment the shape and scale parameters of λ are highly correlated with the shape and scale parameters of λ 0 98 and 0 99 respectively this correlation is expected since the latter is derived from the former see skaugen and onof 2014 accordingly we estimate the shape and scale parameters of λ from the shape and scale parameters of λ with multiple linear regression the performance of the multiple regression method in this study strengthens the statement that relating model parameters to catchment characteristics offers a possibility for estimating hydrological model parameters to predict flow at ungauged catchments magette et al 1976 the results obtained in this paper are consistent with what magette et al 1976 obtained using 21 catchments in usa in the regionalization of six selected parameters of the kwm hydrological model using hourly data they found that the hydrological model with the regressed parameters was successful in predicting flow at ungauged small catchments the satisfactory performance of the multiple regression equations is in agreement with the recent results of skaugen et al 2015 who used daily data on small and large catchments in norway the finding that multiple regression method gives better regionalization is also supported by young 2006 who compares multiple regression against a nearest neighbor based method the performance of the multiple regression method is also supported by the study results of post and jakeman 1999 they regressed six ihacres model parameters from six landscape attributes and the predictions made at the daily stream flow at ungauged catchments gave very good results for some catchments the pooling group type performs better than the single donor type for group members ranging from 3 to 20 the pooling group performance is as good as the multiple regression if we vary the number of members in the pooling group table 6 for each test catchment e g if we take catchment id of 19 79 and 104 22 a pooling group of 17 and 7 members gives as good kge as the multiple regression respectively if we select fixed number of group members multiple regression performs slightly better than the pooling group method we selected 5 7 and 10 members for further analysis a group of 7 members performs as well as a group of 10 members the group of 5 members performs slightly lower than the groups of 7 and 10 members finally the group of 7 members is considered an optimal size of the pooling based physical similarity in this study the performance of the pooling group method in this study adds to the confirmation that the method can be applied for regionalization in different regions with different rainfall runoff hydrological models regionalization results from 119 catchments across england wales and scotland 46 with hourly data 73 with daily data and size ranging from 1 km2 to 1200 km2 showed that pooling group method performed best with the conceptual hydrological model probability distributed model pdm kay et al 2006 bao et al 2012 regionalized variable infiltration capacity vic model parameters using multiple regression and multiple donor 5 donors physical similarity methods at 55 catchments of china and found that the multiple donor performed better than multiple regression 5 3 2 combined method generally the combined method which uses recession parameters estimated from multiple regression and calibrated parameters from the pooling group method of physical similarity performs slightly better than multiple regression and physical similarity methods table 9 the better performance of the combined method shows that multiple regression is slightly better than pooling group method in estimating the recession parameters while the pooling method is slightly better than the regression method in estimating the calibrated model parameters the hydrographs are also used for evaluation of the performance of the regionalization methods in addition to the kge and bias the hydrographs in fig 9 show that the combined method predicted the magnitude and the shape of the observed hydrographs better than the multiple regression and pooling group methods of regionalization the floods are underestimated in both the presented hydrographs when we look at the hydrograph of the catchment with id of 25 32 the combined method predicted the timing and magnitude of the 2014 summer flood better than the pooling group method but the pooling group method of regionalization has a kge value of 0 72 while the combined method has a kge value of 0 71 the combined method combines the advantages from the two methods of regionalizations used in this study physical similarity and multiple regression kokkonen et al 2003 states that exploiting merely relationships between calibrated model parameters and cds can result in a decrease in regionalization performance physical similarity has an advantage of transferring the entire calibrated model parameters from one or few gauged to ungauged catchments arsenault and brissette 2014 mcintyre et al 2005 oudin et al 2010 parajka et al 2005 the recession parameters describe the integrated information of how different factors influence the runoff process fiorotto and caroni 2013 recession parameters are used in the ddd model to estimate the subsurface storage capacity skaugen and mengistu 2016 and they can also be used to model streamflow recession for regionalization and prediction stoelzle et al 2013 vogel and kroll 1996 state that regression procedures for estimating hydrograph recession parameters generally work well which is supported by our findings in that the recession parameters estimated using multiple regression are slightly better than those estimated by physical similarity it must be noted however that the recession parameters derived from the regression method are estimated from hydrographs of 41 study catchments while that of the pooling group method are derived from hydrographs of only 7 study catchments the regionalized recession parameters of ddd model estimated by pooling group multiple regression and combined method are in some cases better than the recession parameters estimated locally from a short period of hydro meteorological data this is the case for four of the test catchments and makes the performance of the regionalization methods better than the calibration result for the four catchments table 10 the main reason that the single donor type of physical similarity performs the poorest is that the recession parameters in the single donor type are estimated from hydrographs of a single catchment while that of a pooling group and multiple regression are estimated from hydrographs of 7 and 41 catchments respectively the other reason is probably the long distance between donor and test catchments the main limitation of this study is related to the precipitation data mainly how heavy precipitation events are represented as discussed previously there are studies which show that the gridded data set has uncertainties and smooths out peaks lussana et al 2018 to reduce the uncertainty in the precipitation we have introduced a precipitation correction factor as mentioned in the methodology section and we estimate the precipitation correction factor for ungauged catchments using a daily specific runoff map of norway produced by nve https atlas nve no another limitation is related to the use of the daily spatial variations of precipitation data for the gamma distributed snow parameters skaugen et al 2015 used observed daily precipitation data from rain gauges to estimate the snow distribution parameters of ddd in this study we assume that the daily spatial variation of precipitation is similar to that of hourly variation and we used the parameters from the 84 calibrated catchments in skaugen et al 2015 due to the lack of sufficient rain gauges with hourly temporal resolution one source of uncertainty in this study that is not yet quantified is the lack of long term discharge data with hourly resolutions for estimating the runoff recession parameters as they are sensitive to the length of the time series 6 conclusions the results of our study show that the ddd model performs satisfactorily both during the calibration and validation periods for small rural catchments in norway area 50 km2 with hourly temporal resolution the model underestimates floods generated by heavy precipitation events and a method to improve the simulation of peak floods should be further investigated the calibrated parameters in the ddd model are identifiable and show small uncertainty in our analysis the uncertainty bound of ddd simulations due to the calibrated parameters is narrow which shows that the uncertainty due to calibrated parameters for predicting flow using hourly temporal resolution is small and this also indicates that the model is suitable for regionalization both the multiple regression and pooling group methods performed satisfactorily except for one test catchment both methods gave a kge performance between 0 5 and 0 75 the combined method which uses recession parameters estimated from multiple regression and calibrated parameters from the pooling group method of physical similarity performed slightly better than the pooling group and multiple regression methods therefore the combined method of regionalization is recommended as a method for estimation of flow at small rural ungauged catchments with hourly resolution in norway the recession parameters estimated by the three regionalization methods are for some catchments better than those estimated from a short period of hydro meteorological data the parameter parsimonious rainfall runoff hydrological model ddd has a capability of generating continuous flow data at ungauged small rural catchments with hourly temporal resolution using regionalized model parameters the satisfactory performance of the combined method shows that regionalization of ddd model parameters is possible by combining multiple regression and physical similarity methods declaration of interests none acknowledgments the authors would like to acknowledge cristian lussana of the norwegian meteorological institute for providing information on how to access and process the 1 1 km spatial and 1 hour temporal resolution gridded precipitation and temperature data for norway we would like to acknowledge abebe girmay also for his support in processing the gridded data the authors also acknowledge and appreciate the anonymous reviewers despite their busy schedules have taken out time to read the manuscript and give us feedback which helped a lot for the improvement of the manuscript finally the authors gratefully acknowledge the financial support by the research council of norway and several partners through the centre for research based innovation klima 2050 see www klima2050 no 
6556,carbon capture and storage ccs has been extensively investigated as a potential engineering measure to reduce anthropogenic carbon emission to the atmosphere real time monitoring of the safety and integrity of carbon storage reservoirs is a critical aspect of any commercial scale ccs deployment pressure based sensing is cost effective suitable for real time monitoring and scalable to large monitoring networks however questions remain on how to best harness intelligent information from the high frequency pressure monitoring sensors to support real time decisions this work presents a deep learning based framework for analyzing and detecting anomalies in pressure data streams by using a convolutional long short term memory convlstm neural network model which allows for the fusion of both static and dynamic reservoir data in convlstm the convolutional neural network cnn is used for spatial pattern mining and the lstm is used for temporal pattern recognition the performance of the convlstm model for real time anomaly detection is demonstrated using a set of pressure monitoring data collected from cranfield mississippi an active enhanced oil recovery field the anomaly detection model is trained using bottom hole pressure data acquired from the base experiment without leak event and then tested on pressure data collected during a series of controlled co 2 release experiments with artificially created leak events results show that the convlstm neural network model successfully detected anomalies in the pressure time series obtained from the controlled release experiments inclusion of static information into the model further improves the robustness of convlstm keywords anomaly detection convolutional long short term memory neural network deep learning pressure tests 1 introduction carbon capture and storage ccs which refers to separating co 2 from large scale atmospheric releases of flue gases from industrial sources and then storing underground has been recognized as a technically feasible engineering measure for reducing global greenhouse emission metz et al 2005 it is estimated that approximately 9 5 gigatons gt carbon year or 35 gt co 2 year needs to be permanently stored in order to maintain future global warming below 2 c above the pre industrial levels quéré et al 2015 from the aspect of commercial scale adoption and deployment geological carbon storage gcs offers a more economically feasible greenhouse gas emission reduction option than many other alternatives bachu 2000 monitoring represents one of the most critical components in geological carbon sequestration gcs projects in order to minimize the risk of unintended migration of the injected co 2 from storage formations haszeldine 2009 jenkins et al 2015 chen et al 2018 zhong and carr 2019 regulations in many countries now mandate that comprehensive monitoring programs be put in place for evaluation and detection of co 2 leakage before the onset of any commercial scale co 2 storage project bielicki et al 2014 atamanchuk et al 2015 sun et al 2018 monitoring and verification of co 2 leakage is challenging because a leakage pathways may manifest in different forms such as fault leakage krevor et al 2010 lee et al 2013 vilarrasa and carrera 2015 wellbore leakage watson and bachu 2009 krevor et al 2010 jung et al 2013 near surface leakage lewicki et al 2005 feitz et al 2014 and groundwater aquifer leakage yang et al 2014 and b leakage signals vary with monitoring methods and across spatial and temporal scales sun and nicot 2012 sun et al 2013 dixon and romanak 2015 nordbotten et al 2004 introduced an analytical model for predicting the magnitude of leakage flux through abandoned wells viswanathan et al 2008 developed a hybrid model for detecting wellbore leakage zeidouni 2012 and wang et al 2016 proposed analytical models to evaluate the potential of leakage along preexisting faults sun et al 2015 proposed a pressure based pulse testing methodology for probing leakage pathways in storage formations and later demonstrated at both the bench sun et al 2017 and field scales sun et al 2016 yang et al 2018 present an adaptive methodology for risk based leakage monitoring design which uses a risk event tree to predict the likelihood of leakage occurrence with detection probabilities of risk events estimated for multiple monitoring plans most methods mentioned herein involve certain process based mechanistic models which are appropriate for process level understanding but can be adversely affected by conceptualization and parameterization uncertainties when used for prediction on the other hand data driven models are suitable for real time anomaly prediction especially when the underlying physical process is less fully understood and characterized which is often the case in subsurface modeling in this work we combine two machine learning algorithms the convolutional neural network cnn and long short term memory lstm neural network for detecting anomalies in monitoring well pressure data streams lstm is a neural network model introduced by hochreiter and schmidhuber 1997 and has shown successful performance in natural language processing and speech recognition lstm is mainly suitable for time series analysis and does not provide mechanisms for incorporating spatial information cnn originally introduced by lecun et al 1995 became popular in the last decade as a result of advances in deep learning training algorithms and computing hardware a number of winners of recent image classification competition and human machine matches are based on cnn silver et al 2017 silver et al 2016 because of its origin in image analyses cnn has the natural advantage of being able to extract embedded spatial patterns or features but may give rather limited performance on time series regression problems the combined cnn and lstm model called convlstm leverages the strengths of cnn and lstm for obtaining deep representations of complex spatiotemporal processes which can then serve as a deep learning based proxy model of the underlying physics shi et al 2015 successfully applied the convlstm model to rainfall nowcasting donahue et al 2015 proposed to use convlstm for visual recognition and description ji et al 2013 used convlstm to detect human motion and zhu et al 2017 applied the convlstm to detect body gesture so far few studies have applied convlstm to subsurface anomaly detection problems the contribution of this research is in the development of a deep learning based approach to fuse both static and dynamic data for pressure anomaly detection thus alleviating the black box nature of traditional machine learning methods while maintaining the real time detection capability for the current application the short term co 2 plume migration or trapping is mostly influenced by reservoir porosity and permeability under given operation conditions oldenburg 2007 thus reservoir characterization data provide important additional constraints to improve the accuracy of anomaly detection algorithms in particular here we treat the porosity and permeability as static variables and operation data e g injection rate and well bottom hole pressure as dynamic variables our convlstm regression model is trained using both the static and dynamic data to predict bottom hole pressure corresponding to the nominal scenario i e no known leaks it can then be deployed as a pressure based anomaly detection algorithm to detect significant deviations from the predicted nominal bottom hole pressure in the following we first briefly describe the background of a series field experiments conducted at the cranfield site that generated the pressure data set used in this study and then we describe the architecture of the convlstm model using the cranfield pressure data as a benchmark problem we compare the anomalies detected by lstm cnn and convlstm models and conclude that convlstm can be used for real time co 2 leakage detection due to its strong ability to fuse both spatial and temporal information 2 materials and methods 2 1 data description the cranfield site located in southwest mississippi u s has been used as a field observatory for testing concepts related to enhanced oil recovery eor and carbon storage by the southeast regional carbon sequestration partnership secarb http www secarbon org since 2008 chevron first discovered the oil reservoir at cranfield in 1943 more than 37 mmbbl million barrel oil and 672 bscf billion of standard cubic feet gas had been produced until 1965 most of the wells had been plugged and abandoned after 1965 in 2008 denbury onshore llc in collaboration with secarb started to perform co 2 eor at the cranfield site the research objective of secarb was to demonstrate the concept of phased use of subsurface volumes combining early use of co 2 for eor with later injection into the underlying or adjacent brine formations for storage hovorka et al 2013 by 2013 more than 3 million tonnes of co 2 had been injected and stored into the fluvial sandstone aquifer of cretaceous lower tuscaloosa formation at depths of about 3300 m hovorka et al 2013 choi et al 2013 hosseini et al 2013 extensive research activities were carried out in a small area east and outside of the main cranfield reservoir in the so called detailed area of study das the das site at cranfield consists of one injection well cfu31 f1 and two nearby observation wells cfu31 f2 and cfu31 f3 fig 1 these three wells will be referred to as f1 f2 and f3 in the rest of this paper the surface distances are 69 8 m between f1 and f2 and 29 9 m between f2 and f3 respectively the original co 2 injection experiment at f1 began on december 1 2009 at a rate ranging from 175 kg min to 330 kg min and completed in late 2010 a number of modeling studies have been conducted to history match the original cranfield co 2 injection experiment hovorka et al 2013 hosseini et al 2013 delshad et al 2013 soltanian et al 2016 min et al 2018 in january 2015 a university of texas team conducted a new series of pulse testing experiments at das site to prove the concept of pressure based pulse testing leakage detection technique prior to the 2015 experiment high resolution permanent downhole gauges were installed in the target zone 3220 m in wells f2 and f3 sun et al 2016 the site had no known leakage at the time of the experiments the pulse testing experiment consisted of two phases see supporting information s1 to demonstrate the feasibility of pulse testing based leakage detection process in the first phase bottom hole pressure was monitored in observation wells f2 and f3 to establish the nominal case i e reservoir responses to pulsing in the absence of known leaks specifically two pulse experiments with cycle durations of 90 min and 150 min fig s2 respectively were conducted on january 19 and january 20 2015 each pulsing cycle consisted of 50 shut in period and 50 injection period to simulate the effect of leakage events in the second phase of the experiment co 2 was artificially produced from well f3 with a constant production rate of 60 kg min while other experimental conditions were kept the same as those used in the base experiments two separate controlled release experiments were conducted on january 30 and january 31 2015 under the same cycle durations of 90 min and 150 min fig s3 the main underlying principle for time lapse detection is that leakage would cause different pressure responses under the same pulse testing conditions in both of the controlled release experiments f2 was used as an observation well to record bottom hole pressure with a sampling rate of 30 readings per min for this study the pressure data were downsampled to the minute level by averaging more details of the experimental setup can be found in sun et al 2016 the cranfield pressure data set is of high temporal resolution and is labeled i e the times of leak events are known thus providing a unique data set for validating the anomaly detection algorithms 2 2 machine learning methods 2 2 1 long short term memory neural network lstm the lstm neural network is a variant of recurrent neural networks rnn it was originally introduced to solve the vanishing exploding gradient problem which tends to cause training divergence in rnn hochreiter and schmidhuber 1997 like rnn lstm has a strong ability to capture the dynamic features via cycles in the graph ma and hovy 2016 moreover lstm also shares the same parameters i e network weights across all time steps which reduces the number of unknowns significantly che et al 2018 the structure of lstm is shown in fig 2 for each hidden unit lstm use an input gate i t a forget gate f t and previous cell state c t to control the current cell state c t and use an output gate o t and current cell state c t to control the hidden state h t at time t the update functions are listed as follows 1 i t σ w hi h t 1 w ci c t 1 w xi x t b i f t σ w hf h t 1 w cf c t 1 w xf x t b f c t tanh w hc h t 1 w xc x t b c c t f t c t 1 i t c t o t σ w ho h t 1 w xo x t b o h t o t tanh c t where σ is the element wise sigmoid function denotes the element wise dot product operator x t is the input vector at time t and h t 1 is the hidden state vector storing all the useful information prior to time t w xi w xf w xc w xo denote the weight matrices of different gates for input x t w hi w hf w hc w ho are the weight matrices for hidden state h t w ci w cf denote the weight matrices of cell state c t 1 and b i b f b c b o denote the bias vector 2 2 2 convolutional neural network cnn cnn is one of the most widely used neural network layers in deep learning models the greatest strength of cnn is that it has strong ability to extract features from an input image by convolution computations to form the so called feature maps a typical cnn building block consists of three basic constructs which are local receptive fields weight sharing and downsampling when dealing with high dimensional images it is impractical to connect all neurons in one layer to all neurons in its input layer local receptive field allows each neuron to connect to only a small neighborhood in the previous layer through the use of these local receptive fields each neuron can extract the local features of the input image such as line segments endpoint and corner weight sharing is a way for significantly reducing the number of parameters to optimize during network training in essence the same set of weights are used in a moving window i e a filter or kernel to extract features in an input image under the assumption that if one feature is useful at one location it is also useful for other locations downsampling or pooling is an operation used to enforce translation invariance i e the same feature stays active even when the image undergoes slight translations because cnn has a strong ability to extract high level features from spatial space it is used to extract the spatial information at each gate and cell states as shown in fig 4 2 2 3 convolutional lstm convlstm as mentioned previously a major drawback of lstm is that it lacks a means for incorporating spatial information to deal with this problem convlstm combines cnn and lstm in convlstm all of the inputs of lstm are treated as tensors denoted as x 1 x t cell outputs c 1 c t hidden states h 1 h t and gates i t f t o t the tensors are high dimensional arrays that can be used to represent static and dynamic reservoir variables the resulting update functions are similar to the lstm model given in eq 1 except that the data for each gate is now a 3d tensor 2 i t σ w hi h t 1 w ci c t 1 w xi x t b i f t σ w hf h t 1 w cf c t 1 w xf x t b f c t tanh w hc h t 1 w xc x t b c c t f t c t 1 i t c t o t σ w ho h t 1 w xo x t b o h t o t tanh c t as eq 2 shows w ho h t 1 and w xo x t are obtained from convolutional calculations in cnn moreover cell outputs c t hidden states h t and gates i t f t o t are all calculated by convolutional calculations 2 3 anomaly detection here we describe a workflow for using convlstm to detect anomalies in the pressure data in particular the input data preparation model architecture and the algorithm performance on training validation and testing data are described below 2 3 1 reservoir model description the das site at cranfield has been characterized by well logging and geophysical surveys the top and bottom of the 3d static model were determined by a 3d seismic survey and are modeled as impermeable layers soltanian et al 2016 here we use a single layer reservoir model to incorporate static information under the assumption that the static variables represent effective properties the reservoir model has a high resolution with grid block sizes of 1 m 1 m in the lateral directions and one thick layer in the vertical direction therefore the reservoir formation is represented as a 120 120 1 image fig 3 f1 f2 and f3 represent the locations of wells in fig 3 2 3 2 input variable preprocessing input variables chosen to train a machine learning model should not only be based on their physical significance but also on the basis of statistical relevance to the response variable we start with the diffusivity equation for reservoir pressure in cylindrical coordinates 3 2 p r 2 1 r p r ϕ μ c p k p t where p is the reservoir pressure r is radial coordinate t is time c p is total compressibility μ is the dynamic viscosity of the fluid ϕ is porosity and k is the intrinsic permeability of the porous medium the reservoir pressure is a function of many factors including geological information such as porosity and permeability and operation conditions such as injection rate and operation schedule geological information is considered static for the purpose of this study therefore the geological data is referred as static data set in this research we only consider the porosity and permeability information to simplify the structure of convlstm model as fig 3 illustrates two static variable images ϕ and k are included in the input data set in addition to the static variables the injection rate q t represents a typical dynamic variable and is also the main driving force for the movement of co 2 plume to accommodate the time series measurements we introduce a dynamic 2d image in which the pixel value at the injection well location represents the injection rate the pixel values at pressure monitoring well locations are the corresponding bottom hole pressure values and the pixel values in all other grid blocks are zero the dynamic image variable is thus a sparse tensor due to the different injection schedules the dynamic variable image varies with time at the injection location stacking the static variable images and dynamic variable images leads to a new 3d input variable which is fed to the convlstm model the formats of the input data set are defined as follows 4 d static t 2 120 120 d dynamic t 1 120 120 d total t 3 120 120 where d static t is the static variable image with image sizes of 120 120 at time t and consists of two static properties porosity and permeability maps d dynamic t is the dynamic variable image with image sizes of 120 120 at time t and consists of injection rate and bottom hole pressure and d total t is the merged final input variable with image sizes of 120 120 3 at time t the output variable of the convlstm model is the predicted bottom hole pressure at time t in the monitoring well i e well f2 the data structure used for the training validation and testing of convlstm is illustrated in fig 3 data normalization is an important technique used in network training to improve prediction accuracy and training speed zhong and carr 2016 zhong et al 2018 all input variables including static variables and dynamic variables and output variables bottom hole pressure are normalized to range 0 1 the following scaling formula is chosen 5 x i new x i old x min x max x min where x i new is the normalized vector x min and x max are the minimum and maximum values for each variable and x i old represents the original variable 2 3 3 model structure and parameterization fig 4 shows the usage of convlstm in a time series fashion to predict bottom hole pressure at time t data sets from the previous k steps i e t k to t 1 are fed to the convlstm model a convolutional layer with 64 filters and a kernel of dimensions of 3 3 is used in the lstm memory cell the output layer is a fully connected network layer fed by flattening previous feature maps and activated by a linear activation function 2 3 4 anomaly detection accuracy assuming gaussian distributed pressure deviations the anomaly detection algorithm uses a threshold based method to identify anomalies for an m variate length n time series data set x x i i 1 m x i r n that follows the gaussian distribution with mean μ i and variance σ i for the i th variable the detection function is defined using gaussian distribution 6 p x i μ i σ i 1 σ i 2 π exp x i μ i 2 2 σ i 2 where μ i 1 n j 1 n x i j and σ i 2 1 n j 1 n x i j μ i 2 for a new test data point x i l the above detection function is used to calculate the probability of the test data point being in a user defined normal data range p d x i l if the probability is less than a user defined threshold i e p d x i l 1 i the test data point is classified as an anomaly otherwise it is considered a normal data point in our anomaly detection model only one property is considered which is the bottom hole pressure thus m 1 we compute the probability of pressure deviation δ p between measured bottom hole pressure p t and predicted bottom hole pressure p t of well f2 at time t the statistics σ and μ can be calculated from the training data for different models proposed in section 2 2 in this work we chose 3 σ as the detection threshold which corresponds to 0 997 therefore the data point p t is identified as an anomaly if δ p 3 σ and is considered normal if δ p 3 σ 3 results 3 1 model evaluation and comparison to train the convlstm we divide the 90 min base case pulse testing experiment data set described under section 2 1 into two parts 75 290 samples for training and the rest 25 90 samples for validation the trained convlstm model is then applied to the 90 min controlled release experiment data set to assess model performance for anomaly detection on data not included in training to highlight the time series prediction performance of the proposed convlstm model two baseline methods are also considered for comparison purposes one is the lstm regression model which is a pure black box model and does not allow incorporation of spatial data the second one is the cnn model which has a good performance on the spatial data set e g 2d porosity and permeability maps but is not particularly designed for time series regression problems reservoir porosity and permeability are assigned with constant values of 0 1 and 1 5 md respectively which represent effective properties derived from previous studies sun et al 2016 fig 5 shows the results obtained using all three models in this case convlstm performed the best during training and validation in terms of the coefficient of determination r 2 and root mean square error rmse see table 1 while the cnn model gave the lowest coefficient of determination r 2 0 9831 and 0 9774 on training and validation data suggesting that the particular cnn model used in this study is not a good regression model because of its lack of memory of the previous information when predicting the future bottom hole pressure in summary both convlstm and lstm show good performance in training and validation processes but convlstm has the advantage of incorporating geospatial information which will be useful for uncertainty analyses as we will show below 3 2 modeled uncertainty analysis effective reservoir properties are used in the base convlstm model to test the sensitivity of the trained convlstm model to the uncertainty in static data we run 1000 monte carlo simulations by sampling the permeability value uniformly from the range 0 1 10 md and performing prediction using the trained convlstm note that the default permeability used in this study is 1 5 md the results are shown in fig 6 the solid line indicates the ground truth bottom hole pressure in well f2 during the co 2 controlled release experiment and the shaded area is generated by using the 95 confidence interval derived from the monte carlo simulations 3 3 modeled anomaly detection fig 7 shows the anomalies detected using the convlstm model the green line corresponds to the predicted bottom hole pressure and the blue line shows the observed pressure data recorded in well f2 the colored zone corresponds to the 95 confidence interval in principle if the convlstm regression model is well trained it can be deployed as an anomaly detector to predict pressure anomalies when a new bottom hole pressure measurement falls within the confidence interval it is labeled normal otherwise it is classified as an anomaly as fig 7a shows most detected anomalies happened when the injector f1 is shut in and the residual values i e δ p between prediction and ground truth bottom hole pressure fig 7b during those time interval are significantly greater than 3 σ during injection cycles the predicted pressure values are mostly located within the confidence intervals 4 discussion 4 1 impact of permeability to study the impact of permeability on anomaly detection we keep the porosity map constant and change the permeability map for each case we apply the trained convlstm to detect the anomalies the result is shown in fig 8 the permeability is varied from 0 1 md to 1000 md when k 0 1 1 5 and 10 md the anomalies always happened when well f1 was shut in and the number of detected anomalies decreased from 68 to 57 during the injection period co 2 was continuously injected into the reservoir so the reservoir pressure was always maintained during artificial co 2 release therefore the pressure difference between co 2 leakage case and base case as predicted by this convlstm model is not significant thus it is not easy to detect the anomalies during the shut in period reservoir pressure could not be maintained because the injection was stopped and the pressure dropped more quickly and sharply in response to the controlled co 2 releases therefore the pressure differences between co 2 leakage case and base case as predicted by convlstm model become more significant however the opposite results were obtained when the permeability increased from 10 md to 1000 md the number of detected anomalies still decreased compared to the base case n 57 but anomalies happened during the injection time this phenomenon is probably caused by faster pressure dispersion in a higher permeability reservoir results shown here suggest that the trained convlstm is relatively robust to uncertain effective permeability values we emphasize that the approach presented here is general and can be applied to spatially heterogeneous permeability and or porosity maps when such information is available examples are shown below in section 4 3 4 2 impact of detection threshold the number of anomalies detected by the trained convlstm model is different if a different threshold is applied as fig 7b shows the anomalies count is 57 when the threshold is 3 σ it changes to 78 if the threshold is 2 σ and changes to 113 if the threshold is decreased to 1 σ different σ values indicate different prediction intervals which also means different credibility of the trained convlstm model higher σ values indicate wider prediction intervals but also less reliability of the trained convlstm model smaller σ values indicate narrower prediction interval and also more reliability of the convlstm model thus the selection of threshold of anomalies is important and depends on the reliability of the regression model 4 3 impact of heterogeneity to investigate the impact of permeability heterogeneity on anomaly detection we generate the permeability maps using geostatistical methods we established the permeability semi variogram in the lateral direction based on measured permeability values hosseini et al 2013 and then applied the semi variogram to generate permeability maps for the study region as shown in fig 9 fig 9a shows the homogeneous permeability map and fig 9b d show the heterogeneous permeability maps as fig 9 shows the number of detected anomalies and the corresponding time point vary for different reservoir properties in absence of detailed subsurface data set an accurate reservoir characterization is impossible which undermines the value of history matching for reservoir forecasting the recently introduced data space inversion dsi paradigm which focuses more on propagating an ensemble of uncalibrated prior models as opposed to history matching provides a more attractive alternative in the context of anomaly detection under uncertainty jeong et al 2018 satija and caers 2015 for example an ensemble of permeability maps can be formed and then fed to the convlstm model to generate the prediction interval 4 4 limitations the convlstm model we proposed in this research is mainly demonstrated for pressure anomaly detection in co 2 sequestration applications the pressure prediction depends on the antecedent time series information if the amount of data is not enough e g discontinuous time series measurements or if the data set is noisy our proposed model may get poor prediction and has limited improvement moreover this work relies on a predictive reservoir model to calculate pressure differences δ p and we assumed that the whole reservoir can be represented by a single layer in other cases a 3d reservoir model might be more reasonable but it may also increase the memory and cpu demand for training the model as an alternative to the approach taken in this study sun et al 2019 applied a supervised machine learning algorithm isolationforest to partition pressure data recursively using an ensemble of random trees in order to identify pressure anomalies their method does not require the use of a predictive reservoir model nevertheless a physics based approach is still required when it is necessary to incorporate knowledge on the uncertain reservoir properties the structure of data set that is fed to convlstm is redundant because we strive for generality i e our model structure can be applied to heterogeneous static variable maps at the expense of specificity in this case in the base case static variable images are constant but still participate in the convolution computation in each time step and most pixel values in dynamic variable images except for the pixel value at the injection well location are zero which increases the computational cost 5 conclusions in this study we propose a spatiotemporal convolutional long short term memory convlstm neural network model for co 2 leakage detection from a co 2 eor site we apply evaluate and discuss the model capability for predicting reservoir pressure before and after co 2 leakage using real data collected from the site our results indicate that 1 the machine learning approach can fuse both spatial information and temporal information which increases detectability of anomalies 2 spatial features from the input images can be learned by convolutional neural nets 3 lstm models can learn temporal features 4 a thorough reservoir characterization is the key for reliable leak detection when a predictive reservoir model is needed in this study anomalies can be more easily detected after injection in low permeability reservoir 5 availability of operation data e g injection rate is also critical for predicting nominal pressure patterns although our results are mainly demonstrated using 2d reservoir models it can be readily extended to 3d models if it is necessary to consider vertical heterogeneity in the reservoir conflict of interest none acknowledgements this work was supported by the u s department of energy national energy technology laboratory netl under grant no de fe0026515 the authors are grateful to the handling associate editor and two anonymous reviewers for their constructive comments appendix a supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2019 04 015 supplementary data the following are the supplementary data to this article appendix a appendix a 
6556,carbon capture and storage ccs has been extensively investigated as a potential engineering measure to reduce anthropogenic carbon emission to the atmosphere real time monitoring of the safety and integrity of carbon storage reservoirs is a critical aspect of any commercial scale ccs deployment pressure based sensing is cost effective suitable for real time monitoring and scalable to large monitoring networks however questions remain on how to best harness intelligent information from the high frequency pressure monitoring sensors to support real time decisions this work presents a deep learning based framework for analyzing and detecting anomalies in pressure data streams by using a convolutional long short term memory convlstm neural network model which allows for the fusion of both static and dynamic reservoir data in convlstm the convolutional neural network cnn is used for spatial pattern mining and the lstm is used for temporal pattern recognition the performance of the convlstm model for real time anomaly detection is demonstrated using a set of pressure monitoring data collected from cranfield mississippi an active enhanced oil recovery field the anomaly detection model is trained using bottom hole pressure data acquired from the base experiment without leak event and then tested on pressure data collected during a series of controlled co 2 release experiments with artificially created leak events results show that the convlstm neural network model successfully detected anomalies in the pressure time series obtained from the controlled release experiments inclusion of static information into the model further improves the robustness of convlstm keywords anomaly detection convolutional long short term memory neural network deep learning pressure tests 1 introduction carbon capture and storage ccs which refers to separating co 2 from large scale atmospheric releases of flue gases from industrial sources and then storing underground has been recognized as a technically feasible engineering measure for reducing global greenhouse emission metz et al 2005 it is estimated that approximately 9 5 gigatons gt carbon year or 35 gt co 2 year needs to be permanently stored in order to maintain future global warming below 2 c above the pre industrial levels quéré et al 2015 from the aspect of commercial scale adoption and deployment geological carbon storage gcs offers a more economically feasible greenhouse gas emission reduction option than many other alternatives bachu 2000 monitoring represents one of the most critical components in geological carbon sequestration gcs projects in order to minimize the risk of unintended migration of the injected co 2 from storage formations haszeldine 2009 jenkins et al 2015 chen et al 2018 zhong and carr 2019 regulations in many countries now mandate that comprehensive monitoring programs be put in place for evaluation and detection of co 2 leakage before the onset of any commercial scale co 2 storage project bielicki et al 2014 atamanchuk et al 2015 sun et al 2018 monitoring and verification of co 2 leakage is challenging because a leakage pathways may manifest in different forms such as fault leakage krevor et al 2010 lee et al 2013 vilarrasa and carrera 2015 wellbore leakage watson and bachu 2009 krevor et al 2010 jung et al 2013 near surface leakage lewicki et al 2005 feitz et al 2014 and groundwater aquifer leakage yang et al 2014 and b leakage signals vary with monitoring methods and across spatial and temporal scales sun and nicot 2012 sun et al 2013 dixon and romanak 2015 nordbotten et al 2004 introduced an analytical model for predicting the magnitude of leakage flux through abandoned wells viswanathan et al 2008 developed a hybrid model for detecting wellbore leakage zeidouni 2012 and wang et al 2016 proposed analytical models to evaluate the potential of leakage along preexisting faults sun et al 2015 proposed a pressure based pulse testing methodology for probing leakage pathways in storage formations and later demonstrated at both the bench sun et al 2017 and field scales sun et al 2016 yang et al 2018 present an adaptive methodology for risk based leakage monitoring design which uses a risk event tree to predict the likelihood of leakage occurrence with detection probabilities of risk events estimated for multiple monitoring plans most methods mentioned herein involve certain process based mechanistic models which are appropriate for process level understanding but can be adversely affected by conceptualization and parameterization uncertainties when used for prediction on the other hand data driven models are suitable for real time anomaly prediction especially when the underlying physical process is less fully understood and characterized which is often the case in subsurface modeling in this work we combine two machine learning algorithms the convolutional neural network cnn and long short term memory lstm neural network for detecting anomalies in monitoring well pressure data streams lstm is a neural network model introduced by hochreiter and schmidhuber 1997 and has shown successful performance in natural language processing and speech recognition lstm is mainly suitable for time series analysis and does not provide mechanisms for incorporating spatial information cnn originally introduced by lecun et al 1995 became popular in the last decade as a result of advances in deep learning training algorithms and computing hardware a number of winners of recent image classification competition and human machine matches are based on cnn silver et al 2017 silver et al 2016 because of its origin in image analyses cnn has the natural advantage of being able to extract embedded spatial patterns or features but may give rather limited performance on time series regression problems the combined cnn and lstm model called convlstm leverages the strengths of cnn and lstm for obtaining deep representations of complex spatiotemporal processes which can then serve as a deep learning based proxy model of the underlying physics shi et al 2015 successfully applied the convlstm model to rainfall nowcasting donahue et al 2015 proposed to use convlstm for visual recognition and description ji et al 2013 used convlstm to detect human motion and zhu et al 2017 applied the convlstm to detect body gesture so far few studies have applied convlstm to subsurface anomaly detection problems the contribution of this research is in the development of a deep learning based approach to fuse both static and dynamic data for pressure anomaly detection thus alleviating the black box nature of traditional machine learning methods while maintaining the real time detection capability for the current application the short term co 2 plume migration or trapping is mostly influenced by reservoir porosity and permeability under given operation conditions oldenburg 2007 thus reservoir characterization data provide important additional constraints to improve the accuracy of anomaly detection algorithms in particular here we treat the porosity and permeability as static variables and operation data e g injection rate and well bottom hole pressure as dynamic variables our convlstm regression model is trained using both the static and dynamic data to predict bottom hole pressure corresponding to the nominal scenario i e no known leaks it can then be deployed as a pressure based anomaly detection algorithm to detect significant deviations from the predicted nominal bottom hole pressure in the following we first briefly describe the background of a series field experiments conducted at the cranfield site that generated the pressure data set used in this study and then we describe the architecture of the convlstm model using the cranfield pressure data as a benchmark problem we compare the anomalies detected by lstm cnn and convlstm models and conclude that convlstm can be used for real time co 2 leakage detection due to its strong ability to fuse both spatial and temporal information 2 materials and methods 2 1 data description the cranfield site located in southwest mississippi u s has been used as a field observatory for testing concepts related to enhanced oil recovery eor and carbon storage by the southeast regional carbon sequestration partnership secarb http www secarbon org since 2008 chevron first discovered the oil reservoir at cranfield in 1943 more than 37 mmbbl million barrel oil and 672 bscf billion of standard cubic feet gas had been produced until 1965 most of the wells had been plugged and abandoned after 1965 in 2008 denbury onshore llc in collaboration with secarb started to perform co 2 eor at the cranfield site the research objective of secarb was to demonstrate the concept of phased use of subsurface volumes combining early use of co 2 for eor with later injection into the underlying or adjacent brine formations for storage hovorka et al 2013 by 2013 more than 3 million tonnes of co 2 had been injected and stored into the fluvial sandstone aquifer of cretaceous lower tuscaloosa formation at depths of about 3300 m hovorka et al 2013 choi et al 2013 hosseini et al 2013 extensive research activities were carried out in a small area east and outside of the main cranfield reservoir in the so called detailed area of study das the das site at cranfield consists of one injection well cfu31 f1 and two nearby observation wells cfu31 f2 and cfu31 f3 fig 1 these three wells will be referred to as f1 f2 and f3 in the rest of this paper the surface distances are 69 8 m between f1 and f2 and 29 9 m between f2 and f3 respectively the original co 2 injection experiment at f1 began on december 1 2009 at a rate ranging from 175 kg min to 330 kg min and completed in late 2010 a number of modeling studies have been conducted to history match the original cranfield co 2 injection experiment hovorka et al 2013 hosseini et al 2013 delshad et al 2013 soltanian et al 2016 min et al 2018 in january 2015 a university of texas team conducted a new series of pulse testing experiments at das site to prove the concept of pressure based pulse testing leakage detection technique prior to the 2015 experiment high resolution permanent downhole gauges were installed in the target zone 3220 m in wells f2 and f3 sun et al 2016 the site had no known leakage at the time of the experiments the pulse testing experiment consisted of two phases see supporting information s1 to demonstrate the feasibility of pulse testing based leakage detection process in the first phase bottom hole pressure was monitored in observation wells f2 and f3 to establish the nominal case i e reservoir responses to pulsing in the absence of known leaks specifically two pulse experiments with cycle durations of 90 min and 150 min fig s2 respectively were conducted on january 19 and january 20 2015 each pulsing cycle consisted of 50 shut in period and 50 injection period to simulate the effect of leakage events in the second phase of the experiment co 2 was artificially produced from well f3 with a constant production rate of 60 kg min while other experimental conditions were kept the same as those used in the base experiments two separate controlled release experiments were conducted on january 30 and january 31 2015 under the same cycle durations of 90 min and 150 min fig s3 the main underlying principle for time lapse detection is that leakage would cause different pressure responses under the same pulse testing conditions in both of the controlled release experiments f2 was used as an observation well to record bottom hole pressure with a sampling rate of 30 readings per min for this study the pressure data were downsampled to the minute level by averaging more details of the experimental setup can be found in sun et al 2016 the cranfield pressure data set is of high temporal resolution and is labeled i e the times of leak events are known thus providing a unique data set for validating the anomaly detection algorithms 2 2 machine learning methods 2 2 1 long short term memory neural network lstm the lstm neural network is a variant of recurrent neural networks rnn it was originally introduced to solve the vanishing exploding gradient problem which tends to cause training divergence in rnn hochreiter and schmidhuber 1997 like rnn lstm has a strong ability to capture the dynamic features via cycles in the graph ma and hovy 2016 moreover lstm also shares the same parameters i e network weights across all time steps which reduces the number of unknowns significantly che et al 2018 the structure of lstm is shown in fig 2 for each hidden unit lstm use an input gate i t a forget gate f t and previous cell state c t to control the current cell state c t and use an output gate o t and current cell state c t to control the hidden state h t at time t the update functions are listed as follows 1 i t σ w hi h t 1 w ci c t 1 w xi x t b i f t σ w hf h t 1 w cf c t 1 w xf x t b f c t tanh w hc h t 1 w xc x t b c c t f t c t 1 i t c t o t σ w ho h t 1 w xo x t b o h t o t tanh c t where σ is the element wise sigmoid function denotes the element wise dot product operator x t is the input vector at time t and h t 1 is the hidden state vector storing all the useful information prior to time t w xi w xf w xc w xo denote the weight matrices of different gates for input x t w hi w hf w hc w ho are the weight matrices for hidden state h t w ci w cf denote the weight matrices of cell state c t 1 and b i b f b c b o denote the bias vector 2 2 2 convolutional neural network cnn cnn is one of the most widely used neural network layers in deep learning models the greatest strength of cnn is that it has strong ability to extract features from an input image by convolution computations to form the so called feature maps a typical cnn building block consists of three basic constructs which are local receptive fields weight sharing and downsampling when dealing with high dimensional images it is impractical to connect all neurons in one layer to all neurons in its input layer local receptive field allows each neuron to connect to only a small neighborhood in the previous layer through the use of these local receptive fields each neuron can extract the local features of the input image such as line segments endpoint and corner weight sharing is a way for significantly reducing the number of parameters to optimize during network training in essence the same set of weights are used in a moving window i e a filter or kernel to extract features in an input image under the assumption that if one feature is useful at one location it is also useful for other locations downsampling or pooling is an operation used to enforce translation invariance i e the same feature stays active even when the image undergoes slight translations because cnn has a strong ability to extract high level features from spatial space it is used to extract the spatial information at each gate and cell states as shown in fig 4 2 2 3 convolutional lstm convlstm as mentioned previously a major drawback of lstm is that it lacks a means for incorporating spatial information to deal with this problem convlstm combines cnn and lstm in convlstm all of the inputs of lstm are treated as tensors denoted as x 1 x t cell outputs c 1 c t hidden states h 1 h t and gates i t f t o t the tensors are high dimensional arrays that can be used to represent static and dynamic reservoir variables the resulting update functions are similar to the lstm model given in eq 1 except that the data for each gate is now a 3d tensor 2 i t σ w hi h t 1 w ci c t 1 w xi x t b i f t σ w hf h t 1 w cf c t 1 w xf x t b f c t tanh w hc h t 1 w xc x t b c c t f t c t 1 i t c t o t σ w ho h t 1 w xo x t b o h t o t tanh c t as eq 2 shows w ho h t 1 and w xo x t are obtained from convolutional calculations in cnn moreover cell outputs c t hidden states h t and gates i t f t o t are all calculated by convolutional calculations 2 3 anomaly detection here we describe a workflow for using convlstm to detect anomalies in the pressure data in particular the input data preparation model architecture and the algorithm performance on training validation and testing data are described below 2 3 1 reservoir model description the das site at cranfield has been characterized by well logging and geophysical surveys the top and bottom of the 3d static model were determined by a 3d seismic survey and are modeled as impermeable layers soltanian et al 2016 here we use a single layer reservoir model to incorporate static information under the assumption that the static variables represent effective properties the reservoir model has a high resolution with grid block sizes of 1 m 1 m in the lateral directions and one thick layer in the vertical direction therefore the reservoir formation is represented as a 120 120 1 image fig 3 f1 f2 and f3 represent the locations of wells in fig 3 2 3 2 input variable preprocessing input variables chosen to train a machine learning model should not only be based on their physical significance but also on the basis of statistical relevance to the response variable we start with the diffusivity equation for reservoir pressure in cylindrical coordinates 3 2 p r 2 1 r p r ϕ μ c p k p t where p is the reservoir pressure r is radial coordinate t is time c p is total compressibility μ is the dynamic viscosity of the fluid ϕ is porosity and k is the intrinsic permeability of the porous medium the reservoir pressure is a function of many factors including geological information such as porosity and permeability and operation conditions such as injection rate and operation schedule geological information is considered static for the purpose of this study therefore the geological data is referred as static data set in this research we only consider the porosity and permeability information to simplify the structure of convlstm model as fig 3 illustrates two static variable images ϕ and k are included in the input data set in addition to the static variables the injection rate q t represents a typical dynamic variable and is also the main driving force for the movement of co 2 plume to accommodate the time series measurements we introduce a dynamic 2d image in which the pixel value at the injection well location represents the injection rate the pixel values at pressure monitoring well locations are the corresponding bottom hole pressure values and the pixel values in all other grid blocks are zero the dynamic image variable is thus a sparse tensor due to the different injection schedules the dynamic variable image varies with time at the injection location stacking the static variable images and dynamic variable images leads to a new 3d input variable which is fed to the convlstm model the formats of the input data set are defined as follows 4 d static t 2 120 120 d dynamic t 1 120 120 d total t 3 120 120 where d static t is the static variable image with image sizes of 120 120 at time t and consists of two static properties porosity and permeability maps d dynamic t is the dynamic variable image with image sizes of 120 120 at time t and consists of injection rate and bottom hole pressure and d total t is the merged final input variable with image sizes of 120 120 3 at time t the output variable of the convlstm model is the predicted bottom hole pressure at time t in the monitoring well i e well f2 the data structure used for the training validation and testing of convlstm is illustrated in fig 3 data normalization is an important technique used in network training to improve prediction accuracy and training speed zhong and carr 2016 zhong et al 2018 all input variables including static variables and dynamic variables and output variables bottom hole pressure are normalized to range 0 1 the following scaling formula is chosen 5 x i new x i old x min x max x min where x i new is the normalized vector x min and x max are the minimum and maximum values for each variable and x i old represents the original variable 2 3 3 model structure and parameterization fig 4 shows the usage of convlstm in a time series fashion to predict bottom hole pressure at time t data sets from the previous k steps i e t k to t 1 are fed to the convlstm model a convolutional layer with 64 filters and a kernel of dimensions of 3 3 is used in the lstm memory cell the output layer is a fully connected network layer fed by flattening previous feature maps and activated by a linear activation function 2 3 4 anomaly detection accuracy assuming gaussian distributed pressure deviations the anomaly detection algorithm uses a threshold based method to identify anomalies for an m variate length n time series data set x x i i 1 m x i r n that follows the gaussian distribution with mean μ i and variance σ i for the i th variable the detection function is defined using gaussian distribution 6 p x i μ i σ i 1 σ i 2 π exp x i μ i 2 2 σ i 2 where μ i 1 n j 1 n x i j and σ i 2 1 n j 1 n x i j μ i 2 for a new test data point x i l the above detection function is used to calculate the probability of the test data point being in a user defined normal data range p d x i l if the probability is less than a user defined threshold i e p d x i l 1 i the test data point is classified as an anomaly otherwise it is considered a normal data point in our anomaly detection model only one property is considered which is the bottom hole pressure thus m 1 we compute the probability of pressure deviation δ p between measured bottom hole pressure p t and predicted bottom hole pressure p t of well f2 at time t the statistics σ and μ can be calculated from the training data for different models proposed in section 2 2 in this work we chose 3 σ as the detection threshold which corresponds to 0 997 therefore the data point p t is identified as an anomaly if δ p 3 σ and is considered normal if δ p 3 σ 3 results 3 1 model evaluation and comparison to train the convlstm we divide the 90 min base case pulse testing experiment data set described under section 2 1 into two parts 75 290 samples for training and the rest 25 90 samples for validation the trained convlstm model is then applied to the 90 min controlled release experiment data set to assess model performance for anomaly detection on data not included in training to highlight the time series prediction performance of the proposed convlstm model two baseline methods are also considered for comparison purposes one is the lstm regression model which is a pure black box model and does not allow incorporation of spatial data the second one is the cnn model which has a good performance on the spatial data set e g 2d porosity and permeability maps but is not particularly designed for time series regression problems reservoir porosity and permeability are assigned with constant values of 0 1 and 1 5 md respectively which represent effective properties derived from previous studies sun et al 2016 fig 5 shows the results obtained using all three models in this case convlstm performed the best during training and validation in terms of the coefficient of determination r 2 and root mean square error rmse see table 1 while the cnn model gave the lowest coefficient of determination r 2 0 9831 and 0 9774 on training and validation data suggesting that the particular cnn model used in this study is not a good regression model because of its lack of memory of the previous information when predicting the future bottom hole pressure in summary both convlstm and lstm show good performance in training and validation processes but convlstm has the advantage of incorporating geospatial information which will be useful for uncertainty analyses as we will show below 3 2 modeled uncertainty analysis effective reservoir properties are used in the base convlstm model to test the sensitivity of the trained convlstm model to the uncertainty in static data we run 1000 monte carlo simulations by sampling the permeability value uniformly from the range 0 1 10 md and performing prediction using the trained convlstm note that the default permeability used in this study is 1 5 md the results are shown in fig 6 the solid line indicates the ground truth bottom hole pressure in well f2 during the co 2 controlled release experiment and the shaded area is generated by using the 95 confidence interval derived from the monte carlo simulations 3 3 modeled anomaly detection fig 7 shows the anomalies detected using the convlstm model the green line corresponds to the predicted bottom hole pressure and the blue line shows the observed pressure data recorded in well f2 the colored zone corresponds to the 95 confidence interval in principle if the convlstm regression model is well trained it can be deployed as an anomaly detector to predict pressure anomalies when a new bottom hole pressure measurement falls within the confidence interval it is labeled normal otherwise it is classified as an anomaly as fig 7a shows most detected anomalies happened when the injector f1 is shut in and the residual values i e δ p between prediction and ground truth bottom hole pressure fig 7b during those time interval are significantly greater than 3 σ during injection cycles the predicted pressure values are mostly located within the confidence intervals 4 discussion 4 1 impact of permeability to study the impact of permeability on anomaly detection we keep the porosity map constant and change the permeability map for each case we apply the trained convlstm to detect the anomalies the result is shown in fig 8 the permeability is varied from 0 1 md to 1000 md when k 0 1 1 5 and 10 md the anomalies always happened when well f1 was shut in and the number of detected anomalies decreased from 68 to 57 during the injection period co 2 was continuously injected into the reservoir so the reservoir pressure was always maintained during artificial co 2 release therefore the pressure difference between co 2 leakage case and base case as predicted by this convlstm model is not significant thus it is not easy to detect the anomalies during the shut in period reservoir pressure could not be maintained because the injection was stopped and the pressure dropped more quickly and sharply in response to the controlled co 2 releases therefore the pressure differences between co 2 leakage case and base case as predicted by convlstm model become more significant however the opposite results were obtained when the permeability increased from 10 md to 1000 md the number of detected anomalies still decreased compared to the base case n 57 but anomalies happened during the injection time this phenomenon is probably caused by faster pressure dispersion in a higher permeability reservoir results shown here suggest that the trained convlstm is relatively robust to uncertain effective permeability values we emphasize that the approach presented here is general and can be applied to spatially heterogeneous permeability and or porosity maps when such information is available examples are shown below in section 4 3 4 2 impact of detection threshold the number of anomalies detected by the trained convlstm model is different if a different threshold is applied as fig 7b shows the anomalies count is 57 when the threshold is 3 σ it changes to 78 if the threshold is 2 σ and changes to 113 if the threshold is decreased to 1 σ different σ values indicate different prediction intervals which also means different credibility of the trained convlstm model higher σ values indicate wider prediction intervals but also less reliability of the trained convlstm model smaller σ values indicate narrower prediction interval and also more reliability of the convlstm model thus the selection of threshold of anomalies is important and depends on the reliability of the regression model 4 3 impact of heterogeneity to investigate the impact of permeability heterogeneity on anomaly detection we generate the permeability maps using geostatistical methods we established the permeability semi variogram in the lateral direction based on measured permeability values hosseini et al 2013 and then applied the semi variogram to generate permeability maps for the study region as shown in fig 9 fig 9a shows the homogeneous permeability map and fig 9b d show the heterogeneous permeability maps as fig 9 shows the number of detected anomalies and the corresponding time point vary for different reservoir properties in absence of detailed subsurface data set an accurate reservoir characterization is impossible which undermines the value of history matching for reservoir forecasting the recently introduced data space inversion dsi paradigm which focuses more on propagating an ensemble of uncalibrated prior models as opposed to history matching provides a more attractive alternative in the context of anomaly detection under uncertainty jeong et al 2018 satija and caers 2015 for example an ensemble of permeability maps can be formed and then fed to the convlstm model to generate the prediction interval 4 4 limitations the convlstm model we proposed in this research is mainly demonstrated for pressure anomaly detection in co 2 sequestration applications the pressure prediction depends on the antecedent time series information if the amount of data is not enough e g discontinuous time series measurements or if the data set is noisy our proposed model may get poor prediction and has limited improvement moreover this work relies on a predictive reservoir model to calculate pressure differences δ p and we assumed that the whole reservoir can be represented by a single layer in other cases a 3d reservoir model might be more reasonable but it may also increase the memory and cpu demand for training the model as an alternative to the approach taken in this study sun et al 2019 applied a supervised machine learning algorithm isolationforest to partition pressure data recursively using an ensemble of random trees in order to identify pressure anomalies their method does not require the use of a predictive reservoir model nevertheless a physics based approach is still required when it is necessary to incorporate knowledge on the uncertain reservoir properties the structure of data set that is fed to convlstm is redundant because we strive for generality i e our model structure can be applied to heterogeneous static variable maps at the expense of specificity in this case in the base case static variable images are constant but still participate in the convolution computation in each time step and most pixel values in dynamic variable images except for the pixel value at the injection well location are zero which increases the computational cost 5 conclusions in this study we propose a spatiotemporal convolutional long short term memory convlstm neural network model for co 2 leakage detection from a co 2 eor site we apply evaluate and discuss the model capability for predicting reservoir pressure before and after co 2 leakage using real data collected from the site our results indicate that 1 the machine learning approach can fuse both spatial information and temporal information which increases detectability of anomalies 2 spatial features from the input images can be learned by convolutional neural nets 3 lstm models can learn temporal features 4 a thorough reservoir characterization is the key for reliable leak detection when a predictive reservoir model is needed in this study anomalies can be more easily detected after injection in low permeability reservoir 5 availability of operation data e g injection rate is also critical for predicting nominal pressure patterns although our results are mainly demonstrated using 2d reservoir models it can be readily extended to 3d models if it is necessary to consider vertical heterogeneity in the reservoir conflict of interest none acknowledgements this work was supported by the u s department of energy national energy technology laboratory netl under grant no de fe0026515 the authors are grateful to the handling associate editor and two anonymous reviewers for their constructive comments appendix a supplementary data supplementary data associated with this article can be found in the online version athttps doi org 10 1016 j jhydrol 2019 04 015 supplementary data the following are the supplementary data to this article appendix a appendix a 
6557,the forecasting accuracy of downstream water levels greatly impacts the economic operation of reregulating hydropower stations if present large errors in water level forecasting may require the hydropower station to discard water which decreases the revenue from hydropower generation especially when the reregulating hydropower station undertakes the task of peak load regulation of the power grid its power output may change drastically over a short period of time such large changes in the discharged flow of the hydropower station may inevitably cause an unsteady flow which can lead to large fluctuations in the water levels of downstream rivers in this case the current forecasting methods such as standard rating curves and empirical formulae may inevitably result in large deviations when forecasting the change in the downstream water level in order to reduce the volume of water discarded as a result of forecasting errors a back propagation neural network based forecasting model for downstream water levels of a reregulating hydropower station was constructed the model enabled the direct accurate real time forecasting of changes in downstream water levels by using measurable operation data from a hydropower station and process data on downstream water level changes this method was applied to the actual hydropower generation dispatch of the gezhouba hydropower plant in china the results showed that as the peak load regulation volume increased the forecasting errors of two conventional methods standard rating curves and empirical formulae became continuously superimposed however the water level forecasting error of the neural network based method was small and could fully meet the real time dispatching requirements of the hydropower station in particular under large peak load regulations the maximum absolute values of the forecasting errors of the two conventional methods were close to 1 m while that of the neural network based method could be controlled within 0 3 m keywords hydropower station downstream water level forecasting bp neural network learning algorithm stage discharge relationship 1 introduction large reservoirs with huge power stations are often equipped with immediate downstream reservoirs to buffer reregulate the high outflow fluctuation caused by highly varying and peak power generation lu et al 2018 in principle the downstream reservoir should actively discard water if the upstream reservoir outflow exceeds the accommodation limits of the downstream reservoir however in order to ensure that the cascade hydropower station system can achieve the maximum power generation revenue the downstream hydropower station rarely takes the initiative to discard water shang et al 2017 take the three gorges gezhouba cascaded reservoirs in china for example the gezhouba is the reregulating reservoir of the three gorges reservoir and the period of time allocated to discarding water is generally no more than 20 of the annual operating period in practice chen et al 2013 since there is no larger tributary inflow between the two hydropower stations in geography the gezhouba reservoir water level can be determined using the discharge of the three gorges hydropower station when it is already known li et al 2012 in this case improving the forecasting accuracy of the downstream water level of the reregulating hydropower station is of great significance for accurately developing a power generation plan reasonably reducing the water loss of the reregulating hydropower station and thereby increasing the overall revenue of cascade hydropower stations ji et al 2018 nevertheless changes in the downstream water level of a hydropower station are related not only to the current output upstream water level and other parameters but also to the previous working state of the hydropower station i e there is a certain aftereffect this makes it very difficult to generate accurate real time forecasting results of changes in the downstream water levels of hydropower stations shrestha and simonovic 2009 gagné et al 1994 presently the following three methods are used for forecasting the downstream water levels of reregulating hydropower stations 1 standard rating curve ajmera and goyal 2012 2 hydrodynamic numerical simulations shao et al 2017 and 3 empirical formulae xia et al 2017 the standard rating curve is easy to use and is the most frequently used of the forecasting methods in the real time scheduling of hydropower stations guerrero et al 2012 the standard rating curve is used to forecast the downstream water level of a hydropower station mainly by the following three steps first the standard curve of the flow level relationship is established by using the measured data secondly the reservoir outflow is forecasted according to the established power generation plan of the hydropower station finally the standard stage discharge rating curve is examined according to the reservoir outflow to determine the corresponding downstream levels of the hydropower station among other factors the correct drawing of the stage discharge rating curve for the downstream section of the power station is critical for the successful implementation of the standard rating curve shimizu et al 2009 the stage discharge rating curve is usually a fitting curve with the water level as the ordinate and the flow as the abscissa in the long term the measured flow of a given section and the point data of the corresponding water level are in a dense zonal distribution and can be fitted by a single curve such that a stable one to one correspondence of stage discharge relationship can be established vafakhah and shojaei 2008 however in the short term and in real time analyses the stage discharge correspondence is unstable herschy 1994 in particular when the hydropower station undertakes peak load regulation the hydropower output changes greatly over a short period of time and the drastically changing discharge from the hydropower station may form an unsteady flow resulting in a sharp change in the water levels of the downstream channel even for the same section the same flow may then have multiple different water level values yu et al 2013 in practice the dispatching department of the hydropower plant typically uses the data for the daily average reservoir outflow and the downstream water level of the power station to establish a single corresponding rating curve the water level forecasting in the current period is then obtained by linear interpolation based on the daily stage discharge rating curve however such a static one to one stage discharge curve cannot reflect the dynamic and nonlinear characteristics of the unsteady flow discharged by the hydropower station birgand et al 2013 and this results in forecasting errors more specifically when the reservoir outflow of a hydropower station changes drastically the forecasting error tends to be very large hydrodynamic numerical simulations are mathematical models that can characterize the main features of the unsteady discharge flow of hydropower stations using hydraulic methods shang et al 2016 carpentier et al 2017 during the practical operation process the hydrodynamic numerical simulation models adopted to forecast the downstream water level of a hydropower station only take three steps first a hydrodynamic method is adopted to establish a mathematic model for the downstream river channel of the hydropower station secondly historical monitoring data are used to assess and validate the established mode finally the influence of changes in the discharge of the hydropower station on the hydrodynamic processes of the downstream river are analyzed thus the change in the downstream water level of the power station may be forecasted provided that a model is well defined and validated it can rather accurately forecast the changes in the downstream water level of a hydropower station under the influence of unsteady flow shang et al 2017 nevertheless hydrodynamic numerical simulations generally require high completeness of the data set such as turbine states and hydrological topographic and other data besides their forecasting accuracy fully depends on reasonable structure and wise parameter selection of the hydrodynamic model jansen et al 2007 in order to ensure the accuracy of the forecasting results it is necessary to obtain all data and use those data to fully validate the model savant et al 2010 however these model validation parameter determination and numerical calculation processes are time intensive and for most cases hydrodynamic numerical simulations cannot meet the real time dispatching requirements of hydropower stations lei et al 2018 zheng et al 2018 especially when a hydropower station participates in the peak load regulation of the power grid there is a strict requirement for the time limit from the issuance of a command to the formation of a dispatch scheme currently hydrodynamic numerical simulations are used in projects with low requirements for timeliness of calculations e g for formulating the dispatch rules of a hydropower station or evaluating the effects of changed water flow conditions on downstream rivers huang et al 2009 shaw et al 2017 the semi empirical formulae used for forecasting downstream water levels are simplifications or approximations of the hydrodynamic model measured data are adopted in a given formula to simplify the hydrodynamic model and to maintain the key hydraulic parameters and the factors that influence unsteady flow e g return water support and these are appropriately considered during the parameter calibration process so as to substantially improve the calculation efficiency reduce the difficulty of parameter setting and properly enhance accuracy zheng et al 2017 maghrebi and ahmadi 2017 many researchers have established corresponding semi empirical formulae for specific engineering objects chia et al 2018 abril and knight 2004 wiele and torizzo 2003 those studies also show that the forecasting results of semi empirical formulae are more accurate than the results of the standard rating curve however semi empirical formulae are still rough approximations of the complex changes in downstream water levels and their forecasting accuracy requires further improvement in general the standard rating curve and semi empirical formulae are very simple in their operations and their water level forecasting accuracies are only high when the changes in water level and flow rates are small basso and botter 2012 strictly speaking neither method can be used to quickly and effectively forecast downstream water levels when flows change sharply additionally both methods forecast future changes in water levels based on the change in the discharge of the power station among other factors the calculation error of the discharge of a hydropower station and the stage discharge conversion error may lead to the accumulation of water level forecasting errors the pressing and difficult problems in current studies are how to avoid stage discharge conversion errors and how to improve the real time forecasting accuracy of downstream water levels through data mining cordova et al 2014 the neural network is a nonlinear complex network system designed according to a biological brain and its basic units are nodes the connections between which are continuously optimized with learning kostić et al 2016 the versatility and strength of neural networks make them well suited for large and highly complex learning tasks in particular neural networks can be applied in the forecasting of hydrological sequences to ascertain their fundamental principles by learning only from sample data without the need to predetermine a mathematical model for said sample data jain 2000 in recent years researchers have attempted to modify the water level flow rating curve with real time monitoring data to improve the forecasting accuracy of the standard rating curve meselhe and habib 2006 designed a stage discharge rating curve optimization method based on historical monitoring data which improved the accuracy of curve fitting guven et al 2013 proposed an explicit neural network formulation ennf for modeling the stage discharge relationship as an alternative approach to standard regression techniques using measured data and an artificial neural network ann nezamkhiavy and nezamkhiavy 2014 obtained the stage discharge rating curve of the dost bayglu hydrometry station in azerbaijan in this study a back propagation bp neural network based forecasting model was established to forecast the downstream water level of a hydropower station according to monitoring data the structure of the remainder of this paper is as follows section 2 describes the proposed research method section 2 begins with a brief introduction to the standard rating curve and semi empirical formula then the proposed neural network based bp forecasting model is introduced in detail including network topology of bp modeling modeling data model training and data processing section 3 demonstrates the actual application of three methods first the application target gezhouba hydropower station is introduced and then the parameters of the three methods are explained finally the water level forecasting error of three methods and their effects on power generation are analyzed section 4 explains the authors understanding of gezhouba s power generation dispatching and discusses the application prospects of this method section 5 summarizes the paper 2 methodology 2 1 standard rating curve the standard rating curve method involves drawing a stage discharge rating curve or a fitted function through the historical daily average outflow and downstream water level points of the hydropower station a reservoir outflow time period or daily average is then input according to the curve or function to directly calculate the corresponding downstream water level the formula for calculating the downstream water level of a hydropower station is as follows 1 z n f q n where z n is the downstream water level q n is reservoir outflow and f is the rating curve or function of the downstream water level and reservoir outflow in the actual dispatching it is found that the error of the downstream water level calculated according to the current time curve is related to the calculation error of the previous time period in order to improve accuracy the average value of the calculation errors of the previous i days can be used as the correction value for the calculation error of the downstream water level on the same day 2 2 semi empirical formula for the semi empirical method the rising amplitude of the downstream water level is considered to be linearly related to the reservoir outflow when there is water discharged from the hydropower station and the downstream water level exponentially declines when the turbines are closed if the hydropower station has not been working for a long time the lowest water level z 0 may appear downstream if the reservoir outflow of the hydropower station is increased for a period of time a certain water level z t may appear downstream and this is related to the minimum water level and reservoir outflow downstream which can be expressed as 2 z t z 0 b q t where z t is the downstream water level at time t after flow increases q t is the reservoir outflow of the hydropower station at that time and b is a proportionality coefficient if this flow is subtracted after a certain time the downstream water level may fall exponentially in accordance with the constant k which is related to the characteristics of the downstream valley 3 z t δ t z 0 δ z t e t k in eq 3 z t δ t is the water level after the downstream water level disappears at time δ t when flow decreases and δ z t is the difference between the downstream water level and the minimum water level z 0 before flow decreases by substituting a e δ t k into eq 3 we get its general form as follows 4 z t z 0 a δ z t 1 where z t is the downstream water level at time t after flow decreases and δ z t 1 is the difference between the downstream water level at time t 1 and the minimum water level z 0 if the reservoir outflow of the hydropower station is increased again at time t the downstream water level at that time is relative to the deviation of z 0 which can be determined by summing the amplitudes in the two stages as follows 5 z t z 0 a δ z t 1 b q t where z t is the downstream water level at time t during the actual dispatch the lowest water level z 0 and the proportional coefficients a and b can be determined using historical data then the reservoir outflow and the downstream water level from the previous time t 1 are input and the downstream water level of the hydropower station at that moment can be calculated using eq 5 2 3 bp neural network based forecasting model for the design of a bp forecasting model it is necessary to first determine the factors affecting the changes in the downstream water levels of the hydropower station and the data required for modeling including model inputs and outputs the network topology of the bp model should then be determined including the number of hidden layers the number of neurons per layer and the activation function of the neurons finally the model data must be standardized and an optimization algorithm for model training must be developed 2 3 1 data required for establishing the bp forecasting model when a hydropower station is not forced to discard water the discharge flow is only related to the output and to the upstream and downstream water levels of the station while the back flow of the downstream water level is related to the reservoir outflow and downstream water flow of the station before a given period in this study the survey points of the downstream water level of the hydropower station are on banks of the reservoir and the water level changes were assumed to have been affected by the changes in the output of the station therefore the total output of the hydropower station outputs of subordinate stations upstream water levels and previous downstream water levels were taken as the influencing factors for forecasting the future downstream water level changes to establish the bp forecasting model in order to avoid calculation error associated with the reservoir outflow of the hydropower station the monitoring data that could be directly measured and read from the operation of the hydropower station and the changes in the downstream water level were selected as the modeling data the input data of the bp forecasting model were as follows hourly total power output sequence in the first n hours hourly substation output sequence within the first n hours hourly upstream water level sequence within the first n hours and hourly downstream water level sequence of the hydropower station in the first n k hours meanwhile the output data of the bp forecasting model were the hourly downstream water level sequences of the power station within k hours where kn n and k are natural numbers 2 3 2 network topology of the bp forecasting model in this study a three layer bp neural network was used to construct a forecasting model for the change in the downstream water level of the hydropower station the topology of the bp network is shown in fig 1 the bp model is a multi layer feed forward network model and the topology includes an input layer a hidden layer and an output layer each layer includes several neurons and the neurons between the upper and lower layers are fully connected while the neurons between the same layers are not connected in fig 1 a represents the input vector a a 1 a h a n b and c represent output vectors b b 1 b i b p and c c 1 c j c q v represents the weight vector for neurons between vectors a and b v v 11 v h 1 v n 1 v 1 i v hi v ni v 1 p v hp v np w represents the weight vector for neurons connecting b and c and w w 11 w i 1 w p 1 v 1 j v ij v pj v 1 q v iq v pq the activation function adds nonlinear factors to the neural network and improves its ability to solve complex problems here the most widely applied function tanh was used as the activation function to ensure that the output of the model was in the range 1 1 a common approach for determining the number of neurons in the hidden layer is the trial and error method kan et al 2018 the training data were divided into a training set and a validation set of which the former was used to train the model and the latter was used to validate the accuracy of the model after 1 16 hidden layer neurons were attempted it was found that when there were 10 hidden layer neurons the error of the validation set was the smallest so the number of hidden layer neurons should be 10 2 3 3 training and data processing of the bp forecasting model 2 3 3 1 input data processing of the bp forecasting model the selected variable indicators were different from each other and the magnitude differences of all variable indices were great which may affect the model therefore before modeling the data must be rendered dimensionless to eliminate the influence on the units and reduce the error caused by differences in the data in this study the input and output data were normalized as follows 6 y y max y min x x min x max x min y min where y is the variable data after normalization y m a x 1 y m i n 1 and x are the original data and x m a x and x m i n are the maximum and minimum values of the variable x respectively 2 3 3 2 training process of the bp forecasting model learning and training of the bp forecasting model included two processes of forward propagation and bp the signal of forward propagation passed through the input layer via the hidden layer and finally to the output layer if the output result did not satisfy the expected error bp was initiated in bp the error signal propagated backwards and corrected the thresholds and weights among neuron nodes layer by layer after several iterations the conditions for termination were reached the levenberg marquardt algorithm has a rapid convergence speed and a high degree of precision nacar et al 2018 the results of multiple practices and application tests have shown that it is an effective training algorithm for three layer bp neural network based forecasting models therefore the levenberg marquardt algorithm was adopted as the optimization algorithm for training the bp forecasting model 2 3 3 3 processing of the forecasted outputs of the bp model the normalized input and output data were substituted into the model and the gradient descent method was used for training after a set termination condition was reached the trained model was saved in the forecasting the data were normalized and then substituted into the model and the outputs of the model were inversely normalized according to the following equation 7 x y y min x max x min y max y min x min where x is the forecasted value of the downstream water level y is the output value of the model and y m a x 1 y m i n 1 x m a x and x m i n are the maximum and minimum values of the downstream water level stored during the normalization process 3 case study 3 1 project overview gezhouba reservoir is located in the main stream of the yangtze river and 38 km downstream from the dam site of the three georges reservoir it serves as a re regulating reservoir of the three georges reservoir and has a re regulating capacity of 85 million m3 the water level upstream of the gezhouba hydropower plant is mainly affected by the discharge of the three gorges reservoir and the gezhouba reservoir filling or emptying the gezhouba reservoir in the course of reservoir application means that the difference between daily inflow and outflow of the gezhouba reservoir reaches or exceeds 1000 m3 s however to avoid rapid rising or falling of water level which may affect the safety of dam structure the daily amplitude of variation in water level upstream from the gezhouba hydropower plant shall not exceed 3 m and the hourly amplitude of variation shall not exceed 1 m the location and engineering layout of gezhouba hydropower plant are demonstrated in fig 2 the gezhouba hydropower station consists of the dajiang power plant and the erjiang power plant which are separated by flood gates the upstream water level of the hydropower station is monitoring by hydrological station 5 and the downstream water level of the hydropower station is monitoring by hydrological station 7 both hydrological stations adopted the radar water level gauges with precision up to 0 01 m at the gezhouba hydropower station there are 23 sets of turbines installed 7 sets 15 sets and 1 set in dajiang plant erjiang plant and the power source plant of the hydropower station respectively the turbines have a combined installation capacity of 2 735 gw fig 3 shows the actual process diagram for the reservoir outflow and output of the gezhouba hydropower station in 2017 the gezhouba hydropower station does not conduct peak load regulation while it is discarding water in the case where no waters needs to be discarded the peak load regulation capacity is determined according to the outflow of the three gorges reservoir and the grid demand as can be seen from fig 2 under normal circumstances when the peak load regulation is less than 150 mw no more than two turbines must be started or shut down for this case the variation of downstream water level is less than 0 3 m when the reservoir outflow is great and the peak load regulation is over 600 mw more than 7 turbines should be started or shut down for this case the downstream water level can vary beyond 2 m 3 2 parameter settings the downstream water level of the gezhouba hydropower station was forecasted using the standard rating curve semi empirical formula and proposed bp forecasting model the 2014 2016 data were adopted to establish the bp model and to determine the parameters of the standard rating curve and semi empirical formula the performances of the three methods were then tested using 2017 as an example 3 2 1 standard rating curve the standard rating curve is obtained by fitting the daily average reservoir outflow and downstream water level data of gezhouba hydropower station from 2014 to 2016 and for the fitted curve r 2 0 9972 a total of 1098 sets of data total number of data 2196 were used in this study the rating curves of the daily average reservoir outflow and downstream water level of gezhouba from 2014 to 2016 are shown in fig 4 the stage discharge relationship shown in fig 4 is fitted by the following quadratic polynomial 8 z 7 2 14 10 9 q c 2 4 53 10 4 q c 37 5 where z 7 is the downstream water level of gezhouba and q c is the outlet outflow of gezhouba in this calculation the average value of the calculation errors for the first three days was used as the error correction value for the calculated downstream water level of the current day 3 2 2 semi empirical formula the typical process was selected from 2 hour operation data i e the flow data were calculated once every 2 h from 2014 to 2016 at the gezhouba hydropower station according to the flow classification the parameters a and b in eq 5 were then determined using a least squares method as shown in table 1 3 2 3 neural network based bp forecasting model from analysis of the 1 h operation data from gezhouba hydropower station between 2014 and 2016 it can be seen that after the output of the station changed the downstream water level reached a steady state in 4 6 h thus the previous impact period for the downstream water level on the current period was set to 6 h according to preliminary trial calculations and dispatch requirements the effective forecasting period of the model was set as 6 h therefore the input variables of the model were as follows average hourly total output in the first 12 h n i 11 n i hourly output of erjiang power plant in the first 12 h bn i 11 bn i hourly water level of station 5 in the first 12 h uz i 11 u z i hourly water level of station 7 in the first 7 12 h dz i 11 d z i 6 meanwhile the output variable of the model was the hourly water level of station 7 during the remaining 6 h dz i 5 d z i after the input and output variable data were normalized the bp neural network algorithm toolbox was selected in matlab v 2017b to set the number of hidden layer neurons as 10 and the maximum iterations as 10 000 the trainlm training function was then chosen with a training precision of 0 0000001 to implement training the output results of the model were inverse normalized and then the forecasting model for the changes in the downstream water levels of gezhouba was constructed in this study the hourly step size of 1 h operation data during the non discarded water period of gezhouba hydropower station from 2014 to 2016 were used in the bp neural network as the model training data sets there are 21 357 sets in total total number of data 512 568 the hourly average step size of 1 h operation data during the non discarded water period of gezhouba hydropower station in 2017 were used as the model validation data there are 8743 sets in total total number of data 209 832 the data is sufficient to enable the neural network based bp forecasting model to have high accuracy 3 3 results and analyses the errors in the downstream water levels forecasted by the three methods were tested when the flood season non flood season and peak load regulation capacity differed so as to compare and analyze the effects of different methods on the electric quantity of gezhouba and the cumulative effects of upstream water levels 3 3 1 overall analysis of water level forecasting errors from three methods the performances forecasted by the three methods were tested with the operational data from gezhouba hydropower station during the non discarded water period in 2017 the measured values of downstream water levels and the forecasting errors of each method when gezhouba did not discard water in 2017 were summarized in table 2 and shown in fig 5 nevertheless only 2 h forecasting results could be made using the current methods since the reservoir outflow of gezhouba was calculated once every 2 h it can be seen from table 2 and fig 5 that when gezhouba did not discard water the three methods exhibited small errors at low water levels and larger errors at high water levels the amount of peak load regulation was small when the reservoir outflow was small resulting in a low downstream water level and small amplitude so the forecasting results were relatively accurate when the reservoir outflow was high the peak load regulation was generally also high at this time the downstream water level was higher the unsteadiness in the flow was obvious and the forecasting error was great in contrast the forecasting model based on monitoring data exhibited high forecasting accuracies for both high and low water levels and flood and non flood seasons its median was stable and small and the absolute value of the forecasting error did not exceed 0 2 m this is because the two current methods first converted the output of the power plant into flow and then forecasted future changes in water level according to the flow level relationship of the downstream station in fact the stage discharge in the unsteady flow process is not in one to one correspondence but rather in a complex nonlinear relationship linear simplification of this nonlinear relationship results in deviation of the current two methods in water level forecasting the proposed method directly reads the output curve and control mode of the power plant during forecasting and therefore can avoid flow level conversion error additionally the bp method is a nonlinear model and the coupling effects of various nonlinear factors are considered in the modeling process therefore the proposed method has the highest water level forecasting accuracy under the conditions of low water level low flow and high water level high flow it can be seen from table 3 and fig 6that when gezhouba does not discard water the forecasting accuracy of the hourly water level process of the bp forecasting method is also very high and the forecasting accuracy at low water levels is slightly higher than that at high water levels the absolute value of the maximum forecasting error within 6 h of the forecasting period is less than 0 3 m meanwhile as the forecasting period extends the mean and median of the error increase slowly but the increase in amplitude is not large and the maximum and minimum values of the error do not increase linearly with the extension of the production period this indicates that there is no obvious cumulative effect on the forecasting error of the model during the forecasting period and that an accurate multi period sequence forecasting can be performed at one time in general the neural network based bp forecasting model exhibited the highest accuracy while the standard rating curve and the objective formula had the same levels of accuracy under high water levels and high peak load regulation the proposed method remained highly accurate however after the downstream water level exceeded 43 m the absolute values of the forecasting errors for the current methods were greater than 0 5 m with maximum absolute errors up to 1 114 m accounting for 5 of the rated head and seriously affecting the accuracy of power generation planning moreover the proposed method could effectively prolong the forecasting period allowing for up to 6 hour in advance forecasting and thus can support more flexible hydropower generation operations compared to the two conventional methods 3 3 2 water level forecasting errors of three methods during peak load regulation operation of the hydropower station in 2017 the peak load regulation of gezhouba lasted for 330 days with an annual average peak load regulation capacity of 350 000 kw minimum monthly average peak load regulation capacity of 80 000 kw january and maximum monthly average peak load regulation capacity of 800 000 kw july in this study three typical operating conditions of maximum peak load regulation 900 000 kw medium peak load regulation 400 000 kw and minimum peak load regulation 100 000 kw for flood and non flood seasons total of six were selected to compare and analyze the forecasting effects of the three methods the forecasting errors were summarized in table 4 and shown in fig 7 it can be seen from table 4 and fig 7 that as the peak load regulation increased the forecasting errors of the two current methods increased continuously but that of the proposed method did not change greatly and continued to exhibit a high level of accuracy and stable results the accuracies of the three methods under minimum peak load regulation during flood and non flood seasons were higher but the absolute forecasting errors of the current methods were within 0 4 m while that of the proposed method was within 0 1 m under medium peak load regulation of gezhouba during the non flood season the accuracies of the two current methods were not high and the maximum absolute forecasting error was 0 45 m the accuracy of the empirical formula was slightly higher than that of the standard rating curve while the accuracy of the proposed method was the highest with an absolute forecasting error within 0 2 m under medium peak load regulation during the flood season the absolute forecasting errors of the two current methods were greater than 0 6 m and their absolute forecasting errors under maximum peak load regulation during the flood and non flood seasons were close to 1 m with unstable forecasting results and a large range in deviation however the accuracy of the proposed method remained high with an absolute forecasting error within 0 1 m in general under the typical conditions of peak load regulation of the gezhouba hydropower station the neural network based bp forecasting model exhibited the highest accuracy and most stable calculation results the accuracies of the semi empirical formula and the standard rating curve may be ranked in second and third places respectively compared with the two current methods the proposed method was able to greatly improve the forecasting accuracy and frequency when the maximum 6 h amplitude of the downstream water level of gezhouba was close to 1 5 m the proposed method could quickly and accurately forecast changes in the downstream water level 3 3 3 cumulative effect of forecasting error on power generation and upstream water levels in this study the actual upstream water level and electricity of the gezhouba hydropower station under maximum medium and minimum peak load regulations during non flood and flood seasons were regarded as the benchmarks and the current and proposed methods were adopted to continuously forecast changes in the downstream water level over 6 h to inversely calculate the power generation of the hydropower station and the upstream water level at the end of the period compare the results with the benchmarks and analyze the cumulative effects of different methods on hydropower generation and upstream water levels fig 8 shows the cumulative effect of downstream water level prediction deviation on power generation of gezhouba hydropower station fig 8 a indicates the cumulative deviations in electricity generation of the gezhouba hydropower station within 6 h using the standard rating curve method semi empirical formula method and neural network based bp forecasting model in 2017 fig 8 b gives the cumulative deviations in water level of hydrological station 5 upstream of the gezhouba hydropower station it can be seen from table 5 and fig 8 that as the peak load regulation increased the cumulative deviation of hydropower generation and the upstream water levels calculated by the current methods increased accordingly and the cumulative deviation of the upstream water level exhibited an exponential growth i e the calculation error of the previous water level may have greatly affected the calculation of the later water level however the forecasting accuracy of the proposed method varied little with the increase in peak load regulation and its calculation results remained stable and with little error as for the standard rating curve the cumulative deviation of the 6 h power generation forecasted was up to 527 000 kw h and the control cumulative deviation of the upstream water level was up to 0 41 m meanwhile for the proposed method the maximum cumulative deviation of the 6 h power generation was only 12 000 kw h and the cumulative deviation of the upstream water level was only 0 10 m therefore the proposed method greatly improved power generation and water level control accuracy which is beneficial for ensuring the efficiency and safe operation of the hydropower station 4 discussion the upstream water level of gezhouba is strictly controlled by the power generation dispatch plan which is considered as known thus accurately forecasting the downstream water level of gezhouba is of great importance for reducing changes in the power generation plan and improving the efficiency of power generation at gezhouba once a large error is found between the actual and forecasted water level the upstream water level should be inversely calculated using the actual downstream water level if the upstream water level change exceeds the permitted range of water variations stipulated by the predetermined reservoir operation plan the power generation plan must be recalculated and the power grid should be requested to modify the current generation plan so as to control the upstream water level that is to say if the forecasting of the downstream water level of gezhouba is inaccurate it can only be corrected by short term continuous adjustment of the output plan to make up for the calculation error and maintain the upstream water level and steady operation of the hydropower station however the successive adjustment of the load on turbines may also affect the safe operation of the power grid practice has shown that the forecasting error of the downstream water level may lead to the deviation of actual station output the upstream water level and the power generation from the plan in particular the effect of the error on the upstream water level and the actual electric quantity exhibits a nonlinear growth trend for instance when the downstream water level of the gezhouba dam differs from the actual value by 0 5 m the deviation between the actual and planned outputs during a 1 h period may reach 100 000 kw when there is a power generation flow of 18 000 m3 s and a peak load regulation of 300 000 kw the deviation between the actual and planned water levels may then exceed 0 1 m and the deviation between the actual and planned power generations may exceed 150 000 kw h if the power generation plan cannot be corrected in time or if the error is not effectively controlled the deviation of the power station output plan at the beginning of the 2 h period can reach 300 000 kw at the end of the period the deviation in the calculated upstream water level may exceed 0 3 m and that of the calculated power generation may exceed 500 000 kw h at present a standard rating curve is the most used method at the gezhouba hydropower station in real time dispatching the standard rating curve can be used to calculate the downstream water level of gezhouba when the reservoir outflow is 6000 m3 s and the operation is not under peak load regulation the forecasting deviation of the period is within 0 5 m however when the output is 18 000 m3 s and the peak load regulation is 1 000 000 kw the absolute forecasting error exceeds 1 m as for power dispatching the gezhouba hydropower station frequently participates in the peak load regulation of the power grid its output fluctuates greatly and the downstream water level often has an hourly variation of more than 1 m with a cumulative variable amplitude of over 3 m the rated head of the power station is 18 6 m meanwhile the proposed method can generate a preliminary estimate of the downstream water level in real time dispatching based on the non discarded water period of the gezhouba hydropower station the operating data of the power station and the changing process data of the downstream water level could be directly measured and read in this study and the bp neural network algorithm was used to establish a real time forecasting model for the downstream water level the application results showed that the bp neural network forecasting model of the downstream water level of the hydropower station which was based on monitoring data could realize an online and real time forecasting for changes in the downstream water level moreover its forecasting accuracy was much higher than that of the current methods rendering the proposed method a very practical alternative in this study a three layer bp neural network was adopted to establish a forecasting model for changes in the downstream water level of the gezhouba hydropower station this selection was mainly based on the ability of such networks to resolve nonlinear relationships and the availability of abundant monitoring data from this station bp neural network models have been demonstrated to simulate complex nonlinear problems in particular a three layer bp network can form arbitrary complex regions and perform arbitrary n dimensional to m dimensional mapping li et al 2016 and such models have been successfully applied in the field of hydrology the gezhouba hydropower station has more than 100 000 sets of annual operating data if real time forecasting results of changes in the downstream water level of the hydropower station were performed it would be necessary to use the real time monitoring data sequence of the power station to generate hourly models at present the currently used forecasting methods are less robust than the bp model in terms of their data processing capabilities and computational efficiency the ann is a nonlinear adaptive information processing system that attempts to simulate the organization of a human brain it does not need to design a mathematical model to deal with ambiguous nonlinear or even noisy data it has been widely used for many purposes such as pattern recognition system identification predicative control and function fitting the information processing of this data mining technology can avoid the weaknesses associated with the conventional hydrodynamic simulation methods for the forecasting of changes in water level it is not necessary to understand the characteristics or rules of the discharge flow of a given hydropower station it is only necessary to directly find the stage discharge relationship of a given section according to large amounts of measured data if the characteristics implied by the real time monitoring data change the ann can adjust its model parameters to achieve an accurate trace function for transforming the downstream water level of the hydropower station 5 conclusion a new method for forecasting changes in the downstream water level by using the monitoring data of a hydropower station was proposed in this paper according to the operation process data of the hydropower station and the change data of the downstream water level that can be directly measured and read the bp neural network algorithm is used to establish a forecasting model for the downstream water level during forecasting it is only necessary to input the historical operation process and output plan data of the power station so that the future changes in the downstream water level can be forecasted compared with current water level forecasting methods the proposed method does not require flow data input and avoids the calculation error associated with the reservoir outflow the aftereffect of changes in the downstream water level is also accounted for in the modeling process which greatly improves the forecasting accuracy of peak load regulation furthermore the model can directly calculate changes in the downstream water level with stable calculation results which avoids the cumulative effect of calculation error for previous water levels on the calculation of later water levels resulting in a higher precision than in the conventional methods according to the application results from the gezhouba hydropower station the proposed method has been demonstrated to be simple fast and to have a higher forecasting accuracy than the current methods and this is of great practical importance for the dispatching operations of hydropower stations when not discarding water the main findings of this study are as follows 1 during non discarded water periods changes in the downstream water level of the hydropower station are affected by many factors in this study in allusion to the greater forecasting errors of the current methods the bp neural network algorithm was used to simulate the relationship between the operation process of the hydropower station and the change process of the downstream water level so as to establish a monitoring data based forecasting model for changes in the downstream water level the application results show that the proposed forecasting model has a high calculation accuracy and can be directly used in production dispatching 2 the bp neural network model is based on the principle of data mining and has a robust predicative effect especially for daily adjustments or run of flow hydropower stations with long running times and detailed data e g gezhouba hydropower station this is because gezhouba is a run of river hydropower station with small running water levels long running periods and abundant data the input data for the model involve various working conditions so that the model s forecasting effect is robust the application results show that the absolute value of the maximum forecasting error in the forecasting period is less than 0 3 m 3 the forecasting method proposed in this study has incomparable advantages over other methods for example the model can directly forecast changes in the downstream water level using the operation and planning data read by the monitoring system additionally the model can forecast the continuous hydrodynamic processes of downstream water levels with a calculation period of 1 h with stable results and greater accuracy that the current methods and avoiding the accumulation of error in the processes of forecasting the higher precision hydrodynamic model requires less data and a shorter calculation time and it can be better applied in the practice of dispatching however the application of the bp neural network model requires many years of detailed monitoring and operation data for the hydropower station in future research bp neural network modeling with a lack of such data should be further analyzed declaration of interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was supported by the national natural science foundation of china grant number 51579248 
6557,the forecasting accuracy of downstream water levels greatly impacts the economic operation of reregulating hydropower stations if present large errors in water level forecasting may require the hydropower station to discard water which decreases the revenue from hydropower generation especially when the reregulating hydropower station undertakes the task of peak load regulation of the power grid its power output may change drastically over a short period of time such large changes in the discharged flow of the hydropower station may inevitably cause an unsteady flow which can lead to large fluctuations in the water levels of downstream rivers in this case the current forecasting methods such as standard rating curves and empirical formulae may inevitably result in large deviations when forecasting the change in the downstream water level in order to reduce the volume of water discarded as a result of forecasting errors a back propagation neural network based forecasting model for downstream water levels of a reregulating hydropower station was constructed the model enabled the direct accurate real time forecasting of changes in downstream water levels by using measurable operation data from a hydropower station and process data on downstream water level changes this method was applied to the actual hydropower generation dispatch of the gezhouba hydropower plant in china the results showed that as the peak load regulation volume increased the forecasting errors of two conventional methods standard rating curves and empirical formulae became continuously superimposed however the water level forecasting error of the neural network based method was small and could fully meet the real time dispatching requirements of the hydropower station in particular under large peak load regulations the maximum absolute values of the forecasting errors of the two conventional methods were close to 1 m while that of the neural network based method could be controlled within 0 3 m keywords hydropower station downstream water level forecasting bp neural network learning algorithm stage discharge relationship 1 introduction large reservoirs with huge power stations are often equipped with immediate downstream reservoirs to buffer reregulate the high outflow fluctuation caused by highly varying and peak power generation lu et al 2018 in principle the downstream reservoir should actively discard water if the upstream reservoir outflow exceeds the accommodation limits of the downstream reservoir however in order to ensure that the cascade hydropower station system can achieve the maximum power generation revenue the downstream hydropower station rarely takes the initiative to discard water shang et al 2017 take the three gorges gezhouba cascaded reservoirs in china for example the gezhouba is the reregulating reservoir of the three gorges reservoir and the period of time allocated to discarding water is generally no more than 20 of the annual operating period in practice chen et al 2013 since there is no larger tributary inflow between the two hydropower stations in geography the gezhouba reservoir water level can be determined using the discharge of the three gorges hydropower station when it is already known li et al 2012 in this case improving the forecasting accuracy of the downstream water level of the reregulating hydropower station is of great significance for accurately developing a power generation plan reasonably reducing the water loss of the reregulating hydropower station and thereby increasing the overall revenue of cascade hydropower stations ji et al 2018 nevertheless changes in the downstream water level of a hydropower station are related not only to the current output upstream water level and other parameters but also to the previous working state of the hydropower station i e there is a certain aftereffect this makes it very difficult to generate accurate real time forecasting results of changes in the downstream water levels of hydropower stations shrestha and simonovic 2009 gagné et al 1994 presently the following three methods are used for forecasting the downstream water levels of reregulating hydropower stations 1 standard rating curve ajmera and goyal 2012 2 hydrodynamic numerical simulations shao et al 2017 and 3 empirical formulae xia et al 2017 the standard rating curve is easy to use and is the most frequently used of the forecasting methods in the real time scheduling of hydropower stations guerrero et al 2012 the standard rating curve is used to forecast the downstream water level of a hydropower station mainly by the following three steps first the standard curve of the flow level relationship is established by using the measured data secondly the reservoir outflow is forecasted according to the established power generation plan of the hydropower station finally the standard stage discharge rating curve is examined according to the reservoir outflow to determine the corresponding downstream levels of the hydropower station among other factors the correct drawing of the stage discharge rating curve for the downstream section of the power station is critical for the successful implementation of the standard rating curve shimizu et al 2009 the stage discharge rating curve is usually a fitting curve with the water level as the ordinate and the flow as the abscissa in the long term the measured flow of a given section and the point data of the corresponding water level are in a dense zonal distribution and can be fitted by a single curve such that a stable one to one correspondence of stage discharge relationship can be established vafakhah and shojaei 2008 however in the short term and in real time analyses the stage discharge correspondence is unstable herschy 1994 in particular when the hydropower station undertakes peak load regulation the hydropower output changes greatly over a short period of time and the drastically changing discharge from the hydropower station may form an unsteady flow resulting in a sharp change in the water levels of the downstream channel even for the same section the same flow may then have multiple different water level values yu et al 2013 in practice the dispatching department of the hydropower plant typically uses the data for the daily average reservoir outflow and the downstream water level of the power station to establish a single corresponding rating curve the water level forecasting in the current period is then obtained by linear interpolation based on the daily stage discharge rating curve however such a static one to one stage discharge curve cannot reflect the dynamic and nonlinear characteristics of the unsteady flow discharged by the hydropower station birgand et al 2013 and this results in forecasting errors more specifically when the reservoir outflow of a hydropower station changes drastically the forecasting error tends to be very large hydrodynamic numerical simulations are mathematical models that can characterize the main features of the unsteady discharge flow of hydropower stations using hydraulic methods shang et al 2016 carpentier et al 2017 during the practical operation process the hydrodynamic numerical simulation models adopted to forecast the downstream water level of a hydropower station only take three steps first a hydrodynamic method is adopted to establish a mathematic model for the downstream river channel of the hydropower station secondly historical monitoring data are used to assess and validate the established mode finally the influence of changes in the discharge of the hydropower station on the hydrodynamic processes of the downstream river are analyzed thus the change in the downstream water level of the power station may be forecasted provided that a model is well defined and validated it can rather accurately forecast the changes in the downstream water level of a hydropower station under the influence of unsteady flow shang et al 2017 nevertheless hydrodynamic numerical simulations generally require high completeness of the data set such as turbine states and hydrological topographic and other data besides their forecasting accuracy fully depends on reasonable structure and wise parameter selection of the hydrodynamic model jansen et al 2007 in order to ensure the accuracy of the forecasting results it is necessary to obtain all data and use those data to fully validate the model savant et al 2010 however these model validation parameter determination and numerical calculation processes are time intensive and for most cases hydrodynamic numerical simulations cannot meet the real time dispatching requirements of hydropower stations lei et al 2018 zheng et al 2018 especially when a hydropower station participates in the peak load regulation of the power grid there is a strict requirement for the time limit from the issuance of a command to the formation of a dispatch scheme currently hydrodynamic numerical simulations are used in projects with low requirements for timeliness of calculations e g for formulating the dispatch rules of a hydropower station or evaluating the effects of changed water flow conditions on downstream rivers huang et al 2009 shaw et al 2017 the semi empirical formulae used for forecasting downstream water levels are simplifications or approximations of the hydrodynamic model measured data are adopted in a given formula to simplify the hydrodynamic model and to maintain the key hydraulic parameters and the factors that influence unsteady flow e g return water support and these are appropriately considered during the parameter calibration process so as to substantially improve the calculation efficiency reduce the difficulty of parameter setting and properly enhance accuracy zheng et al 2017 maghrebi and ahmadi 2017 many researchers have established corresponding semi empirical formulae for specific engineering objects chia et al 2018 abril and knight 2004 wiele and torizzo 2003 those studies also show that the forecasting results of semi empirical formulae are more accurate than the results of the standard rating curve however semi empirical formulae are still rough approximations of the complex changes in downstream water levels and their forecasting accuracy requires further improvement in general the standard rating curve and semi empirical formulae are very simple in their operations and their water level forecasting accuracies are only high when the changes in water level and flow rates are small basso and botter 2012 strictly speaking neither method can be used to quickly and effectively forecast downstream water levels when flows change sharply additionally both methods forecast future changes in water levels based on the change in the discharge of the power station among other factors the calculation error of the discharge of a hydropower station and the stage discharge conversion error may lead to the accumulation of water level forecasting errors the pressing and difficult problems in current studies are how to avoid stage discharge conversion errors and how to improve the real time forecasting accuracy of downstream water levels through data mining cordova et al 2014 the neural network is a nonlinear complex network system designed according to a biological brain and its basic units are nodes the connections between which are continuously optimized with learning kostić et al 2016 the versatility and strength of neural networks make them well suited for large and highly complex learning tasks in particular neural networks can be applied in the forecasting of hydrological sequences to ascertain their fundamental principles by learning only from sample data without the need to predetermine a mathematical model for said sample data jain 2000 in recent years researchers have attempted to modify the water level flow rating curve with real time monitoring data to improve the forecasting accuracy of the standard rating curve meselhe and habib 2006 designed a stage discharge rating curve optimization method based on historical monitoring data which improved the accuracy of curve fitting guven et al 2013 proposed an explicit neural network formulation ennf for modeling the stage discharge relationship as an alternative approach to standard regression techniques using measured data and an artificial neural network ann nezamkhiavy and nezamkhiavy 2014 obtained the stage discharge rating curve of the dost bayglu hydrometry station in azerbaijan in this study a back propagation bp neural network based forecasting model was established to forecast the downstream water level of a hydropower station according to monitoring data the structure of the remainder of this paper is as follows section 2 describes the proposed research method section 2 begins with a brief introduction to the standard rating curve and semi empirical formula then the proposed neural network based bp forecasting model is introduced in detail including network topology of bp modeling modeling data model training and data processing section 3 demonstrates the actual application of three methods first the application target gezhouba hydropower station is introduced and then the parameters of the three methods are explained finally the water level forecasting error of three methods and their effects on power generation are analyzed section 4 explains the authors understanding of gezhouba s power generation dispatching and discusses the application prospects of this method section 5 summarizes the paper 2 methodology 2 1 standard rating curve the standard rating curve method involves drawing a stage discharge rating curve or a fitted function through the historical daily average outflow and downstream water level points of the hydropower station a reservoir outflow time period or daily average is then input according to the curve or function to directly calculate the corresponding downstream water level the formula for calculating the downstream water level of a hydropower station is as follows 1 z n f q n where z n is the downstream water level q n is reservoir outflow and f is the rating curve or function of the downstream water level and reservoir outflow in the actual dispatching it is found that the error of the downstream water level calculated according to the current time curve is related to the calculation error of the previous time period in order to improve accuracy the average value of the calculation errors of the previous i days can be used as the correction value for the calculation error of the downstream water level on the same day 2 2 semi empirical formula for the semi empirical method the rising amplitude of the downstream water level is considered to be linearly related to the reservoir outflow when there is water discharged from the hydropower station and the downstream water level exponentially declines when the turbines are closed if the hydropower station has not been working for a long time the lowest water level z 0 may appear downstream if the reservoir outflow of the hydropower station is increased for a period of time a certain water level z t may appear downstream and this is related to the minimum water level and reservoir outflow downstream which can be expressed as 2 z t z 0 b q t where z t is the downstream water level at time t after flow increases q t is the reservoir outflow of the hydropower station at that time and b is a proportionality coefficient if this flow is subtracted after a certain time the downstream water level may fall exponentially in accordance with the constant k which is related to the characteristics of the downstream valley 3 z t δ t z 0 δ z t e t k in eq 3 z t δ t is the water level after the downstream water level disappears at time δ t when flow decreases and δ z t is the difference between the downstream water level and the minimum water level z 0 before flow decreases by substituting a e δ t k into eq 3 we get its general form as follows 4 z t z 0 a δ z t 1 where z t is the downstream water level at time t after flow decreases and δ z t 1 is the difference between the downstream water level at time t 1 and the minimum water level z 0 if the reservoir outflow of the hydropower station is increased again at time t the downstream water level at that time is relative to the deviation of z 0 which can be determined by summing the amplitudes in the two stages as follows 5 z t z 0 a δ z t 1 b q t where z t is the downstream water level at time t during the actual dispatch the lowest water level z 0 and the proportional coefficients a and b can be determined using historical data then the reservoir outflow and the downstream water level from the previous time t 1 are input and the downstream water level of the hydropower station at that moment can be calculated using eq 5 2 3 bp neural network based forecasting model for the design of a bp forecasting model it is necessary to first determine the factors affecting the changes in the downstream water levels of the hydropower station and the data required for modeling including model inputs and outputs the network topology of the bp model should then be determined including the number of hidden layers the number of neurons per layer and the activation function of the neurons finally the model data must be standardized and an optimization algorithm for model training must be developed 2 3 1 data required for establishing the bp forecasting model when a hydropower station is not forced to discard water the discharge flow is only related to the output and to the upstream and downstream water levels of the station while the back flow of the downstream water level is related to the reservoir outflow and downstream water flow of the station before a given period in this study the survey points of the downstream water level of the hydropower station are on banks of the reservoir and the water level changes were assumed to have been affected by the changes in the output of the station therefore the total output of the hydropower station outputs of subordinate stations upstream water levels and previous downstream water levels were taken as the influencing factors for forecasting the future downstream water level changes to establish the bp forecasting model in order to avoid calculation error associated with the reservoir outflow of the hydropower station the monitoring data that could be directly measured and read from the operation of the hydropower station and the changes in the downstream water level were selected as the modeling data the input data of the bp forecasting model were as follows hourly total power output sequence in the first n hours hourly substation output sequence within the first n hours hourly upstream water level sequence within the first n hours and hourly downstream water level sequence of the hydropower station in the first n k hours meanwhile the output data of the bp forecasting model were the hourly downstream water level sequences of the power station within k hours where kn n and k are natural numbers 2 3 2 network topology of the bp forecasting model in this study a three layer bp neural network was used to construct a forecasting model for the change in the downstream water level of the hydropower station the topology of the bp network is shown in fig 1 the bp model is a multi layer feed forward network model and the topology includes an input layer a hidden layer and an output layer each layer includes several neurons and the neurons between the upper and lower layers are fully connected while the neurons between the same layers are not connected in fig 1 a represents the input vector a a 1 a h a n b and c represent output vectors b b 1 b i b p and c c 1 c j c q v represents the weight vector for neurons between vectors a and b v v 11 v h 1 v n 1 v 1 i v hi v ni v 1 p v hp v np w represents the weight vector for neurons connecting b and c and w w 11 w i 1 w p 1 v 1 j v ij v pj v 1 q v iq v pq the activation function adds nonlinear factors to the neural network and improves its ability to solve complex problems here the most widely applied function tanh was used as the activation function to ensure that the output of the model was in the range 1 1 a common approach for determining the number of neurons in the hidden layer is the trial and error method kan et al 2018 the training data were divided into a training set and a validation set of which the former was used to train the model and the latter was used to validate the accuracy of the model after 1 16 hidden layer neurons were attempted it was found that when there were 10 hidden layer neurons the error of the validation set was the smallest so the number of hidden layer neurons should be 10 2 3 3 training and data processing of the bp forecasting model 2 3 3 1 input data processing of the bp forecasting model the selected variable indicators were different from each other and the magnitude differences of all variable indices were great which may affect the model therefore before modeling the data must be rendered dimensionless to eliminate the influence on the units and reduce the error caused by differences in the data in this study the input and output data were normalized as follows 6 y y max y min x x min x max x min y min where y is the variable data after normalization y m a x 1 y m i n 1 and x are the original data and x m a x and x m i n are the maximum and minimum values of the variable x respectively 2 3 3 2 training process of the bp forecasting model learning and training of the bp forecasting model included two processes of forward propagation and bp the signal of forward propagation passed through the input layer via the hidden layer and finally to the output layer if the output result did not satisfy the expected error bp was initiated in bp the error signal propagated backwards and corrected the thresholds and weights among neuron nodes layer by layer after several iterations the conditions for termination were reached the levenberg marquardt algorithm has a rapid convergence speed and a high degree of precision nacar et al 2018 the results of multiple practices and application tests have shown that it is an effective training algorithm for three layer bp neural network based forecasting models therefore the levenberg marquardt algorithm was adopted as the optimization algorithm for training the bp forecasting model 2 3 3 3 processing of the forecasted outputs of the bp model the normalized input and output data were substituted into the model and the gradient descent method was used for training after a set termination condition was reached the trained model was saved in the forecasting the data were normalized and then substituted into the model and the outputs of the model were inversely normalized according to the following equation 7 x y y min x max x min y max y min x min where x is the forecasted value of the downstream water level y is the output value of the model and y m a x 1 y m i n 1 x m a x and x m i n are the maximum and minimum values of the downstream water level stored during the normalization process 3 case study 3 1 project overview gezhouba reservoir is located in the main stream of the yangtze river and 38 km downstream from the dam site of the three georges reservoir it serves as a re regulating reservoir of the three georges reservoir and has a re regulating capacity of 85 million m3 the water level upstream of the gezhouba hydropower plant is mainly affected by the discharge of the three gorges reservoir and the gezhouba reservoir filling or emptying the gezhouba reservoir in the course of reservoir application means that the difference between daily inflow and outflow of the gezhouba reservoir reaches or exceeds 1000 m3 s however to avoid rapid rising or falling of water level which may affect the safety of dam structure the daily amplitude of variation in water level upstream from the gezhouba hydropower plant shall not exceed 3 m and the hourly amplitude of variation shall not exceed 1 m the location and engineering layout of gezhouba hydropower plant are demonstrated in fig 2 the gezhouba hydropower station consists of the dajiang power plant and the erjiang power plant which are separated by flood gates the upstream water level of the hydropower station is monitoring by hydrological station 5 and the downstream water level of the hydropower station is monitoring by hydrological station 7 both hydrological stations adopted the radar water level gauges with precision up to 0 01 m at the gezhouba hydropower station there are 23 sets of turbines installed 7 sets 15 sets and 1 set in dajiang plant erjiang plant and the power source plant of the hydropower station respectively the turbines have a combined installation capacity of 2 735 gw fig 3 shows the actual process diagram for the reservoir outflow and output of the gezhouba hydropower station in 2017 the gezhouba hydropower station does not conduct peak load regulation while it is discarding water in the case where no waters needs to be discarded the peak load regulation capacity is determined according to the outflow of the three gorges reservoir and the grid demand as can be seen from fig 2 under normal circumstances when the peak load regulation is less than 150 mw no more than two turbines must be started or shut down for this case the variation of downstream water level is less than 0 3 m when the reservoir outflow is great and the peak load regulation is over 600 mw more than 7 turbines should be started or shut down for this case the downstream water level can vary beyond 2 m 3 2 parameter settings the downstream water level of the gezhouba hydropower station was forecasted using the standard rating curve semi empirical formula and proposed bp forecasting model the 2014 2016 data were adopted to establish the bp model and to determine the parameters of the standard rating curve and semi empirical formula the performances of the three methods were then tested using 2017 as an example 3 2 1 standard rating curve the standard rating curve is obtained by fitting the daily average reservoir outflow and downstream water level data of gezhouba hydropower station from 2014 to 2016 and for the fitted curve r 2 0 9972 a total of 1098 sets of data total number of data 2196 were used in this study the rating curves of the daily average reservoir outflow and downstream water level of gezhouba from 2014 to 2016 are shown in fig 4 the stage discharge relationship shown in fig 4 is fitted by the following quadratic polynomial 8 z 7 2 14 10 9 q c 2 4 53 10 4 q c 37 5 where z 7 is the downstream water level of gezhouba and q c is the outlet outflow of gezhouba in this calculation the average value of the calculation errors for the first three days was used as the error correction value for the calculated downstream water level of the current day 3 2 2 semi empirical formula the typical process was selected from 2 hour operation data i e the flow data were calculated once every 2 h from 2014 to 2016 at the gezhouba hydropower station according to the flow classification the parameters a and b in eq 5 were then determined using a least squares method as shown in table 1 3 2 3 neural network based bp forecasting model from analysis of the 1 h operation data from gezhouba hydropower station between 2014 and 2016 it can be seen that after the output of the station changed the downstream water level reached a steady state in 4 6 h thus the previous impact period for the downstream water level on the current period was set to 6 h according to preliminary trial calculations and dispatch requirements the effective forecasting period of the model was set as 6 h therefore the input variables of the model were as follows average hourly total output in the first 12 h n i 11 n i hourly output of erjiang power plant in the first 12 h bn i 11 bn i hourly water level of station 5 in the first 12 h uz i 11 u z i hourly water level of station 7 in the first 7 12 h dz i 11 d z i 6 meanwhile the output variable of the model was the hourly water level of station 7 during the remaining 6 h dz i 5 d z i after the input and output variable data were normalized the bp neural network algorithm toolbox was selected in matlab v 2017b to set the number of hidden layer neurons as 10 and the maximum iterations as 10 000 the trainlm training function was then chosen with a training precision of 0 0000001 to implement training the output results of the model were inverse normalized and then the forecasting model for the changes in the downstream water levels of gezhouba was constructed in this study the hourly step size of 1 h operation data during the non discarded water period of gezhouba hydropower station from 2014 to 2016 were used in the bp neural network as the model training data sets there are 21 357 sets in total total number of data 512 568 the hourly average step size of 1 h operation data during the non discarded water period of gezhouba hydropower station in 2017 were used as the model validation data there are 8743 sets in total total number of data 209 832 the data is sufficient to enable the neural network based bp forecasting model to have high accuracy 3 3 results and analyses the errors in the downstream water levels forecasted by the three methods were tested when the flood season non flood season and peak load regulation capacity differed so as to compare and analyze the effects of different methods on the electric quantity of gezhouba and the cumulative effects of upstream water levels 3 3 1 overall analysis of water level forecasting errors from three methods the performances forecasted by the three methods were tested with the operational data from gezhouba hydropower station during the non discarded water period in 2017 the measured values of downstream water levels and the forecasting errors of each method when gezhouba did not discard water in 2017 were summarized in table 2 and shown in fig 5 nevertheless only 2 h forecasting results could be made using the current methods since the reservoir outflow of gezhouba was calculated once every 2 h it can be seen from table 2 and fig 5 that when gezhouba did not discard water the three methods exhibited small errors at low water levels and larger errors at high water levels the amount of peak load regulation was small when the reservoir outflow was small resulting in a low downstream water level and small amplitude so the forecasting results were relatively accurate when the reservoir outflow was high the peak load regulation was generally also high at this time the downstream water level was higher the unsteadiness in the flow was obvious and the forecasting error was great in contrast the forecasting model based on monitoring data exhibited high forecasting accuracies for both high and low water levels and flood and non flood seasons its median was stable and small and the absolute value of the forecasting error did not exceed 0 2 m this is because the two current methods first converted the output of the power plant into flow and then forecasted future changes in water level according to the flow level relationship of the downstream station in fact the stage discharge in the unsteady flow process is not in one to one correspondence but rather in a complex nonlinear relationship linear simplification of this nonlinear relationship results in deviation of the current two methods in water level forecasting the proposed method directly reads the output curve and control mode of the power plant during forecasting and therefore can avoid flow level conversion error additionally the bp method is a nonlinear model and the coupling effects of various nonlinear factors are considered in the modeling process therefore the proposed method has the highest water level forecasting accuracy under the conditions of low water level low flow and high water level high flow it can be seen from table 3 and fig 6that when gezhouba does not discard water the forecasting accuracy of the hourly water level process of the bp forecasting method is also very high and the forecasting accuracy at low water levels is slightly higher than that at high water levels the absolute value of the maximum forecasting error within 6 h of the forecasting period is less than 0 3 m meanwhile as the forecasting period extends the mean and median of the error increase slowly but the increase in amplitude is not large and the maximum and minimum values of the error do not increase linearly with the extension of the production period this indicates that there is no obvious cumulative effect on the forecasting error of the model during the forecasting period and that an accurate multi period sequence forecasting can be performed at one time in general the neural network based bp forecasting model exhibited the highest accuracy while the standard rating curve and the objective formula had the same levels of accuracy under high water levels and high peak load regulation the proposed method remained highly accurate however after the downstream water level exceeded 43 m the absolute values of the forecasting errors for the current methods were greater than 0 5 m with maximum absolute errors up to 1 114 m accounting for 5 of the rated head and seriously affecting the accuracy of power generation planning moreover the proposed method could effectively prolong the forecasting period allowing for up to 6 hour in advance forecasting and thus can support more flexible hydropower generation operations compared to the two conventional methods 3 3 2 water level forecasting errors of three methods during peak load regulation operation of the hydropower station in 2017 the peak load regulation of gezhouba lasted for 330 days with an annual average peak load regulation capacity of 350 000 kw minimum monthly average peak load regulation capacity of 80 000 kw january and maximum monthly average peak load regulation capacity of 800 000 kw july in this study three typical operating conditions of maximum peak load regulation 900 000 kw medium peak load regulation 400 000 kw and minimum peak load regulation 100 000 kw for flood and non flood seasons total of six were selected to compare and analyze the forecasting effects of the three methods the forecasting errors were summarized in table 4 and shown in fig 7 it can be seen from table 4 and fig 7 that as the peak load regulation increased the forecasting errors of the two current methods increased continuously but that of the proposed method did not change greatly and continued to exhibit a high level of accuracy and stable results the accuracies of the three methods under minimum peak load regulation during flood and non flood seasons were higher but the absolute forecasting errors of the current methods were within 0 4 m while that of the proposed method was within 0 1 m under medium peak load regulation of gezhouba during the non flood season the accuracies of the two current methods were not high and the maximum absolute forecasting error was 0 45 m the accuracy of the empirical formula was slightly higher than that of the standard rating curve while the accuracy of the proposed method was the highest with an absolute forecasting error within 0 2 m under medium peak load regulation during the flood season the absolute forecasting errors of the two current methods were greater than 0 6 m and their absolute forecasting errors under maximum peak load regulation during the flood and non flood seasons were close to 1 m with unstable forecasting results and a large range in deviation however the accuracy of the proposed method remained high with an absolute forecasting error within 0 1 m in general under the typical conditions of peak load regulation of the gezhouba hydropower station the neural network based bp forecasting model exhibited the highest accuracy and most stable calculation results the accuracies of the semi empirical formula and the standard rating curve may be ranked in second and third places respectively compared with the two current methods the proposed method was able to greatly improve the forecasting accuracy and frequency when the maximum 6 h amplitude of the downstream water level of gezhouba was close to 1 5 m the proposed method could quickly and accurately forecast changes in the downstream water level 3 3 3 cumulative effect of forecasting error on power generation and upstream water levels in this study the actual upstream water level and electricity of the gezhouba hydropower station under maximum medium and minimum peak load regulations during non flood and flood seasons were regarded as the benchmarks and the current and proposed methods were adopted to continuously forecast changes in the downstream water level over 6 h to inversely calculate the power generation of the hydropower station and the upstream water level at the end of the period compare the results with the benchmarks and analyze the cumulative effects of different methods on hydropower generation and upstream water levels fig 8 shows the cumulative effect of downstream water level prediction deviation on power generation of gezhouba hydropower station fig 8 a indicates the cumulative deviations in electricity generation of the gezhouba hydropower station within 6 h using the standard rating curve method semi empirical formula method and neural network based bp forecasting model in 2017 fig 8 b gives the cumulative deviations in water level of hydrological station 5 upstream of the gezhouba hydropower station it can be seen from table 5 and fig 8 that as the peak load regulation increased the cumulative deviation of hydropower generation and the upstream water levels calculated by the current methods increased accordingly and the cumulative deviation of the upstream water level exhibited an exponential growth i e the calculation error of the previous water level may have greatly affected the calculation of the later water level however the forecasting accuracy of the proposed method varied little with the increase in peak load regulation and its calculation results remained stable and with little error as for the standard rating curve the cumulative deviation of the 6 h power generation forecasted was up to 527 000 kw h and the control cumulative deviation of the upstream water level was up to 0 41 m meanwhile for the proposed method the maximum cumulative deviation of the 6 h power generation was only 12 000 kw h and the cumulative deviation of the upstream water level was only 0 10 m therefore the proposed method greatly improved power generation and water level control accuracy which is beneficial for ensuring the efficiency and safe operation of the hydropower station 4 discussion the upstream water level of gezhouba is strictly controlled by the power generation dispatch plan which is considered as known thus accurately forecasting the downstream water level of gezhouba is of great importance for reducing changes in the power generation plan and improving the efficiency of power generation at gezhouba once a large error is found between the actual and forecasted water level the upstream water level should be inversely calculated using the actual downstream water level if the upstream water level change exceeds the permitted range of water variations stipulated by the predetermined reservoir operation plan the power generation plan must be recalculated and the power grid should be requested to modify the current generation plan so as to control the upstream water level that is to say if the forecasting of the downstream water level of gezhouba is inaccurate it can only be corrected by short term continuous adjustment of the output plan to make up for the calculation error and maintain the upstream water level and steady operation of the hydropower station however the successive adjustment of the load on turbines may also affect the safe operation of the power grid practice has shown that the forecasting error of the downstream water level may lead to the deviation of actual station output the upstream water level and the power generation from the plan in particular the effect of the error on the upstream water level and the actual electric quantity exhibits a nonlinear growth trend for instance when the downstream water level of the gezhouba dam differs from the actual value by 0 5 m the deviation between the actual and planned outputs during a 1 h period may reach 100 000 kw when there is a power generation flow of 18 000 m3 s and a peak load regulation of 300 000 kw the deviation between the actual and planned water levels may then exceed 0 1 m and the deviation between the actual and planned power generations may exceed 150 000 kw h if the power generation plan cannot be corrected in time or if the error is not effectively controlled the deviation of the power station output plan at the beginning of the 2 h period can reach 300 000 kw at the end of the period the deviation in the calculated upstream water level may exceed 0 3 m and that of the calculated power generation may exceed 500 000 kw h at present a standard rating curve is the most used method at the gezhouba hydropower station in real time dispatching the standard rating curve can be used to calculate the downstream water level of gezhouba when the reservoir outflow is 6000 m3 s and the operation is not under peak load regulation the forecasting deviation of the period is within 0 5 m however when the output is 18 000 m3 s and the peak load regulation is 1 000 000 kw the absolute forecasting error exceeds 1 m as for power dispatching the gezhouba hydropower station frequently participates in the peak load regulation of the power grid its output fluctuates greatly and the downstream water level often has an hourly variation of more than 1 m with a cumulative variable amplitude of over 3 m the rated head of the power station is 18 6 m meanwhile the proposed method can generate a preliminary estimate of the downstream water level in real time dispatching based on the non discarded water period of the gezhouba hydropower station the operating data of the power station and the changing process data of the downstream water level could be directly measured and read in this study and the bp neural network algorithm was used to establish a real time forecasting model for the downstream water level the application results showed that the bp neural network forecasting model of the downstream water level of the hydropower station which was based on monitoring data could realize an online and real time forecasting for changes in the downstream water level moreover its forecasting accuracy was much higher than that of the current methods rendering the proposed method a very practical alternative in this study a three layer bp neural network was adopted to establish a forecasting model for changes in the downstream water level of the gezhouba hydropower station this selection was mainly based on the ability of such networks to resolve nonlinear relationships and the availability of abundant monitoring data from this station bp neural network models have been demonstrated to simulate complex nonlinear problems in particular a three layer bp network can form arbitrary complex regions and perform arbitrary n dimensional to m dimensional mapping li et al 2016 and such models have been successfully applied in the field of hydrology the gezhouba hydropower station has more than 100 000 sets of annual operating data if real time forecasting results of changes in the downstream water level of the hydropower station were performed it would be necessary to use the real time monitoring data sequence of the power station to generate hourly models at present the currently used forecasting methods are less robust than the bp model in terms of their data processing capabilities and computational efficiency the ann is a nonlinear adaptive information processing system that attempts to simulate the organization of a human brain it does not need to design a mathematical model to deal with ambiguous nonlinear or even noisy data it has been widely used for many purposes such as pattern recognition system identification predicative control and function fitting the information processing of this data mining technology can avoid the weaknesses associated with the conventional hydrodynamic simulation methods for the forecasting of changes in water level it is not necessary to understand the characteristics or rules of the discharge flow of a given hydropower station it is only necessary to directly find the stage discharge relationship of a given section according to large amounts of measured data if the characteristics implied by the real time monitoring data change the ann can adjust its model parameters to achieve an accurate trace function for transforming the downstream water level of the hydropower station 5 conclusion a new method for forecasting changes in the downstream water level by using the monitoring data of a hydropower station was proposed in this paper according to the operation process data of the hydropower station and the change data of the downstream water level that can be directly measured and read the bp neural network algorithm is used to establish a forecasting model for the downstream water level during forecasting it is only necessary to input the historical operation process and output plan data of the power station so that the future changes in the downstream water level can be forecasted compared with current water level forecasting methods the proposed method does not require flow data input and avoids the calculation error associated with the reservoir outflow the aftereffect of changes in the downstream water level is also accounted for in the modeling process which greatly improves the forecasting accuracy of peak load regulation furthermore the model can directly calculate changes in the downstream water level with stable calculation results which avoids the cumulative effect of calculation error for previous water levels on the calculation of later water levels resulting in a higher precision than in the conventional methods according to the application results from the gezhouba hydropower station the proposed method has been demonstrated to be simple fast and to have a higher forecasting accuracy than the current methods and this is of great practical importance for the dispatching operations of hydropower stations when not discarding water the main findings of this study are as follows 1 during non discarded water periods changes in the downstream water level of the hydropower station are affected by many factors in this study in allusion to the greater forecasting errors of the current methods the bp neural network algorithm was used to simulate the relationship between the operation process of the hydropower station and the change process of the downstream water level so as to establish a monitoring data based forecasting model for changes in the downstream water level the application results show that the proposed forecasting model has a high calculation accuracy and can be directly used in production dispatching 2 the bp neural network model is based on the principle of data mining and has a robust predicative effect especially for daily adjustments or run of flow hydropower stations with long running times and detailed data e g gezhouba hydropower station this is because gezhouba is a run of river hydropower station with small running water levels long running periods and abundant data the input data for the model involve various working conditions so that the model s forecasting effect is robust the application results show that the absolute value of the maximum forecasting error in the forecasting period is less than 0 3 m 3 the forecasting method proposed in this study has incomparable advantages over other methods for example the model can directly forecast changes in the downstream water level using the operation and planning data read by the monitoring system additionally the model can forecast the continuous hydrodynamic processes of downstream water levels with a calculation period of 1 h with stable results and greater accuracy that the current methods and avoiding the accumulation of error in the processes of forecasting the higher precision hydrodynamic model requires less data and a shorter calculation time and it can be better applied in the practice of dispatching however the application of the bp neural network model requires many years of detailed monitoring and operation data for the hydropower station in future research bp neural network modeling with a lack of such data should be further analyzed declaration of interests the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement this work was supported by the national natural science foundation of china grant number 51579248 
6558,parameters are usually assumed to be stationary and regarded as constants in hydrological modelling however studies have shown that model parameters may vary temporally due to human activities and climate variability and changes this study proposes a framework for quantifying hydrological model parameters as functions of time variant catchment properties aiming to improve the capability of capturing hydrograph and the extrapolative ability of hydrological models under a changing environment the framework includes four steps 1 estimating model parameters by using an ensemble kalman filter based on the observations 2 analyzing correlations between estimated parameter values and catchment properties 3 constructing a set of parameter functions based on the identified catchment properties and the proposed functional forms and 4 selecting and testing the best performed model as a demonstration of the framework the monthly water balance for tongtianhe and ganjiang basins in china with different climate are simulated using a two parameter monthly water balance model results from the tongtianhe basin show that considering the time variant evapotranspiration parameter c brings improvement in low flows when water storage capacity sc is treated as constant since there is no significant improvement in runoff simulation when sc is treated as a time variant parameter the application to ganjiang basin shows that reasonable improvements are achieved when both c and sc are treated as time variant especially in low and high flows the presented framework provides a useful tool for estimating time variant parameters of hydrological models thereby leading to more reliable model predictions under a changing environment keywords hydrological modelling time variant parameter catchment properties ensemble kalman filter monthly water balance model 1 introduction hydrological models are important tools for studying hydrologic processes and assessing water resources availability besides the uncertainties of inputs and model structure model parameters play a significant role on producing credible predictions merz et al 2011 bulygina et al 2012 brigode et al 2013 gharari et al 2013 shi et al 2014 in hydrological modelling model parameters are usually set to be constant assuming that catchment conditions represented by parameters are stationary merz et al 2011 kim et al 2015 however it is no longer appropriate to treat model parameters as constant merz and blöschl 2009 pathiraja et al 2016 since catchment conditions have been significantly influenced by changing climate and human interventions such as urbanization wagener 2007 wang and hejazi 2011 meng et al 2016 wang et al 2016 seasonal variations of model parameters ye et al 1997 paik et al 2005 coron et al 2012 and the increasing trend of catchment water storage capacity due to land use and land cover change have been reported e g deng et al 2016 the climate variability and change of catchment properties could result in variations of hydrological parameters brown et al 2005 merz et al 2011 westra et al 2014 chiew and vaze 2015 patil and stieglitz 2015 for example wu and johnston 2007 calibrated the soil and water assessment tool swat model under climate conditions of drought and normal years they found that the soil evaporation compensation coefficient a parameter related to evapotranspiration process is relatively smaller during the normal years land use and land cover changes may also lead to temporal variations of watershed related model parameters brown et al 2005 a few methods have been investigated to cope with parameter nonstationarity in hydrological modelling one of the most common methods is differential split sample test proposed by klemeš 1986 in which the historical data is divided into consecutive subsets and the model parameters are calibrated separately for each period merz et al 2011 gharari et al 2013 thirel et al 2015 zhang et al 2016 recently sequential data assimilation da techniques such as the ensemble kalman filter enkf have been successfully used to estimate parameters and state variables of hydrological models samuel et al 2014 tamura et al 2014 shi et al 2015 pathiraja et al 2016 for instance deng et al 2016 used the enkf to identify the temporal variation of parameters of a two parameter monthly water balance model another method of estimating time variant parameters is to build its functional form based on time varying covariates shao et al 2012 jiang et al 2015 liu et al 2015 for example westra et al 2014 defined the production store capacity one parameter of a lumped rainfall runoff model gr4j as a function of covariates which are selected for representing seasonal annual and decadal variability specifically the seasonal variability was represented by a sine function of time t while it would be more appropriate to treat parameters with clear physical meanings as dependent on covariates e g indicators of catchment properties reflecting the hydrological dynamics of the catchment the enkf can reliably estimate model parameter values by assimilating available observations e g runoff but it will be extremely difficult to predict model parameters since the parameters are updated based on the observations at the current time step however the enkf can be used to estimate the time series of the model parameters during the calibration period providing opportunity for the construction of parameter functions based on the correlated catchment indicators the time variant parameter forecasts can be then calculated directly by using the constructed parameter functions in which the selected covariates can be available or predictable previous studies have revealed that much of the temporal variability of model parameters could be related to variations of catchment properties pokhrel et al 2008 yang et al 2009 voepel et al 2011 li et al 2013a yang et al 2014 ye et al 2015 for instance chen et al 2013 reported that vegetation is strongly correlated with dry season parameters of a budyko type model and it also has impacts on both evaporation and soil moisture dynamics zhang et al 2016 found that the landscape parameter of a budyko equation is sensitive to vegetation change especially in relatively dry catchments in addition to vegetation climate indicators are also found to be correlated with model parameters for example the temporal variations of the calibrated parameters of the hbv model can be correlated with air temperature and potential evapotranspiration as reported by merz et al 2011 wang and tang 2014 also showed that rainfall variability and vegetation are the dominant controlling factors on the parameter of a budyko equation wallner and haberlandt 2015 proposed a self organizing map based som b optimization approach to cope with the nonstationary hydrological model parameters and found that the storage coefficient of the hbv iww model is highly correlated with potential evaporation despite lots of studies into the relationship between model parameters and catchment properties there has been no comprehensive investigation based on our knowledge for constructing time variant functions of monthly hydrological model parameters based on catchment properties in this study a hydrological modelling framework is developed to enhance the model s capability of producing credible predictions under a changing environment especially for the runoff estimates in extreme values e g low and high flows the key element of the framework is the characterization of time variant parameters as functions of identified catchment indicators compared to the traditional approach of calibrating constant hydrological model parameters based on historical data the proposed method where the time variant parameters are treated as continuous functions of catchment properties offers a possibility for hydrological models to adapt to potential changes of catchment conditions in the future furthermore the model with constructed parameter functions will perform long range hydrological forecasts since the time variant parameters could be estimated using the calibrated functions and available catchment properties two basins with different climate conditions in china are selected as study sites in these basins the catchment indicators are identified for developing the time variant parameter functions during the calibration period the best performed models are selected and evaluated afterwards based on the validation data the paper is organized as follows section 2 describes the hydrological model used in this study the key steps of the proposed framework for building the time variant parameter functions and evaluation criteria of model performance section 3 provides a description of two study basins and data sources results and discussion are presented in section 4 followed by conclusions in section 5 2 methodology 2 1 monthly water balance model the hydrological models with time variant parameters are constructed based on a two parameter monthly water balance model twbm proposed by xiong and guo 1999 the twbm model is chosen due to its simple model structure and parameters furthermore it has been widely and successfully applied for monthly runoff simulation and forecast in china guo et al 2002 guo et al 2005 xiong and guo 2012 li et al 2013b wang et al 2013 zhang et al 2013 xiong et al 2014 bai et al 2015 the two parameters are evapotranspiration parameter c dimensionless and catchment water storage capacity sc mm the inputs of the twbm include monthly precipitation p mm and monthly potential evapotranspiration pet mm the monthly actual evaporation et mm is calculated as follows 1 e t t c p e t t tanh p t p e t t the monthly runoff q mm is dependent on the soil water content s mm and is calculated by the following equation 2 q t s t tanh s t s c the monthly actual evaporation ett can be computed by eq 1 when the monthly precipitation pt and the monthly potential evapotranspiration pett observations are given the available water for runoff at the beginning of the t th month is computed by s t 1 p t e t t after loss through evapotranspiration ett with st 1 being the soil water content at the end of the t 1 th month and at the beginning of the tth month then the monthly runoff at the tth month qt is calculated based on eq 2 as 3 q t s t 1 p t e t t tanh s t 1 p t e t t s c finally the soil water content at the end of the tth month st is updated based on the water conservation law 4 s t s t 1 p t e t t q t it should be noted that et will be zero if p equals to zero in eq 1 technically it is not sufficient enough for the calculation of the actual evaporation without consideration of soil moisture we tried a modification by adding the soil water content directly in eq 1 i e e t t c p e t t tanh p t s t 1 p e t t and it does not work well note that adding st 1 directly is an easy and acceptable way to consider the soil moisture condition of catchment into monthly water balance model wang and tang 2014 thus there is not a simple way for solving zero precipitation issue in actual evaporation calculation other formulations for evaporation module should be developed or other hydrological models should be used when zero precipitation cases occur fortunately the original twbm model can be applied for hydrological modelling in our case study since zero precipitation is not included during the period of 1982 2010 for tongtianhe and ganjiang basins nevertheless our proposed framework idea is still applicable with different evaporation formulations and even different hydrological models 2 2 hydrological modelling with time variant parameters our method for developing functions of time variant parameters for predicting catchment runoff under a changing environment includes the following steps 1 time variant model parameters are estimated using the enkf based on runoff observations during the calibration period 2 correlations between catchment indicators and model parameters are then analyzed by using the spearman rank correlation coefficient 3 functions of time variant parameters are built based on the identified catchment indicators in step 2 and 4 the performance of model with time variant parameter functions is assessed by hydrological metrics and compared with the performance of the model using constant parameters 2 2 1 estimation of time variant parameters as a sequential data assimilation technique enkf has been widely and successfully applied for parameter estimations of hydrological models xie and zhang 2013 thus the enkf is used to estimate the parameter series of the twbm model table 1 during the calibration period a brief description of assimilation process and set up in model parameter estimation is given below further details can be found in deng et al 2016 in this study the state variable i e s and parameters i e c and sc in the twbm model are simultaneously estimated by using the augmented state vector wang et al 2009 i e z θ x t where θ includes the evapotranspiration parameter c and the catchment water storage capacity sc and x is the soil water content s the model forecast is executed for each ensemble member by 5 θ t 1 t k x t 1 t k θ t t k f x t t k θ t 1 t k u t 1 δ t k ε t k where δ t k ñ 0 u t ε t k ñ 0 g t where θ t 1 t k and x t 1 t k are the kth ensemble member forecast of model parameters and state at t 1 month respectively θ t t k and x t t k are the kth updated ensemble member of model parameters and state at t month respectively f is the forecasting model operator i e the twbm model u t 1 is the force inputs for the twbm model including monthly precipitation p and potential evapotranspiration pet ε t k and δ t k are the independent white noise for the forecasting model following a gaussian distribution with zero mean and specified covariance g t and u t respectively the observation equation can be written as 6 y t 1 k h x t 1 t k θ t 1 t k ξ t 1 k ξ t 1 k ñ 0 w t 1 where y t 1 k is the kth ensemble member of the simulated runoff at t 1 month h is the observation operator which represents the relationship between the observation and the state variables i e the twbm model ξ t 1 k is the noise term which follows a gaussian distribution with zero mean and specified covariance w t 1 note that the matrices u g and w are determined empirically based on the previous literatures the standard deviation of c and sc i e u are set to be constant while for model state and observation errors i e g and w they are assumed to be proportional to the magnitude of the state variable and runoff observation the details are presented in section 4 1 1 with the model forecasts and observations being available the model parameters and state can be updated according to the following equations 7 z t 1 t 1 k z t 1 t k k t 1 y t 1 k h z t 1 t k 8 y t 1 k y t 1 ξ t 1 k where z t 1 t 1 k and z t 1 t k are the kth updated and forecasted ensemble member of the augmented state vector that includes both state and parameters at t 1 month respectively y t 1 k is the kth observation ensemble member generated by adding the observation error ξ t 1 k to the observed runoff y t 1 at t 1 month and k t 1 is the kalman gain which represents the weight between the forecasts and observations it can be calculated as follows moradkhani et al 2005 wang et al 2009 9 k t 1 t 1 t zy t 1 t yy w t 1 1 10 t 1 t zy 1 n 1 z t 1 t y t 1 t t 11 t 1 t yy 1 n 1 y t 1 t y t 1 t t where t 1 t zy is the cross covariance of the forecasted state and parameters t 1 t yy is the error covariance of the forecasted output z t 1 t z t 1 t 1 z t 1 t z t 1 t n z t 1 t where z t 1 t is the ensemble mean of the forecasted state and parameters y t 1 t y t 1 t 1 y t 1 t y t 1 t n y t 1 t where y t 1 t is the ensemble mean of the forecasted output n is the ensemble members and the superscript t represents the matrix transpose 2 2 2 correlation analysis between parameters and indicators in this study the two model parameters are allowed to be time variant the evapotranspiration parameter c is considered to vary in time to reflect the seasonal variability of the actual evaporation and the time variant water storage capacity sc is assumed to account for the potential annual or decadal variability owing to the changes of the catchment properties such as the land use and land cover as a significant factor for actual evaporation the consideration of vegetation conditions may improve the model s extrapolative ability especially in a changing environment moreover normalized difference vegetation index ndvi is a proxy for vegetation and has been reported to be strongly correlated with current and time shifted actual evaporation szilagyi et al 1998 voepel et al 2011 chen et al 2013 thus one month shifted ndvi and ndvi at t month are both used to explore the relationship to parameter c besides the antecedent monthly precipitation and potential evapotranspiration related to actual evaporation are also selected as catchment indicators the changes of sc are usually a long term process e g several seasons years or decades that closely related to the variation of catchment properties deng et al 2016 thus the variability of parameter sc potentially caused by hydroclimatic changes is considered by using the antecedent monthly precipitation and potential evapotranspiration westra et al 2014 by treating parameters c and sc as functions of catchment indicators we attempt to characterize the potential time variability of parameters associated with the variation of catchment properties therefore eight catchment indicators table 2 including ndvi one month shifted ndvi ndvi t 1 1 3 6 month antecedent monthly precipitation and potential evapotranspiration p1 p3 p6 pet1 pet3 pet6 are applied for correlation analysis with the estimated time variant parameters all the eight indicators are used for correlation analysis between catchment indicators and parameter c however note that significant changes such as the conversion of the type and rate of land cover and land use might account for the temporal variation of sc e g reservoir construction farm dams westra et al 2014 pathiraja et al 2018 while the ndvi is used as a proxy for vegetation conditions it might be not a proper index for reflecting changes of water storage capacity sc therefore ndvi is excluded for the function construction of sc the seasonality of time variant parameters and its relationship to the catchment indicators are mainly considered in this study therefore the mean monthly values instead of monthly values of the indicators and estimated parameter series are computed for correlation analysis the other reason using the mean monthly values is that it can eliminate the influence of the slight fluctuations in the estimated parameter series on the results of correlation analysis the spearman rank correlation coefficient rs is calculated to assess the relationship between the estimated parameters and the catchment indicators since the model parameters and the indicators are not necessarily linearly correlated merz et al 2011 spearman s rs ranges from 1 to 1 and a value of 1 means a completely negative correlation while 1 means a completely positive correlation pairs of data series have no correlation when rs equals 0 2 2 3 derivation of time variant parameters functions the time variant parameters are assumed to be functions of the identified catchment indicators that have significant correlations with the parameters three different functional forms including linear quadratic and cubic equations are applied for function construction of parameters 12 θ i a x j b θ i a x j 2 b x j c θ i a x j 3 b x j 2 c x j d moreover the multivariate functional forms are taken into account since single parameters may vary as function of the multiple catchment characteristics 13 θ i a x 1 b x 2 c x m d where θ i is the monthly values of the time variant parameters i 1 2 i e c and sc x j is the monthly values of the selected catchment indicators in section 2 2 2 j 1 n u m num is the total number of the selected catchment indicators m is the number of the selected catchment indicators for function construction of parameters 2 m n a b c and d are the parameters of the functions the functional parameters are estimated via nonlinear and multiple linear regression based on the monthly values of the identified indicators and the estimated time variant parameters various parameter scenarios including constant c and sc time variant c time variant sc and time variant c and sc are conducted during the calibration period based on the obtained empirical equations the model performance under each parameter scenario is assessed based on the hydrological metrics it should be noted that the constant parameters are estimated by using the shuffled complex evolution sce ua algorithm duan et al 1993 for the scenarios with one time variant parameter the value of the other parameter is set to be the calibrated constant value the scenario with time variant c and sc is a combination of time variant parameter function that has the best performance in each scenario separately time variant model parameters can also be forecasted by the state transition equation eq 5 in the assimilation process however it will be extremely difficult to predict model parameters since the updating of parameters relies on the observations at the current time step herein the one step parameter forecasts i e one month forward from the enkf are used for runoff estimation and compared with the constant and time variant parameter schemes mentioned above 2 3 performance evaluation criteria four statistical metrics including the nash sutcliffe efficiency nse nash and sutcliffe 1970 the water balance index wbi trudel et al 2014 the box cox transformed root mean square error trmse wang et al 2017 and the kling gupta efficiency kge gupta et al 2009 are employed to evaluate the model performance the nse has been widely used to assess the goodness of fit for hydrological modelling it ranges from to 1 and a value of one means a perfect match between runoff simulations and observations 14 nse 1 t 1 n q sim t q obs t 2 t 1 n q obs t q obs 2 where q sim t and q obs t are the simulated and observed monthly runoff for the tth month q obs is the mean value of the observed monthly runoff n is the total number of observations the wbi is a measure of bias between the simulated and observed runoff for example wbi with the value of one denotes no bias and a value smaller than one means an underestimation of the total runoff volume 15 wbi t 1 n q sim t t 1 n q obs t the trmse emphasizes the simulation errors in low flows and can be calculated by 16 trmse 1 n t 1 n q sim t q obs t 2 17 q 1 q λ 1 λ where q sim t and q obs t are the transformed simulated and observed monthly runoff for the tth month respectively q denotes the box cox transformation of monthly runoff q box and cox 1964 and λ equals to 0 3 as recommended by misirli et al 2013 obviously the smaller value of the trmse the better is the model performance the kge is sensitive to variance and high flows with its values varying from poor fit to 1 perfect fit the function of kge incorporates three basic assessment index i e the pearson s linear correlation coefficient r the ratio of standard deviations of simulated and observed monthly runoff α the ratio of mean values of simulated and observed monthly runoff β 18 kge 1 r 1 2 α 1 2 β 1 2 3 study catchments and data sets the proposed framework for nonstationary hydrological modelling is applied to tongtianhe and ganjiang basins in china as shown in fig 1 the tongtianhe basin located in southwestern qinghai province belongs to the source area of yangtze river basin with a drainage area of about 140 000 km2 and a total main river length of 1206 km the elevation of tongtianhe basin ranges from 3500 to 6500 m above the sea level it is classified as the continental climate with an aridity index of 1 9 and has a summer dominated rainfall regime the mean annual precipitation over the basin is 425 mm of which 77 occurs in the period from june to september the mean annual potential evapotranspiration is 790 mm and the mean annual runoff is about 92 mm the ganjiang basin is located in the middle and lower reaches of yangtze river and has an area of 80 948 km2 it lies in the subtropical region of a warm and humid climate with an aridity index of about 0 7 the mean annual precipitation of ganjiang basin is about 1550 mm of which 80 occurs in the wet season from april to september the mean annual potential evapotranspiration is about 1070 mm and the mean annual runoff is 870 mm the data sets from 1982 to 2010 including monthly precipitation potential evapotranspiration runoff and ndvi in the two basins are used in this study the potential evapotranspiration is calculated using the penman monteith equation allen et al 1998 based on the meteorological data from the china meteorological data sharing service system http data cma cn the ndvi data is obtained from the university of maryland tucker et al 2005 it is grid based with a spatial resolution of 8 km and is available from 1982 to 2006 the ndvi data is available every 15 days the monthly ndvi is represented by the averaged value of the two ndvi values in each month the data from 1982 to 2006 is used for model parameter estimation and that from 2006 to 2010 is used as validation period for the model with time variant parameters to reduce the impact of initial conditions a 2 year data set i e from 1982 to 1983 for both basins is reserved for warming up 4 results and discussion 4 1 estimated time variant parameters 4 1 1 data assimilation setup the ensemble size uncertainties in input and output have significant impacts on the assimilation performance of enkf and are specified following the previous studies samuel et al 2014 deng et al 2016 the ensemble size is set to 1000 for the two case studies note that the errors of model parameter should vary relying on the hydrological model used and the basin studied clark et al 2008 a larger standard deviation can generate greater perturbations to model parameters and can improve the coverage of updated parameters but may cause fluctuations in the estimates the parameter errors δ in eq 5 are determined empirically i e the standard deviation of c and sc are set to 0 01 and 0 5 respectively the standard deviations of model state and observation errors ε and ξ in eqs 5 and 6 are assumed to be proportional to the magnitude of the state variable and runoff observation wang et al 2009 lü et al 2013 the proportional factors of model state and runoff observation are set to 5 and 10 respectively the setup of standard deviation std of c and sc is crucial to the parameter estimation which would successively affect the model performance of runoff simulation thus various std values of c and sc are set to explore its impacts on the estimation of time variant parameter functions and the runoff performances further details are presented in appendix a 4 1 2 parameter estimation fig 2 presents the time series of monthly parameters c and sc obtained from enkf during the period of 1984 2006 along with its mean monthly values for parameter c the results in both basins show that the estimates have no significant temporal patterns in the whole period while seasonal variabilities exist according to the mean monthly series red line with solid square symbols shown in the inset graphs in fig 2 a and c results in fig 2 b and d show that the sc estimates have no detectable trend in tongtianhe basin but significant increasing trend in ganjiang basin the mean monthly series of estimated sc for both basins show seasonal variations the sc estimates for tongtianhe basin is approximately stable with small standard deviation σsc 12 3 which might be partially explained by the reason that the basin is located in a water protection zone and has no significant changes on water storage capacity caused by human activities deng et al 2016 the increasing trend of sc series in ganjiang basin is potentially correlated with the changes of land use and land cover during the calibration period the trees and grasses plantation and reservoir constructions can improve the water holding capacity of the catchment especially the increase of the reservoir total storage capacity since the 1980s zhu 2016 specifically the cumulative total storage capacity of the large reservoir with total storage of greater than 1 0 108 m3 see fig 3 shows an increasing trend during the period of 1984 2006 which is generally in accordance with the increasing trend of sc series presented in fig 2 d the detailed analysis about the identification of time variant parameters can be found in deng et al 2016 this study focuses on developing the functional form of the time variant parameters for improving hydrological model s extrapolative ability and its performance in certain aspects of hydrograph e g low and high flows in general the estimates of the two parameters with or without certain patterns show that the temporal variations exist for both basins the mean monthly values of the time variant c and sc are used for correlation analysis in the next section 4 2 relationships between estimated model parameters and catchment indicators the correlation between mean monthly time variant parameters and catchment indicators is summarized in fig 4 in terms of spearman s rank correlation coefficient rs note that it is considered to be a strong or significant correlation when rs 0 6 the results show that parameter c has strong correlations with ndvi t 1 p6 and pet1 in tongtianhe basin while the corresponding indicators are ndvi t 1 ndvi p1 p3 and pet1 in ganjiang basin the catchment indicators that significantly correlated to parameter sc are p1 pet1 and pet3 in tongtianhe basin and p1 p3 and pet1 in ganjiang basin these indicators for each parameter include at least one type of catchment properties i e vegetation and antecedent monthly precipitation and potential evapotranspiration in this study catchment indicators with rs 0 6 are selected as covariates for the functions of the time variant parameters the empirical equations for monthly time variant parameters are obtained by using linear nonlinear and multiple linear regressions based on the monthly indicators various cases of empirical formulas for estimating the monthly parameters c and sc based on the monthly values of selected catchment indicators are shown in tables 3 and 4 for tongtianhe and ganjiang basins respectively the corresponding model performance in each parameter case during the calibration period 1984 2006 is also presented through the four evaluation metrics introduced in section 2 3 the mean values of the correlation coefficients r 2 are 0 748 and 0 817 with minimum values of 0 283 and 0 392 for tongtianhe and ganjiang basins respectively the results demonstrate that the estimated time variant parameters from the constructed functions have a relatively high correlation with the parameter series obtained from the enkf all these time variant parameter functions are numbered and used to estimate the monthly parameters c and sc model performance is discussed further in the following section 4 3 performance of model with time variant parameters tables 3 and 4 illustrate the model performance statistics for various parameter scenarios in tongtianhe and ganjiang basins respectively the results show that models with time variant c or sc can have lower or higher nse than the model with constant parameters in the scenario of time variant c model with c 1 5 and constant sc has the best performance in tongtianhe basin with a 2 6 higher of nse and a 13 3 lower of trmse suggesting that model with time variant c 1 5 is mainly improved in low flows while for ganjiang basin the best performed model in which parameter is c 2 7 and constant sc has a 1 0 higher of nse a 2 1 lower of trmse and a 3 7 higher of kge suggesting that model with time variant c 2 7 is mainly improved in low and high flows all the cases in the scenario of time variant sc for tongtianhe basin have almost the similar performance in particular the nses are very close and slightly lower 0 4 1 2 than nse in constant parameter scenario while the values of wbi trmse and kge are almost same as those in constant parameter scenario the results indicate that different functional forms and catchment indicators of the time variant sc have no significant impacts on the performance in runoff estimation model with sc 1 7 and constant c outperforms the other cases of this scenario in tongtianhe basin and the corresponding case is sc 2 7 in ganjiang basin the performance of the model with sc 1 7 and constant c shows a 0 4 lower of nse than that of the model with constant parameters along with the same values of wbi trmse and kge it demonstrates that no improvement achieved when treating sc as time variant parameter in tongtianhe basin for ganjiang basin all the cases in this parameter scenario have lower or similar trmse and higher kge values than those in constant parameter scenario suggesting that different degrees of improvements are achieved in both low and high flows by considering time variant sc specifically model with sc 2 7 has the same nse as the model with constant parameters while better performances are achieved in both low and high flows i e a 3 1 lower of trmse and a 4 9 higher of kge respectively according to the nse values the model performance does not show obvious improvements with the increase of complexity of the parameter functions e g from linear to cubic and univariate to multivariate most of the groups of parameter cases generally show very close nse values the best performed parameter cases i e highest value of nse in each time variant parameter scenario are selected to compare with constant parameter cases for the two basins as shown in table 5 model with c 1 5 and constant sc in tongtianhe basin has the best performance among the four time variant parameter cases i e time variant c time variant sc combination of both and one step predicted c and sc from the enkf there is a 2 6 higher of nse and a 13 3 lower of trmse when compared to results of model with constant c and sc suggesting that model with c 1 5 has significant improvement in the estimation of low flows the differences of water balance between runoff observations and estimates obtained from model with c 1 5 and constant parameters are 1 underestimated total runoff volume and 6 overestimated total runoff volume respectively for ganjiang basin the best performed model in which parameter is c 2 7 and sc 2 7 has a 1 0 higher of nse a 5 2 lower of trmse and an 8 6 higher of kge suggesting that model with c 2 7 and sc 2 7 has improvements in both low and high flows although the nses of the two cases are very close the water balance results of the model with c 2 7 and sc 2 7 show a slight runoff overestimation with a relative error of 1 and those of model with constant parameters have an underestimation with a relative error of 1 fig 5 a and c are also presented using the flow duration curve to show the runoff performance in the above parameter cases generally results from the best performed model in each scenario for the two basins demonstrate that obvious improvements in the estimation of low or high flows are achieved during the calibration period when parameter c is considered to vary in time thus parameter c should be treated as time variant for both basins unlike the evapotranspiration parameter c the water storage capacity parameter sc usually has no apparent variations in a short term e g several months it tends to remain static unless severe changes occur in catchment conditions such as the land cover therefore considering time variant sc by using the empirical relationship between monthly parameters and catchment indicators has no significant improvements in tongtianhe basin which is barely affected by human activities owing to the limitation of the topographic condition and the water conservation measures implemented by the government deng et al 2016 the results from tongtianhe basin demonstrate that the sc value is not essentially necessary to be time variant and can be treated as a constant parameter for ganjiang basin parameter sc is considered to vary in time since the model with time variant sc improves runoff estimation in low and high flows as discussed in section 4 1 2 parameter sc has an increase trend during the calibration period and could be related to the catchment condition changes in ganjiang basin i e construction of reservoir and check dams thus sc should be time variant in ganjiang basin the results of both basins also show that the best performed parameter functions of c and sc are related to the antecedent monthly precipitation and potential evapotranspiration specifically the best performance is achieved when parameter c is represented as quadratic and linear functions of p6 and p1 in tongtianhe and ganjiang basins respectively and parameter sc is represented as linear function of pet1 in ganjiang basin based on the aforementioned results model with c 1 5 and constant sc c 2 7 and sc 2 7 are selected to assess the model s extrapolative ability based on the data from the period 2007 2010 in tongtianhe and ganjiang basins respectively table 6 presents the performance metrics of the model with constant parameters best performed parameter scenario and parameter forecasts from the enkf for the two basins during the validation period it shows that model with time variant c has a 1 5 lower of nse compared to that of the constant parameter scenario in tongtianhe basin fig 5 b but it still gives improvements in wbi trmse and kge the smaller nse for the model with time variant c is mainly caused by a larger over simulation in july 2009 see the point at the top of fig 6 a for the year 2009 the runoff observation in july was well out of the data range in the calibration period and the time variant parameter model may sometimes cause over simulation because the flexibility may introduce sensitivity if the observation is out of the data range in calibration in fact the constant parameter also over simulate the runoff value but the over simulation is smaller to see this we also calculate the nse without the use of july 2009 and the results are 0 766 for the time variant parameter model and 0 760 for the constant parameter model for ganjiang basin model with both time variant c and sc has an obvious improvement especially in low and high flows with a 10 6 lower of trmse and a 9 3 higher of kge fig 5 d model with one step forecasted parameters from the enkf has generally worse performances than results from model with constant parameters in both basins except it shows a 6 7 higher of kge in ganjiang basin the scatter plots for the runoff observations and the simulated runoff from models with constant and best performed time variant parameters are depicted in fig 6 for tongtianhe and ganjiang basins as shown in fig 6 a the monthly runoff in tongtianhe basin from the model with best performed time variant parameters solid points is closer to the 45 degree line than that of the constant parameter case hollow points in the lower tail of the scatter points while both the lower and upper tails of the solid points in fig 6 b are closer to the 45 degree line than the hollow points to give a clearer picture of the low flows the scatter of the logarithm of the runoff logq is presented in fig 6 c and d it is apparent that the solid points in both basins are closer to the 45 degree line than the hollow points and more obvious in the tongtianhe basin fig 7 presents comparisons of the observed and simulated monthly runoff from the models with constant parameters and best performed time variant parameters during the validation period for tongtianhe and ganjiang basins respectively it is shown that the runoff estimates obtained from the model with constructed parameter functions are better fitted for the observation of the monthly runoff in low and high flows for the two basins the results from the calibration and validation periods in tongtianhe basin show that model with time variant c has better performance than the model with constant parameters in low flows although it provides slightly higher and lower nses during the calibration and validation periods respectively for ganjiang basin all the streamflow characteristics including low medium and high flows achieve relatively significant improvements when both c and sc are treated as time variant parameters in summary considering time variant model parameters would be necessary and yield reasonable improvements in runoff estimation for catchments in which potential variations of parameter related catchment properties may occur for catchment like ganjiang basin hydrological model with time variant parameters which are assumed to be functions of identified catchment properties can provide more accurate and reliable predictions especially in the certain aspects of the hydrograph e g low and high flows 5 conclusions this study proposes and illustrates a framework for improving hydrological model performance under a changing environment the main purpose is to enhance the abilities of model s extrapolation and capturing extreme values of runoff estimates e g low and high flows by considering model parameter s to be time variant and building the corresponding parameter functions based on catchment indicators the framework includes four steps 1 estimating selected time variant parameter s by using a data assimilation technique such as the ensemble kalman filter enkf 2 analyzing correlations between estimated parameter s and catchment properties e g vegetation and climate related factors and selecting significant related catchment indicators as the covariates of the parameters functions 3 building time variant parameter functions based on the identified catchment properties and estimating function parameters through regression analysis 4 selecting and assessing model parameter functions by using hydrologically oriented metrics such as nash sutcliffe efficiency the framework is illustrated for two basins with different climate conditions in china using the two parameter monthly water balance model twbm for case study the two parameters of the twbm model i e evapotranspiration parameter c and water storage capacity sc are assumed to be time varying as functions of catchment properties i e ndvi antecedent monthly precipitation and potential evapotranspiration a calibration period from 1982 to 2006 is used for parameter function construction and selection and a validation period from 2007 to 2010 is used to assess the model performance when the best performed time variant functions are considered instead of the constant parameters the main conclusions are as follows different degrees of improvements are found in the shape of runoff hydrograph low and high flows during both the calibration and validation periods suggesting that the model with time variant parameter s is more suitable for representing the hydrological dynamics of the catchment the model with time variant c provides significant improvement in low flows in tongtianhe basin while the time variant sc shows no improvement in tongtianhe basin treating evapotranspiration parameter c to be time variant and water storage capacity sc to be constant is easier and more appropriate for monthly runoff simulation during the period of 1982 2010 for ganjiang basin improved model predictions are achieved when both the parameters c and sc are quantified as functions of catchment indicators which have significant correlations with the parameters briefly the selected functions of the time variant c and sc can be used for model prediction for ganjiang basin while time variant c function and constant sc are more suitable for tongtianhe basin as to the issue of the standard deviations stds of c and sc in the data assimilation process the setup of std would affect the actual values of model parameters but has no significant impacts on the runoff performance of the model with function formed parameters the proposed method provides an effective tool for improving model s representativeness to the hydrological processes which can then enhance the capability of models to produce reliable predictions in nonstationary hydrological modelling when this proposed framework is used to conduct runoff simulation for the future the selection of catchment properties and construction of functional forms may be required if the magnitude of climate changes and or land use changes in the future is more significant than that during the calibration period future research can be focused on investigating other factors which may cause the variations of model parameters such as the catchment soil conditions and human activities the enkf is applied to the estimation of the model parameters by considering its mean in this study in the next work improvement of the ensemble calibration may be achieved by using the enkf through the classical performance measures e g see details at https www atmos umd edu ekalnay syllabi aosc630 ensemble101 2014 pdf for accuracy reliability and discrimination acknowledgments this study was supported by the national science foundation of china 51809071 51779073 51579180 the national key research and development program 2016yfc0400907 the distinguished young fund project of jiangsu natural science foundation bk20180021 the fundamental research funds for the central universities 2018b55314 the open foundation of state key laboratory of water resources and hydropower engineering science in wuhan university 2015swg01 and the china postdoctoral science foundation 2017m621613 the authors thank the china meteorological data sharing service system for providing a part of the data used in this study we also thank the editor professor marco borga the associate editor professor yongqiang zhang and anonymous reviewers for their critical and constructive comments which highly improve the quality of the manuscript the data sets related to this study are available from the authors upon request liupan whu edu cn appendix a various cases of model parameter s std setup in enkf here we provide further details about the impact of different setups of standard deviation std of parameters c and sc in the data assimilation process on our conclusions various parameter std cases are set to explore its impacts on the construction functional forms of time variant parameters which will affect the model performance of runoff simulation a total of twenty five scenarios of parameter stds which is the combination of five different stds for each parameter table a1 have been implemented to estimate the time variant parameters for the first step of the proposed framework in section 2 2 based on the estimated parameter series catchment indicators correlated with model parameters are then selected as variables for the construction of time variant parameter functions finally performances of models with constructed time variant parameters are evaluated using hydrologically oriented metrics tables a2 and a3 present the estimated time variant parameter functions and the runoff performances for both calibration and validation periods under all the std scenarios for simplicity the best performed parameter cases i e highest value of nse for three kinds of parameter scenarios including time variant c time variant sc and their combination are selected to compare with constant parameter cases for each parameter std scenario it should be noted that there is no result for part of the std scenarios since the relationships between catchment indicators and estimated parameters does not satisfy the strong correlation requirement i e rs 0 6 fig a1 shows the runoff performance statistics for different parameter scenarios from models with function formed parameters under various parameter std setups the results in general are similar to those in section 4 3 suggesting that the std values would affect the actual parameter evolution but have no significant impacts on the performance of runoff simulation for the model with function formed parameters it means that the conclusions are not changed in particular improvements of runoff performance appear mainly in low flows when function formed c is applied for the tongtianhe basin while it would be more suitable for parameter sc keeping constant since no significant improvement fig a1 e is achieved when sc is treated as time variant for ganjiang basin runoff simulation improvements are achieved significantly in both low and high flows along with slightly higher nses fig a1 d and a1 f show that model with time variant c or time variant sc outperform model with constant parameters more specifically it has almost absolute better performance when both c and sc are treated as time variant green bar in fig a2 b thus treating model parameters as functions of identified catchment indicators can improve model performances for ganjiang basin 
6558,parameters are usually assumed to be stationary and regarded as constants in hydrological modelling however studies have shown that model parameters may vary temporally due to human activities and climate variability and changes this study proposes a framework for quantifying hydrological model parameters as functions of time variant catchment properties aiming to improve the capability of capturing hydrograph and the extrapolative ability of hydrological models under a changing environment the framework includes four steps 1 estimating model parameters by using an ensemble kalman filter based on the observations 2 analyzing correlations between estimated parameter values and catchment properties 3 constructing a set of parameter functions based on the identified catchment properties and the proposed functional forms and 4 selecting and testing the best performed model as a demonstration of the framework the monthly water balance for tongtianhe and ganjiang basins in china with different climate are simulated using a two parameter monthly water balance model results from the tongtianhe basin show that considering the time variant evapotranspiration parameter c brings improvement in low flows when water storage capacity sc is treated as constant since there is no significant improvement in runoff simulation when sc is treated as a time variant parameter the application to ganjiang basin shows that reasonable improvements are achieved when both c and sc are treated as time variant especially in low and high flows the presented framework provides a useful tool for estimating time variant parameters of hydrological models thereby leading to more reliable model predictions under a changing environment keywords hydrological modelling time variant parameter catchment properties ensemble kalman filter monthly water balance model 1 introduction hydrological models are important tools for studying hydrologic processes and assessing water resources availability besides the uncertainties of inputs and model structure model parameters play a significant role on producing credible predictions merz et al 2011 bulygina et al 2012 brigode et al 2013 gharari et al 2013 shi et al 2014 in hydrological modelling model parameters are usually set to be constant assuming that catchment conditions represented by parameters are stationary merz et al 2011 kim et al 2015 however it is no longer appropriate to treat model parameters as constant merz and blöschl 2009 pathiraja et al 2016 since catchment conditions have been significantly influenced by changing climate and human interventions such as urbanization wagener 2007 wang and hejazi 2011 meng et al 2016 wang et al 2016 seasonal variations of model parameters ye et al 1997 paik et al 2005 coron et al 2012 and the increasing trend of catchment water storage capacity due to land use and land cover change have been reported e g deng et al 2016 the climate variability and change of catchment properties could result in variations of hydrological parameters brown et al 2005 merz et al 2011 westra et al 2014 chiew and vaze 2015 patil and stieglitz 2015 for example wu and johnston 2007 calibrated the soil and water assessment tool swat model under climate conditions of drought and normal years they found that the soil evaporation compensation coefficient a parameter related to evapotranspiration process is relatively smaller during the normal years land use and land cover changes may also lead to temporal variations of watershed related model parameters brown et al 2005 a few methods have been investigated to cope with parameter nonstationarity in hydrological modelling one of the most common methods is differential split sample test proposed by klemeš 1986 in which the historical data is divided into consecutive subsets and the model parameters are calibrated separately for each period merz et al 2011 gharari et al 2013 thirel et al 2015 zhang et al 2016 recently sequential data assimilation da techniques such as the ensemble kalman filter enkf have been successfully used to estimate parameters and state variables of hydrological models samuel et al 2014 tamura et al 2014 shi et al 2015 pathiraja et al 2016 for instance deng et al 2016 used the enkf to identify the temporal variation of parameters of a two parameter monthly water balance model another method of estimating time variant parameters is to build its functional form based on time varying covariates shao et al 2012 jiang et al 2015 liu et al 2015 for example westra et al 2014 defined the production store capacity one parameter of a lumped rainfall runoff model gr4j as a function of covariates which are selected for representing seasonal annual and decadal variability specifically the seasonal variability was represented by a sine function of time t while it would be more appropriate to treat parameters with clear physical meanings as dependent on covariates e g indicators of catchment properties reflecting the hydrological dynamics of the catchment the enkf can reliably estimate model parameter values by assimilating available observations e g runoff but it will be extremely difficult to predict model parameters since the parameters are updated based on the observations at the current time step however the enkf can be used to estimate the time series of the model parameters during the calibration period providing opportunity for the construction of parameter functions based on the correlated catchment indicators the time variant parameter forecasts can be then calculated directly by using the constructed parameter functions in which the selected covariates can be available or predictable previous studies have revealed that much of the temporal variability of model parameters could be related to variations of catchment properties pokhrel et al 2008 yang et al 2009 voepel et al 2011 li et al 2013a yang et al 2014 ye et al 2015 for instance chen et al 2013 reported that vegetation is strongly correlated with dry season parameters of a budyko type model and it also has impacts on both evaporation and soil moisture dynamics zhang et al 2016 found that the landscape parameter of a budyko equation is sensitive to vegetation change especially in relatively dry catchments in addition to vegetation climate indicators are also found to be correlated with model parameters for example the temporal variations of the calibrated parameters of the hbv model can be correlated with air temperature and potential evapotranspiration as reported by merz et al 2011 wang and tang 2014 also showed that rainfall variability and vegetation are the dominant controlling factors on the parameter of a budyko equation wallner and haberlandt 2015 proposed a self organizing map based som b optimization approach to cope with the nonstationary hydrological model parameters and found that the storage coefficient of the hbv iww model is highly correlated with potential evaporation despite lots of studies into the relationship between model parameters and catchment properties there has been no comprehensive investigation based on our knowledge for constructing time variant functions of monthly hydrological model parameters based on catchment properties in this study a hydrological modelling framework is developed to enhance the model s capability of producing credible predictions under a changing environment especially for the runoff estimates in extreme values e g low and high flows the key element of the framework is the characterization of time variant parameters as functions of identified catchment indicators compared to the traditional approach of calibrating constant hydrological model parameters based on historical data the proposed method where the time variant parameters are treated as continuous functions of catchment properties offers a possibility for hydrological models to adapt to potential changes of catchment conditions in the future furthermore the model with constructed parameter functions will perform long range hydrological forecasts since the time variant parameters could be estimated using the calibrated functions and available catchment properties two basins with different climate conditions in china are selected as study sites in these basins the catchment indicators are identified for developing the time variant parameter functions during the calibration period the best performed models are selected and evaluated afterwards based on the validation data the paper is organized as follows section 2 describes the hydrological model used in this study the key steps of the proposed framework for building the time variant parameter functions and evaluation criteria of model performance section 3 provides a description of two study basins and data sources results and discussion are presented in section 4 followed by conclusions in section 5 2 methodology 2 1 monthly water balance model the hydrological models with time variant parameters are constructed based on a two parameter monthly water balance model twbm proposed by xiong and guo 1999 the twbm model is chosen due to its simple model structure and parameters furthermore it has been widely and successfully applied for monthly runoff simulation and forecast in china guo et al 2002 guo et al 2005 xiong and guo 2012 li et al 2013b wang et al 2013 zhang et al 2013 xiong et al 2014 bai et al 2015 the two parameters are evapotranspiration parameter c dimensionless and catchment water storage capacity sc mm the inputs of the twbm include monthly precipitation p mm and monthly potential evapotranspiration pet mm the monthly actual evaporation et mm is calculated as follows 1 e t t c p e t t tanh p t p e t t the monthly runoff q mm is dependent on the soil water content s mm and is calculated by the following equation 2 q t s t tanh s t s c the monthly actual evaporation ett can be computed by eq 1 when the monthly precipitation pt and the monthly potential evapotranspiration pett observations are given the available water for runoff at the beginning of the t th month is computed by s t 1 p t e t t after loss through evapotranspiration ett with st 1 being the soil water content at the end of the t 1 th month and at the beginning of the tth month then the monthly runoff at the tth month qt is calculated based on eq 2 as 3 q t s t 1 p t e t t tanh s t 1 p t e t t s c finally the soil water content at the end of the tth month st is updated based on the water conservation law 4 s t s t 1 p t e t t q t it should be noted that et will be zero if p equals to zero in eq 1 technically it is not sufficient enough for the calculation of the actual evaporation without consideration of soil moisture we tried a modification by adding the soil water content directly in eq 1 i e e t t c p e t t tanh p t s t 1 p e t t and it does not work well note that adding st 1 directly is an easy and acceptable way to consider the soil moisture condition of catchment into monthly water balance model wang and tang 2014 thus there is not a simple way for solving zero precipitation issue in actual evaporation calculation other formulations for evaporation module should be developed or other hydrological models should be used when zero precipitation cases occur fortunately the original twbm model can be applied for hydrological modelling in our case study since zero precipitation is not included during the period of 1982 2010 for tongtianhe and ganjiang basins nevertheless our proposed framework idea is still applicable with different evaporation formulations and even different hydrological models 2 2 hydrological modelling with time variant parameters our method for developing functions of time variant parameters for predicting catchment runoff under a changing environment includes the following steps 1 time variant model parameters are estimated using the enkf based on runoff observations during the calibration period 2 correlations between catchment indicators and model parameters are then analyzed by using the spearman rank correlation coefficient 3 functions of time variant parameters are built based on the identified catchment indicators in step 2 and 4 the performance of model with time variant parameter functions is assessed by hydrological metrics and compared with the performance of the model using constant parameters 2 2 1 estimation of time variant parameters as a sequential data assimilation technique enkf has been widely and successfully applied for parameter estimations of hydrological models xie and zhang 2013 thus the enkf is used to estimate the parameter series of the twbm model table 1 during the calibration period a brief description of assimilation process and set up in model parameter estimation is given below further details can be found in deng et al 2016 in this study the state variable i e s and parameters i e c and sc in the twbm model are simultaneously estimated by using the augmented state vector wang et al 2009 i e z θ x t where θ includes the evapotranspiration parameter c and the catchment water storage capacity sc and x is the soil water content s the model forecast is executed for each ensemble member by 5 θ t 1 t k x t 1 t k θ t t k f x t t k θ t 1 t k u t 1 δ t k ε t k where δ t k ñ 0 u t ε t k ñ 0 g t where θ t 1 t k and x t 1 t k are the kth ensemble member forecast of model parameters and state at t 1 month respectively θ t t k and x t t k are the kth updated ensemble member of model parameters and state at t month respectively f is the forecasting model operator i e the twbm model u t 1 is the force inputs for the twbm model including monthly precipitation p and potential evapotranspiration pet ε t k and δ t k are the independent white noise for the forecasting model following a gaussian distribution with zero mean and specified covariance g t and u t respectively the observation equation can be written as 6 y t 1 k h x t 1 t k θ t 1 t k ξ t 1 k ξ t 1 k ñ 0 w t 1 where y t 1 k is the kth ensemble member of the simulated runoff at t 1 month h is the observation operator which represents the relationship between the observation and the state variables i e the twbm model ξ t 1 k is the noise term which follows a gaussian distribution with zero mean and specified covariance w t 1 note that the matrices u g and w are determined empirically based on the previous literatures the standard deviation of c and sc i e u are set to be constant while for model state and observation errors i e g and w they are assumed to be proportional to the magnitude of the state variable and runoff observation the details are presented in section 4 1 1 with the model forecasts and observations being available the model parameters and state can be updated according to the following equations 7 z t 1 t 1 k z t 1 t k k t 1 y t 1 k h z t 1 t k 8 y t 1 k y t 1 ξ t 1 k where z t 1 t 1 k and z t 1 t k are the kth updated and forecasted ensemble member of the augmented state vector that includes both state and parameters at t 1 month respectively y t 1 k is the kth observation ensemble member generated by adding the observation error ξ t 1 k to the observed runoff y t 1 at t 1 month and k t 1 is the kalman gain which represents the weight between the forecasts and observations it can be calculated as follows moradkhani et al 2005 wang et al 2009 9 k t 1 t 1 t zy t 1 t yy w t 1 1 10 t 1 t zy 1 n 1 z t 1 t y t 1 t t 11 t 1 t yy 1 n 1 y t 1 t y t 1 t t where t 1 t zy is the cross covariance of the forecasted state and parameters t 1 t yy is the error covariance of the forecasted output z t 1 t z t 1 t 1 z t 1 t z t 1 t n z t 1 t where z t 1 t is the ensemble mean of the forecasted state and parameters y t 1 t y t 1 t 1 y t 1 t y t 1 t n y t 1 t where y t 1 t is the ensemble mean of the forecasted output n is the ensemble members and the superscript t represents the matrix transpose 2 2 2 correlation analysis between parameters and indicators in this study the two model parameters are allowed to be time variant the evapotranspiration parameter c is considered to vary in time to reflect the seasonal variability of the actual evaporation and the time variant water storage capacity sc is assumed to account for the potential annual or decadal variability owing to the changes of the catchment properties such as the land use and land cover as a significant factor for actual evaporation the consideration of vegetation conditions may improve the model s extrapolative ability especially in a changing environment moreover normalized difference vegetation index ndvi is a proxy for vegetation and has been reported to be strongly correlated with current and time shifted actual evaporation szilagyi et al 1998 voepel et al 2011 chen et al 2013 thus one month shifted ndvi and ndvi at t month are both used to explore the relationship to parameter c besides the antecedent monthly precipitation and potential evapotranspiration related to actual evaporation are also selected as catchment indicators the changes of sc are usually a long term process e g several seasons years or decades that closely related to the variation of catchment properties deng et al 2016 thus the variability of parameter sc potentially caused by hydroclimatic changes is considered by using the antecedent monthly precipitation and potential evapotranspiration westra et al 2014 by treating parameters c and sc as functions of catchment indicators we attempt to characterize the potential time variability of parameters associated with the variation of catchment properties therefore eight catchment indicators table 2 including ndvi one month shifted ndvi ndvi t 1 1 3 6 month antecedent monthly precipitation and potential evapotranspiration p1 p3 p6 pet1 pet3 pet6 are applied for correlation analysis with the estimated time variant parameters all the eight indicators are used for correlation analysis between catchment indicators and parameter c however note that significant changes such as the conversion of the type and rate of land cover and land use might account for the temporal variation of sc e g reservoir construction farm dams westra et al 2014 pathiraja et al 2018 while the ndvi is used as a proxy for vegetation conditions it might be not a proper index for reflecting changes of water storage capacity sc therefore ndvi is excluded for the function construction of sc the seasonality of time variant parameters and its relationship to the catchment indicators are mainly considered in this study therefore the mean monthly values instead of monthly values of the indicators and estimated parameter series are computed for correlation analysis the other reason using the mean monthly values is that it can eliminate the influence of the slight fluctuations in the estimated parameter series on the results of correlation analysis the spearman rank correlation coefficient rs is calculated to assess the relationship between the estimated parameters and the catchment indicators since the model parameters and the indicators are not necessarily linearly correlated merz et al 2011 spearman s rs ranges from 1 to 1 and a value of 1 means a completely negative correlation while 1 means a completely positive correlation pairs of data series have no correlation when rs equals 0 2 2 3 derivation of time variant parameters functions the time variant parameters are assumed to be functions of the identified catchment indicators that have significant correlations with the parameters three different functional forms including linear quadratic and cubic equations are applied for function construction of parameters 12 θ i a x j b θ i a x j 2 b x j c θ i a x j 3 b x j 2 c x j d moreover the multivariate functional forms are taken into account since single parameters may vary as function of the multiple catchment characteristics 13 θ i a x 1 b x 2 c x m d where θ i is the monthly values of the time variant parameters i 1 2 i e c and sc x j is the monthly values of the selected catchment indicators in section 2 2 2 j 1 n u m num is the total number of the selected catchment indicators m is the number of the selected catchment indicators for function construction of parameters 2 m n a b c and d are the parameters of the functions the functional parameters are estimated via nonlinear and multiple linear regression based on the monthly values of the identified indicators and the estimated time variant parameters various parameter scenarios including constant c and sc time variant c time variant sc and time variant c and sc are conducted during the calibration period based on the obtained empirical equations the model performance under each parameter scenario is assessed based on the hydrological metrics it should be noted that the constant parameters are estimated by using the shuffled complex evolution sce ua algorithm duan et al 1993 for the scenarios with one time variant parameter the value of the other parameter is set to be the calibrated constant value the scenario with time variant c and sc is a combination of time variant parameter function that has the best performance in each scenario separately time variant model parameters can also be forecasted by the state transition equation eq 5 in the assimilation process however it will be extremely difficult to predict model parameters since the updating of parameters relies on the observations at the current time step herein the one step parameter forecasts i e one month forward from the enkf are used for runoff estimation and compared with the constant and time variant parameter schemes mentioned above 2 3 performance evaluation criteria four statistical metrics including the nash sutcliffe efficiency nse nash and sutcliffe 1970 the water balance index wbi trudel et al 2014 the box cox transformed root mean square error trmse wang et al 2017 and the kling gupta efficiency kge gupta et al 2009 are employed to evaluate the model performance the nse has been widely used to assess the goodness of fit for hydrological modelling it ranges from to 1 and a value of one means a perfect match between runoff simulations and observations 14 nse 1 t 1 n q sim t q obs t 2 t 1 n q obs t q obs 2 where q sim t and q obs t are the simulated and observed monthly runoff for the tth month q obs is the mean value of the observed monthly runoff n is the total number of observations the wbi is a measure of bias between the simulated and observed runoff for example wbi with the value of one denotes no bias and a value smaller than one means an underestimation of the total runoff volume 15 wbi t 1 n q sim t t 1 n q obs t the trmse emphasizes the simulation errors in low flows and can be calculated by 16 trmse 1 n t 1 n q sim t q obs t 2 17 q 1 q λ 1 λ where q sim t and q obs t are the transformed simulated and observed monthly runoff for the tth month respectively q denotes the box cox transformation of monthly runoff q box and cox 1964 and λ equals to 0 3 as recommended by misirli et al 2013 obviously the smaller value of the trmse the better is the model performance the kge is sensitive to variance and high flows with its values varying from poor fit to 1 perfect fit the function of kge incorporates three basic assessment index i e the pearson s linear correlation coefficient r the ratio of standard deviations of simulated and observed monthly runoff α the ratio of mean values of simulated and observed monthly runoff β 18 kge 1 r 1 2 α 1 2 β 1 2 3 study catchments and data sets the proposed framework for nonstationary hydrological modelling is applied to tongtianhe and ganjiang basins in china as shown in fig 1 the tongtianhe basin located in southwestern qinghai province belongs to the source area of yangtze river basin with a drainage area of about 140 000 km2 and a total main river length of 1206 km the elevation of tongtianhe basin ranges from 3500 to 6500 m above the sea level it is classified as the continental climate with an aridity index of 1 9 and has a summer dominated rainfall regime the mean annual precipitation over the basin is 425 mm of which 77 occurs in the period from june to september the mean annual potential evapotranspiration is 790 mm and the mean annual runoff is about 92 mm the ganjiang basin is located in the middle and lower reaches of yangtze river and has an area of 80 948 km2 it lies in the subtropical region of a warm and humid climate with an aridity index of about 0 7 the mean annual precipitation of ganjiang basin is about 1550 mm of which 80 occurs in the wet season from april to september the mean annual potential evapotranspiration is about 1070 mm and the mean annual runoff is 870 mm the data sets from 1982 to 2010 including monthly precipitation potential evapotranspiration runoff and ndvi in the two basins are used in this study the potential evapotranspiration is calculated using the penman monteith equation allen et al 1998 based on the meteorological data from the china meteorological data sharing service system http data cma cn the ndvi data is obtained from the university of maryland tucker et al 2005 it is grid based with a spatial resolution of 8 km and is available from 1982 to 2006 the ndvi data is available every 15 days the monthly ndvi is represented by the averaged value of the two ndvi values in each month the data from 1982 to 2006 is used for model parameter estimation and that from 2006 to 2010 is used as validation period for the model with time variant parameters to reduce the impact of initial conditions a 2 year data set i e from 1982 to 1983 for both basins is reserved for warming up 4 results and discussion 4 1 estimated time variant parameters 4 1 1 data assimilation setup the ensemble size uncertainties in input and output have significant impacts on the assimilation performance of enkf and are specified following the previous studies samuel et al 2014 deng et al 2016 the ensemble size is set to 1000 for the two case studies note that the errors of model parameter should vary relying on the hydrological model used and the basin studied clark et al 2008 a larger standard deviation can generate greater perturbations to model parameters and can improve the coverage of updated parameters but may cause fluctuations in the estimates the parameter errors δ in eq 5 are determined empirically i e the standard deviation of c and sc are set to 0 01 and 0 5 respectively the standard deviations of model state and observation errors ε and ξ in eqs 5 and 6 are assumed to be proportional to the magnitude of the state variable and runoff observation wang et al 2009 lü et al 2013 the proportional factors of model state and runoff observation are set to 5 and 10 respectively the setup of standard deviation std of c and sc is crucial to the parameter estimation which would successively affect the model performance of runoff simulation thus various std values of c and sc are set to explore its impacts on the estimation of time variant parameter functions and the runoff performances further details are presented in appendix a 4 1 2 parameter estimation fig 2 presents the time series of monthly parameters c and sc obtained from enkf during the period of 1984 2006 along with its mean monthly values for parameter c the results in both basins show that the estimates have no significant temporal patterns in the whole period while seasonal variabilities exist according to the mean monthly series red line with solid square symbols shown in the inset graphs in fig 2 a and c results in fig 2 b and d show that the sc estimates have no detectable trend in tongtianhe basin but significant increasing trend in ganjiang basin the mean monthly series of estimated sc for both basins show seasonal variations the sc estimates for tongtianhe basin is approximately stable with small standard deviation σsc 12 3 which might be partially explained by the reason that the basin is located in a water protection zone and has no significant changes on water storage capacity caused by human activities deng et al 2016 the increasing trend of sc series in ganjiang basin is potentially correlated with the changes of land use and land cover during the calibration period the trees and grasses plantation and reservoir constructions can improve the water holding capacity of the catchment especially the increase of the reservoir total storage capacity since the 1980s zhu 2016 specifically the cumulative total storage capacity of the large reservoir with total storage of greater than 1 0 108 m3 see fig 3 shows an increasing trend during the period of 1984 2006 which is generally in accordance with the increasing trend of sc series presented in fig 2 d the detailed analysis about the identification of time variant parameters can be found in deng et al 2016 this study focuses on developing the functional form of the time variant parameters for improving hydrological model s extrapolative ability and its performance in certain aspects of hydrograph e g low and high flows in general the estimates of the two parameters with or without certain patterns show that the temporal variations exist for both basins the mean monthly values of the time variant c and sc are used for correlation analysis in the next section 4 2 relationships between estimated model parameters and catchment indicators the correlation between mean monthly time variant parameters and catchment indicators is summarized in fig 4 in terms of spearman s rank correlation coefficient rs note that it is considered to be a strong or significant correlation when rs 0 6 the results show that parameter c has strong correlations with ndvi t 1 p6 and pet1 in tongtianhe basin while the corresponding indicators are ndvi t 1 ndvi p1 p3 and pet1 in ganjiang basin the catchment indicators that significantly correlated to parameter sc are p1 pet1 and pet3 in tongtianhe basin and p1 p3 and pet1 in ganjiang basin these indicators for each parameter include at least one type of catchment properties i e vegetation and antecedent monthly precipitation and potential evapotranspiration in this study catchment indicators with rs 0 6 are selected as covariates for the functions of the time variant parameters the empirical equations for monthly time variant parameters are obtained by using linear nonlinear and multiple linear regressions based on the monthly indicators various cases of empirical formulas for estimating the monthly parameters c and sc based on the monthly values of selected catchment indicators are shown in tables 3 and 4 for tongtianhe and ganjiang basins respectively the corresponding model performance in each parameter case during the calibration period 1984 2006 is also presented through the four evaluation metrics introduced in section 2 3 the mean values of the correlation coefficients r 2 are 0 748 and 0 817 with minimum values of 0 283 and 0 392 for tongtianhe and ganjiang basins respectively the results demonstrate that the estimated time variant parameters from the constructed functions have a relatively high correlation with the parameter series obtained from the enkf all these time variant parameter functions are numbered and used to estimate the monthly parameters c and sc model performance is discussed further in the following section 4 3 performance of model with time variant parameters tables 3 and 4 illustrate the model performance statistics for various parameter scenarios in tongtianhe and ganjiang basins respectively the results show that models with time variant c or sc can have lower or higher nse than the model with constant parameters in the scenario of time variant c model with c 1 5 and constant sc has the best performance in tongtianhe basin with a 2 6 higher of nse and a 13 3 lower of trmse suggesting that model with time variant c 1 5 is mainly improved in low flows while for ganjiang basin the best performed model in which parameter is c 2 7 and constant sc has a 1 0 higher of nse a 2 1 lower of trmse and a 3 7 higher of kge suggesting that model with time variant c 2 7 is mainly improved in low and high flows all the cases in the scenario of time variant sc for tongtianhe basin have almost the similar performance in particular the nses are very close and slightly lower 0 4 1 2 than nse in constant parameter scenario while the values of wbi trmse and kge are almost same as those in constant parameter scenario the results indicate that different functional forms and catchment indicators of the time variant sc have no significant impacts on the performance in runoff estimation model with sc 1 7 and constant c outperforms the other cases of this scenario in tongtianhe basin and the corresponding case is sc 2 7 in ganjiang basin the performance of the model with sc 1 7 and constant c shows a 0 4 lower of nse than that of the model with constant parameters along with the same values of wbi trmse and kge it demonstrates that no improvement achieved when treating sc as time variant parameter in tongtianhe basin for ganjiang basin all the cases in this parameter scenario have lower or similar trmse and higher kge values than those in constant parameter scenario suggesting that different degrees of improvements are achieved in both low and high flows by considering time variant sc specifically model with sc 2 7 has the same nse as the model with constant parameters while better performances are achieved in both low and high flows i e a 3 1 lower of trmse and a 4 9 higher of kge respectively according to the nse values the model performance does not show obvious improvements with the increase of complexity of the parameter functions e g from linear to cubic and univariate to multivariate most of the groups of parameter cases generally show very close nse values the best performed parameter cases i e highest value of nse in each time variant parameter scenario are selected to compare with constant parameter cases for the two basins as shown in table 5 model with c 1 5 and constant sc in tongtianhe basin has the best performance among the four time variant parameter cases i e time variant c time variant sc combination of both and one step predicted c and sc from the enkf there is a 2 6 higher of nse and a 13 3 lower of trmse when compared to results of model with constant c and sc suggesting that model with c 1 5 has significant improvement in the estimation of low flows the differences of water balance between runoff observations and estimates obtained from model with c 1 5 and constant parameters are 1 underestimated total runoff volume and 6 overestimated total runoff volume respectively for ganjiang basin the best performed model in which parameter is c 2 7 and sc 2 7 has a 1 0 higher of nse a 5 2 lower of trmse and an 8 6 higher of kge suggesting that model with c 2 7 and sc 2 7 has improvements in both low and high flows although the nses of the two cases are very close the water balance results of the model with c 2 7 and sc 2 7 show a slight runoff overestimation with a relative error of 1 and those of model with constant parameters have an underestimation with a relative error of 1 fig 5 a and c are also presented using the flow duration curve to show the runoff performance in the above parameter cases generally results from the best performed model in each scenario for the two basins demonstrate that obvious improvements in the estimation of low or high flows are achieved during the calibration period when parameter c is considered to vary in time thus parameter c should be treated as time variant for both basins unlike the evapotranspiration parameter c the water storage capacity parameter sc usually has no apparent variations in a short term e g several months it tends to remain static unless severe changes occur in catchment conditions such as the land cover therefore considering time variant sc by using the empirical relationship between monthly parameters and catchment indicators has no significant improvements in tongtianhe basin which is barely affected by human activities owing to the limitation of the topographic condition and the water conservation measures implemented by the government deng et al 2016 the results from tongtianhe basin demonstrate that the sc value is not essentially necessary to be time variant and can be treated as a constant parameter for ganjiang basin parameter sc is considered to vary in time since the model with time variant sc improves runoff estimation in low and high flows as discussed in section 4 1 2 parameter sc has an increase trend during the calibration period and could be related to the catchment condition changes in ganjiang basin i e construction of reservoir and check dams thus sc should be time variant in ganjiang basin the results of both basins also show that the best performed parameter functions of c and sc are related to the antecedent monthly precipitation and potential evapotranspiration specifically the best performance is achieved when parameter c is represented as quadratic and linear functions of p6 and p1 in tongtianhe and ganjiang basins respectively and parameter sc is represented as linear function of pet1 in ganjiang basin based on the aforementioned results model with c 1 5 and constant sc c 2 7 and sc 2 7 are selected to assess the model s extrapolative ability based on the data from the period 2007 2010 in tongtianhe and ganjiang basins respectively table 6 presents the performance metrics of the model with constant parameters best performed parameter scenario and parameter forecasts from the enkf for the two basins during the validation period it shows that model with time variant c has a 1 5 lower of nse compared to that of the constant parameter scenario in tongtianhe basin fig 5 b but it still gives improvements in wbi trmse and kge the smaller nse for the model with time variant c is mainly caused by a larger over simulation in july 2009 see the point at the top of fig 6 a for the year 2009 the runoff observation in july was well out of the data range in the calibration period and the time variant parameter model may sometimes cause over simulation because the flexibility may introduce sensitivity if the observation is out of the data range in calibration in fact the constant parameter also over simulate the runoff value but the over simulation is smaller to see this we also calculate the nse without the use of july 2009 and the results are 0 766 for the time variant parameter model and 0 760 for the constant parameter model for ganjiang basin model with both time variant c and sc has an obvious improvement especially in low and high flows with a 10 6 lower of trmse and a 9 3 higher of kge fig 5 d model with one step forecasted parameters from the enkf has generally worse performances than results from model with constant parameters in both basins except it shows a 6 7 higher of kge in ganjiang basin the scatter plots for the runoff observations and the simulated runoff from models with constant and best performed time variant parameters are depicted in fig 6 for tongtianhe and ganjiang basins as shown in fig 6 a the monthly runoff in tongtianhe basin from the model with best performed time variant parameters solid points is closer to the 45 degree line than that of the constant parameter case hollow points in the lower tail of the scatter points while both the lower and upper tails of the solid points in fig 6 b are closer to the 45 degree line than the hollow points to give a clearer picture of the low flows the scatter of the logarithm of the runoff logq is presented in fig 6 c and d it is apparent that the solid points in both basins are closer to the 45 degree line than the hollow points and more obvious in the tongtianhe basin fig 7 presents comparisons of the observed and simulated monthly runoff from the models with constant parameters and best performed time variant parameters during the validation period for tongtianhe and ganjiang basins respectively it is shown that the runoff estimates obtained from the model with constructed parameter functions are better fitted for the observation of the monthly runoff in low and high flows for the two basins the results from the calibration and validation periods in tongtianhe basin show that model with time variant c has better performance than the model with constant parameters in low flows although it provides slightly higher and lower nses during the calibration and validation periods respectively for ganjiang basin all the streamflow characteristics including low medium and high flows achieve relatively significant improvements when both c and sc are treated as time variant parameters in summary considering time variant model parameters would be necessary and yield reasonable improvements in runoff estimation for catchments in which potential variations of parameter related catchment properties may occur for catchment like ganjiang basin hydrological model with time variant parameters which are assumed to be functions of identified catchment properties can provide more accurate and reliable predictions especially in the certain aspects of the hydrograph e g low and high flows 5 conclusions this study proposes and illustrates a framework for improving hydrological model performance under a changing environment the main purpose is to enhance the abilities of model s extrapolation and capturing extreme values of runoff estimates e g low and high flows by considering model parameter s to be time variant and building the corresponding parameter functions based on catchment indicators the framework includes four steps 1 estimating selected time variant parameter s by using a data assimilation technique such as the ensemble kalman filter enkf 2 analyzing correlations between estimated parameter s and catchment properties e g vegetation and climate related factors and selecting significant related catchment indicators as the covariates of the parameters functions 3 building time variant parameter functions based on the identified catchment properties and estimating function parameters through regression analysis 4 selecting and assessing model parameter functions by using hydrologically oriented metrics such as nash sutcliffe efficiency the framework is illustrated for two basins with different climate conditions in china using the two parameter monthly water balance model twbm for case study the two parameters of the twbm model i e evapotranspiration parameter c and water storage capacity sc are assumed to be time varying as functions of catchment properties i e ndvi antecedent monthly precipitation and potential evapotranspiration a calibration period from 1982 to 2006 is used for parameter function construction and selection and a validation period from 2007 to 2010 is used to assess the model performance when the best performed time variant functions are considered instead of the constant parameters the main conclusions are as follows different degrees of improvements are found in the shape of runoff hydrograph low and high flows during both the calibration and validation periods suggesting that the model with time variant parameter s is more suitable for representing the hydrological dynamics of the catchment the model with time variant c provides significant improvement in low flows in tongtianhe basin while the time variant sc shows no improvement in tongtianhe basin treating evapotranspiration parameter c to be time variant and water storage capacity sc to be constant is easier and more appropriate for monthly runoff simulation during the period of 1982 2010 for ganjiang basin improved model predictions are achieved when both the parameters c and sc are quantified as functions of catchment indicators which have significant correlations with the parameters briefly the selected functions of the time variant c and sc can be used for model prediction for ganjiang basin while time variant c function and constant sc are more suitable for tongtianhe basin as to the issue of the standard deviations stds of c and sc in the data assimilation process the setup of std would affect the actual values of model parameters but has no significant impacts on the runoff performance of the model with function formed parameters the proposed method provides an effective tool for improving model s representativeness to the hydrological processes which can then enhance the capability of models to produce reliable predictions in nonstationary hydrological modelling when this proposed framework is used to conduct runoff simulation for the future the selection of catchment properties and construction of functional forms may be required if the magnitude of climate changes and or land use changes in the future is more significant than that during the calibration period future research can be focused on investigating other factors which may cause the variations of model parameters such as the catchment soil conditions and human activities the enkf is applied to the estimation of the model parameters by considering its mean in this study in the next work improvement of the ensemble calibration may be achieved by using the enkf through the classical performance measures e g see details at https www atmos umd edu ekalnay syllabi aosc630 ensemble101 2014 pdf for accuracy reliability and discrimination acknowledgments this study was supported by the national science foundation of china 51809071 51779073 51579180 the national key research and development program 2016yfc0400907 the distinguished young fund project of jiangsu natural science foundation bk20180021 the fundamental research funds for the central universities 2018b55314 the open foundation of state key laboratory of water resources and hydropower engineering science in wuhan university 2015swg01 and the china postdoctoral science foundation 2017m621613 the authors thank the china meteorological data sharing service system for providing a part of the data used in this study we also thank the editor professor marco borga the associate editor professor yongqiang zhang and anonymous reviewers for their critical and constructive comments which highly improve the quality of the manuscript the data sets related to this study are available from the authors upon request liupan whu edu cn appendix a various cases of model parameter s std setup in enkf here we provide further details about the impact of different setups of standard deviation std of parameters c and sc in the data assimilation process on our conclusions various parameter std cases are set to explore its impacts on the construction functional forms of time variant parameters which will affect the model performance of runoff simulation a total of twenty five scenarios of parameter stds which is the combination of five different stds for each parameter table a1 have been implemented to estimate the time variant parameters for the first step of the proposed framework in section 2 2 based on the estimated parameter series catchment indicators correlated with model parameters are then selected as variables for the construction of time variant parameter functions finally performances of models with constructed time variant parameters are evaluated using hydrologically oriented metrics tables a2 and a3 present the estimated time variant parameter functions and the runoff performances for both calibration and validation periods under all the std scenarios for simplicity the best performed parameter cases i e highest value of nse for three kinds of parameter scenarios including time variant c time variant sc and their combination are selected to compare with constant parameter cases for each parameter std scenario it should be noted that there is no result for part of the std scenarios since the relationships between catchment indicators and estimated parameters does not satisfy the strong correlation requirement i e rs 0 6 fig a1 shows the runoff performance statistics for different parameter scenarios from models with function formed parameters under various parameter std setups the results in general are similar to those in section 4 3 suggesting that the std values would affect the actual parameter evolution but have no significant impacts on the performance of runoff simulation for the model with function formed parameters it means that the conclusions are not changed in particular improvements of runoff performance appear mainly in low flows when function formed c is applied for the tongtianhe basin while it would be more suitable for parameter sc keeping constant since no significant improvement fig a1 e is achieved when sc is treated as time variant for ganjiang basin runoff simulation improvements are achieved significantly in both low and high flows along with slightly higher nses fig a1 d and a1 f show that model with time variant c or time variant sc outperform model with constant parameters more specifically it has almost absolute better performance when both c and sc are treated as time variant green bar in fig a2 b thus treating model parameters as functions of identified catchment indicators can improve model performances for ganjiang basin 
6559,the objective of this paper was to evaluate a recently proposed comprehensive model for three dimensional single ring infiltration and its suitability for estimating soil hydraulic properties infiltration data from four different soils with contrasting characteristics were inverted to estimate field saturated soil hydraulic conductivity kfs values using a total of fourteen different scenarios those scenarios differed by i the way they constrained the macroscopic capillary length λ and the initial and saturated soil water contents θ i and θ s ii the use of transient or steady state data and iii the fitting methods applied to transient data for comparative purposes the ssbi method steady version of the simplified method based on a beerkan infiltration run was also applied for validation purposes kfs data estimated from the different scenarios were compared with those values obtained by numerical inverse modeling with hydrus 2d 3d this comparison identified approaches 1 and 3 which respectively estimate kfs via optimization and using analytical expressions as the most accurate methods the steady state scenario of approach 4 and the ssbi method both of which use a λ value of first approximation appeared preferable for field campaigns aimed to sample remote or large areas given that they do not need additional data and still provide acceptable estimates the reliability of kfs data was also checked through a comparison with unsaturated hydraulic conductivity kh values measured in laboratory on extracted soil cores in order to discriminate between theoretically possible kfs kh and impossible kfs kh situations physically possible kfs values were always obtained with the exception of the crusted soil where kfs kh situations suggested that the crust layer reduced water flow during ponding experiments in the field the new comprehensive model tested in this study represents a valuable tool for analyzing both transient and steady state infiltration data as well as experiments carried out with different depths of ponded water ring sizes and ring insertion depths keywords infiltration model single ring infiltrometer beerkan hydraulic conductivity 1 introduction knowledge of soil properties is essential for modeling hydrological processes among other properties the field saturated soil hydraulic conductivity kfs has an important role in the partitioning of rainfall into runoff and infiltration dusek et al 2012 different devices and techniques have been developed over time to measure kfs in the field such as the guelph permeameter the double and the single ring infiltrometers among others angulo jaramillo et al 2016 the guelph permeameter is a device that establishes three dimensional constant head infiltration within a small well excavated into the soil reynolds and elrick 1985 the double ring infiltrometer uses two concentric rings namely an inner ring and a buffering ring to create a one dimensional 1d infiltration process under the inner ring reynolds et al 2002 however some limitations may be encountered in the field when applying these methods when using the guelph permeameter the excavation of the well may cause soil compaction artificially decreasing the infiltration rates bagarello et al 1999 the water flow under the inner ring of the double ring infiltrometer rarely approaches a one dimensional infiltration process in practice reynolds et al 2002 moreover this latter method also requires a large amount of water to maintain ponding conditions inside the buffering ring thus limiting its application in remote areas the single ring infiltrometer technique reynolds and elrick 1990 is a widespread method e g braud et al 2017 which has the advantage of speed and simplicity over more cumbersome procedures such as the guelph permeameter and the double ring infiltrometer with a single ring infiltrometer a constant or falling head infiltration process has to be established different methods for calculating kfs from single ring data have been developed over time among them the one ponding depth method by reynolds and elrick 1990 and the similar method by wu et al 1999 both estimate kfs from steady state single ring infiltrometer data other approaches make use of transient infiltration data e g wu et al 1999 wu and pan 1997 to determine kfs these alternative approaches may alleviate the experimental efforts needed to determine kfs data in the field di prima et al 2018b for instance limiting the analysis to the transient phase may prove advantageous when characterizing low permeability soils by reducing the required measurement time bagarello et al 2014c a variation of the single ring infiltrometer technique is the beerkan experiment which consists of infiltrating water through a ring inserted shallowly e g 1 cm into the soil with a quasi zero head of water imposed on the soil surface braud et al 2005 many different methods have been used to interpret beerkan data as an example the beerkan estimation of soil transfer parameters best methods bagarello et al 2014b lassabatere et al 2006 yilmaz et al 2010 enable the user to derive the whole set of soil hydraulic parameters related to water retention and unsaturated hydraulic conductivity curves bagarello et al 2014c and bagarello et al 2017 proposed the tsbi and ssbi methods i e the transient and steady simplified methods based on a beerkan infiltration run which allow to estimate kfs by only using a beerkan experiment each method has its own advantages and peculiarities this makes it difficult or impossible to apply one of them to heterogeneous datasets such as the recently developed soil water infiltration global swig database rahmati et al 2018 recently stewart and abou najm 2018a developed a new comprehensive model for single ring infiltration data by combining the infiltration models by reynolds and elrick 1990 and wu et al 1999 these authors proposed four different approaches for estimating kfs values from both transient and steady state single ring infiltration data the four approaches differ in the way they constrain the macroscopic capillary length λ and the initial and saturated soil water contents θ i and θ s each approach requires different types of input parameters and exhibits different types and amounts of error the proposed model has a practical interest in that it treats both transient and steady state infiltration data and can analyze experiments carried out with different ring sizes and ring insertion depths however the model was previously validated using only laboratory and numerical experiments meaning that it has not yet been experimentally validated with field measurements the objective of this research was to test this new comprehensive model stewart and abou najm 2018a using data acquired for four soils with a range of physical and hydraulic properties the model estimated kfs using the four different approaches for constraining λ θ i and θ s along with several methods for determining infiltration constants for a total of thirteen scenarios the ssbi method developed by bagarello et al 2017 was also applied giving a fourteenth scenario the reliability of kfs estimates were verified first through a comparison with values obtained by numerical inverse modeling with hydrus 2d 3d and then via comparison with laboratory measurements of unsaturated hydraulic conductivity 2 theory 2 1 analysis of single ring infiltrometer data the model proposed by stewart and abou najm 2018a describes three dimensional 3d cumulative infiltration i l from a surface circular source under a positive pressure head using the following explicit relationships for transient and steady state conditions 1a i θ s θ i h source λ k f s b t a f k fs t t τ crit 1b i θ s θ i h source λ k fs 4 f b 1 a f k fs t t τ crit where t t is the time τ crit t is the maximum time for which the transient relationship can be considered valid θ s l3l 3 and θ i l3l 3 are respectively the saturated and initial volumetric soil water content hsource l is the established ponding depth of water λ l is the macroscopic capillary length of the soil kfs l t 1 is the field saturated soil hydraulic conductivity a and b are dimensionless constants respectively equal to 0 45 and 0 55 and f is a correction factor that depends on soil initial and boundary conditions and ring geometry reynolds and elrick 1990 2 f h source λ g 1 in which the g l term is equal to 3 g d r d 2 where rd l is the radius of the ring and d l is the ring insertion depth into the soil because τ crit is not known a priori the criterion suggested by bagarello et al 1999 can be considered to discriminate between transient and steady state conditions for cumulative infiltration data assuming the steady state conditions are reached before the end of an infiltration run a linear regression analysis is conducted for the last three data points of i t versus t the time to steady state ts l is determined as the first value for which 4 e i t i reg t i t 100 e where ireg t is estimated from regression analysis and e defines a given threshold to check linearity eq 4 is applied from the start of the experiment until finding the first data point that fits the condition e e angulo jaramillo et al 2016 an illustrative example of ts estimation using the commonly used value of e 2 is shown in fig 1 a transient infiltration conditions therefore occur from time 0 until time ts i e when e 2 fig 1a while steady state conditions exist for all data points measured after time ts i e when e 2 eq 1 can be simplified as follows philip 1957 5a i c 1 t c 2 t 5b i c 3 c 4 t where the intercept c 3 l and the slope c 4 l t 1 are estimated by linear regression analysis of the i t vs t plot while the infiltration coefficients c 1 l t 0 5 and c 2 l t 1 can be determined according to the fitting methods referred to as cumulative infiltration ci e g zhang 1997 cumulative linearization cl smiles and knight 1976 and differential linearization dl vandervaere et al 1997 in this investigation we considered all three fitting methods since each method has its own advantages and peculiarities vandervaere et al 2000a an example of the fitting procedures is depicted in fig 1b d 2 2 estimation of field saturated soil hydraulic conductivity values stewart and abou najm 2018b proposed four different approaches named approaches 1 2 3 and 4 for estimating kfs values from single ring infiltration data the differences between the four approaches involve the way in which λ θ i and θ s are constrained which must occur before estimating kfs in the following sections the four approaches are briefly explained 2 2 1 approach 1 the first approach estimates kfs by constraining all of the other considered parameters i e λ θ i and θ s and then fitting eq 1 to cumulative infiltration stewart and abou najm 2018b proposed to estimate λ from water retention data specifically according to these authors if the soil is relatively dry at the beginning of the infiltration experiment λ tends towards a maximum value λ max l defined as 6 λ max h b η 1 η where η and hb l are respectively the pore size index and the head scale parameter of the brooks and corey 1964 relations for water retention and hydraulic conductivity note that eq 6 can be considered valid for values of the initial matric head of the soil hi l ranging between and 2hb stewart and abou najm 2018a initial and saturated volumetric soil water contents θ i and θ s may be measured from soil samples collected before and after the infiltration run or otherwise estimated 2 2 2 approach 2 approach 2 only requires estimates for θ i and θ s for transient state data once the c 1 and c 2 coefficients are determined the field saturated soil hydraulic conductivity and the macroscopic capillary length are calculated by the following equations 7 k fs c 2 a b c 1 2 θ s θ i g 8 λ b c 1 2 k fs θ s θ i h source while for steady state data kfs and λ are calculated as 9 k fs c 4 g λ h source g 10 λ 4 c 3 b 1 a h source g h source θ s θ i g θ s θ i g 4 c 3 b 1 a 2 2 3 approach 3 this approach allows the estimation of the field saturated soil hydraulic conductivity using only λ estimated by eq 6 and c 2 or c 4 as determined from the infiltration run for transient state data once λ and c 2 are established then the field saturated soil hydraulic conductivity is calculated by the following equation 11 k fs c 2 a h source λ g 1 while for steady state data kfs is calculated as 12 k fs c 4 h source λ g 1 2 2 4 approach 4 approach 4 uses eqs 11 and 12 in conjunction with a λ value of first approximation following stewart and abou najm 2018b a value of λ 150 mm was selected for this investigation this approach does not require additional information to estimate kfs from infiltration runs therefore it is particularly useful when a large number of locations needs to be sampled particularly when time and financial resources are limited 2 2 5 ssbi method for comparative purposes the ssbi method steady state version of the simplified method based on a beerkan infiltration run proposed by bagarello et al 2017 was also applied to estimate kfs ssbi estimates kfs through a beerkan infiltration test i e a simple 3d infiltration run with a quasi zero water pressure head at the soil surface braud et al 2005 lassabatere et al 2006 by the following equation 13 k fs c 4 1 364 λ r d 1 note that eq 13 is analogous to eq 16 in bagarello et al 2017 with the latter considering the sorptive number α l 1 which is equal to λ 1 angulo jaramillo et al 2016 because eqs 12 and 13 are analogous to one another i e both require estimates for c 4 and λ to determine kfs the ssbi method was also applied assuming λ 150 mm 3 material and methods 3 1 soil sampling four soils with contrasting physical and hydraulic properties were evaluated in this study castellini et al 2018 according to the usda classification a sandy soil was sampled at arborea in sardinia and a silty loam soil was sampled at the experimental farm of crea aa in foggia apulia two sandy loam soils were sampled in sicily at the department of agriculture food and forest sciences of the palermo university sandy loam 1 and villabate sandy loam 2 for each site a total 10 undisturbed soil cores 50 mm in height and 50 mm in diameter were collected at randomly sampled points and used to determine both the soil bulk density ρ b g cm 3 and the initial volumetric soil water content θ i cm3 cm 3 the soil porosity was calculated from the ρ b data assuming a soil particle density of 2 65 g cm 3 the field saturated soil water content θ s cm3 cm 3 was considered equal to the porosity in line with other studies e g di prima et al 2018d mubarak et al 2009 disturbed soil samples were also collected to determine the particle size distribution the samples were air dried and sieved through a 2 mm mesh h2o2 pretreatment was used to eliminate organic matter and clay deflocculation was encouraged using sodium metaphosphate and mechanical agitation gee and bauder 1986 fine size fractions were determined by the hydrometer method whereas the coarse fractions were obtained by mechanical dry sieving the soil organic carbon content soc was determined by the walkley black method walkley and black 1934 then the soil organic matter content som was estimated using the van bemmelen conversion factor of 1 724 van bemmelen 1890 the measured soil physical properties are summarized in table 1 furthermore five to nine undisturbed soil cores 85 mm in diameter by 75 mm in height were also collected at each sampling site to conduct measurements of unsaturated hydraulic conductivity and evaporation tests in the laboratory 3 2 laboratory measurements of unsaturated hydraulic conductivity laboratory measurements of unsaturated hydraulic conductivity kh were collected to verify the reliability of kfs estimates we chose to use unsaturated as opposed to saturated conditions as a way to minimize uncertainty due to measurement artifacts such as entrapped air open ended pores and edge flow all these phenomena can result in considerable variations between field measured and laboratory derived estimates of hydraulic conductivity di prima et al 2018c sakaguchi et al 2005 stewart and abou najm 2018b obviously the above mentioned uncertainties are expected to be less noticeable or even negligible for unsaturated measurements in particular the comparison between kfs and kh data allowed us to discriminate between possible kfs kh and physically impossible kfs kh situations the unit hydraulic gradient method klute and dirksen 1986 was used to determine the unsaturated soil hydraulic conductivity kh mm h 1 on the 85 mm by 75 mm soil cores according to the procedure described by bagarello et al 2007 and castellini et al 2015 the upper layer of the soil 2 mm was carefully removed to allow the placement of a nylon guard cloth with an air entry value of 160 mm and a thin contact material layer spheriglass glass spheres no 2227 the nylon guard cloth was also placed at the bottom face of the sample to avoid soil displacement each sample was positioned on a sintered porous plate having an air entry value of 400 mm and then connected to an outflow tube that could be moved in height to establish a given pressure head value at the bottom of the core the sample was previously equilibrated for a 48 h time interval on the porous plate by repeatedly raising the outflow level at the first pressure head value 120 or 75 mm depending on the sample a negative pressure head at the top of the sample h 0 was imposed by the tension infiltrometer device which consisted of a porous disk 85 mm in diameter connected to the water supply reservoir measurements were performed by applying the same pressure head value at the two ends of the soil core infiltration evolved from an initial transient stage to a steady state stage in which a unit hydraulic gradient was obtained i e infiltration rates were constant and pressure head readings were equal throughout the soil core for this stage the steady state flux was equivalent to the unsaturated hydraulic conductivity corresponding to the imposed pressure head value bagarello et al 2007 for the sandy sandy loam 1 and sandy loam 2 samples the pressure head sequences applied was h 0 120 60 30 and 10 mm whereas for the silty loam samples the sequence was h 0 75 30 and 10 mm 3 3 laboratory evaporation experiments soil water retention measurements were carried out on the same undisturbed soil cores used to run the unit hydraulic gradient experiments these experiments allowed us to optimize the parameters of the brooks and corey 1964 relationship in this way an independent estimate of the macroscopic capillary length required for approaches 1 and 3 was determined by inputting the shape η and scale hb l parameters into eq 6 in this investigation we used the evaporation method proposed by wind 1969 for the computation of the water retention curve θ h through the simultaneous measurement of volumetric soil water contents and pressure heads at multiple depths during an evaporation process more details on the laboratory procedure can be found in castellini et al 2018 the fitting of the water retention data was performed using the program swrc fit developed by seki 2007 this program uses an iterative nonlinear regression procedure that finds the values of the optimized parameters by minimizing the sum of the squared residuals between the model and the observed data parameter values are reported in table 2 3 4 ponding infiltrometer runs for each site a total of ten ponded infiltration runs of the beerkan type braud et al 2005 lassabatere et al 2006 were carried out at different sampling points according to the existing literature the chosen sample size n 10 was expected to yield representative mean kfs values at the field scale reynolds et al 2000 verbist et al 2010 a ring with an inner diameter of 150 mm was used in the apulian foggia silty loam and sardinian arborea sandy sites and a ring with an inner diameter of 85 mm was used in both of the sicilian sites sandy loam 1 and 2 at the arborea site a larger ring diameter was chosen due to the presence of a weak but clearly detectable surface structural crust thickness of 2 mm due to the possibility that fractures along the ring edge may connect the ponded surface water with the underlying non crusted soil layer vandervaere et al 1997 beyond the large ring diameter the small insertion depth 10 mm used in this study should also help mitigate the formation of fractures through the crusted layer during ring insertion alagna et al 2019 souza et al 2014 as prescribed by the beerkan experimental procedure the ring was inserted to a depth of 10 mm in all sites for each run 15 water volumes each equal to 64 ml for the 85 mm diameters rings and 200 ml for the 150 mm diameter rings were successively poured on the confined soil surface the number of infiltrated volumes was sufficient to reach steady state as required by the beerkan method lassabatere et al 2006 the energy of the falling water was dissipated with fingers to minimize the soil disturbance owing to water pouring as commonly suggested e g alagna et al 2016 bagarello et al 2014a for each water volume the time needed for the water to infiltrate was recorded and the cumulative infiltration i mm was plotted against time t h 3 5 numerical simulation we chose to use the kfs hydrus values obtained by the inverse procedure in hydrus 2d 3d šimůnek et al 2008 as a benchmark as an independent kfs datum that can be used for assessing simplified procedures or validating new developed methods does not currently exist bagarello et al 2017 as discussed above laboratory measurements induce experimental artifacts that may limit their comparability with in situ measurements di prima et al 2018c discrepancies are also expected when different measurement techniques are applied in the field or even when the same dataset is analyzed by alternative calculation approaches mertens et al 2002 though in the latter case the results can still be compared to one another wu et al 1999 the inverse procedure using in hydrus 2d 3d combines the levenberg marquardt non linear parameter optimization method marquardt 1963 with a numerical solution of the axisymmetric form of richards equation angulo jaramillo et al 2000 šimůnek and hopmans 2002 similarly to the model configuration used by stewart and abou najm 2018b the soil columns were modeled as a 2d axisymmetric plane with a depth of 500 mm and a radius of 250 mm a pressure head boundary condition of 5 7 mm was imposed on the soil surface delimited by the ring while free drainage was set at the bottom of the modeled domain the values of θ r θ s η and hb obtained with the evaporation method were used as initial values to improve the fitting results note that the brooks and corey models were considered for the water retention and hydraulic conductivity functions in accordance with the four analytical approaches the water content parameters θ r and θ s were kept fixed and the tortuosity parameter l was set to 0 5 through a least squares inverse solution routine η hb and kfs hydrus values were optimized using the measured cumulative infiltration data table 3 summarizes the optimized parameters and an example for each soil of the inverse modeling is depicted in fig 2 for the four sampled soils kfs hydrus ranged from 28 2 to 839 9 mm h 1 the wide range of kfs hydrus values supported the choice to test the proposed model and the 14 different scenarios on these four hydraulically distinct soils 3 6 data analysis in this investigation we considered a total of 14 different scenarios to estimate kfs data more specifically the kfs values were estimated by approach 1 scenario i determining λ through eq 6 and θ i and θ s from sampled soil cores and then fitting eq 1 to cumulative infiltration approach 2 scenarios ii v determining λ θ i and θ s and introducing the three datasets of c 2 and c 1 values obtained with the ci cl and dl fitting methods into eqs 7 and 8 and the c 4 and c 3 values into eqs 9 and 10 approach 3 scenarios vi ix estimating λ through eq 6 and introducing the three datasets of c 2 estimates into eq 11 and the c 4 values into eq 12 approach 4 scenarios x xiii using λ 150 mm and introducing the three datasets of c 2 estimates into eq 11 and the c 4 values into eq 12 ssbi method scenario xiv using λ 150 mm and introducing the c 4 values into eq 13 with reference to approaches 1 and 3 λ values obtained from water retention data and estimated by eq 6 were averaged to obtain four site representative values a single value of θ i and θ s was also obtained for a given site by averaging individual determinations approach 1 and 2 the field saturated soil hydraulic conductivity kfs estimates were compared with the corresponding values obtained by inverse solution from hydrus 2d 3d i e the kfs hydrus values using the relative error er kfs defined as follows 14 e r k fs 100 k fs k fs h y d r u s k fs h y d r u s note that positive er kfs values indicate overestimations whereas negative values indicate underestimation small deviations i e er kfs 0 suggest that the estimates are close to actual values er kfs values between 50 and 100 represent a factor of difference fd 2 between estimated and actual values er kfs values between 66 7 and 200 represent fd 3 the factor of difference can be calculated as the ratio between the maximum and minimum of kfs and the corresponding kfs hydrus value i e fd max kfs kfs hydrus min kfs kfs hydrus following elrick and reynolds 1992 fd values not exceeding a value of two were considered indicative of similar estimates also note that all of the estimation and comparison procedures are synthetized in fig 2 for comparisons between paired observations the paired differences i e kfs kfs hydrus for given scenario were calculated and the hypothesis of normality of these differences was checked by the kolmogorov smirnov test for normally distributed data a paired t test was used to test the mean difference between paired observations at p 0 05 for non normally distributed data the wilcoxon signed rank test was used to test the median difference between paired observations at p 0 05 the adequacy of model fits was evaluated by checking the relative error er and the root mean squared differences rmsd defined as 15 er 100 i 1 n x i obs x i 2 i 1 n x i obs 2 16 rmsd i 1 n x i obs x i 2 n where n is the total number of data pairs x i obs are the observed data and x i are the values predicted by the models values of er 5 were assumed indicative of a satisfactory fitting ability of the models angulo jaramillo et al 2016 lassabatere et al 2006 4 results in the following subsections we present i the results of the analysis of single ring infiltration data and the performances of the different fitting methods section 4 1 ii the result of the comparison between kfs data estimated from different scenarios and those values obtained by numerical inverse modeling with hydrus 2d 3d section 4 2 and iii a check for data reliability by comparing kfs estimates with laboratory measurements of unsaturated hydraulic conductivity kh section 4 3 4 1 analysis of single ring infiltration data we firstly used eq 4 to determine the time to steady state ts with the condition e 2 fig 1a this threshold split the experimental data into two subsets that were then fitted to the transient t ts and steady state t ts models time to steady state ranged from 1 5 to 31 1 min depending on the run table 4 for the sandy soil ts was on average 19 1 min with an infiltrated depth i ts of 123 4 mm in comparison the sandy loam soils had mean ts values of 5 2 min sandy loam 1 and 2 2 min sandy loam 2 the sandy soil thus required a factor of 4 to 9 more time to reach steady state conditions compared to the sandy loam soils likely due to the presence of a crust layer which reduced infiltration rates alagna et al 2019 2013 and affected estimates for infiltration parameters di prima et al 2018a during data analysis peculiarities emerged within some of the infiltration datasets with three types of abnormal behaviors identified fig 4 in some runs the early infiltration rates were particularly high in comparison with the rest of the run fig 4a causing a large initial jump in cumulative infiltration fig 4b white circles this circumstance is quite common in coarse or initially dry soils di prima et al 2016 in this case the first data point of the i t vs t plot cl method deviated from the general linear behavior fig 4c white circles this problem can be easily solved by excluding the first data point from the cumulative infiltration fig 4b allowing the detection of a linear relationship fig 4c grey circles and a proper estimation of the c 1 and c 2 coefficients such an adjustment was made on 14 infiltration runs i e 35 of the cases other investigations also suggested removing the early stage of the infiltration process when a perturbation occurs e g bagarello et al 2014c di prima et al 2018b vandervaere et al 2000b one infiltration experiment from the sandy soil showed a sudden decrease in infiltration rate fig 4d this condition was not easily detectable from the visual inspection of the cumulative infiltration curve fig 4e but appeared when the data were linearized fig 4f the lack of linear data meant that eq 5a was inappropriate and that the fitted parameters were physically meaningless vandervaere et al 2000a for this reason the sample was excluded from subsequent analyses possible contributing factors include water infiltrating into a less permeable layer alagna et al 2016 lassabatere et al 2019 air entrapment vertical soil water content gradients and soil sealing at the surface from repeated water applications bagarello et al 2014c di prima et al 2018a other experiments had infiltration rates that increased with time fig 4g such that the cumulative infiltration curves exhibited convex shapes fig 4h the fitting procedures applied to these data produced negative values for the c 1 infiltration coefficient fig 4i these cases occurred at the sandy loam 1 site one instance and sandy loam 2 site three instances and reflect that the early wetting phase was impeded due to hydrophobic surface films on soil particles and non zero contact angles between water and soil particles hallett et al 2001 jarvis et al 2008 hydrophobia may be attributed to locally high oc content goebel et al 2011 and exudates produced by the plant root systems or living organisms like arbuscular mycorrhizal fungi rillig et al 2010 this effect is known to diminish during the wetting process alagna et al 2018 it should be noted that despite the water repellency relatively high early infiltration rates were still measured this result indicates that the soils likely had subcritical water repellency e g di prima et al 2017a lassabatere et al 2019 lichner et al 2007 lozano baez et al 2018 three different sets of c 1 and c 2 values were obtained for transient state data using the ci cl and dl methods overall the c 1 and c 2 coefficients were properly estimated in 93 of the cases 37 of 40 runs for the ci and cl methods and 95 38 of 40 for the dl method the c 1 coefficient ranged between 0 4 and 514 3 mm h 0 5 and the c 2 coefficient between 95 8 and 4424 2 mm h 1 table 5 differences between methods were more pronounced for c 1 compared to c 2 values with the latter only presenting statistically different estimates between the three procedures for the silty loam soil fig 5 mean c 1 values were ordered as dl ci cl good fits i e er 5 were obtained for all cases except the dl method on the sandy loam 2 site mean er 7 6 finally the analysis of steady state data i e the data points for which e 2 eq 4 did not show any such peculiarities thus the intercept c 3 and the slope c 4 of the regression line fitted to the data points describing steady state conditions could be properly estimated in all cases table 5 4 2 validation with hydrus predicted data the inverse option in hydrus 2d 3d was used to optimize the η hb and kfs hydrus parameters on the measured cumulative infiltration data the field saturated soil hydraulic conductivity kfs estimates obtained from the 14 different scenarios were compared with the corresponding values obtained from hydrus i e the kfs hydrus values for approach 1 site representative values of λ table 6 θ i and θ s were considered and kfs was optimized fitting eq 1 to cumulative infiltrations the λ values were obtained by averaging for each soil the individual determination obtained from eq 6 and considering the η and hb parameters optimized on the retention data obtained by the evaporation experiments the kfs values ranged between 29 2 and 429 1 mm h 1 table 7 with 45 and 55 of the runs yielding respectively lower and higher kfs estimates than the hydrus estimated values fig 6 the differences between kfs and kfs hydrus were non normally distributed according to the kolmogorov smirnov test the wilcoxon signed rank test showed that approach 1 yielded kfs estimates not significantly different from the kfs hydrus values figs 7 and 8 the relative error er kfs ranged from 66 5 to 347 3 with mean and median factor of difference fd values equal to 1 45 and 1 22 individual values fd were less than two in 85 0 and less than three in 97 5 of the cases with only one case out of 40 yielding fd 3 fig 9 therefore kfs estimates were acceptable in almost all cases when eq 1 was directly fitted to experimental data for approach 2 four sets of kfs and λ values were determined three sets for transient infiltration data by eqs 12 and 13 one set for each fitting procedure i e ci cl and dl and one set for steady state data by eqs 14 and 15 the three transient scenarios yielded significant higher kfs estimates than the kfs hydrus values figs 7 and 8 with mean fd values equal to 12 23 ci 16 05 cl and 9 30 dl and individual fd values higher than three in 80 0 92 5 and 72 5 of the cases fig 9 the steady state scenario gave negative λ values and consequentially negative kfs in 75 of the cases i e 30 out of 40 overall approach 2 either poorly predicted λ and kfs data or failed to give valid estimates at all the results obtained here can be viewed as a confirmation of the conclusion by stewart and abou najm 2018b for approach 3 site representative values of λ were calculated based on water retention characteristics table 6 and four sets of kfs values were determined three sets for transient infiltration data using eq 11 and one set for steady state data using eq 12 for these scenarios kfs ranged between 23 2 and 687 4 mm h 1 table 7 with the transient scenarios yielding slightly but significantly higher kfs estimates than hydrus and with the steady state scenarios yielding slightly but significantly lower estimates than hydrus figs 7 and 8 for the four scenarios fd values were less than two in at least 75 0 of the transient scenarios and in 95 0 of the steady state cases fig 9 with mean fd values ranging from 1 51 to 1 86 and median fd values from 1 37 to 1 59 given that kfs estimates were acceptable in all cases we considered a new scenario figs 6 9 by averaging for a given run the four kfs estimates this newly conceived scenario yielded lower mean and median fd values respectively equal to 1 46 and 1 24 for approach 4 a λ value of 150 mm was used to determine four sets of kfs values similar to approach 3 for the transient scenarios using a λ value of 150 mm resulted in higher kfs values than were predicted by hydrus figs 7 and 8 for these three scenarios fd values were higher than two in 67 5 82 5 of the cases and higher than three in 30 0 55 0 of the cases fig 9 mean fd values ranged from 2 71 to 3 52 and median fd values varied from 2 59 to 3 27 better kfs predictions were obtained by the steady state scenario with er kfs values ranging from 38 6 to 460 4 this scenario yielded slightly but significant higher kfs estimates than the actual values figs 7 and 8 with mean and median fd values equal to 1 57 and 1 49 individual fd values were respectively less than two and three in 95 0 and 97 5 of the cases and with only one case out of 40 yielding fd 3 fig 9 with the ssbi method the er kfs values ranged from 36 8 to 476 6 with mean and median fd values equal to 1 63 and 1 54 individual values fd were less than two in 90 0 and less than three in 95 0 of the cases with only two cases out of 40 yielding fd 3 fig 9 4 3 unsaturated vs field saturated soil hydraulic conductivity a further check for data reliability was carried out by comparing kfs estimates with laboratory measurements of unsaturated hydraulic conductivity kh table 8 summarizes the kh values measured by the unit hydraulic gradient laboratory method for the four soils as expected kh increased dramatically in the proximity of the saturation i e for lower h 0 values fig 10 the mean values of the unsaturated soil hydraulic conductivity obtained at the pressure head h 0 10 mm k 10 ranged between 21 0 and 154 7 mm h 1 with higher k 10 values measured on the sandy soil cores firstly it should be noted that for the sandy soil this comparison needs specific consideration owing to crusting phenomena at the soil surface in particular the soil core collection process disturbed the crust layer such that fractures on the soil surface were observed in all soil cores therefore the upper layer of the soil was carefully removed in the laboratory and the measurements of unsaturated hydraulic conductivity were conducted on the underlying non crusted soil layer on the contrary in the field we maintained the crust layer during the ponding experiments in order to give an insight on the potential of the applied model when a layered medium is characterized as mentioned above the small insertion depth i e 10 mm of the ring used to run the beerkan experiments avoided the formation of fractures in the crust layer ensuring that the measured infiltration rates were indicative of the crust layer as a consequence 9 of 14 scenarios for this soil produced mean values of kfs lower than k 10 proving that the soil crust layer reduced water flow during ponding experiments in the field for the silty loam sandy loam 1 and sandy loam 2 soils kfs determined from the 14 different scenarios always remained higher than the measured kh values therefore physically possible kfs estimates were obtained in all cases given that kfs k 10 for these soils the 14 scenarios yielded mean kfs values that were 1 7 68 6 times higher than the corresponding k 10 i e up to two orders of magnitude differences of this order of magnitude or even higher between saturated and near saturated hydraulic conductivity have been often observed under field conditions e g buczko et al 2003 castellini et al 2015 di prima et al 2017a dunn and phillips 1991 watson and luxmoore 1986 5 discussion the analysis of the cumulative infiltration measurements identified some runs with peculiarities such as very high initial infiltration rates undetectable linear relationships in the cl and dl methods and negative values of the infiltration coefficients still infiltration data could be analyzed to determine the constants c 1 and c 2 for 93 of the runs using the cumulative infiltration ci and cumulative linearization cl methods and for 95 of the runs using the differential linearization dl method the infiltration constants were next applied to estimate kfs using the comprehensive single ring infiltration model of stewart and abou najm 2018a here we considered four approaches and thirteen scenarios that differed in how λ was constrained while also comparing kfs estimates using the sbbi method approaches 1 and 3 were the most data demanding requiring that λ was estimated from water retention data and that soil samples were collected before the infiltration runs to determine initial and saturated volumetric soil water contents θ i and θ s yet our analysis of the field data showed that those approaches provided the most accurate kfs estimates compared to values obtained through numerical inverse modeling with hydrus 2d 3d approach 1 was the most accurate overall likely because it did not require any transformation of the infiltration data this approach is therefore recommended for situations when λ θ i and θ s are well constrained still by averaging together the four kfs estimates obtained by approach 3 for a given run i e considering together the scenarios vi ix in fig 3 the measurement uncertainty of that approach was reduced to a level comparable to approach 1 these averaged kfs values avoided uncertainties that might exist within each of the specific fitting procedures ci cl and dl while also overcoming any failed analyses e g negative estimates for kfs as a result this newly considered scenario increased the accuracy of kfs estimates and as a result we recommend users apply a similar averaging scheme when using approach 3 the kfs estimates were less accurate but still acceptable for the steady state scenarios of approach 4 and the ssbi method the steady state data likely provided better accuracy than the transient data because the steady phase of the infiltration process avoids uncertainties due to variations in infiltration rates caused by for instance soil sealing di prima et al 2018a or water repellency lichner et al 2013 with both of these methods no additional data are required to determine kfs making these procedures desirable when surveying remote or large areas bagarello et al 2013 one difference between the two is that the ssbi method is theoretically usable for a ponded depth of water on the infiltration surface hsource equal to zero and a null depth of ring insertion into the soil d bagarello et al 2017 whereas both zero and positive values of both hsource and d can be considered with approach 4 here both methods were used to analyze infiltration runs that had a quasi zero head of water imposed on the soil surface beerkan runs so the models performed similarly to one another the predictive potential of the model was also checked via comparison with laboratory measurements of unsaturated hydraulic conductivity kh for the silty loam sandy loam 1 and sandy loam 2 soils kfs estimates from the 14 different scenarios were always higher than the unsaturated soil hydraulic conductivity therefore physically plausible kfs values were obtained in all cases for the crusted sandy soil kfs kh situations suggested that the surface crust layer reduced water flow during ponding experiments in the field in the future measuring kh values directly in the field using a tension infiltrometer casey and derby 2002 or the portable mini disk device decagon 2014 may help to properly characterize unsaturated flow in crusted soils indeed field measurements are known to minimize soil disturbance in comparison with laboratory methods performed on collected soil samples haverkamp et al 1999 moreover tension infiltrometers were successfully used in many investigations to characterize layered soils in the field e g alagna et al 2013 di prima et al 2017b šimůnek et al 1998 vandervaere et al 1997 altogether the new comprehensive model and the underlying approaches to analyze single ring data may allow researchers to better approach heterogeneous datasets including transient or steady state infiltration data and experiments carried out with different setups the versatility of the new model makes it a good candidate to successfully analyze the swig database developed by rahmati et al 2018 which include 5023 infiltration curves collected across the world 6 summary and conclusions in this study we tested a new comprehensive model for single ring data on four soils with different textures i e sandy silty loam and sandy loam the field saturated soil hydraulic conductivity kfs values were estimated by four different approaches which differ by the way they derive kfs and constrain λ θ i and θ s for comparative purposes the ssbi method was also applied to estimate kfs in this investigation we considered a total of 14 different scenarios to estimate kfs data that differed in the considered approach i e approaches 1 4 or ssbi in the use of transient or steady state data and in the fitting methods applied to transient data ci cl and dl the kfs data estimated from different scenarios were compared for validation purposes with those values obtained by numerical inverse modeling with hydrus 2d 3d among the different scenarios approaches 1 and 3 appear as the more promising yielding better kfs predictions conversely the steady state scenario of approach 4 and the ssbi method are preferable when a simplified experimental procedure is required such as when sampling remote or large areas given that these interpretations do not require additional data and still provide acceptable estimates of kfs declaration of interests none acknowledgements this work was supported through the infiltron project anr 17 ce04 0010 funded by the french national research agency anr s di prima outlined the investigation and analyzed the data all authors contributed to discussing the results and writing the manuscript 
6559,the objective of this paper was to evaluate a recently proposed comprehensive model for three dimensional single ring infiltration and its suitability for estimating soil hydraulic properties infiltration data from four different soils with contrasting characteristics were inverted to estimate field saturated soil hydraulic conductivity kfs values using a total of fourteen different scenarios those scenarios differed by i the way they constrained the macroscopic capillary length λ and the initial and saturated soil water contents θ i and θ s ii the use of transient or steady state data and iii the fitting methods applied to transient data for comparative purposes the ssbi method steady version of the simplified method based on a beerkan infiltration run was also applied for validation purposes kfs data estimated from the different scenarios were compared with those values obtained by numerical inverse modeling with hydrus 2d 3d this comparison identified approaches 1 and 3 which respectively estimate kfs via optimization and using analytical expressions as the most accurate methods the steady state scenario of approach 4 and the ssbi method both of which use a λ value of first approximation appeared preferable for field campaigns aimed to sample remote or large areas given that they do not need additional data and still provide acceptable estimates the reliability of kfs data was also checked through a comparison with unsaturated hydraulic conductivity kh values measured in laboratory on extracted soil cores in order to discriminate between theoretically possible kfs kh and impossible kfs kh situations physically possible kfs values were always obtained with the exception of the crusted soil where kfs kh situations suggested that the crust layer reduced water flow during ponding experiments in the field the new comprehensive model tested in this study represents a valuable tool for analyzing both transient and steady state infiltration data as well as experiments carried out with different depths of ponded water ring sizes and ring insertion depths keywords infiltration model single ring infiltrometer beerkan hydraulic conductivity 1 introduction knowledge of soil properties is essential for modeling hydrological processes among other properties the field saturated soil hydraulic conductivity kfs has an important role in the partitioning of rainfall into runoff and infiltration dusek et al 2012 different devices and techniques have been developed over time to measure kfs in the field such as the guelph permeameter the double and the single ring infiltrometers among others angulo jaramillo et al 2016 the guelph permeameter is a device that establishes three dimensional constant head infiltration within a small well excavated into the soil reynolds and elrick 1985 the double ring infiltrometer uses two concentric rings namely an inner ring and a buffering ring to create a one dimensional 1d infiltration process under the inner ring reynolds et al 2002 however some limitations may be encountered in the field when applying these methods when using the guelph permeameter the excavation of the well may cause soil compaction artificially decreasing the infiltration rates bagarello et al 1999 the water flow under the inner ring of the double ring infiltrometer rarely approaches a one dimensional infiltration process in practice reynolds et al 2002 moreover this latter method also requires a large amount of water to maintain ponding conditions inside the buffering ring thus limiting its application in remote areas the single ring infiltrometer technique reynolds and elrick 1990 is a widespread method e g braud et al 2017 which has the advantage of speed and simplicity over more cumbersome procedures such as the guelph permeameter and the double ring infiltrometer with a single ring infiltrometer a constant or falling head infiltration process has to be established different methods for calculating kfs from single ring data have been developed over time among them the one ponding depth method by reynolds and elrick 1990 and the similar method by wu et al 1999 both estimate kfs from steady state single ring infiltrometer data other approaches make use of transient infiltration data e g wu et al 1999 wu and pan 1997 to determine kfs these alternative approaches may alleviate the experimental efforts needed to determine kfs data in the field di prima et al 2018b for instance limiting the analysis to the transient phase may prove advantageous when characterizing low permeability soils by reducing the required measurement time bagarello et al 2014c a variation of the single ring infiltrometer technique is the beerkan experiment which consists of infiltrating water through a ring inserted shallowly e g 1 cm into the soil with a quasi zero head of water imposed on the soil surface braud et al 2005 many different methods have been used to interpret beerkan data as an example the beerkan estimation of soil transfer parameters best methods bagarello et al 2014b lassabatere et al 2006 yilmaz et al 2010 enable the user to derive the whole set of soil hydraulic parameters related to water retention and unsaturated hydraulic conductivity curves bagarello et al 2014c and bagarello et al 2017 proposed the tsbi and ssbi methods i e the transient and steady simplified methods based on a beerkan infiltration run which allow to estimate kfs by only using a beerkan experiment each method has its own advantages and peculiarities this makes it difficult or impossible to apply one of them to heterogeneous datasets such as the recently developed soil water infiltration global swig database rahmati et al 2018 recently stewart and abou najm 2018a developed a new comprehensive model for single ring infiltration data by combining the infiltration models by reynolds and elrick 1990 and wu et al 1999 these authors proposed four different approaches for estimating kfs values from both transient and steady state single ring infiltration data the four approaches differ in the way they constrain the macroscopic capillary length λ and the initial and saturated soil water contents θ i and θ s each approach requires different types of input parameters and exhibits different types and amounts of error the proposed model has a practical interest in that it treats both transient and steady state infiltration data and can analyze experiments carried out with different ring sizes and ring insertion depths however the model was previously validated using only laboratory and numerical experiments meaning that it has not yet been experimentally validated with field measurements the objective of this research was to test this new comprehensive model stewart and abou najm 2018a using data acquired for four soils with a range of physical and hydraulic properties the model estimated kfs using the four different approaches for constraining λ θ i and θ s along with several methods for determining infiltration constants for a total of thirteen scenarios the ssbi method developed by bagarello et al 2017 was also applied giving a fourteenth scenario the reliability of kfs estimates were verified first through a comparison with values obtained by numerical inverse modeling with hydrus 2d 3d and then via comparison with laboratory measurements of unsaturated hydraulic conductivity 2 theory 2 1 analysis of single ring infiltrometer data the model proposed by stewart and abou najm 2018a describes three dimensional 3d cumulative infiltration i l from a surface circular source under a positive pressure head using the following explicit relationships for transient and steady state conditions 1a i θ s θ i h source λ k f s b t a f k fs t t τ crit 1b i θ s θ i h source λ k fs 4 f b 1 a f k fs t t τ crit where t t is the time τ crit t is the maximum time for which the transient relationship can be considered valid θ s l3l 3 and θ i l3l 3 are respectively the saturated and initial volumetric soil water content hsource l is the established ponding depth of water λ l is the macroscopic capillary length of the soil kfs l t 1 is the field saturated soil hydraulic conductivity a and b are dimensionless constants respectively equal to 0 45 and 0 55 and f is a correction factor that depends on soil initial and boundary conditions and ring geometry reynolds and elrick 1990 2 f h source λ g 1 in which the g l term is equal to 3 g d r d 2 where rd l is the radius of the ring and d l is the ring insertion depth into the soil because τ crit is not known a priori the criterion suggested by bagarello et al 1999 can be considered to discriminate between transient and steady state conditions for cumulative infiltration data assuming the steady state conditions are reached before the end of an infiltration run a linear regression analysis is conducted for the last three data points of i t versus t the time to steady state ts l is determined as the first value for which 4 e i t i reg t i t 100 e where ireg t is estimated from regression analysis and e defines a given threshold to check linearity eq 4 is applied from the start of the experiment until finding the first data point that fits the condition e e angulo jaramillo et al 2016 an illustrative example of ts estimation using the commonly used value of e 2 is shown in fig 1 a transient infiltration conditions therefore occur from time 0 until time ts i e when e 2 fig 1a while steady state conditions exist for all data points measured after time ts i e when e 2 eq 1 can be simplified as follows philip 1957 5a i c 1 t c 2 t 5b i c 3 c 4 t where the intercept c 3 l and the slope c 4 l t 1 are estimated by linear regression analysis of the i t vs t plot while the infiltration coefficients c 1 l t 0 5 and c 2 l t 1 can be determined according to the fitting methods referred to as cumulative infiltration ci e g zhang 1997 cumulative linearization cl smiles and knight 1976 and differential linearization dl vandervaere et al 1997 in this investigation we considered all three fitting methods since each method has its own advantages and peculiarities vandervaere et al 2000a an example of the fitting procedures is depicted in fig 1b d 2 2 estimation of field saturated soil hydraulic conductivity values stewart and abou najm 2018b proposed four different approaches named approaches 1 2 3 and 4 for estimating kfs values from single ring infiltration data the differences between the four approaches involve the way in which λ θ i and θ s are constrained which must occur before estimating kfs in the following sections the four approaches are briefly explained 2 2 1 approach 1 the first approach estimates kfs by constraining all of the other considered parameters i e λ θ i and θ s and then fitting eq 1 to cumulative infiltration stewart and abou najm 2018b proposed to estimate λ from water retention data specifically according to these authors if the soil is relatively dry at the beginning of the infiltration experiment λ tends towards a maximum value λ max l defined as 6 λ max h b η 1 η where η and hb l are respectively the pore size index and the head scale parameter of the brooks and corey 1964 relations for water retention and hydraulic conductivity note that eq 6 can be considered valid for values of the initial matric head of the soil hi l ranging between and 2hb stewart and abou najm 2018a initial and saturated volumetric soil water contents θ i and θ s may be measured from soil samples collected before and after the infiltration run or otherwise estimated 2 2 2 approach 2 approach 2 only requires estimates for θ i and θ s for transient state data once the c 1 and c 2 coefficients are determined the field saturated soil hydraulic conductivity and the macroscopic capillary length are calculated by the following equations 7 k fs c 2 a b c 1 2 θ s θ i g 8 λ b c 1 2 k fs θ s θ i h source while for steady state data kfs and λ are calculated as 9 k fs c 4 g λ h source g 10 λ 4 c 3 b 1 a h source g h source θ s θ i g θ s θ i g 4 c 3 b 1 a 2 2 3 approach 3 this approach allows the estimation of the field saturated soil hydraulic conductivity using only λ estimated by eq 6 and c 2 or c 4 as determined from the infiltration run for transient state data once λ and c 2 are established then the field saturated soil hydraulic conductivity is calculated by the following equation 11 k fs c 2 a h source λ g 1 while for steady state data kfs is calculated as 12 k fs c 4 h source λ g 1 2 2 4 approach 4 approach 4 uses eqs 11 and 12 in conjunction with a λ value of first approximation following stewart and abou najm 2018b a value of λ 150 mm was selected for this investigation this approach does not require additional information to estimate kfs from infiltration runs therefore it is particularly useful when a large number of locations needs to be sampled particularly when time and financial resources are limited 2 2 5 ssbi method for comparative purposes the ssbi method steady state version of the simplified method based on a beerkan infiltration run proposed by bagarello et al 2017 was also applied to estimate kfs ssbi estimates kfs through a beerkan infiltration test i e a simple 3d infiltration run with a quasi zero water pressure head at the soil surface braud et al 2005 lassabatere et al 2006 by the following equation 13 k fs c 4 1 364 λ r d 1 note that eq 13 is analogous to eq 16 in bagarello et al 2017 with the latter considering the sorptive number α l 1 which is equal to λ 1 angulo jaramillo et al 2016 because eqs 12 and 13 are analogous to one another i e both require estimates for c 4 and λ to determine kfs the ssbi method was also applied assuming λ 150 mm 3 material and methods 3 1 soil sampling four soils with contrasting physical and hydraulic properties were evaluated in this study castellini et al 2018 according to the usda classification a sandy soil was sampled at arborea in sardinia and a silty loam soil was sampled at the experimental farm of crea aa in foggia apulia two sandy loam soils were sampled in sicily at the department of agriculture food and forest sciences of the palermo university sandy loam 1 and villabate sandy loam 2 for each site a total 10 undisturbed soil cores 50 mm in height and 50 mm in diameter were collected at randomly sampled points and used to determine both the soil bulk density ρ b g cm 3 and the initial volumetric soil water content θ i cm3 cm 3 the soil porosity was calculated from the ρ b data assuming a soil particle density of 2 65 g cm 3 the field saturated soil water content θ s cm3 cm 3 was considered equal to the porosity in line with other studies e g di prima et al 2018d mubarak et al 2009 disturbed soil samples were also collected to determine the particle size distribution the samples were air dried and sieved through a 2 mm mesh h2o2 pretreatment was used to eliminate organic matter and clay deflocculation was encouraged using sodium metaphosphate and mechanical agitation gee and bauder 1986 fine size fractions were determined by the hydrometer method whereas the coarse fractions were obtained by mechanical dry sieving the soil organic carbon content soc was determined by the walkley black method walkley and black 1934 then the soil organic matter content som was estimated using the van bemmelen conversion factor of 1 724 van bemmelen 1890 the measured soil physical properties are summarized in table 1 furthermore five to nine undisturbed soil cores 85 mm in diameter by 75 mm in height were also collected at each sampling site to conduct measurements of unsaturated hydraulic conductivity and evaporation tests in the laboratory 3 2 laboratory measurements of unsaturated hydraulic conductivity laboratory measurements of unsaturated hydraulic conductivity kh were collected to verify the reliability of kfs estimates we chose to use unsaturated as opposed to saturated conditions as a way to minimize uncertainty due to measurement artifacts such as entrapped air open ended pores and edge flow all these phenomena can result in considerable variations between field measured and laboratory derived estimates of hydraulic conductivity di prima et al 2018c sakaguchi et al 2005 stewart and abou najm 2018b obviously the above mentioned uncertainties are expected to be less noticeable or even negligible for unsaturated measurements in particular the comparison between kfs and kh data allowed us to discriminate between possible kfs kh and physically impossible kfs kh situations the unit hydraulic gradient method klute and dirksen 1986 was used to determine the unsaturated soil hydraulic conductivity kh mm h 1 on the 85 mm by 75 mm soil cores according to the procedure described by bagarello et al 2007 and castellini et al 2015 the upper layer of the soil 2 mm was carefully removed to allow the placement of a nylon guard cloth with an air entry value of 160 mm and a thin contact material layer spheriglass glass spheres no 2227 the nylon guard cloth was also placed at the bottom face of the sample to avoid soil displacement each sample was positioned on a sintered porous plate having an air entry value of 400 mm and then connected to an outflow tube that could be moved in height to establish a given pressure head value at the bottom of the core the sample was previously equilibrated for a 48 h time interval on the porous plate by repeatedly raising the outflow level at the first pressure head value 120 or 75 mm depending on the sample a negative pressure head at the top of the sample h 0 was imposed by the tension infiltrometer device which consisted of a porous disk 85 mm in diameter connected to the water supply reservoir measurements were performed by applying the same pressure head value at the two ends of the soil core infiltration evolved from an initial transient stage to a steady state stage in which a unit hydraulic gradient was obtained i e infiltration rates were constant and pressure head readings were equal throughout the soil core for this stage the steady state flux was equivalent to the unsaturated hydraulic conductivity corresponding to the imposed pressure head value bagarello et al 2007 for the sandy sandy loam 1 and sandy loam 2 samples the pressure head sequences applied was h 0 120 60 30 and 10 mm whereas for the silty loam samples the sequence was h 0 75 30 and 10 mm 3 3 laboratory evaporation experiments soil water retention measurements were carried out on the same undisturbed soil cores used to run the unit hydraulic gradient experiments these experiments allowed us to optimize the parameters of the brooks and corey 1964 relationship in this way an independent estimate of the macroscopic capillary length required for approaches 1 and 3 was determined by inputting the shape η and scale hb l parameters into eq 6 in this investigation we used the evaporation method proposed by wind 1969 for the computation of the water retention curve θ h through the simultaneous measurement of volumetric soil water contents and pressure heads at multiple depths during an evaporation process more details on the laboratory procedure can be found in castellini et al 2018 the fitting of the water retention data was performed using the program swrc fit developed by seki 2007 this program uses an iterative nonlinear regression procedure that finds the values of the optimized parameters by minimizing the sum of the squared residuals between the model and the observed data parameter values are reported in table 2 3 4 ponding infiltrometer runs for each site a total of ten ponded infiltration runs of the beerkan type braud et al 2005 lassabatere et al 2006 were carried out at different sampling points according to the existing literature the chosen sample size n 10 was expected to yield representative mean kfs values at the field scale reynolds et al 2000 verbist et al 2010 a ring with an inner diameter of 150 mm was used in the apulian foggia silty loam and sardinian arborea sandy sites and a ring with an inner diameter of 85 mm was used in both of the sicilian sites sandy loam 1 and 2 at the arborea site a larger ring diameter was chosen due to the presence of a weak but clearly detectable surface structural crust thickness of 2 mm due to the possibility that fractures along the ring edge may connect the ponded surface water with the underlying non crusted soil layer vandervaere et al 1997 beyond the large ring diameter the small insertion depth 10 mm used in this study should also help mitigate the formation of fractures through the crusted layer during ring insertion alagna et al 2019 souza et al 2014 as prescribed by the beerkan experimental procedure the ring was inserted to a depth of 10 mm in all sites for each run 15 water volumes each equal to 64 ml for the 85 mm diameters rings and 200 ml for the 150 mm diameter rings were successively poured on the confined soil surface the number of infiltrated volumes was sufficient to reach steady state as required by the beerkan method lassabatere et al 2006 the energy of the falling water was dissipated with fingers to minimize the soil disturbance owing to water pouring as commonly suggested e g alagna et al 2016 bagarello et al 2014a for each water volume the time needed for the water to infiltrate was recorded and the cumulative infiltration i mm was plotted against time t h 3 5 numerical simulation we chose to use the kfs hydrus values obtained by the inverse procedure in hydrus 2d 3d šimůnek et al 2008 as a benchmark as an independent kfs datum that can be used for assessing simplified procedures or validating new developed methods does not currently exist bagarello et al 2017 as discussed above laboratory measurements induce experimental artifacts that may limit their comparability with in situ measurements di prima et al 2018c discrepancies are also expected when different measurement techniques are applied in the field or even when the same dataset is analyzed by alternative calculation approaches mertens et al 2002 though in the latter case the results can still be compared to one another wu et al 1999 the inverse procedure using in hydrus 2d 3d combines the levenberg marquardt non linear parameter optimization method marquardt 1963 with a numerical solution of the axisymmetric form of richards equation angulo jaramillo et al 2000 šimůnek and hopmans 2002 similarly to the model configuration used by stewart and abou najm 2018b the soil columns were modeled as a 2d axisymmetric plane with a depth of 500 mm and a radius of 250 mm a pressure head boundary condition of 5 7 mm was imposed on the soil surface delimited by the ring while free drainage was set at the bottom of the modeled domain the values of θ r θ s η and hb obtained with the evaporation method were used as initial values to improve the fitting results note that the brooks and corey models were considered for the water retention and hydraulic conductivity functions in accordance with the four analytical approaches the water content parameters θ r and θ s were kept fixed and the tortuosity parameter l was set to 0 5 through a least squares inverse solution routine η hb and kfs hydrus values were optimized using the measured cumulative infiltration data table 3 summarizes the optimized parameters and an example for each soil of the inverse modeling is depicted in fig 2 for the four sampled soils kfs hydrus ranged from 28 2 to 839 9 mm h 1 the wide range of kfs hydrus values supported the choice to test the proposed model and the 14 different scenarios on these four hydraulically distinct soils 3 6 data analysis in this investigation we considered a total of 14 different scenarios to estimate kfs data more specifically the kfs values were estimated by approach 1 scenario i determining λ through eq 6 and θ i and θ s from sampled soil cores and then fitting eq 1 to cumulative infiltration approach 2 scenarios ii v determining λ θ i and θ s and introducing the three datasets of c 2 and c 1 values obtained with the ci cl and dl fitting methods into eqs 7 and 8 and the c 4 and c 3 values into eqs 9 and 10 approach 3 scenarios vi ix estimating λ through eq 6 and introducing the three datasets of c 2 estimates into eq 11 and the c 4 values into eq 12 approach 4 scenarios x xiii using λ 150 mm and introducing the three datasets of c 2 estimates into eq 11 and the c 4 values into eq 12 ssbi method scenario xiv using λ 150 mm and introducing the c 4 values into eq 13 with reference to approaches 1 and 3 λ values obtained from water retention data and estimated by eq 6 were averaged to obtain four site representative values a single value of θ i and θ s was also obtained for a given site by averaging individual determinations approach 1 and 2 the field saturated soil hydraulic conductivity kfs estimates were compared with the corresponding values obtained by inverse solution from hydrus 2d 3d i e the kfs hydrus values using the relative error er kfs defined as follows 14 e r k fs 100 k fs k fs h y d r u s k fs h y d r u s note that positive er kfs values indicate overestimations whereas negative values indicate underestimation small deviations i e er kfs 0 suggest that the estimates are close to actual values er kfs values between 50 and 100 represent a factor of difference fd 2 between estimated and actual values er kfs values between 66 7 and 200 represent fd 3 the factor of difference can be calculated as the ratio between the maximum and minimum of kfs and the corresponding kfs hydrus value i e fd max kfs kfs hydrus min kfs kfs hydrus following elrick and reynolds 1992 fd values not exceeding a value of two were considered indicative of similar estimates also note that all of the estimation and comparison procedures are synthetized in fig 2 for comparisons between paired observations the paired differences i e kfs kfs hydrus for given scenario were calculated and the hypothesis of normality of these differences was checked by the kolmogorov smirnov test for normally distributed data a paired t test was used to test the mean difference between paired observations at p 0 05 for non normally distributed data the wilcoxon signed rank test was used to test the median difference between paired observations at p 0 05 the adequacy of model fits was evaluated by checking the relative error er and the root mean squared differences rmsd defined as 15 er 100 i 1 n x i obs x i 2 i 1 n x i obs 2 16 rmsd i 1 n x i obs x i 2 n where n is the total number of data pairs x i obs are the observed data and x i are the values predicted by the models values of er 5 were assumed indicative of a satisfactory fitting ability of the models angulo jaramillo et al 2016 lassabatere et al 2006 4 results in the following subsections we present i the results of the analysis of single ring infiltration data and the performances of the different fitting methods section 4 1 ii the result of the comparison between kfs data estimated from different scenarios and those values obtained by numerical inverse modeling with hydrus 2d 3d section 4 2 and iii a check for data reliability by comparing kfs estimates with laboratory measurements of unsaturated hydraulic conductivity kh section 4 3 4 1 analysis of single ring infiltration data we firstly used eq 4 to determine the time to steady state ts with the condition e 2 fig 1a this threshold split the experimental data into two subsets that were then fitted to the transient t ts and steady state t ts models time to steady state ranged from 1 5 to 31 1 min depending on the run table 4 for the sandy soil ts was on average 19 1 min with an infiltrated depth i ts of 123 4 mm in comparison the sandy loam soils had mean ts values of 5 2 min sandy loam 1 and 2 2 min sandy loam 2 the sandy soil thus required a factor of 4 to 9 more time to reach steady state conditions compared to the sandy loam soils likely due to the presence of a crust layer which reduced infiltration rates alagna et al 2019 2013 and affected estimates for infiltration parameters di prima et al 2018a during data analysis peculiarities emerged within some of the infiltration datasets with three types of abnormal behaviors identified fig 4 in some runs the early infiltration rates were particularly high in comparison with the rest of the run fig 4a causing a large initial jump in cumulative infiltration fig 4b white circles this circumstance is quite common in coarse or initially dry soils di prima et al 2016 in this case the first data point of the i t vs t plot cl method deviated from the general linear behavior fig 4c white circles this problem can be easily solved by excluding the first data point from the cumulative infiltration fig 4b allowing the detection of a linear relationship fig 4c grey circles and a proper estimation of the c 1 and c 2 coefficients such an adjustment was made on 14 infiltration runs i e 35 of the cases other investigations also suggested removing the early stage of the infiltration process when a perturbation occurs e g bagarello et al 2014c di prima et al 2018b vandervaere et al 2000b one infiltration experiment from the sandy soil showed a sudden decrease in infiltration rate fig 4d this condition was not easily detectable from the visual inspection of the cumulative infiltration curve fig 4e but appeared when the data were linearized fig 4f the lack of linear data meant that eq 5a was inappropriate and that the fitted parameters were physically meaningless vandervaere et al 2000a for this reason the sample was excluded from subsequent analyses possible contributing factors include water infiltrating into a less permeable layer alagna et al 2016 lassabatere et al 2019 air entrapment vertical soil water content gradients and soil sealing at the surface from repeated water applications bagarello et al 2014c di prima et al 2018a other experiments had infiltration rates that increased with time fig 4g such that the cumulative infiltration curves exhibited convex shapes fig 4h the fitting procedures applied to these data produced negative values for the c 1 infiltration coefficient fig 4i these cases occurred at the sandy loam 1 site one instance and sandy loam 2 site three instances and reflect that the early wetting phase was impeded due to hydrophobic surface films on soil particles and non zero contact angles between water and soil particles hallett et al 2001 jarvis et al 2008 hydrophobia may be attributed to locally high oc content goebel et al 2011 and exudates produced by the plant root systems or living organisms like arbuscular mycorrhizal fungi rillig et al 2010 this effect is known to diminish during the wetting process alagna et al 2018 it should be noted that despite the water repellency relatively high early infiltration rates were still measured this result indicates that the soils likely had subcritical water repellency e g di prima et al 2017a lassabatere et al 2019 lichner et al 2007 lozano baez et al 2018 three different sets of c 1 and c 2 values were obtained for transient state data using the ci cl and dl methods overall the c 1 and c 2 coefficients were properly estimated in 93 of the cases 37 of 40 runs for the ci and cl methods and 95 38 of 40 for the dl method the c 1 coefficient ranged between 0 4 and 514 3 mm h 0 5 and the c 2 coefficient between 95 8 and 4424 2 mm h 1 table 5 differences between methods were more pronounced for c 1 compared to c 2 values with the latter only presenting statistically different estimates between the three procedures for the silty loam soil fig 5 mean c 1 values were ordered as dl ci cl good fits i e er 5 were obtained for all cases except the dl method on the sandy loam 2 site mean er 7 6 finally the analysis of steady state data i e the data points for which e 2 eq 4 did not show any such peculiarities thus the intercept c 3 and the slope c 4 of the regression line fitted to the data points describing steady state conditions could be properly estimated in all cases table 5 4 2 validation with hydrus predicted data the inverse option in hydrus 2d 3d was used to optimize the η hb and kfs hydrus parameters on the measured cumulative infiltration data the field saturated soil hydraulic conductivity kfs estimates obtained from the 14 different scenarios were compared with the corresponding values obtained from hydrus i e the kfs hydrus values for approach 1 site representative values of λ table 6 θ i and θ s were considered and kfs was optimized fitting eq 1 to cumulative infiltrations the λ values were obtained by averaging for each soil the individual determination obtained from eq 6 and considering the η and hb parameters optimized on the retention data obtained by the evaporation experiments the kfs values ranged between 29 2 and 429 1 mm h 1 table 7 with 45 and 55 of the runs yielding respectively lower and higher kfs estimates than the hydrus estimated values fig 6 the differences between kfs and kfs hydrus were non normally distributed according to the kolmogorov smirnov test the wilcoxon signed rank test showed that approach 1 yielded kfs estimates not significantly different from the kfs hydrus values figs 7 and 8 the relative error er kfs ranged from 66 5 to 347 3 with mean and median factor of difference fd values equal to 1 45 and 1 22 individual values fd were less than two in 85 0 and less than three in 97 5 of the cases with only one case out of 40 yielding fd 3 fig 9 therefore kfs estimates were acceptable in almost all cases when eq 1 was directly fitted to experimental data for approach 2 four sets of kfs and λ values were determined three sets for transient infiltration data by eqs 12 and 13 one set for each fitting procedure i e ci cl and dl and one set for steady state data by eqs 14 and 15 the three transient scenarios yielded significant higher kfs estimates than the kfs hydrus values figs 7 and 8 with mean fd values equal to 12 23 ci 16 05 cl and 9 30 dl and individual fd values higher than three in 80 0 92 5 and 72 5 of the cases fig 9 the steady state scenario gave negative λ values and consequentially negative kfs in 75 of the cases i e 30 out of 40 overall approach 2 either poorly predicted λ and kfs data or failed to give valid estimates at all the results obtained here can be viewed as a confirmation of the conclusion by stewart and abou najm 2018b for approach 3 site representative values of λ were calculated based on water retention characteristics table 6 and four sets of kfs values were determined three sets for transient infiltration data using eq 11 and one set for steady state data using eq 12 for these scenarios kfs ranged between 23 2 and 687 4 mm h 1 table 7 with the transient scenarios yielding slightly but significantly higher kfs estimates than hydrus and with the steady state scenarios yielding slightly but significantly lower estimates than hydrus figs 7 and 8 for the four scenarios fd values were less than two in at least 75 0 of the transient scenarios and in 95 0 of the steady state cases fig 9 with mean fd values ranging from 1 51 to 1 86 and median fd values from 1 37 to 1 59 given that kfs estimates were acceptable in all cases we considered a new scenario figs 6 9 by averaging for a given run the four kfs estimates this newly conceived scenario yielded lower mean and median fd values respectively equal to 1 46 and 1 24 for approach 4 a λ value of 150 mm was used to determine four sets of kfs values similar to approach 3 for the transient scenarios using a λ value of 150 mm resulted in higher kfs values than were predicted by hydrus figs 7 and 8 for these three scenarios fd values were higher than two in 67 5 82 5 of the cases and higher than three in 30 0 55 0 of the cases fig 9 mean fd values ranged from 2 71 to 3 52 and median fd values varied from 2 59 to 3 27 better kfs predictions were obtained by the steady state scenario with er kfs values ranging from 38 6 to 460 4 this scenario yielded slightly but significant higher kfs estimates than the actual values figs 7 and 8 with mean and median fd values equal to 1 57 and 1 49 individual fd values were respectively less than two and three in 95 0 and 97 5 of the cases and with only one case out of 40 yielding fd 3 fig 9 with the ssbi method the er kfs values ranged from 36 8 to 476 6 with mean and median fd values equal to 1 63 and 1 54 individual values fd were less than two in 90 0 and less than three in 95 0 of the cases with only two cases out of 40 yielding fd 3 fig 9 4 3 unsaturated vs field saturated soil hydraulic conductivity a further check for data reliability was carried out by comparing kfs estimates with laboratory measurements of unsaturated hydraulic conductivity kh table 8 summarizes the kh values measured by the unit hydraulic gradient laboratory method for the four soils as expected kh increased dramatically in the proximity of the saturation i e for lower h 0 values fig 10 the mean values of the unsaturated soil hydraulic conductivity obtained at the pressure head h 0 10 mm k 10 ranged between 21 0 and 154 7 mm h 1 with higher k 10 values measured on the sandy soil cores firstly it should be noted that for the sandy soil this comparison needs specific consideration owing to crusting phenomena at the soil surface in particular the soil core collection process disturbed the crust layer such that fractures on the soil surface were observed in all soil cores therefore the upper layer of the soil was carefully removed in the laboratory and the measurements of unsaturated hydraulic conductivity were conducted on the underlying non crusted soil layer on the contrary in the field we maintained the crust layer during the ponding experiments in order to give an insight on the potential of the applied model when a layered medium is characterized as mentioned above the small insertion depth i e 10 mm of the ring used to run the beerkan experiments avoided the formation of fractures in the crust layer ensuring that the measured infiltration rates were indicative of the crust layer as a consequence 9 of 14 scenarios for this soil produced mean values of kfs lower than k 10 proving that the soil crust layer reduced water flow during ponding experiments in the field for the silty loam sandy loam 1 and sandy loam 2 soils kfs determined from the 14 different scenarios always remained higher than the measured kh values therefore physically possible kfs estimates were obtained in all cases given that kfs k 10 for these soils the 14 scenarios yielded mean kfs values that were 1 7 68 6 times higher than the corresponding k 10 i e up to two orders of magnitude differences of this order of magnitude or even higher between saturated and near saturated hydraulic conductivity have been often observed under field conditions e g buczko et al 2003 castellini et al 2015 di prima et al 2017a dunn and phillips 1991 watson and luxmoore 1986 5 discussion the analysis of the cumulative infiltration measurements identified some runs with peculiarities such as very high initial infiltration rates undetectable linear relationships in the cl and dl methods and negative values of the infiltration coefficients still infiltration data could be analyzed to determine the constants c 1 and c 2 for 93 of the runs using the cumulative infiltration ci and cumulative linearization cl methods and for 95 of the runs using the differential linearization dl method the infiltration constants were next applied to estimate kfs using the comprehensive single ring infiltration model of stewart and abou najm 2018a here we considered four approaches and thirteen scenarios that differed in how λ was constrained while also comparing kfs estimates using the sbbi method approaches 1 and 3 were the most data demanding requiring that λ was estimated from water retention data and that soil samples were collected before the infiltration runs to determine initial and saturated volumetric soil water contents θ i and θ s yet our analysis of the field data showed that those approaches provided the most accurate kfs estimates compared to values obtained through numerical inverse modeling with hydrus 2d 3d approach 1 was the most accurate overall likely because it did not require any transformation of the infiltration data this approach is therefore recommended for situations when λ θ i and θ s are well constrained still by averaging together the four kfs estimates obtained by approach 3 for a given run i e considering together the scenarios vi ix in fig 3 the measurement uncertainty of that approach was reduced to a level comparable to approach 1 these averaged kfs values avoided uncertainties that might exist within each of the specific fitting procedures ci cl and dl while also overcoming any failed analyses e g negative estimates for kfs as a result this newly considered scenario increased the accuracy of kfs estimates and as a result we recommend users apply a similar averaging scheme when using approach 3 the kfs estimates were less accurate but still acceptable for the steady state scenarios of approach 4 and the ssbi method the steady state data likely provided better accuracy than the transient data because the steady phase of the infiltration process avoids uncertainties due to variations in infiltration rates caused by for instance soil sealing di prima et al 2018a or water repellency lichner et al 2013 with both of these methods no additional data are required to determine kfs making these procedures desirable when surveying remote or large areas bagarello et al 2013 one difference between the two is that the ssbi method is theoretically usable for a ponded depth of water on the infiltration surface hsource equal to zero and a null depth of ring insertion into the soil d bagarello et al 2017 whereas both zero and positive values of both hsource and d can be considered with approach 4 here both methods were used to analyze infiltration runs that had a quasi zero head of water imposed on the soil surface beerkan runs so the models performed similarly to one another the predictive potential of the model was also checked via comparison with laboratory measurements of unsaturated hydraulic conductivity kh for the silty loam sandy loam 1 and sandy loam 2 soils kfs estimates from the 14 different scenarios were always higher than the unsaturated soil hydraulic conductivity therefore physically plausible kfs values were obtained in all cases for the crusted sandy soil kfs kh situations suggested that the surface crust layer reduced water flow during ponding experiments in the field in the future measuring kh values directly in the field using a tension infiltrometer casey and derby 2002 or the portable mini disk device decagon 2014 may help to properly characterize unsaturated flow in crusted soils indeed field measurements are known to minimize soil disturbance in comparison with laboratory methods performed on collected soil samples haverkamp et al 1999 moreover tension infiltrometers were successfully used in many investigations to characterize layered soils in the field e g alagna et al 2013 di prima et al 2017b šimůnek et al 1998 vandervaere et al 1997 altogether the new comprehensive model and the underlying approaches to analyze single ring data may allow researchers to better approach heterogeneous datasets including transient or steady state infiltration data and experiments carried out with different setups the versatility of the new model makes it a good candidate to successfully analyze the swig database developed by rahmati et al 2018 which include 5023 infiltration curves collected across the world 6 summary and conclusions in this study we tested a new comprehensive model for single ring data on four soils with different textures i e sandy silty loam and sandy loam the field saturated soil hydraulic conductivity kfs values were estimated by four different approaches which differ by the way they derive kfs and constrain λ θ i and θ s for comparative purposes the ssbi method was also applied to estimate kfs in this investigation we considered a total of 14 different scenarios to estimate kfs data that differed in the considered approach i e approaches 1 4 or ssbi in the use of transient or steady state data and in the fitting methods applied to transient data ci cl and dl the kfs data estimated from different scenarios were compared for validation purposes with those values obtained by numerical inverse modeling with hydrus 2d 3d among the different scenarios approaches 1 and 3 appear as the more promising yielding better kfs predictions conversely the steady state scenario of approach 4 and the ssbi method are preferable when a simplified experimental procedure is required such as when sampling remote or large areas given that these interpretations do not require additional data and still provide acceptable estimates of kfs declaration of interests none acknowledgements this work was supported through the infiltron project anr 17 ce04 0010 funded by the french national research agency anr s di prima outlined the investigation and analyzed the data all authors contributed to discussing the results and writing the manuscript 
