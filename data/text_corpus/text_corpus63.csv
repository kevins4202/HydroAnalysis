index,text
315,in this article a δ les sph model is presented to study the generation and propagation of impulse waves in this model a density diffusion term is added to the continuity equation to eliminate the numerical high frequency oscillation of the pressure field a particle shifting technique is introduced and modified in the motion equation to improve the accuracy and robustness of the smoothed particle hydrodynamics sph model the physical viscosity term and the turbulence viscosity term based on the large eddy simulation les are used in the momentum equation to calculate the viscous force to predict the rigid slide motion more effectively we propose a rigid slide motion model that considers friction in the δ les sph frame the δ les sph code was implemented in fortran 90 and openmp programming technology was used to improve the calculation efficiency subsequently this parallel sph code was used to simulate subaerial and submarine rigid landslides in 2 d and more realistic 3 d applications the sph results were compared with the experimental data and other numerical results the results show that the proposed model has a good convergence and less numerical dissipation satisfactory results were obtained for the rigid slide motion wave generation and long distance propagation keywords δ les sph landslide generated impulse waves particle shifting technique large eddy simulation rigid slide motion mode 1 introduction landslides are one of the most catastrophic and frequent geological disasters that occur in nature and the impulse waves generated by landslides in reservoirs bays and oceans are essential secondary disasters impulse waves with considerable amplitudes may cause severe damage to water retaining structures and flood agricultural areas resulting in severe consequences for human life and property wang et al 2016 for instance the largest tsunami in recorded history occurred in july 1958 at lituya bay alaska which generated a wave run up of 524 m tajnesaie et al 2018 in october 1963 the vajont landslide in northern italy caused a 240 m high wave that overtopped the dam crest by approximately 70 m and rushed downstream heller et al 2016 yeylaghi et al 2017 the overtopping water destroyed five towns and caused approximately 2000 casualties lin et al 2015 because landslide generated impulse waves are extremely destructive it is of great practical significance to estimate their characteristics accurately physical model experiments and numerical simulations are important for investigating landslide generated impulse waves tan and chen 2017 experiments are performed in both 2 d and 3 d often resulting in generally applicable equations evers et al 2019 such as empirical formulas for the wave height wave period propagation speed wave run up and overtopping fritz et al 2001 ataie ashtiani and nik khah 2008 lin et al al 2015 heller et al 2016 pilvar et al 2019 generally these equations can easily and quickly provide an initial estimate of the most important wave properties in practice evers et al 2019 in addition physical model experiments have great significance for understanding the physical process of landslide generated impulse waves and validating the accuracy of numerical simulations yeylaghi et al 2017 however numerical simulations play increasingly important roles in the research of landslide generated impulse waves to simulate the entire process of the generation propagation and run up of impulse waves both frequency dispersion and nonlinearity should be considered hassan et al 2010 this requires a useful description of such physical phenomena in terms of mathematical equations as well as an appropriate method to solve these equations behrens and dias 2015 the mathematical equations can be categorized into depth averaged equations width averaged equations and fully three dimensional equations in addition based on their ability to simulate dispersive effects these mathematical equations can also be described as nondispersive weakly dispersive and fully dispersive equations yavari ramshe and ataie ashtiani 2016 among these mathematical equations the shallow water equations swes boussinesq water wave equations bwes and navier stokes n s equations are widely used in numerical studies of landslide generated impulse waves wang et al 2016 according to the classification mentioned above swes are depth averaged and nondispersive equations bwes are depth averaged equations and weakly dispersive equations and n s equations are fully three dimensional and fully dispersive equations both swes and bwes are simplifications of the n s equations the former ignore the vertical flow components whereas the latter consider the vertical structure of flow velocities by using a polynomial approximation of the vertical profile of horizontal velocities yavari ramshe and ataie ashtiani 2016 n s equations provide a complete description of fluid wave behavior and they are suitable for complex wave interactions behrens and dias 2015 the above mathematical equations can be solved using two different approaches eulerian and lagrangian methods eulerian methods such as finite difference methods fdm and finite volume methods fvm encounter difficulties in modeling a landslide with complex geometry owing to the use of structured meshes in mesh based lagrangian methods the computational mesh might be severely distorted and frequent time consuming remeshing might be inevitable yavari ramshe and ataie ashtiani 2016 in recent years particle based lagrangian methods such as smoothed particle hydrodynamic sph monaghan 1994 moving particle semi implicit mps ataie ashtiani and farhadi 2006 gotoh and khayyer 2018 khayyer et al 2019a b and the meshless finite element method idelsohn et al 2003 have been extensively employed in the field of fluid flow in these approaches each particle can be tracked in a lagrangian manner without facing the difficulties of mesh deformation shobeyri and afshar 2012 sph is a lagrangian mesh free method developed by lucy 1977 and gingold and monaghan 1977 to study astrophysical applications this method was later extended to hydrodynamics by monaghan 1994 in contrast with the mesh based methods the n s equations can be solved by the sph method without using computational grids or meshes which makes them highly suitable for free surface flows with large deformations wang et al 2016 in addition the problem of numerical diffusion due to the existence of advection terms in the n s equations is eliminated in the sph method shobeyri and afshar 2012 therefore the sph method based on the n s equations has been extensively applied to the numerical simulation of impulse waves generated by landslides ataie ashtiani and shobeyri 2008 capone et al 2010 viroulet et al 2013 farhadi et al 2016 heller et al al 2016 yeylaghi et al 2017 according to different pressure calculation methods the sph method is divided into the weakly compressible sph wcsph ren et al 2015 and incompressible sph isph abbas et al 2018 khayyer et al 2018 yeylaghi et al 2017 zheng et al 2014 wcsph is suitable for efficient simulation of free surface flows due to its explicit numerical algorithm and advantages in computational efficiency parallelization antuono et al 2012 colagrossi et al 2009 however traditional wcsph has the problem of spurious numerical oscillations in pressure δ sph antuono et al 2012 and riemann based sph vila 1999 ben moussa and vila 2000 have recently become popular variants of wcsph oger et al 2016 the advantage of riemann based sph is that no explicit artificial viscosity is used and numerical dissipation is introduced implicitly δ sph has been shown to be reliable and robust in the simulation of complex free surface flows marrone et al 2011 this method has the advantages of a standard sph scheme low cpu cost and easy implementation and it has been widely used in recent years marrone et al 2013 chowdhury et al 2014 meringolo et al 2015 valizadeh et al 2015 vacondio et al 2016 unfortunately there are some unresolved problems in the δ sph method such as tensile instability possible inhomogeneous spatial configurations and numerical dissipation caused by the artificial viscosity this reduces the accuracy and robustness of the δ sph method and limits its application krimi et al 2020 meringolo et al 2019 sun et al 2017 2019 sun et al 2017 developed a δ sph method which introduced a particle shifting technique pst into the δ sph method this method allows for a regular spatial particle configuration through small continuous resettlements in contrast in di mascio et al 2017 modified the δ sph method from the lagrangian perspective of large eddy simulation les antuono et al 2021 this method was further inspected by antono et al 2018 and called δ les sph this method uses physical and turbulent viscosity terms to calculate the viscous forces avoiding the numerical dissipation caused by the use of an artificial viscosity term in this study our interest is mainly focused on the impulse waves generated by subaerial and submarine rigid landslides to solve the problem of faster decay of impulse waves simulated by the conventional sph method violeau and rogers 2016 a δ les sph model with lower numerical dissipation is presented based on the δ les sph and δ sph methods to predict rigid slide motion more effectively we propose a rigid slide motion model rsmm that considers friction in the δ les sph frame the δ les sph code was implemented in the fortran 90 language and openmp programming technology was used to improve the calculation efficiency the compilation environment was visual studio 2013 and inter visual fortran 2013 first the δ les sph code is verified in terms of free surface evolution pressure and energy versus time through a rotating square patch benchmark test case subsequently we used this method to simulate both subaerial and submarine rigid landslide generated impulse waves and discuss numerical convergence slide kinematics wave profiles hydrodynamic pressure and the role of turbulence it is encouraging to find that the slide motion wave profiles and pressure loading agree reasonably well with the experimental data and other numerical results the remainder of this paper is organized as follows the δ les sph scheme is introduced in section 2 the motion model of a rigid slide considering friction and collision is presented in section 3 the test cases simulated in the present work involve a 2 d submarine landslide section 4 1 a 2 d subaerial landslide section 4 2 and a 3 d subaerial landslide section 4 3 finally the conclusions and comments are presented in section 5 2 δ les sph model 2 1 governing equations in this model the fluid is assumed to be weakly compressible and its governing equations in a lagrangian coordinate system include mass conservation momentum conservation the equation of state and the equation of motion 1 d ρ d t ρ u ρ d u d t p f v f b f τ p f ρ d r d t u where ρ u r t p f v f τ and f b denote the density velocity vector position vector time pressure viscous stress vector turbulent stress vector and physical force vector of the fluid respectively in the wcsph the density change of fluid clusters is limited to 1 monaghan 1994 and under such conditions the fluid can be regarded as barotropic marrone et al 2011 under these hypotheses it is possible to adopt a state equation that is only a function of density meringolo et al 2018 the linear equation of state provides a more stable pressure field antuono et al 2012 as follows 2 p c 0 2 ρ ρ 0 the artificial speed c 0 remains unchanged in this work with the following constraint meringolo et al 2018 3 c 0 10 max p m a x ρ 0 u m a x where pmax is the maximum expected pressure of the flow field ρ 0 is the reference value of the density field and umax is the maximum expected velocity of the flow field and rigid slide 2 2 discrete forms when eq 1 is written in the sph formalism an artificial diffusion term presented by molteni and colagrossi 2009 is added to the continuity equation to eliminate the numerical high frequency oscillations in the pressure field the pst considering the flow mach number presented by sun et al 2017 is introduced and modified in the motion equation to improve the accuracy and robustness of the sph model a viscosity term including physical viscosity and turbulent viscosity presented by di mascio et al 2017 is used in the momentum equation to calculate the viscous forces the final governing equation can be discretized as follows 4 d ρ i dt ρ i j u j u i i w ij v j δ h c 0 ψ ij j i w ij v j d u i dt 1 ρ i j p i p j i w ij v j j v eij π ij i w ij v j g d r i dt u i r i r i δ r i p i c 0 2 ρ i ρ 0 v i t m i ρ i where r i denotes the new location vector of particle i after the pst is applied see section 2 4 for more details and vi and mi denote the volume and mass of particle i respectively in eq 4 wij w r i r j h denotes the kernel function which is related to the efficiency precision and stability of the numerical simulation the wendland c2 kernel function was used as follows 5 w q h a d 1 2 q 1 1 2 q 4 0 q 2 0 q 2 where q r i r j h and δx denotes the initial particle spacing h denotes the smoothing length h 2δx and a d 7 4πh 2 in 2 d h 1 5δx and a d 21 16πh 3 in 3 d the diffusion term tends to zero with an increase in the spatial resolution i e h 0 and does not influence the overall evolution of the flow field antuono et al 2012 where 6 ψ ij 2 ρ j ρ i r j r i r j r i 2 ρ i l ρ j l and ρ l is the renormalized density gradient antuono et al 2010 which is defined as 7 ρ i l j ρ j ρ i l i i w ij v j l i j r j r i i w ij v j 1 because the variable range of the parameter δ is very narrow it is regarded as a non adjustable parameter and is set equal to 0 1 sun et al 2017 in addition di mascio et al 2017 proposed a modified diffusion term where δ is no longer a constant but is evaluated at every instant through the gradient of the velocity field this method can reduce and optimize the additional numerical dissipation however violent fluid motion in the slide water impact region of subaerial landslides may lead to excessive δ values making the density field in this region no longer conform to the weakly compressible assumption therefore a more stable diffusion term with a constant δ was selected in this study the physical viscous forces modeled using the artificial viscosity formula presented by monaghan and gingold 1983 can guarantee the conservation of both linear and angular momenta as follows 8 π ij 2 d 2 u i u j r i r j r i r j 2 where d is the spatial dimension the analysis by colagrossi et al 2011 showed that eq 8 has a good consistency at the free surface therefore it is suitable for the viscous force calculation of free surface flows in the δ les sph method the effective viscosity ve of water includes the kinematic viscosity vw and the turbulent viscosity vt the turbulent viscosity vt presented by di mascio et al 2017 is a function of the local and instantaneous flow conditions in particular the harmonic mean value vt ij is used to replace the turbulence viscosity of particles i or j as follows 9 v t c s l les 2 d v t ij 2 v t i v t j v t i v t j where cs 0 12 is the smagorinsky constant and lles is the reference length for the sph filtering procedure which is set equal to the radius of the kernel 2h the quantity d is given by 10 d 2 d d and the formula for the strain rate tensor d is as follows 11 d 1 2 j u j u i l i w ij l i w ij u j u i v j 2 3 particle shifting technique pst the pst based on the isph method was first presented by xu et al 2009 and further developed by lind et al 2012 and khayyer et al 2017 the pst has been shown to redistribute the particles in a more isotropic manner avoiding particle clustering in the compression direction and sparse discretization error in the stretching direction huang et al al 2018 sun et al 2017 proposed a modified pst in which the shifting vector δ r i considering the influence of the mach number ma is reformulated as 12 δ r i cfl ma 2 h i 2 j 1 r w ij w δ x i n i w ij m j ρ i ρ j where the constants are r 0 2 n 4 cfl denotes the courant friedrichs levy constant to control the incorrect shifting of particles in the free surface region fsr sun et al 2017 presented a shifting vector correction method for particles in the fsr this correction aims to maintain the tangential shifting component of particles in the fsr and improve the normal shifting component and to achieve a uniform distribution of the particles in the fsr the final particle shifting vector δ r i is specified as follows 13 δ r i 0 λ i 0 4 and i s f i n i n i δ r i λ i 0 4 and i s f δ r i i s f where sf represents the fsr composed of particles that are at a distance of less than 2h from the free surface i represents the identity tensor λ is the minimum eigenvalue of the tensor l 1 and n i is the normal vector of particle i in the fsr the following two steps must be satisfied to achieve the above purpose 1 accurate identification of free surface particles 2 the normal vector of particles in the fsr is evaluated for more details see marrone et al 2010 however for long time free surface flow problems with confined domains such as landslide generated impulse waves the pst based on eq 13 causes incorrect shifting of particles in the fsr when meeting with a wall boundary leading to incorrect results the pst presented by sun et al 2017 was modified to address the aforementioned problems 1 the pst shut off threshold in fsr is modified from λ 0 4 to λ 0 75 i e the pst correction of particles near the free surface is turned off to avoid nonphysical fluctuations when the concentration gradient is large huang et al 2018 adopted a similar approach when simulating viscous flow problems using the coupled finite particle method fpm 2 for particles with λ 0 75 in fsr in fact it is a skinny free surface layer the artificial viscosity term is added to eliminate unrealistic fluctuations the surface viscosity variables presented by akbari 2017 were adopted 14 v art s α s x 2 u u max u where as is a damping coefficient recommended as unity by akbari 2017 and the trial calculation shows that as 1 0 as adopted in this study can yield better results the artificial viscosity of the internal particle j is defined as a portion of the viscosity of the closest particle i located on the surface boundary i e 15 v art j ψ v art s ψ w ij w ii 3 after the particles shift the first order terms in the taylor series expansion are used to update their velocity pressure and density as follows hashemi et al 2012 16 u i u i δ r i u i p i p i δ r i p i ρ i ρ i δ r i p c 0 2 i the above correction considers the influence of the particles shifting on the density avoids the error of the particle volume caused by only the correction of the particle position and provides a more regular pressure field in appendix a the modified pst is verified in terms of the free surface evolution the pressure and energy versus time through a rotating square patch benchmark test case 2 4 solid boundary in the sph method the precision and robustness of the final simulation results are largely determined by the boundary implementation technology the impervious condition must be considered for a solid boundary moreover for the lower reynolds number scenarios the no slip boundary condition was used the fixed ghost particle technique proposed by marrone et al 2011 and adami et al 2012 is adopted in the present procedure and the pressure of the ghost particle is obtained by interpolation from the neighboring fluid particles as follows 17 p s f p f w sf g a s f ρ f r sf w sf f w sf where the symbol s represents the ghost particle f represents the fluid particle a s represents the acceleration of the ghost particle and g represents the acceleration vector due to gravity ρ s is obtained using the following equation of state 18 ρ s p s c 0 2 ρ 0 by neglecting the viscous force between the fluid particles and adjacent ghost particles the free slip boundary condition can be realized to impose the non slip boundary condition the velocity of the ghost particles in eq 8 is obtained by interpolation of the adjacent fluid particles as follows 19 u v 2 u s f u f w fs f w fs where u s and u f denote the wall velocity and fluid velocity respectively 2 5 time stepping scheme eq 4 is solved by the 4th order runge kutta integration scheme using a frozen diffusive approach antuono et al 2012 the time step δt is restricted by the maximum acceleration of both the moving solid and fluid viscous diffusion and artificial sound speed the time step constraints are expressed as follows sun et al 2017 20 δ t min 0 125 h max a i 0 25 h 2 max v ei cfl h c 0 the first two time step boundaries were obtained by morris et al 1997 and the third time step limit was obtained by monaghan and kos 1999 antuono et al 2012 showed that the dependence of the first two constraints on a specific integration scheme was very weak the second term is based on the usual condition of the explicit fdm simulating viscous diffusion where ve includes the physical turbulent and surface viscosities at sufficiently high resolution or high viscosity this term is usually the main time step constraint however the acoustic constraint is generally the most restrictive for the reynolds number investigated in this study the acoustic constraints can also be expressed as the cfl limitation similar to those in cfd simulations akbari 2017 21 δ t c cfl h c 0 a t δ x u max where δx is the initial particle spacing and at 0 4 which is generally recommended in wcsph violeau and leroy 2015 in our numerical models at 0 25 as obtained from cfl 1 25 3 rigid slide s motion model rsmm in this section an rsmm in δ les sph is presented to resolve the rigid slide motion on the ramp without a prescribed velocity in general slide motion is difficult to predict in advance in the traditional sph model the velocity of the slide as an input parameter must be prescribed according to experimental data monaghan and kos 2000 ataie ashtiani and shobeyri 2008 capone et al 2010 in recent years there have been some methods for resolving the rigid slide motion in the sph scheme for example lin et al 2015 presented a telescopic boundary based on mirror particles to simulate a rigid slide motion yeylaghi et al 2017 presented a technique for implicitly calculating the rigid slide motion by placing a layer of fluid particles between the slide and fixed particles however these methods ignore the influence of the friction force on the rigid slide motion which leads to an overestimation of the rigid slide velocity in numerical simulations alternatively the coupling of dem kesseler et al 2020 and sph is well suited for simulating solid fluid interaction problems canelas et al 2013 tan et al 2018 heller et al 2016 studied the rigid landslide tsunamis based on the open source code dualsphyics v3 1 in which the dem was used to account for the slide ramp interaction tan and chen 2017 proposed a hybrid dem sph model in which a landslide is composed of many solid particles but the rigid slide motion needs to be prescribed tan et al 2018 proposed a block dem sph model to study the rigid slide motion and its generated waves the rigid slide motion is modeled by the block dem by imposing the drag and added mass coefficients along with a block friction angle to address impulse waves generated by rigid landslides more realistically we propose a simpler and more effective rsmm in the wcsph framework generally the forces acting on the rigid slide and determining its motion are the fluid force f f support force f s friction force f μ and gravity g as shown in fig 1 although f s has no direct contribution to the velocity of the rigid slide it determines the value of f μ which has an important influence on the slide motion therefore the accurate calculation of f s is particularly important for a moving rigid slide its velocity is divided into two parts translation and rotation in contrast with a floating body the rigid slide motion is not only affected by the fluid force and gravity but also by the force on the ramp therefore the conservation equations of momentum and moment of inertia of the rigid slide are as follows 22 md u c dt f f f s f μ g id ω c dt t f t s t μ where m i u c and ω c represent the mass of the rigid slide the moment of inertia relative to centroid c translational velocity and rotational velocity respectively fw and tw are the resultant force and the resultant moment respectively as follows 23 f f i fluid j solid p i p j v eij π ij ρ i v i v j i w ij t f i fluid j solid x i x j 2 x c p i p j v eij π ij ρ i v i v j i w ij where x i x j and x c denote the position vectors of particle i particle j and the slide center respectively eq 23 was originally derived and discussed by bouscasse et al 2013 subsequently sun et al 2015 improved the formula of the resultant moment i e x i x j 2 replaced the position of particle j on the slide surface to prevent the calculated value of the resultant moment from being too small to calculate the friction force f μ it is necessary to accurately calculate the contact force f s between the slide and the fixed boundary traditional contact algorithms need to search for the contact surface and its normal direction at each time step for meshless methods in a 3 d space this process is very complicated the meshless contact algorithm presented by vignjevic et al 2006 is selected here to realize the contact effect by exerting a contact force on the sph particles the contact potential function is expressed as follows 24 ϕ x i j ncont m j ρ j k w ij w δ h avg n where ncont represents the number of particles belonging to different objects in the support domain of particle i δhavg represents the average value of sph particle spacing and k and n represent user defined coefficients related to the impact velocity of the object the gradient of eq 24 is discretized by sph to obtain the contact force exerted on particle i zhang et al 2011 as follows 25 f s x i j solid m i ρ i m j ρ j kn w ij n 1 w δ h avg n i w ij where i and j denote moving and fixed boundary particles respectively the direction of the contact force is determined by the gradient of the sph smooth kernel function and is not directly related to the relative direction of the contact object or the shape of the contact surface therefore this method is suitable for calculating the supported force of rigid slides with various complex contact surfaces in the problem of landslide generated by impulse waves the dynamic friction force between the rigid slide and the ramp has a significant influence on the rigid slide motion as a benefit of the explicit calculation of the contact force in eq 25 the dynamic friction force can be calculated the dynamic friction force of particle i is expressed as 26 f μ x i μ f s x i u i u i where μ represents the dynamic friction coefficient f s x i represents the contact resultant force of the rigid slide on the ramp and u i u i denotes the unit vector of the velocity of particle i which is opposite to the direction of the dynamic friction it is worth noting that dynamic friction exists only when u i 0 the u c and ω c of the rigid slide are obtained by the 4th order runge kutta integration scheme in each time step according to eq 22 and the time step is consistent with the fluid time step after obtaining u c and ω c of the centroid of the rigid slide the velocity and acceleration of the slide particle are obtained according to the principle of rigid body kinematics as follows 27 d x i dt u i u i u c ω c x i x c a i d u c dt d ω c dt x i x c ω c u i u c where x i u i and a i denote the position vector velocity and acceleration of the slide particle i respectively 4 numerical tests in this section three classic experimental cases are used to tests the performance of the present procedure including a 2 d submarine landslide a 2 d subaerial landslide and a 3 d subaerial landslide in the 2 d submarine landslide experiment the rigid slide performed a simple linear motion along an inclined ramp an empirical formula for the velocity of the rigid slide was obtained for the subaerial landslides in 2 d and 3 d the ramp includes an arc shaped transition section such that the rigid slide is no longer a simple linear motion which helps to further test the practicability of the rsmm the particle packing algorithm colagrossi et al 2012 was used to initialize the particle distributions in all simulations to prevent nonphysical oscillations after the calculation starts 4 1 2 d submarine landslide in this section the experimental data of heinrich 1992 were selected to test the performance of the δ les sph code in their experiment a submarine rigid wedge with a density of 2000 kg m3 moved down a ramp with a slope of 45 to generate waves the cross section of the rigid wedge is triangular 0 5 m 0 5 m and the geometry of the experiment is shown in fig 2 the still water depth is 1 m and the top of the wedge is 0 01 m below the free surface in this numerical simulation three simulations with particle resolutions of δx 0 02 0 01 and 0 005 m are carried out to study the convergence of the present numerical solution the movement of the rigid wedge was calculated in two ways the first way is to prescribe the velocity of the wedge based on the formula of ataie ashtiani and shobeyri 2008 the vertical component formula for the wedge velocity is as follows 28 v t a tanh b t t 0 4 s v t 0 6 0 4 s t 1 0 s v t 0 t 1 0 s where a and b are constants a 86 b 0 0175 and the wedge is released at t 0 s the second way calculates the movement of the rigid wedge using the rsmm the parameters in the rsmm of this model were k 5 200 000 n 15 and μ 0 01 fig 3 shows the vertical displacement of the rigid wedge versus time obtained by using the rsmm at three particle resolutions and the sph solutions are compared with the experimental data heinrich 1992 dns numerical results abadie et al 2010 and isph numerical results yeylaghi et al 2017 the results show that the three numerical models are in good agreement with the experimental data but the influence of the friction force is ignored in the isph and dns models resulting in the overestimation of the wedge velocity after t 0 8 s because the dynamic friction effect is considered in the rsmm the displacement of the rigid wedge is closer to the experimental results at different particle resolutions the displacement results were very close showing good convergence of the rsmm fig 4 shows the free surface profiles obtained by using the δ les sph and rsmm at three particle resolutions in comparison with the experimental data heinrich 1992 as shown in fig 4 the free surface profiles at the particle resolution of δx 0 02 m are close enough to the experimental data the free profiles at the particle resolution of δx 0 01 m have converged to the experimental data showing good convergence of the δ les sph code therefore the particle resolution of δx 0 01 m is used for subsequent calculations in this section the free surface profiles at two instants a t 0 5 s and b t 1 0 s obtained through the present procedure are shown in fig 5 and the results are compared with the experimental data heinrich 1992 the results show that the free surface profiles obtained by the abovementioned two movement types of the rigid wedge are in good agreement with the experimental data the advantage of the rsmm is that it can effectively predict the slide motion while it can be conveniently added to the sph code and thus it has a strong practical value fig 6 shows snapshots of velocity fields and free surface profiles at some typical instants obtained through the δ les sph code as mentioned by abadie et al 2010 and yeylaghi et al 2017 two waves are generated due to the motion of the rigid wedge in water these two waves obtained by our code are shown in figure 6 the first wave is produced in the process of the rigid wedge moving downward and squeezing the water body continuously fig 6 a d and the second wave is produced by the plunging wave on the ramp fig 6 e f subsequently this wave breaks and the free surface profiles become more complicated fig 6 g h as reported by abadie et al 2010 and yeylaghi et al 2017 in fig 7 the velocity vectors for the particles are colored by their horizontal velocity at t 0 85 1 35 1 75 and 2 0 s studies by abadie et al 2010 and yeylaghi et al 2017 have shown that vortices occur when a rigid wedge moves along an underwater ramp identical vortices were generated in the present numerical simulation for example after the wedge is released a large vortex is produced above its left side this vortex is depicted by the positive and negative horizontal velocities above the left side of the wedge in fig 7 a and labeled vortex 1 two other vortices labeled vortex 2 and vortex 3 are produced after the plunging wave breaks respectively as shown in fig 7 b and c respectively vortex 2 is located in the internal fluid above the rigid wedge and vortex 3 is located in the wave breaking area of the free surface the free surface becomes increasingly complex as the waves break and small vortices are constantly generated in the region near the free surface but vortices 1 and 2 above the wedge always exist as shown in fig 7 d it is important to emphasize that in the les only the larger scale eddies are directly simulated whereas the subgrid turbulent eddies are modeled by space filtering fig 8 depicts the comparison of the pressure fields and particle distributions between the conventional pst and the improved pst for the traditional pst the disordered particle distributions first appear in the fsr near the left boundary fig 8 a these oscillations then expand along the free surface resulting in apparent nonphysical gaps between the free surface and its vicinity particles fig 8 b d this phenomenon also appears in the right half of the calculation model and directly changes the wave profile the nonphysical oscillations in the fsr also affect the pressure fields of the fluid in contrast when the improved pst is applied the more uniform particle distributions can be maintained 4 2 2 d subaerial landslide heller et al 2016 used the experimental setup shown in fig 9 to conduct two different scenarios of rigid landslide generated impulse waves experiments in a 2 d wave flume and a 3 d wave basin the unobstructed area of the flume is 21 0 m length 0 60 m width and the unobstructed area of the wave basin is 20 0 m width 7 4 m length in the present work we carried out numerical simulations of the 2 d experiment sections 4 2 and the 3 d experiment sections 4 3 in scenario 1 detailed experimental parameters can be found in heller et al 2016 the experimental snapshots and data are available at http spheric sph org tests test 11 in this experiment the ramp transition to the tank bottom was circular for both the 2 d flume and 3 d basin which means that the rigid slide did not stop when it reached the slope toe but rather moved along the tank bottom after passing through the transition section this posed a new challenge to the calculation model of the rigid slide motion however there are currently no effective calculation methods yeylaghi et al 2017 used the experimental data to predict the velocity of rigid slides in their simulation heller et al 2016 utilized the dem sph coupled model to calculate the motion of rigid slides on a ramp but the influence of subpressure and friction was considered by artificially reducing the impact velocity of the rigid slides the rsmm was used to simulate the rigid slide motion to test its performance in simulating complex motions the parameters in the rsmm of this model were k 2 300 000 n 15 and μ 0 2 to investigate the convergence of the present procedure to subaerial landslide problems three simulations with particle resolutions of δx 0 02 0 01 and 0 005 m were carried out the displacement and velocity of the slide front versus time obtained through the rsmm at three particle resolutions are displayed in fig 10 and the sph solutions are compared with the experimental data and numerical results of heller et al 2016 the results of the displacement and velocity of the slide are in good agreement at different particle resolutions which shows that the rsmm also has a good convergence for the simulation of complex motions the results obtained through the rsmm are in good agreement with the experimental data but there are slight deviations in the two time periods of 0 08 0 3 s and 0 55 0 99 s i e when the front and end of the slide pass through the transition section respectively this is because the width of the slide in the experiment is slightly smaller than that of the flume and the water can enter the gap between the bottom of the slide and the transition section the water in this region reduces friction and has a subpressure effect heller et al 2016 the combination of these two effects results in a difference between the numerical results and the experimental data the coordinate origin is defined on the slide axis at the intersection of the still water surface and the ramp and the x axis is along the direction of the flume time evolutions of the free surface elevation at a x 1 2 m b x 1 8 m c x 3 6 m and d x 8 4 m obtained through the δ les sph code at three particle resolutions are displayed in fig 11 as well as the sph solutions compared with the experimental data in heller et al 2016 at positions close to the splash zone yavari ramshe and ataie ashtiani 2016 the height and shape of the first wave at three particle resolutions are almost consistent with the experimental data fig 11 a b at positions far from the splash zone fig 11 d the height of the first wave at the particle resolution of δx 0 02 m is lower than the experimental data whereas the other two particle resolutions still maintain high accuracy the results show that the numerical dissipation of the δ les sph model decreases with increasing the particle resolution in hydrodynamic problems in addition to flow field information scholars have paid attention to the pressures loading on the structure in this section two force sensors from fig 9 s1 and s4 are selected to reproduce their pressure loading in the δ les sph model the pressure loading was measured by p s f p f w s f f w s f where the subscripts f and s represent the fluid particles and solid wall particles respectively fig 12 shows the pressure loading on the s1 and s4 of the slide front versus time obtained using the present procedure at three particle resolutions and the results are compared with the experimental data heller et al 2016 the pressure time curves agree well with the experimental data except that the pressure fluctuates significantly at certain moments these fluctuations are related to the nature of the weakly compressible sph with the increase in particle resolution this problem has been improved proving that the present procedure has a good convergence fig 13 shows the wave profiles in the splash zone at two typical instants obtained through the present procedure at three particle resolutions and the numerical snapshots are compared with experimental photographs heller et al 2016 the main profiles of the impulse waves can be obtained by using the present procedure at the particle resolution of δx 0 02 m however more details of impulse waves can be obtained by increasing the particle resolution for the subsequent calculations in this section the particle resolution of δx 0 01 m is therefore adopted fig 14 shows the pressure fields and free surface profiles at some typical instants obtained through the present procedure and the numerical snapshots are compared with experimental photographs heller et al 2016 at t 0 45 s the slide is released and moves freely along the ramp fig 14 a after passing through the transition section the slide continues and moves along the flume bottom and an impact crater is generated above the slide fig 14 b c at t 0 84 s the slide stops moving and the first wave crest has left the splash zone fig 14 d after t 1 4 s the second wave is produced by the plunging wave on the ramp fig 14 e f fig 15 shows the free surface profiles at two typical instants obtained with and without the turbulence model and the numerical snapshots are compared with experimental photographs heller et al 2016 as can be seen from the snapshots there are intense movements in the tail and upper water regions of the slide at these two instants the turbulent viscosity produced by the turbulence model in these regions helps to reproduce the free surface profiles correctly 4 3 3 d subaerial landslide the 3 d wave basin experiment for scenario 1 of heller et al 2016 is utilized here to further test the performance of the present procedure in the numerical model the length and width of the basin were 8 m and 6 m respectively this section mainly addresses the motion of the rigid slide and the generation and short distance propagation of impulse waves to achieve a better compromise between the computational load and accuracy a particle resolution of δx 0 02 m resulting in 2 520 190 particles was selected in this section the parameters in the rsmm of this model were k 1400 n 10 and μ 0 18 a workstation with an intel xeon e5 2690 v4 cpu with 128gb of ram was used to run the simulation the simulated time was 6 s and the computation time on 25 kernels was approximately 25 h the displacement and velocity of the slide front versus time obtained through the rsmm are displayed in fig 16 and the sph results are compared with the experimental data obtained by heller et al 2016 it is worth noting that the water can enter the gap between the slide and the transition section in this 3 d numerical simulation which is closer to the experimental condition hence the velocity and displacement of the rigid slide were more consistent with the experimental data the time evolutions of the free surface elevation at a x 0 72 m b x 1 2 m c x 1 8 m and d x 3 6 m obtained through the δ les sph code are displayed in fig 17 and the results are compared with the experimental data in heller et al 2016 the results show that the numerical simulation is in good agreement with the experimental data within an acceptable error range it is found that the wave height decays faster in the 3 d case by compared to the 2 d numerical simulation result at the same location and the wave height at x 3 6 m is only one sixth of that in the 2 d case which agrees with the results reported by yeylaghi et al 2017 fig 18 shows the velocity fields and free surface profiles at some typical instants obtained through the present procedure and the numerical snapshots are compared with experimental photographs heller et al 2016 the rigid slide moves along the ramp from the released position t 0 42 s and then moves along the basin bottom and stops soon after passing through the transition section the impact crater and splash are formed in the impact region as the slide impacts the water body t 0 15 s and the impact crater then further extends t 0 35 s the impact crater collapses at t 0 55 s while highly nonlinear waves are being generated with an up rush in the wake of the rigid slide the primary wave propagates with a typical semicircular shape in 3 d t 0 75 s the propagation radius of the primary wave increases and a smaller secondary wave is then produced by the run down of the previous up rush t 0 95 s the velocity fields of the free surface in the y direction shoreline velocity at t 0 08 0 58 1 08 and 1 58 s are shown in fig 19 compared with the 2 d case the reason for the faster decay of the 3 d wave height is that a part of the energy is transferred into the water wave energy with particle velocities in the y direction ruffini et al 2019 considering figs 18 and 19 it can be seen that before the impact crater collapses t 0 58 s the wave velocity in the y direction is relatively high after the impact crater collapses t 0 58 s the wave velocity in the y direction decreases the normalized turbulent eddy viscosity vt vw fields of the free surface obtained using the turbulence model are shown in fig 20 the results show that the eddy viscosity in the splash zone is three orders of magnitude higher than the laminar viscosity the maximum turbulent eddy viscosity occurs when the slide impacts the still water surface t 0 0 s there is a high degree of turbulence during the slide water interaction which is the most critical stage of wave generation these effects propagate along the circular direction on the free surface and decrease with time 5 conclusions in this article a δ les sph model aimed at studying the generation and long distance propagation of impulse waves more effectively is presented in this model a density diffusion term is added to the continuity equation the particle shifting technique pst is introduced and modified in the motion equation physical viscosity term and the turbulence viscosity term based on a large eddy simulation les were used in the momentum equation the introduction of these correction techniques effectively reduces the numerical diffusion of the sph method and improves its accuracy in modeling the generation and long distance propagation of impulse waves the rigid slide s motion model rsmm was presented to resolve the rigid slide motion on the ramp this model can explicitly calculate the contact force acting on a slide as part of the fluid solution scheme because the direction of the contact force is determined by the gradient of the sph kernel function and is not directly related to the relative direction of the contact object and the shape of the contact surface the rsmm is suitable for simulating the slide motion on various complex shaped ramps and has high applicability several typical landslide experimental cases were selected to test the performance of the new δ les sph code including a 2 d submarine landslide a 2 d subaerial landslide and a 3 d subaerial landslide the numerical results are in good agreement with the experimental data convergence tests of impulse waves generated by submarine and subaerial landslides shows that the solutions of both δ les sph and rsmm convergence the simulation results in the 2 d submarine landslide case showed that the δ les sph method improved the particle distributions in the free surface region fsr and reproduced the vortices reported by other numerical simulations in the 3 d numerical simulation of the subaerial landslide because the wave energy spreads over a larger area in 3 d the decay of waves generated by the rigid slide is larger than that in the 2 d case in addition the normalized turbulence eddy viscosities of the impulse waves generated by the 2 d and 3 d subaerial landslides were also reported the results show a high degree of turbulence in the impact region during the entire slide water interaction process in this article the rsmm is only used to describe the interaction between a single block and the boundaries however it must be emphasized that the rsmm can also simulate the interaction of multiple blocks in addition the δ les sph model presented in this work mainly focused on the stages of rigid landslide impact wave generation and propagation in future research the deformable landslides mode should also be incorporated to further expand the application range of the δ les sph model credit authorship contribution statement guibin zhang conceptualization methodology software writing original draft writing review editing jianyun chen conceptualization methodology supervision youting qi writing original draft writing review editing jing li writing review editing funding acquisition qiang xu writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by the national natural science foundation of china no 51679030 no 52031002 supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103890 appendix b supplementary materials image application 1 appendix a rotating square fluid patch as stated before the modified pst can effectively eliminate nonphysical gaps between the free surface and its vicinity particles caused by the traditional pst in the problems of landslide generated impulse waves in this appendix a widely used numerical test of the rotation of a square fluid patch colagrossi 2005 oger et al 2016 wang et al 2019 was selected to further verify the accuracy of the modified pst in terms of the free surface evolution pressure and energy versus time a square fluid domain with side length l was initialized with a rigid rotation velocity field a 1 u 0 x y ω y v 0 x y ω y where ω denotes the constant angular velocity in this article l 1 m and ω 20 rad s assuming that the flow is incompressible the initial pressure can be solved as follows wang et al 2019 a 2 p 0 x y ρ m n 32 ω 2 m n π 2 n π l 2 m π l 2 sin m π x l sin n π y l where x x l 2 and y y l 2 the series given by eq a 2 converges quickly therefore m 1 3 5 and n 1 3 5 are able to fully approximate the value of p 0 le touzé et al 2013 the initial pressure and velocity fields are shown in fig a 1 in this test the initial density of the water was 1000 kg m3 and the maximum expected velocity throughout the flow field was 2 2 ω l the initial sound velocity was set to c 0 5 2 ω l such that the corresponding mach number was 0 1 the numerical simulation was initialized by the particles distributed with a spatial resolution of l δx 100 wang et al 2019 fig a 2 shows the evolution of free surface shapes and pressure fields of the square fluid patch obtained by using the modified pst compared with the results of the bem le touzé et al 2013 the application of the pst helps suppress the tensile instability caused by the negative pressure to achieve good consistency with the reference result sun et al 2017 owing to the accuracy and stability of the δ les sph method the simulation can be continued beyond the times reported in le touzé et al 2013 however because the pst is not applied to the free surface layer there are some regions of numerical noise in the pressure in the vicinity of the free surface a similar situation also appeared in oger et al 2016 note that if the pst is extended to the free surface and this correction is limited to the tangent direction of the free surface these defects can be effectively eliminated sun et al 2017 but this correction will produce an incorrect free surface in landslide generated impulse wave problems see fig 8 however despite these slight remaining defects the good agreement between the free surface evolution shown in fig a 2 and the results of the bem le touzé et al 2013 demonstrates the reliability of the current method in this study the physical viscosity is replaced by the artificial viscosity used in the traditional sph to consider the real physical viscosity of the fluid the artificial viscosity is applied to the free surface to avoid the numerical instability caused by the violent movement of the free surface fig a 3 shows the free surface shapes of the square fluid patch at different instants with and without surface viscosity it can be seen that the surface viscosity can effectively suppress the tensile instability of the fsr and ensure the accuracy and stability of the calculation fig a 4 presents the evolution of the pressure and kinetic energy at the rotation center of a square fluid patch obtained through the ale riemann sph oger et al 2016 and the δ les sph respectively the pressure results of these two methods are very close but there are some slight differences when tω 4 the pressure fluctuation of the δ les sph method is relatively obvious whereas when tω 4 the pressure fluctuation of the ale riemann sph method is noticeable because the artificial viscosity term is imposed on the total fluid domain the energy loss of the ale riemann sph is slightly greater than that of the δ les sph comparing the results of the δ les sph method with and without the surface viscosity it can be seen that the surface viscosity has a relatively small effect on the evolution of pressure and kinetic energy but it can significantly increase the stability of the free surface 
315,in this article a δ les sph model is presented to study the generation and propagation of impulse waves in this model a density diffusion term is added to the continuity equation to eliminate the numerical high frequency oscillation of the pressure field a particle shifting technique is introduced and modified in the motion equation to improve the accuracy and robustness of the smoothed particle hydrodynamics sph model the physical viscosity term and the turbulence viscosity term based on the large eddy simulation les are used in the momentum equation to calculate the viscous force to predict the rigid slide motion more effectively we propose a rigid slide motion model that considers friction in the δ les sph frame the δ les sph code was implemented in fortran 90 and openmp programming technology was used to improve the calculation efficiency subsequently this parallel sph code was used to simulate subaerial and submarine rigid landslides in 2 d and more realistic 3 d applications the sph results were compared with the experimental data and other numerical results the results show that the proposed model has a good convergence and less numerical dissipation satisfactory results were obtained for the rigid slide motion wave generation and long distance propagation keywords δ les sph landslide generated impulse waves particle shifting technique large eddy simulation rigid slide motion mode 1 introduction landslides are one of the most catastrophic and frequent geological disasters that occur in nature and the impulse waves generated by landslides in reservoirs bays and oceans are essential secondary disasters impulse waves with considerable amplitudes may cause severe damage to water retaining structures and flood agricultural areas resulting in severe consequences for human life and property wang et al 2016 for instance the largest tsunami in recorded history occurred in july 1958 at lituya bay alaska which generated a wave run up of 524 m tajnesaie et al 2018 in october 1963 the vajont landslide in northern italy caused a 240 m high wave that overtopped the dam crest by approximately 70 m and rushed downstream heller et al 2016 yeylaghi et al 2017 the overtopping water destroyed five towns and caused approximately 2000 casualties lin et al 2015 because landslide generated impulse waves are extremely destructive it is of great practical significance to estimate their characteristics accurately physical model experiments and numerical simulations are important for investigating landslide generated impulse waves tan and chen 2017 experiments are performed in both 2 d and 3 d often resulting in generally applicable equations evers et al 2019 such as empirical formulas for the wave height wave period propagation speed wave run up and overtopping fritz et al 2001 ataie ashtiani and nik khah 2008 lin et al al 2015 heller et al 2016 pilvar et al 2019 generally these equations can easily and quickly provide an initial estimate of the most important wave properties in practice evers et al 2019 in addition physical model experiments have great significance for understanding the physical process of landslide generated impulse waves and validating the accuracy of numerical simulations yeylaghi et al 2017 however numerical simulations play increasingly important roles in the research of landslide generated impulse waves to simulate the entire process of the generation propagation and run up of impulse waves both frequency dispersion and nonlinearity should be considered hassan et al 2010 this requires a useful description of such physical phenomena in terms of mathematical equations as well as an appropriate method to solve these equations behrens and dias 2015 the mathematical equations can be categorized into depth averaged equations width averaged equations and fully three dimensional equations in addition based on their ability to simulate dispersive effects these mathematical equations can also be described as nondispersive weakly dispersive and fully dispersive equations yavari ramshe and ataie ashtiani 2016 among these mathematical equations the shallow water equations swes boussinesq water wave equations bwes and navier stokes n s equations are widely used in numerical studies of landslide generated impulse waves wang et al 2016 according to the classification mentioned above swes are depth averaged and nondispersive equations bwes are depth averaged equations and weakly dispersive equations and n s equations are fully three dimensional and fully dispersive equations both swes and bwes are simplifications of the n s equations the former ignore the vertical flow components whereas the latter consider the vertical structure of flow velocities by using a polynomial approximation of the vertical profile of horizontal velocities yavari ramshe and ataie ashtiani 2016 n s equations provide a complete description of fluid wave behavior and they are suitable for complex wave interactions behrens and dias 2015 the above mathematical equations can be solved using two different approaches eulerian and lagrangian methods eulerian methods such as finite difference methods fdm and finite volume methods fvm encounter difficulties in modeling a landslide with complex geometry owing to the use of structured meshes in mesh based lagrangian methods the computational mesh might be severely distorted and frequent time consuming remeshing might be inevitable yavari ramshe and ataie ashtiani 2016 in recent years particle based lagrangian methods such as smoothed particle hydrodynamic sph monaghan 1994 moving particle semi implicit mps ataie ashtiani and farhadi 2006 gotoh and khayyer 2018 khayyer et al 2019a b and the meshless finite element method idelsohn et al 2003 have been extensively employed in the field of fluid flow in these approaches each particle can be tracked in a lagrangian manner without facing the difficulties of mesh deformation shobeyri and afshar 2012 sph is a lagrangian mesh free method developed by lucy 1977 and gingold and monaghan 1977 to study astrophysical applications this method was later extended to hydrodynamics by monaghan 1994 in contrast with the mesh based methods the n s equations can be solved by the sph method without using computational grids or meshes which makes them highly suitable for free surface flows with large deformations wang et al 2016 in addition the problem of numerical diffusion due to the existence of advection terms in the n s equations is eliminated in the sph method shobeyri and afshar 2012 therefore the sph method based on the n s equations has been extensively applied to the numerical simulation of impulse waves generated by landslides ataie ashtiani and shobeyri 2008 capone et al 2010 viroulet et al 2013 farhadi et al 2016 heller et al al 2016 yeylaghi et al 2017 according to different pressure calculation methods the sph method is divided into the weakly compressible sph wcsph ren et al 2015 and incompressible sph isph abbas et al 2018 khayyer et al 2018 yeylaghi et al 2017 zheng et al 2014 wcsph is suitable for efficient simulation of free surface flows due to its explicit numerical algorithm and advantages in computational efficiency parallelization antuono et al 2012 colagrossi et al 2009 however traditional wcsph has the problem of spurious numerical oscillations in pressure δ sph antuono et al 2012 and riemann based sph vila 1999 ben moussa and vila 2000 have recently become popular variants of wcsph oger et al 2016 the advantage of riemann based sph is that no explicit artificial viscosity is used and numerical dissipation is introduced implicitly δ sph has been shown to be reliable and robust in the simulation of complex free surface flows marrone et al 2011 this method has the advantages of a standard sph scheme low cpu cost and easy implementation and it has been widely used in recent years marrone et al 2013 chowdhury et al 2014 meringolo et al 2015 valizadeh et al 2015 vacondio et al 2016 unfortunately there are some unresolved problems in the δ sph method such as tensile instability possible inhomogeneous spatial configurations and numerical dissipation caused by the artificial viscosity this reduces the accuracy and robustness of the δ sph method and limits its application krimi et al 2020 meringolo et al 2019 sun et al 2017 2019 sun et al 2017 developed a δ sph method which introduced a particle shifting technique pst into the δ sph method this method allows for a regular spatial particle configuration through small continuous resettlements in contrast in di mascio et al 2017 modified the δ sph method from the lagrangian perspective of large eddy simulation les antuono et al 2021 this method was further inspected by antono et al 2018 and called δ les sph this method uses physical and turbulent viscosity terms to calculate the viscous forces avoiding the numerical dissipation caused by the use of an artificial viscosity term in this study our interest is mainly focused on the impulse waves generated by subaerial and submarine rigid landslides to solve the problem of faster decay of impulse waves simulated by the conventional sph method violeau and rogers 2016 a δ les sph model with lower numerical dissipation is presented based on the δ les sph and δ sph methods to predict rigid slide motion more effectively we propose a rigid slide motion model rsmm that considers friction in the δ les sph frame the δ les sph code was implemented in the fortran 90 language and openmp programming technology was used to improve the calculation efficiency the compilation environment was visual studio 2013 and inter visual fortran 2013 first the δ les sph code is verified in terms of free surface evolution pressure and energy versus time through a rotating square patch benchmark test case subsequently we used this method to simulate both subaerial and submarine rigid landslide generated impulse waves and discuss numerical convergence slide kinematics wave profiles hydrodynamic pressure and the role of turbulence it is encouraging to find that the slide motion wave profiles and pressure loading agree reasonably well with the experimental data and other numerical results the remainder of this paper is organized as follows the δ les sph scheme is introduced in section 2 the motion model of a rigid slide considering friction and collision is presented in section 3 the test cases simulated in the present work involve a 2 d submarine landslide section 4 1 a 2 d subaerial landslide section 4 2 and a 3 d subaerial landslide section 4 3 finally the conclusions and comments are presented in section 5 2 δ les sph model 2 1 governing equations in this model the fluid is assumed to be weakly compressible and its governing equations in a lagrangian coordinate system include mass conservation momentum conservation the equation of state and the equation of motion 1 d ρ d t ρ u ρ d u d t p f v f b f τ p f ρ d r d t u where ρ u r t p f v f τ and f b denote the density velocity vector position vector time pressure viscous stress vector turbulent stress vector and physical force vector of the fluid respectively in the wcsph the density change of fluid clusters is limited to 1 monaghan 1994 and under such conditions the fluid can be regarded as barotropic marrone et al 2011 under these hypotheses it is possible to adopt a state equation that is only a function of density meringolo et al 2018 the linear equation of state provides a more stable pressure field antuono et al 2012 as follows 2 p c 0 2 ρ ρ 0 the artificial speed c 0 remains unchanged in this work with the following constraint meringolo et al 2018 3 c 0 10 max p m a x ρ 0 u m a x where pmax is the maximum expected pressure of the flow field ρ 0 is the reference value of the density field and umax is the maximum expected velocity of the flow field and rigid slide 2 2 discrete forms when eq 1 is written in the sph formalism an artificial diffusion term presented by molteni and colagrossi 2009 is added to the continuity equation to eliminate the numerical high frequency oscillations in the pressure field the pst considering the flow mach number presented by sun et al 2017 is introduced and modified in the motion equation to improve the accuracy and robustness of the sph model a viscosity term including physical viscosity and turbulent viscosity presented by di mascio et al 2017 is used in the momentum equation to calculate the viscous forces the final governing equation can be discretized as follows 4 d ρ i dt ρ i j u j u i i w ij v j δ h c 0 ψ ij j i w ij v j d u i dt 1 ρ i j p i p j i w ij v j j v eij π ij i w ij v j g d r i dt u i r i r i δ r i p i c 0 2 ρ i ρ 0 v i t m i ρ i where r i denotes the new location vector of particle i after the pst is applied see section 2 4 for more details and vi and mi denote the volume and mass of particle i respectively in eq 4 wij w r i r j h denotes the kernel function which is related to the efficiency precision and stability of the numerical simulation the wendland c2 kernel function was used as follows 5 w q h a d 1 2 q 1 1 2 q 4 0 q 2 0 q 2 where q r i r j h and δx denotes the initial particle spacing h denotes the smoothing length h 2δx and a d 7 4πh 2 in 2 d h 1 5δx and a d 21 16πh 3 in 3 d the diffusion term tends to zero with an increase in the spatial resolution i e h 0 and does not influence the overall evolution of the flow field antuono et al 2012 where 6 ψ ij 2 ρ j ρ i r j r i r j r i 2 ρ i l ρ j l and ρ l is the renormalized density gradient antuono et al 2010 which is defined as 7 ρ i l j ρ j ρ i l i i w ij v j l i j r j r i i w ij v j 1 because the variable range of the parameter δ is very narrow it is regarded as a non adjustable parameter and is set equal to 0 1 sun et al 2017 in addition di mascio et al 2017 proposed a modified diffusion term where δ is no longer a constant but is evaluated at every instant through the gradient of the velocity field this method can reduce and optimize the additional numerical dissipation however violent fluid motion in the slide water impact region of subaerial landslides may lead to excessive δ values making the density field in this region no longer conform to the weakly compressible assumption therefore a more stable diffusion term with a constant δ was selected in this study the physical viscous forces modeled using the artificial viscosity formula presented by monaghan and gingold 1983 can guarantee the conservation of both linear and angular momenta as follows 8 π ij 2 d 2 u i u j r i r j r i r j 2 where d is the spatial dimension the analysis by colagrossi et al 2011 showed that eq 8 has a good consistency at the free surface therefore it is suitable for the viscous force calculation of free surface flows in the δ les sph method the effective viscosity ve of water includes the kinematic viscosity vw and the turbulent viscosity vt the turbulent viscosity vt presented by di mascio et al 2017 is a function of the local and instantaneous flow conditions in particular the harmonic mean value vt ij is used to replace the turbulence viscosity of particles i or j as follows 9 v t c s l les 2 d v t ij 2 v t i v t j v t i v t j where cs 0 12 is the smagorinsky constant and lles is the reference length for the sph filtering procedure which is set equal to the radius of the kernel 2h the quantity d is given by 10 d 2 d d and the formula for the strain rate tensor d is as follows 11 d 1 2 j u j u i l i w ij l i w ij u j u i v j 2 3 particle shifting technique pst the pst based on the isph method was first presented by xu et al 2009 and further developed by lind et al 2012 and khayyer et al 2017 the pst has been shown to redistribute the particles in a more isotropic manner avoiding particle clustering in the compression direction and sparse discretization error in the stretching direction huang et al al 2018 sun et al 2017 proposed a modified pst in which the shifting vector δ r i considering the influence of the mach number ma is reformulated as 12 δ r i cfl ma 2 h i 2 j 1 r w ij w δ x i n i w ij m j ρ i ρ j where the constants are r 0 2 n 4 cfl denotes the courant friedrichs levy constant to control the incorrect shifting of particles in the free surface region fsr sun et al 2017 presented a shifting vector correction method for particles in the fsr this correction aims to maintain the tangential shifting component of particles in the fsr and improve the normal shifting component and to achieve a uniform distribution of the particles in the fsr the final particle shifting vector δ r i is specified as follows 13 δ r i 0 λ i 0 4 and i s f i n i n i δ r i λ i 0 4 and i s f δ r i i s f where sf represents the fsr composed of particles that are at a distance of less than 2h from the free surface i represents the identity tensor λ is the minimum eigenvalue of the tensor l 1 and n i is the normal vector of particle i in the fsr the following two steps must be satisfied to achieve the above purpose 1 accurate identification of free surface particles 2 the normal vector of particles in the fsr is evaluated for more details see marrone et al 2010 however for long time free surface flow problems with confined domains such as landslide generated impulse waves the pst based on eq 13 causes incorrect shifting of particles in the fsr when meeting with a wall boundary leading to incorrect results the pst presented by sun et al 2017 was modified to address the aforementioned problems 1 the pst shut off threshold in fsr is modified from λ 0 4 to λ 0 75 i e the pst correction of particles near the free surface is turned off to avoid nonphysical fluctuations when the concentration gradient is large huang et al 2018 adopted a similar approach when simulating viscous flow problems using the coupled finite particle method fpm 2 for particles with λ 0 75 in fsr in fact it is a skinny free surface layer the artificial viscosity term is added to eliminate unrealistic fluctuations the surface viscosity variables presented by akbari 2017 were adopted 14 v art s α s x 2 u u max u where as is a damping coefficient recommended as unity by akbari 2017 and the trial calculation shows that as 1 0 as adopted in this study can yield better results the artificial viscosity of the internal particle j is defined as a portion of the viscosity of the closest particle i located on the surface boundary i e 15 v art j ψ v art s ψ w ij w ii 3 after the particles shift the first order terms in the taylor series expansion are used to update their velocity pressure and density as follows hashemi et al 2012 16 u i u i δ r i u i p i p i δ r i p i ρ i ρ i δ r i p c 0 2 i the above correction considers the influence of the particles shifting on the density avoids the error of the particle volume caused by only the correction of the particle position and provides a more regular pressure field in appendix a the modified pst is verified in terms of the free surface evolution the pressure and energy versus time through a rotating square patch benchmark test case 2 4 solid boundary in the sph method the precision and robustness of the final simulation results are largely determined by the boundary implementation technology the impervious condition must be considered for a solid boundary moreover for the lower reynolds number scenarios the no slip boundary condition was used the fixed ghost particle technique proposed by marrone et al 2011 and adami et al 2012 is adopted in the present procedure and the pressure of the ghost particle is obtained by interpolation from the neighboring fluid particles as follows 17 p s f p f w sf g a s f ρ f r sf w sf f w sf where the symbol s represents the ghost particle f represents the fluid particle a s represents the acceleration of the ghost particle and g represents the acceleration vector due to gravity ρ s is obtained using the following equation of state 18 ρ s p s c 0 2 ρ 0 by neglecting the viscous force between the fluid particles and adjacent ghost particles the free slip boundary condition can be realized to impose the non slip boundary condition the velocity of the ghost particles in eq 8 is obtained by interpolation of the adjacent fluid particles as follows 19 u v 2 u s f u f w fs f w fs where u s and u f denote the wall velocity and fluid velocity respectively 2 5 time stepping scheme eq 4 is solved by the 4th order runge kutta integration scheme using a frozen diffusive approach antuono et al 2012 the time step δt is restricted by the maximum acceleration of both the moving solid and fluid viscous diffusion and artificial sound speed the time step constraints are expressed as follows sun et al 2017 20 δ t min 0 125 h max a i 0 25 h 2 max v ei cfl h c 0 the first two time step boundaries were obtained by morris et al 1997 and the third time step limit was obtained by monaghan and kos 1999 antuono et al 2012 showed that the dependence of the first two constraints on a specific integration scheme was very weak the second term is based on the usual condition of the explicit fdm simulating viscous diffusion where ve includes the physical turbulent and surface viscosities at sufficiently high resolution or high viscosity this term is usually the main time step constraint however the acoustic constraint is generally the most restrictive for the reynolds number investigated in this study the acoustic constraints can also be expressed as the cfl limitation similar to those in cfd simulations akbari 2017 21 δ t c cfl h c 0 a t δ x u max where δx is the initial particle spacing and at 0 4 which is generally recommended in wcsph violeau and leroy 2015 in our numerical models at 0 25 as obtained from cfl 1 25 3 rigid slide s motion model rsmm in this section an rsmm in δ les sph is presented to resolve the rigid slide motion on the ramp without a prescribed velocity in general slide motion is difficult to predict in advance in the traditional sph model the velocity of the slide as an input parameter must be prescribed according to experimental data monaghan and kos 2000 ataie ashtiani and shobeyri 2008 capone et al 2010 in recent years there have been some methods for resolving the rigid slide motion in the sph scheme for example lin et al 2015 presented a telescopic boundary based on mirror particles to simulate a rigid slide motion yeylaghi et al 2017 presented a technique for implicitly calculating the rigid slide motion by placing a layer of fluid particles between the slide and fixed particles however these methods ignore the influence of the friction force on the rigid slide motion which leads to an overestimation of the rigid slide velocity in numerical simulations alternatively the coupling of dem kesseler et al 2020 and sph is well suited for simulating solid fluid interaction problems canelas et al 2013 tan et al 2018 heller et al 2016 studied the rigid landslide tsunamis based on the open source code dualsphyics v3 1 in which the dem was used to account for the slide ramp interaction tan and chen 2017 proposed a hybrid dem sph model in which a landslide is composed of many solid particles but the rigid slide motion needs to be prescribed tan et al 2018 proposed a block dem sph model to study the rigid slide motion and its generated waves the rigid slide motion is modeled by the block dem by imposing the drag and added mass coefficients along with a block friction angle to address impulse waves generated by rigid landslides more realistically we propose a simpler and more effective rsmm in the wcsph framework generally the forces acting on the rigid slide and determining its motion are the fluid force f f support force f s friction force f μ and gravity g as shown in fig 1 although f s has no direct contribution to the velocity of the rigid slide it determines the value of f μ which has an important influence on the slide motion therefore the accurate calculation of f s is particularly important for a moving rigid slide its velocity is divided into two parts translation and rotation in contrast with a floating body the rigid slide motion is not only affected by the fluid force and gravity but also by the force on the ramp therefore the conservation equations of momentum and moment of inertia of the rigid slide are as follows 22 md u c dt f f f s f μ g id ω c dt t f t s t μ where m i u c and ω c represent the mass of the rigid slide the moment of inertia relative to centroid c translational velocity and rotational velocity respectively fw and tw are the resultant force and the resultant moment respectively as follows 23 f f i fluid j solid p i p j v eij π ij ρ i v i v j i w ij t f i fluid j solid x i x j 2 x c p i p j v eij π ij ρ i v i v j i w ij where x i x j and x c denote the position vectors of particle i particle j and the slide center respectively eq 23 was originally derived and discussed by bouscasse et al 2013 subsequently sun et al 2015 improved the formula of the resultant moment i e x i x j 2 replaced the position of particle j on the slide surface to prevent the calculated value of the resultant moment from being too small to calculate the friction force f μ it is necessary to accurately calculate the contact force f s between the slide and the fixed boundary traditional contact algorithms need to search for the contact surface and its normal direction at each time step for meshless methods in a 3 d space this process is very complicated the meshless contact algorithm presented by vignjevic et al 2006 is selected here to realize the contact effect by exerting a contact force on the sph particles the contact potential function is expressed as follows 24 ϕ x i j ncont m j ρ j k w ij w δ h avg n where ncont represents the number of particles belonging to different objects in the support domain of particle i δhavg represents the average value of sph particle spacing and k and n represent user defined coefficients related to the impact velocity of the object the gradient of eq 24 is discretized by sph to obtain the contact force exerted on particle i zhang et al 2011 as follows 25 f s x i j solid m i ρ i m j ρ j kn w ij n 1 w δ h avg n i w ij where i and j denote moving and fixed boundary particles respectively the direction of the contact force is determined by the gradient of the sph smooth kernel function and is not directly related to the relative direction of the contact object or the shape of the contact surface therefore this method is suitable for calculating the supported force of rigid slides with various complex contact surfaces in the problem of landslide generated by impulse waves the dynamic friction force between the rigid slide and the ramp has a significant influence on the rigid slide motion as a benefit of the explicit calculation of the contact force in eq 25 the dynamic friction force can be calculated the dynamic friction force of particle i is expressed as 26 f μ x i μ f s x i u i u i where μ represents the dynamic friction coefficient f s x i represents the contact resultant force of the rigid slide on the ramp and u i u i denotes the unit vector of the velocity of particle i which is opposite to the direction of the dynamic friction it is worth noting that dynamic friction exists only when u i 0 the u c and ω c of the rigid slide are obtained by the 4th order runge kutta integration scheme in each time step according to eq 22 and the time step is consistent with the fluid time step after obtaining u c and ω c of the centroid of the rigid slide the velocity and acceleration of the slide particle are obtained according to the principle of rigid body kinematics as follows 27 d x i dt u i u i u c ω c x i x c a i d u c dt d ω c dt x i x c ω c u i u c where x i u i and a i denote the position vector velocity and acceleration of the slide particle i respectively 4 numerical tests in this section three classic experimental cases are used to tests the performance of the present procedure including a 2 d submarine landslide a 2 d subaerial landslide and a 3 d subaerial landslide in the 2 d submarine landslide experiment the rigid slide performed a simple linear motion along an inclined ramp an empirical formula for the velocity of the rigid slide was obtained for the subaerial landslides in 2 d and 3 d the ramp includes an arc shaped transition section such that the rigid slide is no longer a simple linear motion which helps to further test the practicability of the rsmm the particle packing algorithm colagrossi et al 2012 was used to initialize the particle distributions in all simulations to prevent nonphysical oscillations after the calculation starts 4 1 2 d submarine landslide in this section the experimental data of heinrich 1992 were selected to test the performance of the δ les sph code in their experiment a submarine rigid wedge with a density of 2000 kg m3 moved down a ramp with a slope of 45 to generate waves the cross section of the rigid wedge is triangular 0 5 m 0 5 m and the geometry of the experiment is shown in fig 2 the still water depth is 1 m and the top of the wedge is 0 01 m below the free surface in this numerical simulation three simulations with particle resolutions of δx 0 02 0 01 and 0 005 m are carried out to study the convergence of the present numerical solution the movement of the rigid wedge was calculated in two ways the first way is to prescribe the velocity of the wedge based on the formula of ataie ashtiani and shobeyri 2008 the vertical component formula for the wedge velocity is as follows 28 v t a tanh b t t 0 4 s v t 0 6 0 4 s t 1 0 s v t 0 t 1 0 s where a and b are constants a 86 b 0 0175 and the wedge is released at t 0 s the second way calculates the movement of the rigid wedge using the rsmm the parameters in the rsmm of this model were k 5 200 000 n 15 and μ 0 01 fig 3 shows the vertical displacement of the rigid wedge versus time obtained by using the rsmm at three particle resolutions and the sph solutions are compared with the experimental data heinrich 1992 dns numerical results abadie et al 2010 and isph numerical results yeylaghi et al 2017 the results show that the three numerical models are in good agreement with the experimental data but the influence of the friction force is ignored in the isph and dns models resulting in the overestimation of the wedge velocity after t 0 8 s because the dynamic friction effect is considered in the rsmm the displacement of the rigid wedge is closer to the experimental results at different particle resolutions the displacement results were very close showing good convergence of the rsmm fig 4 shows the free surface profiles obtained by using the δ les sph and rsmm at three particle resolutions in comparison with the experimental data heinrich 1992 as shown in fig 4 the free surface profiles at the particle resolution of δx 0 02 m are close enough to the experimental data the free profiles at the particle resolution of δx 0 01 m have converged to the experimental data showing good convergence of the δ les sph code therefore the particle resolution of δx 0 01 m is used for subsequent calculations in this section the free surface profiles at two instants a t 0 5 s and b t 1 0 s obtained through the present procedure are shown in fig 5 and the results are compared with the experimental data heinrich 1992 the results show that the free surface profiles obtained by the abovementioned two movement types of the rigid wedge are in good agreement with the experimental data the advantage of the rsmm is that it can effectively predict the slide motion while it can be conveniently added to the sph code and thus it has a strong practical value fig 6 shows snapshots of velocity fields and free surface profiles at some typical instants obtained through the δ les sph code as mentioned by abadie et al 2010 and yeylaghi et al 2017 two waves are generated due to the motion of the rigid wedge in water these two waves obtained by our code are shown in figure 6 the first wave is produced in the process of the rigid wedge moving downward and squeezing the water body continuously fig 6 a d and the second wave is produced by the plunging wave on the ramp fig 6 e f subsequently this wave breaks and the free surface profiles become more complicated fig 6 g h as reported by abadie et al 2010 and yeylaghi et al 2017 in fig 7 the velocity vectors for the particles are colored by their horizontal velocity at t 0 85 1 35 1 75 and 2 0 s studies by abadie et al 2010 and yeylaghi et al 2017 have shown that vortices occur when a rigid wedge moves along an underwater ramp identical vortices were generated in the present numerical simulation for example after the wedge is released a large vortex is produced above its left side this vortex is depicted by the positive and negative horizontal velocities above the left side of the wedge in fig 7 a and labeled vortex 1 two other vortices labeled vortex 2 and vortex 3 are produced after the plunging wave breaks respectively as shown in fig 7 b and c respectively vortex 2 is located in the internal fluid above the rigid wedge and vortex 3 is located in the wave breaking area of the free surface the free surface becomes increasingly complex as the waves break and small vortices are constantly generated in the region near the free surface but vortices 1 and 2 above the wedge always exist as shown in fig 7 d it is important to emphasize that in the les only the larger scale eddies are directly simulated whereas the subgrid turbulent eddies are modeled by space filtering fig 8 depicts the comparison of the pressure fields and particle distributions between the conventional pst and the improved pst for the traditional pst the disordered particle distributions first appear in the fsr near the left boundary fig 8 a these oscillations then expand along the free surface resulting in apparent nonphysical gaps between the free surface and its vicinity particles fig 8 b d this phenomenon also appears in the right half of the calculation model and directly changes the wave profile the nonphysical oscillations in the fsr also affect the pressure fields of the fluid in contrast when the improved pst is applied the more uniform particle distributions can be maintained 4 2 2 d subaerial landslide heller et al 2016 used the experimental setup shown in fig 9 to conduct two different scenarios of rigid landslide generated impulse waves experiments in a 2 d wave flume and a 3 d wave basin the unobstructed area of the flume is 21 0 m length 0 60 m width and the unobstructed area of the wave basin is 20 0 m width 7 4 m length in the present work we carried out numerical simulations of the 2 d experiment sections 4 2 and the 3 d experiment sections 4 3 in scenario 1 detailed experimental parameters can be found in heller et al 2016 the experimental snapshots and data are available at http spheric sph org tests test 11 in this experiment the ramp transition to the tank bottom was circular for both the 2 d flume and 3 d basin which means that the rigid slide did not stop when it reached the slope toe but rather moved along the tank bottom after passing through the transition section this posed a new challenge to the calculation model of the rigid slide motion however there are currently no effective calculation methods yeylaghi et al 2017 used the experimental data to predict the velocity of rigid slides in their simulation heller et al 2016 utilized the dem sph coupled model to calculate the motion of rigid slides on a ramp but the influence of subpressure and friction was considered by artificially reducing the impact velocity of the rigid slides the rsmm was used to simulate the rigid slide motion to test its performance in simulating complex motions the parameters in the rsmm of this model were k 2 300 000 n 15 and μ 0 2 to investigate the convergence of the present procedure to subaerial landslide problems three simulations with particle resolutions of δx 0 02 0 01 and 0 005 m were carried out the displacement and velocity of the slide front versus time obtained through the rsmm at three particle resolutions are displayed in fig 10 and the sph solutions are compared with the experimental data and numerical results of heller et al 2016 the results of the displacement and velocity of the slide are in good agreement at different particle resolutions which shows that the rsmm also has a good convergence for the simulation of complex motions the results obtained through the rsmm are in good agreement with the experimental data but there are slight deviations in the two time periods of 0 08 0 3 s and 0 55 0 99 s i e when the front and end of the slide pass through the transition section respectively this is because the width of the slide in the experiment is slightly smaller than that of the flume and the water can enter the gap between the bottom of the slide and the transition section the water in this region reduces friction and has a subpressure effect heller et al 2016 the combination of these two effects results in a difference between the numerical results and the experimental data the coordinate origin is defined on the slide axis at the intersection of the still water surface and the ramp and the x axis is along the direction of the flume time evolutions of the free surface elevation at a x 1 2 m b x 1 8 m c x 3 6 m and d x 8 4 m obtained through the δ les sph code at three particle resolutions are displayed in fig 11 as well as the sph solutions compared with the experimental data in heller et al 2016 at positions close to the splash zone yavari ramshe and ataie ashtiani 2016 the height and shape of the first wave at three particle resolutions are almost consistent with the experimental data fig 11 a b at positions far from the splash zone fig 11 d the height of the first wave at the particle resolution of δx 0 02 m is lower than the experimental data whereas the other two particle resolutions still maintain high accuracy the results show that the numerical dissipation of the δ les sph model decreases with increasing the particle resolution in hydrodynamic problems in addition to flow field information scholars have paid attention to the pressures loading on the structure in this section two force sensors from fig 9 s1 and s4 are selected to reproduce their pressure loading in the δ les sph model the pressure loading was measured by p s f p f w s f f w s f where the subscripts f and s represent the fluid particles and solid wall particles respectively fig 12 shows the pressure loading on the s1 and s4 of the slide front versus time obtained using the present procedure at three particle resolutions and the results are compared with the experimental data heller et al 2016 the pressure time curves agree well with the experimental data except that the pressure fluctuates significantly at certain moments these fluctuations are related to the nature of the weakly compressible sph with the increase in particle resolution this problem has been improved proving that the present procedure has a good convergence fig 13 shows the wave profiles in the splash zone at two typical instants obtained through the present procedure at three particle resolutions and the numerical snapshots are compared with experimental photographs heller et al 2016 the main profiles of the impulse waves can be obtained by using the present procedure at the particle resolution of δx 0 02 m however more details of impulse waves can be obtained by increasing the particle resolution for the subsequent calculations in this section the particle resolution of δx 0 01 m is therefore adopted fig 14 shows the pressure fields and free surface profiles at some typical instants obtained through the present procedure and the numerical snapshots are compared with experimental photographs heller et al 2016 at t 0 45 s the slide is released and moves freely along the ramp fig 14 a after passing through the transition section the slide continues and moves along the flume bottom and an impact crater is generated above the slide fig 14 b c at t 0 84 s the slide stops moving and the first wave crest has left the splash zone fig 14 d after t 1 4 s the second wave is produced by the plunging wave on the ramp fig 14 e f fig 15 shows the free surface profiles at two typical instants obtained with and without the turbulence model and the numerical snapshots are compared with experimental photographs heller et al 2016 as can be seen from the snapshots there are intense movements in the tail and upper water regions of the slide at these two instants the turbulent viscosity produced by the turbulence model in these regions helps to reproduce the free surface profiles correctly 4 3 3 d subaerial landslide the 3 d wave basin experiment for scenario 1 of heller et al 2016 is utilized here to further test the performance of the present procedure in the numerical model the length and width of the basin were 8 m and 6 m respectively this section mainly addresses the motion of the rigid slide and the generation and short distance propagation of impulse waves to achieve a better compromise between the computational load and accuracy a particle resolution of δx 0 02 m resulting in 2 520 190 particles was selected in this section the parameters in the rsmm of this model were k 1400 n 10 and μ 0 18 a workstation with an intel xeon e5 2690 v4 cpu with 128gb of ram was used to run the simulation the simulated time was 6 s and the computation time on 25 kernels was approximately 25 h the displacement and velocity of the slide front versus time obtained through the rsmm are displayed in fig 16 and the sph results are compared with the experimental data obtained by heller et al 2016 it is worth noting that the water can enter the gap between the slide and the transition section in this 3 d numerical simulation which is closer to the experimental condition hence the velocity and displacement of the rigid slide were more consistent with the experimental data the time evolutions of the free surface elevation at a x 0 72 m b x 1 2 m c x 1 8 m and d x 3 6 m obtained through the δ les sph code are displayed in fig 17 and the results are compared with the experimental data in heller et al 2016 the results show that the numerical simulation is in good agreement with the experimental data within an acceptable error range it is found that the wave height decays faster in the 3 d case by compared to the 2 d numerical simulation result at the same location and the wave height at x 3 6 m is only one sixth of that in the 2 d case which agrees with the results reported by yeylaghi et al 2017 fig 18 shows the velocity fields and free surface profiles at some typical instants obtained through the present procedure and the numerical snapshots are compared with experimental photographs heller et al 2016 the rigid slide moves along the ramp from the released position t 0 42 s and then moves along the basin bottom and stops soon after passing through the transition section the impact crater and splash are formed in the impact region as the slide impacts the water body t 0 15 s and the impact crater then further extends t 0 35 s the impact crater collapses at t 0 55 s while highly nonlinear waves are being generated with an up rush in the wake of the rigid slide the primary wave propagates with a typical semicircular shape in 3 d t 0 75 s the propagation radius of the primary wave increases and a smaller secondary wave is then produced by the run down of the previous up rush t 0 95 s the velocity fields of the free surface in the y direction shoreline velocity at t 0 08 0 58 1 08 and 1 58 s are shown in fig 19 compared with the 2 d case the reason for the faster decay of the 3 d wave height is that a part of the energy is transferred into the water wave energy with particle velocities in the y direction ruffini et al 2019 considering figs 18 and 19 it can be seen that before the impact crater collapses t 0 58 s the wave velocity in the y direction is relatively high after the impact crater collapses t 0 58 s the wave velocity in the y direction decreases the normalized turbulent eddy viscosity vt vw fields of the free surface obtained using the turbulence model are shown in fig 20 the results show that the eddy viscosity in the splash zone is three orders of magnitude higher than the laminar viscosity the maximum turbulent eddy viscosity occurs when the slide impacts the still water surface t 0 0 s there is a high degree of turbulence during the slide water interaction which is the most critical stage of wave generation these effects propagate along the circular direction on the free surface and decrease with time 5 conclusions in this article a δ les sph model aimed at studying the generation and long distance propagation of impulse waves more effectively is presented in this model a density diffusion term is added to the continuity equation the particle shifting technique pst is introduced and modified in the motion equation physical viscosity term and the turbulence viscosity term based on a large eddy simulation les were used in the momentum equation the introduction of these correction techniques effectively reduces the numerical diffusion of the sph method and improves its accuracy in modeling the generation and long distance propagation of impulse waves the rigid slide s motion model rsmm was presented to resolve the rigid slide motion on the ramp this model can explicitly calculate the contact force acting on a slide as part of the fluid solution scheme because the direction of the contact force is determined by the gradient of the sph kernel function and is not directly related to the relative direction of the contact object and the shape of the contact surface the rsmm is suitable for simulating the slide motion on various complex shaped ramps and has high applicability several typical landslide experimental cases were selected to test the performance of the new δ les sph code including a 2 d submarine landslide a 2 d subaerial landslide and a 3 d subaerial landslide the numerical results are in good agreement with the experimental data convergence tests of impulse waves generated by submarine and subaerial landslides shows that the solutions of both δ les sph and rsmm convergence the simulation results in the 2 d submarine landslide case showed that the δ les sph method improved the particle distributions in the free surface region fsr and reproduced the vortices reported by other numerical simulations in the 3 d numerical simulation of the subaerial landslide because the wave energy spreads over a larger area in 3 d the decay of waves generated by the rigid slide is larger than that in the 2 d case in addition the normalized turbulence eddy viscosities of the impulse waves generated by the 2 d and 3 d subaerial landslides were also reported the results show a high degree of turbulence in the impact region during the entire slide water interaction process in this article the rsmm is only used to describe the interaction between a single block and the boundaries however it must be emphasized that the rsmm can also simulate the interaction of multiple blocks in addition the δ les sph model presented in this work mainly focused on the stages of rigid landslide impact wave generation and propagation in future research the deformable landslides mode should also be incorporated to further expand the application range of the δ les sph model credit authorship contribution statement guibin zhang conceptualization methodology software writing original draft writing review editing jianyun chen conceptualization methodology supervision youting qi writing original draft writing review editing jing li writing review editing funding acquisition qiang xu writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this study was supported by the national natural science foundation of china no 51679030 no 52031002 supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103890 appendix b supplementary materials image application 1 appendix a rotating square fluid patch as stated before the modified pst can effectively eliminate nonphysical gaps between the free surface and its vicinity particles caused by the traditional pst in the problems of landslide generated impulse waves in this appendix a widely used numerical test of the rotation of a square fluid patch colagrossi 2005 oger et al 2016 wang et al 2019 was selected to further verify the accuracy of the modified pst in terms of the free surface evolution pressure and energy versus time a square fluid domain with side length l was initialized with a rigid rotation velocity field a 1 u 0 x y ω y v 0 x y ω y where ω denotes the constant angular velocity in this article l 1 m and ω 20 rad s assuming that the flow is incompressible the initial pressure can be solved as follows wang et al 2019 a 2 p 0 x y ρ m n 32 ω 2 m n π 2 n π l 2 m π l 2 sin m π x l sin n π y l where x x l 2 and y y l 2 the series given by eq a 2 converges quickly therefore m 1 3 5 and n 1 3 5 are able to fully approximate the value of p 0 le touzé et al 2013 the initial pressure and velocity fields are shown in fig a 1 in this test the initial density of the water was 1000 kg m3 and the maximum expected velocity throughout the flow field was 2 2 ω l the initial sound velocity was set to c 0 5 2 ω l such that the corresponding mach number was 0 1 the numerical simulation was initialized by the particles distributed with a spatial resolution of l δx 100 wang et al 2019 fig a 2 shows the evolution of free surface shapes and pressure fields of the square fluid patch obtained by using the modified pst compared with the results of the bem le touzé et al 2013 the application of the pst helps suppress the tensile instability caused by the negative pressure to achieve good consistency with the reference result sun et al 2017 owing to the accuracy and stability of the δ les sph method the simulation can be continued beyond the times reported in le touzé et al 2013 however because the pst is not applied to the free surface layer there are some regions of numerical noise in the pressure in the vicinity of the free surface a similar situation also appeared in oger et al 2016 note that if the pst is extended to the free surface and this correction is limited to the tangent direction of the free surface these defects can be effectively eliminated sun et al 2017 but this correction will produce an incorrect free surface in landslide generated impulse wave problems see fig 8 however despite these slight remaining defects the good agreement between the free surface evolution shown in fig a 2 and the results of the bem le touzé et al 2013 demonstrates the reliability of the current method in this study the physical viscosity is replaced by the artificial viscosity used in the traditional sph to consider the real physical viscosity of the fluid the artificial viscosity is applied to the free surface to avoid the numerical instability caused by the violent movement of the free surface fig a 3 shows the free surface shapes of the square fluid patch at different instants with and without surface viscosity it can be seen that the surface viscosity can effectively suppress the tensile instability of the fsr and ensure the accuracy and stability of the calculation fig a 4 presents the evolution of the pressure and kinetic energy at the rotation center of a square fluid patch obtained through the ale riemann sph oger et al 2016 and the δ les sph respectively the pressure results of these two methods are very close but there are some slight differences when tω 4 the pressure fluctuation of the δ les sph method is relatively obvious whereas when tω 4 the pressure fluctuation of the ale riemann sph method is noticeable because the artificial viscosity term is imposed on the total fluid domain the energy loss of the ale riemann sph is slightly greater than that of the δ les sph comparing the results of the δ les sph method with and without the surface viscosity it can be seen that the surface viscosity has a relatively small effect on the evolution of pressure and kinetic energy but it can significantly increase the stability of the free surface 
316,few ensemble streamflow forecasting systems are designed to operate for ephemeral rivers in this study we revise our error model for generating forecast guided stochastic scenarios fogss to produce statistically reliable long range 12 month forecasts for ephemeral rivers fogss features an error model with four stages data transformation bias correction an autoregressive error model and the statistical distribution of residuals we revise the fourth stage of fogss with a parameter estimation method that uses data censoring to account for zero values in both observations and forecasts this allows fogss to produce statistically reliable ensemble forecasts in even highly ephemeral streams with 50 zero flows we apply fogss to conventional ensemble hydrological prediction esp forecasts for 50 australian catchments including 26 ephemeral rivers we show that fogss improves the accuracy of esp forecasts at short lead times while at long lead times fogss forecasts transition to climatology like forecasts fogss forecasts are reliable in ensemble spread at individual lead times and for volumes aggregated over lead times even in highly ephemeral rivers fogss forecasts pave the way for operational long range forecasts in ephemeral rivers meeting a key need for improved water management keywords ephemeral rivers dryland streams long range forecasting esp fogss ensemble prediction 1 introduction ephemeral rivers pose particular problems for ensemble streamflow forecasting they often exhibit highly non linear responses in runoff to rainfall making them difficult to model e g costigan et al 2017 at the same time statistical treatments that are necessary to generate reliable ensembles are complicated by the presence of zero values mcinerney et al 2019 smith et al 2015 smith et al 2010 perhaps as a consequence few streamflow forecasting systems are designed for ephemeral rivers this is despite the clear need for methods that can generate skillful and reliable streamflow forecasts for ephemeral rivers ephemeral rivers drain close to half the earth s surface datry et al 2017 tooth 2000 providing water vital to ecosystems and humans in australia the need for streamflow forecasts in ephemeral rivers is acute ephemeral rivers are a crucial source of water over much of australia for example for irrigated agriculture in the northern and western murray darling basin a vital region in australia s most productive agricultural basin balancing the competing needs of irrigators and ecosystems in water stressed systems such as the murray darling basin is one of australia s most pressing water management challenges e g grafton and wheeler 2018 similarly prospective agricultural development in monsoonal northern australia e g petheram et al 2018 will rely heavily on ephemeral streams streamflow forecasts in particular long range 12 month forecasts that assist in water allocation decisions e g kaune et al 2020 are likely to be beneficial in these and other australian drylands long range forecasts of streamflow are often highly uncertain and thus require ensemble forecasting methods to be most useful to water managers long range ensemble forecasts should 1 be in the form of hydrographs at the monthly time step this enables water managers to i consider forecasts for individual months and ii accumulate forecasts for longer periods e g 6 month totals to understand forecasts at a range of temporal scales 2 be statistically reliable both at individual months and for accumulated volumes at all lead times and at all times of year including for ephemeral rivers 3 be as accurate as possible when skill is available and never less accurate than simple climatology forecasts a property known as coherence after krzysztofowicz 1999 we review existing approaches to ensemble prediction in light of these properties with particular reference to ephemeral rivers among the longest standing methods to produce long range streamflow forecasts are simple regression models that describe a relationship between a predictor e g an estimate of moisture stored in soils and future streamflow these methods have been used for decades in the united states pagano et al 2009 this idea has been extended to more complex bayesian models including the bayesian joint probability bjp modelling approach wang and robertson 2011 wang et al 2009 that underpins australia s national seasonal streamflow forecasting service provided by the bureau of meteorology bom http www bom gov au water ssf the bjp formally accounts for heteroscedasticity the inability to assign a single variance to streamflow parameter uncertainty and crucially zero values enabling it to produce statistically reliable ensemble forecasts for ephemeral rivers as with many statistical models forecasts issued with the bjp are for a single lead time total streamflow for the coming 1 2 or 3 months rather than hydrographs that connect streamflow forecasts at multiple lead times while it is possible to break down 3 month streamflow totals into three 1 month forecasts with the bjp zhao et al 2016 it is difficult to construct long range hydrographs from simple predictor predictand relationships this is in large part because it is difficult to model the temporal properties of streamflow without some form of state variable s e g states that mimic soil moisture stores if temporal properties of individual ensemble members are not realistic then aggregations of the ensemble will not be reliable even if predictions at individual lead times are reliable e g shrestha et al 2015 generating hydrographs is more easily performed with hydrological models the practice of using hydrological models in seasonal streamflow prediction also has a long history ensemble streamflow prediction esp methods have been used since the 1970s day 1985 esp works by initialising a hydrological model with observed meteorological forcings e g rainfall potential evaporation and then generating a forecast by running the model with an ensemble of these meteorological forcings taken from the historical record an ensemble of historical forcings is simple to collate and inherently reliable assuming a stationary climate forecast skill in esp forecasts derives entirely from initial hydrological conditions soil moisture etc i e forcings give no information about future meteorological conditions conversely the ensemble spread in esp forecasts derives entirely from the ensemble of forcings esp forecasts ignore the large uncertainties that arise in the conversion of rainfall to runoff resulting in ensemble streamflow forecasts that are often over confident and thus unreliable wood and schaake 2008 more modern forecasting systems combine ensemble climate forecasts with hydrological models e g arnal et al 2018 crochemore et al 2016 without statistical processing uncertainties in climate forecasts and the simulation of hydrological processes are often incorrectly specified including in highly sophisticated ensemble climate prediction systems yuan et al 2015 zhao et al 2017 that is the ensembles they produce are unreliable most usually they produce ensemble spread that is too narrow the most common method to enforce reliable ensembles from such streamflow forecasting systems is to statistically calibrate them with methods analogous to the model output statistics mos approaches long used in meteorology hemri and klein 2017 pokhrel et al 2013 verkade et al 2017 woldemeskel et al 2018 wood and schaake 2008 however mos approaches suffer from the same limitation described for the statistical forecasting methods above calibration is applied separately at each lead time completely disrupting temporal relationships of ensemble members and thus making it difficult to issue forecasts in the form of hydrographs an alternative approach is to separate forecast uncertainties into those related to climate forcings and those related to hydrological modelling a range of methods already exists to effectively calibrate climate forecasts e g strazzo et al 2019 wang et al 2019 this leaves the challenge of specifying hydrological uncertainties which is the subject of this study we address this challenge with error modelling error models have the crucial advantage over mos methods of preserving the temporal sequences of forecast hydrographs most hydrological error models are developed to predict only one lead time in advance but it is possible to propagate uncertainty through multiple lead times seo et al 2006 we have previously developed the fogss forecast guided stochastic scenarios error model to generate reliable long range to 12 months ensemble forecasts in the form of hydrographs at the monthly time step bennett et al 2016b bennett et al 2017 li et al 2013 fogss is based on three principles i key error model parameters are adjusted by calendar month li et al 2013 liu et al 2020 ii the error model is comprised of several independent stages each addressing a particular aspect of model errors rather than a single complex model bennett et al 2016b bennett et al 2017 li et al 2015 li et al 2016 li et al 2017 iii error model parameters that are estimated for lead one predictions are used to calibrate forecasts to long lead times bennett et al 2016b bennett et al 2017 li et al 2017 we have shown that fogss is able to generate reliable streamflow forecasts to lead times of 12 months across a wide variety of perennial catchments bennett et al 2016b bennett et al 2017 fogss reduces forecast error with an autoregressive model particularly at shorter lead times further the forecasts it produces are coherent that is they are always at least as skillful as climatology forecasts even at long lead times however the success of fogss in ephemeral catchments was mixed and depended on the degree of ephemerality it worked as expected in moderately ephemeral catchments defined as never having any calendar month with 50 zeros but performed poorly in highly ephemeral catchments where some months had 50 zeros bennett et al 2017 fogss was unable to generate reliable ensembles in highly ephemeral rivers sometimes resulting in negative forecast skill with respect to climatology accounting for zeros in hydrological error models is both technically challenging and essential smith et al 2010 showed that for parameter estimation methods that use a likelihood it is not possible to correctly optimise error model parameters for ephemeral rivers without explicitly accounting for zeros they developed a likelihood that accounted for zero values by treating residuals as a mixed discrete continuous distribution conditioned on observations they later complemented this work by treating residuals as autocorrelated ammann et al 2019 smith et al 2015 other error models including fogss use data censoring rather than a mixed discrete continuous distribution to treat the presence of zeros in observations li et al 2016 li et al 2017 mcinerney et al 2019 error models that explicitly handle the presence of zeros in observations generally perform well for modelling errors in cases where i catchments are not more than moderately ephemeral and ii hydrological simulations do not equal zero however because these error models treat residuals as symmetrically distributed around the hydrological model simulation usually after transformation to normalise data they cannot generate 50 zeros wang et al 2020 that is error models that handle zeros only in observations are structurally incapable of reliably simulating errors in highly ephemeral catchments as we describe in detail in section 2 2 for this reason fogss and similar models are unsuitable for generating reliable predictions in highly ephemeral catchments in a recent paper we addressed the problems of error models in highly ephemeral streams wang et al 2020 we used data censoring to establish a likelihood that applies censoring to hydrological simulations as well as observations this likelihood was applied to a simple gaussian error model that assumed uncorrelated residuals and produced reliable simulations even in highly ephemeral rivers however the aims of wang et al 2020 were to improve hydrological simulations and to correctly specify uncertainty in highly ephemeral streams not to produce forecasts at multiple lead times in the present study we adapt the likelihood proposed by wang et al 2020 to work with the fogss error model to produce long range streamflow forecasts in ephemeral rivers we test the revised fogss error model on esp forecasts generated with an experimental hydrological model based streamflow forecasting system developed by the bureau of meteorology woldemeskel et al 2018 to demonstrate the fogss error model s more general applicability we test the forecasts on perennial moderately ephemeral and highly ephemeral rivers the paper is structured as follows the fogss error model is described in section 2 dividing the existing components section 2 1 from the changes made for ephemeral rivers section 2 2 section 3 describes the esp forecasting system to which we apply fogss and the process for generating fogss forecasts is described in section 4 catchments and data are described in section 5 forecast verification methods including our cross validation scheme are described in section 6 and the results of our experiments are presented in section 7 we discuss our findings in section 8 and summarise and conclude the study in section 9 2 fogss error model several terms used in this paper are used in specific ways or are not widely known and we define these in table 1 to assist the reader 2 1 previous fogss error model o censored we briefly review the structure of the o censored fogss error model which we have developed previously through a series of papers bennett et al 2016b bennett et al 2017 li et al 2013 li et al 2015 these papers may be consulted for further detail note that fogss is designed to produce forecasts at the monthly time step forecasts are issued at the beginning of each calendar month i e 12 forecasts per year to a lead time of 12 months 2 1 1 stage 1 data transformation in previous studies using fogss bennett et al 2016b bennett et al 2017 stage 1 has encompassed the estimation of hydrological model parameters however it is possible to apply the fogss error model to a hydrological model that is already calibrated in this study we wish to apply fogss to an existing forecasting setup section 3 and thus stage 1 concerns only the transformation we use the log sinh transformation wang et al 2012 to allow us to treat our errors as normally distributed it is given by 1 z t t f q t 1 b log sinh a c q t b where q t is the observed or simulated monthly streamflow at time t and a and b are parameters c 5 max q o is a standardisation constant where max q o is the maximum of the time series of available streamflow observations the standardisation constant allows a and b to take comparable values across all catchments simplifying the application of bayesian priors for parameter estimation appendix a note that when eq 1 is reversed to back transform z to q any values of z t tf 0 the transformed value of zero are first forced to z t tf 0 before back transformation to ensure streamflow values cannot be negative transformation parameters are estimated only from observations using a maximum a posteriori map estimation section 2 2 2 and these parameters are applied to both observed and simulated streamflow 2 1 2 stage 2 bias correction a bias correction is applied to transformed simulations at each calendar month 2 z 2 t d i z 1 t μ i where i 1 2 12 is the calendar month corresponding to t z 1 t is the log sinh transformed simulation stage 1 and d i and μ i are parameters that vary by month we limit d to 0 d 2 values less than zero imply negative correlations i e very poor hydrological model performance meaning that it is more sensible to ignore simulations d 0 the upper limit is arbitrary and avoids overly large corrections the bias correction parameters are estimated using a method we term least squares after transformation lst detailed in section 2 2 2 the bias correction performs two important tasks first it allows us to treat our residuals as normally distributed with a mean of zero see stage 4 second as d i approaches zero which can occur when hydrological simulations are very poor the bias correction tends to z 2 t μ i that is it returns a constant akin to climatology this is similar in concept to the statistical calibration of forecasts with mos methods as noted in the introduction mos methods apply separate regressions to each lead time breaking the temporal sequence of ensemble members for our application 12 month forecasts issued 12 time per year using mos would mean applying a regression at each forecast issue time and each lead time 12 12 144 regressions by contrast in fogss we estimate the bias correction for each calendar month at lead 1 and apply the bias correction to that calendar month at all lead times a total of 12 regressions this allows us to preserve the temporal sequence from the hydrological model in the forecast section 2 2 3 we have shown in previous papers that this method acts like a meteorological calibration at all lead times returning climatology forecasts when predictions are not skilful bennett et al 2016b bennett et al 2017 2 1 3 stage 3 autoregressive updating in stage 3 we apply a first order autoregressive ar1 that follows the general form 3 z 3 t z 2 t ρ i z o t 1 z 2 t 1 where z 2 is the transformed bias corrected simulation from eq 2 zo t 1 tf qo t 1 is the log sinh transformed value of observed flow and ρ i is a parameter that varies by calendar month which can take values between 0 and 1 the transformation eq 1 can amplify values of z 3 t to be unrealistically large after back transformation and to avoid this problem we restrict z 3 t li et al 2015 4 z 3 t t f min q 3 t q 2 t q o t 1 q 2 t 1 when q o t 1 q 2 t 1 t f max q 3 t q 2 t q o t 1 q 2 t 1 when q o t 1 q 2 t 1 where q 2 t tf 1 z 2 t and q 3 t tf 1 z 3 t are the back transformed values of z 2 t and z 3 t in other words we limit the size of the update to the error in the original domain the ar1 model reduces errors and plays a pivotal role in propagating uncertainty through multiple lead times as described in section 2 2 3 as with the bias correction parameters the ar1 parameters are estimated using a method we term least squares after transformation lst detailed in section 2 2 2 2 2 revising fogss for ephemeral rivers os censored 2 2 1 stage 4 residual modelling previous o censored versions of fogss described only 3 stages with the statistical modelling of residuals included in stage 3 for os censoring we separate out the statistical model of residuals into stage 4 to highlight the improvements to fogss for ephemeral catchments as with previous incarnations of fogss we assume residuals follow a normal distribution 5 z 4 t z 3 t ε t ε t n 0 σ 2 i where z 3 is the transformed bias corrected and updated simulation from eq 4 and σ2 i is the standard deviation of residuals varied by calendar month to generate predictive uncertainty we revise fogss by following wang et al 2020 to use data censoring of both observations and simulations os censoring denote a censoring threshold of qc 0 and let zc tf qc be the transformed censoring threshold if z 3 t zc a new value is assigned to z 3 t by 6 z 3 t φ 1 φ z c m 3 i s 3 i 2 r o t r 0 t u 0 1 where φ is the normal cumulative probability m 3 i and s 3 i are the mean and standard deviation of z 3 t for the calendar month i corresponding to t and u 0 1 is a uniform distribution see section 2 2 2 for the estimation of these parameters we then add noise to z 3 t to give z 4 t by sampling from eq 5 note that when we generate a forecast eqs 5 and 6 are applied at each lead time through a process we call stochastic updating we describe the process of generating a forecast including stochastic updating in section 2 2 3 eq 6 is a crucial advance over the o censored fogss as it allows the error model to produce 50 zero values which we show with a schematic in fig 1 in conventional error models z 3 t can only take values z 3 t zc if we assume a symmetrical error distribution e g eq 5 at most 50 of z 4 t can be less than or equal to zc remember that any values of z 4 t zc are forced to z 4 t zc before back transformation in the os censored fogss error model eq 6 re assigns values of z 3 t zc to z 3 t zc when noise is added according to eq 5 the predictive distribution can now produce 50 zeros after back transformation this enables reliable predictive uncertainty to be generated for highly ephemeral streams wang et al 2020 noted that because of the way many hydrological models are structured their simulations can never reach exactly zero the gr4j model we use in this study can suffer from this issue in such cases z 3 t is always greater than tf 0 meaning eq 6 is never enacted if qc 0 this makes reliable predictive uncertainty impossible to generate for streams with 50 zeros accordingly wang et al 2020 suggested using a censoring threshold slightly above zero to ensure eq 6 is enacted in fogss however this is unnecessary the bias correction stage 2 and ar1 model stage 3 can correct simulations to zero ensuring eq 6 is enacted frequently with a censoring threshold of qc 0 stage 4 parameters are estimated by maximum likelihood 2 2 2 revised parameter inference for os censored fogss fogss error model parameters are estimated at lead one as with a conventional hydrological model calibration that is one set of parameters is applied to all lead times when forecasts are generated error model parameters are inferred independently at each stage in all cases a numerical search method is used to find optimal parameters duan et al 1993 we provide a basic overview of the parameter estimation procedure here a more technical description including equations and priors is given in appendix a stage 1 as noted in section 2 1 1 in previous versions of fogss we have included the estimation of hydrological model parameters with the error model at stage 1 in this study we apply fogss to an existing forecasting setup where the hydrological model is already calibrated section 3 1 thus in stage 1 only the transformation parameters are estimated the stage 1 transformation parameters are estimated by maximum a posteriori map estimation detailed in appendix a note that stage 1 applies a single set of transformation parameters to all data rather than varying transformations by month this means that all forecasts and observations take a common range of values in the transform domain greatly simplifying the ar1 modelling in stage 3 stage 2 and stage 3 it is possible to use maximum likelihood estimation mle for stages 2 and 3 using a likelihood similar to that described for stage 4 below and appendix a however the likelihood is quite computationally intensive further we do not require an estimate of residual uncertainty at stages 2 or 3 as that is the role of stage 4 we can therefore use a simple short cut to reduce computation at stage 2 and stage 3 rather than the likelihood we use least squares of residuals on transformed data abbreviated here to lst to achieve similar results chatterjee and mcleish 1986 li et al 2020 as we normalize our data at stage 1 the assumption of normal residuals that underlies least squares regression will be satisfied lst reduces computation considerably for an observed time series of length t 1 2 t the lst objective minimizes 7 l t 1 t max z o t z c max z s t z c 2 where zs t is the transformed simulation at stage s 2 or s 3 stage 4 stage 4 parameters are estimated by mle using the likelihood proposed by wang et al 2020 the os censored likelihood handles four cases depending on whether the simulation and or observation are equal to zero case 1 observed and simulated flow are both greater than zero i e qo t 0 and q 3 t 0 8 p q 4 t q o t q 3 t n z o t z 3 t σ 2 i case 2 observed flow is zero and simulated flow is greater than zero i e qo t 0 and q 3 t 0 9 p q 4 t q o t 0 q 3 t φ z c z 3 t σ 2 i case 3 observed flow is greater than zero and simulated flow equals zero i e qo t 0 and q 3 t 0 10 p q 4 t q o t q 3 t 0 n z c m 3 i s 3 2 i σ 2 i φ z c s 3 2 i z 3 t σ 2 i m 3 i s 3 2 i σ 2 i σ 2 i s 3 2 i s 3 2 i σ 2 i φ z c m 3 i s 3 2 i case 4 observed and simulated flow are both zero i e qo t 0 and q 3 t 0 11 p q 4 t q o t 0 q 3 t 0 z c φ z c z 3 t σ 2 n z 3 t m 3 i s 3 2 i d z 3 t φ z 3 t m 3 i s 3 2 i where q 3 t and z 3 t tf q 3 t are hydrological model simulations at stage 3 before and after transformation and qo t and zo t tf qo t are observations before and after transformation zc tf qc is the transformed censoring threshold m 3 i and s 3 i are the mean and standard deviation of z 3 and φ is the normal cumulative probability note that each of m 3 i s 3 2 i and σ 2 i take different values for different calendar months see eqs 5 and 6 m 3 i and s 3 2 i are estimated from q 3 t simulations generated by applying the first 3 stages of fogss to the hydrological model simulation see appendix a we denote the residual distribution parameters estimated at stage 4 by θ 4 σ 2 i i 1 2 12 the likelihood is given by 12 l θ 4 t c a s e 1 p q 4 t q o t q 3 t t c a s e 2 p q 4 t q o t 0 q 3 t t c a s e 3 p q 4 t q o t q 3 t 0 t c a s e 4 p q 4 t q o t 0 q 3 t 0 where the cases are described by eqs 8 11 eqs 10 and 11 make this likelihood unique in the literature they treat simulated values as censored data as described in section 2 2 1 the treatment of simulations as censored data at q 3 t 0 enables eq 6 to be enacted making it possible to produce reliable predictive uncertainty in highly ephemeral streams streams that have 50 zero flow in some months we have now described the structure of fogss and parameter estimation procedure for os censoring before we describe the forecast generation procedure for fogss section 4 we describe the esp forecasts that are the key input to the fogss error model section 3 3 esp forecasts esp forecasts are generated with the bom s experimental dynamical seasonal streamflow forecasting system feikema et al 2018 woldemeskel et al 2018 this system is run at a daily time step and in its usual configuration outputs are aggregated to 1 month and 3 month totals before mos post processing is applied for our study we aggregate daily forecasts to a monthly time step to produce streamflow forecasts as 12 month time series the dynamical forecast system usually uses calibrated climate forecasts as forcing to lead times of 90 days while it is possible to generate calibrated daily forcings from climate prediction systems schepen et al 2017 these methods have not been tested to the long lead times 365 days we require in our study esp forcings are inherently reliable and simple to generate and as this study focusses on the development of a hydrological error model esp forcings suffice we discuss the prospects for using calibrated climate forecasts in combination with the fogss error model in section 8 3 1 hydrological model hydrological modelling in the bom s dynamical forecasting system is carried out with the daily gr4j model perrin et al 2003 a simple four parameter conceptual hydrological model that has performed strongly in australian catchments in model intercomparison studies bennett et al 2016a coron et al 2012 it is forced by rainfall and potential evaporation pe for each gauge gr4j is calibrated by minimising the sum of squared errors computed on box cox transformed flows mcinerney et al 2017 following the bom s existing practice calibration is carried out under cross validation as described in section 6 1 to enable fogss parameters to be estimated we run gr4j in simulation mode i e forced with observed rainfall and pe and aggregate daily gr4j simulations to monthly to generate q 1 when running these simulations we warm up gr4j for a minimum of 5 years section 3 3 3 2 rainfall and potential evaporation sampling rainfall and pe forcings in esp forecasts are taken from historical observations we sample esp forcings with a leave 4 years out cross validation procedure i e including the target year which we illustrate by an example to generate a forecast for january dec in 1980 we sample daily january dec rainfall and pe sequences from 1985 1986 2008 each sequence is 1 year long we construct sequences from 29 years of data 1980 2008 we choose 1980 2008 because this is the standard period used by the bom to assess seasonal streamflow forecasting products the choice of leaving out 4 years is less stringent than the cross validation used for the hydrological component of the system section 5 1 rainfall has far less interannual memory than streamflow meaning that a less stringent cross validation is acceptable the specific choice of leaving out four years was taken to generate a 25 member ensemble for both rainfall and pe we ultimately generate 1000 member ensembles with fogss and this process was simplified for an esp ensemble of 25 members because 1000 is evenly divisible by 25 pe and rainfall ensemble members are paired i e if a rainfall ensemble member was sampled from 1985 the matching pe member is also from 1985 rainfall and pe can be anticorrelated so pairing rainfall and pe ensemble members is necessary to ensure realistic outputs from the hydrological model 3 3 generating esp forecasts we issue a forecast at the beginning of every calendar month to generate a forecast we initialise gr4j states by running it with observed forcings from 1 1 1975 onwards a minimum of 5 years warmup for our reforecast period of 1980 2008 at the forecast issue time the hydrological model is then forced with a single member of the rainfall pe ensemble to produce a 1 year forecast of streamflow at the daily time step this process is repeated for all 25 ensemble members to produce q f1 we then aggregate the daily forecasts to the monthly time step before applying the fogss error model 4 generating an os censored fogss forecast for a given forecast issue time t we assume we have available an initialised hydrological model simulation q 1 t at the forecast issue date together with an observation qo t we also have available an uncorrected hydrological forecast q f1 q f1 t 1 q f1 t τ q f1 t 12 for lead times τ 1 2 12 section 3 we apply fogss to each ensemble member separately where q f1 takes hydrological states from the hydrological simulation q 1 t and is then forced with a single member from the ensemble climate forecast we apply the os censored fogss error model to q f1 as follows 1 q f1 is transformed stage 1 eq 1 and bias corrected stage 2 eq 2 to produce z f2 z f2 t 1 z f2 t 2 z f2 t 12 in the same way q 1 t is transformed and bias corrected to produce z 2 t then qo t is transformed to produce zo t 2 for τ 1 we apply eq 3 stage 3 as 13 z f 3 t τ z f 2 t τ ρ i z o t z 2 t where i is the calendar month at time t τ we also apply the restriction eq 4 but we omit this equation for brevity 3 if z f3 t τ zc we assign a new value to z f3 t τ by applying eq 6 14 z f 3 t τ φ 1 φ 0 m 3 i s 3 i 2 r o t τ r 0 t τ u 0 1 4 we then draw a single realisation of noise according to eq 5 stage 4 15 z f 4 t τ z f 3 t τ ε t τ ε t τ n 0 σ 2 i 5 for lead times τ 2 3 12 we no longer have an observation at the previous time step we resolve this by substituting z f4 from eq 15 for zo in eq 13 to give 16 z f 3 t τ z f 2 t τ ρ i z f 4 t τ 1 z f 2 t τ 1 where i is the calendar month at time t τ we again apply the restriction given by eq 4 again omitted for brevity we term the substitution of z f4 for zo stochastic updating which we discuss in more detail below 6 apply eqs 14 and 15 to z f3 t τ from step 5 i e steps 3 and 4 are repeated for values of τ 1 7 repeat steps 5 and 6 for each τ to produce the streamflow forecast ensemble memberz f4 z f4 t 1 z f4 t τ z f4 t 12 8 z f4 is converted to the original domain by reversing eq 1 17 q f 4 t f 1 max z f 4 z c we repeat steps 1 8 for each uncorrected ensemble member q f1 that has been generated with the esp ensemble note that it is straightforward to generate large ensembles by repeating steps 1 8 as many times as necessary for each q f1 i e we can have many streamflow forecast ensemble members q f4 for each climate forecast ensemble member q f1 as noted in section 3 the esp forecasts have 25 ensemble members steps 1 8 are repeated 40 times for each ensemble member to produce a 1000 member streamflow forecast ensemble stochastic updating step 5 efficiently propagates uncertainty through the forecast bennett et al 2016b li et al 2017 estimating forecast uncertainty correctly at lead 1 is straightforward because fogss parameters are estimated at lead 1 however uncertainty should grow appropriately through lead times the interaction of the random noise eq 15 and the ar model eq 16 in stochastic updating allows uncertainty to grow through the forecast uncertainty tends to grow rapidly at short lead times but this growth slows and ultimately stops as the influence of the ar model recedes at longer lead times this is what we are seeking in our uncertainty range narrow uncertainty at short lead times when forecasts are skillful widening uncertainty as skill recedes with lead time and an approximately static uncertainty range approaching a climatological distribution when skill is absent stochastic updating is able to achieve this whilst retaining the temporal features of the hydrograph generated by gr4j 5 data we assess esp and fogss forecasts at 50 sites from a range of climates around australia fig 2 we classify these sites into three categories of ephemerality based on observed flows at the monthly time step 1 perennial no month has 5 zero flows 24 sites 2 moderately ephemeral some months have 5 zero flow with no months 50 zero flow 20 sites 3 highly ephemeral some months have 50 zero flow 6 sites from these 50 sites we select the 3 sites one from each category shown in fig 3 to illustrate model performance in more detail note that the degree of ephemerality in the sense of zero flows is not replicated in the gr4j simulations while it is technically possible for gr4j to produce zero flows for particular combinations of states parameters in practice this rarely occurs i e like a lot of hydrological models it tends not to produce zeros for the 26 ephemeral catchments tested here simulations were never zero daily flow data are extracted from water data online http www bom gov au waterdata rainfall and potential evaporation pe are taken from the gridded awap data set australian water availability project jones et al 2009 http www csiro au awap awap produces daily estimates of rainfall interpolated from gauges to a 5 km grid pe estimates from awap are at a monthly time step we disaggregate these to daily estimates by simple linear interpolation catchment estimates of rainfall and pe are calculated by areal averaging of awap grid cells that intersect with each catchment we use data for the period 01 01 1980 31 12 2012 which covers the 1980 2008 period used by the bureau of meteorology to assess all its seasonal streamflow forecasting products we use the 01 01 1980 31 12 2012 period to estimate parameters section 2 2 2 and generate climatology reference forecasts section 6 2 under buffered cross validation section 6 1 to ensure a consistent 4 year buffer for all years 6 forecast verification 6 1 cross validation scheme all forecast verification is carried out under a buffered leave one year out cross validation scheme with a buffer of 4 years the cross validation scheme is best described with an example to attain gr4j and fogss parameters for 2000 we omit data from 2000 and the succeeding 4 years 2000 2004 the buffer is necessary to avoid informing the parameter estimation with rainfall information from the target year 2000 which can influence observed streamflow in subsequent years through catchment memory 6 2 verification scores we focus on two probabilistic verification metrics the probability integral transform pit to measure ensemble reliability and the continuous ranked probability score crps to measure forecast accuracy gneiting and katzfuss 2014 reliability measures the appropriateness of the ensemble spread it should not be too wide underconfident nor too narrow overconfident crps measures both accuracy and reliability but in the context of this study it is not strongly sensitive to reliability this is because the benefits of the new os censored fogss method are mainly that it produces more reliable forecasts at very low flow as crps is averaged over a range of forecasts it tends to be more sensitive to errors in larger events than to the reliability of low flow months a pit value is calculated for each forecast by 18 p t f t q o t q o t 0 u 0 1 f 0 q o t 0 where f t is the cumulative distribution function cdf of the forecast ensemble at time t a set of forecasts at t 1 2 t is reliable if pit values p p 1 p 2 p t are uniformly distributed we check this by plotting pit values against a standard uniform variate we refer to these plots as pit plots for brevity when pit values follow the diagonal in pit plots the forecasting system is perfectly reliable the treatment of pit values at qo 0 in eq 18 is necessary to allow pit values to follow a uniform distribution in the presence of zero values wang and robertson 2011 we refer to pit values calculated when qo 0 as pseudo pit values uniformity of pit values can be summarised with the α index renard et al 2010 the α index describes the tendency of pit values to deviate from the diagonal in pit plots 19 α 1 2 n t 1 t p t p u t pu t is the theoretical value corresponding to p t α ranges between 0 unreliable and 1 perfectly reliable because it reduces pit diagrams to a single value α allows easy comparison between catchments and lead times crps is given by 20 c m 1 t t 1 t f t x h q o t x 2 d x where f t is the cdf of the forecast ensemble at time t and h is the heaviside step function in this study we wish to compare the performance of esp forecasts with m 25 ensemble members to fogss forecasts with m 1000 ensemble members when the cdf of the forecast is estimated empirically from an ensemble crps calculations are sensitive to ensemble size with greater errors occurring in smaller ensembles e g zamo and naveau 2018 ferro et al 2008 derived an unbiased estimator for crps for cases where ensemble members are exchangeable 21 c m m m 1 m m 1 c m where cm is calculated on ensembles of m 1000 with eq 20 and cm is an estimate for the smaller ensemble size m 25 crps is commonly presented as a skill score where forecast accuracy of a forecasting system is compared with a reference forecast 22 c r p s s 1 c m fct c m ref crpss ranges from worst performance to 1 best performance with values near zero indicating the forecast performs similarly to the reference we use climatology forecasts as our reference climatology forecasts are generated by randomly drawing 1000 realisations from a log sinh transformed normal distribution fitted to each calendar month we use the bjp to fit the log sinh transformation following the data and cross validation scheme described in sections 5 and 6 1 the bjp generates reliable distributions even where many zeros are present wang and robertson 2011 we also assess the skill of volume forecasts accumulated over multiple months to calculate the climatology reference forecasts in these cases we first accumulate volumes from the observed record and then generate a climatology as described above to assess the significance of skill we bootstrap eqs 20 22 with 500 repeats when 97 5 of bootstrapped crpss values are positive negative we consider the forecasts to be significantly skilful negatively skilful 7 results 7 1 reliability reliability of esp and fogss forecasts for a dry month is shown in fig 4 for the three example catchments all 50 catchments are presented in fig s1 perfectly reliable forecasts follow the 1 1 line in the pit diagrams as foreshadowed in the introduction esp forecasts are often overconfident the pit diagram is s shaped because they do not consider uncertainties in the conversion of rainfall to runoff e g uncertainties in model states structure and or streamflow observations overconfidence is particularly prevalent for the dry months when rainfall is low and streamflow results primarily from catchment stores draining rainfall accrued in previous often wetter months this means forcing uncertainty has little bearing on overall uncertainty at shorter lead times forecast uncertainty in dry months is dominated by uncertainty in initial hydrological conditions esp reliability is considerably better for wetter months fig 5 than for drier months in wetter months rainfall forcings are often a dominant source of uncertainty and thus esp ensembles do a reasonably good job of representing total uncertainty both previous and new fogss methods o censoring and os censoring respectively correct overconfidence in the esp ensembles in many cases producing reliable forecasts at short and long lead times in most instances improvements are most striking in dry months fig 4 where poor reliability in esp is markedly improved by fogss even in wetter months however we can see small improvements in reliability after fogss is applied at lead 1 in the perennial elizabeth creek catchment fig 5a six observations are below the esp forecast ensemble these points fall on the bottom of the vertical axis while these are technically within the kolmogorov smirnoff confidence intervals to have six forecasts of 29 that completely miss an observation is evidence of a poorly performing forecast fogss completely corrects this problem fig 5d the benefits of os censoring over o censoring are apparent at longer lead times in dry months in the highly ephemeral joyce catchment fig 4f i fogss with os censoring produces reliable ensemble forecasts in the highly ephemeral joyce river catchment in a month with 60 zeros fig 4f regardless of lead time for o censoring at lead 1 the forecasts are slightly underconfident ensembles are too wide signified by the transposed s shape of the pit diagram at lead 6 the forecasts are increasingly positively biased a result of accumulated instances of underconfident forecasts at multiple lead times we note that o censoring still performs reasonably well in this catchment but this is less true of other catchments as discussed in the next paragraph the improved performance of os censoring over o censoring becomes more evident in highly ephemeral months when we summarise reliability at a range of lead times fig 6 both o censored and os censored versions of fogss markedly outperform esp at short lead times especially in highly ephemeral rivers esp forecasts tend to become more reliable closer to the ideal value of 1 with lead time because uncertainties from the forcings explain a large proportion of total uncertainty at long lead times the benefits of os censoring over o censoring are marked in months with 50 zeros at longer lead times fig 6 bottom panel os censoring allows fogss to maintain reliability in even highly ephemeral months to long lead times whereas the reliability of o censored fogss forecasts drops with lead time as instances of underconfidence positive bias accumulate consistent with wang et al 2020 we do not expect and do not see strong differences in skill or the reliability of accumulated volumes between o censored and os censored fogss forecasts we therefore concentrate on os censored forecasts in the remaining figures as stated in the introduction a key advantage of forecasts in the form of time series is that they can be summed to produce total volume forecasts reliability of total volume forecasts is not ensured by reliability at individual lead times it can only be guaranteed if hydrographs in the ensemble have realistic temporal properties demargne et al 2014 fig 7 shows that esp forecasts can achieve reasonably reliable 12 month aggregations but reliability falls away for shorter aggregation periods irrespective of ephemerality fogss forecasts of aggregated values are strongly reliable and reliability is consistent across different aggregation periods and across different catchments reliability of aggregated volumes in highly ephemeral catchments is slightly less than that of perennial and moderately ephemeral rivers but is still high α 0 8 in a large majority of cases where α 1 is perfect reliability 7 2 accuracy and skill while esp forecasts can be skilful to multiple lead times they are beset by statistically significant negative skill in many months and lead times irrespective of catchment ephemerality fig 8 significant negative skills are present in jul oct and feb in elizabeth creek aug nov dec and feb in the collie river and dec feb and mar in joyces creek fogss forecasts by contrast virtually always produce positively skillful forecasts at short lead times and neutrally skilful forecasts i e similarly skilful to climatology at longer lead times the one exception in june at lead 5 in the collie catchment where os censored fogss produces significant negative skill but the esp forecasts do not this is consistent with the findings of our previous work in perennial and moderately ephemeral catchments bennett et al 2016b bennett et al 2017 it confirms that stages 2 and 3 of fogss substantially improve biases and reduce errors at short lead times respectively fig 8 also shows that os censored fogss forecasts for the highly ephemeral joyces creek catchment are now positively or neutrally skilful in all months this is also true of other highly ephemeral catchments fogss improves skill of esp forecasts for 85 of highly ephemeral months used in this study fig s4 indeed fogss almost always improves esp forecasts often substantially with few exceptions fig 8 figs s3 s4 for example negative skills in the perennial elizabeth creek in aug oct are completely removed fig 8 and earlier lead times for these months are now significantly skilful similar improvements are evident for nov dec in the moderately ephemeral collie river and for feb mar in the highly ephemeral joyce creek some positive skills are caused by poor performance of the reference forecast a notable example is the significant positive skill of both esp and fogss forecasts for january for joyces creek even to very long lead times in this case the bjp produces a very wide climatology ensemble for january this is caused by one very large event in the streamflow record in what is usually a dry month which affects the fit of the log sinh transformation by the bjp fogss is less affected because in fogss we fit the transformation to data from all months the bjp s poor performance in this case is highly unusual more often fitting climatology distributions by month leads to more accurate forecasts further fitting the transformation to all months in fogss sometimes leads to a poorly fitting transformation at individual months in exceptional cases this can result in negative skill in fogss forecasts e g forecasts for nov in the 922001a gauge fig s4 there is one notable exception to fogss improving esp forecasts in the collie river strongly negative skill has been introduced by fogss at lead 1 in feb and follows a diagonal to lead 4 in may these negative skills are not statistically significant but demonstrating their cause is instructive fig 9 shows how negative forecast skill is introduced by fogss for the collie river negative skill for the lead 1 feb forecasts is caused by a single large overestimation of streamflow in 1982 fig 9a and this also causes negative skill at lead 2 mar forecasts through to lead 4 may forecasts the large overestimation in feb 1982 is due to the underestimation of a very large and unseasonal streamflow event in jan 1982 driven by tropical cyclone bruno http www bom gov au cyclone history bruno shtml fig 9b shows that this has virtually no impact on the esp forecast for lead 1 feb or the subsequent lead times the ar1 model in fogss however corrects forecasts for feb 1982 up dramatically fig 9c following the mismatch in simulations and observations in jan 1982 under strict cross validation poor performance of a calibrated hydrological model can be difficult to avoid for isolated extreme events in addition the ar1 model in fogss exacerbates the poor performance of the hydrological model in this instance however while the ar1 model exacerbates poor model performance in this instance as well as a few other isolated instances in fig s4 the ar1 model overwhelmingly improves forecast accuracy in the vast majority of cases e g in elizabeth creek for may oct fig 10 removing negative skills at long lead times has considerable benefits for the accuracy of aggregated volume forecasts fig 11 skill at short lead times can carry through the entire volume forecast resulting in fogss forecasts that can be skillful even for 12 month aggregations including in highly ephemeral catchments fogss forecasts for 6 month aggregations are very often skillful irrespective of ephemerality as with individual lead times fogss forecasts of aggregated volumes are almost always more skilful than esp forecasts of aggregated volumes 8 discussion with the addition of the data censoring treatment described in this study fogss now produces 12 month streamflow forecasts at the monthly time step that are reliable in highly ephemeral rivers forecasts are in the form of an ensemble of time series where each ensemble member can be aggregated to produce ensemble forecasts of aggregated volumes forecasts are reliable at individual lead times and for aggregated volumes as with previous versions of fogss forecasts are almost always more skilful than esp forecasts crucially as skill declines with lead time forecasts become neutrally skillful this allows aggregated volume forecasts to be skillful even to very long e g 6 month aggregation periods these properties remove many of the barriers to the use of long range ensemble streamflow forecasts in ephemeral rivers we have shown in other work that fogss forecasts can improve the management of dams turner et al 2017 and the allocation of water kaune et al 2020 and these benefits can now be realised for highly ephemeral rivers this study reaffirms that it is possible to use fogss error model parameters estimated at lead 1 analogous to a hydrological model calibration to calibrate forecasts to multiple lead times crucially this allows forecasts to be represented as a hydrograph rather than a set of discrete probability distributions at each lead time this is possible through the use of stochastic updating stochastic updating assumes that for a given month the autocorrelation properties and error distributions at lead 1 hold at all lead times this assumption is not guaranteed to hold and accordingly fogss cannot enforce reliability at each month lead time in the way that statistical methods can although we have shown that in practice it almost always does it is possible then that statistical forecasts that account for zero values like the bjp wang and robertson 2011 will produce more reliable forecasts at discrete lead times noting again that there is no clear method to generate hydrographs with statistical methods in future work we plan to compare climate forced os censored fogss forecasts with statistical forecasts generated with the bjp where we adapt bjp forecasting methods to produce monthly forecasts to 12 months we note that there are aspects of the fogss error model that may still be improved for example mcinerney et al 2019 found that they could achieve slightly sharper predictions using a fixed parameter box cox transformation instead of a log sinh transformation in ephemeral rivers conversely the log sinh transformation performs strongly in perennial catchments in comparison to other transformations mcinerney et al 2017 wang et al 2012 it is therefore possible that a different transformation may improve the properties of the fogss ensemble in ephemeral rivers in this study we have used uninformative forcings to drive our streamflow forecasts fogss completely separates uncertainties in hydrological modelling from uncertainties in forcings so it is relatively straightforward to include informative forcings from seasonal climate forecasts however to ensure reliable streamflow forecasts forcings must also be reliable only then can uncertainties from forcings and hydrological models sum to correctly represent total forecast uncertainty in addition forcings should be coherent i e at least as skilful as climatology to ensure that streamflow forecast skill does not become negative at long lead times esp forcings are inherently reliable and coherent but this is not necessarily true of climate forecasts e g peng et al 2014 schepen et al 2016 strazzo et al 2019 wang et al 2019 thus climate forecasts should only be used with fogss after they have been formally statistically calibrated for which a number of methods are available manzanas et al 2019 sansom et al 2016 schepen and wang 2014 siegert and stephenson 2019 simple bias corrections do not ensure reliability or coherence and are not suitable for calibrating forecasts zhao et al 2017 in our previous applications of fogss we have used calibrated climate forecasts as forcings and forecasts were reliable in perennial and moderately ephemeral catchments bennett et al 2016b bennett et al 2017 however these studies differed from the present one in that they used a hydrological model run at the monthly time step not at the daily time step calibrating climate forecasts at a monthly time step is much more straightforward than at the daily time step as monthly data are far less noisy while it is technically possible to generate calibrated daily climate forecasts schepen et al 2017 these methods have not been tested to the very long lead times i e 365 days used in our study in addition propagating uncertainty with stochastic updating as used in fogss is more difficult over many lead times bennett et al 2021 li et al 2020 and is likely to require further development to produce forecasts for 365 lead times compared to the 12 lead times in this study testing and further development of daily climate forecast calibration methods and error modelling to very long lead times are thus clear targets for future research fogss is not yet in operational use but offers an attractive means for a future operational long range streamflow forecasting system as we have shown os censoring works across all catchment types in perennial catchments censoring is not enacted while in ephemeral catchments it plays an important role this means that a single method can be applied to all catchment types a clear advantage for operations further we have shown that fogss is effective as a bolt on corrective to esp forecasts in this case for a hydrological model calibrated using an independent procedure as esp forecasts are widely used in operational forecasting fogss can be easily applied to improve these forecasts correcting esp forecasts is also attractive as esp can be readily adapted to accept calibrated climate forecast inputs in other words because fogss is premised on the idea of separating the uncertainties in climate forecasts from uncertainties in hydrological modelling this makes any fogss operational system highly modular climate forecasts can be updated improved independently of hydrological models and vice versa we note also that fogss is highly computationally efficient often a key consideration for operationalisation on a standard desktop computer it takes 2 minutes to estimate parameters for the 29 year estimation period used in this study while it takes at most a few seconds to generate a 12 month forecast with 1000 ensemble members 9 summary and conclusions this study further develops the fogss forecast guided stochastic scenarios method to generate long range 12 month streamflow forecasts for use in highly ephemeral rivers forecasts are in the form of an ensemble of time series at the monthly time step each ensemble member can be summed to produce an ensemble of aggregated volume forecasts we combine the basic staged structure of the fogss error model with a data censoring method that is applied to both observations and simulations the data censoring method treats both modelled and simulated flow as censored data when they are equal to zero this allows fogss to generate reliable ensemble forecasts in highly ephemeral rivers which can cease to flow 50 of the time in some months we test the new version of fogss on 50 catchments of which 26 are ephemeral fogss forecasts are generally highly skillful at short lead times compared to climatology and very often more skillful than conventional esp ensemble streamflow prediction forecasts at longer lead times fogss forecasts are coherent that is never less skillful than climatology which cannot be guaranteed by esp forecasts forecasts are reliable irrespective if they are issued for highly ephemeral 50 zeros or perennial 5 zeros months forecasts perform similarly in highly ephemeral moderately ephemeral and perennial catchments in both skill and reliability these improvements pave the way for operational long range forecasts in ephemeral rivers meeting a key need for improved water management credit authorship contribution statement james c bennett methodology conceptualization investigation validation visualization software writing original draft q j wang conceptualization methodology writing review editing david e robertson methodology conceptualization software writing review editing robert bridgart software julien lerat methodology data curation writing review editing ming li methodology conceptualization writing review editing kelvin michael supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was conducted on the traditional lands of the boonwurrung and wurundjeri peoples of the kulin nation we acknowledge their continuing custodianship of their lands and the rivers that flow through them and pay our respects to their elders past and present we also acknowledge the traditional custodians of the catchments and rivers used in this study this research was supported by the water information research and development alliance wirada between the bureau of meteorology and csiro land water and arc linkage project lp170100922 thanks to elisabeth vogel and richard laugesen both bureau of meteorology for helpful comments on the manuscript all data and model runs used in this paper are available from csiro s data access portal at https doi org 10 25919 s767 q790 matlab and c code used to generate simulations and forecasts and to verify forecasts are available on request license conditions apply supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103891 appendix b supplementary materials image application 1 appendix a parameter estimation for each stage stage 1 maximum a posteriori map estimation is used to estimate the transformation parameters in eq 1 we assume that transformed observed streamflow follows a normal distribution a1 z o n m s 2 in eq 1 and eq a1 a total of four parameters a b m and s are estimated the four parameters are reparameterised to log a log b m s and log s respectively to make it more numerically efficient to find a map solution our parameter set is then θ1 log a log b m s log a the likelihood is given by a2 l θ 1 p θ 1 t j z o t c q o t n z o t m s 2 where j z o t c q o t is the jacobian a3 j z o t c q o t coth a b c q o t with a standardization constant c 5 max q o and p θ1 is a prior a4 p θ 1 p log a p m s p log s p log b where a5 p log a 1 log a 0 a6 p m s 1 a7 p log s 1 and a8 p log b n 0 1 2 the priors in eqs a5 a7 are uninformative the prior on log b eq a8 encourages values closer to zero which in our experience is a good starting point if the datum at time t is a censored value i e qo t 0 the term j z o t c q o t n z o t m s 2 in eq a2 is replaced with the normal cumulative probability φ zc m s 2 where zc tf 0 is the log sinh transformed value of zero stage 2 parameters in eq 2 θ 2 d i μ i i 1 2 12 are estimated by minimizing the lst objective eq 7 stage 3 the θ 3 ρ i i 1 2 12 parameter in eq 3 is estimated by minimizing the lst objective eq 7 stage 4 we first estimate m 3 i and s 3 2 i to do this we generate a streamflow simulation q 3 by applying stages 1 3 to the hydrological model simulation we extract the simulated streamflow for each calendar month from q 3 and then use the map procedure from stage 1 to estimate m 3 i s 3 2 i keeping a and b fixed from the stage 1 estimation we can then use maximum likelihood estimation to infer θ 4 σ 2 i i 1 2 12 with the likelihood specified in eq 12 note that no closed form is available for case 4 eq 11 and thus it requires a monte carlo integration for details of this integration see wang et al 2020 
316,few ensemble streamflow forecasting systems are designed to operate for ephemeral rivers in this study we revise our error model for generating forecast guided stochastic scenarios fogss to produce statistically reliable long range 12 month forecasts for ephemeral rivers fogss features an error model with four stages data transformation bias correction an autoregressive error model and the statistical distribution of residuals we revise the fourth stage of fogss with a parameter estimation method that uses data censoring to account for zero values in both observations and forecasts this allows fogss to produce statistically reliable ensemble forecasts in even highly ephemeral streams with 50 zero flows we apply fogss to conventional ensemble hydrological prediction esp forecasts for 50 australian catchments including 26 ephemeral rivers we show that fogss improves the accuracy of esp forecasts at short lead times while at long lead times fogss forecasts transition to climatology like forecasts fogss forecasts are reliable in ensemble spread at individual lead times and for volumes aggregated over lead times even in highly ephemeral rivers fogss forecasts pave the way for operational long range forecasts in ephemeral rivers meeting a key need for improved water management keywords ephemeral rivers dryland streams long range forecasting esp fogss ensemble prediction 1 introduction ephemeral rivers pose particular problems for ensemble streamflow forecasting they often exhibit highly non linear responses in runoff to rainfall making them difficult to model e g costigan et al 2017 at the same time statistical treatments that are necessary to generate reliable ensembles are complicated by the presence of zero values mcinerney et al 2019 smith et al 2015 smith et al 2010 perhaps as a consequence few streamflow forecasting systems are designed for ephemeral rivers this is despite the clear need for methods that can generate skillful and reliable streamflow forecasts for ephemeral rivers ephemeral rivers drain close to half the earth s surface datry et al 2017 tooth 2000 providing water vital to ecosystems and humans in australia the need for streamflow forecasts in ephemeral rivers is acute ephemeral rivers are a crucial source of water over much of australia for example for irrigated agriculture in the northern and western murray darling basin a vital region in australia s most productive agricultural basin balancing the competing needs of irrigators and ecosystems in water stressed systems such as the murray darling basin is one of australia s most pressing water management challenges e g grafton and wheeler 2018 similarly prospective agricultural development in monsoonal northern australia e g petheram et al 2018 will rely heavily on ephemeral streams streamflow forecasts in particular long range 12 month forecasts that assist in water allocation decisions e g kaune et al 2020 are likely to be beneficial in these and other australian drylands long range forecasts of streamflow are often highly uncertain and thus require ensemble forecasting methods to be most useful to water managers long range ensemble forecasts should 1 be in the form of hydrographs at the monthly time step this enables water managers to i consider forecasts for individual months and ii accumulate forecasts for longer periods e g 6 month totals to understand forecasts at a range of temporal scales 2 be statistically reliable both at individual months and for accumulated volumes at all lead times and at all times of year including for ephemeral rivers 3 be as accurate as possible when skill is available and never less accurate than simple climatology forecasts a property known as coherence after krzysztofowicz 1999 we review existing approaches to ensemble prediction in light of these properties with particular reference to ephemeral rivers among the longest standing methods to produce long range streamflow forecasts are simple regression models that describe a relationship between a predictor e g an estimate of moisture stored in soils and future streamflow these methods have been used for decades in the united states pagano et al 2009 this idea has been extended to more complex bayesian models including the bayesian joint probability bjp modelling approach wang and robertson 2011 wang et al 2009 that underpins australia s national seasonal streamflow forecasting service provided by the bureau of meteorology bom http www bom gov au water ssf the bjp formally accounts for heteroscedasticity the inability to assign a single variance to streamflow parameter uncertainty and crucially zero values enabling it to produce statistically reliable ensemble forecasts for ephemeral rivers as with many statistical models forecasts issued with the bjp are for a single lead time total streamflow for the coming 1 2 or 3 months rather than hydrographs that connect streamflow forecasts at multiple lead times while it is possible to break down 3 month streamflow totals into three 1 month forecasts with the bjp zhao et al 2016 it is difficult to construct long range hydrographs from simple predictor predictand relationships this is in large part because it is difficult to model the temporal properties of streamflow without some form of state variable s e g states that mimic soil moisture stores if temporal properties of individual ensemble members are not realistic then aggregations of the ensemble will not be reliable even if predictions at individual lead times are reliable e g shrestha et al 2015 generating hydrographs is more easily performed with hydrological models the practice of using hydrological models in seasonal streamflow prediction also has a long history ensemble streamflow prediction esp methods have been used since the 1970s day 1985 esp works by initialising a hydrological model with observed meteorological forcings e g rainfall potential evaporation and then generating a forecast by running the model with an ensemble of these meteorological forcings taken from the historical record an ensemble of historical forcings is simple to collate and inherently reliable assuming a stationary climate forecast skill in esp forecasts derives entirely from initial hydrological conditions soil moisture etc i e forcings give no information about future meteorological conditions conversely the ensemble spread in esp forecasts derives entirely from the ensemble of forcings esp forecasts ignore the large uncertainties that arise in the conversion of rainfall to runoff resulting in ensemble streamflow forecasts that are often over confident and thus unreliable wood and schaake 2008 more modern forecasting systems combine ensemble climate forecasts with hydrological models e g arnal et al 2018 crochemore et al 2016 without statistical processing uncertainties in climate forecasts and the simulation of hydrological processes are often incorrectly specified including in highly sophisticated ensemble climate prediction systems yuan et al 2015 zhao et al 2017 that is the ensembles they produce are unreliable most usually they produce ensemble spread that is too narrow the most common method to enforce reliable ensembles from such streamflow forecasting systems is to statistically calibrate them with methods analogous to the model output statistics mos approaches long used in meteorology hemri and klein 2017 pokhrel et al 2013 verkade et al 2017 woldemeskel et al 2018 wood and schaake 2008 however mos approaches suffer from the same limitation described for the statistical forecasting methods above calibration is applied separately at each lead time completely disrupting temporal relationships of ensemble members and thus making it difficult to issue forecasts in the form of hydrographs an alternative approach is to separate forecast uncertainties into those related to climate forcings and those related to hydrological modelling a range of methods already exists to effectively calibrate climate forecasts e g strazzo et al 2019 wang et al 2019 this leaves the challenge of specifying hydrological uncertainties which is the subject of this study we address this challenge with error modelling error models have the crucial advantage over mos methods of preserving the temporal sequences of forecast hydrographs most hydrological error models are developed to predict only one lead time in advance but it is possible to propagate uncertainty through multiple lead times seo et al 2006 we have previously developed the fogss forecast guided stochastic scenarios error model to generate reliable long range to 12 months ensemble forecasts in the form of hydrographs at the monthly time step bennett et al 2016b bennett et al 2017 li et al 2013 fogss is based on three principles i key error model parameters are adjusted by calendar month li et al 2013 liu et al 2020 ii the error model is comprised of several independent stages each addressing a particular aspect of model errors rather than a single complex model bennett et al 2016b bennett et al 2017 li et al 2015 li et al 2016 li et al 2017 iii error model parameters that are estimated for lead one predictions are used to calibrate forecasts to long lead times bennett et al 2016b bennett et al 2017 li et al 2017 we have shown that fogss is able to generate reliable streamflow forecasts to lead times of 12 months across a wide variety of perennial catchments bennett et al 2016b bennett et al 2017 fogss reduces forecast error with an autoregressive model particularly at shorter lead times further the forecasts it produces are coherent that is they are always at least as skillful as climatology forecasts even at long lead times however the success of fogss in ephemeral catchments was mixed and depended on the degree of ephemerality it worked as expected in moderately ephemeral catchments defined as never having any calendar month with 50 zeros but performed poorly in highly ephemeral catchments where some months had 50 zeros bennett et al 2017 fogss was unable to generate reliable ensembles in highly ephemeral rivers sometimes resulting in negative forecast skill with respect to climatology accounting for zeros in hydrological error models is both technically challenging and essential smith et al 2010 showed that for parameter estimation methods that use a likelihood it is not possible to correctly optimise error model parameters for ephemeral rivers without explicitly accounting for zeros they developed a likelihood that accounted for zero values by treating residuals as a mixed discrete continuous distribution conditioned on observations they later complemented this work by treating residuals as autocorrelated ammann et al 2019 smith et al 2015 other error models including fogss use data censoring rather than a mixed discrete continuous distribution to treat the presence of zeros in observations li et al 2016 li et al 2017 mcinerney et al 2019 error models that explicitly handle the presence of zeros in observations generally perform well for modelling errors in cases where i catchments are not more than moderately ephemeral and ii hydrological simulations do not equal zero however because these error models treat residuals as symmetrically distributed around the hydrological model simulation usually after transformation to normalise data they cannot generate 50 zeros wang et al 2020 that is error models that handle zeros only in observations are structurally incapable of reliably simulating errors in highly ephemeral catchments as we describe in detail in section 2 2 for this reason fogss and similar models are unsuitable for generating reliable predictions in highly ephemeral catchments in a recent paper we addressed the problems of error models in highly ephemeral streams wang et al 2020 we used data censoring to establish a likelihood that applies censoring to hydrological simulations as well as observations this likelihood was applied to a simple gaussian error model that assumed uncorrelated residuals and produced reliable simulations even in highly ephemeral rivers however the aims of wang et al 2020 were to improve hydrological simulations and to correctly specify uncertainty in highly ephemeral streams not to produce forecasts at multiple lead times in the present study we adapt the likelihood proposed by wang et al 2020 to work with the fogss error model to produce long range streamflow forecasts in ephemeral rivers we test the revised fogss error model on esp forecasts generated with an experimental hydrological model based streamflow forecasting system developed by the bureau of meteorology woldemeskel et al 2018 to demonstrate the fogss error model s more general applicability we test the forecasts on perennial moderately ephemeral and highly ephemeral rivers the paper is structured as follows the fogss error model is described in section 2 dividing the existing components section 2 1 from the changes made for ephemeral rivers section 2 2 section 3 describes the esp forecasting system to which we apply fogss and the process for generating fogss forecasts is described in section 4 catchments and data are described in section 5 forecast verification methods including our cross validation scheme are described in section 6 and the results of our experiments are presented in section 7 we discuss our findings in section 8 and summarise and conclude the study in section 9 2 fogss error model several terms used in this paper are used in specific ways or are not widely known and we define these in table 1 to assist the reader 2 1 previous fogss error model o censored we briefly review the structure of the o censored fogss error model which we have developed previously through a series of papers bennett et al 2016b bennett et al 2017 li et al 2013 li et al 2015 these papers may be consulted for further detail note that fogss is designed to produce forecasts at the monthly time step forecasts are issued at the beginning of each calendar month i e 12 forecasts per year to a lead time of 12 months 2 1 1 stage 1 data transformation in previous studies using fogss bennett et al 2016b bennett et al 2017 stage 1 has encompassed the estimation of hydrological model parameters however it is possible to apply the fogss error model to a hydrological model that is already calibrated in this study we wish to apply fogss to an existing forecasting setup section 3 and thus stage 1 concerns only the transformation we use the log sinh transformation wang et al 2012 to allow us to treat our errors as normally distributed it is given by 1 z t t f q t 1 b log sinh a c q t b where q t is the observed or simulated monthly streamflow at time t and a and b are parameters c 5 max q o is a standardisation constant where max q o is the maximum of the time series of available streamflow observations the standardisation constant allows a and b to take comparable values across all catchments simplifying the application of bayesian priors for parameter estimation appendix a note that when eq 1 is reversed to back transform z to q any values of z t tf 0 the transformed value of zero are first forced to z t tf 0 before back transformation to ensure streamflow values cannot be negative transformation parameters are estimated only from observations using a maximum a posteriori map estimation section 2 2 2 and these parameters are applied to both observed and simulated streamflow 2 1 2 stage 2 bias correction a bias correction is applied to transformed simulations at each calendar month 2 z 2 t d i z 1 t μ i where i 1 2 12 is the calendar month corresponding to t z 1 t is the log sinh transformed simulation stage 1 and d i and μ i are parameters that vary by month we limit d to 0 d 2 values less than zero imply negative correlations i e very poor hydrological model performance meaning that it is more sensible to ignore simulations d 0 the upper limit is arbitrary and avoids overly large corrections the bias correction parameters are estimated using a method we term least squares after transformation lst detailed in section 2 2 2 the bias correction performs two important tasks first it allows us to treat our residuals as normally distributed with a mean of zero see stage 4 second as d i approaches zero which can occur when hydrological simulations are very poor the bias correction tends to z 2 t μ i that is it returns a constant akin to climatology this is similar in concept to the statistical calibration of forecasts with mos methods as noted in the introduction mos methods apply separate regressions to each lead time breaking the temporal sequence of ensemble members for our application 12 month forecasts issued 12 time per year using mos would mean applying a regression at each forecast issue time and each lead time 12 12 144 regressions by contrast in fogss we estimate the bias correction for each calendar month at lead 1 and apply the bias correction to that calendar month at all lead times a total of 12 regressions this allows us to preserve the temporal sequence from the hydrological model in the forecast section 2 2 3 we have shown in previous papers that this method acts like a meteorological calibration at all lead times returning climatology forecasts when predictions are not skilful bennett et al 2016b bennett et al 2017 2 1 3 stage 3 autoregressive updating in stage 3 we apply a first order autoregressive ar1 that follows the general form 3 z 3 t z 2 t ρ i z o t 1 z 2 t 1 where z 2 is the transformed bias corrected simulation from eq 2 zo t 1 tf qo t 1 is the log sinh transformed value of observed flow and ρ i is a parameter that varies by calendar month which can take values between 0 and 1 the transformation eq 1 can amplify values of z 3 t to be unrealistically large after back transformation and to avoid this problem we restrict z 3 t li et al 2015 4 z 3 t t f min q 3 t q 2 t q o t 1 q 2 t 1 when q o t 1 q 2 t 1 t f max q 3 t q 2 t q o t 1 q 2 t 1 when q o t 1 q 2 t 1 where q 2 t tf 1 z 2 t and q 3 t tf 1 z 3 t are the back transformed values of z 2 t and z 3 t in other words we limit the size of the update to the error in the original domain the ar1 model reduces errors and plays a pivotal role in propagating uncertainty through multiple lead times as described in section 2 2 3 as with the bias correction parameters the ar1 parameters are estimated using a method we term least squares after transformation lst detailed in section 2 2 2 2 2 revising fogss for ephemeral rivers os censored 2 2 1 stage 4 residual modelling previous o censored versions of fogss described only 3 stages with the statistical modelling of residuals included in stage 3 for os censoring we separate out the statistical model of residuals into stage 4 to highlight the improvements to fogss for ephemeral catchments as with previous incarnations of fogss we assume residuals follow a normal distribution 5 z 4 t z 3 t ε t ε t n 0 σ 2 i where z 3 is the transformed bias corrected and updated simulation from eq 4 and σ2 i is the standard deviation of residuals varied by calendar month to generate predictive uncertainty we revise fogss by following wang et al 2020 to use data censoring of both observations and simulations os censoring denote a censoring threshold of qc 0 and let zc tf qc be the transformed censoring threshold if z 3 t zc a new value is assigned to z 3 t by 6 z 3 t φ 1 φ z c m 3 i s 3 i 2 r o t r 0 t u 0 1 where φ is the normal cumulative probability m 3 i and s 3 i are the mean and standard deviation of z 3 t for the calendar month i corresponding to t and u 0 1 is a uniform distribution see section 2 2 2 for the estimation of these parameters we then add noise to z 3 t to give z 4 t by sampling from eq 5 note that when we generate a forecast eqs 5 and 6 are applied at each lead time through a process we call stochastic updating we describe the process of generating a forecast including stochastic updating in section 2 2 3 eq 6 is a crucial advance over the o censored fogss as it allows the error model to produce 50 zero values which we show with a schematic in fig 1 in conventional error models z 3 t can only take values z 3 t zc if we assume a symmetrical error distribution e g eq 5 at most 50 of z 4 t can be less than or equal to zc remember that any values of z 4 t zc are forced to z 4 t zc before back transformation in the os censored fogss error model eq 6 re assigns values of z 3 t zc to z 3 t zc when noise is added according to eq 5 the predictive distribution can now produce 50 zeros after back transformation this enables reliable predictive uncertainty to be generated for highly ephemeral streams wang et al 2020 noted that because of the way many hydrological models are structured their simulations can never reach exactly zero the gr4j model we use in this study can suffer from this issue in such cases z 3 t is always greater than tf 0 meaning eq 6 is never enacted if qc 0 this makes reliable predictive uncertainty impossible to generate for streams with 50 zeros accordingly wang et al 2020 suggested using a censoring threshold slightly above zero to ensure eq 6 is enacted in fogss however this is unnecessary the bias correction stage 2 and ar1 model stage 3 can correct simulations to zero ensuring eq 6 is enacted frequently with a censoring threshold of qc 0 stage 4 parameters are estimated by maximum likelihood 2 2 2 revised parameter inference for os censored fogss fogss error model parameters are estimated at lead one as with a conventional hydrological model calibration that is one set of parameters is applied to all lead times when forecasts are generated error model parameters are inferred independently at each stage in all cases a numerical search method is used to find optimal parameters duan et al 1993 we provide a basic overview of the parameter estimation procedure here a more technical description including equations and priors is given in appendix a stage 1 as noted in section 2 1 1 in previous versions of fogss we have included the estimation of hydrological model parameters with the error model at stage 1 in this study we apply fogss to an existing forecasting setup where the hydrological model is already calibrated section 3 1 thus in stage 1 only the transformation parameters are estimated the stage 1 transformation parameters are estimated by maximum a posteriori map estimation detailed in appendix a note that stage 1 applies a single set of transformation parameters to all data rather than varying transformations by month this means that all forecasts and observations take a common range of values in the transform domain greatly simplifying the ar1 modelling in stage 3 stage 2 and stage 3 it is possible to use maximum likelihood estimation mle for stages 2 and 3 using a likelihood similar to that described for stage 4 below and appendix a however the likelihood is quite computationally intensive further we do not require an estimate of residual uncertainty at stages 2 or 3 as that is the role of stage 4 we can therefore use a simple short cut to reduce computation at stage 2 and stage 3 rather than the likelihood we use least squares of residuals on transformed data abbreviated here to lst to achieve similar results chatterjee and mcleish 1986 li et al 2020 as we normalize our data at stage 1 the assumption of normal residuals that underlies least squares regression will be satisfied lst reduces computation considerably for an observed time series of length t 1 2 t the lst objective minimizes 7 l t 1 t max z o t z c max z s t z c 2 where zs t is the transformed simulation at stage s 2 or s 3 stage 4 stage 4 parameters are estimated by mle using the likelihood proposed by wang et al 2020 the os censored likelihood handles four cases depending on whether the simulation and or observation are equal to zero case 1 observed and simulated flow are both greater than zero i e qo t 0 and q 3 t 0 8 p q 4 t q o t q 3 t n z o t z 3 t σ 2 i case 2 observed flow is zero and simulated flow is greater than zero i e qo t 0 and q 3 t 0 9 p q 4 t q o t 0 q 3 t φ z c z 3 t σ 2 i case 3 observed flow is greater than zero and simulated flow equals zero i e qo t 0 and q 3 t 0 10 p q 4 t q o t q 3 t 0 n z c m 3 i s 3 2 i σ 2 i φ z c s 3 2 i z 3 t σ 2 i m 3 i s 3 2 i σ 2 i σ 2 i s 3 2 i s 3 2 i σ 2 i φ z c m 3 i s 3 2 i case 4 observed and simulated flow are both zero i e qo t 0 and q 3 t 0 11 p q 4 t q o t 0 q 3 t 0 z c φ z c z 3 t σ 2 n z 3 t m 3 i s 3 2 i d z 3 t φ z 3 t m 3 i s 3 2 i where q 3 t and z 3 t tf q 3 t are hydrological model simulations at stage 3 before and after transformation and qo t and zo t tf qo t are observations before and after transformation zc tf qc is the transformed censoring threshold m 3 i and s 3 i are the mean and standard deviation of z 3 and φ is the normal cumulative probability note that each of m 3 i s 3 2 i and σ 2 i take different values for different calendar months see eqs 5 and 6 m 3 i and s 3 2 i are estimated from q 3 t simulations generated by applying the first 3 stages of fogss to the hydrological model simulation see appendix a we denote the residual distribution parameters estimated at stage 4 by θ 4 σ 2 i i 1 2 12 the likelihood is given by 12 l θ 4 t c a s e 1 p q 4 t q o t q 3 t t c a s e 2 p q 4 t q o t 0 q 3 t t c a s e 3 p q 4 t q o t q 3 t 0 t c a s e 4 p q 4 t q o t 0 q 3 t 0 where the cases are described by eqs 8 11 eqs 10 and 11 make this likelihood unique in the literature they treat simulated values as censored data as described in section 2 2 1 the treatment of simulations as censored data at q 3 t 0 enables eq 6 to be enacted making it possible to produce reliable predictive uncertainty in highly ephemeral streams streams that have 50 zero flow in some months we have now described the structure of fogss and parameter estimation procedure for os censoring before we describe the forecast generation procedure for fogss section 4 we describe the esp forecasts that are the key input to the fogss error model section 3 3 esp forecasts esp forecasts are generated with the bom s experimental dynamical seasonal streamflow forecasting system feikema et al 2018 woldemeskel et al 2018 this system is run at a daily time step and in its usual configuration outputs are aggregated to 1 month and 3 month totals before mos post processing is applied for our study we aggregate daily forecasts to a monthly time step to produce streamflow forecasts as 12 month time series the dynamical forecast system usually uses calibrated climate forecasts as forcing to lead times of 90 days while it is possible to generate calibrated daily forcings from climate prediction systems schepen et al 2017 these methods have not been tested to the long lead times 365 days we require in our study esp forcings are inherently reliable and simple to generate and as this study focusses on the development of a hydrological error model esp forcings suffice we discuss the prospects for using calibrated climate forecasts in combination with the fogss error model in section 8 3 1 hydrological model hydrological modelling in the bom s dynamical forecasting system is carried out with the daily gr4j model perrin et al 2003 a simple four parameter conceptual hydrological model that has performed strongly in australian catchments in model intercomparison studies bennett et al 2016a coron et al 2012 it is forced by rainfall and potential evaporation pe for each gauge gr4j is calibrated by minimising the sum of squared errors computed on box cox transformed flows mcinerney et al 2017 following the bom s existing practice calibration is carried out under cross validation as described in section 6 1 to enable fogss parameters to be estimated we run gr4j in simulation mode i e forced with observed rainfall and pe and aggregate daily gr4j simulations to monthly to generate q 1 when running these simulations we warm up gr4j for a minimum of 5 years section 3 3 3 2 rainfall and potential evaporation sampling rainfall and pe forcings in esp forecasts are taken from historical observations we sample esp forcings with a leave 4 years out cross validation procedure i e including the target year which we illustrate by an example to generate a forecast for january dec in 1980 we sample daily january dec rainfall and pe sequences from 1985 1986 2008 each sequence is 1 year long we construct sequences from 29 years of data 1980 2008 we choose 1980 2008 because this is the standard period used by the bom to assess seasonal streamflow forecasting products the choice of leaving out 4 years is less stringent than the cross validation used for the hydrological component of the system section 5 1 rainfall has far less interannual memory than streamflow meaning that a less stringent cross validation is acceptable the specific choice of leaving out four years was taken to generate a 25 member ensemble for both rainfall and pe we ultimately generate 1000 member ensembles with fogss and this process was simplified for an esp ensemble of 25 members because 1000 is evenly divisible by 25 pe and rainfall ensemble members are paired i e if a rainfall ensemble member was sampled from 1985 the matching pe member is also from 1985 rainfall and pe can be anticorrelated so pairing rainfall and pe ensemble members is necessary to ensure realistic outputs from the hydrological model 3 3 generating esp forecasts we issue a forecast at the beginning of every calendar month to generate a forecast we initialise gr4j states by running it with observed forcings from 1 1 1975 onwards a minimum of 5 years warmup for our reforecast period of 1980 2008 at the forecast issue time the hydrological model is then forced with a single member of the rainfall pe ensemble to produce a 1 year forecast of streamflow at the daily time step this process is repeated for all 25 ensemble members to produce q f1 we then aggregate the daily forecasts to the monthly time step before applying the fogss error model 4 generating an os censored fogss forecast for a given forecast issue time t we assume we have available an initialised hydrological model simulation q 1 t at the forecast issue date together with an observation qo t we also have available an uncorrected hydrological forecast q f1 q f1 t 1 q f1 t τ q f1 t 12 for lead times τ 1 2 12 section 3 we apply fogss to each ensemble member separately where q f1 takes hydrological states from the hydrological simulation q 1 t and is then forced with a single member from the ensemble climate forecast we apply the os censored fogss error model to q f1 as follows 1 q f1 is transformed stage 1 eq 1 and bias corrected stage 2 eq 2 to produce z f2 z f2 t 1 z f2 t 2 z f2 t 12 in the same way q 1 t is transformed and bias corrected to produce z 2 t then qo t is transformed to produce zo t 2 for τ 1 we apply eq 3 stage 3 as 13 z f 3 t τ z f 2 t τ ρ i z o t z 2 t where i is the calendar month at time t τ we also apply the restriction eq 4 but we omit this equation for brevity 3 if z f3 t τ zc we assign a new value to z f3 t τ by applying eq 6 14 z f 3 t τ φ 1 φ 0 m 3 i s 3 i 2 r o t τ r 0 t τ u 0 1 4 we then draw a single realisation of noise according to eq 5 stage 4 15 z f 4 t τ z f 3 t τ ε t τ ε t τ n 0 σ 2 i 5 for lead times τ 2 3 12 we no longer have an observation at the previous time step we resolve this by substituting z f4 from eq 15 for zo in eq 13 to give 16 z f 3 t τ z f 2 t τ ρ i z f 4 t τ 1 z f 2 t τ 1 where i is the calendar month at time t τ we again apply the restriction given by eq 4 again omitted for brevity we term the substitution of z f4 for zo stochastic updating which we discuss in more detail below 6 apply eqs 14 and 15 to z f3 t τ from step 5 i e steps 3 and 4 are repeated for values of τ 1 7 repeat steps 5 and 6 for each τ to produce the streamflow forecast ensemble memberz f4 z f4 t 1 z f4 t τ z f4 t 12 8 z f4 is converted to the original domain by reversing eq 1 17 q f 4 t f 1 max z f 4 z c we repeat steps 1 8 for each uncorrected ensemble member q f1 that has been generated with the esp ensemble note that it is straightforward to generate large ensembles by repeating steps 1 8 as many times as necessary for each q f1 i e we can have many streamflow forecast ensemble members q f4 for each climate forecast ensemble member q f1 as noted in section 3 the esp forecasts have 25 ensemble members steps 1 8 are repeated 40 times for each ensemble member to produce a 1000 member streamflow forecast ensemble stochastic updating step 5 efficiently propagates uncertainty through the forecast bennett et al 2016b li et al 2017 estimating forecast uncertainty correctly at lead 1 is straightforward because fogss parameters are estimated at lead 1 however uncertainty should grow appropriately through lead times the interaction of the random noise eq 15 and the ar model eq 16 in stochastic updating allows uncertainty to grow through the forecast uncertainty tends to grow rapidly at short lead times but this growth slows and ultimately stops as the influence of the ar model recedes at longer lead times this is what we are seeking in our uncertainty range narrow uncertainty at short lead times when forecasts are skillful widening uncertainty as skill recedes with lead time and an approximately static uncertainty range approaching a climatological distribution when skill is absent stochastic updating is able to achieve this whilst retaining the temporal features of the hydrograph generated by gr4j 5 data we assess esp and fogss forecasts at 50 sites from a range of climates around australia fig 2 we classify these sites into three categories of ephemerality based on observed flows at the monthly time step 1 perennial no month has 5 zero flows 24 sites 2 moderately ephemeral some months have 5 zero flow with no months 50 zero flow 20 sites 3 highly ephemeral some months have 50 zero flow 6 sites from these 50 sites we select the 3 sites one from each category shown in fig 3 to illustrate model performance in more detail note that the degree of ephemerality in the sense of zero flows is not replicated in the gr4j simulations while it is technically possible for gr4j to produce zero flows for particular combinations of states parameters in practice this rarely occurs i e like a lot of hydrological models it tends not to produce zeros for the 26 ephemeral catchments tested here simulations were never zero daily flow data are extracted from water data online http www bom gov au waterdata rainfall and potential evaporation pe are taken from the gridded awap data set australian water availability project jones et al 2009 http www csiro au awap awap produces daily estimates of rainfall interpolated from gauges to a 5 km grid pe estimates from awap are at a monthly time step we disaggregate these to daily estimates by simple linear interpolation catchment estimates of rainfall and pe are calculated by areal averaging of awap grid cells that intersect with each catchment we use data for the period 01 01 1980 31 12 2012 which covers the 1980 2008 period used by the bureau of meteorology to assess all its seasonal streamflow forecasting products we use the 01 01 1980 31 12 2012 period to estimate parameters section 2 2 2 and generate climatology reference forecasts section 6 2 under buffered cross validation section 6 1 to ensure a consistent 4 year buffer for all years 6 forecast verification 6 1 cross validation scheme all forecast verification is carried out under a buffered leave one year out cross validation scheme with a buffer of 4 years the cross validation scheme is best described with an example to attain gr4j and fogss parameters for 2000 we omit data from 2000 and the succeeding 4 years 2000 2004 the buffer is necessary to avoid informing the parameter estimation with rainfall information from the target year 2000 which can influence observed streamflow in subsequent years through catchment memory 6 2 verification scores we focus on two probabilistic verification metrics the probability integral transform pit to measure ensemble reliability and the continuous ranked probability score crps to measure forecast accuracy gneiting and katzfuss 2014 reliability measures the appropriateness of the ensemble spread it should not be too wide underconfident nor too narrow overconfident crps measures both accuracy and reliability but in the context of this study it is not strongly sensitive to reliability this is because the benefits of the new os censored fogss method are mainly that it produces more reliable forecasts at very low flow as crps is averaged over a range of forecasts it tends to be more sensitive to errors in larger events than to the reliability of low flow months a pit value is calculated for each forecast by 18 p t f t q o t q o t 0 u 0 1 f 0 q o t 0 where f t is the cumulative distribution function cdf of the forecast ensemble at time t a set of forecasts at t 1 2 t is reliable if pit values p p 1 p 2 p t are uniformly distributed we check this by plotting pit values against a standard uniform variate we refer to these plots as pit plots for brevity when pit values follow the diagonal in pit plots the forecasting system is perfectly reliable the treatment of pit values at qo 0 in eq 18 is necessary to allow pit values to follow a uniform distribution in the presence of zero values wang and robertson 2011 we refer to pit values calculated when qo 0 as pseudo pit values uniformity of pit values can be summarised with the α index renard et al 2010 the α index describes the tendency of pit values to deviate from the diagonal in pit plots 19 α 1 2 n t 1 t p t p u t pu t is the theoretical value corresponding to p t α ranges between 0 unreliable and 1 perfectly reliable because it reduces pit diagrams to a single value α allows easy comparison between catchments and lead times crps is given by 20 c m 1 t t 1 t f t x h q o t x 2 d x where f t is the cdf of the forecast ensemble at time t and h is the heaviside step function in this study we wish to compare the performance of esp forecasts with m 25 ensemble members to fogss forecasts with m 1000 ensemble members when the cdf of the forecast is estimated empirically from an ensemble crps calculations are sensitive to ensemble size with greater errors occurring in smaller ensembles e g zamo and naveau 2018 ferro et al 2008 derived an unbiased estimator for crps for cases where ensemble members are exchangeable 21 c m m m 1 m m 1 c m where cm is calculated on ensembles of m 1000 with eq 20 and cm is an estimate for the smaller ensemble size m 25 crps is commonly presented as a skill score where forecast accuracy of a forecasting system is compared with a reference forecast 22 c r p s s 1 c m fct c m ref crpss ranges from worst performance to 1 best performance with values near zero indicating the forecast performs similarly to the reference we use climatology forecasts as our reference climatology forecasts are generated by randomly drawing 1000 realisations from a log sinh transformed normal distribution fitted to each calendar month we use the bjp to fit the log sinh transformation following the data and cross validation scheme described in sections 5 and 6 1 the bjp generates reliable distributions even where many zeros are present wang and robertson 2011 we also assess the skill of volume forecasts accumulated over multiple months to calculate the climatology reference forecasts in these cases we first accumulate volumes from the observed record and then generate a climatology as described above to assess the significance of skill we bootstrap eqs 20 22 with 500 repeats when 97 5 of bootstrapped crpss values are positive negative we consider the forecasts to be significantly skilful negatively skilful 7 results 7 1 reliability reliability of esp and fogss forecasts for a dry month is shown in fig 4 for the three example catchments all 50 catchments are presented in fig s1 perfectly reliable forecasts follow the 1 1 line in the pit diagrams as foreshadowed in the introduction esp forecasts are often overconfident the pit diagram is s shaped because they do not consider uncertainties in the conversion of rainfall to runoff e g uncertainties in model states structure and or streamflow observations overconfidence is particularly prevalent for the dry months when rainfall is low and streamflow results primarily from catchment stores draining rainfall accrued in previous often wetter months this means forcing uncertainty has little bearing on overall uncertainty at shorter lead times forecast uncertainty in dry months is dominated by uncertainty in initial hydrological conditions esp reliability is considerably better for wetter months fig 5 than for drier months in wetter months rainfall forcings are often a dominant source of uncertainty and thus esp ensembles do a reasonably good job of representing total uncertainty both previous and new fogss methods o censoring and os censoring respectively correct overconfidence in the esp ensembles in many cases producing reliable forecasts at short and long lead times in most instances improvements are most striking in dry months fig 4 where poor reliability in esp is markedly improved by fogss even in wetter months however we can see small improvements in reliability after fogss is applied at lead 1 in the perennial elizabeth creek catchment fig 5a six observations are below the esp forecast ensemble these points fall on the bottom of the vertical axis while these are technically within the kolmogorov smirnoff confidence intervals to have six forecasts of 29 that completely miss an observation is evidence of a poorly performing forecast fogss completely corrects this problem fig 5d the benefits of os censoring over o censoring are apparent at longer lead times in dry months in the highly ephemeral joyce catchment fig 4f i fogss with os censoring produces reliable ensemble forecasts in the highly ephemeral joyce river catchment in a month with 60 zeros fig 4f regardless of lead time for o censoring at lead 1 the forecasts are slightly underconfident ensembles are too wide signified by the transposed s shape of the pit diagram at lead 6 the forecasts are increasingly positively biased a result of accumulated instances of underconfident forecasts at multiple lead times we note that o censoring still performs reasonably well in this catchment but this is less true of other catchments as discussed in the next paragraph the improved performance of os censoring over o censoring becomes more evident in highly ephemeral months when we summarise reliability at a range of lead times fig 6 both o censored and os censored versions of fogss markedly outperform esp at short lead times especially in highly ephemeral rivers esp forecasts tend to become more reliable closer to the ideal value of 1 with lead time because uncertainties from the forcings explain a large proportion of total uncertainty at long lead times the benefits of os censoring over o censoring are marked in months with 50 zeros at longer lead times fig 6 bottom panel os censoring allows fogss to maintain reliability in even highly ephemeral months to long lead times whereas the reliability of o censored fogss forecasts drops with lead time as instances of underconfidence positive bias accumulate consistent with wang et al 2020 we do not expect and do not see strong differences in skill or the reliability of accumulated volumes between o censored and os censored fogss forecasts we therefore concentrate on os censored forecasts in the remaining figures as stated in the introduction a key advantage of forecasts in the form of time series is that they can be summed to produce total volume forecasts reliability of total volume forecasts is not ensured by reliability at individual lead times it can only be guaranteed if hydrographs in the ensemble have realistic temporal properties demargne et al 2014 fig 7 shows that esp forecasts can achieve reasonably reliable 12 month aggregations but reliability falls away for shorter aggregation periods irrespective of ephemerality fogss forecasts of aggregated values are strongly reliable and reliability is consistent across different aggregation periods and across different catchments reliability of aggregated volumes in highly ephemeral catchments is slightly less than that of perennial and moderately ephemeral rivers but is still high α 0 8 in a large majority of cases where α 1 is perfect reliability 7 2 accuracy and skill while esp forecasts can be skilful to multiple lead times they are beset by statistically significant negative skill in many months and lead times irrespective of catchment ephemerality fig 8 significant negative skills are present in jul oct and feb in elizabeth creek aug nov dec and feb in the collie river and dec feb and mar in joyces creek fogss forecasts by contrast virtually always produce positively skillful forecasts at short lead times and neutrally skilful forecasts i e similarly skilful to climatology at longer lead times the one exception in june at lead 5 in the collie catchment where os censored fogss produces significant negative skill but the esp forecasts do not this is consistent with the findings of our previous work in perennial and moderately ephemeral catchments bennett et al 2016b bennett et al 2017 it confirms that stages 2 and 3 of fogss substantially improve biases and reduce errors at short lead times respectively fig 8 also shows that os censored fogss forecasts for the highly ephemeral joyces creek catchment are now positively or neutrally skilful in all months this is also true of other highly ephemeral catchments fogss improves skill of esp forecasts for 85 of highly ephemeral months used in this study fig s4 indeed fogss almost always improves esp forecasts often substantially with few exceptions fig 8 figs s3 s4 for example negative skills in the perennial elizabeth creek in aug oct are completely removed fig 8 and earlier lead times for these months are now significantly skilful similar improvements are evident for nov dec in the moderately ephemeral collie river and for feb mar in the highly ephemeral joyce creek some positive skills are caused by poor performance of the reference forecast a notable example is the significant positive skill of both esp and fogss forecasts for january for joyces creek even to very long lead times in this case the bjp produces a very wide climatology ensemble for january this is caused by one very large event in the streamflow record in what is usually a dry month which affects the fit of the log sinh transformation by the bjp fogss is less affected because in fogss we fit the transformation to data from all months the bjp s poor performance in this case is highly unusual more often fitting climatology distributions by month leads to more accurate forecasts further fitting the transformation to all months in fogss sometimes leads to a poorly fitting transformation at individual months in exceptional cases this can result in negative skill in fogss forecasts e g forecasts for nov in the 922001a gauge fig s4 there is one notable exception to fogss improving esp forecasts in the collie river strongly negative skill has been introduced by fogss at lead 1 in feb and follows a diagonal to lead 4 in may these negative skills are not statistically significant but demonstrating their cause is instructive fig 9 shows how negative forecast skill is introduced by fogss for the collie river negative skill for the lead 1 feb forecasts is caused by a single large overestimation of streamflow in 1982 fig 9a and this also causes negative skill at lead 2 mar forecasts through to lead 4 may forecasts the large overestimation in feb 1982 is due to the underestimation of a very large and unseasonal streamflow event in jan 1982 driven by tropical cyclone bruno http www bom gov au cyclone history bruno shtml fig 9b shows that this has virtually no impact on the esp forecast for lead 1 feb or the subsequent lead times the ar1 model in fogss however corrects forecasts for feb 1982 up dramatically fig 9c following the mismatch in simulations and observations in jan 1982 under strict cross validation poor performance of a calibrated hydrological model can be difficult to avoid for isolated extreme events in addition the ar1 model in fogss exacerbates the poor performance of the hydrological model in this instance however while the ar1 model exacerbates poor model performance in this instance as well as a few other isolated instances in fig s4 the ar1 model overwhelmingly improves forecast accuracy in the vast majority of cases e g in elizabeth creek for may oct fig 10 removing negative skills at long lead times has considerable benefits for the accuracy of aggregated volume forecasts fig 11 skill at short lead times can carry through the entire volume forecast resulting in fogss forecasts that can be skillful even for 12 month aggregations including in highly ephemeral catchments fogss forecasts for 6 month aggregations are very often skillful irrespective of ephemerality as with individual lead times fogss forecasts of aggregated volumes are almost always more skilful than esp forecasts of aggregated volumes 8 discussion with the addition of the data censoring treatment described in this study fogss now produces 12 month streamflow forecasts at the monthly time step that are reliable in highly ephemeral rivers forecasts are in the form of an ensemble of time series where each ensemble member can be aggregated to produce ensemble forecasts of aggregated volumes forecasts are reliable at individual lead times and for aggregated volumes as with previous versions of fogss forecasts are almost always more skilful than esp forecasts crucially as skill declines with lead time forecasts become neutrally skillful this allows aggregated volume forecasts to be skillful even to very long e g 6 month aggregation periods these properties remove many of the barriers to the use of long range ensemble streamflow forecasts in ephemeral rivers we have shown in other work that fogss forecasts can improve the management of dams turner et al 2017 and the allocation of water kaune et al 2020 and these benefits can now be realised for highly ephemeral rivers this study reaffirms that it is possible to use fogss error model parameters estimated at lead 1 analogous to a hydrological model calibration to calibrate forecasts to multiple lead times crucially this allows forecasts to be represented as a hydrograph rather than a set of discrete probability distributions at each lead time this is possible through the use of stochastic updating stochastic updating assumes that for a given month the autocorrelation properties and error distributions at lead 1 hold at all lead times this assumption is not guaranteed to hold and accordingly fogss cannot enforce reliability at each month lead time in the way that statistical methods can although we have shown that in practice it almost always does it is possible then that statistical forecasts that account for zero values like the bjp wang and robertson 2011 will produce more reliable forecasts at discrete lead times noting again that there is no clear method to generate hydrographs with statistical methods in future work we plan to compare climate forced os censored fogss forecasts with statistical forecasts generated with the bjp where we adapt bjp forecasting methods to produce monthly forecasts to 12 months we note that there are aspects of the fogss error model that may still be improved for example mcinerney et al 2019 found that they could achieve slightly sharper predictions using a fixed parameter box cox transformation instead of a log sinh transformation in ephemeral rivers conversely the log sinh transformation performs strongly in perennial catchments in comparison to other transformations mcinerney et al 2017 wang et al 2012 it is therefore possible that a different transformation may improve the properties of the fogss ensemble in ephemeral rivers in this study we have used uninformative forcings to drive our streamflow forecasts fogss completely separates uncertainties in hydrological modelling from uncertainties in forcings so it is relatively straightforward to include informative forcings from seasonal climate forecasts however to ensure reliable streamflow forecasts forcings must also be reliable only then can uncertainties from forcings and hydrological models sum to correctly represent total forecast uncertainty in addition forcings should be coherent i e at least as skilful as climatology to ensure that streamflow forecast skill does not become negative at long lead times esp forcings are inherently reliable and coherent but this is not necessarily true of climate forecasts e g peng et al 2014 schepen et al 2016 strazzo et al 2019 wang et al 2019 thus climate forecasts should only be used with fogss after they have been formally statistically calibrated for which a number of methods are available manzanas et al 2019 sansom et al 2016 schepen and wang 2014 siegert and stephenson 2019 simple bias corrections do not ensure reliability or coherence and are not suitable for calibrating forecasts zhao et al 2017 in our previous applications of fogss we have used calibrated climate forecasts as forcings and forecasts were reliable in perennial and moderately ephemeral catchments bennett et al 2016b bennett et al 2017 however these studies differed from the present one in that they used a hydrological model run at the monthly time step not at the daily time step calibrating climate forecasts at a monthly time step is much more straightforward than at the daily time step as monthly data are far less noisy while it is technically possible to generate calibrated daily climate forecasts schepen et al 2017 these methods have not been tested to the very long lead times i e 365 days used in our study in addition propagating uncertainty with stochastic updating as used in fogss is more difficult over many lead times bennett et al 2021 li et al 2020 and is likely to require further development to produce forecasts for 365 lead times compared to the 12 lead times in this study testing and further development of daily climate forecast calibration methods and error modelling to very long lead times are thus clear targets for future research fogss is not yet in operational use but offers an attractive means for a future operational long range streamflow forecasting system as we have shown os censoring works across all catchment types in perennial catchments censoring is not enacted while in ephemeral catchments it plays an important role this means that a single method can be applied to all catchment types a clear advantage for operations further we have shown that fogss is effective as a bolt on corrective to esp forecasts in this case for a hydrological model calibrated using an independent procedure as esp forecasts are widely used in operational forecasting fogss can be easily applied to improve these forecasts correcting esp forecasts is also attractive as esp can be readily adapted to accept calibrated climate forecast inputs in other words because fogss is premised on the idea of separating the uncertainties in climate forecasts from uncertainties in hydrological modelling this makes any fogss operational system highly modular climate forecasts can be updated improved independently of hydrological models and vice versa we note also that fogss is highly computationally efficient often a key consideration for operationalisation on a standard desktop computer it takes 2 minutes to estimate parameters for the 29 year estimation period used in this study while it takes at most a few seconds to generate a 12 month forecast with 1000 ensemble members 9 summary and conclusions this study further develops the fogss forecast guided stochastic scenarios method to generate long range 12 month streamflow forecasts for use in highly ephemeral rivers forecasts are in the form of an ensemble of time series at the monthly time step each ensemble member can be summed to produce an ensemble of aggregated volume forecasts we combine the basic staged structure of the fogss error model with a data censoring method that is applied to both observations and simulations the data censoring method treats both modelled and simulated flow as censored data when they are equal to zero this allows fogss to generate reliable ensemble forecasts in highly ephemeral rivers which can cease to flow 50 of the time in some months we test the new version of fogss on 50 catchments of which 26 are ephemeral fogss forecasts are generally highly skillful at short lead times compared to climatology and very often more skillful than conventional esp ensemble streamflow prediction forecasts at longer lead times fogss forecasts are coherent that is never less skillful than climatology which cannot be guaranteed by esp forecasts forecasts are reliable irrespective if they are issued for highly ephemeral 50 zeros or perennial 5 zeros months forecasts perform similarly in highly ephemeral moderately ephemeral and perennial catchments in both skill and reliability these improvements pave the way for operational long range forecasts in ephemeral rivers meeting a key need for improved water management credit authorship contribution statement james c bennett methodology conceptualization investigation validation visualization software writing original draft q j wang conceptualization methodology writing review editing david e robertson methodology conceptualization software writing review editing robert bridgart software julien lerat methodology data curation writing review editing ming li methodology conceptualization writing review editing kelvin michael supervision writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work was conducted on the traditional lands of the boonwurrung and wurundjeri peoples of the kulin nation we acknowledge their continuing custodianship of their lands and the rivers that flow through them and pay our respects to their elders past and present we also acknowledge the traditional custodians of the catchments and rivers used in this study this research was supported by the water information research and development alliance wirada between the bureau of meteorology and csiro land water and arc linkage project lp170100922 thanks to elisabeth vogel and richard laugesen both bureau of meteorology for helpful comments on the manuscript all data and model runs used in this paper are available from csiro s data access portal at https doi org 10 25919 s767 q790 matlab and c code used to generate simulations and forecasts and to verify forecasts are available on request license conditions apply supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103891 appendix b supplementary materials image application 1 appendix a parameter estimation for each stage stage 1 maximum a posteriori map estimation is used to estimate the transformation parameters in eq 1 we assume that transformed observed streamflow follows a normal distribution a1 z o n m s 2 in eq 1 and eq a1 a total of four parameters a b m and s are estimated the four parameters are reparameterised to log a log b m s and log s respectively to make it more numerically efficient to find a map solution our parameter set is then θ1 log a log b m s log a the likelihood is given by a2 l θ 1 p θ 1 t j z o t c q o t n z o t m s 2 where j z o t c q o t is the jacobian a3 j z o t c q o t coth a b c q o t with a standardization constant c 5 max q o and p θ1 is a prior a4 p θ 1 p log a p m s p log s p log b where a5 p log a 1 log a 0 a6 p m s 1 a7 p log s 1 and a8 p log b n 0 1 2 the priors in eqs a5 a7 are uninformative the prior on log b eq a8 encourages values closer to zero which in our experience is a good starting point if the datum at time t is a censored value i e qo t 0 the term j z o t c q o t n z o t m s 2 in eq a2 is replaced with the normal cumulative probability φ zc m s 2 where zc tf 0 is the log sinh transformed value of zero stage 2 parameters in eq 2 θ 2 d i μ i i 1 2 12 are estimated by minimizing the lst objective eq 7 stage 3 the θ 3 ρ i i 1 2 12 parameter in eq 3 is estimated by minimizing the lst objective eq 7 stage 4 we first estimate m 3 i and s 3 2 i to do this we generate a streamflow simulation q 3 by applying stages 1 3 to the hydrological model simulation we extract the simulated streamflow for each calendar month from q 3 and then use the map procedure from stage 1 to estimate m 3 i s 3 2 i keeping a and b fixed from the stage 1 estimation we can then use maximum likelihood estimation to infer θ 4 σ 2 i i 1 2 12 with the likelihood specified in eq 12 note that no closed form is available for case 4 eq 11 and thus it requires a monte carlo integration for details of this integration see wang et al 2020 
317,clogging of porous media is controlled by attachment of particles and their subsequent detachment in this study we explore particle transport at the pore scale by considering attachment and detachment processes we use pore structures of three samples which have similar topological properties but different initial porosities the main focus is on particle detachment after they are attached to the solid grain boundaries and to explore how particle detachment affects hydraulic properties and clogging of porous media a new approach was proposed by combining the lattice boltzmann method with a lagrangian method to simulate fluid flow and particle transport respectively comparisons between several simulations with and without detachment were used to evaluate the impact of particle detachment on fluid flow velocity distributions the coefficients of carman kozeny relation were used to relate porosity changes of each sample to its permeability alterations additionally the influence of the initial porosity of the sample and flow velocity on the detachment process was analysed the results show that compared to the impact of flow velocity the initial porosity of the media has a greater influence on controlling the rate of detachment and change of pore structures keywords porous media pore scale detachment process lattice boltzmann method attachment process fine particles clogging nomenclature f α boltzmann distribution function c α velocity vector in α direction τ hydrodynamic relaxation time f α e q equilibrium distribution function c lattice sound speed m s δx lattice length δt lattice time ωα weight coefficient for the α direction cs sound speed m s υ kinematic viscosity m2 s ρ fluid density kg m3 u fluid velocity m s m mass of particle kg v particle velocity m s fd hydrodynamic drag force μ dynamic viscosity pa s ac particle radius m σ shear stress pa σ cr critical shear stress pa f n adhesive force n c f friction coefficient kt particle stickiness to surface m cp particle mass concentration α empirical constant h hamaker coefficient l separation distance between the particle surfaces in filter cake m n m c r critical mobility number n r e c r critical reynolds number vcr critical shear velocity m s γ s specific weight of particle re reynolds number k permeability m2 k 0 initial permeability m2 ϕ porosity ϕ0 initial porosity i horizontal nodes counter j vertical nodes counter nx the number of lattice nodes in horizontal direction ny the number of lattice nodes in vertical direction φ s sphericity τ stress tensor σ t standard deviation τ mean stress τ normalized shear stress 1 introduction understanding attachment and detachment of fine particles in porous media is critical in several applications including chemical stewart and buriak 2000 environmental abdul mujeebu et al 2009 raoof and hassanizadeh 2010 raoof et al 2010 and petroleum technologies oil exploitation parazzo et al 2018 industrial filtering netter and conti 2016 groundwater utilization chequer et al 2019 wang et al 2020 grouting engineering zhou et al 2018 and industrial waste disposal tong et al 2019 several approaches including experimental bergendahl and grasso 2000 silliman et al 2001 haque et al 2017 chu et al 2019 computational raoof et al 2013 klimenko and maryshev 2019 benioug et al 2017 gaebler and eberl 2018 yoon et al 2015 and mathematical bedrikovetsky et al 2011 bedrikovetsky et al 2012 bergendahl and grasso 2000 schulz and knabner 2016 methods have been developed focusing on particle transport attachment and detachment of colloids in porous media attachment of particle at the solid grains alters topology and geometry of the pore structure and varies the fluid flow regime at the same time attachment of particles increases the hydrodynamic shear next to the grain surfaces which may cause detachment of the deposited particles coronado and diaz viera 2016 studied permeability loss due to fine migration and clogging using three experiments based on the study of bedrikovetsky et al 2011 they applied an extended mathematical model to simulate permeability impairment endo kokubun et al 2019 explored the effect of hydrodynamic forces on accumulation of particles in water saturated porous media their numerical results showed significant accumulation of particles in both low and high velocity regions they reported that during particle transport in homogeneous media particles are significantly accumulated in low velocity regions however the ultimate porous media clogging is occurred at high velocity regions in addition to particle attachment and retention detachment of fine particles can play a significant role in the clogging behaviour of porous media several studies have included particle detachment process to obtain effective parameters for adsorptive transport tufenkji 2007 kapellos et al 2007 han et al 2019 zhang et al 2019 zheng et al 2014 used a combined experimental mathematical analysis and found that detachment does not necessarily occur under lower darcy velocities and there exist a significant relation between the attachment detachment parameters and flow velocity cui et al 2017 evaluated the influence of flow velocity and its direction on detachment process using experimental observations quartz powder with sizes of 18 and 41 µm were used as colloids and quartz sand was used as porous media they observed that both parameters influence the detachment rate of the deposited particles however the magnitude of fluid velocity showed a larger impact on the detachment rate huang et al 2017 investigated the role of flow conditions fine sizes and fracture aperture on particles detachment during dewatering process a mathematical model was developed to describe single particle detachment mechanism they found a critical pressure gradient under which a massive amount of fine detachment occurred their results showed that with increasing the size of fine particles the pressure gradient required for fine detachment initially decreased to a minimum value called critical gradient pressure and subsequentlyincreased to a larger value during the attachment and detachment of fine particles permeability alterations occur due to porosity variation and change of pore structures the complex nature of porous media have caused challenges in developing relationships among permeability porosity grain size and fine sizes hommel et al 2018 several modelshave been developed to predict the permeability reduction due to particles retention including experimental verma and pruess 1988 civan 2001 thullner 2010 bacci et al 2011 and numerical zhang et al 2015 ju et al 2017 joodat et al 2018 approaches while some studies have applied a more realistic and complex pore structures xiao and yin 2016 rabbani et al 2018 many others were limited to simpler grain geometries like cylindrical shapes yazdchi et al 2011 endo kokubun et al 2019 porous media with identical porosity values often have different topologies i e the way that pore structures with different sizes are interconnected this difference can significantly affect the relationship between porosity and permeability of porous media which even have similar porosities lima et al 2020 showed that samples with higher pore connectivities i e larger pore coordination numbers provide much larger permeabilities compared to samples with similar porosities but with a less number of connected pores deo et al 2010 in an experimental modelling study investigated the permeability reduction in concrete samplesby retention of fine particles and pore clogging they used fine and coarse concrete samples as the matrix materials and observed a substantial permeability reduction when an incremental amount of finer sand was added to the porous concrete mixtures based on their observations they proposed a ratio of pore size to particle size under which permeability reduction is maximum and its reduction would not have a significant trend for coarser sands sato et al 2013 investigated the effect of trapped particles on permeability reduction using an image of real sand grains and applying lattice boltzmann method lbm to simulate fluid flow they used volume fraction and specific surface areas of both grains and the clogging particles to define a relation for permeability alteration they found that the reduction in permeability could not only be attributed to changes in volume fraction of fine particles to the pore volume but also to the size distribution of fine particles according to their results when medium porosity is more or lessconstant along the sample the order of magnitude of the resulting permeabilities is identical to porosity values whether the fine particles are fixed at random positions or they are trapped within the narrow pore throats montessori et al 2015 and montessori et al 2016 employed lattice boltzmann method to simulate strongly non equilibrium flows in porous media and reactive flow related to nano porous materials their results showed that non equilibrium effects increase the reactivity of the porous sample and provided quantitative assessment of the reactivity using the thickness of the reactive layer inside a nano porous catalytic sample ahfir et al 2016 investigated the influence of porous medium grain size and fine particle sizes on clogging and found that a larger number of particles were retained within the narrower pores however the fundamental mechanism of clogging in porous media caused by particle transport was not stated liu and mostaghimi 2017 performed parallel computations on 3d samples using lattice boltzmann and finite volume methods and simulated dissolution of a carbonate rock sample together with particle migration and reactive transport their simulations were conducted under low peclet regime to study the effect of flow rate on reactive transport using image based pore structures they showed that the resulting permeability porosity relation from modelling are less accurate when low resolution images are used for simulations li and prigiobbe 2018 developed a numerical model by the help of lbm immersed boundary method ibm and discrete element method dem they investigated fine particles motion in porous media using a two way coupling implemented between fluid flow and fine particles their results showed that both particle size and the structure of porous media can influence particle transport and retention this consequently could alter the flow regime and decrease the permeability in addition simulations showed that increase of pressure drop because of the retained particles can promote detachment and allow restoring the initial permeability ahkami et al 2020 studied pore scale behaviour of mineral precipitation patterns in a fractured porous medium employing a 2d phase field lattice boltzmann method they introduced a porosity permeability relation that considered species transport mineral precipitation and pore space geometry changes a wide range of diffusivity and reaction rates was explored to study different flow regimes ranging from advection to diffusion dominated regimes their results showed that permeability reduction is affected by clogging regime close to the flow inlet they found a linear reduction in permeability for the fracture isolation regime when the precipitation reactions narrowed down the fractures and permeability reduced slowly in the diffusive precipitation regime where precipitation reactions spread between solid grains in order to a better understanding of grain detachment and migration during reactive flow liu et al 2020 studied the effect of permeable grain boundaries on dissolution of carbonate rock with complex structure and porosities by a 2d grain scale modelling their results showed a decrease in permeability due to the clogging of transport pathways caused by grain detachment in addition they found that an increase in flow rate causes a reduction in detachment and fracture clogging by reducing local dissolution along grain boundaries parvan et al 2020 investigated the influence of initial porosity and different topology on the porosity permeability relationship using lbm for fluid flow simulation six real geometries were used to evaluate the clogging process three geometries with identical topologies but different initial porosities were used for investigating the influences of porous media geometrical effect and an extra three samples for which the solid grain were repositioned were used to study the porous media topological effects in our previous study parvan et al 2020 we explored the dependency of clogging on both porous media geometrical and topological propertiesby only considering particle attachment in this article in addition to particle attachment we include detachment of particlesto explore its impact porous media clogging particle detachment isimplemented by computing a critical shear force at the surfaces of solid grains several hydrodynamicalparameters are presented at the pore scale and the results are compared between simulations with and without particle detachment process the findings are explained by providing fluid velocity fields distribution of shear forces and particle attachment and how these are affected when particle detachment in included finally to show the influence of particle detachment at the larger sample scale we explored the effect of detachment process on coefficients of carman kozeny relation and how these coefficients change during adsorptive transport for simulations with and without detachment process 2 methodology and modelling assumptions to simulate fluid flow and particle transport including attachment and detachment of fine particles we have considered two sequential steps in our simulations first fluid flow is simulated to obtain a steady state flow for a given pore structure the pore structure is determined by the initial pore geometry as well as the subsequent attachment detachment of particles changing the pore structure in a second step using the established flow particle transport including attachment and detachment processes are simulated the challenges encountered in lattice boltzmann modelling of complex geometries are two folds first the representation of the complex geometry in the cartesian grid does not conform to the curved boundaries secondly in implementing the boundary conditions inaccurate distribution functions originated from the solid nodes may be generated during the streaming operation in our study the complex geometry is converted into binary data before the numerical solution the no slip boundary conditions are included using the standard bounce back sbb scheme in this study sbb scheme reverses the distribution functions at the stationary solid surfaces and is used very often in lbm method to represent the non slip boundary conditions it reverses and sends back the distribution functions penetrated to the stationary solid surface for our simulations we have combined the lbm for flow simulation with a lagrangian method for particle transport simulation in porous media the following assumptions have been considered for particles motion during attachment and detachment processes a through the simulations physical properties of fluid such as its dynamic viscosity and densityare unaffected because the concentration of the point particles in the fluid is sufficiently low b particle transport and particle detachment occur due to hydrodynamic drag forces and hydrodynamic shear force respectively and mechanism including interactions between fine particles gravity van der waals forces and electrostatic double layer forces are not considered this assumption is often made in studies considering horizontal flow feng et al 2015 bagalkot and kumar 2018 parvan et al 2020 which is consistent with our simulations c the injected particles have small size relative to the pore size and therefore their effect on fluid flow regime is negligible up to their deposition time after which the flow field is solved and velocities are updated accordingly d the distance between the surface of particles and grain boundaries are used as a measure for attachment and detachment of fine particles through defining a critical value for hydrodynamic shear force 3 mathematical model 3 1 fluid flow simulations lbm is an effective approach for numerical simulations of fluid flow which has been used in diverse studies succi 2001 sukop and thorne 2006 aidun and clausen 2010 parvan et al 2019 including pore scale simulation of flow through different porous media koponen et al 1998 koivu et al 2009 mattila et al 2016 lbmis a mesoscopic numerical method that can bridge the micro and the macro scales in lbm the fluid flow is solved based on discrete version of the boltzmann equation often bounce back algorithm is used in lbm to apply no slip boundary condition at the interface of fluid and solid grains in this study the d2q9 scheme is used and at each time step lbm equations are solved in a transient form until steady state flow is reached the lbm for fluid flow is described by the following discretized boltzmann equation 1 f α x c α δ t t δ t f α x t f α x t f α e q x t τ here f α is boltzmann distribution function to calculate density and velocity field and f α e q is distribution function in equilibrium state used for direction α in addition τ and c α mention hydrodynamic relaxation time and velocity vector in α direction respectively these parameters are expressed as 2 f α e q ω α ρ 1 3 c α u c 2 9 2 c α u 2 c 4 3 2 u u c 2 here c δx δt is related to the lattice sound speed δx and δt are lattice length and lattice time that both are selected as 1 and ωα is the weight coefficient for the α direction expressed as 3 ω α 4 9 α 0 1 9 α 1 2 3 4 1 36 α 5 6 7 8 4 τ υ c s 2 0 5 5 c α 0 α 0 cos π α 1 2 sin π α 1 2 c α 1 2 3 4 cos π α 4 1 2 2 sin π α 4 1 2 2 2 α 5 6 7 8 where c s c 3 and υ are sound speed and kinematic viscosity respectively the macroscopic variables of fluid such as density ρ x t and velocity u x t can be calculated by using of 6 ρ x t α f α x t 7 u x t α f α x t c α ρ x t 3 2 implemented boundary conditions in present simulations a non slip boundary condition is applied for top and bottom boundaries and a periodic boundary condition is used at the inlet and the outlet boundaries the unknown distribution functions in d2q9 lattice arrangement for each boundary are computed as 8 top boundary bounce back f 4 i n y f 2 i n y f 7 i n y f 5 i n y f 8 i n y f 6 i n y 9 bottom boundary bounce back f 2 i 1 f 4 i 1 f 5 i 1 f 7 i 1 f 6 i 1 f 8 i 1 10 inlet boundary periodic f 1 1 j f 1 n x j f 5 1 j f 5 n x j f 8 1 j f 8 n x j 11 outlet boundary periodic f 3 n x j f 3 1 j f 6 n x j f 6 1 j f 7 n x j f 7 1 j where i j nx and ny are the horizontal node indices the vertical node indices the number of lattice nodes in the horizontal direction and the number of lattice nodes in the vertical direction respectively moreover the fluid flow is driven by an extremely small body force on the fluid 3 3 simulating particle transport the motion of a particle in the flow field occurs in the lagrangian simulation step in response to the hydrodynamics drag forces the lagrangian equation of motion of a particle suspended in a fluid is given as 12 m d v d t f d where m is the mass of particle v is particle velocity and fd is hydrodynamic drag force the actual diameter size of the injected fine particles and the average grain diameter are 0 608 µm and 35 40 µm respectively when the reynolds number of the domain is low and the particle is not close to the channel wall the stokes drag force effects on the particle can be expressed as stokes 1850 horwitz and mani 2016 horwitz and mani 2018 qiu 2015 13 f d 6 π μ a c u v whereμ is dynamic viscosity ac is particle radius u fluid velocity and v is particle velocity 3 4 attachment mechanism after fluid flow simulation hydrodynamic drag force is implemented on the existing particles which include the attached particles at the solid boundaries as well as the suspended particle in the fluid phase the attachment of fine particles at the solid boundaries of grains during their transport could ultimately cause permeability reduction and clogging of the pores if conditions for clogging are favourable porous media becomes completely clogged and its permeability approaches zero in this research the distance between the surface of colloid and the boundary of grains was used as the main criterion to determine particle settlement if the distance between the fine colloid and grain boundary is equal or lower than the assumed particle radius the fine particle is considered as attached to the grain surface when the accumulated volume of attached particles in a numerical cell exceeds 90 of the cell volume that fluid cell is converted from fluid into a solid phase cell and the pore structure is updated accordingly the deposited particles can however detach in the presence of sufficient shear rate and the pore spaces re open parvan et al 2020 3 5 detachment mechanism in the presence of fluid flow when the shear force next to the surface of the deposited colloid increases and passes a critical value particle release and re entering into the balk fluid takes place some of the methods for computing the shear force on the boundary of solid grains are expressed in table 1 in eq 14 σ is shear stress and c is used to account for deviation from a sphere shape and μ d p and υ are the fluid viscosity particle diameter and interstitial fluid velocity respectively the direction of the interstitial fluid flow is parallel to solid the surface a friction force is considered in eq 15 to compute the critical shear forces between the attached particles and the pore surface this value could be additionally considered as a criterion for particle detachment f n is adhesive force acting on the deposited particles which results from summation of hydrodynamic force and including viscous drag force and dlvo forces the latter includes attractive lifshitz van der waals and electrostatic double layer forces acting on the deposited particles the parameter c f denotes a friction coefficient which is different for rolling sliding or other forms of particle motion in eq 16 civan 1990 1996a considered a critical shear stress where kt denotes the particle stickiness to surface and cp and α are particle mass concentration and an empirical constant respectively the critical shear stress predicted by potanin and uriev 1991 is based on the interactive van der waals energy between solid phases in the filter cake eq 17 in this relation h is the hamaker coefficient dp and l are the average particle diameter and the separation distance between the particle surfaces in filter cake respectively tremblay et al 1998 developed a critical condition for onset of particle mobilization by fluid shear based on the study of yalin and karahan 1979 and provided the following relation 19 n m c r 0 122 n r e c r a where a is 0 206 and n m c r and n r e c r are the critical mobility number and the critical reynolds number respectively these parameters can be expressed as 20 n m c r ρ υ c r 2 γ s d p 21 n r e c r ρ υ c r d p μ where υ c r and γ s are the critical shear velocity and specific weight of particles suspended in the fluid respectively by using eq 16 and using dimensionless groups tremblay et al 1998 correlated their experimental data on a full logarithmic scale and introduced a critical shear velocity as 22 υ c r 0 385 μ ρ a γ s b d p c ρ d where a b c and d considered 0 0934 0 453 0 36 and 0 453 respectively then they predicted the critical shear stress on the surface as 23 σ c r ρ υ c r 2 we used relations developed by tremblay et al 1998 mainly because of its simplicity using this relation we obtain the critical shear force needed for particle detachment in the presence of fluid flow 4 results and discussions simulations are conducted on real geometries from a sand pack with an original porosity of 36 the geometry of domains was obtained using x ray tomography method with a resolution of 10 µm a 2d slice of this image was used as the pore scale domain furthermore a numerical erosion was performed on this 2d slice to generate two extra pore scale domains i e a total of three pore structures which had similar arrangement of pores and grains but different porosity values in doing so to obtain a domain with a desired porosity value the imagej package rueden et al 2017 was used and image pixels corresponding to the surface of the solid grains were removed in a layer by layer manner for all grains until a desired porosity was obtained for each domain the physical size of the real porous domain is 380 800 µmin horizontal and vertical directions respectively the three geometries had initial porosity values of 38 2 45 9 and 52 1 which we refer to them as samples s1 s2 and s3 a non slip boundary condition was applied using a bounce back method at the top and bottom boundaries and the periodic boundary condition was implemented for both the inlet located at the left side of the domain and the outlet positioned at the right side of the domain boundaries to prevent the effect of inlet and outlet boundary conditions on fluid flow thorough porous domain two fluid jackets were considered before and after the inlet and outlet respectively grid independency tests have provided an optimum grid size of 237 500 in lattice unit for our porous domain the relaxation time was assumed to be 0 65 in lattice unit the parameter values are chosen in the range of natural groundwater and clay particles in the earth subsurface the bulk density of water is set to 1000 k g m 3 and the density of clay or clay loam immersed in groundwater should be between1000 and 1600 k g m 3 brady 1974 in our simulations colloid transport is driven by the hydrodynamic drag force and since density of colloids 1055 k g m 3 is very close to that of fluid solution the gravity and buoyancy forces are neglected in this study we validated our numerical model against a well known benchmark problem which uses cylindrical shape grains and uses kozeny carman equation to calculate permeability as a function of domains porosity hommel et al 2018 voronov et al 2010 lee and yang 1997 24 k ϕ s 2 d p 2 180 φ 3 1 φ 2 where φ s is the sphericity a dimensionless particle geometry parameter computed from li et al 2012 dp is the characteristic particle diameter and φ is the porosity the results of modeming tests and carman kozeny relation results are provided in fig 1 the validated model was used to perform simulations for particle transport thorough porous domains the diameter of the injected particles was 0 61 µm and the average grain diameters in three geometries were 40 5 37 9 and 35 9 micrometres respectively fine particles were injected into the fluid phase at equal distances at the inlet since the aim of this study was to explore detachment of the settled particles under different flow regime we began with applying low velocities in the inlet by using an extremely small body force on fluid for which no detachment happens in the subsequent simulations as inlet velocity was increased the critical velocity was found below which the detachment would not occur the reynolds number r e ρ u d μ based on the inlet fluid velocity and the average grain diameter for these three cases are 0 0005 0 0009 and 0 0019 respectively the magnitude of critical velocity was found to be larger for samples with grater initial porosities this trend could be attributed to the existence of wider pore throats in samples s2 and s3 and lower average velocity values under identical inlet fluid velocity through the pores of these samples fig 2 shows flow velocity distributions for the three pore structures using the same inlet flow velocity fig 3 shows the permeability reduction due to particle attachment during clogging process because of the larger initial porosity and fluid flow thorough domain s3 attachment occurs almost at the boundary of all grains in the other two samples particularlys1 fluid was transported thorough distinct pathways and the injected fine particles accumulated only in specific zones to highlight the influence of particle detachment in domains for each domain two series of simulations with velocities greater than critical inlet velocities were performed one by considering detachment process and one without detachment fig 4 shows simulation results for two situations i e with and without detachment green regions show zones where particle deposition at grains surfaces is occurred in this figure the inlet velocities for sample s1 s2 and s3 are set to 2 8 4 5 and 8 4 m day respectively the reynolds number r e ρ u d μ based on the mean fluid velocity at inlet and the average grain diameter for all three cases are 0 0013 0 0019 and 0 0034 respectively particle detachment caused obvious differences between pore structures and simulation results while considering or neglecting the detachment for better visualization and comparison yellow frames are sketched in the sample with initial porosity of 38 2 in sample s1 due to the low initial porosity clogging could occur fast but detachment delays clogging and because of this reason the attached particles in the final geometry in the state with detachment are more than the state without detachment in sample with initial porosity of 45 9 it is obvious that in the state without detachment attachment occurs in the whole domain but due to detachment process in other state attachment has almost negligible effect for sample s1 when detachment was included clogging occurred in longer period of time compared to simulations without detachment and solid particles had more time to deposit at the surface of grains see figure s3 for sample s1 in addition in presence of detachment in sample s1 most of particle deposition took place during time periods close the complete clogging in cases with detachment in samples s2 and s3 porous geometry was ultimately clogged however in cases without detachment a complete clogging did not occur which allowed the flow to continue and more particles could flow in and attach to the grains surfaces in fig 5 dimensionless permeability porosity relation porosity time relation and dimensionless permeability time relation are provided for different simulations variations in physical parameters such as porosity and permeability in sample s1 follow the same trend both with and without detachment included it is obvious that detachment process delays the clogging almost by two times during which lower porosities and permeabilities could be reached in sample s2 while a complete clogging occurred under no detachment scenario no significant variation in porosity and permeability was observed when detachment was included in sample s3 no variation in porosity and permeability was observed when inducing detachment processes however without detachment both porosity and permeability reduced and complete clogging occurred 4 1 fitting simulation data on carman kozeny relation there are several relations to explain the permeability reduction resulted from a decrease in porosity kozeny 1927 carman 1937 hommel et al 2018 during particle deposition on grains one of the well known relations in this field is carman kozeny relation which we used to fit on our results we used carman kozeny relation in the form of 25 k k 0 a φ φ 0 b 1 φ 1 φ 0 c where k and k 0 are permeability and initial permeability and ϕ and ϕ0 are porosity and initial porosity respectively parameters a b and c in this relation have been fitted to present relation between porosity and permeability based on carman kozeny relation this procedure was repeated for different simulations to investigate the impact of detachment process on these coefficients values are provided in table 2 the value of these parameters depends on different factors such as fluid flow properties specific surface area tortuosity sphericity particle diameter etc the value of coefficient a in all samples for with detachment and without detachment are almost 1 but there are differences in other parameters the magnitudes of b and c parameters decrease with an increase in initial porosity for without detachment state but these values are increased for the with detachment state it is notable that the difference between the magnitudes of both parameters b and c is increased with an increase in initial porosity it can be related to the increase in detachment influence in samples with higher initial porosities 4 2 detachment effect on velocity distribution fig 6 shows the fluid velocity distribution and facilitates the evaluation of the detachment effect on fluid velocity and the maximum fluid flow in the last step of simulation process the inlet fluid flow velocity for samples s1 s2 and s3 are 2 8 4 5 and 8 4 m day respectively according to this figure although sample s1 has the lower inlet velocity the fluid flow velocity in its pore throats is higher than others because of high detachment intensity in sample s2 and s3 fluid velocity in their pore throats cannot exceed too much detachment intensity in sample s2 and s3 is not very different and due to the higher inlet velocity the maximum fluid velocity value in sample s3 is more than its value in sample s2 the unaffected pore structures of samples s2 and s3 helps these samples to maintain their flow pathways over time fig 6 shows that major flow pathways are approximatelythe same in all samples and parameters such as inlet flow velocity difference in initial porosities and particle attachment detachment did not affect them significantly fig 7 shows the average fluid velocity histogram of three samples the behaviour of sample s1 varies over time while samples s2 and s3 does not show any significant changes in their porous structures and their average fluid velocities calculated at successive cross sections is unchanged over time in all three samples because of the porous geometry of the domain the average fluid velocities near the outlet are greater than the inlet geometry changes of sample s1 due to particle attachment and particle detachment causes variations in sample cross sections with time and therefore the average fluid velocity grows in this sample 4 3 detachment effects and adsorbed mass along porous domains during flow a fraction of the injected particles reach to the outlet boundary and exit porous domain while the rest of particles deposit on the solid grain surfaces a fraction of the deposited fine particles are detached and may redeposit on other solid grain located downstream of the flow and some of them may exit the domain the detachment process can postpone or prevent porous media clogging and in some cases fluid flow paths are considerably affected by the detached and attached particles fig 7 shows the adsorbed mass i e due to particle attachment in different locations of porous domains along the flow when sorption is with and without detachment process at the solid grains remarkably in the sample with initial porosity of 38 2 i e s1 the adsorbed mass when particle detachment is included is larger compared to the attached mass without detachment this behaviour is because the detachment process postpones complete clogging of the media by remobilizing a fraction of the attached particles which enables the fluid flow to continue for longer times and more particles will enter into the domain and attach on solid grains without possibility for detachment the pore structure is clogged at the earlier stages and flow is terminated fig 8 also shows that for the sample with initial porosity of 38 2 i e sample s1 more fine particles deposited near the inlet in samples with initial porosity of 45 9 and 52 1 because of higher initial porosity and higher inlet velocity detachment prevents strong clogging and attachment of fine particle occurs rather uniformly throughout the domain however without detachment the density of attached mass is larger at regions closer to the inlet of the porous media 4 4 evaluation of shear force in porous domain for better visualization of detachment in the samples fig 9 is sketched to show the distribution of shear forces in porous domains due to the lower initial porosity and inlet fluid velocity the value of shear forces in sample s1 are lower than sample s2 and s3 although the inlet fluid velocity in sample s3 is almost two times greater than sample s2 there is no significant difference in the values of shear force between them it can be concluded that the initial structure of porous domain has more effective influence on detachment phenomenon than inlet fluid velocity it is obvious that in addition to lower maximum shear force in sample the average shear force in many pores is low and detachment cannot occur by comparing figs 9 and 6 we can conclude that in all samples there is a main path flow and detached particles are related to this path flow as change of porosity modifies the flow field the flow induced stress tensor τ can be utilized to evaluate this modification pham et al 2014 26 τ 1 2 μ u u t whereμis the dynamic viscosity of the fluid and u is the velocity vector the calculation of the probability distribution function of the fluid stresses in the pore space excluded the surface stresses on the fluid solid interfaces eq 26 is normalized by subtracting the mean stress τ and dividing by the standard deviation σ t of the stress distribution as follows porter et al 2005 27 τ τ τ σ t fig 10 provides the probability distribution function of the normalized shear stress in three porous domains the difference in the number of modes might be attributed to the non uniformity of the pore sizes using distributions shown in fig 10 it is possible to estimate probability of finding a certain range of stress in the flow field for a given porous in fig 11 the average shear forces at some cross sections are sketched the values of average shear forces do not vary during all simulations the rate of the variations of average shear forces is identical in three samples the highest shear forces occur near the outlet we can conclude that compared to inlet fluid velocity the average shear forces depend more on initial pore structure 4 5 detachment intensity in porous domains in fig 12 the frequency of detached cells has been sketched it is notable that detachment may occur in each detached cell more than one time in all cases the higher intensity of detachment occurs in the second half of porous domains the third and fourth quarters in sample with initial porosity of 38 2 the minimum detachment occurs near to the inlet but in other two samples the minimum detachment occurs in the second quarter of porous domain by considering figs 9 and 12 it can be concluded that the detachment pattern follow the geometry and initial porous domain of porous domain more than fluid inlet velocity in addition the most detachment in all samples occurs exactly in the same zones that we have the most shear stress in the final third of domains by comparing figs 8 and 11 it is found that in zones with lower detachment more particles are attached to the boundary of solid grains 5 summery and conclusion porosity and permeability of porous media are changed due to attachment and detachment of moving particles at the fluid solid interfaces in this study the importance of particle detachment and its effects on fluid flow and change of solid structures was explored three real porous media samples with identical topological properties but with different initial porosities of 38 2 45 9 and 52 1 were considered our main results have shown that a wide range of pore velocities with large values relative to the average pore velocities exist within a subset of pore throats the distributed large velocities resulted in creation of highly localized shear forces with magnitudes larger than the critical value needed for colloid detachment the initial porosity significantly impacts the location and distribution of large velocity location and shear forces and influenced the detachment behaviour the sample with lower initial porosity value showed a transient behaviour developing to the complete clogging of the sample samples with larger initial porosity values reached to early state state behaviour with no clogging of the media samples with larger initial porosities required higher average velocities to generate sufficiently large shear forces for particle detachment neglecting particle detachment results in early clogging events since detachment is absent to re mobilize some of the attached particles and to re open the pore space and also impacts the form of porosity permeability relation our resultsshow that coefficients of the porosity permeability relation are more sensitive to particle detachment for samples with larger initial porosities in general particle detachment significantly influenced coefficients b and c of the carman kozeny relation and coefficient a showed negligible sensitivity including particle detachment affects the pattern and distribution of the attached mass porous media with larger initial porosities showed relatively lower detachment and the detached mass was concentrated within the downstream locations of the sample author statement amin parvan conceptualization methodology software writing original draft preparation writing reviewing and editing saeedjafari conceptualization methodology software writing reviewing and editing supervision mohamadrahnama conceptualization supervision saeidnorouziapourvary conceptualization methodology writing reviewing and editing amir raoof conceptualization methodology writing reviewing and editing all authors confirm that this paper has not been submitted to any other journals it should be mentioned that all of authors agree to submit this manuscript to advances in water resources they also confirmed that this manuscript is their original work declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103888 appendix supplementary materials image application 1 
317,clogging of porous media is controlled by attachment of particles and their subsequent detachment in this study we explore particle transport at the pore scale by considering attachment and detachment processes we use pore structures of three samples which have similar topological properties but different initial porosities the main focus is on particle detachment after they are attached to the solid grain boundaries and to explore how particle detachment affects hydraulic properties and clogging of porous media a new approach was proposed by combining the lattice boltzmann method with a lagrangian method to simulate fluid flow and particle transport respectively comparisons between several simulations with and without detachment were used to evaluate the impact of particle detachment on fluid flow velocity distributions the coefficients of carman kozeny relation were used to relate porosity changes of each sample to its permeability alterations additionally the influence of the initial porosity of the sample and flow velocity on the detachment process was analysed the results show that compared to the impact of flow velocity the initial porosity of the media has a greater influence on controlling the rate of detachment and change of pore structures keywords porous media pore scale detachment process lattice boltzmann method attachment process fine particles clogging nomenclature f α boltzmann distribution function c α velocity vector in α direction τ hydrodynamic relaxation time f α e q equilibrium distribution function c lattice sound speed m s δx lattice length δt lattice time ωα weight coefficient for the α direction cs sound speed m s υ kinematic viscosity m2 s ρ fluid density kg m3 u fluid velocity m s m mass of particle kg v particle velocity m s fd hydrodynamic drag force μ dynamic viscosity pa s ac particle radius m σ shear stress pa σ cr critical shear stress pa f n adhesive force n c f friction coefficient kt particle stickiness to surface m cp particle mass concentration α empirical constant h hamaker coefficient l separation distance between the particle surfaces in filter cake m n m c r critical mobility number n r e c r critical reynolds number vcr critical shear velocity m s γ s specific weight of particle re reynolds number k permeability m2 k 0 initial permeability m2 ϕ porosity ϕ0 initial porosity i horizontal nodes counter j vertical nodes counter nx the number of lattice nodes in horizontal direction ny the number of lattice nodes in vertical direction φ s sphericity τ stress tensor σ t standard deviation τ mean stress τ normalized shear stress 1 introduction understanding attachment and detachment of fine particles in porous media is critical in several applications including chemical stewart and buriak 2000 environmental abdul mujeebu et al 2009 raoof and hassanizadeh 2010 raoof et al 2010 and petroleum technologies oil exploitation parazzo et al 2018 industrial filtering netter and conti 2016 groundwater utilization chequer et al 2019 wang et al 2020 grouting engineering zhou et al 2018 and industrial waste disposal tong et al 2019 several approaches including experimental bergendahl and grasso 2000 silliman et al 2001 haque et al 2017 chu et al 2019 computational raoof et al 2013 klimenko and maryshev 2019 benioug et al 2017 gaebler and eberl 2018 yoon et al 2015 and mathematical bedrikovetsky et al 2011 bedrikovetsky et al 2012 bergendahl and grasso 2000 schulz and knabner 2016 methods have been developed focusing on particle transport attachment and detachment of colloids in porous media attachment of particle at the solid grains alters topology and geometry of the pore structure and varies the fluid flow regime at the same time attachment of particles increases the hydrodynamic shear next to the grain surfaces which may cause detachment of the deposited particles coronado and diaz viera 2016 studied permeability loss due to fine migration and clogging using three experiments based on the study of bedrikovetsky et al 2011 they applied an extended mathematical model to simulate permeability impairment endo kokubun et al 2019 explored the effect of hydrodynamic forces on accumulation of particles in water saturated porous media their numerical results showed significant accumulation of particles in both low and high velocity regions they reported that during particle transport in homogeneous media particles are significantly accumulated in low velocity regions however the ultimate porous media clogging is occurred at high velocity regions in addition to particle attachment and retention detachment of fine particles can play a significant role in the clogging behaviour of porous media several studies have included particle detachment process to obtain effective parameters for adsorptive transport tufenkji 2007 kapellos et al 2007 han et al 2019 zhang et al 2019 zheng et al 2014 used a combined experimental mathematical analysis and found that detachment does not necessarily occur under lower darcy velocities and there exist a significant relation between the attachment detachment parameters and flow velocity cui et al 2017 evaluated the influence of flow velocity and its direction on detachment process using experimental observations quartz powder with sizes of 18 and 41 µm were used as colloids and quartz sand was used as porous media they observed that both parameters influence the detachment rate of the deposited particles however the magnitude of fluid velocity showed a larger impact on the detachment rate huang et al 2017 investigated the role of flow conditions fine sizes and fracture aperture on particles detachment during dewatering process a mathematical model was developed to describe single particle detachment mechanism they found a critical pressure gradient under which a massive amount of fine detachment occurred their results showed that with increasing the size of fine particles the pressure gradient required for fine detachment initially decreased to a minimum value called critical gradient pressure and subsequentlyincreased to a larger value during the attachment and detachment of fine particles permeability alterations occur due to porosity variation and change of pore structures the complex nature of porous media have caused challenges in developing relationships among permeability porosity grain size and fine sizes hommel et al 2018 several modelshave been developed to predict the permeability reduction due to particles retention including experimental verma and pruess 1988 civan 2001 thullner 2010 bacci et al 2011 and numerical zhang et al 2015 ju et al 2017 joodat et al 2018 approaches while some studies have applied a more realistic and complex pore structures xiao and yin 2016 rabbani et al 2018 many others were limited to simpler grain geometries like cylindrical shapes yazdchi et al 2011 endo kokubun et al 2019 porous media with identical porosity values often have different topologies i e the way that pore structures with different sizes are interconnected this difference can significantly affect the relationship between porosity and permeability of porous media which even have similar porosities lima et al 2020 showed that samples with higher pore connectivities i e larger pore coordination numbers provide much larger permeabilities compared to samples with similar porosities but with a less number of connected pores deo et al 2010 in an experimental modelling study investigated the permeability reduction in concrete samplesby retention of fine particles and pore clogging they used fine and coarse concrete samples as the matrix materials and observed a substantial permeability reduction when an incremental amount of finer sand was added to the porous concrete mixtures based on their observations they proposed a ratio of pore size to particle size under which permeability reduction is maximum and its reduction would not have a significant trend for coarser sands sato et al 2013 investigated the effect of trapped particles on permeability reduction using an image of real sand grains and applying lattice boltzmann method lbm to simulate fluid flow they used volume fraction and specific surface areas of both grains and the clogging particles to define a relation for permeability alteration they found that the reduction in permeability could not only be attributed to changes in volume fraction of fine particles to the pore volume but also to the size distribution of fine particles according to their results when medium porosity is more or lessconstant along the sample the order of magnitude of the resulting permeabilities is identical to porosity values whether the fine particles are fixed at random positions or they are trapped within the narrow pore throats montessori et al 2015 and montessori et al 2016 employed lattice boltzmann method to simulate strongly non equilibrium flows in porous media and reactive flow related to nano porous materials their results showed that non equilibrium effects increase the reactivity of the porous sample and provided quantitative assessment of the reactivity using the thickness of the reactive layer inside a nano porous catalytic sample ahfir et al 2016 investigated the influence of porous medium grain size and fine particle sizes on clogging and found that a larger number of particles were retained within the narrower pores however the fundamental mechanism of clogging in porous media caused by particle transport was not stated liu and mostaghimi 2017 performed parallel computations on 3d samples using lattice boltzmann and finite volume methods and simulated dissolution of a carbonate rock sample together with particle migration and reactive transport their simulations were conducted under low peclet regime to study the effect of flow rate on reactive transport using image based pore structures they showed that the resulting permeability porosity relation from modelling are less accurate when low resolution images are used for simulations li and prigiobbe 2018 developed a numerical model by the help of lbm immersed boundary method ibm and discrete element method dem they investigated fine particles motion in porous media using a two way coupling implemented between fluid flow and fine particles their results showed that both particle size and the structure of porous media can influence particle transport and retention this consequently could alter the flow regime and decrease the permeability in addition simulations showed that increase of pressure drop because of the retained particles can promote detachment and allow restoring the initial permeability ahkami et al 2020 studied pore scale behaviour of mineral precipitation patterns in a fractured porous medium employing a 2d phase field lattice boltzmann method they introduced a porosity permeability relation that considered species transport mineral precipitation and pore space geometry changes a wide range of diffusivity and reaction rates was explored to study different flow regimes ranging from advection to diffusion dominated regimes their results showed that permeability reduction is affected by clogging regime close to the flow inlet they found a linear reduction in permeability for the fracture isolation regime when the precipitation reactions narrowed down the fractures and permeability reduced slowly in the diffusive precipitation regime where precipitation reactions spread between solid grains in order to a better understanding of grain detachment and migration during reactive flow liu et al 2020 studied the effect of permeable grain boundaries on dissolution of carbonate rock with complex structure and porosities by a 2d grain scale modelling their results showed a decrease in permeability due to the clogging of transport pathways caused by grain detachment in addition they found that an increase in flow rate causes a reduction in detachment and fracture clogging by reducing local dissolution along grain boundaries parvan et al 2020 investigated the influence of initial porosity and different topology on the porosity permeability relationship using lbm for fluid flow simulation six real geometries were used to evaluate the clogging process three geometries with identical topologies but different initial porosities were used for investigating the influences of porous media geometrical effect and an extra three samples for which the solid grain were repositioned were used to study the porous media topological effects in our previous study parvan et al 2020 we explored the dependency of clogging on both porous media geometrical and topological propertiesby only considering particle attachment in this article in addition to particle attachment we include detachment of particlesto explore its impact porous media clogging particle detachment isimplemented by computing a critical shear force at the surfaces of solid grains several hydrodynamicalparameters are presented at the pore scale and the results are compared between simulations with and without particle detachment process the findings are explained by providing fluid velocity fields distribution of shear forces and particle attachment and how these are affected when particle detachment in included finally to show the influence of particle detachment at the larger sample scale we explored the effect of detachment process on coefficients of carman kozeny relation and how these coefficients change during adsorptive transport for simulations with and without detachment process 2 methodology and modelling assumptions to simulate fluid flow and particle transport including attachment and detachment of fine particles we have considered two sequential steps in our simulations first fluid flow is simulated to obtain a steady state flow for a given pore structure the pore structure is determined by the initial pore geometry as well as the subsequent attachment detachment of particles changing the pore structure in a second step using the established flow particle transport including attachment and detachment processes are simulated the challenges encountered in lattice boltzmann modelling of complex geometries are two folds first the representation of the complex geometry in the cartesian grid does not conform to the curved boundaries secondly in implementing the boundary conditions inaccurate distribution functions originated from the solid nodes may be generated during the streaming operation in our study the complex geometry is converted into binary data before the numerical solution the no slip boundary conditions are included using the standard bounce back sbb scheme in this study sbb scheme reverses the distribution functions at the stationary solid surfaces and is used very often in lbm method to represent the non slip boundary conditions it reverses and sends back the distribution functions penetrated to the stationary solid surface for our simulations we have combined the lbm for flow simulation with a lagrangian method for particle transport simulation in porous media the following assumptions have been considered for particles motion during attachment and detachment processes a through the simulations physical properties of fluid such as its dynamic viscosity and densityare unaffected because the concentration of the point particles in the fluid is sufficiently low b particle transport and particle detachment occur due to hydrodynamic drag forces and hydrodynamic shear force respectively and mechanism including interactions between fine particles gravity van der waals forces and electrostatic double layer forces are not considered this assumption is often made in studies considering horizontal flow feng et al 2015 bagalkot and kumar 2018 parvan et al 2020 which is consistent with our simulations c the injected particles have small size relative to the pore size and therefore their effect on fluid flow regime is negligible up to their deposition time after which the flow field is solved and velocities are updated accordingly d the distance between the surface of particles and grain boundaries are used as a measure for attachment and detachment of fine particles through defining a critical value for hydrodynamic shear force 3 mathematical model 3 1 fluid flow simulations lbm is an effective approach for numerical simulations of fluid flow which has been used in diverse studies succi 2001 sukop and thorne 2006 aidun and clausen 2010 parvan et al 2019 including pore scale simulation of flow through different porous media koponen et al 1998 koivu et al 2009 mattila et al 2016 lbmis a mesoscopic numerical method that can bridge the micro and the macro scales in lbm the fluid flow is solved based on discrete version of the boltzmann equation often bounce back algorithm is used in lbm to apply no slip boundary condition at the interface of fluid and solid grains in this study the d2q9 scheme is used and at each time step lbm equations are solved in a transient form until steady state flow is reached the lbm for fluid flow is described by the following discretized boltzmann equation 1 f α x c α δ t t δ t f α x t f α x t f α e q x t τ here f α is boltzmann distribution function to calculate density and velocity field and f α e q is distribution function in equilibrium state used for direction α in addition τ and c α mention hydrodynamic relaxation time and velocity vector in α direction respectively these parameters are expressed as 2 f α e q ω α ρ 1 3 c α u c 2 9 2 c α u 2 c 4 3 2 u u c 2 here c δx δt is related to the lattice sound speed δx and δt are lattice length and lattice time that both are selected as 1 and ωα is the weight coefficient for the α direction expressed as 3 ω α 4 9 α 0 1 9 α 1 2 3 4 1 36 α 5 6 7 8 4 τ υ c s 2 0 5 5 c α 0 α 0 cos π α 1 2 sin π α 1 2 c α 1 2 3 4 cos π α 4 1 2 2 sin π α 4 1 2 2 2 α 5 6 7 8 where c s c 3 and υ are sound speed and kinematic viscosity respectively the macroscopic variables of fluid such as density ρ x t and velocity u x t can be calculated by using of 6 ρ x t α f α x t 7 u x t α f α x t c α ρ x t 3 2 implemented boundary conditions in present simulations a non slip boundary condition is applied for top and bottom boundaries and a periodic boundary condition is used at the inlet and the outlet boundaries the unknown distribution functions in d2q9 lattice arrangement for each boundary are computed as 8 top boundary bounce back f 4 i n y f 2 i n y f 7 i n y f 5 i n y f 8 i n y f 6 i n y 9 bottom boundary bounce back f 2 i 1 f 4 i 1 f 5 i 1 f 7 i 1 f 6 i 1 f 8 i 1 10 inlet boundary periodic f 1 1 j f 1 n x j f 5 1 j f 5 n x j f 8 1 j f 8 n x j 11 outlet boundary periodic f 3 n x j f 3 1 j f 6 n x j f 6 1 j f 7 n x j f 7 1 j where i j nx and ny are the horizontal node indices the vertical node indices the number of lattice nodes in the horizontal direction and the number of lattice nodes in the vertical direction respectively moreover the fluid flow is driven by an extremely small body force on the fluid 3 3 simulating particle transport the motion of a particle in the flow field occurs in the lagrangian simulation step in response to the hydrodynamics drag forces the lagrangian equation of motion of a particle suspended in a fluid is given as 12 m d v d t f d where m is the mass of particle v is particle velocity and fd is hydrodynamic drag force the actual diameter size of the injected fine particles and the average grain diameter are 0 608 µm and 35 40 µm respectively when the reynolds number of the domain is low and the particle is not close to the channel wall the stokes drag force effects on the particle can be expressed as stokes 1850 horwitz and mani 2016 horwitz and mani 2018 qiu 2015 13 f d 6 π μ a c u v whereμ is dynamic viscosity ac is particle radius u fluid velocity and v is particle velocity 3 4 attachment mechanism after fluid flow simulation hydrodynamic drag force is implemented on the existing particles which include the attached particles at the solid boundaries as well as the suspended particle in the fluid phase the attachment of fine particles at the solid boundaries of grains during their transport could ultimately cause permeability reduction and clogging of the pores if conditions for clogging are favourable porous media becomes completely clogged and its permeability approaches zero in this research the distance between the surface of colloid and the boundary of grains was used as the main criterion to determine particle settlement if the distance between the fine colloid and grain boundary is equal or lower than the assumed particle radius the fine particle is considered as attached to the grain surface when the accumulated volume of attached particles in a numerical cell exceeds 90 of the cell volume that fluid cell is converted from fluid into a solid phase cell and the pore structure is updated accordingly the deposited particles can however detach in the presence of sufficient shear rate and the pore spaces re open parvan et al 2020 3 5 detachment mechanism in the presence of fluid flow when the shear force next to the surface of the deposited colloid increases and passes a critical value particle release and re entering into the balk fluid takes place some of the methods for computing the shear force on the boundary of solid grains are expressed in table 1 in eq 14 σ is shear stress and c is used to account for deviation from a sphere shape and μ d p and υ are the fluid viscosity particle diameter and interstitial fluid velocity respectively the direction of the interstitial fluid flow is parallel to solid the surface a friction force is considered in eq 15 to compute the critical shear forces between the attached particles and the pore surface this value could be additionally considered as a criterion for particle detachment f n is adhesive force acting on the deposited particles which results from summation of hydrodynamic force and including viscous drag force and dlvo forces the latter includes attractive lifshitz van der waals and electrostatic double layer forces acting on the deposited particles the parameter c f denotes a friction coefficient which is different for rolling sliding or other forms of particle motion in eq 16 civan 1990 1996a considered a critical shear stress where kt denotes the particle stickiness to surface and cp and α are particle mass concentration and an empirical constant respectively the critical shear stress predicted by potanin and uriev 1991 is based on the interactive van der waals energy between solid phases in the filter cake eq 17 in this relation h is the hamaker coefficient dp and l are the average particle diameter and the separation distance between the particle surfaces in filter cake respectively tremblay et al 1998 developed a critical condition for onset of particle mobilization by fluid shear based on the study of yalin and karahan 1979 and provided the following relation 19 n m c r 0 122 n r e c r a where a is 0 206 and n m c r and n r e c r are the critical mobility number and the critical reynolds number respectively these parameters can be expressed as 20 n m c r ρ υ c r 2 γ s d p 21 n r e c r ρ υ c r d p μ where υ c r and γ s are the critical shear velocity and specific weight of particles suspended in the fluid respectively by using eq 16 and using dimensionless groups tremblay et al 1998 correlated their experimental data on a full logarithmic scale and introduced a critical shear velocity as 22 υ c r 0 385 μ ρ a γ s b d p c ρ d where a b c and d considered 0 0934 0 453 0 36 and 0 453 respectively then they predicted the critical shear stress on the surface as 23 σ c r ρ υ c r 2 we used relations developed by tremblay et al 1998 mainly because of its simplicity using this relation we obtain the critical shear force needed for particle detachment in the presence of fluid flow 4 results and discussions simulations are conducted on real geometries from a sand pack with an original porosity of 36 the geometry of domains was obtained using x ray tomography method with a resolution of 10 µm a 2d slice of this image was used as the pore scale domain furthermore a numerical erosion was performed on this 2d slice to generate two extra pore scale domains i e a total of three pore structures which had similar arrangement of pores and grains but different porosity values in doing so to obtain a domain with a desired porosity value the imagej package rueden et al 2017 was used and image pixels corresponding to the surface of the solid grains were removed in a layer by layer manner for all grains until a desired porosity was obtained for each domain the physical size of the real porous domain is 380 800 µmin horizontal and vertical directions respectively the three geometries had initial porosity values of 38 2 45 9 and 52 1 which we refer to them as samples s1 s2 and s3 a non slip boundary condition was applied using a bounce back method at the top and bottom boundaries and the periodic boundary condition was implemented for both the inlet located at the left side of the domain and the outlet positioned at the right side of the domain boundaries to prevent the effect of inlet and outlet boundary conditions on fluid flow thorough porous domain two fluid jackets were considered before and after the inlet and outlet respectively grid independency tests have provided an optimum grid size of 237 500 in lattice unit for our porous domain the relaxation time was assumed to be 0 65 in lattice unit the parameter values are chosen in the range of natural groundwater and clay particles in the earth subsurface the bulk density of water is set to 1000 k g m 3 and the density of clay or clay loam immersed in groundwater should be between1000 and 1600 k g m 3 brady 1974 in our simulations colloid transport is driven by the hydrodynamic drag force and since density of colloids 1055 k g m 3 is very close to that of fluid solution the gravity and buoyancy forces are neglected in this study we validated our numerical model against a well known benchmark problem which uses cylindrical shape grains and uses kozeny carman equation to calculate permeability as a function of domains porosity hommel et al 2018 voronov et al 2010 lee and yang 1997 24 k ϕ s 2 d p 2 180 φ 3 1 φ 2 where φ s is the sphericity a dimensionless particle geometry parameter computed from li et al 2012 dp is the characteristic particle diameter and φ is the porosity the results of modeming tests and carman kozeny relation results are provided in fig 1 the validated model was used to perform simulations for particle transport thorough porous domains the diameter of the injected particles was 0 61 µm and the average grain diameters in three geometries were 40 5 37 9 and 35 9 micrometres respectively fine particles were injected into the fluid phase at equal distances at the inlet since the aim of this study was to explore detachment of the settled particles under different flow regime we began with applying low velocities in the inlet by using an extremely small body force on fluid for which no detachment happens in the subsequent simulations as inlet velocity was increased the critical velocity was found below which the detachment would not occur the reynolds number r e ρ u d μ based on the inlet fluid velocity and the average grain diameter for these three cases are 0 0005 0 0009 and 0 0019 respectively the magnitude of critical velocity was found to be larger for samples with grater initial porosities this trend could be attributed to the existence of wider pore throats in samples s2 and s3 and lower average velocity values under identical inlet fluid velocity through the pores of these samples fig 2 shows flow velocity distributions for the three pore structures using the same inlet flow velocity fig 3 shows the permeability reduction due to particle attachment during clogging process because of the larger initial porosity and fluid flow thorough domain s3 attachment occurs almost at the boundary of all grains in the other two samples particularlys1 fluid was transported thorough distinct pathways and the injected fine particles accumulated only in specific zones to highlight the influence of particle detachment in domains for each domain two series of simulations with velocities greater than critical inlet velocities were performed one by considering detachment process and one without detachment fig 4 shows simulation results for two situations i e with and without detachment green regions show zones where particle deposition at grains surfaces is occurred in this figure the inlet velocities for sample s1 s2 and s3 are set to 2 8 4 5 and 8 4 m day respectively the reynolds number r e ρ u d μ based on the mean fluid velocity at inlet and the average grain diameter for all three cases are 0 0013 0 0019 and 0 0034 respectively particle detachment caused obvious differences between pore structures and simulation results while considering or neglecting the detachment for better visualization and comparison yellow frames are sketched in the sample with initial porosity of 38 2 in sample s1 due to the low initial porosity clogging could occur fast but detachment delays clogging and because of this reason the attached particles in the final geometry in the state with detachment are more than the state without detachment in sample with initial porosity of 45 9 it is obvious that in the state without detachment attachment occurs in the whole domain but due to detachment process in other state attachment has almost negligible effect for sample s1 when detachment was included clogging occurred in longer period of time compared to simulations without detachment and solid particles had more time to deposit at the surface of grains see figure s3 for sample s1 in addition in presence of detachment in sample s1 most of particle deposition took place during time periods close the complete clogging in cases with detachment in samples s2 and s3 porous geometry was ultimately clogged however in cases without detachment a complete clogging did not occur which allowed the flow to continue and more particles could flow in and attach to the grains surfaces in fig 5 dimensionless permeability porosity relation porosity time relation and dimensionless permeability time relation are provided for different simulations variations in physical parameters such as porosity and permeability in sample s1 follow the same trend both with and without detachment included it is obvious that detachment process delays the clogging almost by two times during which lower porosities and permeabilities could be reached in sample s2 while a complete clogging occurred under no detachment scenario no significant variation in porosity and permeability was observed when detachment was included in sample s3 no variation in porosity and permeability was observed when inducing detachment processes however without detachment both porosity and permeability reduced and complete clogging occurred 4 1 fitting simulation data on carman kozeny relation there are several relations to explain the permeability reduction resulted from a decrease in porosity kozeny 1927 carman 1937 hommel et al 2018 during particle deposition on grains one of the well known relations in this field is carman kozeny relation which we used to fit on our results we used carman kozeny relation in the form of 25 k k 0 a φ φ 0 b 1 φ 1 φ 0 c where k and k 0 are permeability and initial permeability and ϕ and ϕ0 are porosity and initial porosity respectively parameters a b and c in this relation have been fitted to present relation between porosity and permeability based on carman kozeny relation this procedure was repeated for different simulations to investigate the impact of detachment process on these coefficients values are provided in table 2 the value of these parameters depends on different factors such as fluid flow properties specific surface area tortuosity sphericity particle diameter etc the value of coefficient a in all samples for with detachment and without detachment are almost 1 but there are differences in other parameters the magnitudes of b and c parameters decrease with an increase in initial porosity for without detachment state but these values are increased for the with detachment state it is notable that the difference between the magnitudes of both parameters b and c is increased with an increase in initial porosity it can be related to the increase in detachment influence in samples with higher initial porosities 4 2 detachment effect on velocity distribution fig 6 shows the fluid velocity distribution and facilitates the evaluation of the detachment effect on fluid velocity and the maximum fluid flow in the last step of simulation process the inlet fluid flow velocity for samples s1 s2 and s3 are 2 8 4 5 and 8 4 m day respectively according to this figure although sample s1 has the lower inlet velocity the fluid flow velocity in its pore throats is higher than others because of high detachment intensity in sample s2 and s3 fluid velocity in their pore throats cannot exceed too much detachment intensity in sample s2 and s3 is not very different and due to the higher inlet velocity the maximum fluid velocity value in sample s3 is more than its value in sample s2 the unaffected pore structures of samples s2 and s3 helps these samples to maintain their flow pathways over time fig 6 shows that major flow pathways are approximatelythe same in all samples and parameters such as inlet flow velocity difference in initial porosities and particle attachment detachment did not affect them significantly fig 7 shows the average fluid velocity histogram of three samples the behaviour of sample s1 varies over time while samples s2 and s3 does not show any significant changes in their porous structures and their average fluid velocities calculated at successive cross sections is unchanged over time in all three samples because of the porous geometry of the domain the average fluid velocities near the outlet are greater than the inlet geometry changes of sample s1 due to particle attachment and particle detachment causes variations in sample cross sections with time and therefore the average fluid velocity grows in this sample 4 3 detachment effects and adsorbed mass along porous domains during flow a fraction of the injected particles reach to the outlet boundary and exit porous domain while the rest of particles deposit on the solid grain surfaces a fraction of the deposited fine particles are detached and may redeposit on other solid grain located downstream of the flow and some of them may exit the domain the detachment process can postpone or prevent porous media clogging and in some cases fluid flow paths are considerably affected by the detached and attached particles fig 7 shows the adsorbed mass i e due to particle attachment in different locations of porous domains along the flow when sorption is with and without detachment process at the solid grains remarkably in the sample with initial porosity of 38 2 i e s1 the adsorbed mass when particle detachment is included is larger compared to the attached mass without detachment this behaviour is because the detachment process postpones complete clogging of the media by remobilizing a fraction of the attached particles which enables the fluid flow to continue for longer times and more particles will enter into the domain and attach on solid grains without possibility for detachment the pore structure is clogged at the earlier stages and flow is terminated fig 8 also shows that for the sample with initial porosity of 38 2 i e sample s1 more fine particles deposited near the inlet in samples with initial porosity of 45 9 and 52 1 because of higher initial porosity and higher inlet velocity detachment prevents strong clogging and attachment of fine particle occurs rather uniformly throughout the domain however without detachment the density of attached mass is larger at regions closer to the inlet of the porous media 4 4 evaluation of shear force in porous domain for better visualization of detachment in the samples fig 9 is sketched to show the distribution of shear forces in porous domains due to the lower initial porosity and inlet fluid velocity the value of shear forces in sample s1 are lower than sample s2 and s3 although the inlet fluid velocity in sample s3 is almost two times greater than sample s2 there is no significant difference in the values of shear force between them it can be concluded that the initial structure of porous domain has more effective influence on detachment phenomenon than inlet fluid velocity it is obvious that in addition to lower maximum shear force in sample the average shear force in many pores is low and detachment cannot occur by comparing figs 9 and 6 we can conclude that in all samples there is a main path flow and detached particles are related to this path flow as change of porosity modifies the flow field the flow induced stress tensor τ can be utilized to evaluate this modification pham et al 2014 26 τ 1 2 μ u u t whereμis the dynamic viscosity of the fluid and u is the velocity vector the calculation of the probability distribution function of the fluid stresses in the pore space excluded the surface stresses on the fluid solid interfaces eq 26 is normalized by subtracting the mean stress τ and dividing by the standard deviation σ t of the stress distribution as follows porter et al 2005 27 τ τ τ σ t fig 10 provides the probability distribution function of the normalized shear stress in three porous domains the difference in the number of modes might be attributed to the non uniformity of the pore sizes using distributions shown in fig 10 it is possible to estimate probability of finding a certain range of stress in the flow field for a given porous in fig 11 the average shear forces at some cross sections are sketched the values of average shear forces do not vary during all simulations the rate of the variations of average shear forces is identical in three samples the highest shear forces occur near the outlet we can conclude that compared to inlet fluid velocity the average shear forces depend more on initial pore structure 4 5 detachment intensity in porous domains in fig 12 the frequency of detached cells has been sketched it is notable that detachment may occur in each detached cell more than one time in all cases the higher intensity of detachment occurs in the second half of porous domains the third and fourth quarters in sample with initial porosity of 38 2 the minimum detachment occurs near to the inlet but in other two samples the minimum detachment occurs in the second quarter of porous domain by considering figs 9 and 12 it can be concluded that the detachment pattern follow the geometry and initial porous domain of porous domain more than fluid inlet velocity in addition the most detachment in all samples occurs exactly in the same zones that we have the most shear stress in the final third of domains by comparing figs 8 and 11 it is found that in zones with lower detachment more particles are attached to the boundary of solid grains 5 summery and conclusion porosity and permeability of porous media are changed due to attachment and detachment of moving particles at the fluid solid interfaces in this study the importance of particle detachment and its effects on fluid flow and change of solid structures was explored three real porous media samples with identical topological properties but with different initial porosities of 38 2 45 9 and 52 1 were considered our main results have shown that a wide range of pore velocities with large values relative to the average pore velocities exist within a subset of pore throats the distributed large velocities resulted in creation of highly localized shear forces with magnitudes larger than the critical value needed for colloid detachment the initial porosity significantly impacts the location and distribution of large velocity location and shear forces and influenced the detachment behaviour the sample with lower initial porosity value showed a transient behaviour developing to the complete clogging of the sample samples with larger initial porosity values reached to early state state behaviour with no clogging of the media samples with larger initial porosities required higher average velocities to generate sufficiently large shear forces for particle detachment neglecting particle detachment results in early clogging events since detachment is absent to re mobilize some of the attached particles and to re open the pore space and also impacts the form of porosity permeability relation our resultsshow that coefficients of the porosity permeability relation are more sensitive to particle detachment for samples with larger initial porosities in general particle detachment significantly influenced coefficients b and c of the carman kozeny relation and coefficient a showed negligible sensitivity including particle detachment affects the pattern and distribution of the attached mass porous media with larger initial porosities showed relatively lower detachment and the detached mass was concentrated within the downstream locations of the sample author statement amin parvan conceptualization methodology software writing original draft preparation writing reviewing and editing saeedjafari conceptualization methodology software writing reviewing and editing supervision mohamadrahnama conceptualization supervision saeidnorouziapourvary conceptualization methodology writing reviewing and editing amir raoof conceptualization methodology writing reviewing and editing all authors confirm that this paper has not been submitted to any other journals it should be mentioned that all of authors agree to submit this manuscript to advances in water resources they also confirmed that this manuscript is their original work declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103888 appendix supplementary materials image application 1 
318,anisotropy is a common feature for most of fibrous and porous media this article reports a new method for measuring the 2d anisotropic permeability of a porous rock utilizing the measurements obtained from the steady state flow between two concentric cylinders the mathematical analysis of the experimental data is based on the general solution of the pressure equation derived for the steady state flow equation for an anisotropic porous medium between two concentric cylinders the general solution incorporating the degree of anisotropy and the ratio between inner and outer cylinder radii is presented in a dimensionless form the solution shows that pressure distribution between the two cylinders is composed of an isotropic part plus a series representing the contribution of the anisotropy the solution is validated through the comparison against numerically derived results and the analytical solution of two extreme cases when the clearance between the two cylinders vanishes and when the material is isotropic the validation shows a perfect performance of the proposed solution even in the vicinity of the inner cylinder not like the approximate solutions existing in the literature the validation also shows that the truncation of the series part has an impact on the results specially in the case of extreme anisotropy two experimental procedures 1 basic approach and 2 modified approach utilizing the pear and tent charts derived from the general solution demonstrate how to obtain the principle permeabilities and their directions the applicability of the proposed experimental techniques is attained through the application of the modified approach over real experimental data from a holed core experiment to estimate anisotropic permeability parameters the application of the proposed technique and the required modifications for measuring the anisotropy in tight cores are discussed also the relation between the three dimension anisotropy and the presented plane anisotropy is presented keywords anisotropic porous medium steady state flow equivalent permeability basic and modified approaches pear and tent charts nomenclature superscript experiment axes 1 flow experiment in the first position in the modified approach before rotating the core 2 flow experiment in the second position in the modified approach after rotating the core subscript 1 inner cylinder 2 outer cylinder d dimensionless p principle direction f first section in core fig 10 s second section in core fig 10 symbols k k and k permeability equivalent isotropic permeability and permeability tensor l2 p pressure and dimensionless pressure ml 1t 2 q flow rate l3t 1 r radius l u dimensionless velocity v velocity vector lt 1 x dimensionless distance in x direction y dimensionless distance in y direction ς gas deviation volume factor α k y k x β r 2 r 1 θ polar angle rad γ angle between priciple axes and experiment axes rad μ fluid viscosity ml 1t 1 1 introduction any porous or fibrous material is characterized by different petrophysical parameters some of these parameters are pure material properties and others are material fluid properties some of the key material parameters are the permeability the thermal conductivity and the mass diffusivity these parameters characterize the material resistance to the flow of fluid heat and mass through the pores network respectively tiab and donaldson 1996 these three parameters are tensorial properties which are rarely found to be isotropic hence it is necessary to determine the principal values and their directions as they play an important role in the fluid flow modeling zhang and al kobaisi 2017 herein the article focuses on the laboratory measurement of the anisotropic permeability only although the mathematical analysis is applicable to the analysis of any tensorial property under the steady state flow regime the determination of the permeability anisotropy has a significant role in the design of different jobs related production injection of fluid from into the porous media some of the important and direct applications of the knowledge of the permeability anisotropy are as follow the determination of maximum and minimum permeability directions helps in locating perforations in the maximum permeability direction which enhances the well productivity injectivity hagoort 2007 the damage profile of the drilling fluid can be determined accurately in all direction around the well once the maximum and the minimum permeability directions are known due to the dependence of mud invasion on the permeability wu et al 2004 several flow equations such as modified darcy equation in horizontal wells requires the knowledge of both the minimum and the maximum permeability stewart 2011 cross validating the permeability anisotropy as an input for reservoir simulation studies that play a crucial role in the optimization of production injection strategies sinan et al 2020 wang et al 2018 over the field scale the electrical borehole imaging tools are utilized to estimate the anisotropic permeability see nian et al 2018 for a detialed comparison between different borehole imaging tools provided from several service companies however these logging tools are limited in their resolution and mainly rely on some correlations to estimate the anisotropic permeability therefore the laboratory flow experiment is expected to be the most accurate tool resolving the anisotropic permeability due to the high control over the resolution and the results are generated from a dynamic flow experiment utilizing darcy s law that has an explicit implantation of the anisotropic permeability then the measured laboratory anisotropic parameters are linked to the field directions through the correlation with marked grid north on the extracted cores collected during the drilling operation or from outcrops mcphee et al 2015 several techniques for the anisotropic permeability measurement in the laboratory have evolved from resin transfer moulding rtm adams et al 1988 provided the exact solution of the frontal advance in an isotropic medium and an approximate solution for the anisotropic case weitzenbӧck et al 1999 extended adams s isotropic solution to the anisotropic medium and developed a generic approach for principle permeabilities measurement without aligning the experiment axes with principal axes during rtm however all the algorithms related to rtm require a relatively large characteristic injection length as the effect of the circular inlet becomes negligible with large flood front radius chan and hwang 1991 hence the approximated analytical solutions are not suitable for relatively small size cores that are extracted from oil and water wells that are usually less than thirteen centimeters in diameter moreover the practical issues related to monitoring the flood front in rtm e g injection of high surface tension fluid like mercury to assure single phase flow donaldson and alam 2008 are very difficult to be applicable over core rocks that have much lower permeability than plastic fibers another way for characterizing the cores permeability is the permeability measurement of different core plugs and plotting the permeability versus the angle of the core plug scheidegger 1956 the early numerical studies performed in this domain showed how greatly the anisotropy and aspect ratio of core plug contribute in misleading permeability measurement bernabé 1992 the experimental study performed by johnson and hughes 1948 to determine the degree of anisotropy provided a comparison between two approaches and constructed the importance of anisotropy in water flooding oil recovery projects the analytical solution provided by mathias and butler 2007 for the steady state flow problem in hollow circular disk is only suitable for infinite outer boundary and not appropriate for finite domains as the transformation to elliptic coordinates produces non confocal ellipses for the outer and inner boundary because all these issues numerical solutions are widely used to describe the fluid flow in anisotropic porous media cf adams et al 1988 chemin 1974 the article is organized into five main sections mathematical analysis practical application and experiment instructions experiment discussion and conclusion the mathematical analysis section demonstrates all the mathematical aspects the geometrical configuration of the proposed problem the detailed explanation of all the steps required to reach to the solution the impact of the degree of the anisotropy and the geometry on the results and finally the validation of the new solution against its numerical solution and special cases from the literature then the utilization of the proposed solution in measuring the anisotropy parameters in the laboratory is demonstrated in practical application and experiment instructions the experimental setup and the analysis of real experimental data are described in experiment section the discussion section provides a criticized point of view for both the mathematical solution and the experimental procedure the article ends up by stating the conclusions and recommendations for future work 2 mathematical analysis 2 1 problem statement consider an anisotropic porous region between two concentric cylinders with inner and outer radii r 1 and r 2 respectively at the steady state flow regime the pressure of the inner cylinder is maintained at p 1 while the pressure of the outer one is maintained at p 2 as shown in fig 1 attempting to solve the following pressure equation that results from the substitution of darcy s law into the conservation of mass equation 1 k x 2 p x 2 k y 2 p y 2 0 p p 1 o n x 2 y 2 r 1 2 p p 2 o n x 2 y 2 r 2 2 where p is the pressure kx and ky are the permeabilities in the x and y directions principle directions respectively it shall be noted the analogy between system 1 and both the steady state heat transfer equation that results from the substitution of fourier s conduction heat law into conservation of energy equation and the steady state species diffusion equation that is generated from the substitution of fick s into the mass conservation equation therefore all the mathematical analysis that is presented here is applicable to all these pdes normalizing eq 1 making it dimensionless by introducing x x r 2 y y r 2 and p d p p 1 p 2 p 1 2 2 p d x 2 α 2 2 p d y 2 0 p d 0 o n x 2 y 2 β 2 p d 1 o n x 2 y 2 1 where α 2 k y k x is the degree of anisotropy 0 α2 1 and β r 1 r 2 is the geometric parameter 0 β 1 considering the transformation 3 x ρ α cos ϕ y ρ sin ϕ where ρ and ϕ are the parameters of a new the co ordinate system fig 2 it is possible to write the differential equation in 2 as 4 ρ 2 2 p d ρ 2 2 p d ϕ 2 ρ p d ρ 0 with the boundary conditions as 5 p d 0 o n ρ β ψ p d 1 o n ρ ψ where ψ α cos 2 ϕ α 2 sin 2 ϕ eq 4 considering the symmetry of the problem has the following general solution 6 p d a 0 b 0 ln ρ n 1 cos 2 n ϕ a n ρ 2 n b n ρ 2 n which is obtained by applying separation of variables approach appendix a using the boundary conditions 5 a linear algebraic system can be easily solved for the coefficients an bn in 6 2 2 results the number of terms in the series expansion was increased gradually until no significant changes were observed in the sum it was found that evaluating the first 30 terms of the sum in eq 6 is sufficient error is less than 10 6 the coefficients are evaluated by considering 31 equally spaced points on the outer cylinder and the same on the inner cylinder the dimensionless iso potential curves for the cases β 1 4 α2 0 5 and β 1 2 α2 1 are shown in fig 3 with the latter being the isotropic case the iso potential lines are circles are at the boundaries in all the cases while they are neither ellipses nor circles in the region in between for any degree of anisotropy except for isotropic case in reality measuring the fluid pressure is easily possible at the boundaries however such measurement is difficult at the region in between therefore we are interested in other practical parameters that can be easily evaluated in the laboratory like the flow velocity at the boundaries and the volumetric flow rate the flow velocity field is calculated through darcy s law as follows 7 v k μ p where v is the velocity vector k k x 0 0 k y is the permeability tensor and μ is the fluid viscosity we can define a dimensionless velocity at the boundaries u normal to the cylinders surfaces as 8 u r 2 μ k x k y p 2 p 1 v n where n is a unit vector normal to the outer cylinder and pointing outward fig 4 shows the normal dimensionless velocity distribution along the inner and the outer cylinders for β 1 2 at different degrees of anisotropy the figure clearly shows the impact of the anisotropy on the flow the velocity reaches its maxima at both outer and inner cylinder along x axis θ 0 where θ is the polar angle measured in the anticlockwise direction from the positive x axis which is aligned with the highest principle direction of the permeability tensor then the velocity starts to decrease until reaching its minima along y axis θ π 2 which is aligned with the minimum principle direction of the permeability tensor it is also important to realize that the velocity estimated at the same θ on both the two cylinders are not linearly correlated like the isotropic case this observation can be clarified from the investigation of the general solution 6 which indicates that in case of an anisotropic medium the terms inside the sum are added to the first two terms which correspond to isotropic case these terms are highly non linear and are functions in both ρ and ϕ therefore the behaviour of the pressure gradient field in the case of anisotropic medium is not simply correlated near boundaries like the isotropic case it is also possible to average the normal dimensionless velocity over the circumference of the outer cylinder as 9 u 2 1 2 π 0 2 π u 2 d θ u 2 is an important parameter for the lab measurements that is used to determine the anisotropic permeability parameters as it will be explained later in 3 practical application and experiment instructions fig 5 shows u 2 and the variation of u 2 with β for α2 0 7 the reduction in the clearance between the two boundaries increase in β increases u 2 for the same degree of anisotropy as shown in fig 5a that is due to the reduction in the flow resistance as the two radii get closer to each other also the increase in β leads to maximizing the difference between the maximum u 2 measured at θ 0 and the minimum q 2 measured at θ π 2 introducing a dimensionless equivalent permeability of the system as 10 k d k k x k y 2 π ln β u 2 where k is the equivalent permeability the permeability of the equivalent isotropic system that would maintain the conservation of mass fig 6 shows the variation of kd versus β for different values of α2 it is noted that that all the curves converge to unity when β 0 k k x k x which is a commonly used approximation in the field of hydrology and petroleum engineering hantush 1966 as the radius of the well inner cylinder radius in our case is very small compared to the reservoir radius outer cylinder in our problem however in the laboratory measurements β is not any more close to zero and thus the existence of inner hole must be taken into consideration when estimating kd fig 6 also shows that when β 1 kd reaches an asymptotic value that increases with the reduction in α2 these asymptotic values are used as one of the validation comparisons as will be shown later 2 3 validation in our point of view comparing the analytical solution with its corresponding numerical solution in most of the cases is not essential as it is just resolving the same system under the same conditions with another approach this comparison is expected to provide the same results with certain degree of accuracy depending on many parameters controlling the selected numerical scheme however the proposed general solution in this article is an infinite series and practically when its truncated version is used the solution is not always guaranteed to be within the acceptable accuracy convergence as mentioned previously the calculations conducted with the solution 6 are based on the first 30 members of the infinite series therefore the validation conducted here is to show the accuracy and the limitation when using the truncated serial solution and not to prove the correctness of the solution which can be easily proved through the substitution by the general solution 6 into differential equation in the system 2 instead of comparing the pressure iso potential with the simulation the main focus is devoted to ratio between the minimum and the maximum velocity at outer cylinder due to their practical importance further details on section 5 practical application fig 7 shows the excellent match between the numerical simulation results and the results generated using the proposed analytical approach in this article for further details it is referred to the supplementary matlab code that utilizes the thermal steady state flow toolbox to simulate the problem of interest by solving the corresponding mathematical system using the finite element however it shall be noted that the coefficients of eq 6 are produced from a highly ill conditioned matrix therefore the minimum α2 that we could reach based on the capabilities on our hand is 0 15 and below this value the system becomes singular another way for validating the proposed solution is to compare it against some special cases that have well known solutions two comparison are conducted when the medium is isotropic α2 1 and when the clearance between the two cylinders becomes very small β 1 the first case is the isotropic case ky kx for such case the boundary conditions 5 are independent on ϕ hence the infinite series in the general solution 6 that is function in ϕ vanishes and we are only left with the isotropic part in such condition the general solution 6 reduces to p d 1 ln ρ ln β with corresponding u 1 1 β ln β on the inner cylinder and u 2 1 ln β on the outer cylinder these results are the same as the well known steady state radial flow in an isotropic porous medium cf stewart 2011 as β 1 the clearance between the two cylinders becomes relatively narrow thus the iso potentials can be approximated as circles due to the circular characteristic of iso potentials at two boundaries therefore the flow field is approximately a radial flow with negligible pressure gradient in the θ direction p θ 0 in this circumstance it is expected that α 2 u 2 min u 2 max fig 8 shows the coincide between the unit slope line and the current approach when using β 0 99 this quasi circular nature of the iso potentials when β 1 makes it possible to estimate the angular permeability k θ which controls the flow in the r direction from the previous analysis it is possible to calculate the dimensionless velocity when β 1 using eq 8 as follows 11 u k θ k x k y r 2 p 2 p 1 p r k θ d r 2 p 2 p 1 p r where k θ d k θ k x k y which is figured out by the rotation of the axes by the angle θ this rotation results in non diagonalized k then the dimensionless velocity can be calculated as following 12 u r 2 k x k y p 2 p 1 k x cos 2 θ k y sin 2 θ 0 5 k x k y sin 2 θ 0 5 k x k y sin 2 θ k x sin 2 θ k y cos 2 θ p r 1 r p θ n 1 α cos 2 θ α sin 2 θ r 2 p 2 p 1 p r by the comparison between eqs 11 and 12 13 k θ d 1 α cos 2 θ α sin 2 θ the plot of 1 k θ d in polar coordinate is an ellipse with area always equal to π for any given α fig 9 reveals good match between 1 k θ d calculated using eq 13 and proposed approach in the article which works as another validation for the general solution 6 moreover when β 1 it can be easily figured out that 14 k d 1 2 π 0 2 π k θ d d θ 1 2 α 1 α this expression is in good agreement with the asymptotic values predicted from fig 6 3 practical application and experiment instructions the main purpose of this article is to put a step forward the complete design of an experiment that is capable of providing all the relevant information related to the anisotropy parameters direction and magnitudes of principle permeabilities herein the main focus is only on the planer antitropy two dimensional it is important to realize that the magnitude of principle permeabilities that are measured from a 2d experiment are in general not equivalent to magnitude of the principle permeabilities in the 3d space due to the non coincidence of the axes the relation between the measured permeability values from the 2d experiment and the actual anisotropic values in the 3d domain are derived in appendix b in the remaining of the article we will stick with the definitions given in section 2 mathematical analysis to avoid any confusion between three dimensional and two dimensional parameters except in appendix b the main target from the proposed experiment is measuring kx ky and their direction without any need for prior information about them up to this point all the analysis performed is based on that the direction of the principle permeability axes is known however it is usual that such piece of information is not available prior to conducting the experiment hence it is expected that the system axes x and y arbitrary experiment axes are not in general aligned with the principle permeability axes and there is exist a phase angle γ between the two systems as shown in fig 10 also r 1 is very small in the majority of laboratory experiments and it is difficult to perform any measurement at the surface of the inner cylinder except the pressure the situation is different in the field where the well radius is usually enough to perform rate measurements at sandface instead the proposed procedure shall rely on measurements performed on the outer circumference r r 2 to estimate the three unknowns kx ky and γ the approach that we are proposing counts on the measurement of two rates on the outer cylinder qf and qs in addition to the total rate 4qt qf is the measured rate of the first section the half of the first quarter close to x axis as shown in fig 10 while qs is the measured rate of the second section the half of the first quarter close to y axis as shown in fig 10 the variation of the sum of qf and qs and their difference both relative to qt is the key element to determining α and γ the top graph in fig 11 the pear plot shows the variation of the degree of anisotropy with q d i f f q t q f q s q t at different phase angles while the bottom graph in fig 11 the tent plot shows the variation of the degree of anisotropy with q s u m q t 1 q f q s q t 1 that is it if q d i f f q t and q s u m q t 1 are determined from laboratory measurements both α and γ can be determined by the use of the pear and the tent plots this idea is the core of the analysis of the laboratory measurements although the proposed algorithm is computerized the supplementary matlab script the approach is explained as handy graphical method that utilizes the pear and the tent plots to reveal how the calculations are performed both the pear and the tent plots are constructed for the β used in the experiment for γ between zero and π fig 11 shows the pear and the tent plots for β 0 1 and the charts for β 0 2 0 3 0 4 and 0 5 are provided in the supplementary material two algorithms are proposed for the measurement of the anisotropy a basic approach and a modified version first the instructions of the basic algorithm are presented then the modified version is explained to show its advantages over the basic approach 3 1 basic approach the basic approach is based on eight steps that can be summarized as following 1 set the arbitrary experiment axes x and y such that they follow standard right hand rule 2 divide the first quarter into two identical sections f and s fig 10 3 measure the flow rate from the two sections qf and qs and also over the entire outer circumference 4qt 4 estimate q d i f f q t using this value with the help of the pear chart fig 11 construct the first relation tabulated values between γ and α2 5 estimate q s u m q t 1 using this value with the help of the tent chart fig 11 construct the second relation between γ and α2 6 plot the two relations generated from steps 4 and 5 on the same plot either on cartesian or polar as shown in fig 12 referred as the intersection plot from the intersection point determine γ and k y k x 7 estimate k from the isotropic form of darcy s law using 4qt the pressure difference between inner and outer cylinder and fluid viscosity 8 estimate kd using fig 5 then by simple mathematical manipulation between these steps it is figured out that k x k α k d and k y α k k d the estimated γ is measured in clockwise direction from x axis to determine x axis the intersection chart fig 12 is one of four cases depending on the different combinations between estimated q d i f f q t and q s u m q t 1 that determine γ these four scenarios are 1 q d i f f q t 0 and q s u m q t 1 0 then 0 γ π 4 2 q d i f f q t 0 and q s u m q t 1 0 then π 4 γ π 2 3 q d i f f q t 0 and q s u m q t 1 0 then π 2 γ 3 π 4 4 q d i f f q t 0 and q s u m q t 1 0 then 3 π 4 γ π 3 2 modified approach the basic approach employs only the measurements of the flow rate from the first and the second section in the first quarter however the repetition of the measurements by choosing different orientation of the experiment axes usually produces different anisotropy ratio due to heterogeneity that exists in the selected sample moreover the measurements of the rate can be difficult because the narrow window π 4 of the measurement to overcome these two difficulties it is preferred to take measurements over a wider window and around the whole circumference of the outer cylinder therefore the modified approach is introduced to estimate qf and qs in a more generic way the rate measurements in the modified approach is taken from a quarter instead of half quarter where the window of the measurement is π 2 the algorithm of the modified approach can be summarized in the following steps 1 set arbitrary experiment axes x and y such that they follow standard right hand rule 2 measure q 1 1 q 2 1 q 3 1 q 4 1 which are the quarters flow rate in the first position of experiment axes fig 13 3 rotate the experiment axes by an angle equivalent to π 4 in the anticlockwise direction 4 again measure the q 1 2 q 2 2 q 3 2 q 4 2 which are the quarters flow rate in the second position of experiment axes fig 13 5 considering the symmetry around the principle axes q f 1 q f 3 q f 2 q f 4 q s 1 q s 3 q s 2 q s 4 determine q f 1 and q s 1 by solving the following over determined linear system using the least square method 15 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 q f 1 q s 1 q f 2 q s 2 q f 3 q s 3 q f 4 q s 4 q 1 1 q 2 1 q 3 1 q 4 1 q 1 2 q 2 2 q 3 2 q 4 2 0 0 0 0 6 use the estimated q f 1 and q s 1 as qf and qs respectively and the remaining steps are the same as the basic approach starting from step 4 in the basic approach algorithm the solution using the least square method is not necessary to satisfy the condition of symmetry mentioned in step 5 in the modified approach algorithm to assure this condition the arithmetic average of each pair of the sections that is expected to be identical is used as the rate of these sections cf durlofsky 2005 for a similar mathimatcal analysis used to estimate upscasled intrisic permeability from flow based simulation the estimated γ in modified approach is measured from x axis of the first position 4 experiment a real experiment is conducted to on a cylindrical core plug to estimate the anisotropy parameters using the method described previously 4 1 rock core preparation cylindrical rock core plug used in this study was chosen due to its anisotropic nature which was seen in previous study standard procedure was followed for cleaning using soxhlet extraction and drying using oven at elevated temperature 70 c the modified approach is selected for the analysis hence arbitrary axes were drawn to guide the direction at which the second experiment after rotation will be done as shown in fig 14 a the sample both ends were then covered by epoxy and sleeve to ensure that the flow is only coming from the radial directions no flow from both ends of the cylindrical rock core next standard drill bit with 1 20 cm diameter was used to drill the centric hole at which the fluid will be injected as shown in fig 14b the dimensions of the rock core are 15 24 cm length with 3 81 cm outer diameter therefore the experiment was done with β 0 315 the measured helium porosity of this sample is 15 02 fig 14 shows images for the rock core used in this study briefing the details mentioned in this section with side and top view of the core 4 2 experiment details procedure core flooding tests were conducted in special core holder designed for radial flow experiments fig 15 shows side view and top view of the rock core holder used for the core flooding experiments de ionized water was used as an injection fluid with viscosity equivalent to 1 cp the core flooding system has a total of four production ports the following steps were tracked in the core flooding experiments 1 the axial pressure is kept at 82 7 bar during the entire experiment 2 the injection fluid was pumped at different rates 4qt 5 10 15 and 20 cm3 min and the rates were controlled using teledyne isco 260d 3 the outlet pressure p 2 is always kept constant during the entire experiment at atmospheric pressure 1 013 bar 4 four graduated cylinders are used to collect the produced fluid from the four production ports as shown in fig 16 with the help of stopwatch the production rates are recorded manually from the four ports simultaneously a total of 12 readings are taken from each port at each injection rate in order to reduce the experimental erroneous this step is repeated for all the rates 5 the rock core is then rotated by π 4 to align the production lines with the axes drawn in rock core as discussed above in the sample preparation section then the steps from 1 to 4 are repeated to measure the rates coming from the four ports 4 3 analysis and results the 12 rate readings of each port are averaged and then the average rates are smoothed to ensure that the sum of the four ports rate is equivalent to pump rate table 1 lists the injection rates smoothed average production rates from the four ports and the injection pressure the superscript 1 and 2 indicates the production rates before rotation and after rotating the rock core with π 4 respectively to assure the steady state condition all of these measurements are only recorded after having stabilization of pressure readings plateau and not from the start of the experiment the linear system 15 is then solved using the method of least square at each injection rate and the arithmetic average is performed to assure the symmetry of the sections rates around the principle axes the best fit linear relations between qf qs and qt fig 17 a show that q d i f f q t 0 0027 while q s u m q t 1 0 4217 utilizing the slope of the best fit linear relation between the pressure drop and the pump injection rate fig 17b the estimated equivalent permeability found to be k 1 426 md the intersection plot fig 17c constructed using the pear and the tent charts of β 0 315 show that α2 0 4649 and γ 0 7485π using the estimated α2 and with the help of fig 6 kd is found to be equivalent to 1 426 fig 17d therefore kx 1 988 md and ky 0 924 md these results are comparable to the results obtained using the mini permeameter on core plugs extracted from the main core al azani et al 2019 5 discussion 5 1 space domain transformation the isotropic counterpart of the boundary value problem 2 as a result of the cylindrical nature of the problem would be typically solved in polar coordinates re coursing to the elliptic coordinates system as the case with the flow problem in unconfined porous medium mathias and butler 2007 to overcome the unequal permeabilities manages to deal with the coefficients however the inner and outer boundaries map to ellipses which are not confocal the present transformation 3 can be viewed as a mixture of the polar and the elliptic coordinates systems from transformation 3 eliminating ϕ leads to α x 2 y 2 ρ 2 which defines the first coordinates ρ constant as ellipses centered at the origin fig 2 eliminating ρ on the other hand guides to y x α tan ϕ which are straight lines through the origin fig 2 however the angle ϕ is not in general equivalent to the polar angle θ instead α tan ϕ tan θ the eccentricity of the constructed ellipses from the first transformation is 1 α 2 as circles have zero eccentricity the increase in the degree of anisotropy leads to more deviation from the radial flow and more localization of the field flow around the principle direction which has the higher permeability 5 2 experiment and data analysis instead of introducing explicit formulas of the three unknowns kx ky and γ a graphical procedure is proposed for analyzing the experiment data to estimate them although the existence of the general solution that is described by eq 6 it is difficult to follow a mathematical approach similar to the one proposed by weitzenöck et al 1999 that is based on the rotation of axes that is mainly due to complexity of the general solution 6 evolved from the infinite series and the mixed axes transformation in addition to that the need to solve an algebraic system of equations prevents introducing an explicit formula for the unknowns also applying an inverse modeling is not recommended due to the possibility of divergence if the selected initial guess is far from the correct solution unless a prior estimate is known from previous studies from the pear chart it is clear that q d i f f q t 0 for γ π 4 or 3 π 4 due to the symmetry of the experiment axes around one of the principle axes also when α2 0 q d i f f q t 1 for γ 0 or π due to flow focusing toward the first section and q d i f f q t 1 for γ π 2 because the flow focusing toward the second section this means that 16 lim α 2 0 q d i f f q t q d i f f q t 0 1 1 γ 0 0 π the corresponding γ0 for the estimated q d i f f q t from the experiment can be estimated from extrapolation of the pear relation on intersection plot to α2 0 the proposed steady state flow experiment can be applied for different lithology types sandstone carbonate and shale with variable petrophysical properties porosity permeability grain density for very tight samples inert gas such as helium can be used as the injection fluid to minimize the time required to reach to the steady state regime however the pressure drop between the inner and the outer cylinder shall be very small not to have a large change in the gas viscosity also it is preferred to conduct the experiment at high pressures to minimize both the gas slippage impact klinkenberg 1941 and compressibility if such conditions could not be achieved in the laboratory the modified pressure p μ ς d p where ς is the gas deviation volume factor can be used instead of the pressure to linearize the differential equation and solve it by the same approach al hussainy et al 1966 6 conclusion this article presents a general solution of the steady state flow problem describing a confined anisotropic porous media between two concentric cylinders the general solution introduced in dimensionless form shows how the pressure distribution inside the domain of interest is a contribution from an isotropic part plus and an anisotropic part represented by a sum of an infinite sequence the solution detects how the pressure varies between the two cylinders from its circular nature at the boundaries to non circular iso potential at the vicinity in between the novel general solution accurately estimates the iso potentials consequently the flow field in the region close to the inner cylinder that is usually approximated by elliptic transformation in the previous studies the analysis of the results shows that both the degree of anisotropy and the ratio between two radii have significant impacts on the flow field and equivalent isotropic permeability the validation of the current solution is demonstrated versus well known analytical solutions of special cases and through the comparison with the numerical simulation the obvious drawback of the presented solution is occurring in the extreme anisotropic cases due to the inability to determine the number of the effective terms of the infinite series that leads to convergence the presented results introduce a new technique for laboratory measurement of two dimensional anisotropy parameters using holed cores instead of whole core permeability approach the experimental algorithms are mainly based on the rate measurements on the outer cylinder which is suitable for laboratory procedures in summary the article introduces a new experimental methodology supported by the theoretical model as a laboratory test method for quantifying the 2d permeability field of a given formation using lab scale core flooding tests the analysis puts step forward introducing a general solution suitable for determining the three dimensional anisotropy credit authorship contribution statement abdallah a youssef methodology software writing original draft r s alassar methodology software writing original draft mohamed mahmoud conceptualization writing review editing mahmoud elsayed investigation writing review editing a y al dweik methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103884 appendix c supplementary materials image image 1 appendix a this appendix shows the detailed steps to arrive to the solution of eq 4 by applying the separation of variables technique the solution can be written as a 1 p d f ρ h ϕ i n β ψ ρ ψ π ϕ π considering the symmetry of the problem around x and y axes we can state the follows a 2 h 0 h π h 0 h π h ϕ h ϕ substituting into eq 4 we can obtain a 3 ρ 2 f ρ f f h h 2 λ eq a 3 is known as the eigen value problem where λ is the eigen value and the corresponding solution is the eigen function there are 3 cases for λ either λ 0 λ 0 or λ 0 the latter case is negligible as it produces a unique constant value of u over the whole domain of interest which is not consistent with the boundary conditions in a 2 hence by considering only the first and the second cases in addition to the symmetry conditions stated in a 2 we get a case λ 0 a 4 p d 0 a 0 ln ρ b 0 b case λ 0 a 5 p d n cos 2 n ϕ a n ρ 2 n b n ρ 2 n n 1 2 3 by applying the principle of superposition eqs a 4 and a 5 are summed up to yield the general solution 6 appendix b fig b1 shows the principle axis directions xp yp and zp which usually form an inclined xpyp plane with horizontal xy plane where the flow takes place during the experiment the velocity in three dimensional space is calculated using darcy s law eq 7 with full tensor intrinsic permeability which is defined as follows b 1 k k x x k x y k x z k y x k y y k y z k z x k z y k z r k x p 0 0 0 k y p 0 0 0 k z p r 1 where r is the rotation matrix which is defined as follows b 2 r r z r y r x cos θ y cos θ z sin θ x sin θ y cos θ z cos θ x sin θ z sin θ x sin θ z cos θ x sin θ y cos θ z sin θ z cos θ y cos θ x cos θ z sin θ x sin θ y sin θ z cos θ x sin θ y sin θ z sin θ x cos θ z sin θ y sin θ x cos θ y cos θ x cos θ y where r x 1 0 0 0 cos θ x sin θ x 0 sin θ x cos θ x r y cos θ y 0 sin θ y 0 1 0 sin θ y 0 cos θ y and r z cos θ z sin θ z 0 sin θ z cos θ z 0 0 0 1 are the rotation matrices around x y and zaxes and θ x θ y and θ z are the counter clockwise rotation angles around them respectively the proposed experiment setup in this article is applying no flow boundary conditions in z direction top and bottom boundaries of core and the injection is taking place over the entire height of the core fully penetrating hole therefore the velocity in the z direction vanishes hence the following relation can be derived from z component of the velocity b 3 p z 1 k z z k z x p x k z y p y substituting by eq b 3 into both x and y velocity components leads to b 4 v x v y 1 μ k x x k z z k x z 2 k z z k x y k z z k x z k y z k z z k x y k z z k x z k y z k z z k y y k z z k y z 2 k z z p x p y the measured permeabilities in two dimensional planes are the eigen values of the permeability tenor in eq b 4 
318,anisotropy is a common feature for most of fibrous and porous media this article reports a new method for measuring the 2d anisotropic permeability of a porous rock utilizing the measurements obtained from the steady state flow between two concentric cylinders the mathematical analysis of the experimental data is based on the general solution of the pressure equation derived for the steady state flow equation for an anisotropic porous medium between two concentric cylinders the general solution incorporating the degree of anisotropy and the ratio between inner and outer cylinder radii is presented in a dimensionless form the solution shows that pressure distribution between the two cylinders is composed of an isotropic part plus a series representing the contribution of the anisotropy the solution is validated through the comparison against numerically derived results and the analytical solution of two extreme cases when the clearance between the two cylinders vanishes and when the material is isotropic the validation shows a perfect performance of the proposed solution even in the vicinity of the inner cylinder not like the approximate solutions existing in the literature the validation also shows that the truncation of the series part has an impact on the results specially in the case of extreme anisotropy two experimental procedures 1 basic approach and 2 modified approach utilizing the pear and tent charts derived from the general solution demonstrate how to obtain the principle permeabilities and their directions the applicability of the proposed experimental techniques is attained through the application of the modified approach over real experimental data from a holed core experiment to estimate anisotropic permeability parameters the application of the proposed technique and the required modifications for measuring the anisotropy in tight cores are discussed also the relation between the three dimension anisotropy and the presented plane anisotropy is presented keywords anisotropic porous medium steady state flow equivalent permeability basic and modified approaches pear and tent charts nomenclature superscript experiment axes 1 flow experiment in the first position in the modified approach before rotating the core 2 flow experiment in the second position in the modified approach after rotating the core subscript 1 inner cylinder 2 outer cylinder d dimensionless p principle direction f first section in core fig 10 s second section in core fig 10 symbols k k and k permeability equivalent isotropic permeability and permeability tensor l2 p pressure and dimensionless pressure ml 1t 2 q flow rate l3t 1 r radius l u dimensionless velocity v velocity vector lt 1 x dimensionless distance in x direction y dimensionless distance in y direction ς gas deviation volume factor α k y k x β r 2 r 1 θ polar angle rad γ angle between priciple axes and experiment axes rad μ fluid viscosity ml 1t 1 1 introduction any porous or fibrous material is characterized by different petrophysical parameters some of these parameters are pure material properties and others are material fluid properties some of the key material parameters are the permeability the thermal conductivity and the mass diffusivity these parameters characterize the material resistance to the flow of fluid heat and mass through the pores network respectively tiab and donaldson 1996 these three parameters are tensorial properties which are rarely found to be isotropic hence it is necessary to determine the principal values and their directions as they play an important role in the fluid flow modeling zhang and al kobaisi 2017 herein the article focuses on the laboratory measurement of the anisotropic permeability only although the mathematical analysis is applicable to the analysis of any tensorial property under the steady state flow regime the determination of the permeability anisotropy has a significant role in the design of different jobs related production injection of fluid from into the porous media some of the important and direct applications of the knowledge of the permeability anisotropy are as follow the determination of maximum and minimum permeability directions helps in locating perforations in the maximum permeability direction which enhances the well productivity injectivity hagoort 2007 the damage profile of the drilling fluid can be determined accurately in all direction around the well once the maximum and the minimum permeability directions are known due to the dependence of mud invasion on the permeability wu et al 2004 several flow equations such as modified darcy equation in horizontal wells requires the knowledge of both the minimum and the maximum permeability stewart 2011 cross validating the permeability anisotropy as an input for reservoir simulation studies that play a crucial role in the optimization of production injection strategies sinan et al 2020 wang et al 2018 over the field scale the electrical borehole imaging tools are utilized to estimate the anisotropic permeability see nian et al 2018 for a detialed comparison between different borehole imaging tools provided from several service companies however these logging tools are limited in their resolution and mainly rely on some correlations to estimate the anisotropic permeability therefore the laboratory flow experiment is expected to be the most accurate tool resolving the anisotropic permeability due to the high control over the resolution and the results are generated from a dynamic flow experiment utilizing darcy s law that has an explicit implantation of the anisotropic permeability then the measured laboratory anisotropic parameters are linked to the field directions through the correlation with marked grid north on the extracted cores collected during the drilling operation or from outcrops mcphee et al 2015 several techniques for the anisotropic permeability measurement in the laboratory have evolved from resin transfer moulding rtm adams et al 1988 provided the exact solution of the frontal advance in an isotropic medium and an approximate solution for the anisotropic case weitzenbӧck et al 1999 extended adams s isotropic solution to the anisotropic medium and developed a generic approach for principle permeabilities measurement without aligning the experiment axes with principal axes during rtm however all the algorithms related to rtm require a relatively large characteristic injection length as the effect of the circular inlet becomes negligible with large flood front radius chan and hwang 1991 hence the approximated analytical solutions are not suitable for relatively small size cores that are extracted from oil and water wells that are usually less than thirteen centimeters in diameter moreover the practical issues related to monitoring the flood front in rtm e g injection of high surface tension fluid like mercury to assure single phase flow donaldson and alam 2008 are very difficult to be applicable over core rocks that have much lower permeability than plastic fibers another way for characterizing the cores permeability is the permeability measurement of different core plugs and plotting the permeability versus the angle of the core plug scheidegger 1956 the early numerical studies performed in this domain showed how greatly the anisotropy and aspect ratio of core plug contribute in misleading permeability measurement bernabé 1992 the experimental study performed by johnson and hughes 1948 to determine the degree of anisotropy provided a comparison between two approaches and constructed the importance of anisotropy in water flooding oil recovery projects the analytical solution provided by mathias and butler 2007 for the steady state flow problem in hollow circular disk is only suitable for infinite outer boundary and not appropriate for finite domains as the transformation to elliptic coordinates produces non confocal ellipses for the outer and inner boundary because all these issues numerical solutions are widely used to describe the fluid flow in anisotropic porous media cf adams et al 1988 chemin 1974 the article is organized into five main sections mathematical analysis practical application and experiment instructions experiment discussion and conclusion the mathematical analysis section demonstrates all the mathematical aspects the geometrical configuration of the proposed problem the detailed explanation of all the steps required to reach to the solution the impact of the degree of the anisotropy and the geometry on the results and finally the validation of the new solution against its numerical solution and special cases from the literature then the utilization of the proposed solution in measuring the anisotropy parameters in the laboratory is demonstrated in practical application and experiment instructions the experimental setup and the analysis of real experimental data are described in experiment section the discussion section provides a criticized point of view for both the mathematical solution and the experimental procedure the article ends up by stating the conclusions and recommendations for future work 2 mathematical analysis 2 1 problem statement consider an anisotropic porous region between two concentric cylinders with inner and outer radii r 1 and r 2 respectively at the steady state flow regime the pressure of the inner cylinder is maintained at p 1 while the pressure of the outer one is maintained at p 2 as shown in fig 1 attempting to solve the following pressure equation that results from the substitution of darcy s law into the conservation of mass equation 1 k x 2 p x 2 k y 2 p y 2 0 p p 1 o n x 2 y 2 r 1 2 p p 2 o n x 2 y 2 r 2 2 where p is the pressure kx and ky are the permeabilities in the x and y directions principle directions respectively it shall be noted the analogy between system 1 and both the steady state heat transfer equation that results from the substitution of fourier s conduction heat law into conservation of energy equation and the steady state species diffusion equation that is generated from the substitution of fick s into the mass conservation equation therefore all the mathematical analysis that is presented here is applicable to all these pdes normalizing eq 1 making it dimensionless by introducing x x r 2 y y r 2 and p d p p 1 p 2 p 1 2 2 p d x 2 α 2 2 p d y 2 0 p d 0 o n x 2 y 2 β 2 p d 1 o n x 2 y 2 1 where α 2 k y k x is the degree of anisotropy 0 α2 1 and β r 1 r 2 is the geometric parameter 0 β 1 considering the transformation 3 x ρ α cos ϕ y ρ sin ϕ where ρ and ϕ are the parameters of a new the co ordinate system fig 2 it is possible to write the differential equation in 2 as 4 ρ 2 2 p d ρ 2 2 p d ϕ 2 ρ p d ρ 0 with the boundary conditions as 5 p d 0 o n ρ β ψ p d 1 o n ρ ψ where ψ α cos 2 ϕ α 2 sin 2 ϕ eq 4 considering the symmetry of the problem has the following general solution 6 p d a 0 b 0 ln ρ n 1 cos 2 n ϕ a n ρ 2 n b n ρ 2 n which is obtained by applying separation of variables approach appendix a using the boundary conditions 5 a linear algebraic system can be easily solved for the coefficients an bn in 6 2 2 results the number of terms in the series expansion was increased gradually until no significant changes were observed in the sum it was found that evaluating the first 30 terms of the sum in eq 6 is sufficient error is less than 10 6 the coefficients are evaluated by considering 31 equally spaced points on the outer cylinder and the same on the inner cylinder the dimensionless iso potential curves for the cases β 1 4 α2 0 5 and β 1 2 α2 1 are shown in fig 3 with the latter being the isotropic case the iso potential lines are circles are at the boundaries in all the cases while they are neither ellipses nor circles in the region in between for any degree of anisotropy except for isotropic case in reality measuring the fluid pressure is easily possible at the boundaries however such measurement is difficult at the region in between therefore we are interested in other practical parameters that can be easily evaluated in the laboratory like the flow velocity at the boundaries and the volumetric flow rate the flow velocity field is calculated through darcy s law as follows 7 v k μ p where v is the velocity vector k k x 0 0 k y is the permeability tensor and μ is the fluid viscosity we can define a dimensionless velocity at the boundaries u normal to the cylinders surfaces as 8 u r 2 μ k x k y p 2 p 1 v n where n is a unit vector normal to the outer cylinder and pointing outward fig 4 shows the normal dimensionless velocity distribution along the inner and the outer cylinders for β 1 2 at different degrees of anisotropy the figure clearly shows the impact of the anisotropy on the flow the velocity reaches its maxima at both outer and inner cylinder along x axis θ 0 where θ is the polar angle measured in the anticlockwise direction from the positive x axis which is aligned with the highest principle direction of the permeability tensor then the velocity starts to decrease until reaching its minima along y axis θ π 2 which is aligned with the minimum principle direction of the permeability tensor it is also important to realize that the velocity estimated at the same θ on both the two cylinders are not linearly correlated like the isotropic case this observation can be clarified from the investigation of the general solution 6 which indicates that in case of an anisotropic medium the terms inside the sum are added to the first two terms which correspond to isotropic case these terms are highly non linear and are functions in both ρ and ϕ therefore the behaviour of the pressure gradient field in the case of anisotropic medium is not simply correlated near boundaries like the isotropic case it is also possible to average the normal dimensionless velocity over the circumference of the outer cylinder as 9 u 2 1 2 π 0 2 π u 2 d θ u 2 is an important parameter for the lab measurements that is used to determine the anisotropic permeability parameters as it will be explained later in 3 practical application and experiment instructions fig 5 shows u 2 and the variation of u 2 with β for α2 0 7 the reduction in the clearance between the two boundaries increase in β increases u 2 for the same degree of anisotropy as shown in fig 5a that is due to the reduction in the flow resistance as the two radii get closer to each other also the increase in β leads to maximizing the difference between the maximum u 2 measured at θ 0 and the minimum q 2 measured at θ π 2 introducing a dimensionless equivalent permeability of the system as 10 k d k k x k y 2 π ln β u 2 where k is the equivalent permeability the permeability of the equivalent isotropic system that would maintain the conservation of mass fig 6 shows the variation of kd versus β for different values of α2 it is noted that that all the curves converge to unity when β 0 k k x k x which is a commonly used approximation in the field of hydrology and petroleum engineering hantush 1966 as the radius of the well inner cylinder radius in our case is very small compared to the reservoir radius outer cylinder in our problem however in the laboratory measurements β is not any more close to zero and thus the existence of inner hole must be taken into consideration when estimating kd fig 6 also shows that when β 1 kd reaches an asymptotic value that increases with the reduction in α2 these asymptotic values are used as one of the validation comparisons as will be shown later 2 3 validation in our point of view comparing the analytical solution with its corresponding numerical solution in most of the cases is not essential as it is just resolving the same system under the same conditions with another approach this comparison is expected to provide the same results with certain degree of accuracy depending on many parameters controlling the selected numerical scheme however the proposed general solution in this article is an infinite series and practically when its truncated version is used the solution is not always guaranteed to be within the acceptable accuracy convergence as mentioned previously the calculations conducted with the solution 6 are based on the first 30 members of the infinite series therefore the validation conducted here is to show the accuracy and the limitation when using the truncated serial solution and not to prove the correctness of the solution which can be easily proved through the substitution by the general solution 6 into differential equation in the system 2 instead of comparing the pressure iso potential with the simulation the main focus is devoted to ratio between the minimum and the maximum velocity at outer cylinder due to their practical importance further details on section 5 practical application fig 7 shows the excellent match between the numerical simulation results and the results generated using the proposed analytical approach in this article for further details it is referred to the supplementary matlab code that utilizes the thermal steady state flow toolbox to simulate the problem of interest by solving the corresponding mathematical system using the finite element however it shall be noted that the coefficients of eq 6 are produced from a highly ill conditioned matrix therefore the minimum α2 that we could reach based on the capabilities on our hand is 0 15 and below this value the system becomes singular another way for validating the proposed solution is to compare it against some special cases that have well known solutions two comparison are conducted when the medium is isotropic α2 1 and when the clearance between the two cylinders becomes very small β 1 the first case is the isotropic case ky kx for such case the boundary conditions 5 are independent on ϕ hence the infinite series in the general solution 6 that is function in ϕ vanishes and we are only left with the isotropic part in such condition the general solution 6 reduces to p d 1 ln ρ ln β with corresponding u 1 1 β ln β on the inner cylinder and u 2 1 ln β on the outer cylinder these results are the same as the well known steady state radial flow in an isotropic porous medium cf stewart 2011 as β 1 the clearance between the two cylinders becomes relatively narrow thus the iso potentials can be approximated as circles due to the circular characteristic of iso potentials at two boundaries therefore the flow field is approximately a radial flow with negligible pressure gradient in the θ direction p θ 0 in this circumstance it is expected that α 2 u 2 min u 2 max fig 8 shows the coincide between the unit slope line and the current approach when using β 0 99 this quasi circular nature of the iso potentials when β 1 makes it possible to estimate the angular permeability k θ which controls the flow in the r direction from the previous analysis it is possible to calculate the dimensionless velocity when β 1 using eq 8 as follows 11 u k θ k x k y r 2 p 2 p 1 p r k θ d r 2 p 2 p 1 p r where k θ d k θ k x k y which is figured out by the rotation of the axes by the angle θ this rotation results in non diagonalized k then the dimensionless velocity can be calculated as following 12 u r 2 k x k y p 2 p 1 k x cos 2 θ k y sin 2 θ 0 5 k x k y sin 2 θ 0 5 k x k y sin 2 θ k x sin 2 θ k y cos 2 θ p r 1 r p θ n 1 α cos 2 θ α sin 2 θ r 2 p 2 p 1 p r by the comparison between eqs 11 and 12 13 k θ d 1 α cos 2 θ α sin 2 θ the plot of 1 k θ d in polar coordinate is an ellipse with area always equal to π for any given α fig 9 reveals good match between 1 k θ d calculated using eq 13 and proposed approach in the article which works as another validation for the general solution 6 moreover when β 1 it can be easily figured out that 14 k d 1 2 π 0 2 π k θ d d θ 1 2 α 1 α this expression is in good agreement with the asymptotic values predicted from fig 6 3 practical application and experiment instructions the main purpose of this article is to put a step forward the complete design of an experiment that is capable of providing all the relevant information related to the anisotropy parameters direction and magnitudes of principle permeabilities herein the main focus is only on the planer antitropy two dimensional it is important to realize that the magnitude of principle permeabilities that are measured from a 2d experiment are in general not equivalent to magnitude of the principle permeabilities in the 3d space due to the non coincidence of the axes the relation between the measured permeability values from the 2d experiment and the actual anisotropic values in the 3d domain are derived in appendix b in the remaining of the article we will stick with the definitions given in section 2 mathematical analysis to avoid any confusion between three dimensional and two dimensional parameters except in appendix b the main target from the proposed experiment is measuring kx ky and their direction without any need for prior information about them up to this point all the analysis performed is based on that the direction of the principle permeability axes is known however it is usual that such piece of information is not available prior to conducting the experiment hence it is expected that the system axes x and y arbitrary experiment axes are not in general aligned with the principle permeability axes and there is exist a phase angle γ between the two systems as shown in fig 10 also r 1 is very small in the majority of laboratory experiments and it is difficult to perform any measurement at the surface of the inner cylinder except the pressure the situation is different in the field where the well radius is usually enough to perform rate measurements at sandface instead the proposed procedure shall rely on measurements performed on the outer circumference r r 2 to estimate the three unknowns kx ky and γ the approach that we are proposing counts on the measurement of two rates on the outer cylinder qf and qs in addition to the total rate 4qt qf is the measured rate of the first section the half of the first quarter close to x axis as shown in fig 10 while qs is the measured rate of the second section the half of the first quarter close to y axis as shown in fig 10 the variation of the sum of qf and qs and their difference both relative to qt is the key element to determining α and γ the top graph in fig 11 the pear plot shows the variation of the degree of anisotropy with q d i f f q t q f q s q t at different phase angles while the bottom graph in fig 11 the tent plot shows the variation of the degree of anisotropy with q s u m q t 1 q f q s q t 1 that is it if q d i f f q t and q s u m q t 1 are determined from laboratory measurements both α and γ can be determined by the use of the pear and the tent plots this idea is the core of the analysis of the laboratory measurements although the proposed algorithm is computerized the supplementary matlab script the approach is explained as handy graphical method that utilizes the pear and the tent plots to reveal how the calculations are performed both the pear and the tent plots are constructed for the β used in the experiment for γ between zero and π fig 11 shows the pear and the tent plots for β 0 1 and the charts for β 0 2 0 3 0 4 and 0 5 are provided in the supplementary material two algorithms are proposed for the measurement of the anisotropy a basic approach and a modified version first the instructions of the basic algorithm are presented then the modified version is explained to show its advantages over the basic approach 3 1 basic approach the basic approach is based on eight steps that can be summarized as following 1 set the arbitrary experiment axes x and y such that they follow standard right hand rule 2 divide the first quarter into two identical sections f and s fig 10 3 measure the flow rate from the two sections qf and qs and also over the entire outer circumference 4qt 4 estimate q d i f f q t using this value with the help of the pear chart fig 11 construct the first relation tabulated values between γ and α2 5 estimate q s u m q t 1 using this value with the help of the tent chart fig 11 construct the second relation between γ and α2 6 plot the two relations generated from steps 4 and 5 on the same plot either on cartesian or polar as shown in fig 12 referred as the intersection plot from the intersection point determine γ and k y k x 7 estimate k from the isotropic form of darcy s law using 4qt the pressure difference between inner and outer cylinder and fluid viscosity 8 estimate kd using fig 5 then by simple mathematical manipulation between these steps it is figured out that k x k α k d and k y α k k d the estimated γ is measured in clockwise direction from x axis to determine x axis the intersection chart fig 12 is one of four cases depending on the different combinations between estimated q d i f f q t and q s u m q t 1 that determine γ these four scenarios are 1 q d i f f q t 0 and q s u m q t 1 0 then 0 γ π 4 2 q d i f f q t 0 and q s u m q t 1 0 then π 4 γ π 2 3 q d i f f q t 0 and q s u m q t 1 0 then π 2 γ 3 π 4 4 q d i f f q t 0 and q s u m q t 1 0 then 3 π 4 γ π 3 2 modified approach the basic approach employs only the measurements of the flow rate from the first and the second section in the first quarter however the repetition of the measurements by choosing different orientation of the experiment axes usually produces different anisotropy ratio due to heterogeneity that exists in the selected sample moreover the measurements of the rate can be difficult because the narrow window π 4 of the measurement to overcome these two difficulties it is preferred to take measurements over a wider window and around the whole circumference of the outer cylinder therefore the modified approach is introduced to estimate qf and qs in a more generic way the rate measurements in the modified approach is taken from a quarter instead of half quarter where the window of the measurement is π 2 the algorithm of the modified approach can be summarized in the following steps 1 set arbitrary experiment axes x and y such that they follow standard right hand rule 2 measure q 1 1 q 2 1 q 3 1 q 4 1 which are the quarters flow rate in the first position of experiment axes fig 13 3 rotate the experiment axes by an angle equivalent to π 4 in the anticlockwise direction 4 again measure the q 1 2 q 2 2 q 3 2 q 4 2 which are the quarters flow rate in the second position of experiment axes fig 13 5 considering the symmetry around the principle axes q f 1 q f 3 q f 2 q f 4 q s 1 q s 3 q s 2 q s 4 determine q f 1 and q s 1 by solving the following over determined linear system using the least square method 15 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 1 q f 1 q s 1 q f 2 q s 2 q f 3 q s 3 q f 4 q s 4 q 1 1 q 2 1 q 3 1 q 4 1 q 1 2 q 2 2 q 3 2 q 4 2 0 0 0 0 6 use the estimated q f 1 and q s 1 as qf and qs respectively and the remaining steps are the same as the basic approach starting from step 4 in the basic approach algorithm the solution using the least square method is not necessary to satisfy the condition of symmetry mentioned in step 5 in the modified approach algorithm to assure this condition the arithmetic average of each pair of the sections that is expected to be identical is used as the rate of these sections cf durlofsky 2005 for a similar mathimatcal analysis used to estimate upscasled intrisic permeability from flow based simulation the estimated γ in modified approach is measured from x axis of the first position 4 experiment a real experiment is conducted to on a cylindrical core plug to estimate the anisotropy parameters using the method described previously 4 1 rock core preparation cylindrical rock core plug used in this study was chosen due to its anisotropic nature which was seen in previous study standard procedure was followed for cleaning using soxhlet extraction and drying using oven at elevated temperature 70 c the modified approach is selected for the analysis hence arbitrary axes were drawn to guide the direction at which the second experiment after rotation will be done as shown in fig 14 a the sample both ends were then covered by epoxy and sleeve to ensure that the flow is only coming from the radial directions no flow from both ends of the cylindrical rock core next standard drill bit with 1 20 cm diameter was used to drill the centric hole at which the fluid will be injected as shown in fig 14b the dimensions of the rock core are 15 24 cm length with 3 81 cm outer diameter therefore the experiment was done with β 0 315 the measured helium porosity of this sample is 15 02 fig 14 shows images for the rock core used in this study briefing the details mentioned in this section with side and top view of the core 4 2 experiment details procedure core flooding tests were conducted in special core holder designed for radial flow experiments fig 15 shows side view and top view of the rock core holder used for the core flooding experiments de ionized water was used as an injection fluid with viscosity equivalent to 1 cp the core flooding system has a total of four production ports the following steps were tracked in the core flooding experiments 1 the axial pressure is kept at 82 7 bar during the entire experiment 2 the injection fluid was pumped at different rates 4qt 5 10 15 and 20 cm3 min and the rates were controlled using teledyne isco 260d 3 the outlet pressure p 2 is always kept constant during the entire experiment at atmospheric pressure 1 013 bar 4 four graduated cylinders are used to collect the produced fluid from the four production ports as shown in fig 16 with the help of stopwatch the production rates are recorded manually from the four ports simultaneously a total of 12 readings are taken from each port at each injection rate in order to reduce the experimental erroneous this step is repeated for all the rates 5 the rock core is then rotated by π 4 to align the production lines with the axes drawn in rock core as discussed above in the sample preparation section then the steps from 1 to 4 are repeated to measure the rates coming from the four ports 4 3 analysis and results the 12 rate readings of each port are averaged and then the average rates are smoothed to ensure that the sum of the four ports rate is equivalent to pump rate table 1 lists the injection rates smoothed average production rates from the four ports and the injection pressure the superscript 1 and 2 indicates the production rates before rotation and after rotating the rock core with π 4 respectively to assure the steady state condition all of these measurements are only recorded after having stabilization of pressure readings plateau and not from the start of the experiment the linear system 15 is then solved using the method of least square at each injection rate and the arithmetic average is performed to assure the symmetry of the sections rates around the principle axes the best fit linear relations between qf qs and qt fig 17 a show that q d i f f q t 0 0027 while q s u m q t 1 0 4217 utilizing the slope of the best fit linear relation between the pressure drop and the pump injection rate fig 17b the estimated equivalent permeability found to be k 1 426 md the intersection plot fig 17c constructed using the pear and the tent charts of β 0 315 show that α2 0 4649 and γ 0 7485π using the estimated α2 and with the help of fig 6 kd is found to be equivalent to 1 426 fig 17d therefore kx 1 988 md and ky 0 924 md these results are comparable to the results obtained using the mini permeameter on core plugs extracted from the main core al azani et al 2019 5 discussion 5 1 space domain transformation the isotropic counterpart of the boundary value problem 2 as a result of the cylindrical nature of the problem would be typically solved in polar coordinates re coursing to the elliptic coordinates system as the case with the flow problem in unconfined porous medium mathias and butler 2007 to overcome the unequal permeabilities manages to deal with the coefficients however the inner and outer boundaries map to ellipses which are not confocal the present transformation 3 can be viewed as a mixture of the polar and the elliptic coordinates systems from transformation 3 eliminating ϕ leads to α x 2 y 2 ρ 2 which defines the first coordinates ρ constant as ellipses centered at the origin fig 2 eliminating ρ on the other hand guides to y x α tan ϕ which are straight lines through the origin fig 2 however the angle ϕ is not in general equivalent to the polar angle θ instead α tan ϕ tan θ the eccentricity of the constructed ellipses from the first transformation is 1 α 2 as circles have zero eccentricity the increase in the degree of anisotropy leads to more deviation from the radial flow and more localization of the field flow around the principle direction which has the higher permeability 5 2 experiment and data analysis instead of introducing explicit formulas of the three unknowns kx ky and γ a graphical procedure is proposed for analyzing the experiment data to estimate them although the existence of the general solution that is described by eq 6 it is difficult to follow a mathematical approach similar to the one proposed by weitzenöck et al 1999 that is based on the rotation of axes that is mainly due to complexity of the general solution 6 evolved from the infinite series and the mixed axes transformation in addition to that the need to solve an algebraic system of equations prevents introducing an explicit formula for the unknowns also applying an inverse modeling is not recommended due to the possibility of divergence if the selected initial guess is far from the correct solution unless a prior estimate is known from previous studies from the pear chart it is clear that q d i f f q t 0 for γ π 4 or 3 π 4 due to the symmetry of the experiment axes around one of the principle axes also when α2 0 q d i f f q t 1 for γ 0 or π due to flow focusing toward the first section and q d i f f q t 1 for γ π 2 because the flow focusing toward the second section this means that 16 lim α 2 0 q d i f f q t q d i f f q t 0 1 1 γ 0 0 π the corresponding γ0 for the estimated q d i f f q t from the experiment can be estimated from extrapolation of the pear relation on intersection plot to α2 0 the proposed steady state flow experiment can be applied for different lithology types sandstone carbonate and shale with variable petrophysical properties porosity permeability grain density for very tight samples inert gas such as helium can be used as the injection fluid to minimize the time required to reach to the steady state regime however the pressure drop between the inner and the outer cylinder shall be very small not to have a large change in the gas viscosity also it is preferred to conduct the experiment at high pressures to minimize both the gas slippage impact klinkenberg 1941 and compressibility if such conditions could not be achieved in the laboratory the modified pressure p μ ς d p where ς is the gas deviation volume factor can be used instead of the pressure to linearize the differential equation and solve it by the same approach al hussainy et al 1966 6 conclusion this article presents a general solution of the steady state flow problem describing a confined anisotropic porous media between two concentric cylinders the general solution introduced in dimensionless form shows how the pressure distribution inside the domain of interest is a contribution from an isotropic part plus and an anisotropic part represented by a sum of an infinite sequence the solution detects how the pressure varies between the two cylinders from its circular nature at the boundaries to non circular iso potential at the vicinity in between the novel general solution accurately estimates the iso potentials consequently the flow field in the region close to the inner cylinder that is usually approximated by elliptic transformation in the previous studies the analysis of the results shows that both the degree of anisotropy and the ratio between two radii have significant impacts on the flow field and equivalent isotropic permeability the validation of the current solution is demonstrated versus well known analytical solutions of special cases and through the comparison with the numerical simulation the obvious drawback of the presented solution is occurring in the extreme anisotropic cases due to the inability to determine the number of the effective terms of the infinite series that leads to convergence the presented results introduce a new technique for laboratory measurement of two dimensional anisotropy parameters using holed cores instead of whole core permeability approach the experimental algorithms are mainly based on the rate measurements on the outer cylinder which is suitable for laboratory procedures in summary the article introduces a new experimental methodology supported by the theoretical model as a laboratory test method for quantifying the 2d permeability field of a given formation using lab scale core flooding tests the analysis puts step forward introducing a general solution suitable for determining the three dimensional anisotropy credit authorship contribution statement abdallah a youssef methodology software writing original draft r s alassar methodology software writing original draft mohamed mahmoud conceptualization writing review editing mahmoud elsayed investigation writing review editing a y al dweik methodology declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103884 appendix c supplementary materials image image 1 appendix a this appendix shows the detailed steps to arrive to the solution of eq 4 by applying the separation of variables technique the solution can be written as a 1 p d f ρ h ϕ i n β ψ ρ ψ π ϕ π considering the symmetry of the problem around x and y axes we can state the follows a 2 h 0 h π h 0 h π h ϕ h ϕ substituting into eq 4 we can obtain a 3 ρ 2 f ρ f f h h 2 λ eq a 3 is known as the eigen value problem where λ is the eigen value and the corresponding solution is the eigen function there are 3 cases for λ either λ 0 λ 0 or λ 0 the latter case is negligible as it produces a unique constant value of u over the whole domain of interest which is not consistent with the boundary conditions in a 2 hence by considering only the first and the second cases in addition to the symmetry conditions stated in a 2 we get a case λ 0 a 4 p d 0 a 0 ln ρ b 0 b case λ 0 a 5 p d n cos 2 n ϕ a n ρ 2 n b n ρ 2 n n 1 2 3 by applying the principle of superposition eqs a 4 and a 5 are summed up to yield the general solution 6 appendix b fig b1 shows the principle axis directions xp yp and zp which usually form an inclined xpyp plane with horizontal xy plane where the flow takes place during the experiment the velocity in three dimensional space is calculated using darcy s law eq 7 with full tensor intrinsic permeability which is defined as follows b 1 k k x x k x y k x z k y x k y y k y z k z x k z y k z r k x p 0 0 0 k y p 0 0 0 k z p r 1 where r is the rotation matrix which is defined as follows b 2 r r z r y r x cos θ y cos θ z sin θ x sin θ y cos θ z cos θ x sin θ z sin θ x sin θ z cos θ x sin θ y cos θ z sin θ z cos θ y cos θ x cos θ z sin θ x sin θ y sin θ z cos θ x sin θ y sin θ z sin θ x cos θ z sin θ y sin θ x cos θ y cos θ x cos θ y where r x 1 0 0 0 cos θ x sin θ x 0 sin θ x cos θ x r y cos θ y 0 sin θ y 0 1 0 sin θ y 0 cos θ y and r z cos θ z sin θ z 0 sin θ z cos θ z 0 0 0 1 are the rotation matrices around x y and zaxes and θ x θ y and θ z are the counter clockwise rotation angles around them respectively the proposed experiment setup in this article is applying no flow boundary conditions in z direction top and bottom boundaries of core and the injection is taking place over the entire height of the core fully penetrating hole therefore the velocity in the z direction vanishes hence the following relation can be derived from z component of the velocity b 3 p z 1 k z z k z x p x k z y p y substituting by eq b 3 into both x and y velocity components leads to b 4 v x v y 1 μ k x x k z z k x z 2 k z z k x y k z z k x z k y z k z z k x y k z z k x z k y z k z z k y y k z z k y z 2 k z z p x p y the measured permeabilities in two dimensional planes are the eigen values of the permeability tenor in eq b 4 
319,the wetting behavior of remaining isolated liquid bridges between particle interfaces determines the efficiency of filter cake dewatering micro processes during and after dewatering can be traced by means of direct x ray microtomography zeiss xradia 510 versa providing insights into the filter cake structure we measure the local contact angle between the immiscible phases on the pore scale after in situ filter cake dewatering by tracing the three phase contact line and the two perpendicular vectors belonging to the solid and liquid surface the contact angle is obtained from their scalar product at every mesh node the range of the resulting distribution and curvature increases with the degree of roughness becoming more obvious for larger contact angles the occurring roughness causes a naturally water repellent surface and leads to low liquid saturations the resulting angular distribution serves for a more accurate prediction of multiphase flow in pore networks as input for further pore model enhancement graphical abstract image graphical abstract keywords micro tomography filter cake dewatering image processing wettability microporous structure three dimensional contact angle 1 introduction wettability characterized by the contact angle at the three phase contact line is a key parameter that controls the flow pattern and pore scale dynamics of the immiscible displacement 1 3 in a water wet porous medium water flows through smaller pores and corners leaving behind a fraction of air or gas ganglia in the centers of larger pores strong capillary forces hold the trapped fluids in place 4 8 the trapped ganglia of the non wetting phase can occupy a single pore up to many pores 7 9 10 during the primary air migration the air penetrates into the water filled pore spaces at the same time air comes into direct contact with the solid surface subsequently these surfaces can be partially de wetted smaller pores and the corners of the pore space remain filled with water and stay wetted the development of pore scale imaging using x ray microtomography xrm has made it possible to see liquid configurations directly inside filter cakes and porous structures imaging has been applied to study the dynamic displacement of oil filled sandstone layers 11 12 and water displacement in a complex carbonate rock 13 14 wildenschild and sheppard who summed up results of recent years 15 provide a current overview of this imaging technique for immiscible fluid flows in porous media most of the available literature focuses on the imaging of two phase flow in water wetted porous media although film flow in a two phase system has been predicted and used in many theoretical and simulation studies 16 22 it has not yet been directly detected and visualized in realistic three dimensional porous media in this work xrm gives us the possibility to perform in situ experiments on water entrapment and continuous gas phase as a function of wettability first we describe the experimental process for the formation of the filter cakes and determine the contact angle distributions with sessile droplet experiments via contour analysis and via xrm measurements then we perform desaturation experiments to compare images of liquid distributions taken from different locations inside the cake within the porous filter cake structure we analyze water morphologies interfacial curvatures contact angles and residual saturations we investigate the spatial differences between these parameters to reveal possible variations within the porous matrix 2 theory the wettability determines macroscopic rock properties such as capillary pressure and relative permeability 23 26 and thus mainly affects the dewatering properties during mechanical filter cake desaturation it influences the overall behavior of multiphase flow in many applications such as geological capture and storage of carbon dioxide co2 and remediation of soil contamination 27 29 wettability can be derived from indirect averaged measurements on powder bulk materials in the laboratory by studying the relative permeability properties 30 33 on the pore scale wettability can be defined by the contact angle between the fluids in the pore space 34 conventionally due to measurement uncertainties of the method contact angle measurements in the laboratory tend to be carried out on ideally smooth mineral surfaces typically on quartz and calcite for the representation of sandstones or carbonates 26 35 36 the wetting properties measured here can differ considerably from those of real porous structures in which fluid distributions are determined by two phase flow the used reservoir rock surfaces differ in mineral composition and roughness which means that equilibrium measurements on chemically ideal surfaces are not representative of the contact angle in a reservoir rock under flow conditions 32 furthermore the contact angle can vary across the pore space due to differences in surface morphology mineralogy and fluid distribution unfortunately until now in situ measurements are still challenging as it is necessary to clarify the pore scale configurations of fluids under representative conditions within a porous matrix 28 37 38 the choice of the method for measuring contact angles depends mainly on the geometry of the system the direct observation problems the optics the mechanics of manipulation and the way the laplace equation is included in the measurement vary greatly from one type of system to another in terms of its configuration shape orientation etc 39 the upper part of fig 1 gives an overview of the most common experimental methods from neumann and good 36 in this paper we focus on the investigation of a sessile droplet both static and in a dynamic process in the static state a droplet is placed on the sample surface and the so called static contact angle on the left and right in the equilibrium state is determined by means of contour analysis if the volume of the droplet is reduced the measurement is referred to as the receding angle if the volume is increased and the droplet raises the advancing angle is measured both times after changing the amount of liquid the state is kept in equilibrium for a few seconds followed by determining the receding advancing contact angle when draining a capillary within a filter cake and displacing the liquid front we come very close to the first case the receding contact angle this can be seen in the lower part of fig 1 using a schematic drawing of spherical particles during dewatering of a filter cake at measuring times t 1 and t 2 t 1 t 2 neumann and good 36 give a more comprehensive insight and more precise description of the different contact angle measurement methods in contrast contact angles after dewatering in porous structures are not investigated because existing indirect measuring methods on particle beds are unreliable and difficult to reproduce the development of imaging tools with micrometer resolution has made it possible to study the pore arrangement of liquid phases 38 40 x ray methods in particular are now widely used as they allow non destructive imaging of the structure and fluids in the pore space under different pressure temperature and or wetting conditions 24 41 42 x ray imaging was initially used to measure contact angles in capillaries 43 to date however only a few studies have determined the contact angle in real porous structures andrew et al 9 have measured the contact angle in situ in a limestone sample for a water wetted co2 salt solution system where the contact angles were determined manually on a raw image of the plane perpendicular to the three phase contact line khishvand et al 44 and lv et al 45 also used this approach to study contact angles in sandstones and for ideal beds of spherical particles the problem with these approaches is that they are time consuming and can involve subjective uncertainties scanziani et al 46 extended this approach by using a circle at the fluid fluid interface and a line to the fluid solid interface on two dimensional sections perpendicular to the three phase contact line klise et al 47 developed another automated contact angle measurement which was applied to liquids in a sphere packing with different wettability properties in their approach planes were applied to the fluid fluid and solid fluid interfaces and the angle between them was calculated subsequently dalton et al 48 compared the algorithm developed by klise et al with laboratory results on sessile droplets and further ct data from limestone samples although they only examined very small sections of the image data they obtained significantly broader distributions of the contact angles when comparing ct values and laboratory data however the two last techniques were developed based on fitting planes lines to voxel based images measuring the contact angle in typical low resolution micro ct images for complex rocks is still no routine all these methods are either complicated or can cause significant errors in this study our main interest is the automatic measurement of the contact angle on the pore scale the basic idea is to decompose the fluid fluid and fluid solid interfaces and define vectors that have a direction perpendicular to these surfaces some authors like singh et al 49 alratrout et al 50 and alhammadi et al 51 also used this kind of approach additionally the interaction of liquids with a rough real surface is traditionally described by the model of wenzel 52 or the theory of cassie and baxter 53 these models explain the formation of a single effective contact angle on rough surfaces the approaches help to interpret the transition from water wet to water repellent conditions of surfaces however these studies deal with external surfaces and do not quantify the typical wetting conditions within a material and the relationship to surface roughness the question of local contact angles and fluid arrangements inside a filter cake remains unresolved furthermore it is decisive how they influence the fluid flow of the present phases in addition to the influence of particle wettability the particle geometry also has a great influence on the permeability of the respective phase 54 therefore it is necessary to consider the local contact angles as well as the porosity the particle shape the particle size distribution and the surface roughness of the particles by investigating this question we can better understand and possibly even influence the dewatering and thus the recovery of the liquid phase at both microscopic and macroscopic level section 3 briefly describes the workflow of the automated procedure to obtain the contact angle distribution in this section we also briefly describe the experiments that were performed and used to test the described method in section 4 1 we validate the method on three dimensional images of droplets of glycerol on an ideally smooth and on a rough solid surface the final section 4 2 shows the application of the method on in situ wettability measurements in x ray images of several desaturated filter cakes 3 material and methods 3 1 image processing micro processes during desaturation can be traced by means of direct computer tomography insights into the formed filter cake structure the zeiss xradia 510 versa x ray microscope combines classic computed tomography with microscopy optics allowing far smaller imaging voxel sizes to be achieved in addition to geometric resolution this allows the imaging of the microscopic structures within the filter cake geometry the tomographic reconstruction is done by using the filtered back projection fbp algorithm implemented in the zeiss xradia reconstruction software xradia xmreconstructor v11 1 8 it includes an automatic center shift and beam hardening correction with a factor of 0 05 a gaussian filter with a kernel of 0 7 for smoothing is applied already at the raw data the measurement parameters can be found in table a 1 of the appendix artefacts related to the xrm measurements makes it necessary to implement a reliable and reproducible image processing method filtering in imagej fiji 1 52n includes additional smoothing edge enhancement and iterative segmentation for the desired phase for the entire image stack a histogram equalization 0 3 saturated pixels and a non local means denoising standard deviation 25 smoothing 1 are applied to the image data then a linear kuwahara smoothing filter angles 11 line length 3 criterion variance mean2 on each single image reduces the remaining image noise but preserving the edges the following unsharp masking for edge enhancement radius 1 mask weight 0 6 increases the gray value gradient at phase changes afterwards a decision tree learning algorithm is applied to the image data which uses a limited number of manual annotations to train a classifier and then automatically segment the remaining data to segment the input image data the 3d grayscale image stacks from x ray tomographic measurements are divided into phase classes the segmentation problem is transformed into a voxel classification problem where each voxel can be classified as belonging to a specific segment or class a set of labeled input voxels is collected in a feature group and used as classifier in a training dataset the classifier was trained by the weka user tool to segment the input image data 55 once the classifier is trained it can be used to classify either the rest of the input voxels or completely new comparable image data in a reproducible way in this way the user can fine tune the parameters of the classifier and the selected labels until satisfactory results are obtained a fastrandomforest learning algorithm was chosen 56 which is a multithreaded version of randomforest and is initialized with 200 trees and 2 random features per node randomforest is an ensemble learning method for the classification and regression of the image data at the time of training a large number of decision trees are created and the class is generated which is the mode of the classes classification or the mean prediction regression of the individual trees the randomforest corrects the habit of decision trees to adapt to their training set which is a major advantage over other machine learning algorithms 57 fig 2 shows details of the image segmentation process the classifier also uses some image filters which work out characteristics such as the distance field of the individual particles at the end the respective phases are clearly defined in the 8 bit format the gas phase was assigned the value 0 the solid phase the value 1 and the liquid phase the value 2 to train the fastrandomforest algorithm we only use gray value regions that lie within the respective phase cf fig 2 the object boundaries are determined by the algorithm by applying the trained algorithm to all data sets a wrong assignment of a voxel at the boundary thus affects all image volumes i e we generate at most a systematic error at the phase boundary this results in either a systematic over or underestimation of the respective phase volume which is why a validation of the contact angle values via another measurement method is mandatory after all voxels have been assigned to the individual phases the three phase contact line can also be defined uniquely for this purpose the voxel based data set is transferred to a polygon mesh and the surface normals n are formed at the vertices of this mesh which share all three phases the local contact angle θ i is derived from the vectors describing the fluid fluid interface and the solid surface where they meet at the three phase contact line the scalar product of these directly adjacent cells of liquid and solid gives the local contact angle θi eq 1 this basic procedure is described in detail in singh et al 49 and alratrout et al 50 and is visualized in the upper part of fig 3 1 θ i arccos n solid n liquid n solid n liquid we also apply the physical condition that in the equilibrium of the fluid phases the fluid fluid interfaces should have a uniform curvature these surfaces are smoothed to increase the accuracy and reliability of the measurements smoothing prevents individual discontinuities in the contact angle between adjacent nodes of the mesh due to errors in segmentation without the application of smoothing isolated voxels at the boundary line either due to incorrect segmentation or real sharp edges can lead to significant single discontinuities in the contact angle distribution we apply gaussian smoothing as a laplacian smoothing on the image data we use an additional step to approximately preserve the volume of the segmented phases as done by several other authors 58 60 the essential point in applying smoothing algorithms is that they modify the positions p i with i v var of the moving vertices while leaving the topology of the mesh unchanged we specify that oi are the given points qi the current points and pi the new modified points after one iteration cf examples in fig 3 thus a smoothing algorithm starts with the vertex positions o q and maps the current positions q to p in one step the new position p i of any vertex i usually depends only on the positions of its neighboring vertices j adj i the used laplacian smoothing algorithm works as follows the position pi of vertex i is replaced by the average of the positions of the neighboring vertices the technique for calculating the new position pi consists in updating the new positions pi immediately in this case a position pi may not only depend on the number of old positions q but may also depend on a previously calculated new position pj therefore the result of a smoothing pass through all vertices i v var depends on the order in which the vertices are considered fig 3 illustrates the basic procedure for the numerical implementation of our work we use the platform openfoam v1906 61 in connection with the contact angle on real surfaces the condition of the geometry at the location of the wetting line is essential since curved surfaces influence the wettability at this point a measure of curvature of the investigated three phase line is appropriate since the 3d scans are stored as polygon meshes i e there are only individual support points with corresponding connections only two different curvature values are available firstly the curvature is zero on the sub surfaces of the mesh and infinite at the edges and nodes because these values are not very useful for further processing and do not correspond to the values of the real object the curvature information must be approximated using the environment of a point mathematically the curvature κ is defined as a change of direction of a function 2 κ 2 x 2 one interpretation of curvature is the circle of curvature in fig 4 an attempt is made to connect a circle to the function to fit in the radius of this circle is indirectly proportional to the calculated curvature considering this we see that a kink in the function must have a curvature of infinity because the circle has a diameter of zero the opposite is true for straight lines the radius is infinite and the curvature is zero for 3d meshes we need the curvature of the surface at a certain point the curvature is also the second derivative here resulting in a 2 2 matrix w the second derivation of a two dimensional function is therefore 3 w 2 x 2 2 y x 2 x y 2 y 2 the eigenvalues of this matrix are called main curvatures κ 1 κ 2 these principal curvatures follow the eigenvectors of the matrix they are called main curvature directions with the help of the two main curvatures further measures such as the gaussian curvature g can be determined 4 g κ 1 κ 2 these calculated dimensions allow a rough categorization of the points into elliptical g 0 points based on the gaussian curvature hyperbolic g 0 and parabolic points g 0 62 the tensor averaging method 63 was used to approximate the curvature for the polygon mesh the basic idea of tensor averaging is a curvature tensor that is calculated for each examined point it is a weighted average of the curvature tensors of the adjacent polygons the desired curvature parameters can then be calculated from this tensor a tensor of curvature is defined in such a way that if a direction vector is multiplied by it it indicates the change of the normal in that direction for this purpose a system of equations is created which contains the changes of the normal of the vertices ni at their respective adjacent edges ej here the values of a polygon must be transformed into a coordinate system u v which lies in the plane of the polygon 3 2 material characterization monocrystalline al2o3 sapphire and hydrophilic martoxid mr 70 hereinafter referred to as mr 70 both from goodfellow gmbh are used for preliminary tests of contact angle measurements on planar surfaces sapphire is a monocrystalline aluminum oxide which is composed of 99 997 al2o3 is colorless and has a density of 3 99 g cm3 the sintered mr 70 is composed of 99 80 al2o3 is white and has a density of 3 87 g cm3 the sample from the sintered t60 64 almatis gmbh as material for the filtration experiments consists of 99 50 al2o3 has a density of 3 82 g cm3 and is white table 2 shows the respective roughness values r z r a and rms which were recorded with the atomic force microscope afm xe 100 park systems and the surface roughness measuring device hommel t1000 hommel gmbh as can already be seen from the roughness values the sapphire has an almost ideally smooth surface the sem images in fig 5 show the inhomogeneities and valleys of mr 70 these are caused by stress cracks either during the sintering process or by escaping h2o contained in the binder for all filtration experiments and the filter cake structure analysis crushed and classified t60 64 al2o3 particles ρ 3 82 g cm³ in size range of 50 to 200 μm are used fig 5 which reveal the highest roughness values for the liquid phase a brine of potassium iodide ki 25 mm purity 99 carl roth germany and 24 wt glycerol purity 99 8 carl roth germany in water with a density of ρ 1 06 g cm³ and a dynamic viscosity of ηη 1 98 mpas at 20 c is chosen for the filtration experiments table 1 contains the corresponding property values of the mixtures water and water glycerol mixtures are not suitable for longer measurements on planar surfaces which is why only glycerol was used for validation with the sessile droplet method the amount of water contained in the solution evaporates from the surface at room temperature potassium iodide as contrast agent inside the liquid enhances the achievable contrast between the phases in the final gray value images compared to the liquid alone a relatively large atomic number n and density ρ significantly increase the resulting x ray attenuation coefficient μ and thus lead to a higher contrast μ n 4 μρ that simplifies the image analysis and the following phase separation for all filtration tests potassium iodide is added to the mother liquid the salt concentration has to stay low to ensure a ζ potential stay above 30 mv so that no agglomeration effects occur any pre structuring of the suspension has a significant impact on the subsequent cake structure and the associated parameters 3 3 experimental set up and analysis procedure to determine the contact angle by contour analysis the planar samples are first cleaned with acetone and then placed in the drying oven at 100 c for five minutes the static contact angle measurements are carried out with the above mentioned samples on the g10 contact angle measuring instrument from krüss gmbh the sessile droplet method is used and the contact angles are evaluated with the circle fit method a droplet of 3 μl is placed on the surface and the baseline is positioned the right and left contact angles are determined by automatically applying tangents to the three phase contact points between the baseline and the droplet contour after a waiting period of 10 s the contact angles on the left and the right are determined from the droplet projection image for each sample 200 droplets are measured dynamic contact angle measurements are performed with the oca50 instrument from dataphysics instruments gmbh in the present work the polynomial fit method is used to record the measurements according to the vdi standard 55660 6 a 3 µl droplet is also chosen which is increased to a volume of 4 µl or reduced to 2 µl in 20 cycles with a pump speed of 0 2 μl s the droplet size is maintained for 30 s at both the maximum and minimum volume and the contact angles are automatically determined at the left and right side of the droplet then a new cycle began the entire time the cuvette tip remains inside the droplet fig 6 shows two measurements with 20 cycles one on the smooth sapphire surface and one on the rough mr 70 surface the same two surface samples are used for the measurements in the xrm therefore the samples are first cut to a size of about 0 5 0 5 cm mr 70 and 0 35 0 35 cm sapphire then a 1 μl droplet is placed on top of the sample table a 1 in the appendix summarizes the parameter settings for the xrm measurements the filtration experiments are done according to guideline vdi 2762 2 association of german engineers due to handling reasons and limiting dimensions inside the xrm housing experiments are carried out inside a downscaled vacuum nutsch cell at 0 5 bar this is a self developed flow cell ii made out of polymethyl methacrylate pmma with low x ray self attenuation the dimensions correlate with vdi 2762 1 i at a downscale factor of a i a ii 100 for xrm measurements the vacuum filtration process is conducted directly inside this in situ flow cell the effective filter area amounts to 20 mm² with an internal nutsch diameter of 5 mm details of the experimental set up and the measurement principle can be found in 65 the feed suspension with a solid volume fraction of cv 0 35 is gently stirred at 250 rpm for 4 min and afterwards filled into the nutsch suspension volume inside the nutsch amounts to 330 μl the filtration tests are stopped at complete desaturation s s rem at this point all voids are emptied and just hydraulic isolated liquid remains inside the cake matrix for validation we perform stepwise deliquoring in the laboratory by increasing pressure from 0 05 to 0 8 bar to confirm the irreducible saturation s rem we also validate the needed pressure difference of 0 5 bar with these capillary pressure tests the filter cakes investigated by xrm are dewatered directly after the filter cake build up at the same pressure of 0 5 bar afterwards the xrm measurements are performed on the desaturated filter cake using the xrm filtration cell we can only represent the static state of dewatering due to the long measuring times up to several hours the dynamic process and thus the dynamic contact angle within the filter cake structure remain inaccessible for measurement 4 results and discussion 4 1 preliminary investigations on flat surfaces xrm measurements are performed with a horizontal static droplet on sapphire and mr 70 three times each with measuring times between 2 5 and 4 hours according to the needed exposure time the measurements with sapphire consist of 1838 to 4124 and those with mr 70 of 1662 to 2166 measuring node points the results of these six measurements are shown in fig 7 together with the 200 laboratory measurements obtained by the krüss g10 device for both surfaces on the left side of the picture one droplet from the xrm measurement and one droplet from the contour analysis are shown the laboratory values are the mean value of both contact angles right left of each droplet in the first xrm measurement with sapphire and glycerol 50 of all values are between 49 and 70 in the respective distribution bottom outliers 83 values minimum 2 are almost twice as many as top outliers 44 values maximum 176 whereas the second measurement shows no outliers the upper interquartile limit is with 70 almost at the same height the lower interquartile limit with 33 and the median with 45 significantly distorts the distribution downwards the third measurement also has no outliers and shows an overall interquartile distance of 45 50 of all values are in the range of 46 and 90 and with a median of 68 the third measurement shows the largest contact angles the absence of outliers in the last two measurements indicates that the solid surface has a regular structure and the droplet thus has a uniform three phase contact line for mr 70 the interquartile range is between 75 and 98 in the first xrm measurement between 97 and 112 in the second and between 69 and 92 in the third the medians also show significantly higher values at 86 105 and 84 thus the contact angles of mr 70 are higher overall in contrast to sapphire there are outliers upwards and downwards in every measurement which reveals the irregular structure of the solid surface with mr 70 a comparatively narrow distribution of contact angles of each single xrm scan can be observed surprisingly all three measurements show high variation among each other these two aspects could indicate the influence of the roughness of the solid surface depending on where the contact angle was recorded at the droplet and the droplet itself was placed on the surface different angles may have been formed for example by edges or unevenness these irregularities can lead to a pinning effect i e the liquid is pinned to a certain site immobilizes and thus changes its contact angle since with a sessile droplet no dynamic is present the liquid cannot overcome a point and remains in this form further explanation can be provided by the model of cassie baxter 53 if air is trapped in the roughness of the surface the apparent contact angle increases the liquid does not penetrate into the valleys of the surface due to the high capillary entrance pressure of the small roughness sizes the existing air cannot be displaced it is noticeable that the standard deviations of the xrm measurements are significantly larger than those of the values from the krüss g10 with mr 70 the contact angles of the static g10 measurement are clearly higher in total all measurements provide similar results and the distributions overlap each other which indicates a good agreement between the two methods however with the xrm the detailed 3d acquisition also reflects the local influence of the solid surface to the three phase contact line and thus to the determined contact angle which is further described in section 4 2 here it is necessary to emphasize the difference between the two measuring methods on the one hand the two dimensional measurement which approximates the integral angles via a fixed geometry on the droplet circle fit method and on the other hand the three dimensional measurement which determines the local contact angles via several thousand individual points on the three phase boundary line statistically possible roughness or inhomogeneities affecting the angles dominate the distribution b less clearly on the sapphire or mr 70 surface microscopic cracks or voids occur only sporadically and in some distance to each other cf fig 5 with respect to the distribution a from the xrm data only the location of the polygons directly at the three phase contact line is decisive a pinning effect can thus become much more visible at individual angles since the polygons located there are strongly forced outward or inward these effects are less apparent when the entire droplet contour is considered as in distribution b furthermore we discretize the surface or the three phase contact line voxel based a or pixel based b although this discretization is relativized in a by the generation of the polygon mesh and the subsequent smoothing it is still only an artificial representation of the real geometry the contour analysis in b also needs this discretization but the resolution of the two dimensional image differs from the three dimensional image 4 2 porous structures the high resolution xrm measurement within the filter cake generates 168 187 contact angle measuring points these data points are shown in the boxplot diagram of fig 8 in comparison with the static krüss g10 and dynamic dataphysics oca50 laboratory measurements the investigated filter cake has a mean porosity of 43 1 1 9 and was desaturated to s 13 1 0 8 ratio of volume of pore liquid to pore volume the height specific filter cake resistance r c defined by vdi 2762 2 amounts to r c 3 05 1012 1 m² it can be seen that the contact angles of the liquid within the filter cake are widely distributed as they range from a minimum of 1 to a maximum of 180 there are more top 1748 than bottom 780 outliers however 50 of the values are in the range between 63 and 91 the median is 77 comparing the mean values and standard deviations of the filter cake with all sessile droplet measurements to the water glycerol mixture the contact angles of the filter cake cannot be clearly assigned the mean value within the filter cake is 78 which is between the measurements with sapphire and mr 70 the contact angles also vary significantly more than for the sessile droplets so that they almost cover the value range of the laboratory measurements completely this indicates that on the one hand the liquid interacts with a rough surface i e that the large contact angles are possibly caused by pores or edges on the other hand due to the low angles it behaves more like on a smooth surface than mr 70 even if the roughness of t60 64 is higher cf table 2 the xrm measurement and the dynamic sessile droplet measurements of mr 70 fall within the same range the standard deviations of the xrm measurements are larger here but the difference is smaller compared to sapphire the measurement of the irregular structure of mr 70 is therefore more representative for filter cakes in comparison the liquid volumes within the filter cake are also smaller than the measured sessile droplets over several orders of magnitude the median volume is v 50 1 64 10 6 μl with the distribution limits of v 10 0 76 10 6 μl and v 90 18 90 10 6 μl regarding the relationship between resolution and voxel edge length the resolution of 3 21 μm vx we used would be sufficient to represent structures with volumes of 0 37 10 6 μl corresponding to the diameter of the volume equivalent sphere of 9 μm 66 67 the small liquid volumes provide only a few voxels representing the corresponding surface area due to the voxel size adsorption layers on the particle surface are not resolvable but it could be that some voxels are assigned to the liquid due to the gray value gradient at the solid air phase boundary these misinterpreted voxels generate small liquid volumes and extremely small contact angles and create the visual impression of film formation another effect of this artifact would be smaller angles of liquid bridges since the liquid film of the bridge is elongated on the surface even though no liquid exists at the surface position during the image processing in section 3 1 we tried to significantly enhance the gray value gradient at the phase boundaries to prevent such effects but especially for the lower limit of the liquid distribution the effect might still occur in contrast the droplet sizes are 1 μl sessile droplet xrm and 2 to 4 μl sessile droplet krüss g10 and dataphysics oca50 due to the long measuring times with the xrm the dynamic process which in this case takes place in a few seconds might not be properly described some studies in the literature report that the wettability of rock surfaces changes permanently and dynamically over time 17 68 69 the results of the studies show capillary instability in drainage imbibition experiments such that the capillary pressure measurements changed steadily over time the authors attributed these deviations from the expected capillary curve to a change in the wettability of the rock sample over time like aging the change of the wetting angle is a pore scale phenomenon that changes the capillary pressure function independent of flow conditions or other instabilities 70 the contact angle therefore has the potential to change even in the static state of the system but during the measurement this would have resulted in a blurred phase interface which we could not observe if the sample shifts in one or more directions during the xrm measurement the voxel data cannot be matched exactly during the reconstruction of the projections the static condition also shows representative values with regard to saturation in comparison to the dynamic dewatering process in laboratory experiments in the incrementally measured saturation curves cf section 3 3 we reached similar irreducible saturation values of 10 to 16 xrm s 13 1 0 8 since the same state of equilibrium is reached after stepwise increase of the pressure level the progression of the liquid in any pore and the resulting receding angle cannot be resolved in the xrm measurement here we only display the liquid in the cake without the influence of external forces distributed capillary forces within the pore space which may move the liquid to other pore volumes and only occur due to the long measuring time cannot be excluded a re relaxation of the liquid may lead to a condition that is more likely to be represented by a static contact angle measurement but does not describe the process of dynamic dewatering since the solid surface was taken up in the state after dewatering and thus has already seen liquid it is possible that a kind of pre wetting may have occurred on some comparatively flat areas whereby the liquids show a rather fluid behavior and thus smaller contact angles driving force for the possible rewetting constitutes the mentioned distributed capillary force within the pore space enhanced by chemical potential differences on the surface as suggested by al ratrout et al 71 and singh et al 49 alratrout et al experimentally compared segmented three dimensional images in pore scale with manually measured contact angles from singh et al based on the same dataset singh et al performed ct measurements in the pore scale here remaining oil in the pore space was used as liquid all authors point out that among other things surface inhomogeneities can cause widely distributed contact angles in the pore space their results from the segmented 3d data also show widely distributed contact angles fig 9 shows the overall 3d complexity of the problem we see a capillary bridge between three particles with the corresponding contact angles even at this single remaining liquid area the contact angle varies between 61 and 92 along the wetting line emphasizing the range of variation of the overall distribution the resolution here is 3 2 μm vx in the visualization only the surfaces adjacent to the respective phase are shown as polygon mesh in the following fig 10 the gaussian curvature of the three phase line is plotted for all surfaces while g 0 is always obtained for the examined drops with good approximation i e there are only parabolic points on the line for sessile droplets on a flat surface g 0 should always occur in the ideal case one of the main curvatures is always zero which is why g 0 applies smaller surface structures which pin the liquid and are still resolvable in the xrm generate both single hyperbolic and elliptical points of curvature however these weak fluctuations can also result from image segmentation and voxel assignment partial volume effects pve at the respective phase boundary with rougher materials the effect of pinning is more pronounced and with the mr 70 surface the gaussian curvature fluctuates considerably more around zero on the contrary the value fluctuates strongly around g 0 within the filter cake structure in the filter cake exists areas of local curvature with both positive and negative values but there is no direct correlation between the curvature of the interface and the contact angle in trapped capillary bridges liquid volumes in partially desaturated areas with larger contact angles tend to have a more positive curvature on the one hand these effects indicate the highly irregular structure of the crushed particles which come close neither to a spherical surface nor to a flat plate and have macroscopically formed valleys and peaks of a few micrometers see roughness values in table 2 on the other hand there is microscopic roughness which is responsible for pinning effects interestingly these significant deviations from g 0 become apparent first at contact angles above 40 we assume that at corners or edges the fluid bulges more until the film snaps off when the applied pressure difference is large enough otherwise the liquid bridge remains in this state additionally any adhesive fluid on the surface of the particles that has not been previously removed influences the contact angles these adhesive fluids can consist of entrapped air during the suspension preparation or through the filtration process although these effects strongly influence the course of the contact line the structures themselves cannot be resolved in the xrm only their effect on the developing interface and the contact line respective their curvature however ideal saddle points for g 0 or elliptical points g 0 within the porous structure do not occur the movement of the interface within the porous filter cake matrix causes changes in phase saturation and interface curvature as well as local phenomena such as the observed contact angle hysteresis shown in fig 8 disruption of the liquid regions and possible haines jumps the reduction of all these factors to the difference of the average pressures at the pore throat seems to be only a strong simplification the fluctuation of the three phase contact line from fig 10 is rather due to the above mentioned features which are not yet fully scientifically identifiable 72 5 conclusion this study provides a basic understanding of water inclusions i e liquid bridges inside a porous medium made of rough particles as a function of wettability we used x ray microtomography to study the in situ contact angles on the pore scale with regard to desaturation effects the wettability effects of the cake and the corresponding data evaluation were validated by conventional droplet shape analysis and xrm measurements on flat surfaces although static xrm measurements provide valuable spatial information on the three phase contact line they are not able to capture the dynamic aspect of dewatering since the particle surface inside the filter cake has already been moistened once i e the solid surface has seen the liquid before the recorded steady state can at least approximately be compared with a dynamic measurement our analysis shows that air only penetrates the larger accessible water wetted pore throats while smaller constrictions remain water filled because they require a higher capillary inlet pressure for moisture removal we provide experimental evidence for the existence of hydraulically isolated water reservoirs with good wettability up to 90 and beyond the prevailing contact angle the low remaining water saturation of s 13 1 0 8 indicates the increased permeability of air and the formation of the cross linked continuous structure of the gas phase in the pore volume as the contact angles of the filter cake are in the small as well as in the large range the small droplet quantities seem to be strongly affected by edges roughness or surface inhomogeneities within the pores as well as by dynamics of the creation of isolated liquid volumes the fact that the solid surface was picked up after dewatering and was thus already wetted once seems to lead to a kind of pre wetting the liquid changes into a flow which in the end results in small contact angles the formation of very thin water layers on solid surfaces during desaturation in a well wettable system has been hypothetically assumed in the literature and considered in many theoretical and model studies 73 but could not be proven experimentally with the resolution used here the range of the distribution of contact angle and curvature increases with the degree of roughness with the correlation becoming more obvious for larger contact angles on rougher surfaces the contact angle tends to be lower due to the accumulation of water in pore throats due to the broad contact angle distribution both better wettable and worse wettable areas exist within the pore space for both phases multiple wet state if these multiple wetting properties are not restricted to single regions of the filter cake but can be found in the entire filter cake both permeabilities remain sufficiently high these conditions might be favorable for water displacement we assume that in other porous materials where it is desirable to have both a liquid and a gas phase flowing over a wide range of saturation the combination of wettability change and rough surfaces will result in this multiple wet state besides the degree of wettability the pore morphology the pore throat distribution and the degree of crosslinking of the pore space also influence the permeabilities of both phases these influencing factors become even more important when process relevant pressure differences are only of secondary importance due to small pore sizes further experiments with variation of the wetting properties would be necessary to prove the advantages of a multiple wet state additionally the variation of the pore space morphology with similar wetting properties e g variation of particle size or shape is assumed to have significant effect on the saturation level besides this further research could focus on the investigation of the stability and mobility of remaining water reservoirs as a function of contact angle and capillary pressure in poorly wetting filter cake structures 6 notation symbol abbr unit meaning a m² filter area cv m3 m3 solid volume fraction related to the total suspension volume n i normal vector to the surface i n atomic number oi original nodes of the mesh before smoothing δp pa pressure difference pi current nodes during smoothing iterations p rel relative vapor pressure qi final node of the mesh after smoothing ra m arithmetic mean deviation of the assessed profile rz m arithmetic mean of maximum heights of five individual measuring sections rms m root mean square roughness r c 1 m² height specific filter cake resistance s m3 m3 liquid saturation ti s time step i γ kg s² surface tension ε m3 m3 porosity κ curvature μ 1 m linear x ray absorption coefficient ρ kg m³ density η pas dynamic viscosity θi local contact angle θ a advancing contact angle θ r receding contact angle afm atomic force microscope fbp filtered back projection pve partial volume effects sem scanning electron microscope xrm x ray microscopy 7 credit author statement erik löwer conceptualization data curation formal analysis investigation methodology software visualization writing original draft christine makowlew data curation investigation thomas leissner supervision writing review editing validation urs peuker supervision writing review editing funding acquisition project administration resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we express our gratitude to the german research foundation dfg pe 1160 23 1 and the international fine particle research institute ifpri which supported this research additionally we thank r ditscherlein and thu trang võ for proof reading appendix table a 1 
319,the wetting behavior of remaining isolated liquid bridges between particle interfaces determines the efficiency of filter cake dewatering micro processes during and after dewatering can be traced by means of direct x ray microtomography zeiss xradia 510 versa providing insights into the filter cake structure we measure the local contact angle between the immiscible phases on the pore scale after in situ filter cake dewatering by tracing the three phase contact line and the two perpendicular vectors belonging to the solid and liquid surface the contact angle is obtained from their scalar product at every mesh node the range of the resulting distribution and curvature increases with the degree of roughness becoming more obvious for larger contact angles the occurring roughness causes a naturally water repellent surface and leads to low liquid saturations the resulting angular distribution serves for a more accurate prediction of multiphase flow in pore networks as input for further pore model enhancement graphical abstract image graphical abstract keywords micro tomography filter cake dewatering image processing wettability microporous structure three dimensional contact angle 1 introduction wettability characterized by the contact angle at the three phase contact line is a key parameter that controls the flow pattern and pore scale dynamics of the immiscible displacement 1 3 in a water wet porous medium water flows through smaller pores and corners leaving behind a fraction of air or gas ganglia in the centers of larger pores strong capillary forces hold the trapped fluids in place 4 8 the trapped ganglia of the non wetting phase can occupy a single pore up to many pores 7 9 10 during the primary air migration the air penetrates into the water filled pore spaces at the same time air comes into direct contact with the solid surface subsequently these surfaces can be partially de wetted smaller pores and the corners of the pore space remain filled with water and stay wetted the development of pore scale imaging using x ray microtomography xrm has made it possible to see liquid configurations directly inside filter cakes and porous structures imaging has been applied to study the dynamic displacement of oil filled sandstone layers 11 12 and water displacement in a complex carbonate rock 13 14 wildenschild and sheppard who summed up results of recent years 15 provide a current overview of this imaging technique for immiscible fluid flows in porous media most of the available literature focuses on the imaging of two phase flow in water wetted porous media although film flow in a two phase system has been predicted and used in many theoretical and simulation studies 16 22 it has not yet been directly detected and visualized in realistic three dimensional porous media in this work xrm gives us the possibility to perform in situ experiments on water entrapment and continuous gas phase as a function of wettability first we describe the experimental process for the formation of the filter cakes and determine the contact angle distributions with sessile droplet experiments via contour analysis and via xrm measurements then we perform desaturation experiments to compare images of liquid distributions taken from different locations inside the cake within the porous filter cake structure we analyze water morphologies interfacial curvatures contact angles and residual saturations we investigate the spatial differences between these parameters to reveal possible variations within the porous matrix 2 theory the wettability determines macroscopic rock properties such as capillary pressure and relative permeability 23 26 and thus mainly affects the dewatering properties during mechanical filter cake desaturation it influences the overall behavior of multiphase flow in many applications such as geological capture and storage of carbon dioxide co2 and remediation of soil contamination 27 29 wettability can be derived from indirect averaged measurements on powder bulk materials in the laboratory by studying the relative permeability properties 30 33 on the pore scale wettability can be defined by the contact angle between the fluids in the pore space 34 conventionally due to measurement uncertainties of the method contact angle measurements in the laboratory tend to be carried out on ideally smooth mineral surfaces typically on quartz and calcite for the representation of sandstones or carbonates 26 35 36 the wetting properties measured here can differ considerably from those of real porous structures in which fluid distributions are determined by two phase flow the used reservoir rock surfaces differ in mineral composition and roughness which means that equilibrium measurements on chemically ideal surfaces are not representative of the contact angle in a reservoir rock under flow conditions 32 furthermore the contact angle can vary across the pore space due to differences in surface morphology mineralogy and fluid distribution unfortunately until now in situ measurements are still challenging as it is necessary to clarify the pore scale configurations of fluids under representative conditions within a porous matrix 28 37 38 the choice of the method for measuring contact angles depends mainly on the geometry of the system the direct observation problems the optics the mechanics of manipulation and the way the laplace equation is included in the measurement vary greatly from one type of system to another in terms of its configuration shape orientation etc 39 the upper part of fig 1 gives an overview of the most common experimental methods from neumann and good 36 in this paper we focus on the investigation of a sessile droplet both static and in a dynamic process in the static state a droplet is placed on the sample surface and the so called static contact angle on the left and right in the equilibrium state is determined by means of contour analysis if the volume of the droplet is reduced the measurement is referred to as the receding angle if the volume is increased and the droplet raises the advancing angle is measured both times after changing the amount of liquid the state is kept in equilibrium for a few seconds followed by determining the receding advancing contact angle when draining a capillary within a filter cake and displacing the liquid front we come very close to the first case the receding contact angle this can be seen in the lower part of fig 1 using a schematic drawing of spherical particles during dewatering of a filter cake at measuring times t 1 and t 2 t 1 t 2 neumann and good 36 give a more comprehensive insight and more precise description of the different contact angle measurement methods in contrast contact angles after dewatering in porous structures are not investigated because existing indirect measuring methods on particle beds are unreliable and difficult to reproduce the development of imaging tools with micrometer resolution has made it possible to study the pore arrangement of liquid phases 38 40 x ray methods in particular are now widely used as they allow non destructive imaging of the structure and fluids in the pore space under different pressure temperature and or wetting conditions 24 41 42 x ray imaging was initially used to measure contact angles in capillaries 43 to date however only a few studies have determined the contact angle in real porous structures andrew et al 9 have measured the contact angle in situ in a limestone sample for a water wetted co2 salt solution system where the contact angles were determined manually on a raw image of the plane perpendicular to the three phase contact line khishvand et al 44 and lv et al 45 also used this approach to study contact angles in sandstones and for ideal beds of spherical particles the problem with these approaches is that they are time consuming and can involve subjective uncertainties scanziani et al 46 extended this approach by using a circle at the fluid fluid interface and a line to the fluid solid interface on two dimensional sections perpendicular to the three phase contact line klise et al 47 developed another automated contact angle measurement which was applied to liquids in a sphere packing with different wettability properties in their approach planes were applied to the fluid fluid and solid fluid interfaces and the angle between them was calculated subsequently dalton et al 48 compared the algorithm developed by klise et al with laboratory results on sessile droplets and further ct data from limestone samples although they only examined very small sections of the image data they obtained significantly broader distributions of the contact angles when comparing ct values and laboratory data however the two last techniques were developed based on fitting planes lines to voxel based images measuring the contact angle in typical low resolution micro ct images for complex rocks is still no routine all these methods are either complicated or can cause significant errors in this study our main interest is the automatic measurement of the contact angle on the pore scale the basic idea is to decompose the fluid fluid and fluid solid interfaces and define vectors that have a direction perpendicular to these surfaces some authors like singh et al 49 alratrout et al 50 and alhammadi et al 51 also used this kind of approach additionally the interaction of liquids with a rough real surface is traditionally described by the model of wenzel 52 or the theory of cassie and baxter 53 these models explain the formation of a single effective contact angle on rough surfaces the approaches help to interpret the transition from water wet to water repellent conditions of surfaces however these studies deal with external surfaces and do not quantify the typical wetting conditions within a material and the relationship to surface roughness the question of local contact angles and fluid arrangements inside a filter cake remains unresolved furthermore it is decisive how they influence the fluid flow of the present phases in addition to the influence of particle wettability the particle geometry also has a great influence on the permeability of the respective phase 54 therefore it is necessary to consider the local contact angles as well as the porosity the particle shape the particle size distribution and the surface roughness of the particles by investigating this question we can better understand and possibly even influence the dewatering and thus the recovery of the liquid phase at both microscopic and macroscopic level section 3 briefly describes the workflow of the automated procedure to obtain the contact angle distribution in this section we also briefly describe the experiments that were performed and used to test the described method in section 4 1 we validate the method on three dimensional images of droplets of glycerol on an ideally smooth and on a rough solid surface the final section 4 2 shows the application of the method on in situ wettability measurements in x ray images of several desaturated filter cakes 3 material and methods 3 1 image processing micro processes during desaturation can be traced by means of direct computer tomography insights into the formed filter cake structure the zeiss xradia 510 versa x ray microscope combines classic computed tomography with microscopy optics allowing far smaller imaging voxel sizes to be achieved in addition to geometric resolution this allows the imaging of the microscopic structures within the filter cake geometry the tomographic reconstruction is done by using the filtered back projection fbp algorithm implemented in the zeiss xradia reconstruction software xradia xmreconstructor v11 1 8 it includes an automatic center shift and beam hardening correction with a factor of 0 05 a gaussian filter with a kernel of 0 7 for smoothing is applied already at the raw data the measurement parameters can be found in table a 1 of the appendix artefacts related to the xrm measurements makes it necessary to implement a reliable and reproducible image processing method filtering in imagej fiji 1 52n includes additional smoothing edge enhancement and iterative segmentation for the desired phase for the entire image stack a histogram equalization 0 3 saturated pixels and a non local means denoising standard deviation 25 smoothing 1 are applied to the image data then a linear kuwahara smoothing filter angles 11 line length 3 criterion variance mean2 on each single image reduces the remaining image noise but preserving the edges the following unsharp masking for edge enhancement radius 1 mask weight 0 6 increases the gray value gradient at phase changes afterwards a decision tree learning algorithm is applied to the image data which uses a limited number of manual annotations to train a classifier and then automatically segment the remaining data to segment the input image data the 3d grayscale image stacks from x ray tomographic measurements are divided into phase classes the segmentation problem is transformed into a voxel classification problem where each voxel can be classified as belonging to a specific segment or class a set of labeled input voxels is collected in a feature group and used as classifier in a training dataset the classifier was trained by the weka user tool to segment the input image data 55 once the classifier is trained it can be used to classify either the rest of the input voxels or completely new comparable image data in a reproducible way in this way the user can fine tune the parameters of the classifier and the selected labels until satisfactory results are obtained a fastrandomforest learning algorithm was chosen 56 which is a multithreaded version of randomforest and is initialized with 200 trees and 2 random features per node randomforest is an ensemble learning method for the classification and regression of the image data at the time of training a large number of decision trees are created and the class is generated which is the mode of the classes classification or the mean prediction regression of the individual trees the randomforest corrects the habit of decision trees to adapt to their training set which is a major advantage over other machine learning algorithms 57 fig 2 shows details of the image segmentation process the classifier also uses some image filters which work out characteristics such as the distance field of the individual particles at the end the respective phases are clearly defined in the 8 bit format the gas phase was assigned the value 0 the solid phase the value 1 and the liquid phase the value 2 to train the fastrandomforest algorithm we only use gray value regions that lie within the respective phase cf fig 2 the object boundaries are determined by the algorithm by applying the trained algorithm to all data sets a wrong assignment of a voxel at the boundary thus affects all image volumes i e we generate at most a systematic error at the phase boundary this results in either a systematic over or underestimation of the respective phase volume which is why a validation of the contact angle values via another measurement method is mandatory after all voxels have been assigned to the individual phases the three phase contact line can also be defined uniquely for this purpose the voxel based data set is transferred to a polygon mesh and the surface normals n are formed at the vertices of this mesh which share all three phases the local contact angle θ i is derived from the vectors describing the fluid fluid interface and the solid surface where they meet at the three phase contact line the scalar product of these directly adjacent cells of liquid and solid gives the local contact angle θi eq 1 this basic procedure is described in detail in singh et al 49 and alratrout et al 50 and is visualized in the upper part of fig 3 1 θ i arccos n solid n liquid n solid n liquid we also apply the physical condition that in the equilibrium of the fluid phases the fluid fluid interfaces should have a uniform curvature these surfaces are smoothed to increase the accuracy and reliability of the measurements smoothing prevents individual discontinuities in the contact angle between adjacent nodes of the mesh due to errors in segmentation without the application of smoothing isolated voxels at the boundary line either due to incorrect segmentation or real sharp edges can lead to significant single discontinuities in the contact angle distribution we apply gaussian smoothing as a laplacian smoothing on the image data we use an additional step to approximately preserve the volume of the segmented phases as done by several other authors 58 60 the essential point in applying smoothing algorithms is that they modify the positions p i with i v var of the moving vertices while leaving the topology of the mesh unchanged we specify that oi are the given points qi the current points and pi the new modified points after one iteration cf examples in fig 3 thus a smoothing algorithm starts with the vertex positions o q and maps the current positions q to p in one step the new position p i of any vertex i usually depends only on the positions of its neighboring vertices j adj i the used laplacian smoothing algorithm works as follows the position pi of vertex i is replaced by the average of the positions of the neighboring vertices the technique for calculating the new position pi consists in updating the new positions pi immediately in this case a position pi may not only depend on the number of old positions q but may also depend on a previously calculated new position pj therefore the result of a smoothing pass through all vertices i v var depends on the order in which the vertices are considered fig 3 illustrates the basic procedure for the numerical implementation of our work we use the platform openfoam v1906 61 in connection with the contact angle on real surfaces the condition of the geometry at the location of the wetting line is essential since curved surfaces influence the wettability at this point a measure of curvature of the investigated three phase line is appropriate since the 3d scans are stored as polygon meshes i e there are only individual support points with corresponding connections only two different curvature values are available firstly the curvature is zero on the sub surfaces of the mesh and infinite at the edges and nodes because these values are not very useful for further processing and do not correspond to the values of the real object the curvature information must be approximated using the environment of a point mathematically the curvature κ is defined as a change of direction of a function 2 κ 2 x 2 one interpretation of curvature is the circle of curvature in fig 4 an attempt is made to connect a circle to the function to fit in the radius of this circle is indirectly proportional to the calculated curvature considering this we see that a kink in the function must have a curvature of infinity because the circle has a diameter of zero the opposite is true for straight lines the radius is infinite and the curvature is zero for 3d meshes we need the curvature of the surface at a certain point the curvature is also the second derivative here resulting in a 2 2 matrix w the second derivation of a two dimensional function is therefore 3 w 2 x 2 2 y x 2 x y 2 y 2 the eigenvalues of this matrix are called main curvatures κ 1 κ 2 these principal curvatures follow the eigenvectors of the matrix they are called main curvature directions with the help of the two main curvatures further measures such as the gaussian curvature g can be determined 4 g κ 1 κ 2 these calculated dimensions allow a rough categorization of the points into elliptical g 0 points based on the gaussian curvature hyperbolic g 0 and parabolic points g 0 62 the tensor averaging method 63 was used to approximate the curvature for the polygon mesh the basic idea of tensor averaging is a curvature tensor that is calculated for each examined point it is a weighted average of the curvature tensors of the adjacent polygons the desired curvature parameters can then be calculated from this tensor a tensor of curvature is defined in such a way that if a direction vector is multiplied by it it indicates the change of the normal in that direction for this purpose a system of equations is created which contains the changes of the normal of the vertices ni at their respective adjacent edges ej here the values of a polygon must be transformed into a coordinate system u v which lies in the plane of the polygon 3 2 material characterization monocrystalline al2o3 sapphire and hydrophilic martoxid mr 70 hereinafter referred to as mr 70 both from goodfellow gmbh are used for preliminary tests of contact angle measurements on planar surfaces sapphire is a monocrystalline aluminum oxide which is composed of 99 997 al2o3 is colorless and has a density of 3 99 g cm3 the sintered mr 70 is composed of 99 80 al2o3 is white and has a density of 3 87 g cm3 the sample from the sintered t60 64 almatis gmbh as material for the filtration experiments consists of 99 50 al2o3 has a density of 3 82 g cm3 and is white table 2 shows the respective roughness values r z r a and rms which were recorded with the atomic force microscope afm xe 100 park systems and the surface roughness measuring device hommel t1000 hommel gmbh as can already be seen from the roughness values the sapphire has an almost ideally smooth surface the sem images in fig 5 show the inhomogeneities and valleys of mr 70 these are caused by stress cracks either during the sintering process or by escaping h2o contained in the binder for all filtration experiments and the filter cake structure analysis crushed and classified t60 64 al2o3 particles ρ 3 82 g cm³ in size range of 50 to 200 μm are used fig 5 which reveal the highest roughness values for the liquid phase a brine of potassium iodide ki 25 mm purity 99 carl roth germany and 24 wt glycerol purity 99 8 carl roth germany in water with a density of ρ 1 06 g cm³ and a dynamic viscosity of ηη 1 98 mpas at 20 c is chosen for the filtration experiments table 1 contains the corresponding property values of the mixtures water and water glycerol mixtures are not suitable for longer measurements on planar surfaces which is why only glycerol was used for validation with the sessile droplet method the amount of water contained in the solution evaporates from the surface at room temperature potassium iodide as contrast agent inside the liquid enhances the achievable contrast between the phases in the final gray value images compared to the liquid alone a relatively large atomic number n and density ρ significantly increase the resulting x ray attenuation coefficient μ and thus lead to a higher contrast μ n 4 μρ that simplifies the image analysis and the following phase separation for all filtration tests potassium iodide is added to the mother liquid the salt concentration has to stay low to ensure a ζ potential stay above 30 mv so that no agglomeration effects occur any pre structuring of the suspension has a significant impact on the subsequent cake structure and the associated parameters 3 3 experimental set up and analysis procedure to determine the contact angle by contour analysis the planar samples are first cleaned with acetone and then placed in the drying oven at 100 c for five minutes the static contact angle measurements are carried out with the above mentioned samples on the g10 contact angle measuring instrument from krüss gmbh the sessile droplet method is used and the contact angles are evaluated with the circle fit method a droplet of 3 μl is placed on the surface and the baseline is positioned the right and left contact angles are determined by automatically applying tangents to the three phase contact points between the baseline and the droplet contour after a waiting period of 10 s the contact angles on the left and the right are determined from the droplet projection image for each sample 200 droplets are measured dynamic contact angle measurements are performed with the oca50 instrument from dataphysics instruments gmbh in the present work the polynomial fit method is used to record the measurements according to the vdi standard 55660 6 a 3 µl droplet is also chosen which is increased to a volume of 4 µl or reduced to 2 µl in 20 cycles with a pump speed of 0 2 μl s the droplet size is maintained for 30 s at both the maximum and minimum volume and the contact angles are automatically determined at the left and right side of the droplet then a new cycle began the entire time the cuvette tip remains inside the droplet fig 6 shows two measurements with 20 cycles one on the smooth sapphire surface and one on the rough mr 70 surface the same two surface samples are used for the measurements in the xrm therefore the samples are first cut to a size of about 0 5 0 5 cm mr 70 and 0 35 0 35 cm sapphire then a 1 μl droplet is placed on top of the sample table a 1 in the appendix summarizes the parameter settings for the xrm measurements the filtration experiments are done according to guideline vdi 2762 2 association of german engineers due to handling reasons and limiting dimensions inside the xrm housing experiments are carried out inside a downscaled vacuum nutsch cell at 0 5 bar this is a self developed flow cell ii made out of polymethyl methacrylate pmma with low x ray self attenuation the dimensions correlate with vdi 2762 1 i at a downscale factor of a i a ii 100 for xrm measurements the vacuum filtration process is conducted directly inside this in situ flow cell the effective filter area amounts to 20 mm² with an internal nutsch diameter of 5 mm details of the experimental set up and the measurement principle can be found in 65 the feed suspension with a solid volume fraction of cv 0 35 is gently stirred at 250 rpm for 4 min and afterwards filled into the nutsch suspension volume inside the nutsch amounts to 330 μl the filtration tests are stopped at complete desaturation s s rem at this point all voids are emptied and just hydraulic isolated liquid remains inside the cake matrix for validation we perform stepwise deliquoring in the laboratory by increasing pressure from 0 05 to 0 8 bar to confirm the irreducible saturation s rem we also validate the needed pressure difference of 0 5 bar with these capillary pressure tests the filter cakes investigated by xrm are dewatered directly after the filter cake build up at the same pressure of 0 5 bar afterwards the xrm measurements are performed on the desaturated filter cake using the xrm filtration cell we can only represent the static state of dewatering due to the long measuring times up to several hours the dynamic process and thus the dynamic contact angle within the filter cake structure remain inaccessible for measurement 4 results and discussion 4 1 preliminary investigations on flat surfaces xrm measurements are performed with a horizontal static droplet on sapphire and mr 70 three times each with measuring times between 2 5 and 4 hours according to the needed exposure time the measurements with sapphire consist of 1838 to 4124 and those with mr 70 of 1662 to 2166 measuring node points the results of these six measurements are shown in fig 7 together with the 200 laboratory measurements obtained by the krüss g10 device for both surfaces on the left side of the picture one droplet from the xrm measurement and one droplet from the contour analysis are shown the laboratory values are the mean value of both contact angles right left of each droplet in the first xrm measurement with sapphire and glycerol 50 of all values are between 49 and 70 in the respective distribution bottom outliers 83 values minimum 2 are almost twice as many as top outliers 44 values maximum 176 whereas the second measurement shows no outliers the upper interquartile limit is with 70 almost at the same height the lower interquartile limit with 33 and the median with 45 significantly distorts the distribution downwards the third measurement also has no outliers and shows an overall interquartile distance of 45 50 of all values are in the range of 46 and 90 and with a median of 68 the third measurement shows the largest contact angles the absence of outliers in the last two measurements indicates that the solid surface has a regular structure and the droplet thus has a uniform three phase contact line for mr 70 the interquartile range is between 75 and 98 in the first xrm measurement between 97 and 112 in the second and between 69 and 92 in the third the medians also show significantly higher values at 86 105 and 84 thus the contact angles of mr 70 are higher overall in contrast to sapphire there are outliers upwards and downwards in every measurement which reveals the irregular structure of the solid surface with mr 70 a comparatively narrow distribution of contact angles of each single xrm scan can be observed surprisingly all three measurements show high variation among each other these two aspects could indicate the influence of the roughness of the solid surface depending on where the contact angle was recorded at the droplet and the droplet itself was placed on the surface different angles may have been formed for example by edges or unevenness these irregularities can lead to a pinning effect i e the liquid is pinned to a certain site immobilizes and thus changes its contact angle since with a sessile droplet no dynamic is present the liquid cannot overcome a point and remains in this form further explanation can be provided by the model of cassie baxter 53 if air is trapped in the roughness of the surface the apparent contact angle increases the liquid does not penetrate into the valleys of the surface due to the high capillary entrance pressure of the small roughness sizes the existing air cannot be displaced it is noticeable that the standard deviations of the xrm measurements are significantly larger than those of the values from the krüss g10 with mr 70 the contact angles of the static g10 measurement are clearly higher in total all measurements provide similar results and the distributions overlap each other which indicates a good agreement between the two methods however with the xrm the detailed 3d acquisition also reflects the local influence of the solid surface to the three phase contact line and thus to the determined contact angle which is further described in section 4 2 here it is necessary to emphasize the difference between the two measuring methods on the one hand the two dimensional measurement which approximates the integral angles via a fixed geometry on the droplet circle fit method and on the other hand the three dimensional measurement which determines the local contact angles via several thousand individual points on the three phase boundary line statistically possible roughness or inhomogeneities affecting the angles dominate the distribution b less clearly on the sapphire or mr 70 surface microscopic cracks or voids occur only sporadically and in some distance to each other cf fig 5 with respect to the distribution a from the xrm data only the location of the polygons directly at the three phase contact line is decisive a pinning effect can thus become much more visible at individual angles since the polygons located there are strongly forced outward or inward these effects are less apparent when the entire droplet contour is considered as in distribution b furthermore we discretize the surface or the three phase contact line voxel based a or pixel based b although this discretization is relativized in a by the generation of the polygon mesh and the subsequent smoothing it is still only an artificial representation of the real geometry the contour analysis in b also needs this discretization but the resolution of the two dimensional image differs from the three dimensional image 4 2 porous structures the high resolution xrm measurement within the filter cake generates 168 187 contact angle measuring points these data points are shown in the boxplot diagram of fig 8 in comparison with the static krüss g10 and dynamic dataphysics oca50 laboratory measurements the investigated filter cake has a mean porosity of 43 1 1 9 and was desaturated to s 13 1 0 8 ratio of volume of pore liquid to pore volume the height specific filter cake resistance r c defined by vdi 2762 2 amounts to r c 3 05 1012 1 m² it can be seen that the contact angles of the liquid within the filter cake are widely distributed as they range from a minimum of 1 to a maximum of 180 there are more top 1748 than bottom 780 outliers however 50 of the values are in the range between 63 and 91 the median is 77 comparing the mean values and standard deviations of the filter cake with all sessile droplet measurements to the water glycerol mixture the contact angles of the filter cake cannot be clearly assigned the mean value within the filter cake is 78 which is between the measurements with sapphire and mr 70 the contact angles also vary significantly more than for the sessile droplets so that they almost cover the value range of the laboratory measurements completely this indicates that on the one hand the liquid interacts with a rough surface i e that the large contact angles are possibly caused by pores or edges on the other hand due to the low angles it behaves more like on a smooth surface than mr 70 even if the roughness of t60 64 is higher cf table 2 the xrm measurement and the dynamic sessile droplet measurements of mr 70 fall within the same range the standard deviations of the xrm measurements are larger here but the difference is smaller compared to sapphire the measurement of the irregular structure of mr 70 is therefore more representative for filter cakes in comparison the liquid volumes within the filter cake are also smaller than the measured sessile droplets over several orders of magnitude the median volume is v 50 1 64 10 6 μl with the distribution limits of v 10 0 76 10 6 μl and v 90 18 90 10 6 μl regarding the relationship between resolution and voxel edge length the resolution of 3 21 μm vx we used would be sufficient to represent structures with volumes of 0 37 10 6 μl corresponding to the diameter of the volume equivalent sphere of 9 μm 66 67 the small liquid volumes provide only a few voxels representing the corresponding surface area due to the voxel size adsorption layers on the particle surface are not resolvable but it could be that some voxels are assigned to the liquid due to the gray value gradient at the solid air phase boundary these misinterpreted voxels generate small liquid volumes and extremely small contact angles and create the visual impression of film formation another effect of this artifact would be smaller angles of liquid bridges since the liquid film of the bridge is elongated on the surface even though no liquid exists at the surface position during the image processing in section 3 1 we tried to significantly enhance the gray value gradient at the phase boundaries to prevent such effects but especially for the lower limit of the liquid distribution the effect might still occur in contrast the droplet sizes are 1 μl sessile droplet xrm and 2 to 4 μl sessile droplet krüss g10 and dataphysics oca50 due to the long measuring times with the xrm the dynamic process which in this case takes place in a few seconds might not be properly described some studies in the literature report that the wettability of rock surfaces changes permanently and dynamically over time 17 68 69 the results of the studies show capillary instability in drainage imbibition experiments such that the capillary pressure measurements changed steadily over time the authors attributed these deviations from the expected capillary curve to a change in the wettability of the rock sample over time like aging the change of the wetting angle is a pore scale phenomenon that changes the capillary pressure function independent of flow conditions or other instabilities 70 the contact angle therefore has the potential to change even in the static state of the system but during the measurement this would have resulted in a blurred phase interface which we could not observe if the sample shifts in one or more directions during the xrm measurement the voxel data cannot be matched exactly during the reconstruction of the projections the static condition also shows representative values with regard to saturation in comparison to the dynamic dewatering process in laboratory experiments in the incrementally measured saturation curves cf section 3 3 we reached similar irreducible saturation values of 10 to 16 xrm s 13 1 0 8 since the same state of equilibrium is reached after stepwise increase of the pressure level the progression of the liquid in any pore and the resulting receding angle cannot be resolved in the xrm measurement here we only display the liquid in the cake without the influence of external forces distributed capillary forces within the pore space which may move the liquid to other pore volumes and only occur due to the long measuring time cannot be excluded a re relaxation of the liquid may lead to a condition that is more likely to be represented by a static contact angle measurement but does not describe the process of dynamic dewatering since the solid surface was taken up in the state after dewatering and thus has already seen liquid it is possible that a kind of pre wetting may have occurred on some comparatively flat areas whereby the liquids show a rather fluid behavior and thus smaller contact angles driving force for the possible rewetting constitutes the mentioned distributed capillary force within the pore space enhanced by chemical potential differences on the surface as suggested by al ratrout et al 71 and singh et al 49 alratrout et al experimentally compared segmented three dimensional images in pore scale with manually measured contact angles from singh et al based on the same dataset singh et al performed ct measurements in the pore scale here remaining oil in the pore space was used as liquid all authors point out that among other things surface inhomogeneities can cause widely distributed contact angles in the pore space their results from the segmented 3d data also show widely distributed contact angles fig 9 shows the overall 3d complexity of the problem we see a capillary bridge between three particles with the corresponding contact angles even at this single remaining liquid area the contact angle varies between 61 and 92 along the wetting line emphasizing the range of variation of the overall distribution the resolution here is 3 2 μm vx in the visualization only the surfaces adjacent to the respective phase are shown as polygon mesh in the following fig 10 the gaussian curvature of the three phase line is plotted for all surfaces while g 0 is always obtained for the examined drops with good approximation i e there are only parabolic points on the line for sessile droplets on a flat surface g 0 should always occur in the ideal case one of the main curvatures is always zero which is why g 0 applies smaller surface structures which pin the liquid and are still resolvable in the xrm generate both single hyperbolic and elliptical points of curvature however these weak fluctuations can also result from image segmentation and voxel assignment partial volume effects pve at the respective phase boundary with rougher materials the effect of pinning is more pronounced and with the mr 70 surface the gaussian curvature fluctuates considerably more around zero on the contrary the value fluctuates strongly around g 0 within the filter cake structure in the filter cake exists areas of local curvature with both positive and negative values but there is no direct correlation between the curvature of the interface and the contact angle in trapped capillary bridges liquid volumes in partially desaturated areas with larger contact angles tend to have a more positive curvature on the one hand these effects indicate the highly irregular structure of the crushed particles which come close neither to a spherical surface nor to a flat plate and have macroscopically formed valleys and peaks of a few micrometers see roughness values in table 2 on the other hand there is microscopic roughness which is responsible for pinning effects interestingly these significant deviations from g 0 become apparent first at contact angles above 40 we assume that at corners or edges the fluid bulges more until the film snaps off when the applied pressure difference is large enough otherwise the liquid bridge remains in this state additionally any adhesive fluid on the surface of the particles that has not been previously removed influences the contact angles these adhesive fluids can consist of entrapped air during the suspension preparation or through the filtration process although these effects strongly influence the course of the contact line the structures themselves cannot be resolved in the xrm only their effect on the developing interface and the contact line respective their curvature however ideal saddle points for g 0 or elliptical points g 0 within the porous structure do not occur the movement of the interface within the porous filter cake matrix causes changes in phase saturation and interface curvature as well as local phenomena such as the observed contact angle hysteresis shown in fig 8 disruption of the liquid regions and possible haines jumps the reduction of all these factors to the difference of the average pressures at the pore throat seems to be only a strong simplification the fluctuation of the three phase contact line from fig 10 is rather due to the above mentioned features which are not yet fully scientifically identifiable 72 5 conclusion this study provides a basic understanding of water inclusions i e liquid bridges inside a porous medium made of rough particles as a function of wettability we used x ray microtomography to study the in situ contact angles on the pore scale with regard to desaturation effects the wettability effects of the cake and the corresponding data evaluation were validated by conventional droplet shape analysis and xrm measurements on flat surfaces although static xrm measurements provide valuable spatial information on the three phase contact line they are not able to capture the dynamic aspect of dewatering since the particle surface inside the filter cake has already been moistened once i e the solid surface has seen the liquid before the recorded steady state can at least approximately be compared with a dynamic measurement our analysis shows that air only penetrates the larger accessible water wetted pore throats while smaller constrictions remain water filled because they require a higher capillary inlet pressure for moisture removal we provide experimental evidence for the existence of hydraulically isolated water reservoirs with good wettability up to 90 and beyond the prevailing contact angle the low remaining water saturation of s 13 1 0 8 indicates the increased permeability of air and the formation of the cross linked continuous structure of the gas phase in the pore volume as the contact angles of the filter cake are in the small as well as in the large range the small droplet quantities seem to be strongly affected by edges roughness or surface inhomogeneities within the pores as well as by dynamics of the creation of isolated liquid volumes the fact that the solid surface was picked up after dewatering and was thus already wetted once seems to lead to a kind of pre wetting the liquid changes into a flow which in the end results in small contact angles the formation of very thin water layers on solid surfaces during desaturation in a well wettable system has been hypothetically assumed in the literature and considered in many theoretical and model studies 73 but could not be proven experimentally with the resolution used here the range of the distribution of contact angle and curvature increases with the degree of roughness with the correlation becoming more obvious for larger contact angles on rougher surfaces the contact angle tends to be lower due to the accumulation of water in pore throats due to the broad contact angle distribution both better wettable and worse wettable areas exist within the pore space for both phases multiple wet state if these multiple wetting properties are not restricted to single regions of the filter cake but can be found in the entire filter cake both permeabilities remain sufficiently high these conditions might be favorable for water displacement we assume that in other porous materials where it is desirable to have both a liquid and a gas phase flowing over a wide range of saturation the combination of wettability change and rough surfaces will result in this multiple wet state besides the degree of wettability the pore morphology the pore throat distribution and the degree of crosslinking of the pore space also influence the permeabilities of both phases these influencing factors become even more important when process relevant pressure differences are only of secondary importance due to small pore sizes further experiments with variation of the wetting properties would be necessary to prove the advantages of a multiple wet state additionally the variation of the pore space morphology with similar wetting properties e g variation of particle size or shape is assumed to have significant effect on the saturation level besides this further research could focus on the investigation of the stability and mobility of remaining water reservoirs as a function of contact angle and capillary pressure in poorly wetting filter cake structures 6 notation symbol abbr unit meaning a m² filter area cv m3 m3 solid volume fraction related to the total suspension volume n i normal vector to the surface i n atomic number oi original nodes of the mesh before smoothing δp pa pressure difference pi current nodes during smoothing iterations p rel relative vapor pressure qi final node of the mesh after smoothing ra m arithmetic mean deviation of the assessed profile rz m arithmetic mean of maximum heights of five individual measuring sections rms m root mean square roughness r c 1 m² height specific filter cake resistance s m3 m3 liquid saturation ti s time step i γ kg s² surface tension ε m3 m3 porosity κ curvature μ 1 m linear x ray absorption coefficient ρ kg m³ density η pas dynamic viscosity θi local contact angle θ a advancing contact angle θ r receding contact angle afm atomic force microscope fbp filtered back projection pve partial volume effects sem scanning electron microscope xrm x ray microscopy 7 credit author statement erik löwer conceptualization data curation formal analysis investigation methodology software visualization writing original draft christine makowlew data curation investigation thomas leissner supervision writing review editing validation urs peuker supervision writing review editing funding acquisition project administration resources declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement we express our gratitude to the german research foundation dfg pe 1160 23 1 and the international fine particle research institute ifpri which supported this research additionally we thank r ditscherlein and thu trang võ for proof reading appendix table a 1 
