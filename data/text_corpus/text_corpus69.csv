index,text
345,subsurface flow model calibration against dynamic response data is often constrained by a prior conceptual model of geologic scenario that specifies the expected spatial variability and geologic patterns in the solution however several sources of uncertainty exist in developing a conceptual geological model including data limitation process based modeling assumptions and subjective interpretations therefore it is prudent to consider the uncertainty in geologic scenarios during model calibration and to utilize the flow response data in supporting or rejecting the proposed scenarios we present a novel framework whereby dynamic response data is used to screen a set of proposed geologic scenarios by combining gradient based inversion for feature extraction and convolutional neural networks for feature recognition to compactly represent the salient features of each scenario an extremely low rank parameterization with the leading elements of the principal components analysis pca is adopted the pca basis elements of different scenarios are combined to define the search space for feature extraction which is implemented via an iterative least squares inversion formulation to match the observed data the inversion solution is obtained by selectively combining the pca representations from different scenarios and contains the dominant spatial patterns that are needed to match the observed data feature recognition to identify the relevant geologic scenarios based on the reconstructed spatial solution of feature extraction inversion is performed using a pre trained convolutional neural network cnn the method offers several advantages including an efficient implementation that does not require extensive forward simulation runs use of flow data to identify pertinent geologic scenarios and the ability to combine geologic scenarios if supported by data the performance of the proposed approach is evaluated using numerical experiments from pumping tests in groundwater aquifers keywords model calibration geologic uncertainty geologic scenarios machine learning convolutional neural network 1 introduction calibration of subsurface flow models against monitoring and performance data is commonly used to improve the predictive capability of simulation models as a tool for decision making the resulting model calibration formulation often leads to ill posed inverse problems where limited data are used to estimate high dimensional parameters that represent heterogeneous rock property distributions parameterization and regularization are the typical approaches to solve underdetermined inverse problems parameterization is performed by finding a compact representation of the original parameters either in the spatial domain e g the zonation method jacquard et al 1965 and the pilot point method ramarao et al 1995 or in a transform domain the transform domain can be either learned from data e g principle component analysis wold et al 1987 sarma et al 2007 or it can be data independent e g discrete cosine transform ahmed et al 1974 recently deep learning approaches such as gan and vae have also been introduced as parameterization techniques laloy et al 2017 2018 canchumuni et al 2019 jiang and jafarpour 2020 mohd razak and jafarpour 2020b regularization on the other hand constrains the solution of an inverse problem by adding a penalty term that promotes user specified properties in the solution for example the tikhonov regularization tarantola 2006 stabilizes the inversion process by requiring the solution to be smooth and the total variation regularization rudin et al 1992 allows for detection of local discontinuity e g facies boundaries in the obtained solution parameterization and regularization techniques often serve two purposes making the inverse problem better posed mathematically and improving the plausibility of the obtained solution by incorporating the expected behavior of the solution e g preserving the geologic continuity traditionally a prior geologic scenario is used to regularize the problem by specifying the expected form of the spatial variability in subsurface properties strebelle 2002 caers and zhang 2004 the prior geologic scenario is usually derived from integrating different sources of knowledge koltermann and gorelick 1996 such as quantitative measurements e g hard data well logs seismic and qualitative data e g outcrops as well as geologic modeling techniques and expert knowledge baddeley et al 2004 conventional model calibration methods assume that a prior conceptual model of geologic scenario is known and must be respected while updating model parameters rock properties to match the observed response data however the assumption that the geologic scenario is known with certainty is not realistic as several sources of uncertainty and subjectivity are present in building such models bond et al 2007 mohd razak and jafarpour 2020a acknowledging and incorporating the uncertainty in conceptual geologic scenarios is therefore important for developing reliable workflows for forecasting model calibration optimization and uncertainty quantification christie et al 2005 li and jafarpour 2010 refsgaard et al 2012 linde et al 2015 on the other hand disregarding the uncertainty in the geologic scenario can result in models that can match the available flow response data but provide incorrect biased predictions therefore it is important to account for the uncertainty in the prior knowledge about the geologic scenario and to use dynamic response data in addition to other sources of information to reduce it khaninezhad and jafarpour 2014 golmohammadi and jafarpour 2016 screening of geologic scenarios based on flow response data is motivated by the need to on the one hand account for the uncertainty and subjectivity in developing conceptual geologic models and on the other hand reduce the uncertainty space by eliminating scenarios that cannot be supported by data one approach to represent the uncertainty in the geologic scenario is to consider multiple plausible conceptual models either based on alternative interpretations by different geologists or by stochastic treatment of process based models that are used to generate the scenarios when confronted with multiple scenarios in model calibration a basic approach is to perform individual calibration with each prior scenario to cover a wide range of variability and to evaluate the likelihood of the resulting solutions while the bayesian framework has been used to quantify the uncertainty when multiple geologic scenarios are present arnold et al 2019 demyanov et al 2019 encapsulating all the proposed scenarios within this framework can be computationally demanding an alternative approach is to reduce the uncertainty by developing formulations that use the available data to eliminate irrelevant or highly unlikely scenarios prior to detailed model calibration and uncertainty quantification this approach is consistent with the popper bayes philosophy that observations can only be used to falsify and not deduce models or theories tarantola 2006 or in our case geologic scenarios that are not supported by data suzuki et al 2006 park et al 2013 scheidt et al 2015 however in practical applications the computational cost of a rigorous and exhaustive falsification process can be prohibitive and more efficient and practical methods may become necessary a computationally less demanding approach is to formulate efficient inverse problems that use the available data to support or reject a set of proposed conceptual geological models khaninezhad and jafarpour 2014 golmohammadi and jafarpour 2016 or to extend model calibration formulations to include multiple plausible scenarios as prior knowledge khaninezhad et al 2012 khaninezhad and jafarpour 2014 regardless of the formulation used it is important to note that the models supported or selected based on available data may be rejected upon the availability of additional data in recent years advances in machine learning have resulted in the popularity and adoption of these techniques in several areas of science and engineering goodfellow et al 2014 arjovsky et al 2017 kingma and welling 2013 including subsurface modeling yu et al 2019 jiang and jafarpour 2019 laloy et al 2018 in particular convolutional neural network cnn has shown great promise for pattern learning and analysis especially when applied to images krizhevsky et al 2012 cnn can efficiently extract local features by scanning and convolving images with small filters that contain the parameters to be learned lecun et al 1998 inspired by the discovery of visual perception mechanism hubel and wiesel 1968 gu et al 2018 the architecture and training process of cnn was first established by lecun et al 1990 they invented a multi layer network called lenet 5 which was trained using the backpropagation algorithm hecht nielsen 1992 with access to a massive amount of data from the internet improvement in gpu and parallel computing convolutional neural network has achieved state of the art performance in many pattern recognition tasks e g natural language processing kim 2014 computer vision krizhevsky et al 2012 and speech recognition graves et al 2013 in this paper we present a new formulation for prior geologic scenario identification by inverting dynamic flow response data the method combines a gradient based feature extraction from flow data with a cnn classification model for feature recognition to identify geologic scenarios that are supported or rejected by the data the details of the developed approach are discussed in section 2 followed by numerical experiments and their discussion in section 3 2 methodology in this section we present the overall workflow and its individual components the inputs to the workflow are multiple plausible geologic scenarios with their corresponding realizations as well as the observed flow response data from the field the objective is to assign importance plausibility weights to each geologic scenario based on the observed flow response data the proposed workflow consists of an iterative implementation of two main steps i feature extraction by inversting the flow data and ii feature recognition using a cnn architecture a more elaborate workflow is shown in fig 1 in the feature extraction step of the workflow a spatial map of the desired property is reconstructed based on the provided geologic scenarios and flow response data by solving an inversion problem with an extremely low rank combined or hybrid parameterization approach the objective of the first step is to utilize the flow response data to extract the salient features from different scenarios that are included in the parameterization in the feature recognition step a pre trained convolutional neural network cnn predicts the relevant geologic scenarios based on the obtained spatial map from the inversion in the first step to further discriminate between the scenarios the composition of the hybrid parameterization is updated at the end of each iteration based on the recognized features by adjusting the number of principal components pcs from each scenario this is achieved by increasing the number of pcs from scenarios that have larger weights to help improve the quality of the reconstructed solution the detailed description of the feature extraction and feature recognition steps is presented next we note that while the feature extraction can also be performed as a regression problem using a cnn model such an approach would require a large number of labeled data where the labels have to be derived based on flow simulation making the process computationally very demanding 2 1 feature extraction using inversion with leading pca elements in the feature extraction step realizations from each geologic scenario are first used to construct very few leading elements of the principal component analysis pca that can be used to compactly represent the salient spatial patterns in the corresponding scenario these principal components for different scenarios are then put into a combined linear expansion to approximately represent a model from any geologic scenario note that the number of pcs should be small enough to avoid obtained detaled solution as the main goal is to approximately represent the global connectivity pattern in each scenario in otherwords the parameterization is not intended for full model calibration and is only used to provide distinguishing power for each scenarios by choosing very few leading pca elements it is ensured that the main spatial patterns from a given scenario can only be useful to approximate models pertaining to that scenario without the ability to represent realizations from other scenarios consequently the constructed parameterization with the combined pca elements possesses a strong discriminating property that is exploited in the formulation the resulting parameterization is used in an inversion formulation to allow for the scenarios to compete against each other in matching the observed data the inversion solution is obtained via an efficient gradient based iterative algorithm to formulate the inverse problem for feature extraction with flow response data we define the forward model that relates the data d m 1 to subsurface flow property distribution u n 1 e g rock permeability at each of the n grid cells in the model as 1 d obs g u where g is the nonlinear mapping from the parameter space to the data domain for example governing partial differential equations pdes for multi phase flow in porous media note that a geologic scenario refers to a conceptual model that can be used to generate many realizations samples and u represents one such sample our objective is to use flow data to identify geologic scenarios that are pertinent to this end a parameterization is needed to compactly represent the main geological features i e spatial patterns in each scenario that is instead of dealing with many samples pertaining to a given scenario a parametrization method is adopted to summarize the main features in the corresponding realizations a classical parameterization method to accomplish this objective is based on the pca representation denoting a set of l permeability model realizations from the geologic scenario s as u s u 1 u 1 u l s and the corresponding k dimensional pca basis as φ n k s k is the number of leading pca basis elements a sample u j s from this geologic scenario can have the following k term pca approximation 2 u j s i ϕ i s v j i s φ s v j s where v j s is the corresponding k dimensional vector of projected pca coefficients a similar parameterization can be obtained for each of the geologic scenarios assuming s proposed geologic scenarios one can obtain a set of s truncated pca bases i e φ 1 φ 2 φ s each providing approximate representation of any given sample from their respective scenario u j 1 u j 2 u j s with the corresponding coefficients v j 1 v j 2 v j s t by stacking the pca bases from different scenarios we obtain φ φ 1 φ 2 φ s which can be used to compactly represent a sample from any of the scenarios i e u j s φ s v j s however for compactness we use the combined stacked bases and the notation introduced above to write u j φ v j with this parameterization the feature extraction inversion solution can be obtained by minimizing the mismatch between the observed and predicted data 3 v a r g m i n v c d 1 2 d obs g φ v 2 2 where c d is the diagonal observation noise covariance aster et al 2018 some important remarks regarding this formulation are in order first the basis corresponding to each geologic scenario can include a different number of leading modes k depending on the complexity of the features in each scenario however if the basis for each geologic scenario has dimension n k the combined version φ will have dimension n k s second the formulation assumes that the geologic scenarios are reasonably far from each other and the number of leading pcs k is sufficiently small with these assumptions a model u j s i e from geologic scenario s is expected to have a similar representation in φ s and in the combined version φ that is the hypothesis is that in approximating a sample from a given geologic scenario large scale features that are contained in the leading pcs from other scenarios have little contribution in general this behavior diminishes with an increasing number of leading pcs k as discussed in the next section third by combining the pca bases from different geologic scenarios into a single representation the method is able to generate very diverse spatial features by mixing the basis elements from different scenarios the combined representation contains a rich set of spatial features that not only represent the dominant spatial pattern in each geologic scenarios but they can also be combined to represent spatial features consisting of the union of individual scenarios as a result it is possible for basis elements corresponding to more than one scenario to contribute to the solution this is an important advantage of the algorithm for practical applications where the correct geologic scenario is unknown and one single prior scenario may not be sufficient for describing the spatial features in the true field fourth in general the flow response data tend to show sensitivity to large scale variability in the permeability field therefore basis elements that preserve the large scale features are used to map the field global connectivity additionally using fewer parameters in the inversion leads to a better posed problem fifth although φ is expected to form a basis with linearly independent columns given the distinct nature of the scenarios the orthogonal property of the individual pca bases is lost after combining them this however only affects the inverse mapping finding v for a given u which is not needed in the formulation the nonlinear least squares problem in eq 3 can be solved to find v and hence the corresponding u φ v using a standard gradient based algorithm the gradients of the objective function with respect to the original property distribution u can be computed using efficient adjoint implementations given the linear form of the parameterization the chain rule of differentiation can be invoked to obtain the gradients with respect to the inversion parameters v the next step is to use the inversion solution v or u to identify which geologic scenarios are used in constructing the solution although this may appear to be a simple task it can prove to be quite challenging considering that the resulting inversion solution is expected to have low quality resolution and can include complex combined features as discussed in the next section to demonstrate the discriminating power of the leading pca basis fig 2 a shows an example with two simple scenarios of circle and bar objects the corresponding pca elements for each case are shown on the right side of fig 2 a the pca basis images in each case clearly show an order the leading modes have dominant large scale features corresponding to the shape of the objects in their respective prior models the non leading basis images e g no 100 do not carry any significant information about the underlying objects fig 2 b illustrates the best approximation in rmse sense of a sample circle image with eight leading basis images from each prior scenario and a combination of 8 circle and 8 bar basis images it is evident from these results that a circle image cannot be approximated by the leading pca basis of the bar images it is also clear that adding the leading bar basis images to those of the circle basis images does not provide a noticeable improvement in approximating the sample circle image this implies that if very few leading basis images from each prior scenario are included in the combined representation only the basis images corresponding to the objects present in the target sample will have a meaningful contribution to its approximation it is important to emphasize that this discriminating property diminishes as more non leading elements of the prior scenarios are included therefore in the developed formulation only very few leading pca basis elements from each prior geologic scenario are included in the combined parameterization to maintain the discriminating power of the feature extraction approach 2 2 feature recognition with cnn with the salient features extracted the next question is how to identify which scenarios the extracted features belong to in general the extracted features from the inversion problem are expected to contain inversion errors artifacts due to the limited data used moreover the solution may involve spatial patterns from more than one geologic scenario which can complicate the feature recognition geologic scenario selection problem many of the existing quantitative measures that are used to evaluate the similarity between images are less sensitive to spatial patterns and may not provide a robust metric for comparing the spatial features in images a seemingly natural choice for deciding about the relevant geologic scenarios after the inversion process can be based on the norm of the pca coefficients loadings of each scenario in the parameterized solution i e coefficients in v the expectation is that if a given scenario has a significant contribution the corresponding weights must be large however we found that this is not necessarily the case because two or more scenarios can have large coefficients while their net contribution is minimal that is they can cancel the effect of each other on the final spatial representation this issue can be avoided by applying a regularization penalty function such as group sparsity golmohammadi and jafarpour 2016 an alternative approach is to use the spatial solution u for feature recognition one way to accomplish this is by projecting the inversion solution u obtained by using the combined leading pca basis for all scenarios onto the leading pca basis of each individual geologic scenario to quantify the projection approximation error for each scenario in the absence of other scenarios e g using ℓ 2 norm of the projection residuals in this case the basis corresponding to the geologic scenario that has relevant features is expected to provide smaller projecting error while this method solves the issue encountered in the first approach we have observed that the projection errors of different scenarios can be quite similar when quantified through the second norm ℓ 2 of the residuals this is attributed to the fact that the ℓ 2 norm over pixel based differences between two images is not sensitive to structural similarity spatial patterns in them a pattern based method is therefore more appropriate for distinguishing images with different structural connectivity patterns in this paper we use convolutional neural network cnn as a powerful image classification method for this task a neural network nn consists of artificial neurons that use the input to change their internal state activation and generate a corresponding output that is effective in recognizing patterns neural networks are formed by connecting the output of certain neurons to the input of other neurons resulting in a directed weighted graph fig 3 left shows a simple nn consisting of an input layer two hidden layers and one output layer the mathematical operations associated with nns are elementary and typically include weighted combinations followed by applying nonlinear activation functions as shown in fig 3 right the use of nn involves two parts training and predicting in the training mode the training data a set of inputs and the corresponding label outputs is fed into the network the loss is calculated based on the difference between network predicted and true outputs then the weights in the network are adjusted to minimize the network prediction errors the minimization is implemented via gradient based backpropagation algorithms rumelhart et al 1986 for classification problems the weight assigned to each category is typically calculated by a softmax or normalized exponential function of the form 4 σ i z e z i k e z k the softmax function converts an arbitrary k dimensional vector z to a new k dimensional vector σ z with entries in the range 0 1 that sum to 1 this conversion assigns probability values to each output class dunne and campbell 1997 with the output of the softmax function representing the probability assigned to each class a compatible loss function for training a classification model is the cross entropy function dunne and campbell 1997 defined as 5 h p q x p x l o g q x where p and q are the true and predicted labels respectively the power of nn comes from stacking several layers and training the resulting network with abundant relevant data to learn the weights in fact nn can be viewed as a nonlinear regression or parameter estimation problem where the observed training data are used to estimate the parameters weights of the model network while stacking layers increases the complexity and power of nn it also results in a substantial increase in the number of parameters and nonlinearity especially in fully connected networks which can lead to diminishing gradient and overfitting issues a convolutional neural network contains convolutional layers in which several filters or kernels with learnable weights scan the input image and perform local convolution operations lecun et al 1989 1990 1995 1998 as shown in fig 4 top several filters are used to capture different spatial attributes of the input image each convolutional layer is typically followed by an activation function that operates on the convolution results and provides an output that indicates whether the node is active for the given input in this paper we use the rectified linear unit relu as the activation function the activation layer is followed by a pooling or down sampling layer which is designed to summarize the output information from each layer before passing to the next layer in addition to reducing the sze of the output from each layer the pooling operation changes the scale of the features that will be learned by the next set of filter resuling in each hidden layer representing a different level of abstraction typical pooling operations are average pooling replacing a subset of inputs with their average value and max pooling replacing a subset of inputs with their maximum value of which we use the latter in this paper fig 4 bottom illustrates these operations for a combined layer of cnn that includes the sequence of convolution relu pooling operations with a simple example showing the typical input output of each operation right to generate the output from cnn as a classification model as shown in fig 4 top the output of the final pooling step is flattened and the resulting outputs are connected to each of the s classes following a softmax transformation as a classification model with parameters θ cnn takes a set of labeled data as input and learns to predict the label geologic scenario associated with any new input image in our examples the input data consists of spatial maps of rock flow property distribution and the labels are the geologic scenarios once trained the cnn is used in feed forward mode to take as input the spatial map with geologic features extracted from flow inversion and compute the corresponding scenario label in practice cnn uses the softmax operation before the output layer to calculate the probability assigned to the corresponding plausible scenarios that is y θ x alternatively one could use a hard thresholding approach to convert the softmax outputs into discrete one hot vectors that provide hard labels if the number of geologic scenarios is s the output is represented as a one hot vector encoding y θ x r s where each column represents the likelihood of each sample to belong to a scenario during training the following cross entropy loss function is minimized by adjusting the weights 6 l z y θ i 0 s y i l o g σ z i 1 y i l o g 1 σ z i where σ is the sigmoid function and z is the data label the cross entropy loss corresponds to the kullback leibler divergence between the empirical distribution of the input data and the predicted distribution which is minimized during training compared to a fully connected netwrok cnn offers three main advantages 1 sparse connections by exploiting local patterns in images 2 shared weights by using the same filter across an entire input image resulting in translation equivariance and 3 pooling operation that leads to local shift invariance a convolutional layer performs local operations with small filter sizes followed by a pooling process which leads to the local shift invariance property of cnn and a significant reduction in the number of parameters unlike classical image processing methods where convolution filters are pre computed weights in the convolutional layers are learned from training data the learned filters are then applied to input images in the forward prediction mode to perform the desired analysis for example classification it is important to note that cnn usually contains both convolutional layers and fully connected layers in general the convolutional layers extract spatial features while the fully connected layers usually the last few layers serve as classification layers the convolutional layer is often followed by a pooling or down sampling layer to compactly represent the salient information in each kernel by replacing the convolution outputs with summary statistics either maximum values max pooling or mean values average pooling cnn architectures have achieved excellent performance in pattern recognition krizhevsky et al 2012 sharif razavian et al 2014 simonyan and zisserman 2014 the success of cnn can be partly attributed to the efficiency of its architecture for capturing local correlations patterns in natural images the drawbacks of cnn include the ad hoc nature of its design the number of tuning parameters involved and its black box nature that makes it difficult to explain its behavior and learning mechanism despite these limitations cnn has enjoyed great success in many applications and remains a growing field of research given the complexities associated with assigning geological scenarios based on extracted features in our workflow and the success of cnn in imaging applications for feature detection and classification we adopt cnn as an effective pattern based tool for feature recognition to predict the relevant geologic scenarios for a given input image construction of a cnn architecture requires tuning through a trial and error process where different design parameters are adjusted until acceptable performance in training validation and test data is achieved an important consideration in the design and training of neural networks is overfitting without regularization redundant weights and or limited training data can result in the networks showing great performance during the training stage but very poor performance on test cases prediction stage some common regularization techniques that are used to prevent overfitting includes weight decay krogh and hertz 1992 dropout srivastava et al 2014 and batch normalization ioffe and szegedy 2015 weight decay is equivalent to having a quadratic penalty term on the weights dropout improves overfitting by randomly dropping out neurons and fitting the training data with a subset of weights hence it imparts robustness on the trained network and can be viewed as an approximate ensemble learning framework although it was initially applied to fully connected layers more recently its application with cnn has been shown to be effective park and kwak 2016 batch normalization re centers and re scales data between layers although batch normalization and dropout are two of the most powerful regularization techniques recent results in the literature suggest that combining them can lead to performance degradation li et al 2019 in this study we use the combination of dropout and weight decay as the regularization approach for training the cnn although cnn has shown great performance for pattern learning in spatial images the interpretability of cnn is important for real world applications and design purposes the main aspects of the interpretability are the features learned in different parts of cnn and the features used for prediction i e attribution olah et al 2017 visualization tools such as grad cam can be used to understand the importance of different regions of the input image in predicting the output selvaraju et al 2017 another feature visualization tool is the activation maximization algorithm in which the objective is to find an input image that maximizes the activation of a specific neuron or filter in the network these visualization tools offer useful interpretations of the learned representations in cnn we used these methods in our work to gain insight into the design and tuning of the cnn architecture 2 3 training data in this work the input image for the feature recognition classification task is the solution of the corresponding feature extraction inverse problem which is estimated from incomplete flow data and involves inversion errors this implies that the input data for training cnn should also represent solutions of similar inverse problems while the output remains the correct label associated with each input however generating input data that represent the solution of an inverse problem is not practical as it requires solving an inverse problem per each training data as an approximation one may simply use as training data the exact representation of prior models and their corresponding scenario labels a better alternative is to use pca approximation of the original images to account for the parameterization error in the first step while the latter approach is consistent with the pca parameterization that is used in the feature extraction step it does not account for the errors and artifacts that are introduced during inversion to account for the inversion errors in the training data we added spatially correlated errors to the pca approximations of the original models input data for each scenario this was done by introducing leading pcs from other scenarios with random coefficients this approach is consistent with the intended application of cnn as the expected inversion solution artifacts are spanned by the hybrid pca parameterization that is used in feature extraction tensorflow abadi et al 2015 was used to build and train the cnn in our study for the examples presented in the next section the specific parameters of the cnn model are summarized in the corresponding tables 2 4 iterative workflow in the proposed workflow we assume that multiple realizations from each geologic scenario are available a cnn model is first designed and trained with these realizations the scenarios are then parameterized into pca components using their corresponding realizations initially the number of pca elements from each scenario in the hybrid basis k 0 k 0 1 k 0 2 k 0 3 k 0 s is selected to retain the same amount of cumulative energy variance for each scenario this approach accounts for the variability in the level of complexity across the scenarios e g straight and meandering channels to ensure that initially each scenario is represented with similar quality we note that the retained level of energy is one of the hyper parameters that depends on the complexity of the scenarios the similarity of the scenarios and the quality and quantity of the flow response data when the scenarios are distinct only a few leading pcs can provide significant distinguishing power the total number of pcs in the hybrid basis k is then fixed throughout the workflow with the initial hybrid basis the feature extraction step is performed and the solution is passed to cnn for geologic scenario selection the presence of multiple potentially irrelevant scenarios in the extracted features however may have an impact of the quality of the solution therefore in order to improve the accuracy of the algorithm we implement an adaptive algorithm by iteratively performing the two steps in the iterative formulation the number of pcs that are included from each scenario is scaled according to the weights assigned to that scenario during feature recognition with cnn at iteration i the spatial solution from the feature extraction step is based on a hybrid basis that has a composition k i with the pattern based probabilities p i p i 1 p i 2 p i 3 p i s assigned by cnn the new composition of the hybrid basis k i 1 is updated by linearly adjusting the number of corresponding pcs for each scenario we performed an extensive set of numerical experiments to evaluate the performance of this iterative approach in general two situations are commonly encountered a the flow response is sensitive to the significant features of each scenario and the hybrid basis is dominated by the correct scenario within one or two iterations and b data is insufficient to discriminate against the scenarios or a mixture of features from different scenarios remain in the solution after several iterations to deal with the latter situation a maximum number of iteration is set to terminate the algorithm 3 numerical experiments to test the performance of the developed workflow with nonlinear response data we apply it to several pumping test experiments involving single phase flow in two dimensional and three dimensional aquifers manzocchi et al 2008 howell et al 2008 we evaluate the performance of the method by computing a dominating rate as well as a surviving rate of the correct scenario the dominating rate refers to the fraction of solutions in which the correct scenario is considered as the most likely scenario by the workflow the surviving rate refers to the fraction of solutions in which the correct scenario is promoted by the workflow having a likelihood that is larger than 1 n s c e n a r i o where the n s c e n a r i o is the total number of scenarios 3 1 pumping test with non gaussian 2d models for the pumping test we consider non gaussian models with distinct alluvial channel patterns fig 5 the models have a dimension of 100 100 the geologic scenarios are defined based on the orientation and connectivity of the alluvial channel features these scenarios are derived from three training images with meandering intersecting and straight channels by changing the channel orientations two diagonal directions are used for the intersecting and straight channels two facies realizations are generated using the snesim algorithm caers and zhang 2004 implemented in s gems remy 2005 within facies heterogeneity is modeled using multi gaussian random fields the logarithm of hydraulic conductivity inside and outside the channels has a mean value of 0 6 and 2 4 respectively for each scenario a total of 500 realizations are generated of which 400 are used to construct the pca bases and to train the cnn model the remaining 100 models from each scenario are divided into two sets of 50 one used for validation to tune the hyper parameters and the other for testing the performance of the algorithm general information about the architecture of the cnn model is listed in table 1 the relu is used as the activation layer for the convolutional and fully connected layers dropout is added before relu in the convolutional layers for training the spatial models are approximated with a pca basis that contains 80 energy and contain both correlated and uncorrelated noise as shown in fig 6 we set up an aquifer pumping test where a pumping well is extracting water at a constant rate and the distribution of the logarithm of hydraulic conductivity is unknown the unit of hydraulic conductivity is c m s while the non gaussian models are used as the distribution of log hydraulic conductivity the configuration of the pumping test is shown in fig 7 a the aquifer has a dimension of 1000 m 1000 m 10 m the top and the bottom of the domain are no flow boundaries the pressures at the left and right boundary are 20 m and 10 m respectively the porosity in the domain has a constant value of 0 36 the background water flow due to the pressure difference in the field is from left to right the pumping rate is 3000 m 3 d a y a total of 36 monitoring wells are uniformly placed in the aquifer where the log hydraulic conductivity and pressure head are observed neglecting diffusion and dispersion chen et al 2006 the governing equations mass conservation and darcy s law are expressed as 7 ϕ ρ t ρ v q 8 v 1 μ k p ρ g z where ϕ ρ t v q μ k and p are porosity density time velocity source term viscosity and pressure respectively the feature extraction is implemented using gradient based inversion as discussed in the methodology section one of the test cases from scenario 1 is shown in fig 7 b since scenario 1 meandering channel has significantly more variability than the other scenarios the initial hybrid basis has more elements from this scenario initially the basis elements represent an equal amount of variance or energy from each scenario fig 7 d shows the details of the solution iterations in the first iteration the recovered solution shows disconnected channel features because the pcs from several geologic scenarios are included however cnn is able to recognize the meandering feature and increases the weight assigned to the correct scenario the next iterations only confirm the relevance of the scenario with meandering channels and identify it as the dominant scenario it is important to note that the main objective of the pca based parameterization is to screen the geologic scenarios using extremely low rank approximations once the geologic scenario is identified existing model calibration methods for non gaussian problems can be adopted to obtain more detailed calibrated models khodabakhshi and jafarpour 2011 in fig 8 a failed test case from scenario 1 is illustrated in this case the reference model fig 8 b has both meandering and intersecting channel features the center plots in fig 8 d show that the recovered solution also contains features that can be identified as intersecting channels with some meandering patterns therefore the intersecting scenario scenario 3 is assigned the highest probability and the correct scenario scenario 1 is identified with a lower likelihood given the south east to north west orientation of the identified features cnn also assigns a small probability to scenario 5 the results from several experiments with different reference scenarios discussed below indicate that cnn is successful in identifying the scenarios that are likely to contribute to the identified patterns in the feature extraction problem the above pumping experiment was repeated for 250 test cases 50 per scenario and the results are summarized in fig 9 on average in approximately 72 of the test cases the highest probability is assigned to the correct scenario dominating rate while in 92 8 of the cases the correct scenario was included in the solution surviving rate the dominating and surviving rates in the first iteration are 64 and 90 showing the additional improvement achieved through the iterative scheme however for scenarios with overlapping features straight and intersecting scenarios that have the same directionality these probabilities are lower indicating that they are harder to distinguish based on the extracted features in the flow data inversion problem in those cases the algorithm tends to promote and maintain the scenarios with overlapping features if they are supported by the data as a result the surviving rate is a more reliable measure of performance when scenarios have overlap 3 2 pumping test with 3d models to further evaluate the performance of the developed approach we consider 3d models that are adapted from the saigup geological formation howell et al 2008 the configuration of the pumping test is shown in fig 10 a the area under investigation has a dimension 750 m 2250 m 20 m which is divided into a 3d mesh with 40 120 40 cells a total of 12 evenly spaced observation wells are distributed throughout the aquifer the logarithm of hydraulic conductivity and pressure in the observation wells are measured with 10 measurement noise and used for screening the geologic scenarios the pumping rate is fixed at 9000 m 3 d a y an example of the facies distribution with four distinct facies types is shown in fig 10 b to account for the uncertainty in the conceptual geologic model eight scenarios with different aggradation angle and azimuth are considered as shown in fig 11 scenarios 1 2 3 and 4 have a low aggradation angle while the aggradation angles of scenarios 5 6 7 and 8 are high the azimuth of different scenarios are as follows scenarios 1 and 5 0 scenarios 2 and 6 45 scenario 3 and 7 90 and scenarios 4 and 8 135 the parasequence is 2 for all the scenarios the object based geological modeling package of petrel was used to generate the realizations for each of the scenarios in this example a total of 500 realizations from each scenario was generated with 400 realizations used for training 50 for validation and 50 as test cases a cnn model with 3d convolutional and pooling layers are built for feature recognition the details of the cnn model are summarized in table 2 the geological features are recovered through gradient based inversion as discussed in the methodology section since the scenarios share a similar level of variability the first 8 leading pcs from each scenario are included initially for the test case from scenario 8 shown in fig 10 b fig 12 shows that the reconstruction with the initial basis iteration 1 is far from the reference case however after one iteration cnn is able to identify the scenarios that have the correct azimuth scenarios 4 and 8 with azimuth 135 once the scenarios with incorrect azimuth are eliminated the existing spatial patterns are recovered more accurately enabling cnn to identify the correct scenario scenario 8 in later iterations the results from 400 test cases 50 test cases per scenario are shown in fig 13 the overall dominating and surviving rates across all scenarios are 82 5 and 86 5 showing the effectiveness of the workflow in recovering the geologic scenario from flow data in this case study to test the method we also considered a reference case that does not belong to any of the scenarios in this case the reference model has high aggregation angle and 0 azimuth same as scenario 5 but a parasequence of 6 fig 14 a fig 14 b shows that the parasequence isn t correctly extracted yz surface is very noisy because this feature isn t included in the training data but the azimuth and aggregation angle features that are included in the training dataset are extracted hence the two relevant scenarios scenario 5 and 1 are promoted with the closest scenario to the true scenario scenario 5 being assigned the highest likelihood 4 conclusion in this paper we present a workflow for screening geologic scenarios based on flow response data to reduce geologic uncertainty the proposed method is computationally efficient since only a small number of forward simulations are involved the presented workflow consists of two main components feature extraction and feature recognition the feature extraction step takes advantage of the discriminating power of very few leading pca elements to effectively extract the main features that are supported by data the feature recognition step leverages the pattern based classification power of cnn to provide feature based distances that can be used to distinguish between different geologic scenarios an iterative scheme is proposed to improve the accuracy of the method by gradually adapting the solution to the identified scenarios the proposed method is evaluated using aquifer pumping tests in non gaussian two dimensional models and a three dimensional case study the results over several hundred test cases involving two dimensional and three dimensional aquifers are used to show the effectiveness of inversion based feature extraction and cnn based feature recognition for screening geologic scenarios based on flow response data in most cases our workflow is able to extract the correct salient features from flow data and yields reliable predictions of relevant geologic scenarios in particular the robustness of cnn was evident in consistently identifying the geologic scenarios that could potentially contribute to the feature extraction solution even when such solutions did not uniquely capture the geologic features in conclusion the presented geologic screening method offers an efficient and flexible approach for reducing the uncertainty in geologic scenarios prior to performing model calibration the method takes advantage of the discriminating power of the leading pca elements from different geologic scenarios and uses the flow data in a gradient based workflow to construct a spatial map of aquifer hydraulic conductivity the constructed map does not include small scale details and is intended for scenario identification the extracted features indicate which spatial connectivity patterns can be used to reproduce the flow data the resulting map is then used in a trained cnn classifier to identify the geologic scenarios that are consistent with the extracted spatial patterns it is important to note that the workflow presented in this paper serves as a tool for geologists to include the information in pressure and flow data to reduce their uncertainty about plausible geologic scenarios in some cases the results from our method may be used to revise the proposed geologic scenarios or generate new geologic scenarios that were not included initially we note that the presented algorithm and the assumptions used in this paper are not intended for model calibration more elaborate probabilistic and deterministic model calibration methods exist in the literature that can use the selected geologic scenarios from our method to perform detailed model calibration finally one can generate cnn architectures that directly map flow data to geological scenarios in a single step however such a model would require a large number of flow simulation runs to generate the training data which is not practical the presented framework in this paper combines the efficiency of gradient based inversion with classification power of cnn for image data to accomplish this goal in a practical way credit authorship contribution statement anyue jiang data curation formal analysis investigation methodology software validation writing original draft behnam jafarpour conceptualization project administration supervision resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors acknowledge the financial support of energi simulation chair program for this project the flow simulations in this work were performed using the matlab reservoir simulation toolbox mrst the authors also thank syamil mohd razak for helping build the three dimensional case study for this work the python and matlab codes for the proposed method and experiments are available on https github com anyuej cnn ss 
345,subsurface flow model calibration against dynamic response data is often constrained by a prior conceptual model of geologic scenario that specifies the expected spatial variability and geologic patterns in the solution however several sources of uncertainty exist in developing a conceptual geological model including data limitation process based modeling assumptions and subjective interpretations therefore it is prudent to consider the uncertainty in geologic scenarios during model calibration and to utilize the flow response data in supporting or rejecting the proposed scenarios we present a novel framework whereby dynamic response data is used to screen a set of proposed geologic scenarios by combining gradient based inversion for feature extraction and convolutional neural networks for feature recognition to compactly represent the salient features of each scenario an extremely low rank parameterization with the leading elements of the principal components analysis pca is adopted the pca basis elements of different scenarios are combined to define the search space for feature extraction which is implemented via an iterative least squares inversion formulation to match the observed data the inversion solution is obtained by selectively combining the pca representations from different scenarios and contains the dominant spatial patterns that are needed to match the observed data feature recognition to identify the relevant geologic scenarios based on the reconstructed spatial solution of feature extraction inversion is performed using a pre trained convolutional neural network cnn the method offers several advantages including an efficient implementation that does not require extensive forward simulation runs use of flow data to identify pertinent geologic scenarios and the ability to combine geologic scenarios if supported by data the performance of the proposed approach is evaluated using numerical experiments from pumping tests in groundwater aquifers keywords model calibration geologic uncertainty geologic scenarios machine learning convolutional neural network 1 introduction calibration of subsurface flow models against monitoring and performance data is commonly used to improve the predictive capability of simulation models as a tool for decision making the resulting model calibration formulation often leads to ill posed inverse problems where limited data are used to estimate high dimensional parameters that represent heterogeneous rock property distributions parameterization and regularization are the typical approaches to solve underdetermined inverse problems parameterization is performed by finding a compact representation of the original parameters either in the spatial domain e g the zonation method jacquard et al 1965 and the pilot point method ramarao et al 1995 or in a transform domain the transform domain can be either learned from data e g principle component analysis wold et al 1987 sarma et al 2007 or it can be data independent e g discrete cosine transform ahmed et al 1974 recently deep learning approaches such as gan and vae have also been introduced as parameterization techniques laloy et al 2017 2018 canchumuni et al 2019 jiang and jafarpour 2020 mohd razak and jafarpour 2020b regularization on the other hand constrains the solution of an inverse problem by adding a penalty term that promotes user specified properties in the solution for example the tikhonov regularization tarantola 2006 stabilizes the inversion process by requiring the solution to be smooth and the total variation regularization rudin et al 1992 allows for detection of local discontinuity e g facies boundaries in the obtained solution parameterization and regularization techniques often serve two purposes making the inverse problem better posed mathematically and improving the plausibility of the obtained solution by incorporating the expected behavior of the solution e g preserving the geologic continuity traditionally a prior geologic scenario is used to regularize the problem by specifying the expected form of the spatial variability in subsurface properties strebelle 2002 caers and zhang 2004 the prior geologic scenario is usually derived from integrating different sources of knowledge koltermann and gorelick 1996 such as quantitative measurements e g hard data well logs seismic and qualitative data e g outcrops as well as geologic modeling techniques and expert knowledge baddeley et al 2004 conventional model calibration methods assume that a prior conceptual model of geologic scenario is known and must be respected while updating model parameters rock properties to match the observed response data however the assumption that the geologic scenario is known with certainty is not realistic as several sources of uncertainty and subjectivity are present in building such models bond et al 2007 mohd razak and jafarpour 2020a acknowledging and incorporating the uncertainty in conceptual geologic scenarios is therefore important for developing reliable workflows for forecasting model calibration optimization and uncertainty quantification christie et al 2005 li and jafarpour 2010 refsgaard et al 2012 linde et al 2015 on the other hand disregarding the uncertainty in the geologic scenario can result in models that can match the available flow response data but provide incorrect biased predictions therefore it is important to account for the uncertainty in the prior knowledge about the geologic scenario and to use dynamic response data in addition to other sources of information to reduce it khaninezhad and jafarpour 2014 golmohammadi and jafarpour 2016 screening of geologic scenarios based on flow response data is motivated by the need to on the one hand account for the uncertainty and subjectivity in developing conceptual geologic models and on the other hand reduce the uncertainty space by eliminating scenarios that cannot be supported by data one approach to represent the uncertainty in the geologic scenario is to consider multiple plausible conceptual models either based on alternative interpretations by different geologists or by stochastic treatment of process based models that are used to generate the scenarios when confronted with multiple scenarios in model calibration a basic approach is to perform individual calibration with each prior scenario to cover a wide range of variability and to evaluate the likelihood of the resulting solutions while the bayesian framework has been used to quantify the uncertainty when multiple geologic scenarios are present arnold et al 2019 demyanov et al 2019 encapsulating all the proposed scenarios within this framework can be computationally demanding an alternative approach is to reduce the uncertainty by developing formulations that use the available data to eliminate irrelevant or highly unlikely scenarios prior to detailed model calibration and uncertainty quantification this approach is consistent with the popper bayes philosophy that observations can only be used to falsify and not deduce models or theories tarantola 2006 or in our case geologic scenarios that are not supported by data suzuki et al 2006 park et al 2013 scheidt et al 2015 however in practical applications the computational cost of a rigorous and exhaustive falsification process can be prohibitive and more efficient and practical methods may become necessary a computationally less demanding approach is to formulate efficient inverse problems that use the available data to support or reject a set of proposed conceptual geological models khaninezhad and jafarpour 2014 golmohammadi and jafarpour 2016 or to extend model calibration formulations to include multiple plausible scenarios as prior knowledge khaninezhad et al 2012 khaninezhad and jafarpour 2014 regardless of the formulation used it is important to note that the models supported or selected based on available data may be rejected upon the availability of additional data in recent years advances in machine learning have resulted in the popularity and adoption of these techniques in several areas of science and engineering goodfellow et al 2014 arjovsky et al 2017 kingma and welling 2013 including subsurface modeling yu et al 2019 jiang and jafarpour 2019 laloy et al 2018 in particular convolutional neural network cnn has shown great promise for pattern learning and analysis especially when applied to images krizhevsky et al 2012 cnn can efficiently extract local features by scanning and convolving images with small filters that contain the parameters to be learned lecun et al 1998 inspired by the discovery of visual perception mechanism hubel and wiesel 1968 gu et al 2018 the architecture and training process of cnn was first established by lecun et al 1990 they invented a multi layer network called lenet 5 which was trained using the backpropagation algorithm hecht nielsen 1992 with access to a massive amount of data from the internet improvement in gpu and parallel computing convolutional neural network has achieved state of the art performance in many pattern recognition tasks e g natural language processing kim 2014 computer vision krizhevsky et al 2012 and speech recognition graves et al 2013 in this paper we present a new formulation for prior geologic scenario identification by inverting dynamic flow response data the method combines a gradient based feature extraction from flow data with a cnn classification model for feature recognition to identify geologic scenarios that are supported or rejected by the data the details of the developed approach are discussed in section 2 followed by numerical experiments and their discussion in section 3 2 methodology in this section we present the overall workflow and its individual components the inputs to the workflow are multiple plausible geologic scenarios with their corresponding realizations as well as the observed flow response data from the field the objective is to assign importance plausibility weights to each geologic scenario based on the observed flow response data the proposed workflow consists of an iterative implementation of two main steps i feature extraction by inversting the flow data and ii feature recognition using a cnn architecture a more elaborate workflow is shown in fig 1 in the feature extraction step of the workflow a spatial map of the desired property is reconstructed based on the provided geologic scenarios and flow response data by solving an inversion problem with an extremely low rank combined or hybrid parameterization approach the objective of the first step is to utilize the flow response data to extract the salient features from different scenarios that are included in the parameterization in the feature recognition step a pre trained convolutional neural network cnn predicts the relevant geologic scenarios based on the obtained spatial map from the inversion in the first step to further discriminate between the scenarios the composition of the hybrid parameterization is updated at the end of each iteration based on the recognized features by adjusting the number of principal components pcs from each scenario this is achieved by increasing the number of pcs from scenarios that have larger weights to help improve the quality of the reconstructed solution the detailed description of the feature extraction and feature recognition steps is presented next we note that while the feature extraction can also be performed as a regression problem using a cnn model such an approach would require a large number of labeled data where the labels have to be derived based on flow simulation making the process computationally very demanding 2 1 feature extraction using inversion with leading pca elements in the feature extraction step realizations from each geologic scenario are first used to construct very few leading elements of the principal component analysis pca that can be used to compactly represent the salient spatial patterns in the corresponding scenario these principal components for different scenarios are then put into a combined linear expansion to approximately represent a model from any geologic scenario note that the number of pcs should be small enough to avoid obtained detaled solution as the main goal is to approximately represent the global connectivity pattern in each scenario in otherwords the parameterization is not intended for full model calibration and is only used to provide distinguishing power for each scenarios by choosing very few leading pca elements it is ensured that the main spatial patterns from a given scenario can only be useful to approximate models pertaining to that scenario without the ability to represent realizations from other scenarios consequently the constructed parameterization with the combined pca elements possesses a strong discriminating property that is exploited in the formulation the resulting parameterization is used in an inversion formulation to allow for the scenarios to compete against each other in matching the observed data the inversion solution is obtained via an efficient gradient based iterative algorithm to formulate the inverse problem for feature extraction with flow response data we define the forward model that relates the data d m 1 to subsurface flow property distribution u n 1 e g rock permeability at each of the n grid cells in the model as 1 d obs g u where g is the nonlinear mapping from the parameter space to the data domain for example governing partial differential equations pdes for multi phase flow in porous media note that a geologic scenario refers to a conceptual model that can be used to generate many realizations samples and u represents one such sample our objective is to use flow data to identify geologic scenarios that are pertinent to this end a parameterization is needed to compactly represent the main geological features i e spatial patterns in each scenario that is instead of dealing with many samples pertaining to a given scenario a parametrization method is adopted to summarize the main features in the corresponding realizations a classical parameterization method to accomplish this objective is based on the pca representation denoting a set of l permeability model realizations from the geologic scenario s as u s u 1 u 1 u l s and the corresponding k dimensional pca basis as φ n k s k is the number of leading pca basis elements a sample u j s from this geologic scenario can have the following k term pca approximation 2 u j s i ϕ i s v j i s φ s v j s where v j s is the corresponding k dimensional vector of projected pca coefficients a similar parameterization can be obtained for each of the geologic scenarios assuming s proposed geologic scenarios one can obtain a set of s truncated pca bases i e φ 1 φ 2 φ s each providing approximate representation of any given sample from their respective scenario u j 1 u j 2 u j s with the corresponding coefficients v j 1 v j 2 v j s t by stacking the pca bases from different scenarios we obtain φ φ 1 φ 2 φ s which can be used to compactly represent a sample from any of the scenarios i e u j s φ s v j s however for compactness we use the combined stacked bases and the notation introduced above to write u j φ v j with this parameterization the feature extraction inversion solution can be obtained by minimizing the mismatch between the observed and predicted data 3 v a r g m i n v c d 1 2 d obs g φ v 2 2 where c d is the diagonal observation noise covariance aster et al 2018 some important remarks regarding this formulation are in order first the basis corresponding to each geologic scenario can include a different number of leading modes k depending on the complexity of the features in each scenario however if the basis for each geologic scenario has dimension n k the combined version φ will have dimension n k s second the formulation assumes that the geologic scenarios are reasonably far from each other and the number of leading pcs k is sufficiently small with these assumptions a model u j s i e from geologic scenario s is expected to have a similar representation in φ s and in the combined version φ that is the hypothesis is that in approximating a sample from a given geologic scenario large scale features that are contained in the leading pcs from other scenarios have little contribution in general this behavior diminishes with an increasing number of leading pcs k as discussed in the next section third by combining the pca bases from different geologic scenarios into a single representation the method is able to generate very diverse spatial features by mixing the basis elements from different scenarios the combined representation contains a rich set of spatial features that not only represent the dominant spatial pattern in each geologic scenarios but they can also be combined to represent spatial features consisting of the union of individual scenarios as a result it is possible for basis elements corresponding to more than one scenario to contribute to the solution this is an important advantage of the algorithm for practical applications where the correct geologic scenario is unknown and one single prior scenario may not be sufficient for describing the spatial features in the true field fourth in general the flow response data tend to show sensitivity to large scale variability in the permeability field therefore basis elements that preserve the large scale features are used to map the field global connectivity additionally using fewer parameters in the inversion leads to a better posed problem fifth although φ is expected to form a basis with linearly independent columns given the distinct nature of the scenarios the orthogonal property of the individual pca bases is lost after combining them this however only affects the inverse mapping finding v for a given u which is not needed in the formulation the nonlinear least squares problem in eq 3 can be solved to find v and hence the corresponding u φ v using a standard gradient based algorithm the gradients of the objective function with respect to the original property distribution u can be computed using efficient adjoint implementations given the linear form of the parameterization the chain rule of differentiation can be invoked to obtain the gradients with respect to the inversion parameters v the next step is to use the inversion solution v or u to identify which geologic scenarios are used in constructing the solution although this may appear to be a simple task it can prove to be quite challenging considering that the resulting inversion solution is expected to have low quality resolution and can include complex combined features as discussed in the next section to demonstrate the discriminating power of the leading pca basis fig 2 a shows an example with two simple scenarios of circle and bar objects the corresponding pca elements for each case are shown on the right side of fig 2 a the pca basis images in each case clearly show an order the leading modes have dominant large scale features corresponding to the shape of the objects in their respective prior models the non leading basis images e g no 100 do not carry any significant information about the underlying objects fig 2 b illustrates the best approximation in rmse sense of a sample circle image with eight leading basis images from each prior scenario and a combination of 8 circle and 8 bar basis images it is evident from these results that a circle image cannot be approximated by the leading pca basis of the bar images it is also clear that adding the leading bar basis images to those of the circle basis images does not provide a noticeable improvement in approximating the sample circle image this implies that if very few leading basis images from each prior scenario are included in the combined representation only the basis images corresponding to the objects present in the target sample will have a meaningful contribution to its approximation it is important to emphasize that this discriminating property diminishes as more non leading elements of the prior scenarios are included therefore in the developed formulation only very few leading pca basis elements from each prior geologic scenario are included in the combined parameterization to maintain the discriminating power of the feature extraction approach 2 2 feature recognition with cnn with the salient features extracted the next question is how to identify which scenarios the extracted features belong to in general the extracted features from the inversion problem are expected to contain inversion errors artifacts due to the limited data used moreover the solution may involve spatial patterns from more than one geologic scenario which can complicate the feature recognition geologic scenario selection problem many of the existing quantitative measures that are used to evaluate the similarity between images are less sensitive to spatial patterns and may not provide a robust metric for comparing the spatial features in images a seemingly natural choice for deciding about the relevant geologic scenarios after the inversion process can be based on the norm of the pca coefficients loadings of each scenario in the parameterized solution i e coefficients in v the expectation is that if a given scenario has a significant contribution the corresponding weights must be large however we found that this is not necessarily the case because two or more scenarios can have large coefficients while their net contribution is minimal that is they can cancel the effect of each other on the final spatial representation this issue can be avoided by applying a regularization penalty function such as group sparsity golmohammadi and jafarpour 2016 an alternative approach is to use the spatial solution u for feature recognition one way to accomplish this is by projecting the inversion solution u obtained by using the combined leading pca basis for all scenarios onto the leading pca basis of each individual geologic scenario to quantify the projection approximation error for each scenario in the absence of other scenarios e g using ℓ 2 norm of the projection residuals in this case the basis corresponding to the geologic scenario that has relevant features is expected to provide smaller projecting error while this method solves the issue encountered in the first approach we have observed that the projection errors of different scenarios can be quite similar when quantified through the second norm ℓ 2 of the residuals this is attributed to the fact that the ℓ 2 norm over pixel based differences between two images is not sensitive to structural similarity spatial patterns in them a pattern based method is therefore more appropriate for distinguishing images with different structural connectivity patterns in this paper we use convolutional neural network cnn as a powerful image classification method for this task a neural network nn consists of artificial neurons that use the input to change their internal state activation and generate a corresponding output that is effective in recognizing patterns neural networks are formed by connecting the output of certain neurons to the input of other neurons resulting in a directed weighted graph fig 3 left shows a simple nn consisting of an input layer two hidden layers and one output layer the mathematical operations associated with nns are elementary and typically include weighted combinations followed by applying nonlinear activation functions as shown in fig 3 right the use of nn involves two parts training and predicting in the training mode the training data a set of inputs and the corresponding label outputs is fed into the network the loss is calculated based on the difference between network predicted and true outputs then the weights in the network are adjusted to minimize the network prediction errors the minimization is implemented via gradient based backpropagation algorithms rumelhart et al 1986 for classification problems the weight assigned to each category is typically calculated by a softmax or normalized exponential function of the form 4 σ i z e z i k e z k the softmax function converts an arbitrary k dimensional vector z to a new k dimensional vector σ z with entries in the range 0 1 that sum to 1 this conversion assigns probability values to each output class dunne and campbell 1997 with the output of the softmax function representing the probability assigned to each class a compatible loss function for training a classification model is the cross entropy function dunne and campbell 1997 defined as 5 h p q x p x l o g q x where p and q are the true and predicted labels respectively the power of nn comes from stacking several layers and training the resulting network with abundant relevant data to learn the weights in fact nn can be viewed as a nonlinear regression or parameter estimation problem where the observed training data are used to estimate the parameters weights of the model network while stacking layers increases the complexity and power of nn it also results in a substantial increase in the number of parameters and nonlinearity especially in fully connected networks which can lead to diminishing gradient and overfitting issues a convolutional neural network contains convolutional layers in which several filters or kernels with learnable weights scan the input image and perform local convolution operations lecun et al 1989 1990 1995 1998 as shown in fig 4 top several filters are used to capture different spatial attributes of the input image each convolutional layer is typically followed by an activation function that operates on the convolution results and provides an output that indicates whether the node is active for the given input in this paper we use the rectified linear unit relu as the activation function the activation layer is followed by a pooling or down sampling layer which is designed to summarize the output information from each layer before passing to the next layer in addition to reducing the sze of the output from each layer the pooling operation changes the scale of the features that will be learned by the next set of filter resuling in each hidden layer representing a different level of abstraction typical pooling operations are average pooling replacing a subset of inputs with their average value and max pooling replacing a subset of inputs with their maximum value of which we use the latter in this paper fig 4 bottom illustrates these operations for a combined layer of cnn that includes the sequence of convolution relu pooling operations with a simple example showing the typical input output of each operation right to generate the output from cnn as a classification model as shown in fig 4 top the output of the final pooling step is flattened and the resulting outputs are connected to each of the s classes following a softmax transformation as a classification model with parameters θ cnn takes a set of labeled data as input and learns to predict the label geologic scenario associated with any new input image in our examples the input data consists of spatial maps of rock flow property distribution and the labels are the geologic scenarios once trained the cnn is used in feed forward mode to take as input the spatial map with geologic features extracted from flow inversion and compute the corresponding scenario label in practice cnn uses the softmax operation before the output layer to calculate the probability assigned to the corresponding plausible scenarios that is y θ x alternatively one could use a hard thresholding approach to convert the softmax outputs into discrete one hot vectors that provide hard labels if the number of geologic scenarios is s the output is represented as a one hot vector encoding y θ x r s where each column represents the likelihood of each sample to belong to a scenario during training the following cross entropy loss function is minimized by adjusting the weights 6 l z y θ i 0 s y i l o g σ z i 1 y i l o g 1 σ z i where σ is the sigmoid function and z is the data label the cross entropy loss corresponds to the kullback leibler divergence between the empirical distribution of the input data and the predicted distribution which is minimized during training compared to a fully connected netwrok cnn offers three main advantages 1 sparse connections by exploiting local patterns in images 2 shared weights by using the same filter across an entire input image resulting in translation equivariance and 3 pooling operation that leads to local shift invariance a convolutional layer performs local operations with small filter sizes followed by a pooling process which leads to the local shift invariance property of cnn and a significant reduction in the number of parameters unlike classical image processing methods where convolution filters are pre computed weights in the convolutional layers are learned from training data the learned filters are then applied to input images in the forward prediction mode to perform the desired analysis for example classification it is important to note that cnn usually contains both convolutional layers and fully connected layers in general the convolutional layers extract spatial features while the fully connected layers usually the last few layers serve as classification layers the convolutional layer is often followed by a pooling or down sampling layer to compactly represent the salient information in each kernel by replacing the convolution outputs with summary statistics either maximum values max pooling or mean values average pooling cnn architectures have achieved excellent performance in pattern recognition krizhevsky et al 2012 sharif razavian et al 2014 simonyan and zisserman 2014 the success of cnn can be partly attributed to the efficiency of its architecture for capturing local correlations patterns in natural images the drawbacks of cnn include the ad hoc nature of its design the number of tuning parameters involved and its black box nature that makes it difficult to explain its behavior and learning mechanism despite these limitations cnn has enjoyed great success in many applications and remains a growing field of research given the complexities associated with assigning geological scenarios based on extracted features in our workflow and the success of cnn in imaging applications for feature detection and classification we adopt cnn as an effective pattern based tool for feature recognition to predict the relevant geologic scenarios for a given input image construction of a cnn architecture requires tuning through a trial and error process where different design parameters are adjusted until acceptable performance in training validation and test data is achieved an important consideration in the design and training of neural networks is overfitting without regularization redundant weights and or limited training data can result in the networks showing great performance during the training stage but very poor performance on test cases prediction stage some common regularization techniques that are used to prevent overfitting includes weight decay krogh and hertz 1992 dropout srivastava et al 2014 and batch normalization ioffe and szegedy 2015 weight decay is equivalent to having a quadratic penalty term on the weights dropout improves overfitting by randomly dropping out neurons and fitting the training data with a subset of weights hence it imparts robustness on the trained network and can be viewed as an approximate ensemble learning framework although it was initially applied to fully connected layers more recently its application with cnn has been shown to be effective park and kwak 2016 batch normalization re centers and re scales data between layers although batch normalization and dropout are two of the most powerful regularization techniques recent results in the literature suggest that combining them can lead to performance degradation li et al 2019 in this study we use the combination of dropout and weight decay as the regularization approach for training the cnn although cnn has shown great performance for pattern learning in spatial images the interpretability of cnn is important for real world applications and design purposes the main aspects of the interpretability are the features learned in different parts of cnn and the features used for prediction i e attribution olah et al 2017 visualization tools such as grad cam can be used to understand the importance of different regions of the input image in predicting the output selvaraju et al 2017 another feature visualization tool is the activation maximization algorithm in which the objective is to find an input image that maximizes the activation of a specific neuron or filter in the network these visualization tools offer useful interpretations of the learned representations in cnn we used these methods in our work to gain insight into the design and tuning of the cnn architecture 2 3 training data in this work the input image for the feature recognition classification task is the solution of the corresponding feature extraction inverse problem which is estimated from incomplete flow data and involves inversion errors this implies that the input data for training cnn should also represent solutions of similar inverse problems while the output remains the correct label associated with each input however generating input data that represent the solution of an inverse problem is not practical as it requires solving an inverse problem per each training data as an approximation one may simply use as training data the exact representation of prior models and their corresponding scenario labels a better alternative is to use pca approximation of the original images to account for the parameterization error in the first step while the latter approach is consistent with the pca parameterization that is used in the feature extraction step it does not account for the errors and artifacts that are introduced during inversion to account for the inversion errors in the training data we added spatially correlated errors to the pca approximations of the original models input data for each scenario this was done by introducing leading pcs from other scenarios with random coefficients this approach is consistent with the intended application of cnn as the expected inversion solution artifacts are spanned by the hybrid pca parameterization that is used in feature extraction tensorflow abadi et al 2015 was used to build and train the cnn in our study for the examples presented in the next section the specific parameters of the cnn model are summarized in the corresponding tables 2 4 iterative workflow in the proposed workflow we assume that multiple realizations from each geologic scenario are available a cnn model is first designed and trained with these realizations the scenarios are then parameterized into pca components using their corresponding realizations initially the number of pca elements from each scenario in the hybrid basis k 0 k 0 1 k 0 2 k 0 3 k 0 s is selected to retain the same amount of cumulative energy variance for each scenario this approach accounts for the variability in the level of complexity across the scenarios e g straight and meandering channels to ensure that initially each scenario is represented with similar quality we note that the retained level of energy is one of the hyper parameters that depends on the complexity of the scenarios the similarity of the scenarios and the quality and quantity of the flow response data when the scenarios are distinct only a few leading pcs can provide significant distinguishing power the total number of pcs in the hybrid basis k is then fixed throughout the workflow with the initial hybrid basis the feature extraction step is performed and the solution is passed to cnn for geologic scenario selection the presence of multiple potentially irrelevant scenarios in the extracted features however may have an impact of the quality of the solution therefore in order to improve the accuracy of the algorithm we implement an adaptive algorithm by iteratively performing the two steps in the iterative formulation the number of pcs that are included from each scenario is scaled according to the weights assigned to that scenario during feature recognition with cnn at iteration i the spatial solution from the feature extraction step is based on a hybrid basis that has a composition k i with the pattern based probabilities p i p i 1 p i 2 p i 3 p i s assigned by cnn the new composition of the hybrid basis k i 1 is updated by linearly adjusting the number of corresponding pcs for each scenario we performed an extensive set of numerical experiments to evaluate the performance of this iterative approach in general two situations are commonly encountered a the flow response is sensitive to the significant features of each scenario and the hybrid basis is dominated by the correct scenario within one or two iterations and b data is insufficient to discriminate against the scenarios or a mixture of features from different scenarios remain in the solution after several iterations to deal with the latter situation a maximum number of iteration is set to terminate the algorithm 3 numerical experiments to test the performance of the developed workflow with nonlinear response data we apply it to several pumping test experiments involving single phase flow in two dimensional and three dimensional aquifers manzocchi et al 2008 howell et al 2008 we evaluate the performance of the method by computing a dominating rate as well as a surviving rate of the correct scenario the dominating rate refers to the fraction of solutions in which the correct scenario is considered as the most likely scenario by the workflow the surviving rate refers to the fraction of solutions in which the correct scenario is promoted by the workflow having a likelihood that is larger than 1 n s c e n a r i o where the n s c e n a r i o is the total number of scenarios 3 1 pumping test with non gaussian 2d models for the pumping test we consider non gaussian models with distinct alluvial channel patterns fig 5 the models have a dimension of 100 100 the geologic scenarios are defined based on the orientation and connectivity of the alluvial channel features these scenarios are derived from three training images with meandering intersecting and straight channels by changing the channel orientations two diagonal directions are used for the intersecting and straight channels two facies realizations are generated using the snesim algorithm caers and zhang 2004 implemented in s gems remy 2005 within facies heterogeneity is modeled using multi gaussian random fields the logarithm of hydraulic conductivity inside and outside the channels has a mean value of 0 6 and 2 4 respectively for each scenario a total of 500 realizations are generated of which 400 are used to construct the pca bases and to train the cnn model the remaining 100 models from each scenario are divided into two sets of 50 one used for validation to tune the hyper parameters and the other for testing the performance of the algorithm general information about the architecture of the cnn model is listed in table 1 the relu is used as the activation layer for the convolutional and fully connected layers dropout is added before relu in the convolutional layers for training the spatial models are approximated with a pca basis that contains 80 energy and contain both correlated and uncorrelated noise as shown in fig 6 we set up an aquifer pumping test where a pumping well is extracting water at a constant rate and the distribution of the logarithm of hydraulic conductivity is unknown the unit of hydraulic conductivity is c m s while the non gaussian models are used as the distribution of log hydraulic conductivity the configuration of the pumping test is shown in fig 7 a the aquifer has a dimension of 1000 m 1000 m 10 m the top and the bottom of the domain are no flow boundaries the pressures at the left and right boundary are 20 m and 10 m respectively the porosity in the domain has a constant value of 0 36 the background water flow due to the pressure difference in the field is from left to right the pumping rate is 3000 m 3 d a y a total of 36 monitoring wells are uniformly placed in the aquifer where the log hydraulic conductivity and pressure head are observed neglecting diffusion and dispersion chen et al 2006 the governing equations mass conservation and darcy s law are expressed as 7 ϕ ρ t ρ v q 8 v 1 μ k p ρ g z where ϕ ρ t v q μ k and p are porosity density time velocity source term viscosity and pressure respectively the feature extraction is implemented using gradient based inversion as discussed in the methodology section one of the test cases from scenario 1 is shown in fig 7 b since scenario 1 meandering channel has significantly more variability than the other scenarios the initial hybrid basis has more elements from this scenario initially the basis elements represent an equal amount of variance or energy from each scenario fig 7 d shows the details of the solution iterations in the first iteration the recovered solution shows disconnected channel features because the pcs from several geologic scenarios are included however cnn is able to recognize the meandering feature and increases the weight assigned to the correct scenario the next iterations only confirm the relevance of the scenario with meandering channels and identify it as the dominant scenario it is important to note that the main objective of the pca based parameterization is to screen the geologic scenarios using extremely low rank approximations once the geologic scenario is identified existing model calibration methods for non gaussian problems can be adopted to obtain more detailed calibrated models khodabakhshi and jafarpour 2011 in fig 8 a failed test case from scenario 1 is illustrated in this case the reference model fig 8 b has both meandering and intersecting channel features the center plots in fig 8 d show that the recovered solution also contains features that can be identified as intersecting channels with some meandering patterns therefore the intersecting scenario scenario 3 is assigned the highest probability and the correct scenario scenario 1 is identified with a lower likelihood given the south east to north west orientation of the identified features cnn also assigns a small probability to scenario 5 the results from several experiments with different reference scenarios discussed below indicate that cnn is successful in identifying the scenarios that are likely to contribute to the identified patterns in the feature extraction problem the above pumping experiment was repeated for 250 test cases 50 per scenario and the results are summarized in fig 9 on average in approximately 72 of the test cases the highest probability is assigned to the correct scenario dominating rate while in 92 8 of the cases the correct scenario was included in the solution surviving rate the dominating and surviving rates in the first iteration are 64 and 90 showing the additional improvement achieved through the iterative scheme however for scenarios with overlapping features straight and intersecting scenarios that have the same directionality these probabilities are lower indicating that they are harder to distinguish based on the extracted features in the flow data inversion problem in those cases the algorithm tends to promote and maintain the scenarios with overlapping features if they are supported by the data as a result the surviving rate is a more reliable measure of performance when scenarios have overlap 3 2 pumping test with 3d models to further evaluate the performance of the developed approach we consider 3d models that are adapted from the saigup geological formation howell et al 2008 the configuration of the pumping test is shown in fig 10 a the area under investigation has a dimension 750 m 2250 m 20 m which is divided into a 3d mesh with 40 120 40 cells a total of 12 evenly spaced observation wells are distributed throughout the aquifer the logarithm of hydraulic conductivity and pressure in the observation wells are measured with 10 measurement noise and used for screening the geologic scenarios the pumping rate is fixed at 9000 m 3 d a y an example of the facies distribution with four distinct facies types is shown in fig 10 b to account for the uncertainty in the conceptual geologic model eight scenarios with different aggradation angle and azimuth are considered as shown in fig 11 scenarios 1 2 3 and 4 have a low aggradation angle while the aggradation angles of scenarios 5 6 7 and 8 are high the azimuth of different scenarios are as follows scenarios 1 and 5 0 scenarios 2 and 6 45 scenario 3 and 7 90 and scenarios 4 and 8 135 the parasequence is 2 for all the scenarios the object based geological modeling package of petrel was used to generate the realizations for each of the scenarios in this example a total of 500 realizations from each scenario was generated with 400 realizations used for training 50 for validation and 50 as test cases a cnn model with 3d convolutional and pooling layers are built for feature recognition the details of the cnn model are summarized in table 2 the geological features are recovered through gradient based inversion as discussed in the methodology section since the scenarios share a similar level of variability the first 8 leading pcs from each scenario are included initially for the test case from scenario 8 shown in fig 10 b fig 12 shows that the reconstruction with the initial basis iteration 1 is far from the reference case however after one iteration cnn is able to identify the scenarios that have the correct azimuth scenarios 4 and 8 with azimuth 135 once the scenarios with incorrect azimuth are eliminated the existing spatial patterns are recovered more accurately enabling cnn to identify the correct scenario scenario 8 in later iterations the results from 400 test cases 50 test cases per scenario are shown in fig 13 the overall dominating and surviving rates across all scenarios are 82 5 and 86 5 showing the effectiveness of the workflow in recovering the geologic scenario from flow data in this case study to test the method we also considered a reference case that does not belong to any of the scenarios in this case the reference model has high aggregation angle and 0 azimuth same as scenario 5 but a parasequence of 6 fig 14 a fig 14 b shows that the parasequence isn t correctly extracted yz surface is very noisy because this feature isn t included in the training data but the azimuth and aggregation angle features that are included in the training dataset are extracted hence the two relevant scenarios scenario 5 and 1 are promoted with the closest scenario to the true scenario scenario 5 being assigned the highest likelihood 4 conclusion in this paper we present a workflow for screening geologic scenarios based on flow response data to reduce geologic uncertainty the proposed method is computationally efficient since only a small number of forward simulations are involved the presented workflow consists of two main components feature extraction and feature recognition the feature extraction step takes advantage of the discriminating power of very few leading pca elements to effectively extract the main features that are supported by data the feature recognition step leverages the pattern based classification power of cnn to provide feature based distances that can be used to distinguish between different geologic scenarios an iterative scheme is proposed to improve the accuracy of the method by gradually adapting the solution to the identified scenarios the proposed method is evaluated using aquifer pumping tests in non gaussian two dimensional models and a three dimensional case study the results over several hundred test cases involving two dimensional and three dimensional aquifers are used to show the effectiveness of inversion based feature extraction and cnn based feature recognition for screening geologic scenarios based on flow response data in most cases our workflow is able to extract the correct salient features from flow data and yields reliable predictions of relevant geologic scenarios in particular the robustness of cnn was evident in consistently identifying the geologic scenarios that could potentially contribute to the feature extraction solution even when such solutions did not uniquely capture the geologic features in conclusion the presented geologic screening method offers an efficient and flexible approach for reducing the uncertainty in geologic scenarios prior to performing model calibration the method takes advantage of the discriminating power of the leading pca elements from different geologic scenarios and uses the flow data in a gradient based workflow to construct a spatial map of aquifer hydraulic conductivity the constructed map does not include small scale details and is intended for scenario identification the extracted features indicate which spatial connectivity patterns can be used to reproduce the flow data the resulting map is then used in a trained cnn classifier to identify the geologic scenarios that are consistent with the extracted spatial patterns it is important to note that the workflow presented in this paper serves as a tool for geologists to include the information in pressure and flow data to reduce their uncertainty about plausible geologic scenarios in some cases the results from our method may be used to revise the proposed geologic scenarios or generate new geologic scenarios that were not included initially we note that the presented algorithm and the assumptions used in this paper are not intended for model calibration more elaborate probabilistic and deterministic model calibration methods exist in the literature that can use the selected geologic scenarios from our method to perform detailed model calibration finally one can generate cnn architectures that directly map flow data to geological scenarios in a single step however such a model would require a large number of flow simulation runs to generate the training data which is not practical the presented framework in this paper combines the efficiency of gradient based inversion with classification power of cnn for image data to accomplish this goal in a practical way credit authorship contribution statement anyue jiang data curation formal analysis investigation methodology software validation writing original draft behnam jafarpour conceptualization project administration supervision resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgement the authors acknowledge the financial support of energi simulation chair program for this project the flow simulations in this work were performed using the matlab reservoir simulation toolbox mrst the authors also thank syamil mohd razak for helping build the three dimensional case study for this work the python and matlab codes for the proposed method and experiments are available on https github com anyuej cnn ss 
346,groundwater plays a major role in human adaptation and ecological sustainability against climate variability by providing global water and food security in the indus ganges brahmaputra meghna aquifers igbm groundwater abstraction has been reported to be one of the primary contributors to groundwater storage variability however there is still a lack of understanding on the relative influence of climate and abstraction on groundwater data guided statistical studies are reported to be crucial in understanding the human natural complex system here we attributed the long term 1985 2015 impact of local precipitation global climate cycles and human influence on multi depth groundwater levels n 6753 in the igbm using lag correlation analysis wavelet coherence analysis and regression based dominance analysis our findings highlight the variable patterns of phase lags observed between multi depth groundwater levels and precipitation depending on the different nature of climatic and anthropogenic drivers in different parts of the basin we observed intuitive responses i e rapid response in shallow groundwater and relatively delayed responses to the global climate patterns with increasing depth however in the most exploited areas the hydrological processes governing the groundwater recharge are overwhelmed by unsustainable groundwater abstraction thus decoupling the hydro climatic continuum our results also suggest groundwater abstraction to be the dominant influence in most of the basin particularly at the greater depth of the aquifer thus highlighting the importance of understanding multi depth groundwater dynamics for future groundwater management and policy interventions keywords multi depth groundwater level climate variability anthropogenic influences data guided methods transboundary indus ganges brahmaputra meghna basin 1 introduction the indus ganges brahmaputra meghna igbm river system is one of the largest transboundary basin aquifer systems across the world macdonald et al 2016 mukherjee 2018 this highly yielding aquifer system fig 1 a was formed from the sediments eroded by the himalayas and redistributed by these mega rivers across south asia mukherjee et al 2015 mukherjee 2018 this basin has one of the highest irrigation water demands and very high population density richey et al 2015 the basin contributes almost 25 of the global groundwater abstraction 205 km3 year macdonald et al 2016 about 80 of total precipitation in india and bangladesh occur in june july august september through indian summer monsoon mukherjee et al 2015 paul et al 2016 however in northwest india mostly indus basin in the study area 15 20 of the total rainfall occurs due to the indian winter monsoon yadav et al 2009 during december january and february by western disturbance which is the eastward propagating cyclones scott et al 2019 recent studies mukherjee et al 2007 macdonald et al 2016 asoka et al 2017 bhanja et al 2017a 2017b 2019 bhanja and mukherjee 2019 disagree on the triggers for groundwater storage changes and recharge patterns across south asia while some studies asoka et al 2017 have argued that the precipitation patterns are the primary influencing factor for groundwater level gwl changes across the indian subcontinent other studies on this topic mukherjee et al 2007 macdonald et al 2016 bhanja et al 2017a 2017b 2019 suggest that even in areas demonstrating increased precipitation and primary secondary recharge enhanced depletion of groundwater storage are observed which is potentially caused by intensive groundwater abstraction rodell et al 2009 wada et al 2010 gleeson et al 2012 döll et al 2014 bhanja et al 2019 bhanja and mukherjee 2019 furthermore the groundwater regime may also be influenced by the seepage from natural surface water bodies mukherjee et al 2018 canals macdonald et al 2016 irrigation return flows bhanja et al 2019 and groundwater policy interventions bhanja et al 2017a leakages from the distributor canals are significant for the indus 59 000 km of canal network and the ganges aquifer system 25 000 km of canal network macdonald et al 2015 constituting a major portion of recharge in the drier parts macdonald et al 2016 although the local scale groundwater withdrawals for public and private water supplies in the urban areas are minor compared to the irrigational abstractions macdonald et al 2015 it can be the potential driver for rapid gwl decline locally macdonald et al 2016 earlier studies stressed on the inter annual dhanya and kumar 2009 to multi decadal climate variability affecting the different components of the hydrologic cycle scanlon et al 2005 through changes in the precipitation pattern streamflow snow and drought occurrence mccabe et al 2004 vicente serrano et al 2011 moreover interplay within the different forms of climate variability partially controls the gwl change and recharge rates gurdak et al 2007 tremblay et al 2011 perez valdivia et al 2012 the el niño southern oscillation enso and indian ocean sea surface temperature directly influence the precipitation seasonality in the indo gangetic plain sahany et al 2018 a study reports that drought variability in india is primarily impacted by enso kumar et al 2013 furthermore the pacific decadal oscillations pdo modifies the relationship between enso and the indian monsoon by a mechanism involving equatorial pacific and indian ocean krishnamurthy and krishnamurthy 2014 eventually affecting the groundwater systems in the basin another study shows that the short period heavy to moderate intensity rainfall events have a higher contribution to the total seasonal rainfall than the short period low intensity to long period moderate rainfall events in india dash et al 2011 significantly contributing to the groundwater recharge taylor et al 2013 the global climate patterns considerably influence the rainfall patterns and intensities at various scales and degrees krishnaswamy et al 2015 xavier et al 2018 rathinasamy et al 2019 the uncontrolled groundwater pumping for food production is further instigated by subsidized low electricity rates harvey et al 2002 shah 2009 mukherjee et al 2015 barik et al 2016 additionally groundwater pumping may also increase the leakage from canals affecting groundwater recharge ò dochartaigh et al 2019 land surface models that have been used to estimate groundwater depletion wada et al 2010 doll et al 2014 or gwl decline de graaf et al 2019 may also be used to separate the effects of groundwater abstraction and climate variability on gwls however the modern advanced land surface models have limitations in considering these irrigation practices barik et al 2016 a recent comparative analysis between global models and gravity recovery and climate experiment grace derived water storage trends show that the models underestimate the water storage trends relative to grace reflecting the effects of water withdrawals for irrigation and climate variations scanlon et al 2018 thus it becomes difficult to isolate the effect of human induced components in the human natural complex system due to the large grid size of grace and global models scanlon et al 2018 furthermore regional groundwater flow models mukherjee et al 2007 michael and voss 2009a 2009b de graaf et al 2019 of the region also provides critical insights on the human natural complex hydrologic systems however the disadvantage would be that it requires the hydrogeological setup of the aquifer system which may be difficult to obtain therefore data guided statistical approaches involving a dense network of monitoring wells could serve as useful tools to understand the system where the state of the art models have restrictions in doing so for example using a statistical approach thomas and famiglietti 2019 showed that the precipitation and groundwater recharge exhibit greater influence than groundwater pumping across the united states and linked this to climate induced groundwater depletion the trade off between climate and groundwater abstraction is critical for the security and sustainability of the climate water energy food nexus following the lack of agreement on the relative importance of drivers in previous studies in this large basin aquifer system we revisited the subject matter with a focused attempt to attribute the effect of natural and anthropogenic triggers on groundwater by a hypothesis guided approach our hypothesis is that while intuitive responses of groundwater to climate variability may be captured in the natural system without human interventions pervasive human interference involving groundwater pumping may cause alteration in the natural dynamics leading to non intuitive differential responses depending on the abstraction pattern and hydro stratigraphy it should be noted that here intuitive responses signify the hydraulically expected responses i e rapid response in shallow groundwater and relatively delayed responses to the climate with increasing depth despite well recognized previous studies examining the relationship between primary drivers and groundwater our study focuses on the multi depth aspect of groundwater characterization for the first time in terms of climate and abstraction on this critical aquifer system it provides an understanding on how the gwls at different depths of the aquifer respond to groundwater abstraction and climate to evaluate our hypothesis here we present a data driven statistical approach to determine the influence of climate via local precipitation and global climate cycles on groundwater levels under the effect of groundwater abstraction with new information on the intake depths of the observation wells in the parts of the indus ganges brahmaputra meghna igbm basin and sub basins for the last three decades we used lag correlation analysis wavelet analysis and dominance analysis as our tools based on its wide uses by previous researchers grinsted et al 2004 kuss and gurdak 2014 russo and lall 2017 velasco et al 2017 thomas and famiglietti 2019 and rigorous statistical insights the lag correlation is an efficient tool to assess the strength of the connections between time series variables at different time shifts wavelet coherence is used as a tool to decompose the time series signals while preserving the spatial or chronological information chavez and cazelles 2019 see si s1 the multiple linear regression based dominance analysis is employed since it provides a rigorous and quantitative description on the influence of climate and abstraction on groundwater 2 materials and methods 2 1 data treatment 2 1 1 groundwater level measurements we used 31 years 1985 2015 of groundwater level gwl data from 13 646 monitoring wells with intake depths ranging from 3 m to 500 m the data is assembled from various sources table s1 the water level data for india is in quarterly structure which is the monthly monitoring data for january late post monsoon may pre monsoon august monsoon and november early post monsoon however the gwl data for bangladesh is in the weekly format which was then converted to the quarterly format by taking the average values of the weekly data for january may august and november to maintain continuity within the datasets the gwl datasets used in the study show a wide range of continuity frequency and time intervals we have imposed tukey s method tukey 1977 bhanja et al 2017a to remove the noise and outliers from the raw dataset these quarterly gwl datasets figure s1 s2 s3 s4 were converted to yearly gwl time series figs 2 s1 s2 s3 s4 s5 by taking the average values of the quarterly data the annual minimum average and maximum groundwater levels map between 1985 and 2015 from the whole igbm and each of the sub basins are shown in figure s6 furthermore when yearly gwls are calculated only those yearly data were considered having a minimum of three seasonal data out of four records each year our selection criteria for the final observation wells of yearly averaged gwl time series required a minimum of 10 yearly observation points out of 31 for 31 years a detailed flow chart of the filtering and processing methods of the gwl dataset is shown in figure s7 after the post processing and the application of these additional filters the count of usable observation wells has reduced to 6753 for further analysis figure s8a the missing values in these time series records were interpolated with splines russo and lall 2017 for each of the observation wells gwls were normalized by calculating the gwl anomaly by subtracting the long term 1985 2015 mean gwl depth from the actual gwl depth bhanja et al 2017a to understand the response of climate at different depth in the aquifer the observation wells were classified by their intake depths sh shallow wells intake depth 35 m n 5546 im intermediate wells intake depth 35 70 m n 685 dp deep wells intake depth 70 m n 522 the depth classes sh im dp are classified based on the dominant abstraction depths for irrigation practiced in the region minor irrigation 2017 the observation well numbers reduced significantly with increasing intake depths figure s8b the mean count of observation wells for all the depth categories in the basin and sub basins are provided in table s2 we also note that most of the observation wells in the region are reported to be unconfined in type central ground water board cgwb 2014a 2 1 2 climate data treatment the gridded precipitation data used in this study are assembled from various sources for india and bangladesh table s1 we calculated the average precipitation for the basin and sub basins by averaging the precipitation time series of the grids 0 25 0 25 for india 0 5 0 5 for bangladesh that lie in the respective basins and sub basins the monthly multivariate enso index mei cycle 2 to 7 year the pacific decadal oscillation index pdo cycle 15 to 30 year the indian ocean dipole mode index dmi cycle 2 to 3 years the north atlantic oscillation index nao cycle 3 to 6 year 8 to 10 year data figure s9 were obtained from national oceanic and atmospheric administration noaa 2018 the yearly average from monthly data of each climate index mei pdo nao and nao were calculated and used for further analysis in general the observed anomalies in sea level pressure sea surface temperature wind speed fluctuation in earth s orbit geo potential heights ghil 2002 at multiple locations on the planet were processed to create the climatic indices for different modes of climate variability velasco et al 2017 2 1 3 groundwater abstraction data we have developed a groundwater abstraction map for the year 2013 in million cubic meters mcm for the entire igbm basin by combining datasets from various sources table s1 s1a for india district level groundwater abstraction data were collected from the dynamic ground water resources of india by central ground water board cgwb 2017 for bangladesh the groundwater abstraction map was derived from data local and published datasets aquastat 2018a badc 2013 2020 table s1 s1a the yearly groundwater abstraction figure s10 were calculated mukherjee et al 2007 bhanja et al 2017a using pumping well numbers n for irrigation purposes minor irrigation 1993 2001 2005 2014 2017 badc 2013 2020 pumping rate r and yearly duration t zahid et al 2006 minor irrigation 2014 2017 qureshi et al 2014 and combined and compared with published estimates central ground water board cgwb 2006 central ground water board cgwb 2011 central ground water board cgwb 2014b central ground water board cgwb 2017 central ground water board cgwb 2019 aquastat 2018b qureshi et al 2014 from several datasets table s1 s1a for the basin and each of the sub basins the yearly groundwater abstraction q of the basin and sub basins are computed mukherjee et al 2007 bhanja et al 2017a with the following equation 1 q n r t 2 2 statistical methods 2 2 1 lag correlation lag correlation analysis is performed predominantly when a variable or forcing has some delayed effect on a system kuss and gurdak 2014 velasco et al 2017 we have estimated the lag correlation between precipitation xt and groundwater levels yt with the help of the cross correlation function rxy k to investigate the phase shift the function provides knowledge on the causal relationships or relationships without attribution of a cause between the two time series larocque et al 1998 tirogo et al 2016 and is not necessarily symmetrical rxy k ryx k for k 0 2 r x y k c x y k σ x σ y 3 c x y k 1 n i 1 n k x t x y t k y here cxy k is the cross correlogram k is the time lag k 0 1 n the duration of the time series is denoted as n x y and σx σy are the mean and standard deviation of the precipitation and gwls respectively in equations 1 and 2 if k 0 y replaces x and vice versa if k 0 then it indicates that x and y signals respond to a third independent signal at the same time larocque et al 1998 in the complicated dynamic hydrological system lag correlation analysis may provide crucial information on the regional hydrogeology and the anthropogenic stress on groundwater daily gridded precipitation data were retrieved from different sources for the period 1985 2015 table s1 afterward yearly total precipitation was calculated for the entire igbm basin and sub basins we used the lag correlation analysis to estimate the correlation coefficient between gwls basin wide averaged yearly averaged time series and precipitation basin averaged yearly averaged time series for lag values from 1 to 16 years in the study area hence the analysis provides a single value of lag correlation coefficient corresponding to each lag years for the different well depth categories for the lack of prior study in the basin and from a statistical point of view since we have used a total of 31 years of yearly gwl data we have considered a maximum possible 16 years lag period with a 95 confidence interval here we present the lag correlation coefficients with their corresponding phase lags in years zero lag indicates less than 12 months of lag between precipitation and gwls the lag analysis was conducted using eviews v 9 statistical software 2 2 2 dominance analysis the dominance analysis provides the relative importance of the influencing variables by computing the coefficient of determination r2 in multiple linear regression azen and budescu 2006 here we performed conditional dominance of the variable for p 1 sub models where p is the numeric value of total sub models budescu 1993 thomas and famiglietti 2019 the yearly groundwater abstraction figure s10 precipitation fig 2 enso pdo nao and iod figure s9 for the basin and each sub basins were considered as the predictor variables to understand their influence with the outcome variable gwls i e yearly averaged basin averaged time series for all depth categories a more detailed description of the dominance analysis can be found in azen and budescu 2006 and budescu 1993 the dominance analysis was conducted using rstudio v 1 2 5001 software 2 3 numerical computation 2 3 1 principal component analysis pca the groundwater level data used in this study are obtained from a dense network of monitoring wells in the igbm basin we used a multivariate statistical method principal component analysis pca on water level data to reduce the size of the dataset extract only the essential information simplify the structure of the dataset wold et al 1987 and search for uncorrelated components that reflect the true nature of the groundwater level data tirogo et al 2016 pca is a commonly used approach that decreases the dimensionality of the datasets however it holds the greater part of the varieties for more comfortable data exploration zahra et al 2014 chang et al 2017 these components are the linear combinations of the primary variables suppose there are n individuals each characterized by p variables firstly a correlation matrix is generated by the pca then the total variance of all the pairs n p is projected on the imaginary factorial planes fi i 1 2 n tirogo et al 2016 each factorial axis represents each of the principal components we used the first principal component which corresponds to the first factorial plane that accounts for the largest variability possible detailed descriptions of principal component analysis can be found in abdi and williams 2010 and gangopadhyay et al 2001 2 3 2 wavelet coherence analysis statistically non stationary hydrological time series may exhibit variations in periodic signals over the long term period by altering its frequency and amplitude mitra et al 2014 these complex time series and periodic signals can be analyzed with the wavelet analysis the purpose of the wavelet analysis is to decompose the time series signal into a frequency component using wavelets these wavelets are waves that travel forward or backward temporally for a range of defined periods holman et al 2011 here the product of the analysis wavelet coherence is equivalent to the localized coefficient of correlation in the time frequency domain labat et al 2000 grinsted et al 2004 wavelet analysis can offer crucial insights into the variations of the power of climate groundwater teleconnections with time holman et al 2011 in this study the association between groundwater and climatic teleconnections was surveyed through bivariate wavelet analysis utilizing the morlet wavelet function mitra et al 2014 russo and lall 2017 the morlet wavelet function accommodates a good balance between frequency domain and time domain grinsted et al 2004 for dimensionless frequency ω0 and dimensionless time η the morlet function is defined as 4 ψ 0 n π 1 4 e i ω 0 η e 1 2 η 2 additionally ward s agglomerative hierarchical clustering was employed on the yearly gwl time series for all the observation wells to carry out wavelet cluster analysis murtagh and legendre 2014 russo and lall 2017 the selection of the number of clusters was determined with the parsimony coefficient rousseeuw 1987 russo and lall 2017 this method was applied to identify the clusters with similar frequency amplitude behaviors the number of clusters in all the basin and sub basin ranges from 2 to 4 for all the depth categories next using the first principal component obtained from wavelet cluster analysis and using climate indices we performed cross wavelet transform to analyze the cross wavelet power between them and classify the region of differential powers kuss and gurdak 2014 in the wavelet coherence spectrum essential features are recognized at a 5 significant level using the monte carlo method with 1000 random synthetic series newman et al 2003 grinsted et al 2004 holman et al 2011 kuss and gurdak 2014 this represents coherence at a 95 confidence level between the hydrologic and climatic variables in the wavelet spectrum the edge effect occurs close to the edge of the time series chavez and cazelles 2019 thus a cone of influence is introduced within which the edge effects become important torrence and compo 1998 grinsted et al 2004 schulte 2016 and the region outside the cone of influence is not affected by the edge effect chavez and cazelles 2019 it should be noted that wavelet coherence bands that lie inside the cone of influence cannot be evaluated reliably because of the edge effects russo et al 2014 in the power spectrum the spectral coherence is identified even if the coherence is of low power in the time frequency domain the wavelet coherence wtc measures the cross correlation as a number between 0 and 1 between the two time series as a function of frequency detailed descriptions of the entire process can be found in kuss and gurdak 2014 and grinsted et al 2004 to summarize for the gwl time series the first principal component in each of the clusters in all the basin and sub basin was used with the climatic indices mei pdo index nao index dmi to generate wavelet cross spectrum and wavelet coherence wtc torrence and compo 1998 russo and lall 2017 more information regarding the application of wavelet analysis is discussed in the supplementary information si s1 the wavelet analysis was conducted using matlab v 2018b software 2 4 assumptions limitations and uncertainty gwl data from the different government agencies are not continuous several missing data with varying frequency and length which leads us to use the maximum possible data range 1985 2015 based on the availability of data in the basin also the gwl data for india and bangladesh are of a different time interval which was converted to the same interval to maintain consistency within the datasets the gridded datasets for precipitation were used from cru ts 0 5 0 5 and imd 0 25 0 25 table s1 these datasets are smoothed products from observed point data and have limitations in capturing hydro climatic extremes in this study we have not considered the parts of the indus basin in pakistan due to data inaccessibility the deeper im and dp wells particularly are not evenly distributed and biased towards a few sub basins than others table s3 s4 few of the deeper gwl datasets used in the study are clustered towards the urban areas and can be locally influenced by the groundwater withdrawals for public and private water supply moreover few of the observation wells in the basin lies in close proximity to each other and may show and reinforce similar seasonal patterns the bias due to observation wells lying close to each other is not considered in the analysis to get a satisfactory data coverage of the deeper observation wells we needed to adopt a filtering criteria of selecting those observation wells having a minimum of 10 out of 31 yearly gwl data points the influence of canal leakage which is significant in some parts of the basin was discussed based on previous literature and our understanding on the subject matter as quantitative analysis could not be performed due to the paucity of data the groundwater response signal even at a depth of the aquifer due to the mass loading effect coupled with the compressibility of the confined aquifer maliva et al 2011 was not analyzed in the study due to data unavailability the quantification of the deeper groundwater flow is out of the scope of this study 3 results 3 1 lag based relationship between precipitation and groundwater the annual precipitation in the basin varies significantly with the lowest occurring in the indus sub basin mean precipitation 590 mm year and the highest in the meghna sub basin mean precipitation 2560 mm year fig 1c table s5 in general the basin averaged yearly averaged gwls in the indus basin is the deepest whereas shallower gwls are observed in the brahmaputra basin and meghna basin and these gwls deepen with the depth of the observation wells for the sub basins i e indus ganges fig 2 the lowest precipitation is observed in the indus basin and the highest in the brahmaputra and meghna basins fig 2 the basin averaged yearly averaged time series for gwl and precipitation in the whole igbm show a similar pattern with the ganges basin fig 2 due to the presence of the majority of land area 78 and the observation wells 80 in the ganges basin table s2 s3 respectively we applied lag correlation analysis using the basin and sub basin averaged yearly averaged time series of gwls in the observation wells sh im and dp and precipitation to explore the lagged relationship between them at the basin to sub basin scale the results based on igbm basin scale observations suggest that the correlation is maximum for the same year 0 year lag ravg 0 47 p 0 01 and for the previous year 1 year lag ravg 0 45 p 0 01 table s6 fig 3 a the gwls in the shs have little correlation ravg 0 13 with lag 1 year the dps also show a relatively highest correlation at lower lag values 0 and 1 year lag ravg 0 43 p 0 01 the dps have intake depths 70 m at that depth the possibility of the occurrence of one or multiple confining layers is greater therefore for dps the direct vertical meteoric infiltrated water contributing to groundwater recharge is restricted and attenuated by the hydrostratigraphic confining layers groundwater recharge in the aforementioned scenario depends upon the hydraulic properties and physical extent of the confining layers recent studies emphasized on the increased vertical recharge in deeper sites induced by pumping and landuse lapworth et al 2015 macdonald et al 2016 this pumping induced accelerated recharge could be linked to the higher correlation at lower lag years in the deeper sites the mass loading effects of the aquifer due to mechanical loading by the precipitation tidal surface flooding and few other hydrologic processes of terrestrial water and subsequent poroelastic response could be a relevant process in changing the water levels in the study area burgess et al 2017 particularly in the deeper sites ravenscroft et al 2018 the mass loading could be related to the consistent higher correlation at lower lag years in the deeper observation wells however the mass loading effect on the water level is at an intra annual i e even at a daily to sub monthly scale whereas the scale of observation we are trying to measure is annual to decadal the influence of mass loading on groundwater level change is difficult to study based on current data availability i e seasonal data the uncertainty associated with the lag correlation between precipitation and dps is high therefore it is difficult to accurately interpret the teleconnections of the dps with precipitation furthermore for the indus basin the maximum correlation ravg 0 65 p 0 01 for the depth categories is observed at higher lag 3 years values the ims show a maximum statistically significant correlation r 0 71 p 0 01 at the 9 years lag fig 3b with increasing aquifer depth the gwls and precipitation seem to have significant correlations at higher values of lag fig 3b indus basin is the most exploited basin in the study area the reported water level decline rate in the basin is severe with some parts showing the formidable decline rate macdonald et al 2016 of 1 m year the yearly groundwater withdrawals reported in north western parts are more than 100 of recharge rodell et al 2009 the pervasive groundwater abstraction exceeding groundwater recharge leads to the rapid decline in groundwater storage hence the observed higher lag for shs in the indus basin maybe because the meteoric water is taking a longer time to reach the lower water table in this region the presence of a thicker vadose zone could be responsible for this the larger response time is required in the case of deeper groundwater to travel through the thicker unsaturated zone gurdak et al 2007 scanlon et al 2010 and also depends on the vertical continuity and preferential recharge pathways between aquifers ravenscroft et al 2018 in the ganges river basin shs are mostly correlated ravg 0 53 p 0 01 with the precipitation at a lag of 0 to 1 year fig 3c table s7 the pattern of lag analysis for the ganges basin is similar to that of the whole igbm basin in our study area the brahmaputra basin is mostly located in the state of assam which is relatively less exploited cgwb 2017 fig 1d table s9 and has a high annual rainfall of 2240 mm year our analysis reveals the gwls in the brahmaputra basin is dominantly correlated ravg 0 58 p 0 01 with precipitation in the contemporaneous year fig 3d the meghna basin has a maximum lag correlation ravg 0 42 p 0 01 at 1 year fig 3e si s3 but compared to the brahmaputra basin it shows lower lagged correlation values at 1 year lag overall our results show the basin specific differential effects of the continuous year to year interaction between precipitation and groundwater at different aquifer depths under human influence 3 2 groundwater links to global climate forcings the wavelet coherence between climate oscillations and groundwater indicates the degree of influence of climate oscillations on groundwater kuss and gurdak 2014 in this section we have examined the teleconnections between multi decadal global climate cycles and groundwater with time which are essential to understand the degree of aquifer venerability to climate variability 3 2 1 assessments for the entire igbm basin in general our observations from wavelet coherence wtc suggest that the shallow groundwater responds to climate patterns at a shorter time period 2 to 4 years than the groundwater at increasing depths wavelet coherence spectrums show coherence at the maximum 12 year periods fig 4 s11 s12 s13 and s14 however for the deeper im and dp wells particularly most of the coherence within the cone of influence lies at the period between 8 and 12 years for the sh records in the entire igbm basin the pacific decadal oscillation pdo shows the highest coherence with groundwater levels at 95 confidence level followed by north atlantic oscillation nao el niño southern oscillation enso indian ocean dipole iod fig 4a d g j the intermediate depth wells show coherence particularly with enso and pdo fig 4b e the deep wells show relatively weaker coherence with enso pdo along with iod fig 4i l f this implies weakened climate response to groundwater level fluctuations in deep wells for enso pdo and iod however stronger coherence for the deep wells with nao is observed it is worth mentioning that most of the coherence bands for the deeper wells at the higher periods 8 12 years lie in the cone of influence hence these bands cannot be evaluated in confidence due to reliability issues related to edge effects wavelet coherence power spectra reflect a weakening of the power with increasing depth for enso and pdo table s11 for the nao shs show strong coherence but ims do not the coherence between iod and groundwater is moderate and consistent although no statistically significant coherence is observed for iod signals with groundwater in the whole igbm basin fig 4j l our findings from wtc indicate climate oscillations from the pacific ocean pdo and enso have a greater influence on groundwater than the oscillations from the atlantic ocean nao and the indian ocean iod table s10 in the igbm basin coherence at a 5 significance level from 2 to 7 years in the shallow wells is observed predominantly before the mid 1990s and in 2010s fig 4a which is consistent with the strong la niña episodes during 1990 1995 figure s9 however the coherence observed in post 2010 is inside the cone of influence the period of strong coherence in the shallow wells is consistent with a positive pdo event from 1995 to 1997 and a negative pdo event between 2004 and 2013 fig 4d figure s9 3 2 2 variation in response patterns across the sub basins in the indus basin both short and long period coherences are identified irrespective of the depth of the aquifer figure s11 si s4 this suggests irregularities in response time at various depths of the aquifer moreover the wtcs show significant coherence of enso pdo with gwls at deeper depths interestingly for nao with increasing depth short period coherence power increases whereas long period coherence power decrease the relationship between nao and gwls is not clear however for iod the wavelet coherence features are statistically insignificant figure s11 table s12 these wavelet features reflect the irregular nature of the indus basin which happens to be the most exploited basin in the study area however due to the edge effect in the wavelet spectrum the results for the dps are less reliable for the ganges basin the patterns are similar to that of the whole igbm basin with relatively weaker coherence for deeper wells figure s12 table s13 the coherence between enso pdo with gwls is significant in the brahmaputra basin whereas for nao the coherence reduces with depth contrary to the other basins significant coherence is recognized for iod in the brahmaputra basin figure s13 table s14 in general for the meghna basin a weakening coherence with increasing depth is observed however there are a few irregular coherence pattern e g nao with shs observed for the meghna basin which is inconsistent to the general hydraulic expectation figure s14 table s15 3 3 relationship between gwl climate and abstraction the gwl response to the natural and anthropogenic triggers varies significantly across the basin due to the complexities in the climate pumping sub surface depth and land use to further corroborate the observed patterns from lag correlation and wavelet analysis we applied the dominance analysis budescu 1993 azen and budescu 2006 thomas and famiglietti 2019 using dominance analysis we present a quantitative evaluation of the relationship between the gwls with global climate patterns precipitation and groundwater abstraction at the igbm basin and the sub basins scale we find that abstraction precipitation enso pdo have strong dominance across the igbm and sub basins except for the brahmaputra basin where nao seems to have significant dominance fig 5 furthermore precipitation has the lowest dominance in the indus basin whereas the influence of precipitation is high in the meghna basin in the indus and meghna basin abstraction has a stronger dominance over other drivers however the higher precipitation in the meghna basin may result in a trade off between precipitation and abstraction the ganges basin shows intermediate dominance of groundwater abstraction and precipitation moreover the influence of groundwater abstraction on the gwls in the deeper observation wells ims and dps is stronger than the shallow observation wells shs the higher groundwater abstraction from the deeper depths may explain the greater dominance of abstraction in the deeper observation wells the dominance of groundwater abstraction from the greater depths is higher in the most exploited areas e g north west india in the brahmaputra basin precipitation shows the highest dominance whereas abstraction shows a lower dominance in general the result suggests that that enso has the highest influence on gwl change followed by pdo nao and iod 4 discussion groundwater fed irrigation is crucial for food and water security in the igbm basin the contamination of shallow groundwater mostly in eastern india and bangladesh is a severe issue for the suitability of groundwater resources in the basin mukherjee et al 2015 this crisis is further intensified by excessive rates of groundwater abstraction mainly in northwest india indus basin the eastern part of ganges basin bengal basin and southeast bangladesh meghna basin rodell et al 2009 macdonald et al 2016 bhanja et al 2019 deep groundwater withdrawal is a common practice world bank 2010 in the basin to avoid the shallow contaminated i e mostly saline and arsenic groundwater and or to cope with the continuous drop in water levels ravenscroft et al 2009 fendorf et al 2010 famiglietti 2014 macdonald et al 2016 thus in recent times there has been a decrease in the number of shallow irrigation wells and an increase in deep irrigation wells 15 times higher annual output than shallow irrigation wells minor irrigation 2017 figure s15 this observation is in accordance with the findings of dominance analysis which shows higher groundwater abstraction from the deeper parts of the aquifer the influence of deeper groundwater abstraction is notable higher for the indus and meghna basi while intermediate for ganges basin fig 5 however in the bengal basin area within the ganges basin deep groundwater abstraction is significantly higher than rest of the ganges basin macdonald et al 2015 2016 besides groundwater abstraction studies also report that canal leakage macdonald et al 2015 2016 bonsor et al 2017 is significant for the ganges basin leakage in upper part 50 of the total canals flow and indus basin wwf 2015 bonsor et al 2017 ò dochartaigh et al 2019 a trade off between canal water leakage and abstraction leads to the spatial variation in gwl fluctuation in the different segments of canal command areas macdonald et al 2015 although the canal leakage induced recharge may be significant for the shallow groundwater 30 m in contrast deeper groundwater 30 m and groundwater away from a canal command area are less affected by canal leakage ò dochartaigh et al 2019 the complexity of the system is further exacerbated by the low cost i e cost associated with electricity high efficiency pump etc of irrigation in the region irrigation return flows furthermore the winter time precipitations provide critical mass mostly in the indus basin contributing to transient groundwater storage and a crucial water source for the winter crops e g wheat and millet hence winter precipitation also has a major role in groundwater level change in the northwest parts of the basin thus we conclude that the observed correlation pattern between precipitation and groundwater in the indus basin results from the various drivers governing a highly complex recharge process the results i e higher dominance of groundwater abstraction at greater depths in the indus basin obtained from the dominance analysis when combined with the findings of lag analysis i e higher lag values in northwest india suggests a relatively delayed buffering potential of precipitation on deeper groundwater in the sub basin in the 31 year time scale of this study on the contrary the meghna basin in bangladesh suffered from high groundwater abstraction macdonald et al 2016 fig 1d while receiving high annual precipitation the high influence of precipitation and abstraction fig 5 in the meghna basin may lead to higher direct and induced recharge which could explain lower values of lag in the meghna basin in a hydro climatic system without human interference it is expected that the climate and recharge signal would attenuate with increasing depth considering the physical constraints and longer travel time mostly in the unconfined aquifers the dps would show weaker climate signatures at an extended time period this is mainly because of the restrictions provided by the confining layers to the direct infiltration in deep aquifers moreover the longer flow path followed by the groundwater to bypass the confining layers could also be a reason for this delayed response in deeper parts in contrast the irregular response shown in the wavelet coherence spectrums could be related to the accelerated groundwater vertical flux caused by an enhanced induced hydraulic gradient and the associated disruption in the natural groundwater flow in the deep groundwater systems due to deep groundwater pumping si s2 we also note that the findings presented in the study on deeper groundwater are less reliable following the lack of hydro stratigraphic knowledge lack of temporal data on evenly distributed deep gwls and the uncertainty associated with the wavelet analysis see assumptions limitations and uncertainty thus the natural dynamics of the hydro climatic cycle gets obscured when groundwater abstraction through pumping is introduced furthermore irrigation return flow bhanja et al 2019 mass loading effects and canal leakage macdonald et al 2016 bonsor et al 2017 2015 which have a significant contribution to the groundwater recharge in the parts of the basin maybe partially accountable for modifying the natural linkage between climate and groundwater the results presented here are sensitive to the spatio temporal coverage of the existing data and availability of data on other important drivers furthermore additional information on groundwater use canal leakage is required to truly isolate the anthropogenic effects and the climate effects on groundwater future studies with a more rigorous hypothesis guided approach based on better spatial and temporal datasets may enhance our understanding of the significance of the possible contributors in the human natural complex system a case needs to be made to develop the data models and predictive understanding necessary to build insights on deeper groundwater flow at a large scale based on rigorous quantitative analyses the findings of the study could be used to understand the groundwater climate linkage under the influence of human interventions in other densely populated basins of the world researchers may increase the resolution of the study with higher resolution verifiable information on the irrigation amount sub surface lithology and ideally utilizing output from more advanced global models for a focused area 5 conclusions in the study we used lag correlation wavelet analysis and dominance analysis to understand the extent of climatic impact on the groundwater at different aquifer depths under the anthropogenic influence the findings from the dominance analysis are mostly in agreement with the lag and wavelet analysis and suggest stronger dominance of abstraction precipitation enso pdo in the study area in general groundwater abstraction particularly from deeper depths dominates in indus and meghna basin while precipitation dominates in the brahmaputra and meghna basin the influence of precipitation and abstraction are moderate for the ganges basin we also find that precipitation affects groundwater at various aquifer depths differently and climate oscillations from the pacific ocean have a greater influence on groundwater than the oscillations from the atlantic ocean and the indian ocean however results suggest irregular response between gwls and global climate patterns in areas where human interferences dominate over the natural recharge processes thus we surmise that groundwater pumping could provide an important role in modifying the link between hydro climate and groundwater despite the associated caveats and data limitations discussed above our study emphasizes the climatic and the human induced effects on different depths of the aquifer particularly the adverse effects on greater depths due to increasing deep groundwater abstraction thus efficient monitoring of deep groundwater abstraction is required to ensure its sustainability and usability in the present and future ravenscroft et al 2013 the findings may be helpful in constructing regional strategies and relevant policies related to prevailing high groundwater withdrawals in the region data availability statement all the data used in this study are freely available groundwater level data are retrieved from the repositories of the central ground water board http cgwb gov in gw data access html of the government of india and bangladesh water development board https www bwdb gov bd of the government of bangladesh precipitation data for india and bangladesh was available from the india meteorological department imd http www imd gov in welcome 20to 20imd welcome php and climatic research unit cru ts v 4 01 https crudata uea ac uk cru data hrg respectively climate indices data are available on the national oceanic and atmospheric administration noaa website https psl noaa gov data climateindices minor irrigation based tube well data available at the open government data ogd platform india https data gov in search site query tubewell minor irrigation census reports of india http mowr gov in schemes projects programmes schemes irrigation census and minor irrigation survey reports of bangladesh https badc portal gov bd sites default files files badc portal gov bd page c23bdffd 22fd 4f15 8fc4 b1fc7a91a36a 2020 09 01 14 15 bbb411c861df9a62fdafcccbd8025192 pdf groundwater abstraction data are available from the dynamic ground water resources of india by cgwb http cgwb gov in dynamic gw resources html and aquastat fao s global information system on water and agriculture country profile india http www fao org aquastat en countries and basins country profiles country ind and bangladesh http www fao org aquastat en countries and basins country profiles country bgd author contribution statement p m and a m designed the study p m performed background analyses and simulations p m did the study under the supervision of a m and advice from s n b a r g data management and processing were performed by pm with inputs from s n b r k r d s and a z helped with the data retrieval p m performed the statistical analyses with inputs from a r g and s c p m wrote the manuscript with inputs from a m a r g s n b s s r k r a z d s and s c declaration of competing interest the authors declare that they have no competing interests acknowledgments we acknowledge agi project iit sric gg cse agi 2013 14 201 from ministry of human resource development mhrd govt of india we also acknowledge the national oceanic and atmospheric administration noaa central ground water board ministry of water resources government of india and bangladesh water development board government of bangladesh for the availability of climate indices data water level measurement data for india and bangladesh respectively we also acknowledge precipitation data provided by the indian meteorological department imd and climatic research unit cru ts v 4 01 the authors acknowledge the use of the matlab version 2018b eviews software version 9 rstudio software version 1 2 5001 and ferret http ferret pmel noaa gov ferret pacific marine environmental laboratory noaa program for analysis the authors also acknowledge arcgis software version 10 2 1 origin software version 2015 for some of the graphics in this paper the authors are very much thankful to palash debnath for his valuable suggestions special thanks to srimanti dutta gupta kousik das at iit kharagpur for help with data analyses supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103856 appendix supplementary materials image application 1 
346,groundwater plays a major role in human adaptation and ecological sustainability against climate variability by providing global water and food security in the indus ganges brahmaputra meghna aquifers igbm groundwater abstraction has been reported to be one of the primary contributors to groundwater storage variability however there is still a lack of understanding on the relative influence of climate and abstraction on groundwater data guided statistical studies are reported to be crucial in understanding the human natural complex system here we attributed the long term 1985 2015 impact of local precipitation global climate cycles and human influence on multi depth groundwater levels n 6753 in the igbm using lag correlation analysis wavelet coherence analysis and regression based dominance analysis our findings highlight the variable patterns of phase lags observed between multi depth groundwater levels and precipitation depending on the different nature of climatic and anthropogenic drivers in different parts of the basin we observed intuitive responses i e rapid response in shallow groundwater and relatively delayed responses to the global climate patterns with increasing depth however in the most exploited areas the hydrological processes governing the groundwater recharge are overwhelmed by unsustainable groundwater abstraction thus decoupling the hydro climatic continuum our results also suggest groundwater abstraction to be the dominant influence in most of the basin particularly at the greater depth of the aquifer thus highlighting the importance of understanding multi depth groundwater dynamics for future groundwater management and policy interventions keywords multi depth groundwater level climate variability anthropogenic influences data guided methods transboundary indus ganges brahmaputra meghna basin 1 introduction the indus ganges brahmaputra meghna igbm river system is one of the largest transboundary basin aquifer systems across the world macdonald et al 2016 mukherjee 2018 this highly yielding aquifer system fig 1 a was formed from the sediments eroded by the himalayas and redistributed by these mega rivers across south asia mukherjee et al 2015 mukherjee 2018 this basin has one of the highest irrigation water demands and very high population density richey et al 2015 the basin contributes almost 25 of the global groundwater abstraction 205 km3 year macdonald et al 2016 about 80 of total precipitation in india and bangladesh occur in june july august september through indian summer monsoon mukherjee et al 2015 paul et al 2016 however in northwest india mostly indus basin in the study area 15 20 of the total rainfall occurs due to the indian winter monsoon yadav et al 2009 during december january and february by western disturbance which is the eastward propagating cyclones scott et al 2019 recent studies mukherjee et al 2007 macdonald et al 2016 asoka et al 2017 bhanja et al 2017a 2017b 2019 bhanja and mukherjee 2019 disagree on the triggers for groundwater storage changes and recharge patterns across south asia while some studies asoka et al 2017 have argued that the precipitation patterns are the primary influencing factor for groundwater level gwl changes across the indian subcontinent other studies on this topic mukherjee et al 2007 macdonald et al 2016 bhanja et al 2017a 2017b 2019 suggest that even in areas demonstrating increased precipitation and primary secondary recharge enhanced depletion of groundwater storage are observed which is potentially caused by intensive groundwater abstraction rodell et al 2009 wada et al 2010 gleeson et al 2012 döll et al 2014 bhanja et al 2019 bhanja and mukherjee 2019 furthermore the groundwater regime may also be influenced by the seepage from natural surface water bodies mukherjee et al 2018 canals macdonald et al 2016 irrigation return flows bhanja et al 2019 and groundwater policy interventions bhanja et al 2017a leakages from the distributor canals are significant for the indus 59 000 km of canal network and the ganges aquifer system 25 000 km of canal network macdonald et al 2015 constituting a major portion of recharge in the drier parts macdonald et al 2016 although the local scale groundwater withdrawals for public and private water supplies in the urban areas are minor compared to the irrigational abstractions macdonald et al 2015 it can be the potential driver for rapid gwl decline locally macdonald et al 2016 earlier studies stressed on the inter annual dhanya and kumar 2009 to multi decadal climate variability affecting the different components of the hydrologic cycle scanlon et al 2005 through changes in the precipitation pattern streamflow snow and drought occurrence mccabe et al 2004 vicente serrano et al 2011 moreover interplay within the different forms of climate variability partially controls the gwl change and recharge rates gurdak et al 2007 tremblay et al 2011 perez valdivia et al 2012 the el niño southern oscillation enso and indian ocean sea surface temperature directly influence the precipitation seasonality in the indo gangetic plain sahany et al 2018 a study reports that drought variability in india is primarily impacted by enso kumar et al 2013 furthermore the pacific decadal oscillations pdo modifies the relationship between enso and the indian monsoon by a mechanism involving equatorial pacific and indian ocean krishnamurthy and krishnamurthy 2014 eventually affecting the groundwater systems in the basin another study shows that the short period heavy to moderate intensity rainfall events have a higher contribution to the total seasonal rainfall than the short period low intensity to long period moderate rainfall events in india dash et al 2011 significantly contributing to the groundwater recharge taylor et al 2013 the global climate patterns considerably influence the rainfall patterns and intensities at various scales and degrees krishnaswamy et al 2015 xavier et al 2018 rathinasamy et al 2019 the uncontrolled groundwater pumping for food production is further instigated by subsidized low electricity rates harvey et al 2002 shah 2009 mukherjee et al 2015 barik et al 2016 additionally groundwater pumping may also increase the leakage from canals affecting groundwater recharge ò dochartaigh et al 2019 land surface models that have been used to estimate groundwater depletion wada et al 2010 doll et al 2014 or gwl decline de graaf et al 2019 may also be used to separate the effects of groundwater abstraction and climate variability on gwls however the modern advanced land surface models have limitations in considering these irrigation practices barik et al 2016 a recent comparative analysis between global models and gravity recovery and climate experiment grace derived water storage trends show that the models underestimate the water storage trends relative to grace reflecting the effects of water withdrawals for irrigation and climate variations scanlon et al 2018 thus it becomes difficult to isolate the effect of human induced components in the human natural complex system due to the large grid size of grace and global models scanlon et al 2018 furthermore regional groundwater flow models mukherjee et al 2007 michael and voss 2009a 2009b de graaf et al 2019 of the region also provides critical insights on the human natural complex hydrologic systems however the disadvantage would be that it requires the hydrogeological setup of the aquifer system which may be difficult to obtain therefore data guided statistical approaches involving a dense network of monitoring wells could serve as useful tools to understand the system where the state of the art models have restrictions in doing so for example using a statistical approach thomas and famiglietti 2019 showed that the precipitation and groundwater recharge exhibit greater influence than groundwater pumping across the united states and linked this to climate induced groundwater depletion the trade off between climate and groundwater abstraction is critical for the security and sustainability of the climate water energy food nexus following the lack of agreement on the relative importance of drivers in previous studies in this large basin aquifer system we revisited the subject matter with a focused attempt to attribute the effect of natural and anthropogenic triggers on groundwater by a hypothesis guided approach our hypothesis is that while intuitive responses of groundwater to climate variability may be captured in the natural system without human interventions pervasive human interference involving groundwater pumping may cause alteration in the natural dynamics leading to non intuitive differential responses depending on the abstraction pattern and hydro stratigraphy it should be noted that here intuitive responses signify the hydraulically expected responses i e rapid response in shallow groundwater and relatively delayed responses to the climate with increasing depth despite well recognized previous studies examining the relationship between primary drivers and groundwater our study focuses on the multi depth aspect of groundwater characterization for the first time in terms of climate and abstraction on this critical aquifer system it provides an understanding on how the gwls at different depths of the aquifer respond to groundwater abstraction and climate to evaluate our hypothesis here we present a data driven statistical approach to determine the influence of climate via local precipitation and global climate cycles on groundwater levels under the effect of groundwater abstraction with new information on the intake depths of the observation wells in the parts of the indus ganges brahmaputra meghna igbm basin and sub basins for the last three decades we used lag correlation analysis wavelet analysis and dominance analysis as our tools based on its wide uses by previous researchers grinsted et al 2004 kuss and gurdak 2014 russo and lall 2017 velasco et al 2017 thomas and famiglietti 2019 and rigorous statistical insights the lag correlation is an efficient tool to assess the strength of the connections between time series variables at different time shifts wavelet coherence is used as a tool to decompose the time series signals while preserving the spatial or chronological information chavez and cazelles 2019 see si s1 the multiple linear regression based dominance analysis is employed since it provides a rigorous and quantitative description on the influence of climate and abstraction on groundwater 2 materials and methods 2 1 data treatment 2 1 1 groundwater level measurements we used 31 years 1985 2015 of groundwater level gwl data from 13 646 monitoring wells with intake depths ranging from 3 m to 500 m the data is assembled from various sources table s1 the water level data for india is in quarterly structure which is the monthly monitoring data for january late post monsoon may pre monsoon august monsoon and november early post monsoon however the gwl data for bangladesh is in the weekly format which was then converted to the quarterly format by taking the average values of the weekly data for january may august and november to maintain continuity within the datasets the gwl datasets used in the study show a wide range of continuity frequency and time intervals we have imposed tukey s method tukey 1977 bhanja et al 2017a to remove the noise and outliers from the raw dataset these quarterly gwl datasets figure s1 s2 s3 s4 were converted to yearly gwl time series figs 2 s1 s2 s3 s4 s5 by taking the average values of the quarterly data the annual minimum average and maximum groundwater levels map between 1985 and 2015 from the whole igbm and each of the sub basins are shown in figure s6 furthermore when yearly gwls are calculated only those yearly data were considered having a minimum of three seasonal data out of four records each year our selection criteria for the final observation wells of yearly averaged gwl time series required a minimum of 10 yearly observation points out of 31 for 31 years a detailed flow chart of the filtering and processing methods of the gwl dataset is shown in figure s7 after the post processing and the application of these additional filters the count of usable observation wells has reduced to 6753 for further analysis figure s8a the missing values in these time series records were interpolated with splines russo and lall 2017 for each of the observation wells gwls were normalized by calculating the gwl anomaly by subtracting the long term 1985 2015 mean gwl depth from the actual gwl depth bhanja et al 2017a to understand the response of climate at different depth in the aquifer the observation wells were classified by their intake depths sh shallow wells intake depth 35 m n 5546 im intermediate wells intake depth 35 70 m n 685 dp deep wells intake depth 70 m n 522 the depth classes sh im dp are classified based on the dominant abstraction depths for irrigation practiced in the region minor irrigation 2017 the observation well numbers reduced significantly with increasing intake depths figure s8b the mean count of observation wells for all the depth categories in the basin and sub basins are provided in table s2 we also note that most of the observation wells in the region are reported to be unconfined in type central ground water board cgwb 2014a 2 1 2 climate data treatment the gridded precipitation data used in this study are assembled from various sources for india and bangladesh table s1 we calculated the average precipitation for the basin and sub basins by averaging the precipitation time series of the grids 0 25 0 25 for india 0 5 0 5 for bangladesh that lie in the respective basins and sub basins the monthly multivariate enso index mei cycle 2 to 7 year the pacific decadal oscillation index pdo cycle 15 to 30 year the indian ocean dipole mode index dmi cycle 2 to 3 years the north atlantic oscillation index nao cycle 3 to 6 year 8 to 10 year data figure s9 were obtained from national oceanic and atmospheric administration noaa 2018 the yearly average from monthly data of each climate index mei pdo nao and nao were calculated and used for further analysis in general the observed anomalies in sea level pressure sea surface temperature wind speed fluctuation in earth s orbit geo potential heights ghil 2002 at multiple locations on the planet were processed to create the climatic indices for different modes of climate variability velasco et al 2017 2 1 3 groundwater abstraction data we have developed a groundwater abstraction map for the year 2013 in million cubic meters mcm for the entire igbm basin by combining datasets from various sources table s1 s1a for india district level groundwater abstraction data were collected from the dynamic ground water resources of india by central ground water board cgwb 2017 for bangladesh the groundwater abstraction map was derived from data local and published datasets aquastat 2018a badc 2013 2020 table s1 s1a the yearly groundwater abstraction figure s10 were calculated mukherjee et al 2007 bhanja et al 2017a using pumping well numbers n for irrigation purposes minor irrigation 1993 2001 2005 2014 2017 badc 2013 2020 pumping rate r and yearly duration t zahid et al 2006 minor irrigation 2014 2017 qureshi et al 2014 and combined and compared with published estimates central ground water board cgwb 2006 central ground water board cgwb 2011 central ground water board cgwb 2014b central ground water board cgwb 2017 central ground water board cgwb 2019 aquastat 2018b qureshi et al 2014 from several datasets table s1 s1a for the basin and each of the sub basins the yearly groundwater abstraction q of the basin and sub basins are computed mukherjee et al 2007 bhanja et al 2017a with the following equation 1 q n r t 2 2 statistical methods 2 2 1 lag correlation lag correlation analysis is performed predominantly when a variable or forcing has some delayed effect on a system kuss and gurdak 2014 velasco et al 2017 we have estimated the lag correlation between precipitation xt and groundwater levels yt with the help of the cross correlation function rxy k to investigate the phase shift the function provides knowledge on the causal relationships or relationships without attribution of a cause between the two time series larocque et al 1998 tirogo et al 2016 and is not necessarily symmetrical rxy k ryx k for k 0 2 r x y k c x y k σ x σ y 3 c x y k 1 n i 1 n k x t x y t k y here cxy k is the cross correlogram k is the time lag k 0 1 n the duration of the time series is denoted as n x y and σx σy are the mean and standard deviation of the precipitation and gwls respectively in equations 1 and 2 if k 0 y replaces x and vice versa if k 0 then it indicates that x and y signals respond to a third independent signal at the same time larocque et al 1998 in the complicated dynamic hydrological system lag correlation analysis may provide crucial information on the regional hydrogeology and the anthropogenic stress on groundwater daily gridded precipitation data were retrieved from different sources for the period 1985 2015 table s1 afterward yearly total precipitation was calculated for the entire igbm basin and sub basins we used the lag correlation analysis to estimate the correlation coefficient between gwls basin wide averaged yearly averaged time series and precipitation basin averaged yearly averaged time series for lag values from 1 to 16 years in the study area hence the analysis provides a single value of lag correlation coefficient corresponding to each lag years for the different well depth categories for the lack of prior study in the basin and from a statistical point of view since we have used a total of 31 years of yearly gwl data we have considered a maximum possible 16 years lag period with a 95 confidence interval here we present the lag correlation coefficients with their corresponding phase lags in years zero lag indicates less than 12 months of lag between precipitation and gwls the lag analysis was conducted using eviews v 9 statistical software 2 2 2 dominance analysis the dominance analysis provides the relative importance of the influencing variables by computing the coefficient of determination r2 in multiple linear regression azen and budescu 2006 here we performed conditional dominance of the variable for p 1 sub models where p is the numeric value of total sub models budescu 1993 thomas and famiglietti 2019 the yearly groundwater abstraction figure s10 precipitation fig 2 enso pdo nao and iod figure s9 for the basin and each sub basins were considered as the predictor variables to understand their influence with the outcome variable gwls i e yearly averaged basin averaged time series for all depth categories a more detailed description of the dominance analysis can be found in azen and budescu 2006 and budescu 1993 the dominance analysis was conducted using rstudio v 1 2 5001 software 2 3 numerical computation 2 3 1 principal component analysis pca the groundwater level data used in this study are obtained from a dense network of monitoring wells in the igbm basin we used a multivariate statistical method principal component analysis pca on water level data to reduce the size of the dataset extract only the essential information simplify the structure of the dataset wold et al 1987 and search for uncorrelated components that reflect the true nature of the groundwater level data tirogo et al 2016 pca is a commonly used approach that decreases the dimensionality of the datasets however it holds the greater part of the varieties for more comfortable data exploration zahra et al 2014 chang et al 2017 these components are the linear combinations of the primary variables suppose there are n individuals each characterized by p variables firstly a correlation matrix is generated by the pca then the total variance of all the pairs n p is projected on the imaginary factorial planes fi i 1 2 n tirogo et al 2016 each factorial axis represents each of the principal components we used the first principal component which corresponds to the first factorial plane that accounts for the largest variability possible detailed descriptions of principal component analysis can be found in abdi and williams 2010 and gangopadhyay et al 2001 2 3 2 wavelet coherence analysis statistically non stationary hydrological time series may exhibit variations in periodic signals over the long term period by altering its frequency and amplitude mitra et al 2014 these complex time series and periodic signals can be analyzed with the wavelet analysis the purpose of the wavelet analysis is to decompose the time series signal into a frequency component using wavelets these wavelets are waves that travel forward or backward temporally for a range of defined periods holman et al 2011 here the product of the analysis wavelet coherence is equivalent to the localized coefficient of correlation in the time frequency domain labat et al 2000 grinsted et al 2004 wavelet analysis can offer crucial insights into the variations of the power of climate groundwater teleconnections with time holman et al 2011 in this study the association between groundwater and climatic teleconnections was surveyed through bivariate wavelet analysis utilizing the morlet wavelet function mitra et al 2014 russo and lall 2017 the morlet wavelet function accommodates a good balance between frequency domain and time domain grinsted et al 2004 for dimensionless frequency ω0 and dimensionless time η the morlet function is defined as 4 ψ 0 n π 1 4 e i ω 0 η e 1 2 η 2 additionally ward s agglomerative hierarchical clustering was employed on the yearly gwl time series for all the observation wells to carry out wavelet cluster analysis murtagh and legendre 2014 russo and lall 2017 the selection of the number of clusters was determined with the parsimony coefficient rousseeuw 1987 russo and lall 2017 this method was applied to identify the clusters with similar frequency amplitude behaviors the number of clusters in all the basin and sub basin ranges from 2 to 4 for all the depth categories next using the first principal component obtained from wavelet cluster analysis and using climate indices we performed cross wavelet transform to analyze the cross wavelet power between them and classify the region of differential powers kuss and gurdak 2014 in the wavelet coherence spectrum essential features are recognized at a 5 significant level using the monte carlo method with 1000 random synthetic series newman et al 2003 grinsted et al 2004 holman et al 2011 kuss and gurdak 2014 this represents coherence at a 95 confidence level between the hydrologic and climatic variables in the wavelet spectrum the edge effect occurs close to the edge of the time series chavez and cazelles 2019 thus a cone of influence is introduced within which the edge effects become important torrence and compo 1998 grinsted et al 2004 schulte 2016 and the region outside the cone of influence is not affected by the edge effect chavez and cazelles 2019 it should be noted that wavelet coherence bands that lie inside the cone of influence cannot be evaluated reliably because of the edge effects russo et al 2014 in the power spectrum the spectral coherence is identified even if the coherence is of low power in the time frequency domain the wavelet coherence wtc measures the cross correlation as a number between 0 and 1 between the two time series as a function of frequency detailed descriptions of the entire process can be found in kuss and gurdak 2014 and grinsted et al 2004 to summarize for the gwl time series the first principal component in each of the clusters in all the basin and sub basin was used with the climatic indices mei pdo index nao index dmi to generate wavelet cross spectrum and wavelet coherence wtc torrence and compo 1998 russo and lall 2017 more information regarding the application of wavelet analysis is discussed in the supplementary information si s1 the wavelet analysis was conducted using matlab v 2018b software 2 4 assumptions limitations and uncertainty gwl data from the different government agencies are not continuous several missing data with varying frequency and length which leads us to use the maximum possible data range 1985 2015 based on the availability of data in the basin also the gwl data for india and bangladesh are of a different time interval which was converted to the same interval to maintain consistency within the datasets the gridded datasets for precipitation were used from cru ts 0 5 0 5 and imd 0 25 0 25 table s1 these datasets are smoothed products from observed point data and have limitations in capturing hydro climatic extremes in this study we have not considered the parts of the indus basin in pakistan due to data inaccessibility the deeper im and dp wells particularly are not evenly distributed and biased towards a few sub basins than others table s3 s4 few of the deeper gwl datasets used in the study are clustered towards the urban areas and can be locally influenced by the groundwater withdrawals for public and private water supply moreover few of the observation wells in the basin lies in close proximity to each other and may show and reinforce similar seasonal patterns the bias due to observation wells lying close to each other is not considered in the analysis to get a satisfactory data coverage of the deeper observation wells we needed to adopt a filtering criteria of selecting those observation wells having a minimum of 10 out of 31 yearly gwl data points the influence of canal leakage which is significant in some parts of the basin was discussed based on previous literature and our understanding on the subject matter as quantitative analysis could not be performed due to the paucity of data the groundwater response signal even at a depth of the aquifer due to the mass loading effect coupled with the compressibility of the confined aquifer maliva et al 2011 was not analyzed in the study due to data unavailability the quantification of the deeper groundwater flow is out of the scope of this study 3 results 3 1 lag based relationship between precipitation and groundwater the annual precipitation in the basin varies significantly with the lowest occurring in the indus sub basin mean precipitation 590 mm year and the highest in the meghna sub basin mean precipitation 2560 mm year fig 1c table s5 in general the basin averaged yearly averaged gwls in the indus basin is the deepest whereas shallower gwls are observed in the brahmaputra basin and meghna basin and these gwls deepen with the depth of the observation wells for the sub basins i e indus ganges fig 2 the lowest precipitation is observed in the indus basin and the highest in the brahmaputra and meghna basins fig 2 the basin averaged yearly averaged time series for gwl and precipitation in the whole igbm show a similar pattern with the ganges basin fig 2 due to the presence of the majority of land area 78 and the observation wells 80 in the ganges basin table s2 s3 respectively we applied lag correlation analysis using the basin and sub basin averaged yearly averaged time series of gwls in the observation wells sh im and dp and precipitation to explore the lagged relationship between them at the basin to sub basin scale the results based on igbm basin scale observations suggest that the correlation is maximum for the same year 0 year lag ravg 0 47 p 0 01 and for the previous year 1 year lag ravg 0 45 p 0 01 table s6 fig 3 a the gwls in the shs have little correlation ravg 0 13 with lag 1 year the dps also show a relatively highest correlation at lower lag values 0 and 1 year lag ravg 0 43 p 0 01 the dps have intake depths 70 m at that depth the possibility of the occurrence of one or multiple confining layers is greater therefore for dps the direct vertical meteoric infiltrated water contributing to groundwater recharge is restricted and attenuated by the hydrostratigraphic confining layers groundwater recharge in the aforementioned scenario depends upon the hydraulic properties and physical extent of the confining layers recent studies emphasized on the increased vertical recharge in deeper sites induced by pumping and landuse lapworth et al 2015 macdonald et al 2016 this pumping induced accelerated recharge could be linked to the higher correlation at lower lag years in the deeper sites the mass loading effects of the aquifer due to mechanical loading by the precipitation tidal surface flooding and few other hydrologic processes of terrestrial water and subsequent poroelastic response could be a relevant process in changing the water levels in the study area burgess et al 2017 particularly in the deeper sites ravenscroft et al 2018 the mass loading could be related to the consistent higher correlation at lower lag years in the deeper observation wells however the mass loading effect on the water level is at an intra annual i e even at a daily to sub monthly scale whereas the scale of observation we are trying to measure is annual to decadal the influence of mass loading on groundwater level change is difficult to study based on current data availability i e seasonal data the uncertainty associated with the lag correlation between precipitation and dps is high therefore it is difficult to accurately interpret the teleconnections of the dps with precipitation furthermore for the indus basin the maximum correlation ravg 0 65 p 0 01 for the depth categories is observed at higher lag 3 years values the ims show a maximum statistically significant correlation r 0 71 p 0 01 at the 9 years lag fig 3b with increasing aquifer depth the gwls and precipitation seem to have significant correlations at higher values of lag fig 3b indus basin is the most exploited basin in the study area the reported water level decline rate in the basin is severe with some parts showing the formidable decline rate macdonald et al 2016 of 1 m year the yearly groundwater withdrawals reported in north western parts are more than 100 of recharge rodell et al 2009 the pervasive groundwater abstraction exceeding groundwater recharge leads to the rapid decline in groundwater storage hence the observed higher lag for shs in the indus basin maybe because the meteoric water is taking a longer time to reach the lower water table in this region the presence of a thicker vadose zone could be responsible for this the larger response time is required in the case of deeper groundwater to travel through the thicker unsaturated zone gurdak et al 2007 scanlon et al 2010 and also depends on the vertical continuity and preferential recharge pathways between aquifers ravenscroft et al 2018 in the ganges river basin shs are mostly correlated ravg 0 53 p 0 01 with the precipitation at a lag of 0 to 1 year fig 3c table s7 the pattern of lag analysis for the ganges basin is similar to that of the whole igbm basin in our study area the brahmaputra basin is mostly located in the state of assam which is relatively less exploited cgwb 2017 fig 1d table s9 and has a high annual rainfall of 2240 mm year our analysis reveals the gwls in the brahmaputra basin is dominantly correlated ravg 0 58 p 0 01 with precipitation in the contemporaneous year fig 3d the meghna basin has a maximum lag correlation ravg 0 42 p 0 01 at 1 year fig 3e si s3 but compared to the brahmaputra basin it shows lower lagged correlation values at 1 year lag overall our results show the basin specific differential effects of the continuous year to year interaction between precipitation and groundwater at different aquifer depths under human influence 3 2 groundwater links to global climate forcings the wavelet coherence between climate oscillations and groundwater indicates the degree of influence of climate oscillations on groundwater kuss and gurdak 2014 in this section we have examined the teleconnections between multi decadal global climate cycles and groundwater with time which are essential to understand the degree of aquifer venerability to climate variability 3 2 1 assessments for the entire igbm basin in general our observations from wavelet coherence wtc suggest that the shallow groundwater responds to climate patterns at a shorter time period 2 to 4 years than the groundwater at increasing depths wavelet coherence spectrums show coherence at the maximum 12 year periods fig 4 s11 s12 s13 and s14 however for the deeper im and dp wells particularly most of the coherence within the cone of influence lies at the period between 8 and 12 years for the sh records in the entire igbm basin the pacific decadal oscillation pdo shows the highest coherence with groundwater levels at 95 confidence level followed by north atlantic oscillation nao el niño southern oscillation enso indian ocean dipole iod fig 4a d g j the intermediate depth wells show coherence particularly with enso and pdo fig 4b e the deep wells show relatively weaker coherence with enso pdo along with iod fig 4i l f this implies weakened climate response to groundwater level fluctuations in deep wells for enso pdo and iod however stronger coherence for the deep wells with nao is observed it is worth mentioning that most of the coherence bands for the deeper wells at the higher periods 8 12 years lie in the cone of influence hence these bands cannot be evaluated in confidence due to reliability issues related to edge effects wavelet coherence power spectra reflect a weakening of the power with increasing depth for enso and pdo table s11 for the nao shs show strong coherence but ims do not the coherence between iod and groundwater is moderate and consistent although no statistically significant coherence is observed for iod signals with groundwater in the whole igbm basin fig 4j l our findings from wtc indicate climate oscillations from the pacific ocean pdo and enso have a greater influence on groundwater than the oscillations from the atlantic ocean nao and the indian ocean iod table s10 in the igbm basin coherence at a 5 significance level from 2 to 7 years in the shallow wells is observed predominantly before the mid 1990s and in 2010s fig 4a which is consistent with the strong la niña episodes during 1990 1995 figure s9 however the coherence observed in post 2010 is inside the cone of influence the period of strong coherence in the shallow wells is consistent with a positive pdo event from 1995 to 1997 and a negative pdo event between 2004 and 2013 fig 4d figure s9 3 2 2 variation in response patterns across the sub basins in the indus basin both short and long period coherences are identified irrespective of the depth of the aquifer figure s11 si s4 this suggests irregularities in response time at various depths of the aquifer moreover the wtcs show significant coherence of enso pdo with gwls at deeper depths interestingly for nao with increasing depth short period coherence power increases whereas long period coherence power decrease the relationship between nao and gwls is not clear however for iod the wavelet coherence features are statistically insignificant figure s11 table s12 these wavelet features reflect the irregular nature of the indus basin which happens to be the most exploited basin in the study area however due to the edge effect in the wavelet spectrum the results for the dps are less reliable for the ganges basin the patterns are similar to that of the whole igbm basin with relatively weaker coherence for deeper wells figure s12 table s13 the coherence between enso pdo with gwls is significant in the brahmaputra basin whereas for nao the coherence reduces with depth contrary to the other basins significant coherence is recognized for iod in the brahmaputra basin figure s13 table s14 in general for the meghna basin a weakening coherence with increasing depth is observed however there are a few irregular coherence pattern e g nao with shs observed for the meghna basin which is inconsistent to the general hydraulic expectation figure s14 table s15 3 3 relationship between gwl climate and abstraction the gwl response to the natural and anthropogenic triggers varies significantly across the basin due to the complexities in the climate pumping sub surface depth and land use to further corroborate the observed patterns from lag correlation and wavelet analysis we applied the dominance analysis budescu 1993 azen and budescu 2006 thomas and famiglietti 2019 using dominance analysis we present a quantitative evaluation of the relationship between the gwls with global climate patterns precipitation and groundwater abstraction at the igbm basin and the sub basins scale we find that abstraction precipitation enso pdo have strong dominance across the igbm and sub basins except for the brahmaputra basin where nao seems to have significant dominance fig 5 furthermore precipitation has the lowest dominance in the indus basin whereas the influence of precipitation is high in the meghna basin in the indus and meghna basin abstraction has a stronger dominance over other drivers however the higher precipitation in the meghna basin may result in a trade off between precipitation and abstraction the ganges basin shows intermediate dominance of groundwater abstraction and precipitation moreover the influence of groundwater abstraction on the gwls in the deeper observation wells ims and dps is stronger than the shallow observation wells shs the higher groundwater abstraction from the deeper depths may explain the greater dominance of abstraction in the deeper observation wells the dominance of groundwater abstraction from the greater depths is higher in the most exploited areas e g north west india in the brahmaputra basin precipitation shows the highest dominance whereas abstraction shows a lower dominance in general the result suggests that that enso has the highest influence on gwl change followed by pdo nao and iod 4 discussion groundwater fed irrigation is crucial for food and water security in the igbm basin the contamination of shallow groundwater mostly in eastern india and bangladesh is a severe issue for the suitability of groundwater resources in the basin mukherjee et al 2015 this crisis is further intensified by excessive rates of groundwater abstraction mainly in northwest india indus basin the eastern part of ganges basin bengal basin and southeast bangladesh meghna basin rodell et al 2009 macdonald et al 2016 bhanja et al 2019 deep groundwater withdrawal is a common practice world bank 2010 in the basin to avoid the shallow contaminated i e mostly saline and arsenic groundwater and or to cope with the continuous drop in water levels ravenscroft et al 2009 fendorf et al 2010 famiglietti 2014 macdonald et al 2016 thus in recent times there has been a decrease in the number of shallow irrigation wells and an increase in deep irrigation wells 15 times higher annual output than shallow irrigation wells minor irrigation 2017 figure s15 this observation is in accordance with the findings of dominance analysis which shows higher groundwater abstraction from the deeper parts of the aquifer the influence of deeper groundwater abstraction is notable higher for the indus and meghna basi while intermediate for ganges basin fig 5 however in the bengal basin area within the ganges basin deep groundwater abstraction is significantly higher than rest of the ganges basin macdonald et al 2015 2016 besides groundwater abstraction studies also report that canal leakage macdonald et al 2015 2016 bonsor et al 2017 is significant for the ganges basin leakage in upper part 50 of the total canals flow and indus basin wwf 2015 bonsor et al 2017 ò dochartaigh et al 2019 a trade off between canal water leakage and abstraction leads to the spatial variation in gwl fluctuation in the different segments of canal command areas macdonald et al 2015 although the canal leakage induced recharge may be significant for the shallow groundwater 30 m in contrast deeper groundwater 30 m and groundwater away from a canal command area are less affected by canal leakage ò dochartaigh et al 2019 the complexity of the system is further exacerbated by the low cost i e cost associated with electricity high efficiency pump etc of irrigation in the region irrigation return flows furthermore the winter time precipitations provide critical mass mostly in the indus basin contributing to transient groundwater storage and a crucial water source for the winter crops e g wheat and millet hence winter precipitation also has a major role in groundwater level change in the northwest parts of the basin thus we conclude that the observed correlation pattern between precipitation and groundwater in the indus basin results from the various drivers governing a highly complex recharge process the results i e higher dominance of groundwater abstraction at greater depths in the indus basin obtained from the dominance analysis when combined with the findings of lag analysis i e higher lag values in northwest india suggests a relatively delayed buffering potential of precipitation on deeper groundwater in the sub basin in the 31 year time scale of this study on the contrary the meghna basin in bangladesh suffered from high groundwater abstraction macdonald et al 2016 fig 1d while receiving high annual precipitation the high influence of precipitation and abstraction fig 5 in the meghna basin may lead to higher direct and induced recharge which could explain lower values of lag in the meghna basin in a hydro climatic system without human interference it is expected that the climate and recharge signal would attenuate with increasing depth considering the physical constraints and longer travel time mostly in the unconfined aquifers the dps would show weaker climate signatures at an extended time period this is mainly because of the restrictions provided by the confining layers to the direct infiltration in deep aquifers moreover the longer flow path followed by the groundwater to bypass the confining layers could also be a reason for this delayed response in deeper parts in contrast the irregular response shown in the wavelet coherence spectrums could be related to the accelerated groundwater vertical flux caused by an enhanced induced hydraulic gradient and the associated disruption in the natural groundwater flow in the deep groundwater systems due to deep groundwater pumping si s2 we also note that the findings presented in the study on deeper groundwater are less reliable following the lack of hydro stratigraphic knowledge lack of temporal data on evenly distributed deep gwls and the uncertainty associated with the wavelet analysis see assumptions limitations and uncertainty thus the natural dynamics of the hydro climatic cycle gets obscured when groundwater abstraction through pumping is introduced furthermore irrigation return flow bhanja et al 2019 mass loading effects and canal leakage macdonald et al 2016 bonsor et al 2017 2015 which have a significant contribution to the groundwater recharge in the parts of the basin maybe partially accountable for modifying the natural linkage between climate and groundwater the results presented here are sensitive to the spatio temporal coverage of the existing data and availability of data on other important drivers furthermore additional information on groundwater use canal leakage is required to truly isolate the anthropogenic effects and the climate effects on groundwater future studies with a more rigorous hypothesis guided approach based on better spatial and temporal datasets may enhance our understanding of the significance of the possible contributors in the human natural complex system a case needs to be made to develop the data models and predictive understanding necessary to build insights on deeper groundwater flow at a large scale based on rigorous quantitative analyses the findings of the study could be used to understand the groundwater climate linkage under the influence of human interventions in other densely populated basins of the world researchers may increase the resolution of the study with higher resolution verifiable information on the irrigation amount sub surface lithology and ideally utilizing output from more advanced global models for a focused area 5 conclusions in the study we used lag correlation wavelet analysis and dominance analysis to understand the extent of climatic impact on the groundwater at different aquifer depths under the anthropogenic influence the findings from the dominance analysis are mostly in agreement with the lag and wavelet analysis and suggest stronger dominance of abstraction precipitation enso pdo in the study area in general groundwater abstraction particularly from deeper depths dominates in indus and meghna basin while precipitation dominates in the brahmaputra and meghna basin the influence of precipitation and abstraction are moderate for the ganges basin we also find that precipitation affects groundwater at various aquifer depths differently and climate oscillations from the pacific ocean have a greater influence on groundwater than the oscillations from the atlantic ocean and the indian ocean however results suggest irregular response between gwls and global climate patterns in areas where human interferences dominate over the natural recharge processes thus we surmise that groundwater pumping could provide an important role in modifying the link between hydro climate and groundwater despite the associated caveats and data limitations discussed above our study emphasizes the climatic and the human induced effects on different depths of the aquifer particularly the adverse effects on greater depths due to increasing deep groundwater abstraction thus efficient monitoring of deep groundwater abstraction is required to ensure its sustainability and usability in the present and future ravenscroft et al 2013 the findings may be helpful in constructing regional strategies and relevant policies related to prevailing high groundwater withdrawals in the region data availability statement all the data used in this study are freely available groundwater level data are retrieved from the repositories of the central ground water board http cgwb gov in gw data access html of the government of india and bangladesh water development board https www bwdb gov bd of the government of bangladesh precipitation data for india and bangladesh was available from the india meteorological department imd http www imd gov in welcome 20to 20imd welcome php and climatic research unit cru ts v 4 01 https crudata uea ac uk cru data hrg respectively climate indices data are available on the national oceanic and atmospheric administration noaa website https psl noaa gov data climateindices minor irrigation based tube well data available at the open government data ogd platform india https data gov in search site query tubewell minor irrigation census reports of india http mowr gov in schemes projects programmes schemes irrigation census and minor irrigation survey reports of bangladesh https badc portal gov bd sites default files files badc portal gov bd page c23bdffd 22fd 4f15 8fc4 b1fc7a91a36a 2020 09 01 14 15 bbb411c861df9a62fdafcccbd8025192 pdf groundwater abstraction data are available from the dynamic ground water resources of india by cgwb http cgwb gov in dynamic gw resources html and aquastat fao s global information system on water and agriculture country profile india http www fao org aquastat en countries and basins country profiles country ind and bangladesh http www fao org aquastat en countries and basins country profiles country bgd author contribution statement p m and a m designed the study p m performed background analyses and simulations p m did the study under the supervision of a m and advice from s n b a r g data management and processing were performed by pm with inputs from s n b r k r d s and a z helped with the data retrieval p m performed the statistical analyses with inputs from a r g and s c p m wrote the manuscript with inputs from a m a r g s n b s s r k r a z d s and s c declaration of competing interest the authors declare that they have no competing interests acknowledgments we acknowledge agi project iit sric gg cse agi 2013 14 201 from ministry of human resource development mhrd govt of india we also acknowledge the national oceanic and atmospheric administration noaa central ground water board ministry of water resources government of india and bangladesh water development board government of bangladesh for the availability of climate indices data water level measurement data for india and bangladesh respectively we also acknowledge precipitation data provided by the indian meteorological department imd and climatic research unit cru ts v 4 01 the authors acknowledge the use of the matlab version 2018b eviews software version 9 rstudio software version 1 2 5001 and ferret http ferret pmel noaa gov ferret pacific marine environmental laboratory noaa program for analysis the authors also acknowledge arcgis software version 10 2 1 origin software version 2015 for some of the graphics in this paper the authors are very much thankful to palash debnath for his valuable suggestions special thanks to srimanti dutta gupta kousik das at iit kharagpur for help with data analyses supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2021 103856 appendix supplementary materials image application 1 
347,understanding transport and biogeochemical turnover processes of solutes in riverine systems is vital in order to preserve aquatic and terrestrial ecosystem health the hyporheic zone is the well studied interface between stream water and underlying aquifer it acts as a hydrodynamically driven bioreactor i e its reactivity is strongly controlled by its dynamic subsurface flow patterns fibre optic sensing techniques and in particular fluorescence spectroscopy using a suite of fluorescent substances can provide unique information about physical chemical and biological processes occurring in the hyporheic zone however current devices for in situ fluorescence measurements in sediment pore water are insufficient in measurement reproducibility due to significant shortcomings of their mechanical design therefore a novel design concept for a robust fluorescence sensor system performing reproducible real time in situ fluorescence measurements in sediment pore water was developed the holistic design concept includes the mechanical protection of the fibre optic tip constant optical properties of the measurement environment significantly reduced turbidity effects and de risk the formation of interfering gas bubbles the study demonstrates the robustness and suitability of the prototype for in situ fluorescence measurements in laboratory and field using the fluorescence dye uranine the presented proof of concept for the fluorescence sensor system may provide a fundamental basis for a sensor system performing any fluorescence spectroscopy analysis in sediment pore water in real time keywords fluorescent tracer hyporheic zone fibre optic sensor uranine fluorescein sediment pore water 1 introduction understanding surface water groundwater interactions in streams i e transport processes as well as biogeochemical turnover processes in the streambed sediment is key to assess the fate of solutes in riverine systems and hence overall water quality boano et al 2014 hester and gooseff 2010 lewandowski et al 2019 the hyporheic zone hz i e the streambed sediment where surface water and groundwater mix has been well reported to act as a hydrodynamically driven bioreactor that may have a significant capacity to remove pollutants findlay 1995 lewandowski et al 2011 schaper et al 2018 assessing and understanding the reactivity of streams and their hz s requires an appropriate investigation of subsurface transport processes i e identification of hyporheic flow paths hyporheic flow velocities and quantification of hyporheic exchange fluxes abbott et al 2016 molins and knabner 2019 stonedahl et al 2010 however due to the hz s temporally and spatially heterogeneous properties its flow paths flow velocities and exchange flux determination is hitherto a key challenge which likewise hampers the investigation of biogeochemical processes and riverine freshwater system functioning lewandowski et al 2019 the current state of the art approaches for hyporheic flow path determination hyporheic flow velocity measurement and exchange flux investigations are based on tracers such as temperature salt and dyes among others brunner et al 2017 the main drawbacks are retardation effects density effects and limited temporal and spatial resolution lewandowski et al 2011a banks et al 2018 leibundgut et al 2009 ongoing research is therefore focusing more and more on fibre optic sensor techniques and in particular on fluorescence spectroscopy in general fluorescence describes the spontaneous emission of radiation for instance of visible light by a substance shortly after having absorbed radiation fluorescent substances have been reported to be an effective tracer in many environmental and medical disciplines due to their real time monitoring and sensitive measurement capabilities shanafield et al 2018 rogers and poziomek 1996 in regard to hydrological questions fluorescent tracers are beneficial as there is a vast range of non toxic conservative substances such as uranine in order to study physical transport processes flow path flow velocity flux ghodrati et al 2000 garrido et al 2001 as well as reactive substances such as resazurin which are sensitive to ideally one specific condition for instance microbial activity haggerty et al 2008 knapp et al 2017 using a suite of fluorescent tracers may be an effective tool to investigate different processes occurring in the investigated system abbott et al 2016 bosch et al 2007 current fibre optic sensors for fluorescence measurements in sediment pore water may not provide the expected data quality as a result of significant shortcomings regarding their mechanical design in situ fibre optic sensor systems consist of a fibre optic placed in a stainless steel sleeve that is directly inserted into the streambed sediment without any further mechanical protection ghodrati 1999 garrido et al 2000 the measurement using the aforementioned systems may be very error prone and may be hardly reproducible especially for lower concentrations for three major reasons first the tip of the fibre optic is scratched when being inserted into the sediment which consequently causes random optical effects second the optical properties of the pore volume as well as the pore volume itself in front of the fiber optics tip may alter randomly either due to unintentional moves of the sensor system due to unsteady subsurface flow processes or due to moving bedforms third turbidity may undergo temporal and spatial fluctuations and likewise arbitrarily affect the measurement the aim of the present study is to develop and test a robust mechanical design for a fluorescence sensor system to perform reproducible real time in situ measurements in sediment pore water at a high temporal and spatial resolution the design criteria for the novel sensor system are i mechanical protection of the fibre optics tip ii constant optical properties of the background and iii negligible turbidity effects the objective is to prove the concept by demonstrating the prototypes functionality under laboratory and field conditions 2 materials and methods 2 1 general concept the general concept of the novel fluorescence sensor system for in situ measurements in sediment pore water was to utilise an in situ measuring chamber rather than performing measurements directly in the sediment in brief a robust stainless steel pipe with a small diameter in which several measuring chambers are placed at different depth is inserted into the streambed shortly before a measurement sediment pore water is automatically pumped through a multi layered filter into the measuring chamber in order to reduce its turbidity the specific excitation spectra of the fluorescent substance of interest is emitted by a led light source and transmitted with the means of a fibre optic cable to the respective measuring chamber the specific excitation light may excite the fluorescent substance dissolved in the sampled pore water the characteristic emission spectra of the excited fluorescent substance is carried back through the same fibre optic cable to the spectrometer the spectrometer records the emission light intensity of the fluorescent substance as a function of time after the measurement the sampled pore water is automatically forced out into the sediment in this way any fluorescence spectroscopy analysis can be performed in real time in sediment pore water 2 2 design and operational principles the fluorescence sensor system consists of the fluorescence sensor the hydraulic valve system the pump automation unit and an outdoor suitcase containing a spectrometer qe65000 ocean optics ostfildern germany a blue led light source ls 450 ocean optics ostfildern germany and an electronic control unit fig 1 c the spectrometer and the led light source are connected to the two single legs of a bifurcated fibre bundle respectively the common leg of the bifurcated fibre bundle is connected to the respective polymer fibre optics from the measuring chamber units of each sensor at the right side of the suitcase the fluorescence sensor prototype is composed of two measuring chamber units that are mounted inside a 30 mm in diameter and 25 cm long stainless steel pipe at 10 cm distance fig d 8 each measuring chamber unit consists of a 3d printed measuring chamber a multi layered filter a polymer fibre optic and a deformable silicone membrane fig 1b the self engineered measuring chamber unit is the core innovation of the proposed sensor design combining three crucial key features first the measuring chamber provides a constant homogeneous measuring environment i e same volume same reflection properties and a mechanical protection of the fibre optics tip second the multi layered filter greatly reduces turbidity effects which is one of the greatest challenges in fluorescence measurements in fact previous investigations reported that 0 5 to 1 µm filtered water samples do not require any further correction of turbidity effects leibundgut et al 2009 in addition a wide range of different filters i e in material and mesh sizes is available so that the filters can specifically be chosen and arranged that makes the presented multi layered filter system highly adaptable to different conditions fig 1b the multi layered filter for all experiments conducted in the present study consisted of three layers with mesh sizes of 500 µm 60 µm and 34 µm respectively third sediment pore water is sampled and measured in situ while being operated remotely without the use of complex components in brief the stainless steel pipe of the sensor is filled with water fig 1a to sample sediment pore water the internal pressure within the pipe has to be lower than the pressure of the sediment pore water p s e n s o r p p o r e w a t e r the internal pressure in the pipe is reduced by the pump automation unit which is hydraulically connected to the sensor via a hose that also carries the polymer fibre optics of the measuring chamber units the lower pressure in the pipe unfolds the silicone membrane s so that the pore water is pumped through the multi layered filter f into the measuring chamber filling the entire volume of the measuring chamber f c s to empty the measuring chamber after the measurement the internal sensor pressure has to be higher than the sediment pore water pressure p s e n s o r p p o r e w a t e r the silicone membrane is compressed and thus pumps the pore water back into the sediment the velocity of pumping pore water in and out is adjusted using the hydraulic valve system fig 1c the hydraulic valve system consists of two valves connected in parallel a one way valve allowing to fill and to increase the internal pressure of the pipe quickly and one throttle valve in order to control the backflow of the pipe s internal water i e its internal pressure in particular pumping pore water into the measuring chamber is conducted at a low speed assuring the integrity of the pore water flow field in the sediment in contrast pumping pore water back into the sediment is carried out at a slightly higher speed in order to clean i e backflush the multi layered filter pumping pore water into the measuring chamber introduces a time lag on the according measurements the total time lag ranges within a few minutes 2 3 sensor preparation calibration and data analysis the sensor preparation aims to reduce the risk of gas bubble formation during a measurement as these adversely affect spectroscopic measurements the risk of the occurrence of gas bubbles within the measuring chamber is reduced due to three features first the multi layered filter prevents gas bubbles larger than its mesh size from entering and leaving the measuring chamber due to surface tension the second measure involves filling the measuring chambers with water and degassing its dissolved gases with a vacuum pump as sensor preparation procedure before an experiment the degassing of the water in the measuring chamber under very low pressures down to the boiling point of water at room temperature aims to remove all existing gas bubbles so that they cannot facilitate seed germination i e gas bubble formation during the course of a measurement lastly the hydraulic valve system allows the pumping rate to be adjusted with high sensitivity preventing sudden excessive vacuum pressures and gas bubble formation to calibrate the fluorescence sensor system the emission light intensity of several tracer stream water solutions with known concentrations were measured stream water was used to have the same matrix effects as they occur during in situ measurements in particular the fluorescent tracer uranine and the stream water from erpe river an urban lowland stream in berlin germany were used for calibration uranine has been widely used in surface water and groundwater tracer studies due to its excellent optical properties ph stability and non toxicity leibundgut et al 2009 uranine s maximum absorption peaks are at 415 nm and 495 nm its maximum emission peaks are at 513 nm and 515 nm ghodrati 1999 for calibration the fluorescence sensor was placed in a cylinder filled with stream water the whole set up was protected from light as uranine is highly sensitive to uv radiation i e it degrades the calibration procedure consisted of consecutively applying approx 100 ml of a 20 mg l 1 uranine stock solution to the cylinder filled with stream water so that uranine concentrations were measured from low to high emission light intensities of uranine stream water solutions between 0 µg l 1 pure stream water and 1954 µg l 1 were measured in triplicates i e the measuring chamber was emptied and refilled for each measurement in general all liquids were given sufficient time in order to acclimatize to room temperature moreover ph and temperature were regularly recorded for each experiment using a handheld ph meter sentix 41 wtw germany the measured intensities were recorded with the software oceanview ocean optics ostfildern germany the recorded spectra were integrated between the wavelengths 505 to 580 nm detailed justification in appendix a and normalized with the respective integration time used for each measurement further corrections for temperature or ph differences were not necessary for three major reasons first the present study aims at providing a proof of concept and thus a qualitative data analysis is sufficient second the temperature and ph were kept constant during the laboratory experiments and it is known from previous investigations that they are quite constant within the sediment during the day third the fluorescence intensity changes of uranine for the ph and temperature changes during the presented experiments are insignificant lemke et al 2013 during calibration and laboratory experiment in the sandbox fluorescence intensities were additionally measured with a handheld fluorometer aquafluor handheld fluorometer turner designs usa the handheld fluorometer was calibrated using two calibration solutions namely a blank pure stream water and a 2 mg l 1 uranine stream water solution 2 4 experimental setup and measurement procedure for laboratory and field the robustness and proper functioning of the fluorescence sensor system was tested in the laboratory with a sediment filled box with a total length of 40 cm in which different flow rates can be set a detailed description about the dimensions and operation of the sandbox can be found in lewandowski et al 2011a the laboratory experiment was conducted with actual stream water and streambed sediment of erpe river saturated hydraulic conductivities k of the sediment used analysed at 10 c using a ksat device meter germany ranged from 7 56 10 4 m s 1 to 1 01 10 3 m s 1 the average sediment porosity calculated from oven dried samples at 105 c for 96 h was 0 346 before the experiments the stream water was pumped in a circuit until the flow rate was constant in addition the stream water and the uranine solution used were given sufficient time to equilibrate to room temperature the use of a head difference between the inlet basin and outlet basin of 4 cm resulted in a total outflow of about 200 ml min 1 the effective cross sectional area at the outflow i e cross sectional area times sediment porosity was 103 cm 2 and was converted into a theoretical flow velocity of approximately 1 9 cm min 1 the fluorescence sensor was placed in the sediment at a distance of about 27 cm from the inlet basin the measurements were only carried out with the lower measuring chamber at a depth of 9 5 cm since the sandbox was not large enough to test both measuring chambers for the experiment 40 ml of a 200 mg l 1 uranine solution was injected into the inlet reservoir as a single slug the water of the sandbox was recirculated until a constant fluorescence intensity was measured fluorescence measurements were conducted approximately every three minutes whereby the pore water sampling i e pumping of pore water into the measuring chamber lasted 40 s in addition ph and temperature measurements were recorded regularly after the fluorescence sensor system had been tested in the laboratory a first field application was conducted to test whether the device was applicable under field conditions fig 2 the field experiment was conducted in a sandy side channel of erpe river lat 52 476578 long 13 625639 sediment characteristics at the sampling site were determined from sediment cores in previous investigations in brief 25 cm long sediment cores were taken with a hand auger inner diameter 9 cm and cut into 5 cm long sections which were transferred into ksat rings meter germany saturated hydraulic conductivity ranged between 8 06 10 6 and 8 95 10 5 m s 1 and average porosity was 0 18 0 02 furthermore a general detailed description on the hydrology and biogeochemistry of erpe river can be found in lewandowski et al 2011b the experimental setup consisted of two fluorescence sensors installed at a distance of 3 cm from the injection point one downstream and one perpendicular to the main flow direction of the stream and 123 cm apart from the river bank fig c 7 the measuring chambers of both sensors were located at a depth of 5 cm and 15 cm with the inlet i e the filters of the measuring chambers facing the injection site which was located at a depth of 4 5 cm additionally a handheld ph and temperature sensor sentix 41 wtw germany was placed in the flow direction behind each fluorescence sensor for the experiment 9 ml of a 20 mg l 1 uranine solution were injected at a constant rate of 1 ml min 1 for 9 min using a syringe pump ne 1600 new era pump systems inc farmingdale u s a and a hplc tube peek id 0 03 in sigma aldrich us connected via swagelok fittings swagelok us to a syringe becton dickinson company us fluorescence measurements were performed approximately every 10 min in addition water table as well as ph and temperature were recorded regularly the experiment was considered to be finished once the initial background fluorescence spectra that had been measured before the start of the experiment was measured for both measuring chambers 3 results and discussion 3 1 general sensor performance the calibration of the fluorescence sensor was conducted with uranine stream water solutions ranging between 0 µg l 1 i e pure stream water and 1954 µg l 1 the intensities measured for each solution were consistent not only for a single measuring chamber but also between measuring chambers fig 3 a a detailed view reveals that concentrations as low as 16 µg l 1 can be clearly distinguished from the background fluorescence of pure stream water fig 3b for comparison the detection limit for uranine with the handheld fluorometer aquafluor from turner designs is 0 4 µg l 1 which translates in about 4 µg l 1 as quantification limit however under ideal test conditions uranine concentrations can theoretically be detected down to 0 002 µg l 1 with modern benchtop spectrofluorometers gerke et al 2013 kranjc 1997 moreover the measurement results demonstrate excellent repeatability which was demonstrated by measuring the 89 µg l 1 solution black arrow in fig 3c this solution has subsequently been measured after the 1954 µg l 1 solution and agrees with the other measurements this result also shows that the proposed water sampling concept of the fluorescence sensor system works appropriately i e exchanging the volume of the measuring chamber works sufficiently well so that subsequent measurements are not affected by the previous one the spectra of the calibration results reveals the occurrence of background fluorescence in the magnitude of 2500 counts per second between approximately 520 and 560 nm which is particularly noticeable at lower uranine concentrations in contrast the background fluorescence at higher uranine concentrations is not distinguishable from the expected emission peak of uranine at 515 nm measurements of the empty measuring chamber demonstrate that this fluorescence signal can be attributed to the measuring chamber itself fig b 6 in fact the measuring chamber is made of the photopolymer black resin which is a commonly used substance for 3d printing therefore a reasonable explanation for the background fluorescence trend may be that at high uranine concentrations the excitation light is mainly absorbed and likewise mainly excites the uranine molecules rather than the measuring chamber in other words the higher the uranine concentration the lower the probability that the excitation light will reach the measuring chamber and thus excites it an additional effect may be that the emission light of uranine may even outshine the emission light of the measuring chamber at a certain uranine concentration in the future background fluorescence can be eliminated by using a different material to manufacture the measuring chamber the investigated calibration range is well within the linear range reported for uranine which is from 1 µg l 1 to 2 mg l 1 gerke et al 2013 a linear regression analysis of the normalised intensity and the actual uranine concentration in stream water results in almost the same gradient for both measuring chambers fig 3c in addition all measurements show a low variance which also leads to a high r 2 value of 0 9997 i e the coefficient of determination for both linear regressions the low scattering of the measurements is mainly caused by measurement errors using the handheld fluorometer as well as by manufacturing differences among the measuring chambers and the polymer fibre optics the calibration results show that the measurements with the developed fluorescence sensor are reproducible and consistent for the investigated calibration solutions despite the decreasing background fluorescence of the measuring chamber at higher uranine concentrations 3 2 proof of concept in situ the result from the almost five hour lasting sandbox experiment with actual streambed sediment and stream water in which measurements were taken every three minutes shows a consistent decreasing sinusodial trend with no distinct measurement outliers fig 4 the periodicity of the graph indicates the turnaround time of the injected uranine plume which was about 35 min using the calculated flow velocity of 1 9 cm min 1 results in an effective flow path length of 66 5 cm which is reasonable for a total sandbox length of 40 cm and some storage time in the inlet and outlet basins overall the sandbox experiment clearly proves that the design concept of the developed sensor works well in particular this result demonstrates that i the multi layered filter of the fluorescence sensor did not clog over time and thus confirming the concept of the hydraulic valve system ii the optical properties within the measuring chamber remained sufficiently constant i e no disturbing gas bubbles no mechanical damage of the fibre optics tip and no interfering turbidity effects the field experiment lasted two hours with measurements being taken approximately every 10 min the water table dropped from 17 cm to 15 cm during the experiment but this change was assumed to have minimal effect on the flow field furthermore the ph and temperature t in the subsurface varied little during the experiment ph 7 182 0 044 t 14 34 0 11 c measured fluorescence intensities were converted into uranine concentrations using the respective fluorescence intensity uranine calibration curves fig 3c the injected uranine solution was clearly measured at a depth of 5 cm at both sensors with the downstream sensor i e in surface water flow direction showing a slightly higher and more enduring signal than the sensor perpendicular to the surface water flow direction fig 5 the results indicate that hyporheic flow is more intense in the direction of the downgradient sensor than of the sensor perpendicular to surface water flow in contrast no distinct signal was detected at 15 cm depth at both sensors suggesting that there is no downward hyporheic flow at the field site and thus horizontal hyporheic flow predominates however there are currently only four measuring points around the injection port reliable flow path detection would require a much denser grid of measuring points around the injection port lewandowski et al 2011a and angermann et al 2012 presented setups with 24 or 36 sensors measuring temperature on a virtual cylinder around a heater to calculate flow directions in 3d the advantage of a fluorescent tracer compared to temperature as a tracer is the absence of retardation due to heat storage and absence of dispersion due to heat conduction thus the fluorescence signal should in principal be detectable over much larger distances than the 3 cm used with the heat pulse sensor after successful miniaturization of the fluorescence sensor a 2d grid with a horizontal spacing of several centimeters between sensors of 8 times 8 fluorescence sensors and a vertical spacing of 2 cm of 8 measuring chambers in each device would result in 512 measuring ports thereby the sediment distortion becomes less important with higher distances between the sensors the use of different fluorescent tracers would allow the simultaneous identification of several subsurface flow paths besides the detection of hyporheic flow directions and hyporheic flow paths the fluorescence sensor also allows the determination of hyporheic flow velocities to avoid an inhomogeneous distribution of the tracer plume during injection the fluorescent tracer was injected at a low velocity and the injection lasted 9 min we use the center of the injection period as start time of the tracer injection the distance from the injection port to the downstream sensor was 3 cm however considering an injection volume of 9 ml a sediment porosity of 0 18 an undirected homogeneous injection an absence of hyporheic flow during injection and no mixing of the injected solution the pore water present in the sediment would result in a sphere with a radius of 2 28 cm around the injection port therefore the effective distance from the injection port to the downstream sensor was about 0 72 cm however in reality the volume impacted by the injection is larger because of mixing more disk shaped because hydraulic conductivity is usually 10 times higher in horizontal direction than in vertical direction and distorted in flow direction because of hyporheic flow we additionally calculated the area below the normalized breakthrough curve of the uranine concentration and calculated the time when 50 of the tracer plume passed the sensor the calculated hyporheic flow velocity considering the simple sphere shaped plume of the injected uranine was about 0 016 m h 1 we did not perform a similar calculation for the sensor perpendicular to the direction of flow because we assume that dispersion of the tracer plume during injection is the main transport mechanism in the direction of that sensor in addition to the flow pattern fluorescent tracers could also be used to elucidate the biogeochemical milieu along the flow paths or the predominant microbial processes for this purpose reactive tracers are needed instead of conservative tracers i e tracers that change their fluorescence properties along the flow paths depending on the predominant processes overall the recorded measurements are consistent and indicate that there were no measurement outliers over the course of the experiment this field deployment clearly demonstrates the robustness and proper working of the developed fluorescence sensor system under field conditions and thus provides its proof of concept 4 conclusion and outlook the present study demonstrates the proof of concept for a robust fluorescence sensor system that performs reproducible in situ fluorescence measurements in sediment pore water with high temporal and spatial resolution in particular it has been shown that fluorescence measurements for a given solution were well reproducible both for the measuring chamber unit itself as well as among other measuring chamber units moreover the robustness of the fluorescence sensor system has been validated in a five hour laboratory experiment at a three minute sampling interval and in a two hour field experiment at a ten minute sampling interval neither measurement outliers nor clogging of filters occurred in conclusion the decisive key for this well functioning prototype lies in its holistic design concept which consists of i the mechanical protection of the fibre optics tip and the assurance of constant optical properties of the measurement background by means of a measuring chamber unit and ii the avoidance of turbidity effects as well as the prevention of gas bubble formation within the measuring chamber by means of a multi layered filer in combination with a hydraulic valve system future device development will include further miniaturization full automation of its operation and integration of additional light sources for the investigation of other fluorescent substances the presented robust fluorescence sensor system has proven well suitable for fluorescence measurements in sediment pore water and therefore opens up the myriad applications of fluorescence spectroscopy in particular the extension of the range of measurable fluorescent substances i e the integration of further light sources will contribute to the investigation of different physical chemical and biological properties in saturated porous media both in technical systems e g in bankfiltration and sandfilters for drinking water production or in sandfilters in sewage treatment plants and in natural systems e g in sediments of streams lakes and oceans beyond that such an adapted fluorescence sensor system will enable researchers to measure time series of the well established valuable excitation emission scans in situ and in real time which has not been possible so far such high quality fluorescence measurements in sediment pore water will pave the way for novel predictive modelling towards a solid understanding of the functioning of ecosystems and technical systems credit authorship contribution statement anja höhne conceptualization methodology validation formal analysis writing original draft writing review editing karl mellerowicz conceptualization methodology validation writing review editing oliver lischtschenko formal analysis writing review editing jörg lewandowski conceptualization methodology validation writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a emission light intensity analysis the analysis of the emission light intensity is done by normalizing all intensities measured by their respective integration time used in the next step the emission light intensities are integrated for the range of interest i e the range where the maximum emission light signal of the substance of interest is expected for uranine the normalized spectra between 505 and 580 nm was integrated and divided by its according sum of measurements the spectra has been selected so that it includes the fluorescence background signal from the measuring chamber since this effect cannot be explicitly differentiated from the uranine signal appendix b background fluorescence of the measuring chamber the occurrence of background fluorescence particularly at low uranine concentrations may be caused by the measuring chamber itself to investigate the source of the background fluorescence the emission light spectra of the empty measuring chambers was measured using the same led light source as for the experiments with uranine fig b 6 the integration time was set to 400 ms and the set up was protected from light the fluorescence spectra of the measuring chamber itself shows a signal between about 512 and 580 nm the result thus demonstrates that the background fluorescence can be attributed to the measuring chamber unit itself appendix c field experiment setup appendix d technical drawing of the sensor 
347,understanding transport and biogeochemical turnover processes of solutes in riverine systems is vital in order to preserve aquatic and terrestrial ecosystem health the hyporheic zone is the well studied interface between stream water and underlying aquifer it acts as a hydrodynamically driven bioreactor i e its reactivity is strongly controlled by its dynamic subsurface flow patterns fibre optic sensing techniques and in particular fluorescence spectroscopy using a suite of fluorescent substances can provide unique information about physical chemical and biological processes occurring in the hyporheic zone however current devices for in situ fluorescence measurements in sediment pore water are insufficient in measurement reproducibility due to significant shortcomings of their mechanical design therefore a novel design concept for a robust fluorescence sensor system performing reproducible real time in situ fluorescence measurements in sediment pore water was developed the holistic design concept includes the mechanical protection of the fibre optic tip constant optical properties of the measurement environment significantly reduced turbidity effects and de risk the formation of interfering gas bubbles the study demonstrates the robustness and suitability of the prototype for in situ fluorescence measurements in laboratory and field using the fluorescence dye uranine the presented proof of concept for the fluorescence sensor system may provide a fundamental basis for a sensor system performing any fluorescence spectroscopy analysis in sediment pore water in real time keywords fluorescent tracer hyporheic zone fibre optic sensor uranine fluorescein sediment pore water 1 introduction understanding surface water groundwater interactions in streams i e transport processes as well as biogeochemical turnover processes in the streambed sediment is key to assess the fate of solutes in riverine systems and hence overall water quality boano et al 2014 hester and gooseff 2010 lewandowski et al 2019 the hyporheic zone hz i e the streambed sediment where surface water and groundwater mix has been well reported to act as a hydrodynamically driven bioreactor that may have a significant capacity to remove pollutants findlay 1995 lewandowski et al 2011 schaper et al 2018 assessing and understanding the reactivity of streams and their hz s requires an appropriate investigation of subsurface transport processes i e identification of hyporheic flow paths hyporheic flow velocities and quantification of hyporheic exchange fluxes abbott et al 2016 molins and knabner 2019 stonedahl et al 2010 however due to the hz s temporally and spatially heterogeneous properties its flow paths flow velocities and exchange flux determination is hitherto a key challenge which likewise hampers the investigation of biogeochemical processes and riverine freshwater system functioning lewandowski et al 2019 the current state of the art approaches for hyporheic flow path determination hyporheic flow velocity measurement and exchange flux investigations are based on tracers such as temperature salt and dyes among others brunner et al 2017 the main drawbacks are retardation effects density effects and limited temporal and spatial resolution lewandowski et al 2011a banks et al 2018 leibundgut et al 2009 ongoing research is therefore focusing more and more on fibre optic sensor techniques and in particular on fluorescence spectroscopy in general fluorescence describes the spontaneous emission of radiation for instance of visible light by a substance shortly after having absorbed radiation fluorescent substances have been reported to be an effective tracer in many environmental and medical disciplines due to their real time monitoring and sensitive measurement capabilities shanafield et al 2018 rogers and poziomek 1996 in regard to hydrological questions fluorescent tracers are beneficial as there is a vast range of non toxic conservative substances such as uranine in order to study physical transport processes flow path flow velocity flux ghodrati et al 2000 garrido et al 2001 as well as reactive substances such as resazurin which are sensitive to ideally one specific condition for instance microbial activity haggerty et al 2008 knapp et al 2017 using a suite of fluorescent tracers may be an effective tool to investigate different processes occurring in the investigated system abbott et al 2016 bosch et al 2007 current fibre optic sensors for fluorescence measurements in sediment pore water may not provide the expected data quality as a result of significant shortcomings regarding their mechanical design in situ fibre optic sensor systems consist of a fibre optic placed in a stainless steel sleeve that is directly inserted into the streambed sediment without any further mechanical protection ghodrati 1999 garrido et al 2000 the measurement using the aforementioned systems may be very error prone and may be hardly reproducible especially for lower concentrations for three major reasons first the tip of the fibre optic is scratched when being inserted into the sediment which consequently causes random optical effects second the optical properties of the pore volume as well as the pore volume itself in front of the fiber optics tip may alter randomly either due to unintentional moves of the sensor system due to unsteady subsurface flow processes or due to moving bedforms third turbidity may undergo temporal and spatial fluctuations and likewise arbitrarily affect the measurement the aim of the present study is to develop and test a robust mechanical design for a fluorescence sensor system to perform reproducible real time in situ measurements in sediment pore water at a high temporal and spatial resolution the design criteria for the novel sensor system are i mechanical protection of the fibre optics tip ii constant optical properties of the background and iii negligible turbidity effects the objective is to prove the concept by demonstrating the prototypes functionality under laboratory and field conditions 2 materials and methods 2 1 general concept the general concept of the novel fluorescence sensor system for in situ measurements in sediment pore water was to utilise an in situ measuring chamber rather than performing measurements directly in the sediment in brief a robust stainless steel pipe with a small diameter in which several measuring chambers are placed at different depth is inserted into the streambed shortly before a measurement sediment pore water is automatically pumped through a multi layered filter into the measuring chamber in order to reduce its turbidity the specific excitation spectra of the fluorescent substance of interest is emitted by a led light source and transmitted with the means of a fibre optic cable to the respective measuring chamber the specific excitation light may excite the fluorescent substance dissolved in the sampled pore water the characteristic emission spectra of the excited fluorescent substance is carried back through the same fibre optic cable to the spectrometer the spectrometer records the emission light intensity of the fluorescent substance as a function of time after the measurement the sampled pore water is automatically forced out into the sediment in this way any fluorescence spectroscopy analysis can be performed in real time in sediment pore water 2 2 design and operational principles the fluorescence sensor system consists of the fluorescence sensor the hydraulic valve system the pump automation unit and an outdoor suitcase containing a spectrometer qe65000 ocean optics ostfildern germany a blue led light source ls 450 ocean optics ostfildern germany and an electronic control unit fig 1 c the spectrometer and the led light source are connected to the two single legs of a bifurcated fibre bundle respectively the common leg of the bifurcated fibre bundle is connected to the respective polymer fibre optics from the measuring chamber units of each sensor at the right side of the suitcase the fluorescence sensor prototype is composed of two measuring chamber units that are mounted inside a 30 mm in diameter and 25 cm long stainless steel pipe at 10 cm distance fig d 8 each measuring chamber unit consists of a 3d printed measuring chamber a multi layered filter a polymer fibre optic and a deformable silicone membrane fig 1b the self engineered measuring chamber unit is the core innovation of the proposed sensor design combining three crucial key features first the measuring chamber provides a constant homogeneous measuring environment i e same volume same reflection properties and a mechanical protection of the fibre optics tip second the multi layered filter greatly reduces turbidity effects which is one of the greatest challenges in fluorescence measurements in fact previous investigations reported that 0 5 to 1 µm filtered water samples do not require any further correction of turbidity effects leibundgut et al 2009 in addition a wide range of different filters i e in material and mesh sizes is available so that the filters can specifically be chosen and arranged that makes the presented multi layered filter system highly adaptable to different conditions fig 1b the multi layered filter for all experiments conducted in the present study consisted of three layers with mesh sizes of 500 µm 60 µm and 34 µm respectively third sediment pore water is sampled and measured in situ while being operated remotely without the use of complex components in brief the stainless steel pipe of the sensor is filled with water fig 1a to sample sediment pore water the internal pressure within the pipe has to be lower than the pressure of the sediment pore water p s e n s o r p p o r e w a t e r the internal pressure in the pipe is reduced by the pump automation unit which is hydraulically connected to the sensor via a hose that also carries the polymer fibre optics of the measuring chamber units the lower pressure in the pipe unfolds the silicone membrane s so that the pore water is pumped through the multi layered filter f into the measuring chamber filling the entire volume of the measuring chamber f c s to empty the measuring chamber after the measurement the internal sensor pressure has to be higher than the sediment pore water pressure p s e n s o r p p o r e w a t e r the silicone membrane is compressed and thus pumps the pore water back into the sediment the velocity of pumping pore water in and out is adjusted using the hydraulic valve system fig 1c the hydraulic valve system consists of two valves connected in parallel a one way valve allowing to fill and to increase the internal pressure of the pipe quickly and one throttle valve in order to control the backflow of the pipe s internal water i e its internal pressure in particular pumping pore water into the measuring chamber is conducted at a low speed assuring the integrity of the pore water flow field in the sediment in contrast pumping pore water back into the sediment is carried out at a slightly higher speed in order to clean i e backflush the multi layered filter pumping pore water into the measuring chamber introduces a time lag on the according measurements the total time lag ranges within a few minutes 2 3 sensor preparation calibration and data analysis the sensor preparation aims to reduce the risk of gas bubble formation during a measurement as these adversely affect spectroscopic measurements the risk of the occurrence of gas bubbles within the measuring chamber is reduced due to three features first the multi layered filter prevents gas bubbles larger than its mesh size from entering and leaving the measuring chamber due to surface tension the second measure involves filling the measuring chambers with water and degassing its dissolved gases with a vacuum pump as sensor preparation procedure before an experiment the degassing of the water in the measuring chamber under very low pressures down to the boiling point of water at room temperature aims to remove all existing gas bubbles so that they cannot facilitate seed germination i e gas bubble formation during the course of a measurement lastly the hydraulic valve system allows the pumping rate to be adjusted with high sensitivity preventing sudden excessive vacuum pressures and gas bubble formation to calibrate the fluorescence sensor system the emission light intensity of several tracer stream water solutions with known concentrations were measured stream water was used to have the same matrix effects as they occur during in situ measurements in particular the fluorescent tracer uranine and the stream water from erpe river an urban lowland stream in berlin germany were used for calibration uranine has been widely used in surface water and groundwater tracer studies due to its excellent optical properties ph stability and non toxicity leibundgut et al 2009 uranine s maximum absorption peaks are at 415 nm and 495 nm its maximum emission peaks are at 513 nm and 515 nm ghodrati 1999 for calibration the fluorescence sensor was placed in a cylinder filled with stream water the whole set up was protected from light as uranine is highly sensitive to uv radiation i e it degrades the calibration procedure consisted of consecutively applying approx 100 ml of a 20 mg l 1 uranine stock solution to the cylinder filled with stream water so that uranine concentrations were measured from low to high emission light intensities of uranine stream water solutions between 0 µg l 1 pure stream water and 1954 µg l 1 were measured in triplicates i e the measuring chamber was emptied and refilled for each measurement in general all liquids were given sufficient time in order to acclimatize to room temperature moreover ph and temperature were regularly recorded for each experiment using a handheld ph meter sentix 41 wtw germany the measured intensities were recorded with the software oceanview ocean optics ostfildern germany the recorded spectra were integrated between the wavelengths 505 to 580 nm detailed justification in appendix a and normalized with the respective integration time used for each measurement further corrections for temperature or ph differences were not necessary for three major reasons first the present study aims at providing a proof of concept and thus a qualitative data analysis is sufficient second the temperature and ph were kept constant during the laboratory experiments and it is known from previous investigations that they are quite constant within the sediment during the day third the fluorescence intensity changes of uranine for the ph and temperature changes during the presented experiments are insignificant lemke et al 2013 during calibration and laboratory experiment in the sandbox fluorescence intensities were additionally measured with a handheld fluorometer aquafluor handheld fluorometer turner designs usa the handheld fluorometer was calibrated using two calibration solutions namely a blank pure stream water and a 2 mg l 1 uranine stream water solution 2 4 experimental setup and measurement procedure for laboratory and field the robustness and proper functioning of the fluorescence sensor system was tested in the laboratory with a sediment filled box with a total length of 40 cm in which different flow rates can be set a detailed description about the dimensions and operation of the sandbox can be found in lewandowski et al 2011a the laboratory experiment was conducted with actual stream water and streambed sediment of erpe river saturated hydraulic conductivities k of the sediment used analysed at 10 c using a ksat device meter germany ranged from 7 56 10 4 m s 1 to 1 01 10 3 m s 1 the average sediment porosity calculated from oven dried samples at 105 c for 96 h was 0 346 before the experiments the stream water was pumped in a circuit until the flow rate was constant in addition the stream water and the uranine solution used were given sufficient time to equilibrate to room temperature the use of a head difference between the inlet basin and outlet basin of 4 cm resulted in a total outflow of about 200 ml min 1 the effective cross sectional area at the outflow i e cross sectional area times sediment porosity was 103 cm 2 and was converted into a theoretical flow velocity of approximately 1 9 cm min 1 the fluorescence sensor was placed in the sediment at a distance of about 27 cm from the inlet basin the measurements were only carried out with the lower measuring chamber at a depth of 9 5 cm since the sandbox was not large enough to test both measuring chambers for the experiment 40 ml of a 200 mg l 1 uranine solution was injected into the inlet reservoir as a single slug the water of the sandbox was recirculated until a constant fluorescence intensity was measured fluorescence measurements were conducted approximately every three minutes whereby the pore water sampling i e pumping of pore water into the measuring chamber lasted 40 s in addition ph and temperature measurements were recorded regularly after the fluorescence sensor system had been tested in the laboratory a first field application was conducted to test whether the device was applicable under field conditions fig 2 the field experiment was conducted in a sandy side channel of erpe river lat 52 476578 long 13 625639 sediment characteristics at the sampling site were determined from sediment cores in previous investigations in brief 25 cm long sediment cores were taken with a hand auger inner diameter 9 cm and cut into 5 cm long sections which were transferred into ksat rings meter germany saturated hydraulic conductivity ranged between 8 06 10 6 and 8 95 10 5 m s 1 and average porosity was 0 18 0 02 furthermore a general detailed description on the hydrology and biogeochemistry of erpe river can be found in lewandowski et al 2011b the experimental setup consisted of two fluorescence sensors installed at a distance of 3 cm from the injection point one downstream and one perpendicular to the main flow direction of the stream and 123 cm apart from the river bank fig c 7 the measuring chambers of both sensors were located at a depth of 5 cm and 15 cm with the inlet i e the filters of the measuring chambers facing the injection site which was located at a depth of 4 5 cm additionally a handheld ph and temperature sensor sentix 41 wtw germany was placed in the flow direction behind each fluorescence sensor for the experiment 9 ml of a 20 mg l 1 uranine solution were injected at a constant rate of 1 ml min 1 for 9 min using a syringe pump ne 1600 new era pump systems inc farmingdale u s a and a hplc tube peek id 0 03 in sigma aldrich us connected via swagelok fittings swagelok us to a syringe becton dickinson company us fluorescence measurements were performed approximately every 10 min in addition water table as well as ph and temperature were recorded regularly the experiment was considered to be finished once the initial background fluorescence spectra that had been measured before the start of the experiment was measured for both measuring chambers 3 results and discussion 3 1 general sensor performance the calibration of the fluorescence sensor was conducted with uranine stream water solutions ranging between 0 µg l 1 i e pure stream water and 1954 µg l 1 the intensities measured for each solution were consistent not only for a single measuring chamber but also between measuring chambers fig 3 a a detailed view reveals that concentrations as low as 16 µg l 1 can be clearly distinguished from the background fluorescence of pure stream water fig 3b for comparison the detection limit for uranine with the handheld fluorometer aquafluor from turner designs is 0 4 µg l 1 which translates in about 4 µg l 1 as quantification limit however under ideal test conditions uranine concentrations can theoretically be detected down to 0 002 µg l 1 with modern benchtop spectrofluorometers gerke et al 2013 kranjc 1997 moreover the measurement results demonstrate excellent repeatability which was demonstrated by measuring the 89 µg l 1 solution black arrow in fig 3c this solution has subsequently been measured after the 1954 µg l 1 solution and agrees with the other measurements this result also shows that the proposed water sampling concept of the fluorescence sensor system works appropriately i e exchanging the volume of the measuring chamber works sufficiently well so that subsequent measurements are not affected by the previous one the spectra of the calibration results reveals the occurrence of background fluorescence in the magnitude of 2500 counts per second between approximately 520 and 560 nm which is particularly noticeable at lower uranine concentrations in contrast the background fluorescence at higher uranine concentrations is not distinguishable from the expected emission peak of uranine at 515 nm measurements of the empty measuring chamber demonstrate that this fluorescence signal can be attributed to the measuring chamber itself fig b 6 in fact the measuring chamber is made of the photopolymer black resin which is a commonly used substance for 3d printing therefore a reasonable explanation for the background fluorescence trend may be that at high uranine concentrations the excitation light is mainly absorbed and likewise mainly excites the uranine molecules rather than the measuring chamber in other words the higher the uranine concentration the lower the probability that the excitation light will reach the measuring chamber and thus excites it an additional effect may be that the emission light of uranine may even outshine the emission light of the measuring chamber at a certain uranine concentration in the future background fluorescence can be eliminated by using a different material to manufacture the measuring chamber the investigated calibration range is well within the linear range reported for uranine which is from 1 µg l 1 to 2 mg l 1 gerke et al 2013 a linear regression analysis of the normalised intensity and the actual uranine concentration in stream water results in almost the same gradient for both measuring chambers fig 3c in addition all measurements show a low variance which also leads to a high r 2 value of 0 9997 i e the coefficient of determination for both linear regressions the low scattering of the measurements is mainly caused by measurement errors using the handheld fluorometer as well as by manufacturing differences among the measuring chambers and the polymer fibre optics the calibration results show that the measurements with the developed fluorescence sensor are reproducible and consistent for the investigated calibration solutions despite the decreasing background fluorescence of the measuring chamber at higher uranine concentrations 3 2 proof of concept in situ the result from the almost five hour lasting sandbox experiment with actual streambed sediment and stream water in which measurements were taken every three minutes shows a consistent decreasing sinusodial trend with no distinct measurement outliers fig 4 the periodicity of the graph indicates the turnaround time of the injected uranine plume which was about 35 min using the calculated flow velocity of 1 9 cm min 1 results in an effective flow path length of 66 5 cm which is reasonable for a total sandbox length of 40 cm and some storage time in the inlet and outlet basins overall the sandbox experiment clearly proves that the design concept of the developed sensor works well in particular this result demonstrates that i the multi layered filter of the fluorescence sensor did not clog over time and thus confirming the concept of the hydraulic valve system ii the optical properties within the measuring chamber remained sufficiently constant i e no disturbing gas bubbles no mechanical damage of the fibre optics tip and no interfering turbidity effects the field experiment lasted two hours with measurements being taken approximately every 10 min the water table dropped from 17 cm to 15 cm during the experiment but this change was assumed to have minimal effect on the flow field furthermore the ph and temperature t in the subsurface varied little during the experiment ph 7 182 0 044 t 14 34 0 11 c measured fluorescence intensities were converted into uranine concentrations using the respective fluorescence intensity uranine calibration curves fig 3c the injected uranine solution was clearly measured at a depth of 5 cm at both sensors with the downstream sensor i e in surface water flow direction showing a slightly higher and more enduring signal than the sensor perpendicular to the surface water flow direction fig 5 the results indicate that hyporheic flow is more intense in the direction of the downgradient sensor than of the sensor perpendicular to surface water flow in contrast no distinct signal was detected at 15 cm depth at both sensors suggesting that there is no downward hyporheic flow at the field site and thus horizontal hyporheic flow predominates however there are currently only four measuring points around the injection port reliable flow path detection would require a much denser grid of measuring points around the injection port lewandowski et al 2011a and angermann et al 2012 presented setups with 24 or 36 sensors measuring temperature on a virtual cylinder around a heater to calculate flow directions in 3d the advantage of a fluorescent tracer compared to temperature as a tracer is the absence of retardation due to heat storage and absence of dispersion due to heat conduction thus the fluorescence signal should in principal be detectable over much larger distances than the 3 cm used with the heat pulse sensor after successful miniaturization of the fluorescence sensor a 2d grid with a horizontal spacing of several centimeters between sensors of 8 times 8 fluorescence sensors and a vertical spacing of 2 cm of 8 measuring chambers in each device would result in 512 measuring ports thereby the sediment distortion becomes less important with higher distances between the sensors the use of different fluorescent tracers would allow the simultaneous identification of several subsurface flow paths besides the detection of hyporheic flow directions and hyporheic flow paths the fluorescence sensor also allows the determination of hyporheic flow velocities to avoid an inhomogeneous distribution of the tracer plume during injection the fluorescent tracer was injected at a low velocity and the injection lasted 9 min we use the center of the injection period as start time of the tracer injection the distance from the injection port to the downstream sensor was 3 cm however considering an injection volume of 9 ml a sediment porosity of 0 18 an undirected homogeneous injection an absence of hyporheic flow during injection and no mixing of the injected solution the pore water present in the sediment would result in a sphere with a radius of 2 28 cm around the injection port therefore the effective distance from the injection port to the downstream sensor was about 0 72 cm however in reality the volume impacted by the injection is larger because of mixing more disk shaped because hydraulic conductivity is usually 10 times higher in horizontal direction than in vertical direction and distorted in flow direction because of hyporheic flow we additionally calculated the area below the normalized breakthrough curve of the uranine concentration and calculated the time when 50 of the tracer plume passed the sensor the calculated hyporheic flow velocity considering the simple sphere shaped plume of the injected uranine was about 0 016 m h 1 we did not perform a similar calculation for the sensor perpendicular to the direction of flow because we assume that dispersion of the tracer plume during injection is the main transport mechanism in the direction of that sensor in addition to the flow pattern fluorescent tracers could also be used to elucidate the biogeochemical milieu along the flow paths or the predominant microbial processes for this purpose reactive tracers are needed instead of conservative tracers i e tracers that change their fluorescence properties along the flow paths depending on the predominant processes overall the recorded measurements are consistent and indicate that there were no measurement outliers over the course of the experiment this field deployment clearly demonstrates the robustness and proper working of the developed fluorescence sensor system under field conditions and thus provides its proof of concept 4 conclusion and outlook the present study demonstrates the proof of concept for a robust fluorescence sensor system that performs reproducible in situ fluorescence measurements in sediment pore water with high temporal and spatial resolution in particular it has been shown that fluorescence measurements for a given solution were well reproducible both for the measuring chamber unit itself as well as among other measuring chamber units moreover the robustness of the fluorescence sensor system has been validated in a five hour laboratory experiment at a three minute sampling interval and in a two hour field experiment at a ten minute sampling interval neither measurement outliers nor clogging of filters occurred in conclusion the decisive key for this well functioning prototype lies in its holistic design concept which consists of i the mechanical protection of the fibre optics tip and the assurance of constant optical properties of the measurement background by means of a measuring chamber unit and ii the avoidance of turbidity effects as well as the prevention of gas bubble formation within the measuring chamber by means of a multi layered filer in combination with a hydraulic valve system future device development will include further miniaturization full automation of its operation and integration of additional light sources for the investigation of other fluorescent substances the presented robust fluorescence sensor system has proven well suitable for fluorescence measurements in sediment pore water and therefore opens up the myriad applications of fluorescence spectroscopy in particular the extension of the range of measurable fluorescent substances i e the integration of further light sources will contribute to the investigation of different physical chemical and biological properties in saturated porous media both in technical systems e g in bankfiltration and sandfilters for drinking water production or in sandfilters in sewage treatment plants and in natural systems e g in sediments of streams lakes and oceans beyond that such an adapted fluorescence sensor system will enable researchers to measure time series of the well established valuable excitation emission scans in situ and in real time which has not been possible so far such high quality fluorescence measurements in sediment pore water will pave the way for novel predictive modelling towards a solid understanding of the functioning of ecosystems and technical systems credit authorship contribution statement anja höhne conceptualization methodology validation formal analysis writing original draft writing review editing karl mellerowicz conceptualization methodology validation writing review editing oliver lischtschenko formal analysis writing review editing jörg lewandowski conceptualization methodology validation writing review editing funding acquisition declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper appendix a emission light intensity analysis the analysis of the emission light intensity is done by normalizing all intensities measured by their respective integration time used in the next step the emission light intensities are integrated for the range of interest i e the range where the maximum emission light signal of the substance of interest is expected for uranine the normalized spectra between 505 and 580 nm was integrated and divided by its according sum of measurements the spectra has been selected so that it includes the fluorescence background signal from the measuring chamber since this effect cannot be explicitly differentiated from the uranine signal appendix b background fluorescence of the measuring chamber the occurrence of background fluorescence particularly at low uranine concentrations may be caused by the measuring chamber itself to investigate the source of the background fluorescence the emission light spectra of the empty measuring chambers was measured using the same led light source as for the experiments with uranine fig b 6 the integration time was set to 400 ms and the set up was protected from light the fluorescence spectra of the measuring chamber itself shows a signal between about 512 and 580 nm the result thus demonstrates that the background fluorescence can be attributed to the measuring chamber unit itself appendix c field experiment setup appendix d technical drawing of the sensor 
348,nanoparticle np transport is increasingly relevant to subsurface engineering applications such as aquifer characterization and enhanced oil recovery an efficient field scale simulation framework is critical for predicting np performance and designing subsurface applications in this work for the first time a streamline based model is presented to simulate np transport in field scale subsurface systems with heterogeneous permeability it considers a series of smart behaviors exhibited by engineered nanoparticles nps including time triggered encapsulation retention formation damage effects and variable nanofluid viscosity the key methods employed by the algorithm are streamline based simulation sls and an operator splitting os technique for modeling np transport the model is implemented in an in house streamline based code which is verified against analytical solutions commercial simulator and academic codes simulations on a synthetic three dimensional 3d nanocapsule application engineering design case are also performed to investigate the effect of fluid and np properties on the displacement pattern of an existing subsurface fluid keywords streamline based simulation nanoparticle transport reservoir simulation field scale simulation 1 introduction the transport and retention of nanoparticles nps in porous media is relevant to a variety of applications in groundwater nps can appear after release into the environment and subsequently cause facilitated transport of contaminants or may be environmental hazards themselves bundschuh et al 2018 for filtration separations or microfluidic operations with nps the behavior of the nps inside these porous domains dictates the effectiveness of the processes in oil and gas and environmental cleanup operations nps are being developed and tested for use in site characterization enhanced oil recovery eor drilling fluid improvements and conformance mobility control gu et al 2020 khalil et al 2017 mohamadian et al 2018 yekeen et al 2019 for these applications a wide range of functionalities are being designed including single component particles that enhance contrast during subsurface imaging rahmani et al 2015 and ahmadian et al 2019 nano capsules that release a payload at prescribed times or locations in a reservoir singh et al 2019 and smart nps with chemical switches or memory to record reservoir conditions encountered between their injection and production detection linley et al 2019 additionally in situations where larger particles can be used e g in a propped fracture micro fabricated devices are being designed to collect and report data duenckel et al 2019 a challenge for modeling nps in any of these applications is that their flow and retention mechanisms make them behave differently than fluid or solutes that traditional models are designed for if they are much smaller than pore sizes a common situation individual particles will not be susceptible to mechanical straining however they are highly sensitive to electrostatic interactions with surfaces fluid interfaces and other particles these surface interactions in turn can result in reversible or irreversible capture babakhani et al 2017 additionally density differences can make nps respond to gravity or inertial flows in ways that solutes do not lyon marion et al 2017 finally engineered behaviors such as payload release or triggered responses add a more complex reaction component to the modeling compared to traditional advective dispersive reactive transport johnson et al 2016a 2016b our understanding of basic np behavior in porous media is founded on a long history of experiments and theory on colloids and interfaces particularly examples such as tufenkji and elimelech 2004 li et al 2008 wang et al 2012 zhang et al 2016 becker et al 2015 and bianco et al 2016 colloid filtration theory cft provides a good point of reference for modeling the capture mechanisms fig 1 of small particles in porous media traditional cft is derived from a single spherical collector representing a particle in a granular porous medium combined with modified happel flow around a sphere rajagopalan and tien 1976 cft uses this flow field to predict the expected trajectory of finite sized particles which combined with surface forces leads to probabilistic values for capture of the particles when mechanistic particle dynamics are upscaled and tied to the porosity of a material being modeled the results can be used to estimate a continuum scale capture efficiency representing the ability of the porous media to retain colloidal particles petosa et al 2010 molnar et al 2015 gives a comprehensive review on transport and retention mechanisms and cft models of nps in porous media based on mechanistic studies various continuum models have been proposed to fit laboratory results by considering different transport mechanisms most continuum based models were calibrated and validated against one dimensional column experiments by interpreting and fitting measured breakthrough curves btcs from effluent np concentrations in classic cft a continuum model that only considers irreversible adsorption is used for colloids transport in porous media tufenkji and elimelech 2004 because desorption of nps is usually observed in experiments continuum models that incorporate reversible adsorption are commonly used for example tian et al 2010 shows that the experimental btcs of engineered nps silver and carbon nanotubes matches well with a continuum model that accounts for adsorption and desorption li et al 2008 proposed a continuum model considering adsorption desorption and site blocking with adsorption limited by a maximum attachment capacity which successfully fit fullerene np breakthrough curves in a sand column recent experimental data indicate that np capture in porous media is controlled by multiple mechanisms for instance zhang et al 2016 proposed a two site continuum model considering both reversible and irreversible retention mechanisms this model was successfully validated with five different sets of experimental data for silica nps results also show that capture is greatly affected by fluid salinity bianco et al 2016 developed a multi site reversible retention cft model that accounts for the effect of different ionic strengths so that the proposed model is able to reproduce the experimental observations as well as breakthrough curves under different values of fluid salinity continuum models with more complex mechanisms are summarized in the review paper by babakhani et al 2017 while various mechanistic and continuum models have been successful in reproducing and understanding np transport behavior from 1d laboratory columns studies of np transport in realistic large scale systems are scarce and need exists for new 3d modeling tools to take more of the np transport mechanisms into account babakhani et al 2017 velimirovic et al 2020 in addition modeling np transport is challenging from a computational standpoint in highly heterogeneous environments both porosity permeability and chemical heterogeneity such as those found in the subsurface and with the complex reaction behaviors that may be exhibited by smart nps fast np transport solutions are crucial for industrial application of engineered nps with these complex situations in general terms streamline based simulation sls is known to be an efficient method with low numerical dispersion an important feature of modern sls is that complex 3d flow and transport problems can be simplified to a series of 1d solutions along each streamline this feature makes sls particularly effective when dealing with large systems with permeability heterogeneity particularly for advection dominant flow since the 1990s sls has been extended to simulate non isothermal multiphase multi compositional flow and mass transport in a wide range of reservoir scenarios batycky 1997 crane and blunt 1999 datta gupta and king 2007 obi and blunt 2006 siavashi et al 2014 and chen et al 2020 it has been applied to many field scale petroleum engineering applications including waterflooding polymer flooding carbon dioxide storage and the history matching of field production data datta gupta and king 2007 of particular note here crane and blunt 1999 successfully applied sls to model reactive solute transport in porous media where the solution of the sls matches well with a particle tracking code and a commercial simulator results show that sls has low numerical dispersion and high computational efficiency for advection dominated transport in this paper we present a new sls model to simulate multi component np transport in heterogeneous subsurface systems the model includes essential physics that affect nanoparticle transport and it incorporates a reaction matrix to accommodate the much broader range of behaviors one can expect from smart engineered nanoparticles compared to traditional reactive systems an operator splitting approach is used to develop a flexible and accurate numerical scheme for the np transport along streamlines including a new framework that implements a stable explicit fd scheme a classic implicit fd scheme and an adaptive runge kutta scheme to solve for advection diffusion and nonlinear reactions respectively additionally the time of flight tof coordinate transformation in sls is used to model time triggered np behaviors such as encapsulated release the model is verified with a series of analytical solutions under the limiting conditions for which these solutions are relevant it is also compared for general accuracy and efficiency against a commercial fd reservoir simulator eclipse and compared for np transport against a specialized one dimensional finite difference code mnms tosco et al 2009 finally it is demonstrated on the more complex scenarios for which it was designed by simulating a series of hypothetical situations where the functionality of the reaction matrix is used in conjunction with a 3d reservoir model with heterogeneous porosity permeability the remainder of the paper is organized as follows in section 2 the assumptions and governing equations of flow and transport for nps are introduced together with the streamline based transport equations in section 3 the algorithm and numerical implementation are presented in section 4 several verification examples are presented and compared to analytical solutions and other simulators in section 5 a proposed field test for np based conformance control is simulated and analyzed for a reasonably large reservoir model 2 mathematical formulation in this section the governing equations for np transport and reaction are introduced transport mechanisms include advection and dispersion behaviors generalized into the reaction term include retention time triggered encapsulation permeability loss and concentration dependent viscosity several assumptions are made in the current development but could be relaxed if necessary 1 single phase incompressible fluid flow solved in a regular cartesian grid system 2 np transport is dominated by advection and heterogeneity meaning molecular diffusion transverse dispersion and gravity are neglected we ignore molecular diffusion because we expect to be modeling high peclet number conditions and ignore gravity both for numerical simplicity and because current simulations do not exhibit significant density differences dispersion is more complicated we have chosen to neglect transverse dispersion partly for numerical efficiency and partly because for mechanical dispersion the longitudinal component is approximately an order of magnitude larger than transverse for the materials we are considering well established operator splitting methods that could be used to relax these assumptions include datta gupta and king 2007 tanaka 2014 2 1 governing equations for flow and transport the mass balance equation for single phase incompressible flow in porous media is 1 0 u q where u l t is the darcy velocity and q 1 t is a volumetric source or sink per unit volume for 3d flow not considering gravitational forces the differential form of darcy s law is 2 u k μ δ p introducing darcy s law into the mass balance gives the governing equation for fluid flow 3 k μ c λ k s p q 0 where k 1 l 2 is the permeability tensor μ m l t is the fluid viscosity dependent on np behavior or concentration in some situations p m l t 2 is the pressure and λ k dimensionless is a mobility correction factor this mobility correction term is dependent on the concentration of deposited or attached particles in the rock matrix and is used to account for structure based permeability changes attributed to the presences of nps e g mechanical plugging by the particles themselves stimulation by acid released from nps etc the advection dispersion reaction equation adre is used to describe the transport of nps in porous media zhang et al 2016 and becker et al 2015 the adre for the i th np type can be expressed as follows 4 c i t v c i d c i r where c i m l 3 is concentration in the fluid s i m l 3 is the concentration of the adsorbed nps on the rock surface d l 2 t is the hydrodynamic dispersion tensor v l t is the interstitial velocity which can be related to darcy velocity as v u ϕ and r is the reaction term used to represent all manner of changes to the nps or caused by the nps we refer to these changes collectively as reaction behaviors and examples include surface interactions that transform nps from free to adsorbed or vice versa r r e t burst of a capsule that eliminates nps of one type but releases other molecular or particle species r c a p and conformational changes in response to time or environment that transforms them to a different species in the model r r retention is often the most important reaction behavior babakhani et al 2017 2 1 1 hydrodynamic dispersion based on the assumptions listed above only longitudinal dispersion is considered and can be directly calculated along streamlines the simplified dispersion tensor is calculated in terms of longitudinal dispersivity α l l as follows zheng and wang 1999 5 d d l α l v α l v x 2 v y 2 v z 2 considering a cartesian coordinate system v l t is the magnitude of the interstitial velocity and v x v y and v z l t are the respective components of the velocity vector 2 1 2 nps retention one of the most important reaction behaviors in many scenarios is adsorption desorption based on zhang et al 2016 s 2016 research a two site retention model captures many experimental observations including both irreversible and reversible attachment the retention reaction term r r e t c s can be expressed by a general two site retention model as in eq 6 zhang et al 2016 6 c i t r r e t c i s i ρ b ϕ s 1 i t ρ b ϕ s 2 i t ρ b ϕ s 1 i t k i r r i 1 s 1 i s 1 max i c i ρ b ϕ s 2 i t k r a i 1 s 2 i s 2 max i c i ρ b ϕ k r d i s 2 i where s 1 i and s 2 i m m mass of nanoparticle mass of porous medium are the concentrations of the irreversible and reversible adsorbed nps on the rock surface respectively ρ b m l 3 is the density of rock matrix k i r r i 1 t is the irreversible adsorption rate coefficient k r a i 1 t is the reversible adsorption rate coefficient k r d i 1 t is the reversible detachment rate coefficient and s 1 m a x i and s 2 m a x i m m represent the capacities for the irreversible and reversible adsorptions respectively if k i r r i 0 the two site retention model reduces to a one site retention model 2 1 3 other np reaction behaviors when envisioning types of smart nanoparticles that might be developed in the future the possibilities for complex reaction behaviors are almost endless the model is designed to accommodate new functionalities with operator splitting described below ensuring that new reaction terms can be added in a modular way however to keep a reasonable focus in this paper we describe one specific example a promising new technology johnson et al 2016a 2016b for controlled delivery in the subsurface a species of interest e g acid crosslinker surfactant etc is encapsulated into a nanocapsule which then dissolves bursts at a desired time upon encountering an external trigger or from an internal trigger the idea is to release its payload at an optimal location in the subsurface and or to minimize loss of the species before it reaches the intended target for the sake of brevity we focus on modeling a time triggered release from a nanocapsule this particular reaction behavior assumes that an encapsulated np type i will release an encapsulated payload chemical j when its time since injection or time since mixing reaches the designed burst time assuming the payload c j release follows a simple first order reaction of c i c j and s i c j the reaction model is expressed as follows 7 c i t r c a p c i c j 0 k r e c i t t i b u r s t t t i b u r s t c j t w i j k r e c i for encapsulated nps attached on porous media s i similar reaction models can be written as 8 s i t r c a p s i c j 0 k r e s i t t i b u r s t t t i b u r s t c j t w i j k r e s i where w i j m m is the releasing mass fraction defined as the mass fraction between each encapsulated payload j and the total mass of a nanocapsule i johnson et al 2016a k r e 1 t is the empirical release rate constant and t i b u r s t is the designed burst time of a nanocapsule if the capsule is designed to release based on a different trigger than burst time e g a local concentration or temperature the reaction term would be modified accordingly and tied to the relevant variable in the model after internal species are released from the nanocapsule they continue to follow their own relevant reaction models a complicating factor is that nanocapsules of the same type but having different clock times toward their triggered release e g because they were created or injected at different times on the surface can end up mixed together in the subsurface modeling the release behavior for this situation is nontrivial and is addressed using a lagrangian splitting approach discussed below 2 1 4 viscosity nanofluids are colloidal suspensions of nps in a base fluid the viscosity behavior of these nanofluids is often experimentally determined as a function of volumetric concentration murshed and estellé 2017 various empirical models for different types of nps have been proposed and two classes of empirical models can be summarized as follows sundar et al 2014 9 μ c i μ b r i n e a 0 a 1 η a 2 η 2 a 3 η 3 μ c i μ b r i n e a 4 e a 5 η where a 0 a 1 a 2 a 3 a 4 and a 5 dimensionless are empirical coefficients μ b r i n e is the viscosity of the base fluid brine and η l 3 l 3 is volumetric concentration for a multicomponent nanofluid with nnp nanparticles the volumetric concentration can be calculated as follows soltani and akbari 2016 10 η i 1 n n p c i ρ i i 1 n n p c i ρ i 1 100 where c i and ρ i is the np concentration and density of i th component in a nanofluid mixture 2 1 5 permeability alteration np injection has the potential to alter permeability for instance damage from mechanical straining of the nps or stimulation from injection of acid encapsulated nanocapsules in the model effects of permeability change are kept separate from viscosity in eq 3 i e instead of lumping them as a single mobility term which allows the nps to cause permanent permeability change at a specific location independently of viscosity changes that can continue to move with the flow experimental studies on permeability loss due to straining have been performed including yuan et al 2017 and abdelfatah et al 2017 permeability reduction is modeled using a linear flow resistance factor expressed as follows yuan et al 2017 11 k 0 k λ k s 1 β a d s o r p t i o n s where β a d s o r p t i o n is the formation damage coefficient dimensionless a situation that causes permeability change based on a different mechanism e g acid dissolution of the porous medium would need a different constitutive equation for k 0 k likely fitted empirically or tied to a simple permeability porosity relationship if an appropriate version is available 2 2 streamline formulation streamline simulation includes the important feature that a 3d transport problem eq 4 can be reformulated to a series of 1d sub problems along each streamline in terms of the time of flight tof datta gupta and king 2007 following the definitions and notations from datta gupta and king 2007 the tof τ is the time it takes for a neutral particle for travel to a specific distance s along a streamline mathematically tof can be expressed as 12 τ 0 s ϕ u d ξ 0 s 1 v d ξ where s is the spatial distance coordinate along a streamline datta gupta and king 2007 based on eq 12 the following transform operator can be defined as datta gupta and king 2007 13 v v s τ following the derivations for multiphase flow described in batycky 1997 the 3d transport equation of eq 4 can be transformed into multiple 1d equations using the above transform operator along streamlines and can be rewritten as 14 c i t c i τ τ α l v c i τ r c i s i detailed derivations are presented in appendix a the first second and third terms on the right hand side of eq 14 describe the advection longitudinal dispersion and generalized np reaction terms respectively 3 numerical implementation streamline based simulation has become increasingly popular due to its advantage in computational efficiency for large geologically complex and heterogeneous systems operator splitting os is a key aspect of streamline based simulation as shown in fig 2 os is used to decouple the flow eq 3 and transport eq 14 equations into an underlying 3d spatial grid and a 1d streamline time of flight grid datta gupta and king 2007 in this scheme the flow solution on the underling grid allows one to have different timesteps along a streamline additionally the off streamline physics vs streamline oriented physics can be solved independently on the 3d grids and streamline grids respectively os is also used to handle reaction terms which we view as essential in order to handle the nearly infinite type of reaction behaviors that smart nanoparticles may exhibit in the future instead of solving adre in a coupled manner as shown in fig 3 the solution of advection eq 16 dispersion eq 18 and various reaction terms for np transport such as retention in eq 6 and encapsulation in eq 7 can be solved independently with different numerical methods the use of operator splitting in the np streamline based simulations is summarized by the following steps 1 solve the pressure equation and compute face velocities on the underlying 3d grid this step is repeated periodically depending on changes to fluid and rock properties denoted by global pressure update timesteps δ t 2 trace streamlines and construct 1d tof grids for each streamline 3 solve the advection dispersion and various reactions independently along each streamline using local streamline timesteps δ t 4 map transport solution variables c i and s i from 1d tof grids to the underlying 3d grids 5 update the concentration dependent fluid and porous media properties such as concentration dependent nanofluid viscosity eq 9 and permeability loss eq 11 in the underlying 3d grids if necessary repeat steps 1 2 to re compute velocity field and obtain new streamlines 6 map transport solution variables c i and s i back from the underlying 3d grids to 1d tof grids 7 repeat step 3 6 until the end of simulation time operator splitting allows use of a relatively large pressure update timestep global timesteps δ t for the pressure solution in the 3d underlying grids with a smaller transport timestep local streamline timesteps δ t for the transport solution in 1d streamline grids the flowchart for the numerical implementation of the streamline based simulation is shown in fig 2 and the computational procedures for each step are described in detail in the following sub sections as mentioned above the off streamline physics such as molecular diffusion transverse diffusion and gravity can be included by solving the diffusivity equation for np concentration in the underlying 3d grids after step 5 tanaka 2014 3 1 pressure solution as shown in fig 2 the first step in streamline based simulation is to calculate the pressure field and face velocities for each block on the underlying grid the steady state single phase flow equation eq 3 is solved based on the standard finite difference method with a 7 point stencil lie 2019 a no flow boundary condition is prescribed on the reservoir boundaries of the entire model the boundary conditions for wells are either constrained by constant flow rate or constant bottom hole pressure bhp the classic peaceman well model peaceman et al 1983 is employed in the modeling details of the numerical implementation of the pressure solution can be found in lie 2019 once the pressures in each gridblock are obtained the darcy velocity u on each of the six faces of a gridblock can be calculated using eq 2 between two neighboring grids in addition the permeability and viscosity field are frequently updated e g every δ t in effect linearizing the nonlinear pressure equation for effects related to formation damage or viscosity change from the np behavior or other factors such as fluid mixing the frequency of global pressure updates δ t is influenced by non linearity in the simulation model in this paper the δ t determined by a simple trial and error method where several simulation runs are performed with decreasing δ t until the solution variables converge this process is demonstrated in the numerical example case 2 more details of advanced time step control scheme can be found in tanaka 2014 s work 3 2 streamline tracing knowing the interstitial velocity field on the underlying cartesian grid pollock 1988 s semi analytical method is used to trace a streamline grid by grid from injector to producer the velocity components in the x y and z directions are assumed to vary linearly in each gridblock therefore the exit coordinates and tof can be analytically calculated within a particular gridblock based on given inlet coordinates launching streamlines from gridblocks containing wells cannot guarantee every underlying grid cell will contain as least one streamline especially for large heterogeneous models the gridblocks containing no streamlines are marked as missed gridblocks for which fluid properties must still be defined batycky 1997 for example mapping np concentrations from streamlines back to underlying grids requires that each grid cell has at least one streamline passing through it after tracing streamlines from injector s to producer s new streamlines can be launched from the center of each missed gridblock and traced backward to an injector and forward to a producer this process is repeated until there are no missed grids batycky 1997 one other note is that pollock s algorithm cannot be directly applied to a grid cell containing an injector or a producer due to the existence of a sink or source pollock 1988 the fill grid method eq 15 can be adopted to estimate the average travel time for grid cells containing wells wang et al 2018 15 τ w i j k v g r i d ϕ g r i d q w where q w l 3 t is the wellbore flow rate δ v g r i d l 3 is the grid volume ϕ g r i d dimensionless is the grid porosity 3 3 np transport solution from the constructed 1d streamlines the np transport equations can be solved along each streamline by discretizing a streamline into 1d uniform grids in terms of tof in order to simulate the potentially complex behaviors exhibited by nanoparticles e g including nanosensors and nanocapsules a flexible and robust numerical scheme is needed one example discussed below is core shell encapsulation conformance control technology see section 5 which involves four species and five reaction behaviors operator splitting helps make this and similar situations tractable as shown in other applications with complex reactive transport behaviors with an arbitrary number of species clement et al 1998 for the current model a numerical scheme based on os is developed to solve np transport along each streamline as shown in fig 3 in our approach explicit finite difference implicit finite difference and adaptive runge kutta rk methods are implemented sequentially to solve the advection dispersion and reaction terms respectively this scheme provides a stable solution for both advection and dispersion by using the tof grids along each streamline which results in an unconditionally stable np transport solution by setting the uniform tof grid size δ τ equal to the local streamline timestep δ t lantz et al 1971 the detailed implementation and derivation are described below 3 3 1 advection for each np species i the advection term in eq 14 can be solved using explicit finite difference method as follows 16 c i k n 1 c i k n δ t c i k n c i k 1 n δ τ the local streamline time steps δ t should be selected based on courant fredrich lewy cfl conditions to guarantee numerical stability δ t δ τ 1 if a maximum cfl of 1 is adopted the spacing of 1d regular streamline grids δ τ is equal to the local streamline solution time step δ t substituting cfl condition of δ t δ τ 1 into eq 16 gives 17 c i k n 1 c i k 1 n eq 17 gives the exact and unconditionally stable solution lantz et al 1971 for advection which implies that advection of the concentration from the previous node will move forward to the next node in one timestep this solution removes the timestep restriction for stability in the conventional treatment for advection in streamline simulation by equating spatial and temporal step size crane and blunt 1999 and herrera et al 2010 3 3 2 longitudinal dispersion for each np species i the longitudinal dispersion term in eq 14 can be solved using an implicit finite difference method as follows 18 c i k n 1 c i k n δ t d l k 1 2 c i k 1 n 1 c i k n 1 d l k 1 2 c i k n 1 c i k 1 n 1 δ τ 2 the discretization scheme for advection is also adopted for dispersion substituting δ τ δ t into eq 18 gives 19 d l k 1 2 δ t c i k 1 n 1 d l k 1 2 d l k 1 2 1 δ t c i k n 1 d l k 1 2 δ t c i k 1 n 1 c i k n where d l k 1 2 and d l k 1 2 are the dispersion coefficients at each interface of two gridblocks and which can be directly estimated by interpolating the local velocity at the interfaces 20 d l k 1 2 α l v k 1 2 where α l is the average interface dispersivity which can be calculated by average of the values in the two adjacent cells zheng and wang 1999 v k 1 2 is the interface interstitial velocity which can be interpolated in the underlying grid at any position on the 1d regular streamline grids fig 4 the local interstitial velocity v can be represented using linear interpolation based on pollock s algorithm as follows 21 v v x 2 v y 2 v z 2 v x v x 0 a x x x 0 v y v y 0 a y y y 0 v z v z 0 a z z z 0 where a x a y and a z 1 t are the components of the linear velocity slope within an underlying grid for example the velocity gradient in the x direction is a x v x 1 v x 0 δ x pollock 1988 for a cartesian underlying grid the coordinates of the lower left corner point and top right corner point are x 0 y 0 z 0 and x 1 y 1 z 1 respectively the velocity in this grid can be linearly interpolated using grid interface velocities v x 0 v x 1 v y 0 v y 1 v z 0 v z 1 which are defined at the grid interfaces of x x 0 x x 1 y y 0 y y 1 z z 0 z z 1 respectively 3 3 3 np retention np retention is solved on each grid at each local timestep for np species i the retention part of the reaction term in eq 14 is a system of nonlinear ordinary differential equations such as eq 6 which can be calculated using a numerical integration method in this paper the adaptive cash karp rk algorithm cash and karp 1990 is implemented which will adaptively subdivide the local timestep δ t into several sub solution steps to control the relative error within a given tolerance which in this work is set to 1 10 6 3 3 4 time triggered encapsulation behavior if nanocapsules are injected in a way other than a single pulse then we may expect to encounter gridblocks with a mixture of time triggered nanocapsules having different burst times this problem is not restricted to nanocapsules but is relevant for modeling any time triggered behavior in which the start time for the trigger is not uniform reasons might include particles with a chemical timer that are created in sequential batches or a technology where injection is continuous but each particle s internal clock begins when it enters the wellbore particles with a range of different burst times is a related issue which is handled by treating these as separate np species in the model numerically solving for the burst and release reaction behavior for such mixtures is nontrivial we propose a lagrangian splitting approach to solve the reaction behavior described in eqs 7 8 where injected nanocapsules are split into different batches based on their injection time fig 19 for each batch the burst time is tracked and the reactive transport equation is solved independently the brute force implementation of the lagrangian splitting approach is to split the nanocapsules into several n batches where n injection time timestep obviously the computational cost of the brute force implementation will grow significantly for a simulation with a long period of injection for example a plan to inject nanocapsules for 100 days with a timestep of 1 day will require solution of 100 adr equations at each simulation timestep instead we developed an optimized implementation where the adr equations are grouped into several grouped batches n b a t c h the size of the batches n b a t c h is determined from the ratio between the burst time of the nanocapsule and simulation timestep the details of the optimized implementation for lagrangian splitting approach can be found in appendix b 3 3 5 implementation the model has been implemented in an in house three dimensional streamline code which referred to internally and in this paper as npsl nanoparticle streamline the current user interface is either through text input files or a microsoft excel front end that allows more intuitive control but then launches the same code the reaction matrix is an essential part of the functionality it allows a user to define complex np scenarios by assigning relevant reaction behaviors to each species in the simulation design by activating them on a grid for instance if species a is a nanocapsule the user might check time triggered burst and reversible adsorption as two of the behaviors if species b is acid contained inside a nanocapsule the user might check comes from a capsule and permeability change as two relevant behaviors each reaction behavior activated by the user requires associated parameters e g burst time adsorption desorption rate parameters reaction stoichiometry and dissolution kinetics for the behaviors listed above 4 model verification in this section we present case studies on 1d and 2d scenarios that have been performed to verify specific aspects of the model against exact solutions the academic colloid transport code mnms tosco et al 2009 and the commercial reservoir simulator eclipse eclipse 2018 the np transport solution is first verified against an analytic solution and mnms simulation for a 1d homogeneous model in the second case the functionalities for solute transport and viscosity change are compared to a commercial simulator on a 2d heterogeneous model finally an error analysis is performed to quantify the numerical errors of the presented solution algorithm the base model and simulation parameters for all cases are shown in table 1 4 1 case 1 verification for advection dispersion and retention to evaluate our implementation of the streamline model for solving the advection dispersion equation the np transport solution is verified against an analytical solution and an established numerical solution mnms as shown in fig 5 a 1d reservoir with a length of 298 70 m has been discretized into 50 gridblocks in the x direction an injection well is located at the center of the first grid block 1 1 1 and given a constant injection rate of 79 49 m3 day a production well is located at the center of the last grid block 50 1 1 and given a constant bottom hole pressure of 27 58 mpa a np slug is injected at a concentration of 1 kg m3 for a period of 10 days the detailed model and simulation parameters are given in table 2 other parameters are the same as shown in table 1 above for the analytic comparison we set the irreversible adsorption coefficient to zero and make the surface adsorption capacity infinite which allows direct comparison with the model described by bradford et al 2002 22 c t v c x d l 2 c x 2 ρ b ϕ s t ρ b ϕ s t k r a c ρ b ϕ k r d s the analytical solution of the above problem with pulse injection can be derived based on laplace transformation and superposition as follows goltz and huang 2017 23 x t c 0 m x t c 0 m x t c 0 m x t t i n j 0 t t i n j t t i n j m x t l 1 r 2 e r 2 l r 1 x r 1 e r 1 l r 2 x r 2 e r 2 l r 1 e r 1 l r 1 2 v v 2 4 d l s l s l k r a s l k r d 2 d l where the coefficients r 1 r 2 dimensionless are two solution constants and s l t 1 is the laplace variable to calculate the concentration in eq 23 a numerical inverse laplace transform by de hoog is used goltz and huang 2017 for 1d np transport the damköhler number and peclet number are defined as follows 24 p e v l d l d a k r a l v fig 6 shows the effluent breakthrough curve btc with different peclet numbers and damköhler numbers fig 7 comparing the npsl and analytical solutions of eq 23 the numerical solutions from npsl match well with analytical solutions for a wide range of da and pe in particular we note that the sharp front is accurately captured without any oscillations that high da behavior is indicated by the lower np concentrations in the production well and that low pe behavior is indicated by the dispersive spread of the effluent concentration and an earlier breakthrough time solution of the nonlinear np transport equations eq 6 is also validated with an academic colloid transport code mnms which has successfully reproduced nanoparticle column experiments tosco et al 2009 2012 this second comparison allows modeling of an adsorptive capacity of the porous medium quantified by s 2 m a x see eq 6 in this case parameters remain the same as before except the retention capacity s 2 m a x is set equal to 0 1 mg g and reversible attachment rate coefficient are varied as k r a 0 0 078 0 39 day 1 as shown in fig 7 npsl shows excellent agreement with mnms for various da and pe numbers note that to obtain these matching results the mnms system required 500 grid cells in the x direction and smaller timesteps δ t 0 01 days compared to the streamline approach 4 2 case 2 variable fluid properties the npsl simulator was also compared against the commercial reservoir simulator eclipse in a heterogeneous 2d model with a focus on simulating variable fluid properties the scenario used in this comparison is a simple polymer injection scenario without formation damage retention or reaction by injecting polymer the fluid viscosity will be linearly increased with increasing polymer concentration the implemented fluid viscosity model can be expressed as follows eclipse 2018 25 μ μ b r i n e μ 0 μ b r i n e 1 c c 0 1 where μ 0 is the initial polymer viscosity at the injection concentration c 0 eq 25 describes a simple linear relationship between concentration and viscosity the minimum and maximum values are the brine viscosity and initial polymer viscosity respectively fig 8 shows the permeability field from a portion of the 8th layer of the spe 10 comparative solution project dataset 2 christie et al 2001 an injector is located at the center of the model and four producers are located at the four corners a polymer slug is injected at a concentration of 1 kg m 3 for a period of 400 days additional model parameters are shown in table 3 all other parameters are the same as in table 1 the concentration map and btc for npsl and eclipse are shown in figs 9 10 respectively qualitatively the npsl solution matches well with eclipse but the streamline based method shows less numerical dispersion and presents a much sharper concentration front than the conventional fully implicit fd simulator as expected the btc for eclipse shows earlier breakthrough time than npsl because of the higher numerical dispersion these differences between finite difference and streamline solutions are well documented datta gupta and king 2007 and are pointed out here simply to explain the differences between the npsl solution and a well accepted numerical simulation tool the nonlinearity introduced by variable fluid properties must be addressed by periodically re solving the pressure field and regenerating the streamlines at each global pressure update timestep δ t these procedures require the polymer concentration to be mapped from the streamlines to the underlying grid which allows the in situ fluid viscosity to be updated by eq 25 as mentioned earlier the update frequency δ t is determined by some form of a trial and error method as shown in fig 11 the bottom hole pressure bhp of the injector converges when δ t is reduced from 200 days to 40 days further decreasing δ t to 20 days introduces more numerical mapping errors obi and blunt 2006 and the bhp shows abnormal fluctuations thus δ t is set at 40 days with 50 pressure updates for all spe10 simulations in this paper the mapping error issue of sls is discussed by obi and blunt 2006 and can be addressed by advanced timestep control technologies if needed tanaka 2014 5 model applications in this section three examples of injection scenarios of smart nps are presented to demonstrate the versatility and applicability of the presented streamline np transport model 5 1 case 3 1d laboratory column experiment in the first example application npsl is used to perform inverse modeling of a silica np column experiment murphy 2012 in which a 3 pv slug of 5 wt silica nps was injected into a one foot column of 90 wt 250 297 μ m boise sandstone mixed with 10 wt kaolinite using the npsl code the dispersivity of the column sample was fit against the measured btc of a tracer the retention parameters are then fitted against the btc of the np injection table 4 as shown in fig 12 the btc of the nps has a delayed breakthrough curve and a tail compared to the tracer the npsl solver matches well with the np experiment r 2 0 97 5 2 case 4 encapsulated np tracer injection into a 2d reservoir recently nanocapsule technology has been developed for subsurface characterization mikutis et al 2018 this example illustrates how the model could be used to help optimize treatment design it simulates np encapsulation technology that can deliver a payload or tracer deeper into a reservoir by protecting it from the reservoir environment which may cause loss from adsorption or premature reaction a quarter five spot problem is used with a 2d heterogeneous reservoir from the 85th layer of the spe10b model christie et al 2001 fig 13 shows the permeability field and flow streamlines the retention behavior parameters of the np are taken from table 4 all other simulation parameters are the same as case 2 as shown in table 5 three simulation scenarios are tested in case 4a 1 pv of tracer is injected in the reservoir as the reference solution in case 4b 1 pv of np tracer is injected but is susceptible to retention behavior in case 4c the same amount of nps are injected but they are nanocapsules with tracer inside the mass fraction and burst time of the nanocapsules are 100 and 30 days respectively fig 14 shows the concentration map of the np tracer and the encapsulated np tracer by comparing the results between case 4b and case 4c the encapsulated nps case 4c are released far from the injection well creating less absorptive loss and the earlier breakthrough time fig 15 is a plot of the produced np concentration which shows that retention behavior in case 4b and case 4c leads to delayed breakthrough and lower peak concentration due to nps being captured via adsorbing to the formation rock however a larger amount of the nps are produced in case 4c where they are protected by encapsulation during the first 30 days generally time trigger encapsulation technology can be designed to protect the payload flowing through the reservoir from being affected by the reservoir environment in the vicinity of injectors the encapsulation technology may release the payload in a variety of ways temperature encountering a chemical ph value etc 5 3 case 5 encapsulation conformance control in a 3d reservoir the purpose of this case is to demonstrate the applicability of npsl in 3d field scale application model with complex reaction behavoir a pilot simulation of encapsulation conformance control verga et al 2017 and johnson et al 2016a 2016b is simulated on a quarter five spot problem based on a portion of the spe10b model fig 16 an injector is located at one corner of a rectangular model and a producer is located at the opposite corner the wells are completed in all layers of the model the detailed model parameters are shown in table 6 as shown in table 7 three simulation scenarios are shown waterflooding and polymer flooding are simulated as reference solutions in case 5a and case 5b respectively in case 5b 0 67 pv of 10 cp polymer is injected in the reservoir in case 5c 0 67 pv of time triggered nanocapsules containing a cross linker and a special chemical base fluid is injected into the reservoir the burst time of the nanocapsules was set as 10 days after the nanocapsules reach their burst time the cross linker is released and can react with the base fluid to produce a 10 cp polymer in order to compare the results with those in case 5b a cross linking reaction cross linker base fluid polymer is used to produce a polymer with the same properties used in case 5b this system also assumes the reaction reaches to steady state within 1 simulation timestep 5 days similar to retention behavior the cross linking reaction can be solved using numerical integration where the reaction model of can be expressed as 26 c c l t k r x n c c l c b f c b f t k r x n c c l c b f c p t k r x n c c l c b f note that shear thinning effects and adsorption are neglected for all polymers simulated to evaluate the effect of different schemes on the conformance control a pre existing tracer is uniformly distributed in the domain this allows the different displacement schemes injected water injected polymer or in situ created polymer to be compared through the production response of the tracer that was originally present the intent is to mimic the sweep of oil by injected fluid even though the model is currently being run for single phase conditions retention and formation damage parameters vary with the different rock and np encapsulation types and are usually determined by column experiments in this case experimental np retention parameters are adopted from a large scale lab experiment lyon marion et al 2017 formation damage is also considered by assuming the maximum permeability reduction is 50 which means the formation damage coefficient β a d s o r p t i o n can be calculated based on eq 11 the viscosity of the nanofluids can be determined based on the concentration and density of the nps because silica iron and iron oxide nps are often used in subsurface research zhang et al 2016 an average nanoparticle density of 3 000 kg m 3 is used to estimate the volume concentration and the viscosity of the nanofluid the exponential function shown in eq 9 is used to compute fluid viscosity with empirical coefficients of a 4 12 5 and a 5 6 356 for iron oxide nanoparticles sundar et al 2014 the detailed nps encapsulation and fluid properties are provided in table 8 fig 17 shows the distribution of the unswept tracer and the recovery ratio for the three different scenarios at the end of each simulation a lower viscosity contrast μ d i s p l a c i n g μ d i s p l a c e d 1 between the displacing and the displaced fluid in case 5a will lead to a lower recovery ratio lie 2019 as shown in fig 17 in case 5a most of the displacing fluids are passing through the high permeability channels especially in the upper layers of the model leading to a large quantity of displaced tracer remaining in the lower permeability regions the simulation cases with higher viscosity contrasts case 5b 5c show better sweep efficiency the use of encapsulated crosslinker to create the polymer in situ case 5c has a slightly increased the recovery ratio by sweeping the marginal regions towards the top left corner in addition as shown in fig 18 the injection pressure of case 5c is significantly reduced compared to the conventional polymer treatment case 5b while these results represent only one set of conditions they illustrate how the npsl could be used to optimize sweep efficiency and injection pressure by varying treatment design including factors such as volume of the initial pad total volume of capsules burst time concentrations of base polymer and crosslinker or even sequencing the pad and crosslinker to enhance in situ mixing 6 conclusions the paper extends the efficient streamline based method to simulate nanoparticle transport and complex reaction behavior in field scale models the model considers a number of important characteristics of np transport including the retention and fluid properties of nanofluids encapsulation and formation damage an improved numerical scheme for np streamline based simulation is presented and several conclusions can be drawn as follows 1 the proposed method is a robust and accurate method for nanoparticle transport especially for large scale problems based on operator splitting and streamline based methods the improved numerical scheme guarantees the transport solution is oscillation free bounded and stable even when large timesteps and the conditions of high peclet number pe 1000 are used taking a 1d case as an example in order to match the analytical solutions the conventional fully implicit finite different scheme requires 10 times finer grid and 50 times smaller timesteps than the streamline based method 2 a series of comprehensive verification cases were also conducted by comparing the proposed method to analytical solutions and solutions from conventional fd based academic codes and commercial simulators the solution for advection diffusion retention and variable fluid properties all match well with the reference solutions and experimental data 3 a pilot engineering design of encapsulation conformance control is presented results indicate that the nps encapsulation polymer flooding is a promising technology in improving the performance of conventional polymer flooding not only for improved sweep but lower injection pressure 4 the method s computational speed suggests it is a promising tool for optimizing np treatment design for subsurface applications credit authorship contribution statement bin wang methodology data curation software investigation validation resources writing original draft yin feng supervision conceptualization methodology writing review editing methodology data curation software investigation resources john blears formal analysis data curation software visualization investigation writing review editing karsten thompson supervision conceptualization methodology funding acquisition project administration resources writing review editing richard hughes supervision conceptualization methodology funding acquisition project administration resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper the authors declare the following financial interests personal relationships which may be considered as potential competing interests none acknowledgments this work was supported by the advanced energy consortium http http www beg utexas edu aec with bhp billiton department of energy exxonmobil repsol shell and total as members in addition thanks to boyun guo university of louisiana at lafayette and tianqi ma louisiana state university for providing support and helpful suggestions appendix a derivation of 1d np transport equation along a streamline the np transport equation in 3d porous media can be expressed as follows a 1 c i t v c i d c i r c i s i i 1 m substituting eq 5 from the main body of the paper into eq a 1 gives a 2 c i t v c i α l v c i r c i s i i 1 m applying the transform operation from eq 13 into the advection term of eq a 2 the advection in terms of tof coordinates along a streamline can be expressed as follows a 3 v c i c i τ similarly applying eq 13 again into the dispersion term only streamline oriented longitudinal dispersion considered of eq a 2 gives a 4 α l v c i v s α l v v c i s τ α l v c i τ thus the 1d np transport equation can be expressed by substituting eqs a 3 and a 4 into eq a 2 as follows a 5 c i t c i τ τ α l v c i τ r c i s i i 1 m appendix b algorithm of lagrangian splitting approach as shown in fig 19 assume a nanocapsule has a designed burst time of t b u r s t the injection is started at time t 0 and continues for a period t i n j if the solution timestep is δ t the nanocapsule can be split into n b a t c h t b u r s t δ t batches injected in ceil t b u r s t δ t rounds of batches during each injection round m 1 2 ceil t b u r s t δ t the timestep n t i n j l to inject a batch l 1 2 n b a t c h can be calculated by n t i n j l l n b a t c h m 1 t 0 δ t 1 the burst timestep n t b u r s t i for the batch can be determined as n t b u r s t i n t i n j l t b u r s t δ t the np transport equations for advection eq 21 dispersion eq 22 and reaction terms are solved for each batch individually only when the global timestep reaches the burst timestep for a batch will the payload releasing equations eqs 9 10 be solved using an adaptive cash karp rk algorithm taking the fig 5 as an example assuming a nanocapsule has designed burst time of 3 days with injection time starting on the second day for a period of five days period t i n j simulation timestep is δ t 1 day the nanocapsule can be split into n b a t c h 3 1 3 batches and needs ceil 5 3 2 rounds of batches injection the injection and burst timesteps for the 3rd green batch l 3 at the 1st injection round m 1 are n t i n j 3 3 5 1 1 1 1 1 3 and n t b u r s t 1 3 3 1 6 respectively the injection and burst timesteps for other batches can be calculated accordingly 
348,nanoparticle np transport is increasingly relevant to subsurface engineering applications such as aquifer characterization and enhanced oil recovery an efficient field scale simulation framework is critical for predicting np performance and designing subsurface applications in this work for the first time a streamline based model is presented to simulate np transport in field scale subsurface systems with heterogeneous permeability it considers a series of smart behaviors exhibited by engineered nanoparticles nps including time triggered encapsulation retention formation damage effects and variable nanofluid viscosity the key methods employed by the algorithm are streamline based simulation sls and an operator splitting os technique for modeling np transport the model is implemented in an in house streamline based code which is verified against analytical solutions commercial simulator and academic codes simulations on a synthetic three dimensional 3d nanocapsule application engineering design case are also performed to investigate the effect of fluid and np properties on the displacement pattern of an existing subsurface fluid keywords streamline based simulation nanoparticle transport reservoir simulation field scale simulation 1 introduction the transport and retention of nanoparticles nps in porous media is relevant to a variety of applications in groundwater nps can appear after release into the environment and subsequently cause facilitated transport of contaminants or may be environmental hazards themselves bundschuh et al 2018 for filtration separations or microfluidic operations with nps the behavior of the nps inside these porous domains dictates the effectiveness of the processes in oil and gas and environmental cleanup operations nps are being developed and tested for use in site characterization enhanced oil recovery eor drilling fluid improvements and conformance mobility control gu et al 2020 khalil et al 2017 mohamadian et al 2018 yekeen et al 2019 for these applications a wide range of functionalities are being designed including single component particles that enhance contrast during subsurface imaging rahmani et al 2015 and ahmadian et al 2019 nano capsules that release a payload at prescribed times or locations in a reservoir singh et al 2019 and smart nps with chemical switches or memory to record reservoir conditions encountered between their injection and production detection linley et al 2019 additionally in situations where larger particles can be used e g in a propped fracture micro fabricated devices are being designed to collect and report data duenckel et al 2019 a challenge for modeling nps in any of these applications is that their flow and retention mechanisms make them behave differently than fluid or solutes that traditional models are designed for if they are much smaller than pore sizes a common situation individual particles will not be susceptible to mechanical straining however they are highly sensitive to electrostatic interactions with surfaces fluid interfaces and other particles these surface interactions in turn can result in reversible or irreversible capture babakhani et al 2017 additionally density differences can make nps respond to gravity or inertial flows in ways that solutes do not lyon marion et al 2017 finally engineered behaviors such as payload release or triggered responses add a more complex reaction component to the modeling compared to traditional advective dispersive reactive transport johnson et al 2016a 2016b our understanding of basic np behavior in porous media is founded on a long history of experiments and theory on colloids and interfaces particularly examples such as tufenkji and elimelech 2004 li et al 2008 wang et al 2012 zhang et al 2016 becker et al 2015 and bianco et al 2016 colloid filtration theory cft provides a good point of reference for modeling the capture mechanisms fig 1 of small particles in porous media traditional cft is derived from a single spherical collector representing a particle in a granular porous medium combined with modified happel flow around a sphere rajagopalan and tien 1976 cft uses this flow field to predict the expected trajectory of finite sized particles which combined with surface forces leads to probabilistic values for capture of the particles when mechanistic particle dynamics are upscaled and tied to the porosity of a material being modeled the results can be used to estimate a continuum scale capture efficiency representing the ability of the porous media to retain colloidal particles petosa et al 2010 molnar et al 2015 gives a comprehensive review on transport and retention mechanisms and cft models of nps in porous media based on mechanistic studies various continuum models have been proposed to fit laboratory results by considering different transport mechanisms most continuum based models were calibrated and validated against one dimensional column experiments by interpreting and fitting measured breakthrough curves btcs from effluent np concentrations in classic cft a continuum model that only considers irreversible adsorption is used for colloids transport in porous media tufenkji and elimelech 2004 because desorption of nps is usually observed in experiments continuum models that incorporate reversible adsorption are commonly used for example tian et al 2010 shows that the experimental btcs of engineered nps silver and carbon nanotubes matches well with a continuum model that accounts for adsorption and desorption li et al 2008 proposed a continuum model considering adsorption desorption and site blocking with adsorption limited by a maximum attachment capacity which successfully fit fullerene np breakthrough curves in a sand column recent experimental data indicate that np capture in porous media is controlled by multiple mechanisms for instance zhang et al 2016 proposed a two site continuum model considering both reversible and irreversible retention mechanisms this model was successfully validated with five different sets of experimental data for silica nps results also show that capture is greatly affected by fluid salinity bianco et al 2016 developed a multi site reversible retention cft model that accounts for the effect of different ionic strengths so that the proposed model is able to reproduce the experimental observations as well as breakthrough curves under different values of fluid salinity continuum models with more complex mechanisms are summarized in the review paper by babakhani et al 2017 while various mechanistic and continuum models have been successful in reproducing and understanding np transport behavior from 1d laboratory columns studies of np transport in realistic large scale systems are scarce and need exists for new 3d modeling tools to take more of the np transport mechanisms into account babakhani et al 2017 velimirovic et al 2020 in addition modeling np transport is challenging from a computational standpoint in highly heterogeneous environments both porosity permeability and chemical heterogeneity such as those found in the subsurface and with the complex reaction behaviors that may be exhibited by smart nps fast np transport solutions are crucial for industrial application of engineered nps with these complex situations in general terms streamline based simulation sls is known to be an efficient method with low numerical dispersion an important feature of modern sls is that complex 3d flow and transport problems can be simplified to a series of 1d solutions along each streamline this feature makes sls particularly effective when dealing with large systems with permeability heterogeneity particularly for advection dominant flow since the 1990s sls has been extended to simulate non isothermal multiphase multi compositional flow and mass transport in a wide range of reservoir scenarios batycky 1997 crane and blunt 1999 datta gupta and king 2007 obi and blunt 2006 siavashi et al 2014 and chen et al 2020 it has been applied to many field scale petroleum engineering applications including waterflooding polymer flooding carbon dioxide storage and the history matching of field production data datta gupta and king 2007 of particular note here crane and blunt 1999 successfully applied sls to model reactive solute transport in porous media where the solution of the sls matches well with a particle tracking code and a commercial simulator results show that sls has low numerical dispersion and high computational efficiency for advection dominated transport in this paper we present a new sls model to simulate multi component np transport in heterogeneous subsurface systems the model includes essential physics that affect nanoparticle transport and it incorporates a reaction matrix to accommodate the much broader range of behaviors one can expect from smart engineered nanoparticles compared to traditional reactive systems an operator splitting approach is used to develop a flexible and accurate numerical scheme for the np transport along streamlines including a new framework that implements a stable explicit fd scheme a classic implicit fd scheme and an adaptive runge kutta scheme to solve for advection diffusion and nonlinear reactions respectively additionally the time of flight tof coordinate transformation in sls is used to model time triggered np behaviors such as encapsulated release the model is verified with a series of analytical solutions under the limiting conditions for which these solutions are relevant it is also compared for general accuracy and efficiency against a commercial fd reservoir simulator eclipse and compared for np transport against a specialized one dimensional finite difference code mnms tosco et al 2009 finally it is demonstrated on the more complex scenarios for which it was designed by simulating a series of hypothetical situations where the functionality of the reaction matrix is used in conjunction with a 3d reservoir model with heterogeneous porosity permeability the remainder of the paper is organized as follows in section 2 the assumptions and governing equations of flow and transport for nps are introduced together with the streamline based transport equations in section 3 the algorithm and numerical implementation are presented in section 4 several verification examples are presented and compared to analytical solutions and other simulators in section 5 a proposed field test for np based conformance control is simulated and analyzed for a reasonably large reservoir model 2 mathematical formulation in this section the governing equations for np transport and reaction are introduced transport mechanisms include advection and dispersion behaviors generalized into the reaction term include retention time triggered encapsulation permeability loss and concentration dependent viscosity several assumptions are made in the current development but could be relaxed if necessary 1 single phase incompressible fluid flow solved in a regular cartesian grid system 2 np transport is dominated by advection and heterogeneity meaning molecular diffusion transverse dispersion and gravity are neglected we ignore molecular diffusion because we expect to be modeling high peclet number conditions and ignore gravity both for numerical simplicity and because current simulations do not exhibit significant density differences dispersion is more complicated we have chosen to neglect transverse dispersion partly for numerical efficiency and partly because for mechanical dispersion the longitudinal component is approximately an order of magnitude larger than transverse for the materials we are considering well established operator splitting methods that could be used to relax these assumptions include datta gupta and king 2007 tanaka 2014 2 1 governing equations for flow and transport the mass balance equation for single phase incompressible flow in porous media is 1 0 u q where u l t is the darcy velocity and q 1 t is a volumetric source or sink per unit volume for 3d flow not considering gravitational forces the differential form of darcy s law is 2 u k μ δ p introducing darcy s law into the mass balance gives the governing equation for fluid flow 3 k μ c λ k s p q 0 where k 1 l 2 is the permeability tensor μ m l t is the fluid viscosity dependent on np behavior or concentration in some situations p m l t 2 is the pressure and λ k dimensionless is a mobility correction factor this mobility correction term is dependent on the concentration of deposited or attached particles in the rock matrix and is used to account for structure based permeability changes attributed to the presences of nps e g mechanical plugging by the particles themselves stimulation by acid released from nps etc the advection dispersion reaction equation adre is used to describe the transport of nps in porous media zhang et al 2016 and becker et al 2015 the adre for the i th np type can be expressed as follows 4 c i t v c i d c i r where c i m l 3 is concentration in the fluid s i m l 3 is the concentration of the adsorbed nps on the rock surface d l 2 t is the hydrodynamic dispersion tensor v l t is the interstitial velocity which can be related to darcy velocity as v u ϕ and r is the reaction term used to represent all manner of changes to the nps or caused by the nps we refer to these changes collectively as reaction behaviors and examples include surface interactions that transform nps from free to adsorbed or vice versa r r e t burst of a capsule that eliminates nps of one type but releases other molecular or particle species r c a p and conformational changes in response to time or environment that transforms them to a different species in the model r r retention is often the most important reaction behavior babakhani et al 2017 2 1 1 hydrodynamic dispersion based on the assumptions listed above only longitudinal dispersion is considered and can be directly calculated along streamlines the simplified dispersion tensor is calculated in terms of longitudinal dispersivity α l l as follows zheng and wang 1999 5 d d l α l v α l v x 2 v y 2 v z 2 considering a cartesian coordinate system v l t is the magnitude of the interstitial velocity and v x v y and v z l t are the respective components of the velocity vector 2 1 2 nps retention one of the most important reaction behaviors in many scenarios is adsorption desorption based on zhang et al 2016 s 2016 research a two site retention model captures many experimental observations including both irreversible and reversible attachment the retention reaction term r r e t c s can be expressed by a general two site retention model as in eq 6 zhang et al 2016 6 c i t r r e t c i s i ρ b ϕ s 1 i t ρ b ϕ s 2 i t ρ b ϕ s 1 i t k i r r i 1 s 1 i s 1 max i c i ρ b ϕ s 2 i t k r a i 1 s 2 i s 2 max i c i ρ b ϕ k r d i s 2 i where s 1 i and s 2 i m m mass of nanoparticle mass of porous medium are the concentrations of the irreversible and reversible adsorbed nps on the rock surface respectively ρ b m l 3 is the density of rock matrix k i r r i 1 t is the irreversible adsorption rate coefficient k r a i 1 t is the reversible adsorption rate coefficient k r d i 1 t is the reversible detachment rate coefficient and s 1 m a x i and s 2 m a x i m m represent the capacities for the irreversible and reversible adsorptions respectively if k i r r i 0 the two site retention model reduces to a one site retention model 2 1 3 other np reaction behaviors when envisioning types of smart nanoparticles that might be developed in the future the possibilities for complex reaction behaviors are almost endless the model is designed to accommodate new functionalities with operator splitting described below ensuring that new reaction terms can be added in a modular way however to keep a reasonable focus in this paper we describe one specific example a promising new technology johnson et al 2016a 2016b for controlled delivery in the subsurface a species of interest e g acid crosslinker surfactant etc is encapsulated into a nanocapsule which then dissolves bursts at a desired time upon encountering an external trigger or from an internal trigger the idea is to release its payload at an optimal location in the subsurface and or to minimize loss of the species before it reaches the intended target for the sake of brevity we focus on modeling a time triggered release from a nanocapsule this particular reaction behavior assumes that an encapsulated np type i will release an encapsulated payload chemical j when its time since injection or time since mixing reaches the designed burst time assuming the payload c j release follows a simple first order reaction of c i c j and s i c j the reaction model is expressed as follows 7 c i t r c a p c i c j 0 k r e c i t t i b u r s t t t i b u r s t c j t w i j k r e c i for encapsulated nps attached on porous media s i similar reaction models can be written as 8 s i t r c a p s i c j 0 k r e s i t t i b u r s t t t i b u r s t c j t w i j k r e s i where w i j m m is the releasing mass fraction defined as the mass fraction between each encapsulated payload j and the total mass of a nanocapsule i johnson et al 2016a k r e 1 t is the empirical release rate constant and t i b u r s t is the designed burst time of a nanocapsule if the capsule is designed to release based on a different trigger than burst time e g a local concentration or temperature the reaction term would be modified accordingly and tied to the relevant variable in the model after internal species are released from the nanocapsule they continue to follow their own relevant reaction models a complicating factor is that nanocapsules of the same type but having different clock times toward their triggered release e g because they were created or injected at different times on the surface can end up mixed together in the subsurface modeling the release behavior for this situation is nontrivial and is addressed using a lagrangian splitting approach discussed below 2 1 4 viscosity nanofluids are colloidal suspensions of nps in a base fluid the viscosity behavior of these nanofluids is often experimentally determined as a function of volumetric concentration murshed and estellé 2017 various empirical models for different types of nps have been proposed and two classes of empirical models can be summarized as follows sundar et al 2014 9 μ c i μ b r i n e a 0 a 1 η a 2 η 2 a 3 η 3 μ c i μ b r i n e a 4 e a 5 η where a 0 a 1 a 2 a 3 a 4 and a 5 dimensionless are empirical coefficients μ b r i n e is the viscosity of the base fluid brine and η l 3 l 3 is volumetric concentration for a multicomponent nanofluid with nnp nanparticles the volumetric concentration can be calculated as follows soltani and akbari 2016 10 η i 1 n n p c i ρ i i 1 n n p c i ρ i 1 100 where c i and ρ i is the np concentration and density of i th component in a nanofluid mixture 2 1 5 permeability alteration np injection has the potential to alter permeability for instance damage from mechanical straining of the nps or stimulation from injection of acid encapsulated nanocapsules in the model effects of permeability change are kept separate from viscosity in eq 3 i e instead of lumping them as a single mobility term which allows the nps to cause permanent permeability change at a specific location independently of viscosity changes that can continue to move with the flow experimental studies on permeability loss due to straining have been performed including yuan et al 2017 and abdelfatah et al 2017 permeability reduction is modeled using a linear flow resistance factor expressed as follows yuan et al 2017 11 k 0 k λ k s 1 β a d s o r p t i o n s where β a d s o r p t i o n is the formation damage coefficient dimensionless a situation that causes permeability change based on a different mechanism e g acid dissolution of the porous medium would need a different constitutive equation for k 0 k likely fitted empirically or tied to a simple permeability porosity relationship if an appropriate version is available 2 2 streamline formulation streamline simulation includes the important feature that a 3d transport problem eq 4 can be reformulated to a series of 1d sub problems along each streamline in terms of the time of flight tof datta gupta and king 2007 following the definitions and notations from datta gupta and king 2007 the tof τ is the time it takes for a neutral particle for travel to a specific distance s along a streamline mathematically tof can be expressed as 12 τ 0 s ϕ u d ξ 0 s 1 v d ξ where s is the spatial distance coordinate along a streamline datta gupta and king 2007 based on eq 12 the following transform operator can be defined as datta gupta and king 2007 13 v v s τ following the derivations for multiphase flow described in batycky 1997 the 3d transport equation of eq 4 can be transformed into multiple 1d equations using the above transform operator along streamlines and can be rewritten as 14 c i t c i τ τ α l v c i τ r c i s i detailed derivations are presented in appendix a the first second and third terms on the right hand side of eq 14 describe the advection longitudinal dispersion and generalized np reaction terms respectively 3 numerical implementation streamline based simulation has become increasingly popular due to its advantage in computational efficiency for large geologically complex and heterogeneous systems operator splitting os is a key aspect of streamline based simulation as shown in fig 2 os is used to decouple the flow eq 3 and transport eq 14 equations into an underlying 3d spatial grid and a 1d streamline time of flight grid datta gupta and king 2007 in this scheme the flow solution on the underling grid allows one to have different timesteps along a streamline additionally the off streamline physics vs streamline oriented physics can be solved independently on the 3d grids and streamline grids respectively os is also used to handle reaction terms which we view as essential in order to handle the nearly infinite type of reaction behaviors that smart nanoparticles may exhibit in the future instead of solving adre in a coupled manner as shown in fig 3 the solution of advection eq 16 dispersion eq 18 and various reaction terms for np transport such as retention in eq 6 and encapsulation in eq 7 can be solved independently with different numerical methods the use of operator splitting in the np streamline based simulations is summarized by the following steps 1 solve the pressure equation and compute face velocities on the underlying 3d grid this step is repeated periodically depending on changes to fluid and rock properties denoted by global pressure update timesteps δ t 2 trace streamlines and construct 1d tof grids for each streamline 3 solve the advection dispersion and various reactions independently along each streamline using local streamline timesteps δ t 4 map transport solution variables c i and s i from 1d tof grids to the underlying 3d grids 5 update the concentration dependent fluid and porous media properties such as concentration dependent nanofluid viscosity eq 9 and permeability loss eq 11 in the underlying 3d grids if necessary repeat steps 1 2 to re compute velocity field and obtain new streamlines 6 map transport solution variables c i and s i back from the underlying 3d grids to 1d tof grids 7 repeat step 3 6 until the end of simulation time operator splitting allows use of a relatively large pressure update timestep global timesteps δ t for the pressure solution in the 3d underlying grids with a smaller transport timestep local streamline timesteps δ t for the transport solution in 1d streamline grids the flowchart for the numerical implementation of the streamline based simulation is shown in fig 2 and the computational procedures for each step are described in detail in the following sub sections as mentioned above the off streamline physics such as molecular diffusion transverse diffusion and gravity can be included by solving the diffusivity equation for np concentration in the underlying 3d grids after step 5 tanaka 2014 3 1 pressure solution as shown in fig 2 the first step in streamline based simulation is to calculate the pressure field and face velocities for each block on the underlying grid the steady state single phase flow equation eq 3 is solved based on the standard finite difference method with a 7 point stencil lie 2019 a no flow boundary condition is prescribed on the reservoir boundaries of the entire model the boundary conditions for wells are either constrained by constant flow rate or constant bottom hole pressure bhp the classic peaceman well model peaceman et al 1983 is employed in the modeling details of the numerical implementation of the pressure solution can be found in lie 2019 once the pressures in each gridblock are obtained the darcy velocity u on each of the six faces of a gridblock can be calculated using eq 2 between two neighboring grids in addition the permeability and viscosity field are frequently updated e g every δ t in effect linearizing the nonlinear pressure equation for effects related to formation damage or viscosity change from the np behavior or other factors such as fluid mixing the frequency of global pressure updates δ t is influenced by non linearity in the simulation model in this paper the δ t determined by a simple trial and error method where several simulation runs are performed with decreasing δ t until the solution variables converge this process is demonstrated in the numerical example case 2 more details of advanced time step control scheme can be found in tanaka 2014 s work 3 2 streamline tracing knowing the interstitial velocity field on the underlying cartesian grid pollock 1988 s semi analytical method is used to trace a streamline grid by grid from injector to producer the velocity components in the x y and z directions are assumed to vary linearly in each gridblock therefore the exit coordinates and tof can be analytically calculated within a particular gridblock based on given inlet coordinates launching streamlines from gridblocks containing wells cannot guarantee every underlying grid cell will contain as least one streamline especially for large heterogeneous models the gridblocks containing no streamlines are marked as missed gridblocks for which fluid properties must still be defined batycky 1997 for example mapping np concentrations from streamlines back to underlying grids requires that each grid cell has at least one streamline passing through it after tracing streamlines from injector s to producer s new streamlines can be launched from the center of each missed gridblock and traced backward to an injector and forward to a producer this process is repeated until there are no missed grids batycky 1997 one other note is that pollock s algorithm cannot be directly applied to a grid cell containing an injector or a producer due to the existence of a sink or source pollock 1988 the fill grid method eq 15 can be adopted to estimate the average travel time for grid cells containing wells wang et al 2018 15 τ w i j k v g r i d ϕ g r i d q w where q w l 3 t is the wellbore flow rate δ v g r i d l 3 is the grid volume ϕ g r i d dimensionless is the grid porosity 3 3 np transport solution from the constructed 1d streamlines the np transport equations can be solved along each streamline by discretizing a streamline into 1d uniform grids in terms of tof in order to simulate the potentially complex behaviors exhibited by nanoparticles e g including nanosensors and nanocapsules a flexible and robust numerical scheme is needed one example discussed below is core shell encapsulation conformance control technology see section 5 which involves four species and five reaction behaviors operator splitting helps make this and similar situations tractable as shown in other applications with complex reactive transport behaviors with an arbitrary number of species clement et al 1998 for the current model a numerical scheme based on os is developed to solve np transport along each streamline as shown in fig 3 in our approach explicit finite difference implicit finite difference and adaptive runge kutta rk methods are implemented sequentially to solve the advection dispersion and reaction terms respectively this scheme provides a stable solution for both advection and dispersion by using the tof grids along each streamline which results in an unconditionally stable np transport solution by setting the uniform tof grid size δ τ equal to the local streamline timestep δ t lantz et al 1971 the detailed implementation and derivation are described below 3 3 1 advection for each np species i the advection term in eq 14 can be solved using explicit finite difference method as follows 16 c i k n 1 c i k n δ t c i k n c i k 1 n δ τ the local streamline time steps δ t should be selected based on courant fredrich lewy cfl conditions to guarantee numerical stability δ t δ τ 1 if a maximum cfl of 1 is adopted the spacing of 1d regular streamline grids δ τ is equal to the local streamline solution time step δ t substituting cfl condition of δ t δ τ 1 into eq 16 gives 17 c i k n 1 c i k 1 n eq 17 gives the exact and unconditionally stable solution lantz et al 1971 for advection which implies that advection of the concentration from the previous node will move forward to the next node in one timestep this solution removes the timestep restriction for stability in the conventional treatment for advection in streamline simulation by equating spatial and temporal step size crane and blunt 1999 and herrera et al 2010 3 3 2 longitudinal dispersion for each np species i the longitudinal dispersion term in eq 14 can be solved using an implicit finite difference method as follows 18 c i k n 1 c i k n δ t d l k 1 2 c i k 1 n 1 c i k n 1 d l k 1 2 c i k n 1 c i k 1 n 1 δ τ 2 the discretization scheme for advection is also adopted for dispersion substituting δ τ δ t into eq 18 gives 19 d l k 1 2 δ t c i k 1 n 1 d l k 1 2 d l k 1 2 1 δ t c i k n 1 d l k 1 2 δ t c i k 1 n 1 c i k n where d l k 1 2 and d l k 1 2 are the dispersion coefficients at each interface of two gridblocks and which can be directly estimated by interpolating the local velocity at the interfaces 20 d l k 1 2 α l v k 1 2 where α l is the average interface dispersivity which can be calculated by average of the values in the two adjacent cells zheng and wang 1999 v k 1 2 is the interface interstitial velocity which can be interpolated in the underlying grid at any position on the 1d regular streamline grids fig 4 the local interstitial velocity v can be represented using linear interpolation based on pollock s algorithm as follows 21 v v x 2 v y 2 v z 2 v x v x 0 a x x x 0 v y v y 0 a y y y 0 v z v z 0 a z z z 0 where a x a y and a z 1 t are the components of the linear velocity slope within an underlying grid for example the velocity gradient in the x direction is a x v x 1 v x 0 δ x pollock 1988 for a cartesian underlying grid the coordinates of the lower left corner point and top right corner point are x 0 y 0 z 0 and x 1 y 1 z 1 respectively the velocity in this grid can be linearly interpolated using grid interface velocities v x 0 v x 1 v y 0 v y 1 v z 0 v z 1 which are defined at the grid interfaces of x x 0 x x 1 y y 0 y y 1 z z 0 z z 1 respectively 3 3 3 np retention np retention is solved on each grid at each local timestep for np species i the retention part of the reaction term in eq 14 is a system of nonlinear ordinary differential equations such as eq 6 which can be calculated using a numerical integration method in this paper the adaptive cash karp rk algorithm cash and karp 1990 is implemented which will adaptively subdivide the local timestep δ t into several sub solution steps to control the relative error within a given tolerance which in this work is set to 1 10 6 3 3 4 time triggered encapsulation behavior if nanocapsules are injected in a way other than a single pulse then we may expect to encounter gridblocks with a mixture of time triggered nanocapsules having different burst times this problem is not restricted to nanocapsules but is relevant for modeling any time triggered behavior in which the start time for the trigger is not uniform reasons might include particles with a chemical timer that are created in sequential batches or a technology where injection is continuous but each particle s internal clock begins when it enters the wellbore particles with a range of different burst times is a related issue which is handled by treating these as separate np species in the model numerically solving for the burst and release reaction behavior for such mixtures is nontrivial we propose a lagrangian splitting approach to solve the reaction behavior described in eqs 7 8 where injected nanocapsules are split into different batches based on their injection time fig 19 for each batch the burst time is tracked and the reactive transport equation is solved independently the brute force implementation of the lagrangian splitting approach is to split the nanocapsules into several n batches where n injection time timestep obviously the computational cost of the brute force implementation will grow significantly for a simulation with a long period of injection for example a plan to inject nanocapsules for 100 days with a timestep of 1 day will require solution of 100 adr equations at each simulation timestep instead we developed an optimized implementation where the adr equations are grouped into several grouped batches n b a t c h the size of the batches n b a t c h is determined from the ratio between the burst time of the nanocapsule and simulation timestep the details of the optimized implementation for lagrangian splitting approach can be found in appendix b 3 3 5 implementation the model has been implemented in an in house three dimensional streamline code which referred to internally and in this paper as npsl nanoparticle streamline the current user interface is either through text input files or a microsoft excel front end that allows more intuitive control but then launches the same code the reaction matrix is an essential part of the functionality it allows a user to define complex np scenarios by assigning relevant reaction behaviors to each species in the simulation design by activating them on a grid for instance if species a is a nanocapsule the user might check time triggered burst and reversible adsorption as two of the behaviors if species b is acid contained inside a nanocapsule the user might check comes from a capsule and permeability change as two relevant behaviors each reaction behavior activated by the user requires associated parameters e g burst time adsorption desorption rate parameters reaction stoichiometry and dissolution kinetics for the behaviors listed above 4 model verification in this section we present case studies on 1d and 2d scenarios that have been performed to verify specific aspects of the model against exact solutions the academic colloid transport code mnms tosco et al 2009 and the commercial reservoir simulator eclipse eclipse 2018 the np transport solution is first verified against an analytic solution and mnms simulation for a 1d homogeneous model in the second case the functionalities for solute transport and viscosity change are compared to a commercial simulator on a 2d heterogeneous model finally an error analysis is performed to quantify the numerical errors of the presented solution algorithm the base model and simulation parameters for all cases are shown in table 1 4 1 case 1 verification for advection dispersion and retention to evaluate our implementation of the streamline model for solving the advection dispersion equation the np transport solution is verified against an analytical solution and an established numerical solution mnms as shown in fig 5 a 1d reservoir with a length of 298 70 m has been discretized into 50 gridblocks in the x direction an injection well is located at the center of the first grid block 1 1 1 and given a constant injection rate of 79 49 m3 day a production well is located at the center of the last grid block 50 1 1 and given a constant bottom hole pressure of 27 58 mpa a np slug is injected at a concentration of 1 kg m3 for a period of 10 days the detailed model and simulation parameters are given in table 2 other parameters are the same as shown in table 1 above for the analytic comparison we set the irreversible adsorption coefficient to zero and make the surface adsorption capacity infinite which allows direct comparison with the model described by bradford et al 2002 22 c t v c x d l 2 c x 2 ρ b ϕ s t ρ b ϕ s t k r a c ρ b ϕ k r d s the analytical solution of the above problem with pulse injection can be derived based on laplace transformation and superposition as follows goltz and huang 2017 23 x t c 0 m x t c 0 m x t c 0 m x t t i n j 0 t t i n j t t i n j m x t l 1 r 2 e r 2 l r 1 x r 1 e r 1 l r 2 x r 2 e r 2 l r 1 e r 1 l r 1 2 v v 2 4 d l s l s l k r a s l k r d 2 d l where the coefficients r 1 r 2 dimensionless are two solution constants and s l t 1 is the laplace variable to calculate the concentration in eq 23 a numerical inverse laplace transform by de hoog is used goltz and huang 2017 for 1d np transport the damköhler number and peclet number are defined as follows 24 p e v l d l d a k r a l v fig 6 shows the effluent breakthrough curve btc with different peclet numbers and damköhler numbers fig 7 comparing the npsl and analytical solutions of eq 23 the numerical solutions from npsl match well with analytical solutions for a wide range of da and pe in particular we note that the sharp front is accurately captured without any oscillations that high da behavior is indicated by the lower np concentrations in the production well and that low pe behavior is indicated by the dispersive spread of the effluent concentration and an earlier breakthrough time solution of the nonlinear np transport equations eq 6 is also validated with an academic colloid transport code mnms which has successfully reproduced nanoparticle column experiments tosco et al 2009 2012 this second comparison allows modeling of an adsorptive capacity of the porous medium quantified by s 2 m a x see eq 6 in this case parameters remain the same as before except the retention capacity s 2 m a x is set equal to 0 1 mg g and reversible attachment rate coefficient are varied as k r a 0 0 078 0 39 day 1 as shown in fig 7 npsl shows excellent agreement with mnms for various da and pe numbers note that to obtain these matching results the mnms system required 500 grid cells in the x direction and smaller timesteps δ t 0 01 days compared to the streamline approach 4 2 case 2 variable fluid properties the npsl simulator was also compared against the commercial reservoir simulator eclipse in a heterogeneous 2d model with a focus on simulating variable fluid properties the scenario used in this comparison is a simple polymer injection scenario without formation damage retention or reaction by injecting polymer the fluid viscosity will be linearly increased with increasing polymer concentration the implemented fluid viscosity model can be expressed as follows eclipse 2018 25 μ μ b r i n e μ 0 μ b r i n e 1 c c 0 1 where μ 0 is the initial polymer viscosity at the injection concentration c 0 eq 25 describes a simple linear relationship between concentration and viscosity the minimum and maximum values are the brine viscosity and initial polymer viscosity respectively fig 8 shows the permeability field from a portion of the 8th layer of the spe 10 comparative solution project dataset 2 christie et al 2001 an injector is located at the center of the model and four producers are located at the four corners a polymer slug is injected at a concentration of 1 kg m 3 for a period of 400 days additional model parameters are shown in table 3 all other parameters are the same as in table 1 the concentration map and btc for npsl and eclipse are shown in figs 9 10 respectively qualitatively the npsl solution matches well with eclipse but the streamline based method shows less numerical dispersion and presents a much sharper concentration front than the conventional fully implicit fd simulator as expected the btc for eclipse shows earlier breakthrough time than npsl because of the higher numerical dispersion these differences between finite difference and streamline solutions are well documented datta gupta and king 2007 and are pointed out here simply to explain the differences between the npsl solution and a well accepted numerical simulation tool the nonlinearity introduced by variable fluid properties must be addressed by periodically re solving the pressure field and regenerating the streamlines at each global pressure update timestep δ t these procedures require the polymer concentration to be mapped from the streamlines to the underlying grid which allows the in situ fluid viscosity to be updated by eq 25 as mentioned earlier the update frequency δ t is determined by some form of a trial and error method as shown in fig 11 the bottom hole pressure bhp of the injector converges when δ t is reduced from 200 days to 40 days further decreasing δ t to 20 days introduces more numerical mapping errors obi and blunt 2006 and the bhp shows abnormal fluctuations thus δ t is set at 40 days with 50 pressure updates for all spe10 simulations in this paper the mapping error issue of sls is discussed by obi and blunt 2006 and can be addressed by advanced timestep control technologies if needed tanaka 2014 5 model applications in this section three examples of injection scenarios of smart nps are presented to demonstrate the versatility and applicability of the presented streamline np transport model 5 1 case 3 1d laboratory column experiment in the first example application npsl is used to perform inverse modeling of a silica np column experiment murphy 2012 in which a 3 pv slug of 5 wt silica nps was injected into a one foot column of 90 wt 250 297 μ m boise sandstone mixed with 10 wt kaolinite using the npsl code the dispersivity of the column sample was fit against the measured btc of a tracer the retention parameters are then fitted against the btc of the np injection table 4 as shown in fig 12 the btc of the nps has a delayed breakthrough curve and a tail compared to the tracer the npsl solver matches well with the np experiment r 2 0 97 5 2 case 4 encapsulated np tracer injection into a 2d reservoir recently nanocapsule technology has been developed for subsurface characterization mikutis et al 2018 this example illustrates how the model could be used to help optimize treatment design it simulates np encapsulation technology that can deliver a payload or tracer deeper into a reservoir by protecting it from the reservoir environment which may cause loss from adsorption or premature reaction a quarter five spot problem is used with a 2d heterogeneous reservoir from the 85th layer of the spe10b model christie et al 2001 fig 13 shows the permeability field and flow streamlines the retention behavior parameters of the np are taken from table 4 all other simulation parameters are the same as case 2 as shown in table 5 three simulation scenarios are tested in case 4a 1 pv of tracer is injected in the reservoir as the reference solution in case 4b 1 pv of np tracer is injected but is susceptible to retention behavior in case 4c the same amount of nps are injected but they are nanocapsules with tracer inside the mass fraction and burst time of the nanocapsules are 100 and 30 days respectively fig 14 shows the concentration map of the np tracer and the encapsulated np tracer by comparing the results between case 4b and case 4c the encapsulated nps case 4c are released far from the injection well creating less absorptive loss and the earlier breakthrough time fig 15 is a plot of the produced np concentration which shows that retention behavior in case 4b and case 4c leads to delayed breakthrough and lower peak concentration due to nps being captured via adsorbing to the formation rock however a larger amount of the nps are produced in case 4c where they are protected by encapsulation during the first 30 days generally time trigger encapsulation technology can be designed to protect the payload flowing through the reservoir from being affected by the reservoir environment in the vicinity of injectors the encapsulation technology may release the payload in a variety of ways temperature encountering a chemical ph value etc 5 3 case 5 encapsulation conformance control in a 3d reservoir the purpose of this case is to demonstrate the applicability of npsl in 3d field scale application model with complex reaction behavoir a pilot simulation of encapsulation conformance control verga et al 2017 and johnson et al 2016a 2016b is simulated on a quarter five spot problem based on a portion of the spe10b model fig 16 an injector is located at one corner of a rectangular model and a producer is located at the opposite corner the wells are completed in all layers of the model the detailed model parameters are shown in table 6 as shown in table 7 three simulation scenarios are shown waterflooding and polymer flooding are simulated as reference solutions in case 5a and case 5b respectively in case 5b 0 67 pv of 10 cp polymer is injected in the reservoir in case 5c 0 67 pv of time triggered nanocapsules containing a cross linker and a special chemical base fluid is injected into the reservoir the burst time of the nanocapsules was set as 10 days after the nanocapsules reach their burst time the cross linker is released and can react with the base fluid to produce a 10 cp polymer in order to compare the results with those in case 5b a cross linking reaction cross linker base fluid polymer is used to produce a polymer with the same properties used in case 5b this system also assumes the reaction reaches to steady state within 1 simulation timestep 5 days similar to retention behavior the cross linking reaction can be solved using numerical integration where the reaction model of can be expressed as 26 c c l t k r x n c c l c b f c b f t k r x n c c l c b f c p t k r x n c c l c b f note that shear thinning effects and adsorption are neglected for all polymers simulated to evaluate the effect of different schemes on the conformance control a pre existing tracer is uniformly distributed in the domain this allows the different displacement schemes injected water injected polymer or in situ created polymer to be compared through the production response of the tracer that was originally present the intent is to mimic the sweep of oil by injected fluid even though the model is currently being run for single phase conditions retention and formation damage parameters vary with the different rock and np encapsulation types and are usually determined by column experiments in this case experimental np retention parameters are adopted from a large scale lab experiment lyon marion et al 2017 formation damage is also considered by assuming the maximum permeability reduction is 50 which means the formation damage coefficient β a d s o r p t i o n can be calculated based on eq 11 the viscosity of the nanofluids can be determined based on the concentration and density of the nps because silica iron and iron oxide nps are often used in subsurface research zhang et al 2016 an average nanoparticle density of 3 000 kg m 3 is used to estimate the volume concentration and the viscosity of the nanofluid the exponential function shown in eq 9 is used to compute fluid viscosity with empirical coefficients of a 4 12 5 and a 5 6 356 for iron oxide nanoparticles sundar et al 2014 the detailed nps encapsulation and fluid properties are provided in table 8 fig 17 shows the distribution of the unswept tracer and the recovery ratio for the three different scenarios at the end of each simulation a lower viscosity contrast μ d i s p l a c i n g μ d i s p l a c e d 1 between the displacing and the displaced fluid in case 5a will lead to a lower recovery ratio lie 2019 as shown in fig 17 in case 5a most of the displacing fluids are passing through the high permeability channels especially in the upper layers of the model leading to a large quantity of displaced tracer remaining in the lower permeability regions the simulation cases with higher viscosity contrasts case 5b 5c show better sweep efficiency the use of encapsulated crosslinker to create the polymer in situ case 5c has a slightly increased the recovery ratio by sweeping the marginal regions towards the top left corner in addition as shown in fig 18 the injection pressure of case 5c is significantly reduced compared to the conventional polymer treatment case 5b while these results represent only one set of conditions they illustrate how the npsl could be used to optimize sweep efficiency and injection pressure by varying treatment design including factors such as volume of the initial pad total volume of capsules burst time concentrations of base polymer and crosslinker or even sequencing the pad and crosslinker to enhance in situ mixing 6 conclusions the paper extends the efficient streamline based method to simulate nanoparticle transport and complex reaction behavior in field scale models the model considers a number of important characteristics of np transport including the retention and fluid properties of nanofluids encapsulation and formation damage an improved numerical scheme for np streamline based simulation is presented and several conclusions can be drawn as follows 1 the proposed method is a robust and accurate method for nanoparticle transport especially for large scale problems based on operator splitting and streamline based methods the improved numerical scheme guarantees the transport solution is oscillation free bounded and stable even when large timesteps and the conditions of high peclet number pe 1000 are used taking a 1d case as an example in order to match the analytical solutions the conventional fully implicit finite different scheme requires 10 times finer grid and 50 times smaller timesteps than the streamline based method 2 a series of comprehensive verification cases were also conducted by comparing the proposed method to analytical solutions and solutions from conventional fd based academic codes and commercial simulators the solution for advection diffusion retention and variable fluid properties all match well with the reference solutions and experimental data 3 a pilot engineering design of encapsulation conformance control is presented results indicate that the nps encapsulation polymer flooding is a promising technology in improving the performance of conventional polymer flooding not only for improved sweep but lower injection pressure 4 the method s computational speed suggests it is a promising tool for optimizing np treatment design for subsurface applications credit authorship contribution statement bin wang methodology data curation software investigation validation resources writing original draft yin feng supervision conceptualization methodology writing review editing methodology data curation software investigation resources john blears formal analysis data curation software visualization investigation writing review editing karsten thompson supervision conceptualization methodology funding acquisition project administration resources writing review editing richard hughes supervision conceptualization methodology funding acquisition project administration resources writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper the authors declare the following financial interests personal relationships which may be considered as potential competing interests none acknowledgments this work was supported by the advanced energy consortium http http www beg utexas edu aec with bhp billiton department of energy exxonmobil repsol shell and total as members in addition thanks to boyun guo university of louisiana at lafayette and tianqi ma louisiana state university for providing support and helpful suggestions appendix a derivation of 1d np transport equation along a streamline the np transport equation in 3d porous media can be expressed as follows a 1 c i t v c i d c i r c i s i i 1 m substituting eq 5 from the main body of the paper into eq a 1 gives a 2 c i t v c i α l v c i r c i s i i 1 m applying the transform operation from eq 13 into the advection term of eq a 2 the advection in terms of tof coordinates along a streamline can be expressed as follows a 3 v c i c i τ similarly applying eq 13 again into the dispersion term only streamline oriented longitudinal dispersion considered of eq a 2 gives a 4 α l v c i v s α l v v c i s τ α l v c i τ thus the 1d np transport equation can be expressed by substituting eqs a 3 and a 4 into eq a 2 as follows a 5 c i t c i τ τ α l v c i τ r c i s i i 1 m appendix b algorithm of lagrangian splitting approach as shown in fig 19 assume a nanocapsule has a designed burst time of t b u r s t the injection is started at time t 0 and continues for a period t i n j if the solution timestep is δ t the nanocapsule can be split into n b a t c h t b u r s t δ t batches injected in ceil t b u r s t δ t rounds of batches during each injection round m 1 2 ceil t b u r s t δ t the timestep n t i n j l to inject a batch l 1 2 n b a t c h can be calculated by n t i n j l l n b a t c h m 1 t 0 δ t 1 the burst timestep n t b u r s t i for the batch can be determined as n t b u r s t i n t i n j l t b u r s t δ t the np transport equations for advection eq 21 dispersion eq 22 and reaction terms are solved for each batch individually only when the global timestep reaches the burst timestep for a batch will the payload releasing equations eqs 9 10 be solved using an adaptive cash karp rk algorithm taking the fig 5 as an example assuming a nanocapsule has designed burst time of 3 days with injection time starting on the second day for a period of five days period t i n j simulation timestep is δ t 1 day the nanocapsule can be split into n b a t c h 3 1 3 batches and needs ceil 5 3 2 rounds of batches injection the injection and burst timesteps for the 3rd green batch l 3 at the 1st injection round m 1 are n t i n j 3 3 5 1 1 1 1 1 3 and n t b u r s t 1 3 3 1 6 respectively the injection and burst timesteps for other batches can be calculated accordingly 
349,this work provides a comprehensive analysis of soil water dynamics in australia for the climate projections of the coupled model intercomparison project 6 cmip6 we modelled the historical soil water dynamics from 1981 to 2018 at various depths within and below the root zone using the brtsim computational solver to generate the current conditions we then investigated how the cmip6 scenario can affect water accessibility by plants and hence their potential impact on croplands and native ecosystems we found that surface soil moisture can decline by 7 across australia between 2020 and 2050 with the 2030 decade projected to experience the greatest soil water loss above average precipitation during the 2040s will still lead to 2 soil moisture decline relative to current conditions with about 1 million km2 projected to recover from this deficit later on seasonally our results inferred drier summers and winters with 13 and 5 loss in soil water respectively shrublands and savannas were the most affected native ecosystems with a moisture decline between 16 and 7 within the root zone respectively more importantly 36 to 52 of croplands were found to undergo a 7 decline in soil moisture within the root zone which was spatially and temporally heterogeneous across crop types within the crop calendar wheat growing regions were affected by soil moisture deficiencies from sowing to harvest in almost the entire time frame of our assessment keywords australia soil saturation soil moisture soil water content climate impacts future climate scanraio 1 introduction since the second half of the 19th century global climate data show the persistent rise in atmospheric and oceanic temperature the shrinking of snow and ice caps with the consequent increase of sea level and the altered frequency in extreme hydrological events lenton 2011 allen and zickfeld 2018 because of global warming the frequency of extreme rainfall events and duration of droughts are expected to become more intense trenberth et al 2003 contractor et al 2018 in australia these weather extremes can exacerbate dry conditions and extreme rainfalls that have been experienced across different regions nicholls et al 1997 king et al 2014 ummenhofer et al 2011 cai et al 2011 although extreme variability in weather patterns is a natural part of australia s climate an increase in their frequency and intensity has been observed in the last fifty years across the country the years between 1950 and 2007 have seen a substantial decline in winter and autumn precipitation in southeastern australia murphy and timbal 2008 cai and cowan 2008 larsen and nicholls 2009 in contrast the northern regions have experienced a pronounced increase in annual rainfall dey et al 2019 and references within concurrent with the general decrease in annual precipitation the australian yearly mean temperature has increased by 0 9 c since 1910 western et al 2018 according to the 2019 australia bureau of meteorology annual climate statement bom 2020 2019 has been the warmest year on record with 0 31 c increase compared to the average of the 2000 2009 decade at the same time the frequency and intensity of heatwaves and consequent extreme high temperatures have changed trewin and vermont 2010 showed that in australia high temperature records outnumbered cool records by almost 3 to 1 for daytime maximum temperature and by 5 to 1 for the night time temperature in the period 1957 2009 such changes in climate can interfere in agricultural production and management therefore leading to an increased vulnerability and economic loss on a global scale estimates show that climate change can cause an annual loss from 0 2 to 0 3 of the global economic growth calzadilla et al 2013 costinot et al 2016 contractor et al 2018 in australia the millennium drought 1997 2010 one of the driest periods in australia since 1900 was solely responsible for a steep fall of the agricultural contribution to the australian gdp from 2 9 to 2 4 van dijk et al 2013 according to the australian bureau of agricultural and resource economics and sciences abares the changes in climate observed during 2000 and 2019 have had a negative effect on the profitability of broadacre farms causing the average annual profit of australian farms to drop by 22 in 2000 2019 compared to the period 1950 1999 hughes et al 2019 the loss in revenue during dry years is mainly driven by a decrease in crop yield and a reduction of planted area due to the drought increased frequency and duration of droughts caused by altered patterns in rainfall and rise in temperature are key factors influencing losses for agricultural production during dry periods low atmospheric relative humidity high air temperature and a lack of rainfall can lead to high soil evaporation and plant water demand and a consequent decline in soil moisture within the root zone as a result a decrease in soil moisture can lower plant water uptake alter the soil nutrient biogeochemistry and hence affect plant productivity which is an unfavourable situation during the crop growing season porporato et al 2001 2003 laio et al 2001 these changes have consequences not only for the croplands but also for the native vegetation which may undergo a shift in land cover type saco et al 2018 2020 existing studies on australian ecosystems have analysed how weather patterns affect soil moisture and soil organic matter and their repercussions on the native ecosystems ellsworth et al 2017 murphy et al 2019 dey et al 2019 however these works rely on aridity or drought indexes that assess the soil water content based on the trade off between precipitation and the atmospheric water demand on land using bucket models or alike wei et al 2011 buxton et al 2016 western et al 2018 herold et al 2018 although valid these methods neglect water remobilisation from below ground storage such as from capillary rise or hydraulic lift that feeds the root zone caldwell and richards 1989 huang et al 2017 the lack of a full accounting for the vertical soil moisture dynamics and uplift to roots possibly leads to overestimating the decline in near surface soil moisture and the negative impact of droughts berg et al 2017 and reference within we thereforeadvice that improved assessments of water stress induced by climate change in australian ecosystems may be achieved by a mechanistic accounting for space and time resolved soil water dynamics along the vertical profile from the surface to within and below the root zone note that reconstructions of soil moisture runoff and evapotranspiration exist and are provided by the bureau of meteorology based on the output of the australian water resources assessment landscape models awra l frost et al 2016 van dijk and warren 2010 however these only refer to past conditions from 1911 to present and do not include projections into the future the availability of mechanistic based estimates over climatic projections can therefore aid in assessing the impact of weather variability on the native ecosystem and agriculture anticipating land management operations or adapting strategies to cope with potentially negative effects on the economy this work aims to quantify the soil water dynamics in response to climate projections and highlights the possible negative repercussions on the australian ecosystems and agricultural regions to this end we deploy a mechanistic ecohydrological model on a georeferenced grid of australia to develop a water budget for the historical and projected time frames as follows firstly we used historical precipitation and evapotranspiration data from 1981 to 2018 as boundaries to estimate the soil water dynamics this first step defines the reference scenario of current conditions used for benchmarking next we used the scenario model intercomparison project scenariomips o neill et al 2016 ssp1 of the sixth coupled modelling intercomparison project cmip6 eyring et al 2016 for the expected climate scenario corresponding to 2 6 w m 2 radiative forcing hereafter ssp1 and we estimated the soil water dynamics from 2015 to 2050 our modelling outputs were next analysed in depth in selected geographic regions to determine the differences relative to the historical scenario also we investigated whether deficits in soil water content could be exacerbated by local soil physical and hydraulic conditions especially in regions with decreased rainfall assessing the changes in soil moisture due to future climate on a national scale allows us to identify ecosystems and crops that may undergo water stress this assessment can inform decision and policy making on optimal strategies to mitigate potential losses of the australian environmental asset as a whole 2 materials and methods 2 1 data sourcing data from different sources were combined to set up the modelling framework of this work table s1 supplementary information section 1 historical daily rainfalls from 1981 to 2018 were retrieved from the cps us unified precipitation database provided by the noaa oar esrl psd boulder colorado usa xie et al 2010 the monthly ecosystem specific evapotranspiration from 1981 to 2018 was obtained from the global land evaporation amsterdam model gleam miralles et al 2011 martens et al 2017 both datasets were used as boundary conditions in our modelling work described in section 2 2 to construct the reference simulation at current conditions projections of daily rainfall and monthly evapotranspiration used for assessment against the current conditions were retrieved from the sixth coupled modelling intercomparison project dataset cmip6 eyring et al 2016 in particular we used the scenario model intercomparison project scenariomips o neill et al 2016 that provides climate projections based on the shared socioeconomic pathways ssps these projections consider the effect of society demographics and economics on the greenhouse gas emission and therefore their global warming effect over this century among the ssps we selected the ssp1 which corresponds to the 2 6 w m 2 radiative forcing leading to an increase of about 2 c by 2100 the ssp1 scenario represents the low end of future forcing pathways presented by the scenariomips project which aligns with the paris agreement 2016 that foresees a future where environmentally friendly technologies and renewable energy are used on a global level within within the ssp1 scenarios we selected the mri esm2 0 model yukimoto et al 2019a 2019b because it provides the most complete boundary condition datasets required for our assessment the ssp1 covers the period from 2015 to 2100 but our analyses explicitly refer only to the period from 2015 to 2050 to validate the use of ssp1 scenario over the australian continent in this study we calculated the annual cumulative rainfall and evapotranspiration for the 36 years from 2015 to 2050 and we compared them to historical observations from 1981 to 2019 see details in supplementary information section 2 and 3 all data can be accessed through the cmip6 search interface as described in section 1 table s2 of the supplementary information the soil pore volume distribution index air entry suction and soil absolute permeability were retrieved from dai et al 2019 while the soil porosity was taken from the soilgrids database hengl et al 2017 at seven depths from land surface to 2 m depth the soil residual water saturation and soil thickness were taken from zhang et al 2018 and pelletier et al 2016 respectively the depth of the equilibrium water table was retrieved from the global pattern database in fan et al 2013 we sourced the satellite monthly soil moisture from the esa cci dataset gruber et al 2017 dorigo et al 2017 2019 to validate our model results for the reference scenario 2009 2018 the land cover classification used in this work to identify the native vegetation and corresponding surface area follows the 2016 international geosphere biosphere program igbp sulla menashe and friedl 2018 we further grouped the land cover types into forests inclusive of needle leaved leaf and broadleaf approximately 0 2 million km2 grasslands 1 3 million km2 shrublands inclusive of closed and open region 4 3 million km2 and savannas inclusive of woody savanna 0 3 million km2 in this work we did not consider land cover changes croplands and crop types were aggregated as in monfreda et al 2008 the crop root density crop calendar and irrigation water volume were taken from maggi et al 2020 which used global information of maximum and average crop root density profiles from allen et al 1998 usda scs 1983 and fan et al 2016 conditioned to the corresponding crops in monfreda et al 2008 and ramankutty et al 2008 the crop calendar is a re analysis of the data in sacks et al 2010 conducted to generate a daily gridded normalized crop calendar and to derive the daily irrigation water volume using the data of crop water security in thenkabail et al 2016 the root density distributions of the native vegetation were estimated based on canadell et al 1996 2 2 dynamic process based modelling soil moisture dynamics modelling was conducted using the general purpose multiphase and multi species bio reactive transport simulator brtsim v4 0b maggi 2019 hereafter brtsim brtsim uses hybrid explicit implicit finite volume solvers of the richards equation richards 1931 to describe variably saturated water flow along a one dimensional soil profile with heterogeneous hydraulic characteristics and soil physical properties soil hydraulics are described with the relative permeability water potential water saturation relationships of the brooks corey model brooks and corey 1964 a detailed description of the numerical methods and corresponding convergence criteria used in the brtsim solver can be found in the user manual and technical guide maggi 2020 brtsim was applied to a multi resolution grid i 0 25 0 25 resolution consisting of 7251 grid cells covering the crop and pasture regions selected according to monfreda et al 2008 see section 2 1 and ii 0 50 0 50 resolution consisting of 948 grid cells for the remaining non cropland ecosystems both grids have the bounding box ranging from 11 s to 44 s and from 113 w to 144 w and are three dimensional in each geographic grid cell the soil column extends over three soil layers centred at 15 45 and 80 cm depth with a thickness equal to 30 30 and 40 cm respectively within the first meter of the root zone in the vertical direction to describe the soil below the root zone an additional layer is included with a thickness equal to the distance to the equilibrium water table or bedrock depending on which of the two is closer to the surface both grids also account for one atmospheric layer to allow for ponding water enters and leaves the soil column via precipitation irrigation and evapotranspiration we neglected surface runoff in this work as the runoff to precipitation ratio is generally low in australian catchments i e a median value of 0 15 saft et al 2015 incoming water fluxes were applied at the first soil layer while the evapotranspiration was allocated over the soil profile according to the root distribution the root distribution was calculated based on a negative exponential distribution function assuming that 1 of the root mass was below the maximum root depth the monthly ecosystem specific evapotranspiration used as the boundary flux is intended as the potential evapotranspiration the actual evapotranspiration i e the water actually leaving the soil column is then solved within brtsim and it depends on the soil water available at a particular time step the one dimensional solvers in brtsim calculate the soil moisture dynamics in each of the multiscale grids along the vertical direction prior to modelling all the data described in section 2 1 were harmonized to the corresponding resolution of the two grids using the imresize function in the matlab 2018b environment with a conservative control where needed modelling was implemented in two steps the first step relative to the historical conditions was initialized over the 28 years from 1981 to 2018 and the current conditions corresponded to the 2009 to 2018 period the second step for climate projections was initialized over the years 2015 to 2019 using the ssp1 and the decades to follow were used for analyses we report that one to two years were enough to complete modelling spinup and allow the soil water content in the root zone to reach a statistically stationary state in both steps 2 3 data analyses to quantify the change in soil moisture with respect to a reference we defined the relative anomaly as 1 δ r x δ x x ref where the difference δx is defined as 2 δ x x x ref with x and x ref being the modelled and reference variable in any grid cell and at any depth respectively for benchmarking section 3 1 we used the esa cci dataset gruber et al 2017 dorigo et al 2017 2019 which provides the satellite derived volumetric soil moisture θ in m3m 3 we tested the modelled long term monthly θ averaged across the 2009 2018 period i e the current conditions against the esa cci long term monthly θ averaged across the 1980 2018 period using the pearson s correlation coefficient r we also calculated the absolute anomalies δθ using eq 2 withx referring to the modelled long term average θ for the current conditions and x ref as the long term average θ obtained from the esa cci dataset to understand the control of net recharge percolation and capillary rise on soil water saturation s we quantified the correlation between the monthly averaged modelled s and the monthly averaged net recharge including irrigation i e p irr et of the historical scenario from 1980 to 2018 where p is the precipitation irr is the irrigation and et is the potential evapotranspiration for each grid cell we also calculated the time fraction of water percolating to below the root zone and rising by capillary into the root zone section 3 2 for analyses of the future scenario we assessed the decadal section 3 3 and seasonal section 3 4 changes in soil water saturation as compared to the current conditions by calculating the anomalies using eq 1 with x andx ref referring to the modelled soil water saturation for the ssp1 s ssp1 and the current conditions s ref respectively we then investigated the ecosystems that are mostly affected by decadal variations in soil water saturation section 3 5 we further selected four major crops cultivated in australia namely wheat sorghum maize and cotton to investigate how seasonal variations in soil water saturation overlap with their growing stages section 3 6 spatial parametric variability analyses were conducted using the ama index defined in dell oca et al 2017 as 3 ama e j e f p p j e f p ρ p j d p j e f p where amaej reflects the influence of the parameter pj on the expected value e of the model output f p by quantifying the absolute difference between its expected value conditional to pj against the unconditional one expected values conditional to parameter values are numerically obtained by subdividing samples into classes of different parameter ranges here p p1 pj pn is a vector gathering all soil parameters and ρ pj is the probability distribution function of the parameter pj high values of amaej imply a higher system response to the variability in parameter pj parameters included in this analysis are the porosity φ the absolute permeability k the brooks corey parameters i e pore volume distribution index b and air entry suction ψs the liquid residual saturation s r and the net recharge excluding irrigation i e p et 3 results 3 1 benchmarking of historical soil moisture overall the comparison between long term monthly average between our model output and esa cci data shows no particular seasonal bias in our estimates with r spanning from 0 60 april october and november to about 0 7 for the other months scatter plots in fig 1 the soil moisture estimated using brtsim with the historical forcing presents sparse spatial anomalies as compared to the esa cci data with some overestimation of the soil moisture in the inner areas of australia fig 1a although there is an overall tendency to overestimate the θ values of the esa cci data approximately 64 of grid cells have anomalies ranging within 0 05 m3m 3 with respect to the satellite data white area in fig 1a we slightly underestimated θ in the southeastern region and part of tasmania i e δθ 0 07 m3m 3 these regions are mainly covered by forest and thus suggesting that our modelling may overestimate the plant water uptake 3 2 control of net recharge percolation and capillary rise on soil water saturation the correlation between the monthly averaged net recharge including irrigation p irr et and monthly averaged soil water saturation in the top soil and the root zone decreases from north r between 0 75 and 1 to south r between 0 and 0 25 fig 2 a and b overall results in fig 2a and b signify that the soil water saturation in low correlation regions may not entirely depend on the net recharge from the above ground rather soil can receive water from below ground such as by capillary rise from the aquifer in particular the native ecosystems and croplands are distributed across these high and low correlation regions in a relatively heterogeneous way with only grasslands appearing to rely prevalently on recharge from above ground because the majority of australia is characterized by low correlation between soil saturation and the net recharge a characterisation of the soil hydraulic properties is necessary to describe whether ecosystems are sustained by vertical water flow such as due to percolation downward or capillary rise upward hence we analysed the instantaneous fluxes below the root zone to identify those regions where groundwater can play a vital role in maintaining the soil moisture in the root zone by quantifying the time fraction of water percolation and capillary rise we showed that percolation is significant in the northern regions where the correlation with the net recharge is the highest fig 3 a in contrast territories along the south eastern coast show frequent events of capillary rise for around 60 of the time fig 3b these territories are mainly occupied by croplands and forests two land covers that have a low correlation with the net recharge fig 2c overall figs 2 and 3 reveal that there is no uniform response in soil water content to the surface or below root zone fluxes depending on soil properties the soil water may be controlled by water percolation and capillary rise which may be neglected by climatic metrics this analysis therefore highlights that a mechanistic account of the water percolation and capillary rise can allow in depth characterisation of the soil water dynamics especially within the root zone where the interactions with groundwater become crucial in determining the soil water content and accessibility to ecosystems 3 3 soil moisture in climate projections our analyses of the ten year average soil water saturation over the three projected decades showed a widespread soil drying across australia with respect to the reference scenario in both the top soil 0 to 30 cm and the root zone 0 to 100 cm fig 4 in the near future 2020 29 about 73 of australian land experiences a soil water decline between 15 and 6 at both depths while about 1 1 million km2 recovers soil moisture with respect to the historical scenario between 2030 and 2039 the area undergoing soil water loss increases to roughly 6 5 million km2 86 of the country and experiences an 11 average decline in soil water saturation however above average precipitation during the 2040 49 period lead to improvement with 16 of australia land surface experiencing similar conditions to the historical scenario and 20 about 1 5 million km2 recording an increase between 4 and 11 of soil water fig 4d and h a comparison between water saturation at the surface and within the root zone indicates a vertical stratification in the soil moisture response to climate projections fig 4 the most relevant negative anomalies appeared at the surface especially in the western regions and the south coast marker a and c respecitvely fig 4 the root zone appears the driest in most of central australia marker b stratification shows a wetter soil at greater depth and suggests that a soil water decline would not uniformly occur throughout the vertical direction such stratification is caused by the water stored at greater depths below the root zone which can recharge the root zone by capillary rise an effect that may be neglected by bucket models that do not explicitly solve for the vertical water flow as discussed further in the discussion section 3 4 soil moisture seasonality australia is estimated to experience a severe soil water deficiency especially during the warmer seasons as compared to the reference scenario first and fourth columns in fig 5 during summer only the south eastern regions regain soil water marker a in fig 5 during the cold seasons instead we found a geographic pattern for all the three decades analysed northern and central regions are projected to recover soil moisture during autumn and winter marker c fig 5 similarly part of the coastal areas in queensland qld and new south wales nsw gain soil water during autumn but experience winters drier than the reference scenario especially during the second decade markers a and b in fig 5 as mentioned above the 2030 39 maps show a clear tendency toward arid conditions in all seasons with the only exception of the northern coastal and central regions marker c in fig 5 that show a substantial recovery during the cold seasons second and third columns in fig 5 3 5 water decline in ecosystems with different vegetation covers we analysed the potential deficit caused by changes in soil water saturation highlighted in fig 4 on the australian native vegetation and croplands for each land cover we present the results for the three decades from 2020 to 2049 for the analysis in this section we consider the major agriculture regions as a whole see fig 6 a without differentiating by crop type within each grid cell which are analysed later in section 3 6 covering a total of about 0 2 million km2 forested regions are the least affected by soil water loss with an average area of about 0 1 million km2 gaining 8 to 32 of soil moisture fig 6b conversely shrublands and savannas are largely influenced by the lack of soil water especially during the 2030 decade fig 6e and f respectively over the three decades an average of about 3 4 million km2 of shrublands experience a soil water loss with an overall decline of soil moisture ranging between 16 and 7 similarly savannas experience a 9 of soil water loss over 74 of the surface area grasslands alternate between a 9 loss and 6 gain in soil water with an average of 12 of surface area presenting no significant changes fig 6d the fraction of area experiencing soil water loss in the cropping regions varied between 40 and 38 during the 2020 and 2040 decades with about 35 000 km2 of cultivated area presenting 2 changes to the historical scenario fig 6c during the driest decade 2030 2039 about 0 1 million km2 approximately 53 of the croplands suffered from 12 to 5 soil moisture deficiency 3 6 water decline in croplands as inferred from fig 4 the response to the ssp1 scenario varied across the country and therefore the selected crops i e wheat sorghum maize and cotton were heterogeneously affected the analysis of the surface area undergoing positive or negative variations in soil water saturation shown in fig 7 reveals that an average of 50 of the wheat and maize regions fig 7a and c experience a loss in water saturation during the three decades analysed here approximately 30 to 40 of cotton and sorghum croplands display negative changes but with higher yearly variations fig 7b and d the soil water loss in the driest crop growing regions varies between 10 and 5 by the end of 2049 an important aspect is the soil moisture seasonal variability and its overlap with the crop calendar wheat growing areas can experience a decline of 4 in soil water during the mid season in the 2020 to 2035 period fig 8 a despite showing a 6 recovery in the first half of the 2040 decade solid red line the entire wheat growing season is generally affected by soil water loss severe soil water deficiency was observed in the sorghum and maize regions with a decline from 7 to 5 during the early growing stage in the 2035 to 2039 period fig 8b and c among the four crops cotton is the least affected by soil water deficiency fig 8d however during the three decades analysed the regions experience an average of 10 loss in soil moisture from april to september just before the seeding season with possible consequences on the germination rate due to the lack of water in the soil 3 7 analysis of parametric variability we analysed the effects of parameter variability on the soil water saturation using the ama family metrics described in section 2 3 we considered each grid cell as a model realisation of the soil water saturation dynamics and we calculated the amae indices for all parameters of interest φ k b ψs s r and the net recharge p et using the ten year average in the period 2009 to 2018 as the model output figure s5 and s6 in the supplementary information section 4 show the distribution of the input parameters used for this analysis we found a high response in water saturation to the pore volume distribution index b having high amae values especially in the top soil fig 9 red circles this result is consistent with the physical meaning of the parameter that controls water mobility at low saturation values frequently occurring close to the land surface the porosity φ has amae values of about 0 06 suggesting that soil moisture is less sensitive to variations in φ than other parameters in the top soil and within the root zone the absolute permeability k pore volume distribution index b air entry suction ψs and liquid residual saturation s r have amae values of around 0 1 however within the root zone amae values do not show any prevalent parameter as all soil properties have a similar influence on the variability of the average soil water saturation 4 discussion the results presented in this work mostly agree with those shown in previous studies but highlight the importance of accounting for the vertical water flow in the assessment of water resources in australian ecosystems using the cmip5 rcp8 5 emission scenario berg et al 2017 concluded that future climate projections suggest an overall increase in land aridity between 2070 and 2099 relative to australia their analysis indicates an overall decrease of 10 in surface soil moisture although we concentrated only on a time frame up to 2050 our results lead to similar conclusions with the majority of australian land experiencing dry conditions using the scenario from the new south wales australian capital territory regional climate modelling narclim herold et al 2018 reported on a decrease in seasonal soil moisture over australia in the near future 2020 2039 those results are consistent with ours but with some geographical differences our estimates of the seasonality in soil moisture for the near future fig 5 show the drying of the southeast region during summer and spring in agreement with herold et al 2018 however the northern regions in the northern territory and western australia tend to regain water during the coldest season in contrast with herold et al 2018 results our estimates of soil moisture depend on the hydroclimatic projections provided by the cmip6 scenario although a great effort has been invested in guaranteeing the reliability of the data we notice a substantial difference between scenario projections and historical trends within the overlapping period from 2015 to 2018 the ssp1 scenario shows a decrease in the annual cumulative rainfall with a similar trend observed in the noaa data xie et al 2010 however the ssp1 scenario underpredicts the number of dry days see supplementary information section s2 figure s1 when considering the overlapping years 2015 to 2019 the ssp1 overpredicts the cumulative rainfall by 43 and underestimates the number of dry days by about 6 such differences are worsened by the data relative to 2019 a particularly dry year for australia still if 2019 is considered as an outlier and is excluded from the comparison the ssp1 overprediction in cumulative rainfall reduces to 27 although the cmip6 scenarios are not intended as exact weather forecast the differences observed here indicate that the ssp1 scenario might be in some sense optimistic thus implying a possible overestimation of the soil water availability in the top soil and root zone therefore the extent of native ecosystems and croplands that experience water deficiency can be much wider than that estimated in this study for example decline in soil water content in the majority of shrublands and savannas may result in a shift towards reduced biological productivity leading to desertification and loss of biodiversity although we assumed no crop rotation and no change in agricultural practices in the future scenario our analyses identify the native ecosystems and cropping systems that are susceptible to future climates in these regions tailored management strategies have to be implemented to reduce the negative impacts for example our analyses show that wheat growing areas are among the most impacted suggesting that investments into more effective irrigation infrastructures and the development of wheat varieties with better drought tolerance characteristics are needed in those regions to balance the uncertainty in the climatic scenario mentioned above we presented a method to identify the influence of variability uncertainty in soil physical and hydraulic parameters on the soil water saturation our simplified approach section 3 7 may not be interpreted as a robust sensitivity analysis but as an indication of which parameters influence the soil moisture variability in the top soil 0 to 30 cm and within the root zone 0 to 100 cm however the sensitivity of the soil moisture to the variations of the pore volume distribution index is consistent with feki et al 2018 that performed a more robust sensitivity analysis than the one presented here also implementing alternative models using a different description of the relative permeability and saturation relationships such as the van genuchten model van genuchten 1980 or the hysteresis adsorptive water retention model by minasny et al 2020 can inform on the robustness of model estimates of soil moisture it is essential to mention some numerical and modelling limitations that may be overcome by a future release of the brtsim solver despite incorporating groundwater information our model does not include lateral flow and runoff across each one dimensional soil column over the three dimensional grid surface water and runoff may influence the soil moisture content in regions that have a relatively significant elevation gradient such as near the snowy mountains and other ranges throughout australia in addition the overall overestimation of soil moisture when comparing to the satellite derived data obtained from the esa cci dataset fig 1 is very likely a consequence of not including the surface runoff in our model hence incorporating hydrological information on flow direction and accumulation in our model will provide a better estimation of soil water content and a better analysis of the australian ecohydrological functioning we also acknowledge that our simulations did not account for the heat flux and consequent temperature variability along with the soil profile neglecting their influence on water phase changes accounting for the interplay between water and heat flows may lead to estimate lower soil moisture especially in regions where a higher temperature is predicted by climate projections 5 conclusion we conducted a comprehensive analysis of the soil moisture dynamics over australia using the conservative climate projections of the cmip6 ssp1 2015 to 2050 and historical data of the recent past years 2009 18 our analyses show that the australian soil undergoes heterogeneous soil water variability with regions experiencing losses between 15 and 6 the driest decade 2030 2039 will cause about 6 5 million km2 to suffer from 10 surface soil water decline while only about 1 million km2 will record a positive difference with respect to the current conditions with an average 6 increase in soil water moisture by 2050 an increase of 10 is expected over about 2 million km2 due to an increase in precipitation especially during winter and autumn supplementary information section s2 figure s2 3 these estimates however are subject to the uncertainty of ssp1 which are not quantified or accounted for explicitly in this work seasonally instances of soil water deficiency may affect the warmer seasons except in the south eastern regions geographic differences may be exacerbated during the cold seasons northern regions are generally wetter than in the reference scenario during winter and autumn south eastern regions retain or acquire more soil water during autumn but become drier during winter on the other hand water saturation changes observed in tasmania do not show any seasonal and decadal trend among the considered land cover types forests are the least affected by soil water loss more than 80 of shrublands and savannas are affected by soil water loss while grasslands alternate between 9 loss and 6 gain in soil water sorghum and cotton croplands experience cyclic dry and wet conditions with the year 2035 involving the broadest increase in soil moisture as compared to current conditions dry conditions in wheat growing regions are estimated to reach a maximum of 92 000 km2 81 of the covered area in 2048 more importantly we found a high occurrence of dry conditions before and during crop development stages between april and august in most cropping regions thus implying potential consequences on yield overall the presented results suggest a relevant impact of climate change on water availability on the australian ecosystems in particular this work can be used to assess future planning of agricultural development and water policies kiem 2013 especially in areas that are projected to be affected by the most severe soil water decrease code and data availability the brtsim solver package can be downloaded at https sites google com site thebrtsimproject download or by contacting the author data output of simulations used for analyses in this work about 77 gb are not distributed but can be inquired to the authors animations of the soil water saturation dynamics are available as interpretation aid to the reader at https doi org 10 6084 m9 figshare 12470096 v1 credit authorship contribution statement magda guglielmo investigation software formal analysis visualization validation data curation methodology writing original draft dario zambonini validation formal analysis giovanni porta formal analysis writing review editing arunima malik conceptualization validation data curation methodology writing review editing fiona h m tang writing review editing federico maggi supervision conceptualization software data curation funding acquisition writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is supported by the centre for translational data science ctds incubator fund and by the srei2020 of the university of sydney the authors acknowledge the sydney informatics hub and the university of sydney s high performance computing cluster artemis for providing the high performance computing resources that have contributed to the results reported within this work we thank sally cripps and richard scalzo for the conversations and feedback about weather spatial modelling we thank budiman minasny for his feedback on the modelling and analyses conducted in this work we thanks also two anonymous reviewers for their constructive comments to out work supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103837 appendix supplementary materials image application 1 
349,this work provides a comprehensive analysis of soil water dynamics in australia for the climate projections of the coupled model intercomparison project 6 cmip6 we modelled the historical soil water dynamics from 1981 to 2018 at various depths within and below the root zone using the brtsim computational solver to generate the current conditions we then investigated how the cmip6 scenario can affect water accessibility by plants and hence their potential impact on croplands and native ecosystems we found that surface soil moisture can decline by 7 across australia between 2020 and 2050 with the 2030 decade projected to experience the greatest soil water loss above average precipitation during the 2040s will still lead to 2 soil moisture decline relative to current conditions with about 1 million km2 projected to recover from this deficit later on seasonally our results inferred drier summers and winters with 13 and 5 loss in soil water respectively shrublands and savannas were the most affected native ecosystems with a moisture decline between 16 and 7 within the root zone respectively more importantly 36 to 52 of croplands were found to undergo a 7 decline in soil moisture within the root zone which was spatially and temporally heterogeneous across crop types within the crop calendar wheat growing regions were affected by soil moisture deficiencies from sowing to harvest in almost the entire time frame of our assessment keywords australia soil saturation soil moisture soil water content climate impacts future climate scanraio 1 introduction since the second half of the 19th century global climate data show the persistent rise in atmospheric and oceanic temperature the shrinking of snow and ice caps with the consequent increase of sea level and the altered frequency in extreme hydrological events lenton 2011 allen and zickfeld 2018 because of global warming the frequency of extreme rainfall events and duration of droughts are expected to become more intense trenberth et al 2003 contractor et al 2018 in australia these weather extremes can exacerbate dry conditions and extreme rainfalls that have been experienced across different regions nicholls et al 1997 king et al 2014 ummenhofer et al 2011 cai et al 2011 although extreme variability in weather patterns is a natural part of australia s climate an increase in their frequency and intensity has been observed in the last fifty years across the country the years between 1950 and 2007 have seen a substantial decline in winter and autumn precipitation in southeastern australia murphy and timbal 2008 cai and cowan 2008 larsen and nicholls 2009 in contrast the northern regions have experienced a pronounced increase in annual rainfall dey et al 2019 and references within concurrent with the general decrease in annual precipitation the australian yearly mean temperature has increased by 0 9 c since 1910 western et al 2018 according to the 2019 australia bureau of meteorology annual climate statement bom 2020 2019 has been the warmest year on record with 0 31 c increase compared to the average of the 2000 2009 decade at the same time the frequency and intensity of heatwaves and consequent extreme high temperatures have changed trewin and vermont 2010 showed that in australia high temperature records outnumbered cool records by almost 3 to 1 for daytime maximum temperature and by 5 to 1 for the night time temperature in the period 1957 2009 such changes in climate can interfere in agricultural production and management therefore leading to an increased vulnerability and economic loss on a global scale estimates show that climate change can cause an annual loss from 0 2 to 0 3 of the global economic growth calzadilla et al 2013 costinot et al 2016 contractor et al 2018 in australia the millennium drought 1997 2010 one of the driest periods in australia since 1900 was solely responsible for a steep fall of the agricultural contribution to the australian gdp from 2 9 to 2 4 van dijk et al 2013 according to the australian bureau of agricultural and resource economics and sciences abares the changes in climate observed during 2000 and 2019 have had a negative effect on the profitability of broadacre farms causing the average annual profit of australian farms to drop by 22 in 2000 2019 compared to the period 1950 1999 hughes et al 2019 the loss in revenue during dry years is mainly driven by a decrease in crop yield and a reduction of planted area due to the drought increased frequency and duration of droughts caused by altered patterns in rainfall and rise in temperature are key factors influencing losses for agricultural production during dry periods low atmospheric relative humidity high air temperature and a lack of rainfall can lead to high soil evaporation and plant water demand and a consequent decline in soil moisture within the root zone as a result a decrease in soil moisture can lower plant water uptake alter the soil nutrient biogeochemistry and hence affect plant productivity which is an unfavourable situation during the crop growing season porporato et al 2001 2003 laio et al 2001 these changes have consequences not only for the croplands but also for the native vegetation which may undergo a shift in land cover type saco et al 2018 2020 existing studies on australian ecosystems have analysed how weather patterns affect soil moisture and soil organic matter and their repercussions on the native ecosystems ellsworth et al 2017 murphy et al 2019 dey et al 2019 however these works rely on aridity or drought indexes that assess the soil water content based on the trade off between precipitation and the atmospheric water demand on land using bucket models or alike wei et al 2011 buxton et al 2016 western et al 2018 herold et al 2018 although valid these methods neglect water remobilisation from below ground storage such as from capillary rise or hydraulic lift that feeds the root zone caldwell and richards 1989 huang et al 2017 the lack of a full accounting for the vertical soil moisture dynamics and uplift to roots possibly leads to overestimating the decline in near surface soil moisture and the negative impact of droughts berg et al 2017 and reference within we thereforeadvice that improved assessments of water stress induced by climate change in australian ecosystems may be achieved by a mechanistic accounting for space and time resolved soil water dynamics along the vertical profile from the surface to within and below the root zone note that reconstructions of soil moisture runoff and evapotranspiration exist and are provided by the bureau of meteorology based on the output of the australian water resources assessment landscape models awra l frost et al 2016 van dijk and warren 2010 however these only refer to past conditions from 1911 to present and do not include projections into the future the availability of mechanistic based estimates over climatic projections can therefore aid in assessing the impact of weather variability on the native ecosystem and agriculture anticipating land management operations or adapting strategies to cope with potentially negative effects on the economy this work aims to quantify the soil water dynamics in response to climate projections and highlights the possible negative repercussions on the australian ecosystems and agricultural regions to this end we deploy a mechanistic ecohydrological model on a georeferenced grid of australia to develop a water budget for the historical and projected time frames as follows firstly we used historical precipitation and evapotranspiration data from 1981 to 2018 as boundaries to estimate the soil water dynamics this first step defines the reference scenario of current conditions used for benchmarking next we used the scenario model intercomparison project scenariomips o neill et al 2016 ssp1 of the sixth coupled modelling intercomparison project cmip6 eyring et al 2016 for the expected climate scenario corresponding to 2 6 w m 2 radiative forcing hereafter ssp1 and we estimated the soil water dynamics from 2015 to 2050 our modelling outputs were next analysed in depth in selected geographic regions to determine the differences relative to the historical scenario also we investigated whether deficits in soil water content could be exacerbated by local soil physical and hydraulic conditions especially in regions with decreased rainfall assessing the changes in soil moisture due to future climate on a national scale allows us to identify ecosystems and crops that may undergo water stress this assessment can inform decision and policy making on optimal strategies to mitigate potential losses of the australian environmental asset as a whole 2 materials and methods 2 1 data sourcing data from different sources were combined to set up the modelling framework of this work table s1 supplementary information section 1 historical daily rainfalls from 1981 to 2018 were retrieved from the cps us unified precipitation database provided by the noaa oar esrl psd boulder colorado usa xie et al 2010 the monthly ecosystem specific evapotranspiration from 1981 to 2018 was obtained from the global land evaporation amsterdam model gleam miralles et al 2011 martens et al 2017 both datasets were used as boundary conditions in our modelling work described in section 2 2 to construct the reference simulation at current conditions projections of daily rainfall and monthly evapotranspiration used for assessment against the current conditions were retrieved from the sixth coupled modelling intercomparison project dataset cmip6 eyring et al 2016 in particular we used the scenario model intercomparison project scenariomips o neill et al 2016 that provides climate projections based on the shared socioeconomic pathways ssps these projections consider the effect of society demographics and economics on the greenhouse gas emission and therefore their global warming effect over this century among the ssps we selected the ssp1 which corresponds to the 2 6 w m 2 radiative forcing leading to an increase of about 2 c by 2100 the ssp1 scenario represents the low end of future forcing pathways presented by the scenariomips project which aligns with the paris agreement 2016 that foresees a future where environmentally friendly technologies and renewable energy are used on a global level within within the ssp1 scenarios we selected the mri esm2 0 model yukimoto et al 2019a 2019b because it provides the most complete boundary condition datasets required for our assessment the ssp1 covers the period from 2015 to 2100 but our analyses explicitly refer only to the period from 2015 to 2050 to validate the use of ssp1 scenario over the australian continent in this study we calculated the annual cumulative rainfall and evapotranspiration for the 36 years from 2015 to 2050 and we compared them to historical observations from 1981 to 2019 see details in supplementary information section 2 and 3 all data can be accessed through the cmip6 search interface as described in section 1 table s2 of the supplementary information the soil pore volume distribution index air entry suction and soil absolute permeability were retrieved from dai et al 2019 while the soil porosity was taken from the soilgrids database hengl et al 2017 at seven depths from land surface to 2 m depth the soil residual water saturation and soil thickness were taken from zhang et al 2018 and pelletier et al 2016 respectively the depth of the equilibrium water table was retrieved from the global pattern database in fan et al 2013 we sourced the satellite monthly soil moisture from the esa cci dataset gruber et al 2017 dorigo et al 2017 2019 to validate our model results for the reference scenario 2009 2018 the land cover classification used in this work to identify the native vegetation and corresponding surface area follows the 2016 international geosphere biosphere program igbp sulla menashe and friedl 2018 we further grouped the land cover types into forests inclusive of needle leaved leaf and broadleaf approximately 0 2 million km2 grasslands 1 3 million km2 shrublands inclusive of closed and open region 4 3 million km2 and savannas inclusive of woody savanna 0 3 million km2 in this work we did not consider land cover changes croplands and crop types were aggregated as in monfreda et al 2008 the crop root density crop calendar and irrigation water volume were taken from maggi et al 2020 which used global information of maximum and average crop root density profiles from allen et al 1998 usda scs 1983 and fan et al 2016 conditioned to the corresponding crops in monfreda et al 2008 and ramankutty et al 2008 the crop calendar is a re analysis of the data in sacks et al 2010 conducted to generate a daily gridded normalized crop calendar and to derive the daily irrigation water volume using the data of crop water security in thenkabail et al 2016 the root density distributions of the native vegetation were estimated based on canadell et al 1996 2 2 dynamic process based modelling soil moisture dynamics modelling was conducted using the general purpose multiphase and multi species bio reactive transport simulator brtsim v4 0b maggi 2019 hereafter brtsim brtsim uses hybrid explicit implicit finite volume solvers of the richards equation richards 1931 to describe variably saturated water flow along a one dimensional soil profile with heterogeneous hydraulic characteristics and soil physical properties soil hydraulics are described with the relative permeability water potential water saturation relationships of the brooks corey model brooks and corey 1964 a detailed description of the numerical methods and corresponding convergence criteria used in the brtsim solver can be found in the user manual and technical guide maggi 2020 brtsim was applied to a multi resolution grid i 0 25 0 25 resolution consisting of 7251 grid cells covering the crop and pasture regions selected according to monfreda et al 2008 see section 2 1 and ii 0 50 0 50 resolution consisting of 948 grid cells for the remaining non cropland ecosystems both grids have the bounding box ranging from 11 s to 44 s and from 113 w to 144 w and are three dimensional in each geographic grid cell the soil column extends over three soil layers centred at 15 45 and 80 cm depth with a thickness equal to 30 30 and 40 cm respectively within the first meter of the root zone in the vertical direction to describe the soil below the root zone an additional layer is included with a thickness equal to the distance to the equilibrium water table or bedrock depending on which of the two is closer to the surface both grids also account for one atmospheric layer to allow for ponding water enters and leaves the soil column via precipitation irrigation and evapotranspiration we neglected surface runoff in this work as the runoff to precipitation ratio is generally low in australian catchments i e a median value of 0 15 saft et al 2015 incoming water fluxes were applied at the first soil layer while the evapotranspiration was allocated over the soil profile according to the root distribution the root distribution was calculated based on a negative exponential distribution function assuming that 1 of the root mass was below the maximum root depth the monthly ecosystem specific evapotranspiration used as the boundary flux is intended as the potential evapotranspiration the actual evapotranspiration i e the water actually leaving the soil column is then solved within brtsim and it depends on the soil water available at a particular time step the one dimensional solvers in brtsim calculate the soil moisture dynamics in each of the multiscale grids along the vertical direction prior to modelling all the data described in section 2 1 were harmonized to the corresponding resolution of the two grids using the imresize function in the matlab 2018b environment with a conservative control where needed modelling was implemented in two steps the first step relative to the historical conditions was initialized over the 28 years from 1981 to 2018 and the current conditions corresponded to the 2009 to 2018 period the second step for climate projections was initialized over the years 2015 to 2019 using the ssp1 and the decades to follow were used for analyses we report that one to two years were enough to complete modelling spinup and allow the soil water content in the root zone to reach a statistically stationary state in both steps 2 3 data analyses to quantify the change in soil moisture with respect to a reference we defined the relative anomaly as 1 δ r x δ x x ref where the difference δx is defined as 2 δ x x x ref with x and x ref being the modelled and reference variable in any grid cell and at any depth respectively for benchmarking section 3 1 we used the esa cci dataset gruber et al 2017 dorigo et al 2017 2019 which provides the satellite derived volumetric soil moisture θ in m3m 3 we tested the modelled long term monthly θ averaged across the 2009 2018 period i e the current conditions against the esa cci long term monthly θ averaged across the 1980 2018 period using the pearson s correlation coefficient r we also calculated the absolute anomalies δθ using eq 2 withx referring to the modelled long term average θ for the current conditions and x ref as the long term average θ obtained from the esa cci dataset to understand the control of net recharge percolation and capillary rise on soil water saturation s we quantified the correlation between the monthly averaged modelled s and the monthly averaged net recharge including irrigation i e p irr et of the historical scenario from 1980 to 2018 where p is the precipitation irr is the irrigation and et is the potential evapotranspiration for each grid cell we also calculated the time fraction of water percolating to below the root zone and rising by capillary into the root zone section 3 2 for analyses of the future scenario we assessed the decadal section 3 3 and seasonal section 3 4 changes in soil water saturation as compared to the current conditions by calculating the anomalies using eq 1 with x andx ref referring to the modelled soil water saturation for the ssp1 s ssp1 and the current conditions s ref respectively we then investigated the ecosystems that are mostly affected by decadal variations in soil water saturation section 3 5 we further selected four major crops cultivated in australia namely wheat sorghum maize and cotton to investigate how seasonal variations in soil water saturation overlap with their growing stages section 3 6 spatial parametric variability analyses were conducted using the ama index defined in dell oca et al 2017 as 3 ama e j e f p p j e f p ρ p j d p j e f p where amaej reflects the influence of the parameter pj on the expected value e of the model output f p by quantifying the absolute difference between its expected value conditional to pj against the unconditional one expected values conditional to parameter values are numerically obtained by subdividing samples into classes of different parameter ranges here p p1 pj pn is a vector gathering all soil parameters and ρ pj is the probability distribution function of the parameter pj high values of amaej imply a higher system response to the variability in parameter pj parameters included in this analysis are the porosity φ the absolute permeability k the brooks corey parameters i e pore volume distribution index b and air entry suction ψs the liquid residual saturation s r and the net recharge excluding irrigation i e p et 3 results 3 1 benchmarking of historical soil moisture overall the comparison between long term monthly average between our model output and esa cci data shows no particular seasonal bias in our estimates with r spanning from 0 60 april october and november to about 0 7 for the other months scatter plots in fig 1 the soil moisture estimated using brtsim with the historical forcing presents sparse spatial anomalies as compared to the esa cci data with some overestimation of the soil moisture in the inner areas of australia fig 1a although there is an overall tendency to overestimate the θ values of the esa cci data approximately 64 of grid cells have anomalies ranging within 0 05 m3m 3 with respect to the satellite data white area in fig 1a we slightly underestimated θ in the southeastern region and part of tasmania i e δθ 0 07 m3m 3 these regions are mainly covered by forest and thus suggesting that our modelling may overestimate the plant water uptake 3 2 control of net recharge percolation and capillary rise on soil water saturation the correlation between the monthly averaged net recharge including irrigation p irr et and monthly averaged soil water saturation in the top soil and the root zone decreases from north r between 0 75 and 1 to south r between 0 and 0 25 fig 2 a and b overall results in fig 2a and b signify that the soil water saturation in low correlation regions may not entirely depend on the net recharge from the above ground rather soil can receive water from below ground such as by capillary rise from the aquifer in particular the native ecosystems and croplands are distributed across these high and low correlation regions in a relatively heterogeneous way with only grasslands appearing to rely prevalently on recharge from above ground because the majority of australia is characterized by low correlation between soil saturation and the net recharge a characterisation of the soil hydraulic properties is necessary to describe whether ecosystems are sustained by vertical water flow such as due to percolation downward or capillary rise upward hence we analysed the instantaneous fluxes below the root zone to identify those regions where groundwater can play a vital role in maintaining the soil moisture in the root zone by quantifying the time fraction of water percolation and capillary rise we showed that percolation is significant in the northern regions where the correlation with the net recharge is the highest fig 3 a in contrast territories along the south eastern coast show frequent events of capillary rise for around 60 of the time fig 3b these territories are mainly occupied by croplands and forests two land covers that have a low correlation with the net recharge fig 2c overall figs 2 and 3 reveal that there is no uniform response in soil water content to the surface or below root zone fluxes depending on soil properties the soil water may be controlled by water percolation and capillary rise which may be neglected by climatic metrics this analysis therefore highlights that a mechanistic account of the water percolation and capillary rise can allow in depth characterisation of the soil water dynamics especially within the root zone where the interactions with groundwater become crucial in determining the soil water content and accessibility to ecosystems 3 3 soil moisture in climate projections our analyses of the ten year average soil water saturation over the three projected decades showed a widespread soil drying across australia with respect to the reference scenario in both the top soil 0 to 30 cm and the root zone 0 to 100 cm fig 4 in the near future 2020 29 about 73 of australian land experiences a soil water decline between 15 and 6 at both depths while about 1 1 million km2 recovers soil moisture with respect to the historical scenario between 2030 and 2039 the area undergoing soil water loss increases to roughly 6 5 million km2 86 of the country and experiences an 11 average decline in soil water saturation however above average precipitation during the 2040 49 period lead to improvement with 16 of australia land surface experiencing similar conditions to the historical scenario and 20 about 1 5 million km2 recording an increase between 4 and 11 of soil water fig 4d and h a comparison between water saturation at the surface and within the root zone indicates a vertical stratification in the soil moisture response to climate projections fig 4 the most relevant negative anomalies appeared at the surface especially in the western regions and the south coast marker a and c respecitvely fig 4 the root zone appears the driest in most of central australia marker b stratification shows a wetter soil at greater depth and suggests that a soil water decline would not uniformly occur throughout the vertical direction such stratification is caused by the water stored at greater depths below the root zone which can recharge the root zone by capillary rise an effect that may be neglected by bucket models that do not explicitly solve for the vertical water flow as discussed further in the discussion section 3 4 soil moisture seasonality australia is estimated to experience a severe soil water deficiency especially during the warmer seasons as compared to the reference scenario first and fourth columns in fig 5 during summer only the south eastern regions regain soil water marker a in fig 5 during the cold seasons instead we found a geographic pattern for all the three decades analysed northern and central regions are projected to recover soil moisture during autumn and winter marker c fig 5 similarly part of the coastal areas in queensland qld and new south wales nsw gain soil water during autumn but experience winters drier than the reference scenario especially during the second decade markers a and b in fig 5 as mentioned above the 2030 39 maps show a clear tendency toward arid conditions in all seasons with the only exception of the northern coastal and central regions marker c in fig 5 that show a substantial recovery during the cold seasons second and third columns in fig 5 3 5 water decline in ecosystems with different vegetation covers we analysed the potential deficit caused by changes in soil water saturation highlighted in fig 4 on the australian native vegetation and croplands for each land cover we present the results for the three decades from 2020 to 2049 for the analysis in this section we consider the major agriculture regions as a whole see fig 6 a without differentiating by crop type within each grid cell which are analysed later in section 3 6 covering a total of about 0 2 million km2 forested regions are the least affected by soil water loss with an average area of about 0 1 million km2 gaining 8 to 32 of soil moisture fig 6b conversely shrublands and savannas are largely influenced by the lack of soil water especially during the 2030 decade fig 6e and f respectively over the three decades an average of about 3 4 million km2 of shrublands experience a soil water loss with an overall decline of soil moisture ranging between 16 and 7 similarly savannas experience a 9 of soil water loss over 74 of the surface area grasslands alternate between a 9 loss and 6 gain in soil water with an average of 12 of surface area presenting no significant changes fig 6d the fraction of area experiencing soil water loss in the cropping regions varied between 40 and 38 during the 2020 and 2040 decades with about 35 000 km2 of cultivated area presenting 2 changes to the historical scenario fig 6c during the driest decade 2030 2039 about 0 1 million km2 approximately 53 of the croplands suffered from 12 to 5 soil moisture deficiency 3 6 water decline in croplands as inferred from fig 4 the response to the ssp1 scenario varied across the country and therefore the selected crops i e wheat sorghum maize and cotton were heterogeneously affected the analysis of the surface area undergoing positive or negative variations in soil water saturation shown in fig 7 reveals that an average of 50 of the wheat and maize regions fig 7a and c experience a loss in water saturation during the three decades analysed here approximately 30 to 40 of cotton and sorghum croplands display negative changes but with higher yearly variations fig 7b and d the soil water loss in the driest crop growing regions varies between 10 and 5 by the end of 2049 an important aspect is the soil moisture seasonal variability and its overlap with the crop calendar wheat growing areas can experience a decline of 4 in soil water during the mid season in the 2020 to 2035 period fig 8 a despite showing a 6 recovery in the first half of the 2040 decade solid red line the entire wheat growing season is generally affected by soil water loss severe soil water deficiency was observed in the sorghum and maize regions with a decline from 7 to 5 during the early growing stage in the 2035 to 2039 period fig 8b and c among the four crops cotton is the least affected by soil water deficiency fig 8d however during the three decades analysed the regions experience an average of 10 loss in soil moisture from april to september just before the seeding season with possible consequences on the germination rate due to the lack of water in the soil 3 7 analysis of parametric variability we analysed the effects of parameter variability on the soil water saturation using the ama family metrics described in section 2 3 we considered each grid cell as a model realisation of the soil water saturation dynamics and we calculated the amae indices for all parameters of interest φ k b ψs s r and the net recharge p et using the ten year average in the period 2009 to 2018 as the model output figure s5 and s6 in the supplementary information section 4 show the distribution of the input parameters used for this analysis we found a high response in water saturation to the pore volume distribution index b having high amae values especially in the top soil fig 9 red circles this result is consistent with the physical meaning of the parameter that controls water mobility at low saturation values frequently occurring close to the land surface the porosity φ has amae values of about 0 06 suggesting that soil moisture is less sensitive to variations in φ than other parameters in the top soil and within the root zone the absolute permeability k pore volume distribution index b air entry suction ψs and liquid residual saturation s r have amae values of around 0 1 however within the root zone amae values do not show any prevalent parameter as all soil properties have a similar influence on the variability of the average soil water saturation 4 discussion the results presented in this work mostly agree with those shown in previous studies but highlight the importance of accounting for the vertical water flow in the assessment of water resources in australian ecosystems using the cmip5 rcp8 5 emission scenario berg et al 2017 concluded that future climate projections suggest an overall increase in land aridity between 2070 and 2099 relative to australia their analysis indicates an overall decrease of 10 in surface soil moisture although we concentrated only on a time frame up to 2050 our results lead to similar conclusions with the majority of australian land experiencing dry conditions using the scenario from the new south wales australian capital territory regional climate modelling narclim herold et al 2018 reported on a decrease in seasonal soil moisture over australia in the near future 2020 2039 those results are consistent with ours but with some geographical differences our estimates of the seasonality in soil moisture for the near future fig 5 show the drying of the southeast region during summer and spring in agreement with herold et al 2018 however the northern regions in the northern territory and western australia tend to regain water during the coldest season in contrast with herold et al 2018 results our estimates of soil moisture depend on the hydroclimatic projections provided by the cmip6 scenario although a great effort has been invested in guaranteeing the reliability of the data we notice a substantial difference between scenario projections and historical trends within the overlapping period from 2015 to 2018 the ssp1 scenario shows a decrease in the annual cumulative rainfall with a similar trend observed in the noaa data xie et al 2010 however the ssp1 scenario underpredicts the number of dry days see supplementary information section s2 figure s1 when considering the overlapping years 2015 to 2019 the ssp1 overpredicts the cumulative rainfall by 43 and underestimates the number of dry days by about 6 such differences are worsened by the data relative to 2019 a particularly dry year for australia still if 2019 is considered as an outlier and is excluded from the comparison the ssp1 overprediction in cumulative rainfall reduces to 27 although the cmip6 scenarios are not intended as exact weather forecast the differences observed here indicate that the ssp1 scenario might be in some sense optimistic thus implying a possible overestimation of the soil water availability in the top soil and root zone therefore the extent of native ecosystems and croplands that experience water deficiency can be much wider than that estimated in this study for example decline in soil water content in the majority of shrublands and savannas may result in a shift towards reduced biological productivity leading to desertification and loss of biodiversity although we assumed no crop rotation and no change in agricultural practices in the future scenario our analyses identify the native ecosystems and cropping systems that are susceptible to future climates in these regions tailored management strategies have to be implemented to reduce the negative impacts for example our analyses show that wheat growing areas are among the most impacted suggesting that investments into more effective irrigation infrastructures and the development of wheat varieties with better drought tolerance characteristics are needed in those regions to balance the uncertainty in the climatic scenario mentioned above we presented a method to identify the influence of variability uncertainty in soil physical and hydraulic parameters on the soil water saturation our simplified approach section 3 7 may not be interpreted as a robust sensitivity analysis but as an indication of which parameters influence the soil moisture variability in the top soil 0 to 30 cm and within the root zone 0 to 100 cm however the sensitivity of the soil moisture to the variations of the pore volume distribution index is consistent with feki et al 2018 that performed a more robust sensitivity analysis than the one presented here also implementing alternative models using a different description of the relative permeability and saturation relationships such as the van genuchten model van genuchten 1980 or the hysteresis adsorptive water retention model by minasny et al 2020 can inform on the robustness of model estimates of soil moisture it is essential to mention some numerical and modelling limitations that may be overcome by a future release of the brtsim solver despite incorporating groundwater information our model does not include lateral flow and runoff across each one dimensional soil column over the three dimensional grid surface water and runoff may influence the soil moisture content in regions that have a relatively significant elevation gradient such as near the snowy mountains and other ranges throughout australia in addition the overall overestimation of soil moisture when comparing to the satellite derived data obtained from the esa cci dataset fig 1 is very likely a consequence of not including the surface runoff in our model hence incorporating hydrological information on flow direction and accumulation in our model will provide a better estimation of soil water content and a better analysis of the australian ecohydrological functioning we also acknowledge that our simulations did not account for the heat flux and consequent temperature variability along with the soil profile neglecting their influence on water phase changes accounting for the interplay between water and heat flows may lead to estimate lower soil moisture especially in regions where a higher temperature is predicted by climate projections 5 conclusion we conducted a comprehensive analysis of the soil moisture dynamics over australia using the conservative climate projections of the cmip6 ssp1 2015 to 2050 and historical data of the recent past years 2009 18 our analyses show that the australian soil undergoes heterogeneous soil water variability with regions experiencing losses between 15 and 6 the driest decade 2030 2039 will cause about 6 5 million km2 to suffer from 10 surface soil water decline while only about 1 million km2 will record a positive difference with respect to the current conditions with an average 6 increase in soil water moisture by 2050 an increase of 10 is expected over about 2 million km2 due to an increase in precipitation especially during winter and autumn supplementary information section s2 figure s2 3 these estimates however are subject to the uncertainty of ssp1 which are not quantified or accounted for explicitly in this work seasonally instances of soil water deficiency may affect the warmer seasons except in the south eastern regions geographic differences may be exacerbated during the cold seasons northern regions are generally wetter than in the reference scenario during winter and autumn south eastern regions retain or acquire more soil water during autumn but become drier during winter on the other hand water saturation changes observed in tasmania do not show any seasonal and decadal trend among the considered land cover types forests are the least affected by soil water loss more than 80 of shrublands and savannas are affected by soil water loss while grasslands alternate between 9 loss and 6 gain in soil water sorghum and cotton croplands experience cyclic dry and wet conditions with the year 2035 involving the broadest increase in soil moisture as compared to current conditions dry conditions in wheat growing regions are estimated to reach a maximum of 92 000 km2 81 of the covered area in 2048 more importantly we found a high occurrence of dry conditions before and during crop development stages between april and august in most cropping regions thus implying potential consequences on yield overall the presented results suggest a relevant impact of climate change on water availability on the australian ecosystems in particular this work can be used to assess future planning of agricultural development and water policies kiem 2013 especially in areas that are projected to be affected by the most severe soil water decrease code and data availability the brtsim solver package can be downloaded at https sites google com site thebrtsimproject download or by contacting the author data output of simulations used for analyses in this work about 77 gb are not distributed but can be inquired to the authors animations of the soil water saturation dynamics are available as interpretation aid to the reader at https doi org 10 6084 m9 figshare 12470096 v1 credit authorship contribution statement magda guglielmo investigation software formal analysis visualization validation data curation methodology writing original draft dario zambonini validation formal analysis giovanni porta formal analysis writing review editing arunima malik conceptualization validation data curation methodology writing review editing fiona h m tang writing review editing federico maggi supervision conceptualization software data curation funding acquisition writing review editing declaration of competing interest the authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper acknowledgments this work is supported by the centre for translational data science ctds incubator fund and by the srei2020 of the university of sydney the authors acknowledge the sydney informatics hub and the university of sydney s high performance computing cluster artemis for providing the high performance computing resources that have contributed to the results reported within this work we thank sally cripps and richard scalzo for the conversations and feedback about weather spatial modelling we thank budiman minasny for his feedback on the modelling and analyses conducted in this work we thanks also two anonymous reviewers for their constructive comments to out work supplementary materials supplementary material associated with this article can be found in the online version at doi 10 1016 j advwatres 2020 103837 appendix supplementary materials image application 1 
